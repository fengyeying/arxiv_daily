<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 22 Aug 23  to  Wed 23 Aug 23, announced Thu, 24 Aug 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item285">Cross-lists</a></li>
<li><a href="#item340">Replacements</a></li>
</ul>
<small>[ total of 505 entries:  <b>1-505</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 24 Aug 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11619" title="Abstract">arXiv:2308.11619</a> [<a href="/pdf/2308.11619" title="Download PDF">pdf</a>, <a href="/ps/2308.11619" title="Download PostScript">ps</a>, <a href="/format/2308.11619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An algorithm to approximate the real trilogarithm for a real argument
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voigt%2C+A">Alexander Voigt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 tables, attached source code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; High Energy Physics - Phenomenology (hep-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present an algorithm to approximate the real trilogarithm for a real
argument with IEEE 754-1985 double precision accuracy. The approximation is
structured such that it can make use of instruction-level parallelism when
executed on appropriate CPUs.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11620" title="Abstract">arXiv:2308.11620</a> [<a href="/pdf/2308.11620" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software-based signal compression algorithm for ROM-stored electrical  cables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngoy%2C+T+J">Tshimankinda Jerome Ngoy</a>, 
<a href="/search/cs?searchtype=author&query=Nkongolo%2C+M">Mike Nkongolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the International Journal of Reconfigurable and Embedded Systems (IJRES). Section: Reconfigurable System. Title: A Signal Compression Algorithm Transmitted by the Software for Electrical Cables Stored in ROM. Article ID: 21019. Editor: Selvakumar Manickam. Review Initiated: 2023-07-07
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Hardware Architecture (cs.AR); Signal Processing (eess.SP)

</div>
<p class="mathjax">This project introduces a groundbreaking approach to address the challenge of
periodic signal compression. By proposing a novel adaptive coding method,
coupled with hardware-assisted data compression, we have developed a new
architecture model tailored for efficient data compression. The selected
compression scheme has demonstrated remarkable results, showcasing reduced
memory communication volume and power consumption in the cache memory path of
benchmark systems. With a reduction range of 4.2% to 35.2%, this innovation
paves the way for affordable smart sensing, monitoring, diagnostics, and
protection in emerging low-cost device types. Consequently, this cutting-edge
technology enhances electrical signal compression and contributes to grid
improvement. Additionally, we explore the novel application of harnessing
wasted thermal energy in the Read-Only Memory (ROM) using thermoelectricity
(TE). This approach captures the excess thermal energy, converting it into
electrical energy through optimized supercapacitor charging, resulting in
efficient energy utilization. This innovation intersects the fields of embedded
systems, data compression, energy efficiency, and smart grid technology.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11621" title="Abstract">arXiv:2308.11621</a> [<a href="/pdf/2308.11621" title="Download PDF">pdf</a>, <a href="/format/2308.11621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning -based Adaptation and Scheduling Methods for  Multi-source DASH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+T">Nghia T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+L">Long Luu</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+P+L">Phuong L. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T+S">Thi Thanh Sang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+C+T">Cuong T. Do</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Ngoc-thanh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic adaptive streaming over HTTP (DASH) has been widely used in video
streaming recently. In DASH, the client downloads video chunks in order from a
server. The rate adaptation function at the video client enhances the user's
quality-of-experience (QoE) by choosing a suitable quality level for each video
chunk to download based on the network condition. Today networks such as
content delivery networks, edge caching networks, content-centric networks,...
usually replicate video contents on multiple cache nodes. We study video
streaming from multiple sources in this work. In multi-source streaming, video
chunks may arrive out of order due to different conditions of the network
paths. Hence, to guarantee a high QoE, the video client needs not only rate
adaptation but also chunk scheduling. Reinforcement learning (RL) has emerged
as the state-of-the-art control method in various fields in recent years. This
paper proposes two algorithms for streaming from multiple sources: RL-based
adaptation with greedy scheduling (RLAGS) and RL-based adaptation and
scheduling (RLAS). We also build a simulation environment for training and
evaluating. The efficiency of the proposed algorithms is proved via extensive
simulations with real-trace data.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11624" title="Abstract">arXiv:2308.11624</a> [<a href="/pdf/2308.11624" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing TCAD Simulations with Universal Device Encoding and  Graph Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guangxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+K+L">Kain Lu Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 13 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">An innovative methodology that leverages artificial intelligence (AI) and
graph representation for semiconductor device encoding in TCAD device
simulation is proposed. A graph-based universal encoding scheme is presented
that not only considers material-level and device-level embeddings, but also
introduces a novel spatial relationship embedding inspired by interpolation
operations typically used in finite element meshing. Universal physical laws
from device simulations are leveraged for comprehensive data-driven modeling,
which encompasses surrogate Poisson emulation and current-voltage (IV)
prediction based on drift-diffusion model. Both are achieved using a novel
graph attention network, referred to as RelGAT. Comprehensive technical details
based on the device simulator Sentaurus TCAD are presented, empowering
researchers to adopt the proposed AI-driven Electronic Design Automation (EDA)
solution at the device level.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11628" title="Abstract">arXiv:2308.11628</a> [<a href="/pdf/2308.11628" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Engineering For Students of Medicine and Their Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heston%2C+T+F">Thomas F. Heston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">"Prompt Engineering for Students of Medicine and Their Teachers" brings the
principles of prompt engineering for large language models such as ChatGPT and
Google Bard to medical education. This book contains a comprehensive guide to
prompt engineering to help both teachers and students improve education in the
medical field. Just as prompt engineering is critical in getting good
information out of an AI, it is also critical to get students to think and
understand more deeply. The principles of prompt engineering that we have
learned from AI systems have the potential to simultaneously revolutionize
learning in the healthcare field. The book analyzes from multiple angles the
anatomy of a good prompt for both AI models and students. The different types
of prompts are examined, showing how each style has unique characteristics and
applications. The principles of prompt engineering, applied properly, are
demonstrated to be effective in teaching across the diverse fields of anatomy,
physiology, pathology, pharmacology, and clinical skills. Just like ChatGPT and
similar large language AI models, students need clear and detailed prompting in
order for them to fully understand a topic. Using identical principles, a
prompt that gets good information from an AI will also cause a student to think
more deeply and accurately. The process of prompt engineering facilitates this
process. Because each chapter contains multiple examples and key takeaways, it
is a practical guide for implementing prompt engineering in the learning
process. It provides a hands-on approach to ensure readers can immediately
apply the concepts they learn
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11630" title="Abstract">arXiv:2308.11630</a> [<a href="/pdf/2308.11630" title="Download PDF">pdf</a>, <a href="/format/2308.11630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Data Scarcity in Optical Matrix Multiplier Modeling Using  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cem%2C+A">Ali Cem</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+O">Ognjen Jovanovic</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Siqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yunhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zibar%2C+D">Darko Zibar</a>, 
<a href="/search/cs?searchtype=author&query=Da+Ros%2C+F">Francesco Da Ros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optics (physics.optics)

</div>
<p class="mathjax">We present and experimentally evaluate using transfer learning to address
experimental data scarcity when training neural network (NN) models for
Mach-Zehnder interferometer mesh-based optical matrix multipliers. Our approach
involves pre-training the model using synthetic data generated from a less
accurate analytical model and fine-tuning with experimental data. Our
investigation demonstrates that this method yields significant reductions in
modeling errors compared to using an analytical model, or a standalone NN model
when training data is limited. Utilizing regularization techniques and ensemble
averaging, we achieve &lt; 1 dB root-mean-square error on the matrix weights
implemented by a photonic chip while using only 25% of the available data.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11643" title="Abstract">arXiv:2308.11643</a> [<a href="/pdf/2308.11643" title="Download PDF">pdf</a>, <a href="/format/2308.11643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invisible, Unreadable, and Inaudible Cookie Notices: An Evaluation of  Cookie Notices for Users with Visual Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clarke%2C+J+M">James M. Clarke</a>, 
<a href="/search/cs?searchtype=author&query=Mehrnezhad%2C+M">Maryam Mehrnezhad</a>, 
<a href="/search/cs?searchtype=author&query=Toreini%2C+E">Ehsan Toreini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper investigates the accessibility of cookie notices on websites for
users with visual impairments (VI) via a set of system studies on top UK
websites (n=46) and a user study (n=100). We use a set of methods and
tools--including accessibility testing tools, text-only browsers, and screen
readers, to perform our system studies. Our results demonstrate that the
majority of cookie notices on these websites have some form of accessibility
issues including contrast issues, not having headings, and not being read aloud
immediately when the page is loaded. We discuss how such practises impact the
user experience and privacy and provide a set of recommendations for multiple
stakeholders for more accessible websites and better privacy practises for
users with VIs. To complement our technical contribution we conduct a user
study and finding that people with VIs generally have a negative view of cookie
notices and believe our recommendations could help their online experience. We
also find a disparity in how users wish to respond to cookie notices as apposed
to how they do in reality.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11646" title="Abstract">arXiv:2308.11646</a> [<a href="/pdf/2308.11646" title="Download PDF">pdf</a>, <a href="/format/2308.11646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Local Relational Augmentation and Global Nash Equilibrium for  Federated Learning with Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huabin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shuheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yanchao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ACM International Conference on Multimedia (ACM MM23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Federated learning (FL) is a distributed machine learning paradigm that needs
collaboration between a server and a series of clients with decentralized data.
To make FL effective in real-world applications, existing work devotes to
improving the modeling of decentralized data with non-independent and identical
distributions (non-IID). In non-IID settings, there are intra-client
inconsistency that comes from the imbalanced data modeling, and inter-client
inconsistency among heterogeneous client distributions, which not only hinders
sufficient representation of the minority data, but also brings discrepant
model deviations. However, previous work overlooks to tackle the above two
coupling inconsistencies together. In this work, we propose FedRANE, which
consists of two main modules, i.e., local relational augmentation (LRA) and
global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency
simultaneously. Specifically, in each client, LRA mines the similarity
relations among different data samples and enhances the minority sample
representations with their neighbors using attentive message passing. In
server, GNE reaches an agreement among inconsistent and discrepant model
deviations from clients to server, which encourages the global model to update
in the direction of global optimum without breaking down the clients
optimization toward their local optimums. We conduct extensive experiments on
four benchmark datasets to show the superiority of FedRANE in enhancing the
performance of FL with non-IID data.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11649" title="Abstract">arXiv:2308.11649</a> [<a href="/pdf/2308.11649" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Power of Creative AI Tools and Game-Based Methodologies  for Interactive Web-Based Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kenwright%2C+B">Benjamin Kenwright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, the fields of artificial intelligence and web-based
programming have seen tremendous advancements, enabling developers to create
dynamic and interactive websites and applications. At the forefront of these
advancements, creative AI tools and game-based methodologies have emerged as
potent instruments, promising enhanced user experiences and increased
engagement in educational environments. This chapter explores the potential of
these tools and methodologies for interactive web-based programming, examining
their benefits, limitations, and real-world applications. We examine the
challenges and ethical considerations that arise when integrating these
technologies into web development, such as privacy concerns and the potential
for bias in AI-generated content. Through this exploration, we aim to provide
insights into the exciting possibilities that creative AI tools and game-based
methodologies offer for the future of web-based programming.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11652" title="Abstract">arXiv:2308.11652</a> [<a href="/pdf/2308.11652" title="Download PDF">pdf</a>, <a href="/format/2308.11652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Exact Combinatorial Optimization via RL-based  Initialization -- A Case Study in Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jiaqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunxi Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer-Aided Design 2023 (ICCAD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Scheduling on dataflow graphs (also known as computation graphs) is an
NP-hard problem. The traditional exact methods are limited by runtime
complexity, while reinforcement learning (RL) and heuristic-based approaches
struggle with determinism and solution quality. This research aims to develop
an innovative approach that employs machine learning (ML) for addressing
combinatorial optimization problems, using scheduling as a case study. The goal
is to provide guarantees in optimality and determinism while maintaining the
runtime cost of heuristic methods. Specifically, we introduce a novel two-phase
RL-to-ILP scheduling framework, which includes three steps: 1) RL solver acts
as coarse-grain scheduler, 2) solution relaxation and 3) exact solving via ILP.
Our framework demonstrates the same scheduling performance compared with using
exact scheduling methods while achieving up to 128 $\times$ speed improvements.
This was conducted on actual EdgeTPU platforms, utilizing ImageNet DNN
computation graphs as input. Additionally, the framework offers improved
on-chip inference runtime and acceleration compared to the commercially
available EdgeTPU compiler.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11656" title="Abstract">arXiv:2308.11656</a> [<a href="/pdf/2308.11656" title="Download PDF">pdf</a>, <a href="/format/2308.11656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-online framework for BCI evaluation: A MOABB perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carrara%2C+I">Igor Carrara</a> (UCA, CRISAM), 
<a href="/search/cs?searchtype=author&query=Papadopoulo%2C+T">Th&#xe9;odore Papadopoulo</a> (UCA, CRISAM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Objective: BCI (Brain-Computer Interface) technology operates in three modes:
online, offline, and pseudo-online. In the online mode, real-time EEG data is
constantly analyzed. In offline mode, the signal is acquired and processed
afterwards. The pseudo-online mode processes collected data as if they were
received in real-time. The main difference is that the offline mode often
analyzes the whole data, while the online and pseudo-online modes only analyze
data in short time windows. Offline analysis is usually done with asynchronous
BCIs, which restricts analysis to predefined time windows. Asynchronous BCI,
compatible with online and pseudo-online modes, allows flexible mental activity
duration. Offline processing tends to be more accurate, while online analysis
is better for therapeutic applications. Pseudo-online implementation
approximates online processing without real-time constraints. Many BCI studies
being offline introduce biases compared to real-life scenarios, impacting
classification algorithm performance. Approach: The objective of this research
paper is therefore to extend the current MOABB framework, operating in offline
mode, so as to allow a comparison of different algorithms in a pseudo-online
setting with the use of a technology based on overlapping sliding windows. To
do this will require the introduction of a idle state event in the dataset that
takes into account all different possibilities that are not task thinking. To
validate the performance of the algorithms we will use the normalized Matthews
Correlation Coefficient (nMCC) and the Information Transfer Rate (ITR). Main
results: We analyzed the state-of-the-art algorithms of the last 15 years over
several Motor Imagery (MI) datasets composed by several subjects, showing the
differences between the two approaches from a statistical point of view.
Significance: The ability to analyze the performance of different algorithms in
offline and pseudo-online modes will allow the BCI community to obtain more
accurate and comprehensive reports regarding the performance of classification
algorithms.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11659" title="Abstract">arXiv:2308.11659</a> [<a href="/pdf/2308.11659" title="Download PDF">pdf</a>, <a href="/format/2308.11659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An engine to simulate insurance fraud network data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campo%2C+B+D+C">Bavo D.C. Campo</a>, 
<a href="/search/cs?searchtype=author&query=Antonio%2C+K">Katrien Antonio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Computation (stat.CO)

</div>
<p class="mathjax">Traditionally, the detection of fraudulent insurance claims relies on
business rules and expert judgement which makes it a time-consuming and
expensive process (\'Oskarsd\'ottir et al., 2022). Consequently, researchers
have been examining ways to develop efficient and accurate analytic strategies
to flag suspicious claims. Feeding learning methods with features engineered
from the social network of parties involved in a claim is a particularly
promising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et
al. (2023)). When developing a fraud detection model, however, we are
confronted with several challenges. The uncommon nature of fraud, for example,
creates a high class imbalance which complicates the development of well
performing analytic classification models. In addition, only a small number of
claims are investigated and get a label, which results in a large corpus of
unlabeled data. Yet another challenge is the lack of publicly available data.
This hinders not only the development of new methods, but also the validation
of existing techniques. We therefore design a simulation machine that is
engineered to create synthetic data with a network structure and available
covariates similar to the real life insurance fraud data set analyzed in
\'Oskarsd\'ottir et al. (2022). Further, the user has control over several
data-generating mechanisms. We can specify the total number of policyholders
and parties, the desired level of imbalance and the (effect size of the)
features in the fraud generating model. As such, the simulation engine enables
researchers and practitioners to examine several methodological challenges as
well as to test their (development strategy of) insurance fraud detection
models in a range of different settings. Moreover, large synthetic data sets
can be generated to evaluate the predictive performance of (advanced) machine
learning techniques.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11662" title="Abstract">arXiv:2308.11662</a> [<a href="/pdf/2308.11662" title="Download PDF">pdf</a>, <a href="/format/2308.11662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQA Therapy: Exploring Answer Differences by Visually Grounding Answers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Anjum%2C+S">Samreen Anjum</a>, 
<a href="/search/cs?searchtype=author&query=Gurari%2C+D">Danna Gurari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/CVF International Conference on Computer Vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual question answering is a task of predicting the answer to a question
about an image. Given that different people can provide different answers to a
visual question, we aim to better understand why with answer groundings. We
introduce the first dataset that visually grounds each unique answer to each
visual question, which we call VQAAnswerTherapy. We then propose two novel
problems of predicting whether a visual question has a single answer grounding
and localizing all answer groundings. We benchmark modern algorithms for these
novel problems to show where they succeed and struggle. The dataset and
evaluation server can be found publicly at
https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11669" title="Abstract">arXiv:2308.11669</a> [<a href="/pdf/2308.11669" title="Download PDF">pdf</a>, <a href="/format/2308.11669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Label-aware Graph Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=In%2C+Y">Yeonjun In</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kanghoon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junmo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023 (short paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a
node is anomalous or not. One common observation we made from previous
unsupervised methods is that they not only assume the absence of such anomaly
labels, but also the absence of class labels (the class a node belongs to used
in a general node classification task). In this work, we study the utility of
class labels for unsupervised GAD; in particular, how they enhance the
detection of structural anomalies. To this end, we propose a Class Label-aware
Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of
labeled nodes to enhance the performance of unsupervised GAD. Extensive
experiments on ten datasets demonstrate the superior performance of CLAD in
comparison to existing unsupervised GAD methods, even in the absence of
ground-truth class label information. The source code for CLAD is available at
\url{https://github.com/jhkim611/CLAD}.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11675" title="Abstract">arXiv:2308.11675</a> [<a href="/pdf/2308.11675" title="Download PDF">pdf</a>, <a href="/format/2308.11675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flying Capacitor Cell Equalization for Li-ion Automotive Battery Stacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramaswamy%2C+M">Manish Ramaswamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The automotive industry is fast evolving to Li-ion chemistries, which have
more favorable power, energy density, and efficiency. To meet the demands of
greater electric ranges, parallel strings of batteries are required to increase
the overall system capacity. Differences in chemical characteristics, internal
resistance, and operating conditions can cause variations in remaining cell
capacity, decreasing the total battery storage capacity over time, shortening
the battery lifetime and eventually damaging the cells. Cell equalization tries
to restore all the cells in the pack to an equal state of charge in order to
prolong the battery lifetime and to ensure safe battery operations. This work
presents an active charge equalization scheme with a flying capacitor to
shuttle charge between the unbalanced cells in a parallel battery pack. The
theoretical framework is accompanied by MATLAB simulations on a twelve cell
pack in series/parallel configuration supporting the validity of the chosen
approach.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11677" title="Abstract">arXiv:2308.11677</a> [<a href="/pdf/2308.11677" title="Download PDF">pdf</a>, <a href="/format/2308.11677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Initial Training Strategies for Exemplar-Free  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petit%2C+G">Gr&#xe9;goire Petit</a>, 
<a href="/search/cs?searchtype=author&query=Soumm%2C+M">Michael Soumm</a>, 
<a href="/search/cs?searchtype=author&query=Feillet%2C+E">Eva Feillet</a>, 
<a href="/search/cs?searchtype=author&query=Popescu%2C+A">Adrian Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Delezoide%2C+B">Bertrand Delezoide</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+D">David Picard</a>, 
<a href="/search/cs?searchtype=author&query=Hudelot%2C+C">C&#xe9;line Hudelot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Class-Incremental Learning (CIL) aims to build classification models from
data streams. At each step of the CIL process, new classes must be integrated
into the model. Due to catastrophic forgetting, CIL is particularly challenging
when examples from past classes cannot be stored, the case on which we focus
here. To date, most approaches are based exclusively on the target dataset of
the CIL process. However, the use of models pre-trained in a self-supervised
way on large amounts of data has recently gained momentum. The initial model of
the CIL process may only use the first batch of the target dataset, or also use
pre-trained weights obtained on an auxiliary dataset. The choice between these
two initial learning strategies can significantly influence the performance of
the incremental learning model, but has not yet been studied in depth.
Performance is also influenced by the choice of the CIL algorithm, the neural
architecture, the nature of the target task, the distribution of classes in the
stream and the number of examples available for learning. We conduct a
comprehensive experimental study to assess the roles of these factors. We
present a statistical analysis framework that quantifies the relative
contribution of each factor to incremental performance. Our main finding is
that the initial training strategy is the dominant factor influencing the
average incremental accuracy, but that the choice of CIL algorithm is more
important in preventing forgetting. Based on this analysis, we propose
practical recommendations for choosing the right initial training strategy for
a given incremental learning use case. These recommendations are intended to
facilitate the practical deployment of incremental learning.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11681" title="Abstract">arXiv:2308.11681</a> [<a href="/pdf/2308.11681" title="Download PDF">pdf</a>, <a href="/format/2308.11681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuerong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lingru Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qingsen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The recent contrastive language-image pre-training (CLIP) model has shown
great success in a wide range of image-level tasks, revealing remarkable
ability for learning powerful visual representations with rich semantics. An
open and worthwhile problem is efficiently adapting such a strong model to the
video domain and designing a robust video anomaly detector. In this work, we
propose VadCLIP, a new paradigm for weakly supervised video anomaly detection
(WSVAD) by leveraging the frozen CLIP model directly without any pre-training
and fine-tuning process. Unlike current works that directly feed extracted
features into the weakly supervised classifier for frame-level binary
classification, VadCLIP makes full use of fine-grained associations between
vision and language on the strength of CLIP and involves dual branch. One
branch simply utilizes visual features for coarse-grained binary
classification, while the other fully leverages the fine-grained language-image
alignment. With the benefit of dual branch, VadCLIP achieves both
coarse-grained and fine-grained video anomaly detection by transferring
pre-trained knowledge from CLIP to WSVAD task. We conduct extensive experiments
on two commonly-used benchmarks, demonstrating that VadCLIP achieves the best
performance on both coarse-grained and fine-grained WSVAD, surpassing the
state-of-the-art methods by a large margin. Specifically, VadCLIP achieves
84.51% AP and 88.02% AUC on XD-Violence and UCF-Crime, respectively. Code and
features will be released to facilitate future VAD research.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11683" title="Abstract">arXiv:2308.11683</a> [<a href="/pdf/2308.11683" title="Download PDF">pdf</a>, <a href="/format/2308.11683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to generate and corr- uh I mean repair language in real-time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eshghi%2C+A">Arash Eshghi</a>, 
<a href="/search/cs?searchtype=author&query=Ashrafzadeh%2C+A">Arash Ashrafzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the workshop on the Semantics and Pragmatics of Dialogue, SemDial, Maribor, Slovenia (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In conversation, speakers produce language incrementally, word by word, while
continuously monitoring the appropriateness of their own contribution in the
dynamically unfolding context of the conversation; and this often leads them to
repair their own utterance on the fly. This real-time language processing
capacity is furthermore crucial to the development of fluent and natural
conversational AI. In this paper, we use a previously learned Dynamic Syntax
grammar and the CHILDES corpus to develop, train and evaluate a probabilistic
model for incremental generation where input to the model is a purely semantic
generation goal concept in Type Theory with Records (TTR). We show that the
model's output exactly matches the gold candidate in 78% of cases with a
ROUGE-l score of 0.86. We further do a zero-shot evaluation of the ability of
the same model to generate self-repairs when the generation goal changes
mid-utterance. Automatic evaluation shows that the model can generate
self-repairs correctly in 85% of cases. A small human evaluation confirms the
naturalness and grammaticality of the generated self-repairs. Overall, these
results further highlight the generalisation power of grammar-based models and
lay the foundations for more controllable, and naturally interactive
conversational AI systems.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11684" title="Abstract">arXiv:2308.11684</a> [<a href="/pdf/2308.11684" title="Download PDF">pdf</a>, <a href="/format/2308.11684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Identity Linkage in Social Media Using Linguistic and Social  Interaction Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatzakou%2C+D">Despoina Chatzakou</a>, 
<a href="/search/cs?searchtype=author&query=Soler-Company%2C+J">Juan Soler-Company</a>, 
<a href="/search/cs?searchtype=author&query=Tsikrika%2C+T">Theodora Tsikrika</a>, 
<a href="/search/cs?searchtype=author&query=Wanner%2C+L">Leo Wanner</a>, 
<a href="/search/cs?searchtype=author&query=Vrochidis%2C+S">Stefanos Vrochidis</a>, 
<a href="/search/cs?searchtype=author&query=Kompatsiaris%2C+I">Ioannis Kompatsiaris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Social media users often hold several accounts in their effort to multiply
the spread of their thoughts, ideas, and viewpoints. In the particular case of
objectionable content, users tend to create multiple accounts to bypass the
combating measures enforced by social media platforms and thus retain their
online identity even if some of their accounts are suspended. User identity
linkage aims to reveal social media accounts likely to belong to the same
natural person so as to prevent the spread of abusive/illegal activities. To
this end, this work proposes a machine learning-based detection model, which
uses multiple attributes of users' online activity in order to identify whether
two or more virtual identities belong to the same real natural person. The
models efficacy is demonstrated on two cases on abusive and terrorism-related
Twitter content.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11696" title="Abstract">arXiv:2308.11696</a> [<a href="/pdf/2308.11696" title="Download PDF">pdf</a>, <a href="/format/2308.11696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Benchmarking (of Language Models)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perlitz%2C+Y">Yotam Perlitz</a>, 
<a href="/search/cs?searchtype=author&query=Bandel%2C+E">Elron Bandel</a>, 
<a href="/search/cs?searchtype=author&query=Gera%2C+A">Ariel Gera</a>, 
<a href="/search/cs?searchtype=author&query=Arviv%2C+O">Ofir Arviv</a>, 
<a href="/search/cs?searchtype=author&query=Ein-Dor%2C+L">Liat Ein-Dor</a>, 
<a href="/search/cs?searchtype=author&query=Shnarch%2C+E">Eyal Shnarch</a>, 
<a href="/search/cs?searchtype=author&query=Slonim%2C+N">Noam Slonim</a>, 
<a href="/search/cs?searchtype=author&query=Shmueli-Scheuer%2C+M">Michal Shmueli-Scheuer</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing versatility of language models LMs has given rise to a new
class of benchmarks that comprehensively assess a broad range of capabilities.
Such benchmarks are associated with massive computational costs reaching
thousands of GPU hours per model. However the efficiency aspect of these
evaluation efforts had raised little discussion in the literature. In this work
we present the problem of Efficient Benchmarking namely intelligently reducing
the computation costs of LM evaluation without compromising reliability. Using
the HELM benchmark as a test case we investigate how different benchmark design
choices affect the computation-reliability tradeoff. We propose to evaluate the
reliability of such decisions by using a new measure Decision Impact on
Reliability DIoR for short. We find for example that the current leader on HELM
may change by merely removing a low-ranked model from the benchmark and observe
that a handful of examples suffice to obtain the correct benchmark ranking.
Conversely a slightly different choice of HELM scenarios varies ranking widely.
Based on our findings we outline a set of concrete recommendations for more
efficient benchmark design and utilization practices leading to dramatic cost
savings with minimal loss of benchmark reliability often reducing computation
by x100 or more.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11720" title="Abstract">arXiv:2308.11720</a> [<a href="/pdf/2308.11720" title="Download PDF">pdf</a>, <a href="/format/2308.11720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Relation Extraction through Language Probing with Exemplars  from Set Co-Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yerong Li</a>, 
<a href="/search/cs?searchtype=author&query=Girju%2C+R">Roxana Girju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Relation Extraction (RE) is a pivotal task in automatically extracting
structured information from unstructured text. In this paper, we present a
multi-faceted approach that integrates representative examples and through
co-set expansion. The primary goal of our method is to enhance relation
classification accuracy and mitigating confusion between contrastive classes.
<br />Our approach begins by seeding each relationship class with representative
examples. Subsequently, our co-set expansion algorithm enriches training
objectives by incorporating similarity measures between target pairs and
representative pairs from the target class. Moreover, the co-set expansion
process involves a class ranking procedure that takes into account exemplars
from contrastive classes. Contextual details encompassing relation mentions are
harnessed via context-free Hearst patterns to ascertain contextual similarity.
<br />Empirical evaluation demonstrates the efficacy of our co-set expansion
approach, resulting in a significant enhancement of relation classification
performance. Our method achieves an observed margin of at least 1 percent
improvement in accuracy in most settings, on top of existing fine-tuning
approaches. To further refine our approach, we conduct an in-depth analysis
that focuses on tuning contrastive examples. This strategic selection and
tuning effectively reduce confusion between classes sharing similarities,
leading to a more precise classification process.
<br />Experimental results underscore the effectiveness of our proposed framework
for relation extraction. The synergy between co-set expansion and context-aware
prompt tuning substantially contributes to improved classification accuracy.
Furthermore, the reduction in confusion between contrastive classes through
contrastive examples tuning validates the robustness and reliability of our
method.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11721" title="Abstract">arXiv:2308.11721</a> [<a href="/pdf/2308.11721" title="Download PDF">pdf</a>, <a href="/format/2308.11721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Are Two Lists Better than One?: Benefits and Harms in Joint  Decision-making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donahue%2C+K">Kate Donahue</a>, 
<a href="/search/cs?searchtype=author&query=Kollias%2C+K">Kostas Kollias</a>, 
<a href="/search/cs?searchtype=author&query=Gollapudi%2C+S">Sreenivas Gollapudi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Historically, much of machine learning research has focused on the
performance of the algorithm alone, but recently more attention has been
focused on optimizing joint human-algorithm performance. Here, we analyze a
specific type of human-algorithm collaboration where the algorithm has access
to a set of $n$ items, and presents a subset of size $k$ to the human, who
selects a final item from among those $k$. This scenario could model content
recommendation, route planning, or any type of labeling task. Because both the
human and algorithm have imperfect, noisy information about the true ordering
of items, the key question is: which value of $k$ maximizes the probability
that the best item will be ultimately selected? For $k=1$, performance is
optimized by the algorithm acting alone, and for $k=n$ it is optimized by the
human acting alone. Surprisingly, we show that for multiple of noise models, it
is optimal to set $k \in [2, n-1]$ - that is, there are strict benefits to
collaborating, even when the human and algorithm have equal accuracy
separately. We demonstrate this theoretically for the Mallows model and
experimentally for the Random Utilities models of noisy permutations. However,
we show this pattern is reversed when the human is anchored on the algorithm's
presented ordering - the joint system always has strictly worse performance. We
extend these results to the case where the human and algorithm differ in their
accuracy levels, showing that there always exist regimes where a more accurate
agent would strictly benefit from collaborating with a less accurate one, but
these regimes are asymmetric between the human and the algorithm's accuracy.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11728" title="Abstract">arXiv:2308.11728</a> [<a href="/pdf/2308.11728" title="Download PDF">pdf</a>, <a href="/format/2308.11728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant representation learning for sequential recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaofan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation involves automatically recommending the next item
to users based on their historical item sequence. While most prior research
employs RNN or transformer methods to glean information from the item
sequence-generating probabilities for each user-item pair and recommending the
top items, these approaches often overlook the challenge posed by spurious
relationships. This paper specifically addresses these spurious relations. We
introduce a novel sequential recommendation framework named Irl4Rec. This
framework harnesses invariant learning and employs a new objective that factors
in the relationship between spurious variables and adjustment variables during
model training. This approach aids in identifying spurious relations.
Comparative analyses reveal that our framework outperforms three typical
methods, underscoring the effectiveness of our model. Moreover, an ablation
study further demonstrates the critical role our model plays in detecting
spurious relations.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11730" title="Abstract">arXiv:2308.11730</a> [<a href="/pdf/2308.11730" title="Download PDF">pdf</a>, <a href="/format/2308.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Prompting for Multi-Document Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R+A">Ryan A. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A">Alexa Siu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has
achieved remarkable success in open-domain question answering (OD-QA). However,
few works explore this paradigm in the scenario of multi-document question
answering (MD-QA), a task demanding a thorough understanding of the logical
associations among the contents and structures of different documents. To fill
this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to
formulate the right context in prompting LLMs for MD-QA, which consists of a
graph construction module and a graph traversal module. For graph construction,
we create a knowledge graph (KG) over multiple documents with nodes symbolizing
passages or document structures (e.g., pages/tables), and edges denoting the
semantic/lexical similarity between passages or intra-document structural
relations. For graph traversal, we design an LM-guided graph traverser that
navigates across nodes and gathers supporting passages assisting LLMs in MD-QA.
The constructed graph serves as the global ruler that regulates the
transitional space among passages and reduces retrieval latency. Concurrently,
the LM-guided traverser acts as a local navigator that gathers pertinent
context to progressively approach the question and guarantee retrieval quality.
Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the
potential of leveraging graphs in enhancing the prompt design for LLMs. Our
code is at https://github.com/YuWVandy/KG-LLM-MDQA.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11732" title="Abstract">arXiv:2308.11732</a> [<a href="/pdf/2308.11732" title="Download PDF">pdf</a>, <a href="/format/2308.11732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Un)fair Exposure in Deep Face Rankings at a Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atzori%2C+A">Andrea Atzori</a>, 
<a href="/search/cs?searchtype=author&query=Fenu%2C+G">Gianni Fenu</a>, 
<a href="/search/cs?searchtype=author&query=Marras%2C+M">Mirko Marras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper at IJCB 2023 Special Session "Long-Range Biometrics Challenges": 2023 International Joint Conference on Biometrics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Law enforcement regularly faces the challenge of ranking suspects from their
facial images. Deep face models aid this process but frequently introduce
biases that disproportionately affect certain demographic segments. While bias
investigation is common in domains like job candidate ranking, the field of
forensic face rankings remains underexplored. In this paper, we propose a novel
experimental framework, encompassing six state-of-the-art face encoders and two
public data sets, designed to scrutinize the extent to which demographic groups
suffer from biases in exposure in the context of forensic face rankings.
Through comprehensive experiments that cover both re-identification and
identification tasks, we show that exposure biases within this domain are far
from being countered, demanding attention towards establishing ad-hoc policies
and corrective measures. The source code is available at
https://github.com/atzoriandrea/ijcb2023-unfair-face-rankings
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11733" title="Abstract">arXiv:2308.11733</a> [<a href="/pdf/2308.11733" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demand-driven provisioning of Kubernetes-like resources in OSG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sfiligoi%2C+I">Igor Sfiligoi</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCrthwein%2C+F">Frank W&#xfc;rthwein</a>, 
<a href="/search/cs?searchtype=author&query=Dost%2C+J">Jeff Dost</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Brian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Schultz%2C+D">David Schultz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, Submitted to Proceedings of CHEP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The OSG-operated Open Science Pool is an HTCondor-based virtual cluster that
aggregates resources from compute clusters provided by several organizations.
Most of the resources are not owned by OSG, so demand-based dynamic
provisioning is important for maximizing usage without incurring excessive
waste. OSG has long relied on GlideinWMS for most of its resource provisioning
needs but is limited to resources that provide a Grid-compliant Compute
Entrypoint. To work around this limitation, the OSG Software Team has developed
a glidein container that resource providers could use to directly contribute to
the OSPool. The problem of that approach is that it is not demand-driven,
relegating it to backfill scenarios only. To address this limitation, a
demand-driven direct provisioner of Kubernetes resources has been developed and
successfully used on the NRP. The setup still relies on the OSG-maintained
backfill container image but automates the provisioning matchmaking and
successive requests. That provisioner has also been extended to support
Lancium, a green computing cloud provider with a Kubernetes-like proprietary
interface. The provisioner logic has been intentionally kept very simple,
making this extension a low-cost project. Both NRP and Lancium resources have
been provisioned exclusively using this mechanism for many months.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11734" title="Abstract">arXiv:2308.11734</a> [<a href="/pdf/2308.11734" title="Download PDF">pdf</a>, <a href="/format/2308.11734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Compact Data Structure for Temporal Reachability with Unsorted  Contact Insertions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brito%2C+L+F+A">Luiz Fernando Afra Brito</a>, 
<a href="/search/cs?searchtype=author&query=Albertini%2C+M+K">Marcelo Keese Albertini</a>, 
<a href="/search/cs?searchtype=author&query=Traven%C3%A7olo%2C+B+A+N">Bruno Augusto Nassif Traven&#xe7;olo</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Temporal graphs represent interactions between entities over time. Deciding
whether entities can reach each other through temporal paths is useful for
various applications such as in communication networks and epidemiology.
Previous works have studied the scenario in which addition of new interactions
can happen at any point in time. A known strategy maintains, incrementally, a
Timed Transitive Closure by using a dynamic data structure composed of $O(n^2)$
binary search trees containing non-nested time intervals. However, space usage
for storing these trees grows rapidly as more interactions are inserted. In
this paper, we present a compact data structures that represent each tree as
two dynamic bit-vectors. In our experiments, we observed that our data
structure improves space usage while having similar time performance for
incremental updates when comparing with the previous strategy in temporally
dense temporal graphs.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11737" title="Abstract">arXiv:2308.11737</a> [<a href="/pdf/2308.11737" title="Download PDF">pdf</a>, <a href="/format/2308.11737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiacong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiawei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wufei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jesslen%2C+A">Artur Jesslen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+P">Pengliang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qixin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiehua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoding Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+P">Prakhar Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yushan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yawen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurately estimating the 3D pose and shape is an essential step towards
understanding animal behavior, and can potentially benefit many downstream
applications, such as wildlife conservation. However, research in this area is
held back by the lack of a comprehensive and diverse dataset with high-quality
3D pose and shape annotations. In this paper, we propose Animal3D, the first
comprehensive dataset for mammal animal 3D pose and shape estimation. Animal3D
consists of 3379 images collected from 40 mammal species, high-quality
annotations of 26 keypoints, and importantly the pose and shape parameters of
the SMAL model. All annotations were labeled and checked manually in a
multi-stage process to ensure highest quality results. Based on the Animal3D
dataset, we benchmark representative shape and pose estimation models at: (1)
supervised learning from only the Animal3D data, (2) synthetic to real transfer
from synthetically generated images, and (3) fine-tuning human pose and shape
estimation models. Our experimental results demonstrate that predicting the 3D
shape and pose of animals across species remains a very challenging task,
despite significant advances in human pose estimation. Our results further
demonstrate that synthetic pre-training is a viable strategy to boost the model
performance. Overall, Animal3D opens new directions for facilitating future
research in animal 3D pose and shape estimation, and is publicly available.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11738" title="Abstract">arXiv:2308.11738</a> [<a href="/pdf/2308.11738" title="Download PDF">pdf</a>, <a href="/ps/2308.11738" title="Download PostScript">ps</a>, <a href="/format/2308.11738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifted Inference beyond First-Order Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malhotra%2C+S">Sagar Malhotra</a>, 
<a href="/search/cs?searchtype=author&query=Bizzaro%2C+D">Davide Bizzaro</a>, 
<a href="/search/cs?searchtype=author&query=Serafini%2C+L">Luciano Serafini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.09830">arXiv:2302.09830</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
<p class="mathjax">Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic
inference in statistical relational learning models. As WFOMC is known to be
intractable in general ($\#$P-complete), logical fragments that admit
polynomial time WFOMC are of significant interest. Such fragments are called
domain liftable. Recent works have shown that the two-variable fragment of
first order logic extended with counting quantifiers ($\mathrm{C^2}$) is
domain-liftable. However, many properties of real-world data, like acyclicity
in citation networks and connectivity in social networks, cannot be modeled in
$\mathrm{C^2}$, or first order logic in general. In this work, we expand the
domain liftability of $\mathrm{C^2}$ with multiple such properties. We show
that any $\mathrm{C^2}$ sentence remains domain liftable when one of its
relations is restricted to represent a directed acyclic graph, a connected
graph, a tree (resp. a directed tree) or a forest (resp. a directed forest).
All our results rely on a novel and general methodology of "counting by
splitting". Besides their application to probabilistic inference, our results
provide a general framework for counting combinatorial structures. We expand a
vast array of previous results in discrete mathematics literature on directed
acyclic graphs, phylogenetic networks, etc.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11742" title="Abstract">arXiv:2308.11742</a> [<a href="/pdf/2308.11742" title="Download PDF">pdf</a>, <a href="/ps/2308.11742" title="Download PostScript">ps</a>, <a href="/format/2308.11742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Programming based Reductions for Multiple Visit TSP and Vehicle  Routing Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillai%2C+A">Aditya Pillai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mohit Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Multiple TSP ($\mathrm{mTSP}$) is a important variant of $\mathrm{TSP}$ where
a set of $k$ salesperson together visit a set of $n$ cities. The
$\mathrm{mTSP}$ problem has applications to many real life applications such as
vehicle routing. Rothkopf introduced another variant of $\mathrm{TSP}$ called
many-visits TSP ($\mathrm{MV\mbox{-}TSP}$) where a request $r(v)\in
\mathbb{Z}_+$ is given for each city $v$ and a single salesperson needs to
visit each city $r(v)$ times and return back to his starting point. A
combination of $\mathrm{mTSP}$ and $\mathrm{MV\mbox{-}TSP}$ called many-visits
multiple TSP $(\mathrm{MV\mbox{-}mTSP})$ was studied by B\'erczi, Mnich, and
Vincze where the authors give approximation algorithms for various variants of
$\mathrm{MV\mbox{-}mTSP}$.
<br />In this work, we show a simple linear programming (LP) based reduction that
converts a $\mathrm{mTSP}$ LP-based algorithm to a LP-based algorithm for
$\mathrm{MV\mbox{-}mTSP}$ with the same approximation factor. We apply this
reduction to improve or match the current best approximation factors of several
variants of the $\mathrm{MV\mbox{-}mTSP}$. Our reduction shows that the
addition of visit requests $r(v)$ to $\mathrm{mTSP}$ does $\textit{not}$ make
the problem harder to approximate even when $r(v)$ is exponential in number of
vertices.
<br />To apply our reduction, we either use existing LP-based algorithms for
$\mathrm{mTSP}$ variants or show that several existing combinatorial algorithms
for $\mathrm{mTSP}$ variants can be interpreted as LP-based algorithms. This
allows us to apply our reduction to these combinatorial algorithms as well
achieving the improved guarantees.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11744" title="Abstract">arXiv:2308.11744</a> [<a href="/pdf/2308.11744" title="Download PDF">pdf</a>, <a href="/format/2308.11744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Controllable Multi-Task Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aich%2C+A">Abhishek Aich</a>, 
<a href="/search/cs?searchtype=author&query=Schulter%2C+S">Samuel Schulter</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Yumin Suh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We aim to train a multi-task model such that users can adjust the desired
compute budget and relative importance of task performances after deployment,
without retraining. This enables optimizing performance for dynamically varying
user needs, without heavy computational overhead to train and save models for
various scenarios. To this end, we propose a multi-task model consisting of a
shared encoder and task-specific decoders where both encoder and decoder
channel widths are slimmable. Our key idea is to control the task importance by
varying the capacities of task-specific decoders, while controlling the total
computational cost by jointly adjusting the encoder capacity. This improves
overall accuracy by allowing a stronger encoder for a given budget, increases
control over computational cost, and delivers high-quality slimmed
sub-architectures based on user's constraints. Our training strategy involves a
novel 'Configuration-Invariant Knowledge Distillation' loss that enforces
backbone representations to be invariant under different runtime width
configurations to enhance accuracy. Further, we present a simple but effective
search algorithm that translates user constraints to runtime width
configurations of both the shared encoder and task decoders, for sampling the
sub-architectures. The key rule for the search algorithm is to provide a larger
computational budget to the higher preferred task decoder, while searching a
shared encoder configuration that enhances the overall MTL performance. Various
experiments on three multi-task benchmarks (PASCALContext, NYUDv2, and
CIFAR100-MTL) with diverse backbone architectures demonstrate the advantage of
our approach. For example, our method shows a higher controllability by ~33.5%
in the NYUD-v2 dataset over prior methods, while incurring much less compute
cost.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11747" title="Abstract">arXiv:2308.11747</a> [<a href="/pdf/2308.11747" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-case study of agile requirements engineering and the use of test  cases as requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bjarnason%2C+E">Elizabeth Bjarnason</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Borg%2C+M">Markus Borg</a>, 
<a href="/search/cs?searchtype=author&query=Engstr%C3%B6m%2C+E">Emelie Engstr&#xf6;m</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Inf. Softw. Technol. 77: 61-79 (2016)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: It is an enigma that agile projects can succeed 'without
requirements' when weak requirements engineering is a known cause for project
failures. While agile development projects often manage well without extensive
requirements test cases are commonly viewed as requirements and detailed
requirements are documented as test cases. Objective: We have investigated this
agile practice of using test cases as requirements to understand how test cases
can support the main requirements activities, and how this practice varies.
Method: We performed an iterative case study at three companies and collected
data through 14 interviews and two focus groups. Results: The use of test cases
as requirements poses both benefits and challenges when eliciting, validating,
verifying, and managing requirements, and when used as a documented agreement.
We have identified five variants of the test-cases-as-requirements practice,
namely de facto, behaviour-driven, story-test driven, stand-alone strict and
stand-alone manual for which the application of the practice varies concerning
the time frame of requirements documentation, the requirements format, the
extent to which the test cases are a machine executable specification and the
use of tools which provide specific support for the practice of using test
cases as requirements. Conclusions: The findings provide empirical insight into
how agile development projects manage and communicate requirements. The
identified variants of the practice of using test cases as requirements can be
used to perform in-depth investigations into agile requirements engineering.
Practitioners can use the provided recommendations as a guide in designing and
improving their agile requirements practices based on project characteristics
such as number of stakeholders and rate of change.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11748" title="Abstract">arXiv:2308.11748</a> [<a href="/pdf/2308.11748" title="Download PDF">pdf</a>, <a href="/format/2308.11748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patient Clustering via Integrated Profiling of Clinical and Digital Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dongjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+A">Andy Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ozturk%2C+O">Ozgur Ozturk</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+D">Deep Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Drake%2C+B">Barry Drake</a>, 
<a href="/search/cs?searchtype=author&query=Haidarian%2C+H">Hamid Haidarian</a>, 
<a href="/search/cs?searchtype=author&query=Javed%2C+F">Faizan Javed</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Haesun Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the Short Paper track of CIKM'23, October 21-25, 2023, Birmingham, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a novel profile-based patient clustering model designed for
clinical data in healthcare. By utilizing a method grounded on constrained
low-rank approximation, our model takes advantage of patients' clinical data
and digital interaction data, including browsing and search, to construct
patient profiles. As a result of the method, nonnegative embedding vectors are
generated, serving as a low-dimensional representation of the patients. Our
model was assessed using real-world patient data from a healthcare web portal,
with a comprehensive evaluation approach which considered clustering and
recommendation capabilities. In comparison to other baselines, our approach
demonstrated superior performance in terms of clustering coherence and
recommendation accuracy.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11750" title="Abstract">arXiv:2308.11750</a> [<a href="/pdf/2308.11750" title="Download PDF">pdf</a>, <a href="/format/2308.11750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale information retrieval in software engineering -- an  experience report from industrial application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Gorschek%2C+T">Tony Gorschek</a>, 
<a href="/search/cs?searchtype=author&query=Feldt%2C+R">Robert Feldt</a>, 
<a href="/search/cs?searchtype=author&query=Lavesson%2C+N">Niklas Lavesson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Empir. Softw. Eng. 21(6): 2324-2365 (2016)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software Engineering activities are information intensive. Research proposes
Information Retrieval (IR) techniques to support engineers in their daily
tasks, such as establishing and maintaining traceability links, fault
identification, and software maintenance. We describe an engineering task, test
case selection, and illustrate our problem analysis and solution discovery
process. The objective of the study is to gain an understanding of to what
extent IR techniques (one potential solution) can be applied to test case
selection and provide decision support in a large-scale, industrial setting. We
analyze, in the context of the studied company, how test case selection is
performed and design a series of experiments evaluating the performance of
different IR techniques. Each experiment provides lessons learned from
implementation, execution, and results, feeding to its successor. The three
experiments led to the following observations: 1) there is a lack of research
on scalable parameter optimization of IR techniques for software engineering
problems; 2) scaling IR techniques to industry data is challenging, in
particular for latent semantic analysis; 3) the IR context poses constraints on
the empirical evaluation of IR techniques, requiring more research on
developing valid statistical approaches. We believe that our experiences in
conducting a series of IR experiments with industry grade data are valuable for
peer researchers so that they can avoid the pitfalls that we have encountered.
Furthermore, we identified challenges that need to be addressed in order to
bridge the gap between laboratory IR experiments and real applications of IR in
the industry.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11754" title="Abstract">arXiv:2308.11754</a> [<a href="/pdf/2308.11754" title="Download PDF">pdf</a>, <a href="/format/2308.11754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Instance Adversarial Attack on GNN-Based Malicious Domain  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazzal%2C+M">Mahmoud Nazzal</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+I">Issa Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Khreishah%2C+A">Abdallah Khreishah</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+N">NhatHai Phan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 45th IEEE Symposium on Security and Privacy (IEEE S\&amp;P 2024), May 20-23, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Malicious domain detection (MDD) is an open security challenge that aims to
detect if an Internet domain is associated with cyber-attacks. Among many
approaches to this problem, graph neural networks (GNNs) are deemed highly
effective. GNN-based MDD uses DNS logs to represent Internet domains as nodes
in a maliciousness graph (DMG) and trains a GNN to infer their maliciousness by
leveraging identified malicious domains. Since this method relies on accessible
DNS logs to construct DMGs, it exposes a vulnerability for adversaries to
manipulate their domain nodes' features and connections within DMGs. Existing
research mainly concentrates on threat models that manipulate individual
attacker nodes. However, adversaries commonly generate multiple domains to
achieve their goals economically and avoid detection. Their objective is to
evade discovery across as many domains as feasible. In this work, we call the
attack that manipulates several nodes in the DMG concurrently a multi-instance
evasion attack. We present theoretical and empirical evidence that the existing
single-instance evasion techniques for are inadequate to launch multi-instance
evasion attacks against GNN-based MDDs. Therefore, we introduce MintA, an
inference-time multi-instance adversarial attack on GNN-based MDDs. MintA
enhances node and neighborhood evasiveness through optimized perturbations and
operates successfully with only black-box access to the target model,
eliminating the need for knowledge about the model's specifics or non-adversary
nodes. We formulate an optimization challenge for MintA, achieving an
approximate solution. Evaluating MintA on a leading GNN-based MDD technique
with real-world data showcases an attack success rate exceeding 80%. These
findings act as a warning for security experts, underscoring GNN-based MDDs'
susceptibility to practical attacks that can undermine their effectiveness and
benefits.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11755" title="Abstract">arXiv:2308.11755</a> [<a href="/pdf/2308.11755" title="Download PDF">pdf</a>, <a href="/format/2308.11755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VBMO: Voting-Based Multi-Objective Path Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korpan%2C+R">Raj Korpan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First International Workshop on Search and Planning with Complex Objectives (WoSePCO) at IJCAI'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents VBMO, the Voting-Based Multi-Objective path planning
algorithm, that generates optimal single-objective plans, evaluates each of
them with respect to the other objectives, and selects one with a voting
mechanism. VBMO does not use hand-tuned weights, consider the multiple
objectives at every step of search, or use an evolutionary algorithm. Instead,
it considers how a plan that is optimal in one objective may perform well with
respect to others. VBMO incorporates three voting mechanisms: range, Borda, and
combined approval. Extensive evaluation in diverse and complex environments
demonstrates the algorithm's ability to efficiently produce plans that satisfy
multiple objectives.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11757" title="Abstract">arXiv:2308.11757</a> [<a href="/pdf/2308.11757" title="Download PDF">pdf</a>, <a href="/format/2308.11757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Face and Whole Body Recognition in Turbulent  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikhal%2C+K">Kshitij Nikhal</a>, 
<a href="/search/cs?searchtype=author&query=Riggan%2C+B+S">Benjamin S. Riggan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face and person recognition have recently achieved remarkable success under
challenging scenarios, such as off-pose and cross-spectrum matching. However,
long-range recognition systems are often hindered by atmospheric turbulence,
leading to spatially and temporally varying distortions in the image. Current
solutions rely on generative models to reconstruct a turbulent-free image, but
often preserve photo-realism instead of discriminative features that are
essential for recognition. This can be attributed to the lack of large-scale
datasets of turbulent and pristine paired images, necessary for optimal
reconstruction. To address this issue, we propose a new weakly supervised
framework that employs a parameter-efficient self-attention module to generate
domain agnostic representations, aligning turbulent and pristine images into a
common subspace. Additionally, we introduce a new tilt map estimator that
predicts geometric distortions observed in turbulent images. This estimate is
used to re-rank gallery matches, resulting in up to 13.86\% improvement in
rank-1 accuracy. Our method does not require synthesizing turbulent-free images
or ground-truth paired images, and requires significantly fewer annotated
samples, enabling more practical and rapid utility of increasingly large
datasets. We analyze our framework using two datasets -- Long-Range Face
Identification Dataset (LRFID) and BRIAR Government Collection 1 (BGC1) --
achieving enhanced discriminability under varying turbulence and standoff
distance.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11758" title="Abstract">arXiv:2308.11758</a> [<a href="/pdf/2308.11758" title="Download PDF">pdf</a>, <a href="/ps/2308.11758" title="Download PostScript">ps</a>, <a href="/format/2308.11758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Circuits for Fixed Substring Matching Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cantone%2C+D">Domenico Cantone</a>, 
<a href="/search/cs?searchtype=author&query=Faro%2C+S">Simone Faro</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+A">Arianna Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+C">Caterina Viola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Quantum computation represents a computational paradigm whose distinctive
attributes confer the ability to devise algorithms with asymptotic performance
levels significantly superior to those achievable via classical computation.
Recent strides have been taken to apply this computational framework in
tackling and resolving various issues related to text processing. The resultant
solutions demonstrate marked advantages over their classical counterparts. This
study employs quantum computation to efficaciously surmount text processing
challenges, particularly those involving string comparison. The focus is on the
alignment of fixed-length substrings within two input strings. Specifically,
given two input strings, $x$ and $y$, both of length $n$, and a value $d \leq
n$, we want to verify the following conditions: the existence of a common
prefix of length $d$, the presence of a common substring of length $d$
beginning at position $j$ (with $0 \leq j &lt; n$) and, the presence of any common
substring of length $d$ beginning in both strings at the same position. Such
problems find applications as sub-procedures in a variety of problems
concerning text processing and sequence analysis. Notably, our approach
furnishes polylogarithmic solutions, a stark contrast to the linear complexity
inherent in the best classical alternatives.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11759" title="Abstract">arXiv:2308.11759</a> [<a href="/pdf/2308.11759" title="Download PDF">pdf</a>, <a href="/format/2308.11759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Framework for Progressive Data Compression and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magri%2C+V+A+P">Victor A. P. Magri</a>, 
<a href="/search/cs?searchtype=author&query=Lindstrom%2C+P">Peter Lindstrom</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of IEEE VIS 2023, IEEE Transactions on Visualization and Computer Graphics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In scientific simulations, observations, and experiments, the cost of
transferring data to and from disk and across networks has become a significant
bottleneck that particularly impacts subsequent data analysis and
visualization. To address this challenge, compression techniques have been
widely adopted. However, traditional lossy compression approaches often require
setting error tolerances conservatively to respect the numerical sensitivities
of a wide variety of post hoc data analyses, some of which may not even be
known a priori. Progressive data compression and retrieval has emerged as a
solution, allowing for the adaptive handling of compressed data according to
the needs of a given post-processing task. However, few analysis algorithms
natively support progressive data processing, and adapting compression
techniques, file formats, client/server frameworks, and APIs to support
progressivity can be challenging. This work presents a general framework that
supports progressive-precision data queries independently of the underlying
data compressor or number representation. Our approach is based on a
multiple-component representation that successively, with each new component,
reduces the error between the original and compressed field, allowing each
field in the progressive sequence to be expressed as a partial sum of
components. We have implemented our approach on top of four popular scientific
data compressors and have evaluated its behavior on several real-world data
sets from the SDRBench collection. Numerical results indicate that our
framework is effective in terms of accuracy compared to each of the standalone
compressors it builds upon. In addition, (de)compression time is proportional
to the number and granularity of components. Finally, our framework allows for
fully lossless compression using lossy compressors when a sufficient number of
components are employed.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11761" title="Abstract">arXiv:2308.11761</a> [<a href="/pdf/2308.11761" title="Download PDF">pdf</a>, <a href="/format/2308.11761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowledGPT: Enhancing Large Language Models with Retrieval and Storage  Access on Knowledge Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yongting Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhouhong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive impact in the field
of natural language processing, but they still struggle with several issues
regarding, such as completeness, timeliness, faithfulness and adaptability.
While recent efforts have focuses on connecting LLMs with external knowledge
sources, the integration of knowledge bases (KBs) remains understudied and
faces several challenges. In this paper, we introduce KnowledGPT, a
comprehensive framework to bridge LLMs with various knowledge bases,
facilitating both the retrieval and storage of knowledge. The retrieval process
employs the program of thought prompting, which generates search language for
KBs in code format with pre-defined functions for KB operations. Besides
retrieval, KnowledGPT offers the capability to store knowledge in a
personalized KB, catering to individual user demands. With extensive
experiments, we show that by integrating LLMs with KBs, KnowledGPT properly
answers a broader range of questions requiring world knowledge compared with
vanilla LLMs, utilizing both knowledge existing in widely-known KBs and
extracted into personalized KBs.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11762" title="Abstract">arXiv:2308.11762</a> [<a href="/pdf/2308.11762" title="Download PDF">pdf</a>, <a href="/format/2308.11762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INS/DVL Fusion with DVL Based Acceleration Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Levy%2C+O">Orzion Levy</a>, 
<a href="/search/eess?searchtype=author&query=Klein%2C+I">Itzik Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 diagram, 1 image, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Autonomous underwater vehicles (AUVs) are increasingly used in many
applications such as oceanographic surveys, mapping, and inspection of
underwater structures. To successfully complete those tasks, a Doppler velocity
log (DVL) and an inertial navigation system (INS) are utilized to determine the
AUV navigation solution. In such fusion, DVL velocity measurement is used to
update the navigation states. In this paper, we propose calculating the AUV
acceleration vector based on past DVL measurements and using it as an
additional update to increase the system's accuracy. Simulations and sea
experiments were conducted to demonstrate the efficiency of our approach. The
results indicate that the proposed method exhibits rapid convergence and
significantly improves the overall performance compared to the baseline INS and
DVL fusion approach.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11764" title="Abstract">arXiv:2308.11764</a> [<a href="/pdf/2308.11764" title="Download PDF">pdf</a>, <a href="/format/2308.11764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Halo: Estimation and Reduction of Hallucinations in Open-Source Weak  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elaraby%2C+M">Mohamed Elaraby</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mengyin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dunn%2C+J">Jacob Dunn</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shizhu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP). Although convenient for research and practical applications, open-source
LLMs with fewer parameters often suffer from severe hallucinations compared to
their larger counterparts. This paper focuses on measuring and reducing
hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs
that are publicly available for research and commercial applications. We
introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed
to quantify the severity of hallucinations in LLMs. Additionally, we explore
techniques like knowledge injection and teacher-student approaches to alleviate
hallucinations in low-parameter LLMs. Our experiments effectively demonstrate
the reduction of hallucinations in challenging domains for these LLMs.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11767" title="Abstract">arXiv:2308.11767</a> [<a href="/pdf/2308.11767" title="Download PDF">pdf</a>, <a href="/format/2308.11767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Detection of ChatGPT-Generated Fake Science Using Real  Publication Text: Introducing xFakeBibs a Supervised-Learning Network  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+A+A">Ahmed Abdeen Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xindong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 4 tables, 2 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">ChatGPT is becoming a new reality. In this paper, we show how to distinguish
ChatGPT-generated publications from counterparts produced by scientists. Using
a newly designed supervised Machine Learning algorithm, we demonstrate how to
detect machine-generated publications from those produced by scientists. The
algorithm was trained using 100 real publication abstracts, followed by a
10-fold calibration approach to establish a lower-upper bound range of
acceptance. In the comparison with ChatGPT content, it was evident that ChatGPT
contributed merely 23\% of the bigram content, which is less than 50\% of any
of the other 10 calibrating folds. This analysis highlights a significant
disparity in technical terms where ChatGPT fell short of matching real science.
When categorizing the individual articles, the xFakeBibs algorithm accurately
identified 98 out of 100 publications as fake, with 2 articles incorrectly
classified as real publications. Though this work introduced an algorithmic
approach that detected the ChatGPT-generated fake science with a high degree of
accuracy, it remains challenging to detect all fake records. This work is
indeed a step in the right direction to counter fake science and
misinformation.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11771" title="Abstract">arXiv:2308.11771</a> [<a href="/pdf/2308.11771" title="Download PDF">pdf</a>, <a href="/format/2308.11771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zuowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shih-Chii Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at the 2023 IEEE Biomedical Circuits and Systems (BioCAS) Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a sparse Change-Based Convolutional Long Short-Term
Memory (CB-ConvLSTM) model for event-based eye tracking, key for
next-generation wearable healthcare technology such as AR/VR headsets. We
leverage the benefits of retina-inspired event cameras, namely their
low-latency response and sparse output event stream, over traditional
frame-based cameras. Our CB-ConvLSTM architecture efficiently extracts
spatio-temporal features for pupil tracking from the event stream,
outperforming conventional CNN structures. Utilizing a delta-encoded recurrent
path enhancing activation sparsity, CB-ConvLSTM reduces arithmetic operations
by approximately 4.7$\times$ without losing accuracy when tested on a
\texttt{v2e}-generated event dataset of labeled pupils. This increase in
efficiency makes it ideal for real-time eye tracking in resource-constrained
devices. The project code and dataset are openly available at
\url{https://github.com/qinche106/cb-convlstm-eyetracking}.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11773" title="Abstract">arXiv:2308.11773</a> [<a href="/pdf/2308.11773" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying depression-related topics in smartphone-collected  free-response speech recordings using an automatic speech recognition system  and a deep learning topic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuezhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Folarin%2C+A+A">Amos A Folarin</a>, 
<a href="/search/cs?searchtype=author&query=Dineley%2C+J">Judith Dineley</a>, 
<a href="/search/cs?searchtype=author&query=Conde%2C+P">Pauline Conde</a>, 
<a href="/search/cs?searchtype=author&query=de+Angel%2C+V">Valeria de Angel</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaoxiong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+Y">Yatharth Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+Z">Zulqarnain Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Callum Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Laiou%2C+P">Petroula Laiou</a>, 
<a href="/search/cs?searchtype=author&query=Sankesara%2C+H">Heet Sankesara</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Linglong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Matcham%2C+F">Faith Matcham</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+K+M">Katie M White</a>, 
<a href="/search/cs?searchtype=author&query=Oetzmann%2C+C">Carolin Oetzmann</a>, 
<a href="/search/cs?searchtype=author&query=Lamers%2C+F">Femke Lamers</a>, 
<a href="/search/cs?searchtype=author&query=Siddi%2C+S">Sara Siddi</a>, 
<a href="/search/cs?searchtype=author&query=Simblett%2C+S">Sara Simblett</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Vairavan%2C+S">Srinivasan Vairavan</a>, 
<a href="/search/cs?searchtype=author&query=Wykes%2C+T">Til Wykes</a>, 
<a href="/search/cs?searchtype=author&query=Haro%2C+J+M">Josep Maria Haro</a>, 
<a href="/search/cs?searchtype=author&query=Penninx%2C+B+W">Brenda WJH Penninx</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+V+A">Vaibhav A Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Hotopf%2C+M">Matthew Hotopf</a>, 
<a href="/search/cs?searchtype=author&query=Dobson%2C+R+J">Richard JB Dobson</a>, 
<a href="/search/cs?searchtype=author&query=Cummins%2C+N">Nicholas Cummins</a>, 
<a href="/search/cs?searchtype=author&query=consortium%2C+R">RADAR-CNS consortium</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Language use has been shown to correlate with depression, but large-scale
validation is needed. Traditional methods like clinic studies are expensive.
So, natural language processing has been employed on social media to predict
depression, but limitations remain-lack of validated labels, biased user
samples, and no context. Our study identified 29 topics in 3919
smartphone-collected speech recordings from 265 participants using the Whisper
tool and BERTopic model. Six topics with a median PHQ-8 greater than or equal
to 10 were regarded as risk topics for depression: No Expectations, Sleep,
Mental Therapy, Haircut, Studying, and Coursework. To elucidate the topic
emergence and associations with depression, we compared behavioral (from
wearables) and linguistic characteristics across identified topics. The
correlation between topic shifts and changes in depression severity over time
was also investigated, indicating the importance of longitudinally monitoring
language use. We also tested the BERTopic model on a similar smaller dataset
(356 speech recordings from 57 participants), obtaining some consistent
results. In summary, our findings demonstrate specific speech topics may
indicate depression severity. The presented data-driven workflow provides a
practical approach to collecting and analyzing large-scale speech data from
real-world settings for digital health research.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11774" title="Abstract">arXiv:2308.11774</a> [<a href="/pdf/2308.11774" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene  Reconstruction by Neural Radiance Field (NeRF)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Ange Lou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yamin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+J">Jack Noble</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accurate reconstruction of surgical scenes from surgical videos is
critical for various applications, including intraoperative navigation and
image-guided robotic surgery automation. However, previous approaches, mainly
relying on depth estimation, have limited effectiveness in reconstructing
surgical scenes with moving surgical tools. To address this limitation and
provide accurate 3D position prediction for surgical tools in all frames, we
propose a novel approach called SAMSNeRF that combines Segment Anything Model
(SAM) and Neural Radiance Field (NeRF) techniques. Our approach generates
accurate segmentation masks of surgical tools using SAM, which guides the
refinement of the dynamic surgical scene reconstruction by NeRF. Our
experimental results on public endoscopy surgical videos demonstrate that our
approach successfully reconstructs high-fidelity dynamic surgical scenes and
accurately reflects the spatial information of surgical tools. Our proposed
approach can significantly enhance surgical navigation and automation by
providing surgeons with accurate 3D position information of surgical tools
during surgery.The source code will be released soon.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11776" title="Abstract">arXiv:2308.11776</a> [<a href="/pdf/2308.11776" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation  on Surgical Videos with Unknown Camera Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Ange Lou</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+J">Jack Noble</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Depth estimation in surgical video plays a crucial role in many image-guided
surgery procedures. However, it is difficult and time consuming to create depth
map ground truth datasets in surgical videos due in part to inconsistent
brightness and noise in the surgical scene. Therefore, building an accurate and
robust self-supervised depth and camera ego-motion estimation system is gaining
more attention from the computer vision community. Although several
self-supervision methods alleviate the need for ground truth depth maps and
poses, they still need known camera intrinsic parameters, which are often
missing or not recorded. Moreover, the camera intrinsic prediction methods in
existing works depend heavily on the quality of datasets. In this work, we
aimed to build a self-supervised depth and ego-motion estimation system which
can predict not only accurate depth maps and camera pose, but also camera
intrinsic parameters. We proposed a cost-volume-based supervision manner to
give the system auxiliary supervision for camera parameters prediction. The
experimental results showed that the proposed method improved the accuracy of
estimated camera parameters, ego-motion, and depth estimation.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11778" title="Abstract">arXiv:2308.11778</a> [<a href="/pdf/2308.11778" title="Download PDF">pdf</a>, <a href="/format/2308.11778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Hessian Alignment for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemati%2C+S">Sobhan Hemati</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guojun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Estiri%2C+A">Amir Estiri</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Out-of-distribution (OOD) generalization is a critical ability for deep
learning models in many real-world scenarios including healthcare and
autonomous vehicles. Recently, different techniques have been proposed to
improve OOD generalization. Among these methods, gradient-based regularizers
have shown promising performance compared with other competitors. Despite this
success, our understanding of the role of Hessian and gradient alignment in
domain generalization is still limited. To address this shortcoming, we analyze
the role of the classifier's head Hessian matrix and gradient in domain
generalization using recent OOD theory of transferability. Theoretically, we
show that spectral norm between the classifier's head Hessian matrices across
domains is an upper bound of the transfer measure, a notion of distance between
target and source domains. Furthermore, we analyze all the attributes that get
aligned when we encourage similarity between Hessians and gradients. Our
analysis explains the success of many regularizers like CORAL, IRM, V-REx,
Fish, IGA, and Fishr as they regularize part of the classifier's head Hessian
and/or gradient. Finally, we propose two simple yet effective methods to match
the classifier's head Hessians and gradients in an efficient way, based on the
Hessian Gradient Product (HGP) and Hutchinson's method (Hutchinson), and
without directly calculating Hessians. We validate the OOD generalization
ability of proposed methods in different scenarios, including transferability,
severe correlation shift, label shift and diversity shift. Our results show
that Hessian alignment methods achieve promising performance on various OOD
benchmarks. The code is available at
\url{https://github.com/huawei-noah/Federated-Learning/tree/main/HessianAlignment}.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11780" title="Abstract">arXiv:2308.11780</a> [<a href="/pdf/2308.11780" title="Download PDF">pdf</a>, <a href="/format/2308.11780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Anomaly Detection in Text with Deviation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A+S">Anindya Sundar Das</a>, 
<a href="/search/cs?searchtype=author&query=Ajay%2C+A">Aravind Ajay</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sriparna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Bhuyan%2C+M">Monowar Bhuyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICONIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Most current methods for detecting anomalies in text concentrate on
constructing models solely relying on unlabeled data. These models operate on
the presumption that no labeled anomalous examples are available, which
prevents them from utilizing prior knowledge of anomalies that are typically
present in small numbers in many real-world applications. Furthermore, these
models prioritize learning feature embeddings rather than optimizing anomaly
scores directly, which could lead to suboptimal anomaly scoring and inefficient
use of data during the learning process. In this paper, we introduce FATE, a
deep few-shot learning-based framework that leverages limited anomaly examples
and learns anomaly scores explicitly in an end-to-end method using deviation
learning. In this approach, the anomaly scores of normal examples are adjusted
to closely resemble reference scores obtained from a prior distribution.
Conversely, anomaly samples are forced to have anomalous scores that
considerably deviate from the reference score in the upper tail of the prior.
Additionally, our model is optimized to learn the distinct behavior of
anomalies by utilizing a multi-head self-attention layer and multiple instance
learning approaches. Comprehensive experiments on several benchmark datasets
demonstrate that our proposed approach attains a new level of state-of-the-art
performance.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11781" title="Abstract">arXiv:2308.11781</a> [<a href="/pdf/2308.11781" title="Download PDF">pdf</a>, <a href="/format/2308.11781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Dynamic and Sparse Qualitative Data: A Hilbert Space  Embedding of Categorical Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anirban Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+H">Hannah H. Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a novel framework for incorporating qualitative data into
quantitative models for causal estimation. Previous methods use categorical
variables derived from qualitative data to build quantitative models. However,
this approach can lead to data-sparse categories and yield inconsistent
(asymptotically biased) and imprecise (finite sample biased) estimates if the
qualitative information is dynamic and intricate. We use functional analysis to
create a more nuanced and flexible framework. We embed the observed categories
into a latent Baire space and introduce a continuous linear map -- a Hilbert
space embedding -- from the Baire space of categories to a Reproducing Kernel
Hilbert Space (RKHS) of representation functions. Through the Riesz
representation theorem, we establish that the canonical treatment of
categorical variables in causal models can be transformed into an identified
structure in the RKHS. Transfer learning acts as a catalyst to streamline
estimation -- embeddings from traditional models are paired with the kernel
trick to form the Hilbert space embedding. We validate our model through
comprehensive simulation evidence and demonstrate its relevance in a real-world
study that contrasts theoretical predictions from economics and psychology in
an e-commerce marketplace. The results confirm the superior performance of our
model, particularly in scenarios where qualitative information is nuanced and
complex.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11782" title="Abstract">arXiv:2308.11782</a> [<a href="/pdf/2308.11782" title="Download PDF">pdf</a>, <a href="/format/2308.11782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation in Cloud Computing Using Genetic Algorithm and  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manavi%2C+M">Mahdi Manavi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoning Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Smart Cloud 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Cloud computing is one of the most used distributed systems for data
processing and data storage. Due to the continuous increase in the size of the
data processed by cloud computing, scheduling multiple tasks to maintain
efficiency while reducing idle becomes more and more challenging. Efficient
cloud-based scheduling is also highly sought by modern transportation systems
to improve their security. In this paper, we propose a hybrid algorithm that
leverages genetic algorithms and neural networks to improve scheduling. Our
method classifies tasks with the Neural Network Task Classification (N2TC) and
sends the selected tasks to the Genetic Algorithm Task Assignment (GATA) to
allocate resources. It is fairness aware to prevent starvation and considers
the execution time, response time, cost, and system efficiency. Evaluations
show that our approach outperforms the state-of-the-art method by 3.2% at
execution time, 13.3% in costs, and 12.1% at response time.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11783" title="Abstract">arXiv:2308.11783</a> [<a href="/pdf/2308.11783" title="Download PDF">pdf</a>, <a href="/format/2308.11783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-to-Fine Multi-Scene Pose Regression with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shavit%2C+Y">Yoli Shavit</a>, 
<a href="/search/cs?searchtype=author&query=Ferens%2C+R">Ron Ferens</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+Y">Yosi Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). arXiv admin note: substantial text overlap with <a href="/abs/2103.11468">arXiv:2103.11468</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Absolute camera pose regressors estimate the position and orientation of a
camera given the captured image alone. Typically, a convolutional backbone with
a multi-layer perceptron (MLP) head is trained using images and pose labels to
embed a single reference scene at a time. Recently, this scheme was extended to
learn multiple scenes by replacing the MLP head with a set of fully connected
layers. In this work, we propose to learn multi-scene absolute camera pose
regression with Transformers, where encoders are used to aggregate activation
maps with self-attention and decoders transform latent features and scenes
encoding into pose predictions. This allows our model to focus on general
features that are informative for localization, while embedding multiple scenes
in parallel. We extend our previous MS-Transformer approach
\cite{shavit2021learning} by introducing a mixed classification-regression
architecture that improves the localization accuracy. Our method is evaluated
on commonly benchmark indoor and outdoor datasets and has been shown to exceed
both multi-scene and state-of-the-art single-scene absolute pose regressors.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11785" title="Abstract">arXiv:2308.11785</a> [<a href="/pdf/2308.11785" title="Download PDF">pdf</a>, <a href="/ps/2308.11785" title="Download PostScript">ps</a>, <a href="/format/2308.11785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe Automated Refactoring of Imperative Deep Learning Programs  to Graph Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatchadourian%2C+R">Raffi Khatchadourian</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A9lez%2C+T+C">Tatiana Castro V&#xe9;lez</a>, 
<a href="/search/cs?searchtype=author&query=Bagherzadeh%2C+M">Mehdi Bagherzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+N">Nan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+A">Anita Raja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Automated Software Engineering, ASE '23, Kirchberg, Luxembourg, September 2023. IEEE/ACM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Efficiency is essential to support responsiveness w.r.t. ever-growing
datasets, especially for Deep Learning (DL) systems. DL frameworks have
traditionally embraced deferred execution-style DL code -- supporting symbolic,
graph-based Deep Neural Network (DNN) computation. While scalable, such
development tends to produce code that is error-prone, non-intuitive, and
difficult to debug. Consequently, more natural, less error-prone imperative DL
frameworks encouraging eager execution have emerged at the expense of run-time
performance. Though hybrid approaches aim for the "best of both worlds," using
them effectively requires subtle considerations to make code amenable to safe,
accurate, and efficient graph execution -- avoiding performance bottlenecks and
semantically inequivalent results. We present our ongoing work on an automated
refactoring approach that assists developers in specifying whether and how
their otherwise eagerly-executed imperative DL code could be reliably and
efficiently executed as graphs at run-time in a semantics-preserving fashion.
The approach, based on a novel tensor analysis specifically for imperative DL
code, consists of refactoring preconditions for automatically determining when
it is safe and potentially advantageous to migrate imperative DL code to graph
execution and modifying decorator parameters or eagerly executing code already
running as graphs. The approach is being implemented as a PyDev Eclipse IDE
plug-in and uses the WALA Ariadne analysis framework. We discuss our ongoing
work towards optimizing imperative DL code to its full potential.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11786" title="Abstract">arXiv:2308.11786</a> [<a href="/pdf/2308.11786" title="Download PDF">pdf</a>, <a href="/format/2308.11786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Better Human-Agent Teams: Tradeoffs in Helpfulness and  Humanness in Voice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westby%2C+S">Samuel Westby</a>, 
<a href="/search/cs?searchtype=author&query=Radke%2C+R+J">Richard J. Radke</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+C">Christoph Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Welles%2C+B+F">Brooke Foucault Welles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We manipulate the helpfulness and voice type of a voice-only agent teammate
to examine subjective and objective outcomes in twenty teams with one agent and
at least three humans during a problem solving task. Our results show that
agent helpfulness, but not the humanness of the agent's voice, significantly
alters perceptions of agent intelligence and trust in agent teammates, as well
as affects team performance. Additionally, we find that the humanness of an
agent's voice negatively interacts with agent helpfulness to flip its effect on
perceived anthropomorphism and perceived animacy. This means human teammates
interpret the agent's contributions differently depending on its vocal type.
These findings suggest that function matters more than form when designing
agents for effective human-agent teams and help to explain contradictory
findings in the literature. Practitioners should be aware of the interactive
effects of voice and helpfulness on subjective outcomes such as perceived
anthropomorphism and animacy.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11787" title="Abstract">arXiv:2308.11787</a> [<a href="/pdf/2308.11787" title="Download PDF">pdf</a>, <a href="/format/2308.11787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HypBO: Expert-Guided Chemist-in-the-Loop Bayesian Search for New  Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cisse%2C+A">Abdoulatif Cisse</a>, 
<a href="/search/cs?searchtype=author&query=Evangelopoulos%2C+X">Xenophon Evangelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Carruthers%2C+S">Sam Carruthers</a>, 
<a href="/search/cs?searchtype=author&query=Gusev%2C+V+V">Vladimir V. Gusev</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+I">Andrew I. Cooper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Robotics and automation offer massive accelerations for solving intractable,
multivariate scientific problems such as materials discovery, but the available
search spaces can be dauntingly large. Bayesian optimization (BO) has emerged
as a popular sample-efficient optimization engine, thriving in tasks where no
analytic form of the target function/property is known. Here we exploit expert
human knowledge in the form of hypotheses to direct Bayesian searches more
quickly to promising regions of chemical space. Previous methods have used
underlying distributions derived from existing experimental measurements, which
is unfeasible for new, unexplored scientific tasks. Also, such distributions
cannot capture intricate hypotheses. Our proposed method, which we call HypBO,
uses expert human hypotheses to generate an improved seed of samples.
Unpromising seeds are automatically discounted, while promising seeds are used
to augment the surrogate model data, thus achieving better-informed sampling.
This process continues in a global versus local search fashion, organized in a
bilevel optimization framework. We validate the performance of our method on a
range of synthetic functions and demonstrate its practical utility on a real
chemical design task where the use of expert hypotheses accelerates the search
performance significantly.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11788" title="Abstract">arXiv:2308.11788</a> [<a href="/pdf/2308.11788" title="Download PDF">pdf</a>, <a href="/format/2308.11788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extensible point-based method for data chart value detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soto%2C+C">Carlos Soto</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present an extensible method for identifying semantic points to reverse
engineer (i.e. extract the values of) data charts, particularly those in
scientific articles. Our method uses a point proposal network (akin to region
proposal networks for object detection) to directly predict the position of
points of interest in a chart, and it is readily extensible to multiple chart
types and chart elements. We focus on complex bar charts in the scientific
literature, on which our model is able to detect salient points with an
accuracy of 0.8705 F1 (@1.5-cell max deviation); it achieves 0.9810 F1 on
synthetically-generated charts similar to those used in prior works. We also
explore training exclusively on synthetic data with novel augmentations,
reaching surprisingly competent performance in this way (0.6621 F1) on real
charts with widely varying appearance, and we further demonstrate our unchanged
method applied directly to synthetic pie charts (0.8343 F1). Datasets, trained
models, and evaluation code are available at
https://github.com/BNLNLP/PPN_model.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11792" title="Abstract">arXiv:2308.11792</a> [<a href="/pdf/2308.11792" title="Download PDF">pdf</a>, <a href="/format/2308.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Karasu: A Collaborative Approach to Efficient Cluster Configuration for  Big Data Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Wittkopp%2C+T">Thorsten Wittkopp</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>, 
<a href="/search/cs?searchtype=author&query=Will%2C+J">Jonathan Will</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Selecting the right resources for big data analytics jobs is hard because of
the wide variety of configuration options like machine type and cluster size.
As poor choices can have a significant impact on resource efficiency, cost, and
energy usage, automated approaches are gaining popularity. Most existing
methods rely on profiling recurring workloads to find near-optimal solutions
over time. Due to the cold-start problem, this often leads to lengthy and
costly profiling phases. However, big data analytics jobs across users can
share many common properties: they often operate on similar infrastructure,
using similar algorithms implemented in similar frameworks. The potential in
sharing aggregated profiling runs to collaboratively address the cold start
problem is largely unexplored.
<br />We present Karasu, an approach to more efficient resource configuration
profiling that promotes data sharing among users working with similar
infrastructures, frameworks, algorithms, or datasets. Karasu trains lightweight
performance models using aggregated runtime information of collaborators and
combines them into an ensemble method to exploit inherent knowledge of the
configuration search space. Moreover, Karasu allows the optimization of
multiple objectives simultaneously. Our evaluation is based on performance data
from diverse workload executions in a public cloud environment. We show that
Karasu is able to significantly boost existing methods in terms of performance,
search time, and cost, even when few comparable profiling runs are available
that share only partial common characteristics with the target job.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11793" title="Abstract">arXiv:2308.11793</a> [<a href="/pdf/2308.11793" title="Download PDF">pdf</a>, <a href="/format/2308.11793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer  with Mixture-of-View-Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+W">Wenyan Cong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Hanxue Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+M">Mukund Varma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-scene generalizable NeRF models, which can directly synthesize novel
views of unseen scenes, have become a new spotlight of the NeRF field. Several
existing attempts rely on increasingly end-to-end "neuralized" architectures,
i.e., replacing scene representation and/or rendering modules with performant
neural networks such as transformers, and turning novel view synthesis into a
feed-forward inference pipeline. While those feedforward "neuralized"
architectures still do not fit diverse scenes well out of the box, we propose
to bridge them with the powerful Mixture-of-Experts (MoE) idea from large
language models (LLMs), which has demonstrated superior generalization ability
by balancing between larger overall model capacity and flexible per-instance
specialization. Starting from a recent generalizable NeRF architecture called
GNT, we first demonstrate that MoE can be neatly plugged in to enhance the
model. We further customize a shared permanent expert and a geometry-aware
consistency loss to enforce cross-scene consistency and spatial smoothness
respectively, which are essential for generalizable view synthesis. Our
proposed model, dubbed GNT with Mixture-of-View-Experts (GNT-MOVE), has
experimentally shown state-of-the-art results when transferring to unseen
scenes, indicating remarkably better cross-scene generalization in both
zero-shot and few-shot settings. Our codes are available at
https://github.com/VITA-Group/GNT-MOVE.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11796" title="Abstract">arXiv:2308.11796</a> [<a href="/pdf/2308.11796" title="Download PDF">pdf</a>, <a href="/format/2308.11796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Does Tell: Self-Supervised Time-Tuning of Dense Image  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mohammadreza Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spatially dense self-supervised learning is a rapidly growing problem domain
with promising applications for unsupervised segmentation and pretraining for
dense downstream tasks. Despite the abundance of temporal data in the form of
videos, this information-rich source has been largely overlooked. Our paper
aims to address this gap by proposing a novel approach that incorporates
temporal consistency in dense self-supervised learning. While methods designed
solely for images face difficulties in achieving even the same performance on
videos, our method improves not only the representation quality for videos-but
also images. Our approach, which we call time-tuning, starts from
image-pretrained models and fine-tunes them with a novel self-supervised
temporal-alignment clustering loss on unlabeled videos. This effectively
facilitates the transfer of high-level information from videos to image
representations. Time-tuning improves the state-of-the-art by 8-10% for
unsupervised semantic segmentation on videos and matches it for images. We
believe this method paves the way for further self-supervised scaling by
leveraging the abundant availability of videos. The implementation can be found
here : https://github.com/SMSD75/Timetuning
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11797" title="Abstract">arXiv:2308.11797</a> [<a href="/pdf/2308.11797" title="Download PDF">pdf</a>, <a href="/format/2308.11797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP Multi-modal Hashing: A new baseline CLIPMH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+M">Mingkai Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+M">Mingda Ke</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhangmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jingfei Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Multimedia (cs.MM)

</div>
<p class="mathjax">The multi-modal hashing method is widely used in multimedia retrieval. It can
fuse multi-source data to generate binary hash code. However, the current
multi-modal methods have the problem of low retrieval accuracy. The reason is
that the individual backbone networks have limited feature expression
capabilities and are not jointly pre-trained on large-scale unsupervised
multi-modal data. To solve this problem, we propose a new baseline CLIP
Multi-modal Hashing (CLIPMH) method. It uses CLIP model to extract text and
image features, and then fuse to generate hash code. CLIP improves the
expressiveness of each modal feature. In this way, it can greatly improve the
retrieval performance of multi-modal hashing methods. In comparison to
state-of-the-art unsupervised and supervised multi-modal hashing methods,
experiments reveal that the proposed CLIPMH can significantly enhance
performance (Maximum increase of 8.38%). CLIP also has great advantages over
the text and visual backbone networks commonly used before.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11800" title="Abstract">arXiv:2308.11800</a> [<a href="/pdf/2308.11800" title="Download PDF">pdf</a>, <a href="/format/2308.11800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex-valued neural networks for voice anti-spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+N+M">Nicolas M. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Sperl%2C+P">Philip Sperl</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttinger%2C+K">Konstantin B&#xf6;ttinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Current anti-spoofing and audio deepfake detection systems use either
magnitude spectrogram-based features (such as CQT or Melspectrograms) or raw
audio processed through convolution or sinc-layers. Both methods have
drawbacks: magnitude spectrograms discard phase information, which affects
audio naturalness, and raw-feature-based models cannot use traditional
explainable AI methods. This paper proposes a new approach that combines the
benefits of both methods by using complex-valued neural networks to process the
complex-valued, CQT frequency-domain representation of the input audio. This
method retains phase information and allows for explainable AI methods. Results
show that this approach outperforms previous methods on the "In-the-Wild"
anti-spoofing dataset and enables interpretation of the results through
explainable AI. Ablation studies confirm that the model has learned to use
phase information to detect voice spoofing.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11801" title="Abstract">arXiv:2308.11801</a> [<a href="/pdf/2308.11801" title="Download PDF">pdf</a>, <a href="/ps/2308.11801" title="Download PostScript">ps</a>, <a href="/format/2308.11801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Density Propagation Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelini%2C+C">Christopher Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Bouaynaya%2C+N">Nidhal Bouaynaya</a>, 
<a href="/search/cs?searchtype=author&query=Rasool%2C+G">Ghulam Rasool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 13th Int'l Symposium on Image and Signal Processing and Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) deployed to the real world are regularly subject
to out-of-distribution (OoD) data, various types of noise, and shifting
conceptual objectives. This paper proposes a framework for adapting to data
distribution drift modeled by benchmark Continual Learning datasets. We develop
and evaluate a method of Continual Learning that leverages uncertainty
quantification from Bayesian Inference to mitigate catastrophic forgetting. We
expand on previous approaches by removing the need for Monte Carlo sampling of
the model weights to sample the predictive distribution. We optimize a
closed-form Evidence Lower Bound (ELBO) objective approximating the predictive
distribution by propagating the first two moments of a distribution, i.e. mean
and covariance, through all network layers. Catastrophic forgetting is
mitigated by using the closed-form ELBO to approximate the Minimum Description
Length (MDL) Principle, inherently penalizing changes in the model likelihood
by minimizing the KL Divergence between the variational posterior for the
current task and the previous task's variational posterior acting as the prior.
Leveraging the approximation of the MDL principle, we aim to initially learn a
sparse variational posterior and then minimize additional model complexity
learned for subsequent tasks. Our approach is evaluated for the task
incremental learning scenario using density propagated versions of
fully-connected and convolutional neural networks across multiple sequential
benchmark datasets with varying task sequence lengths. Ultimately, this
procedure produces a minimally complex network over a series of tasks
mitigating catastrophic forgetting.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11804" title="Abstract">arXiv:2308.11804</a> [<a href="/pdf/2308.11804" title="Download PDF">pdf</a>, <a href="/format/2308.11804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ceci n&#x27;est pas une pomme: Adversarial Illusions in Multi-Modal  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagdasaryan%2C+E">Eugene Bagdasaryan</a>, 
<a href="/search/cs?searchtype=author&query=Shmatikov%2C+V">Vitaly Shmatikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-modal encoders map images, sounds, texts, videos, etc. into a single
embedding space, aligning representations across modalities (e.g., associate an
image of a dog with a barking sound). We show that multi-modal embeddings can
be vulnerable to an attack we call "adversarial illusions." Given an input in
any modality, an adversary can perturb it so as to make its embedding close to
that of an arbitrary, adversary-chosen input in another modality. Illusions
thus enable the adversary to align any image with any text, any text with any
sound, etc.
<br />Adversarial illusions exploit proximity in the embedding space and are thus
agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how
adversarially aligned inputs, generated without knowledge of specific
downstream tasks, mislead image generation, text generation, and zero-shot
classification.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11806" title="Abstract">arXiv:2308.11806</a> [<a href="/pdf/2308.11806" title="Download PDF">pdf</a>, <a href="/format/2308.11806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Multi-DoF Aerial 3D Printing Supported with Automated Optimal  Chunking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stamatopoulos%2C+M">Marios-Nektarios Stamatopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Avijit Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Nikolakopoulos%2C+G">George Nikolakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The future of 3D printing utilizing unmanned aerial vehicles (UAVs) presents
a promising capability to revolutionize manufacturing and to enable the
creation of large-scale structures in remote and hard- to-reach areas e.g. in
other planetary systems. Nevertheless, the limited payload capacity of UAVs and
the complexity in the 3D printing of large objects pose significant challenges.
In this article we propose a novel chunk-based framework for distributed 3D
printing using UAVs that sets the basis for a fully collaborative aerial 3D
printing of challenging structures. The presented framework, through a novel
proposed optimisation process, is able to divide the 3D model to be printed
into small, manageable chunks and to assign them to a UAV for partial printing
of the assigned chunk, in a fully autonomous approach. Thus, we establish the
algorithms for chunk division, allocation, and printing, and we also introduce
a novel algorithm that efficiently partitions the mesh into planar chunks,
while accounting for the inter-connectivity constraints of the chunks. The
efficiency of the proposed framework is demonstrated through multiple physics
based simulations in Gazebo, where a CAD construction mesh is printed via
multiple UAVs carrying materials whose volume is proportionate to a fraction of
the total mesh volume.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11807" title="Abstract">arXiv:2308.11807</a> [<a href="/pdf/2308.11807" title="Download PDF">pdf</a>, <a href="/format/2308.11807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an On-device Agent for Text Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Stahlberg%2C+F">Felix Stahlberg</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shankar Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liangchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+L">Lei Shu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Renjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lei Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated impressive capabilities for
text rewriting. Nonetheless, the large sizes of these models make them
impractical for on-device inference, which would otherwise allow for enhanced
privacy and economical inference. Creating a smaller yet potent language model
for text rewriting presents a formidable challenge because it requires
balancing the need for a small size with the need to retain the emergent
capabilities of the LLM, that requires costly data collection. To address the
above challenge, we introduce a new instruction tuning approach for building a
mobile-centric text rewriting model. Our strategies enable the generation of
high quality training data without any human labeling. In addition, we propose
a heuristic reinforcement learning framework which substantially enhances
performance without requiring preference data. To further bridge the
performance gap with the larger server-side model, we propose an effective
approach that combines the mobile rewrite agent with the server model using a
cascade. To tailor the text rewriting tasks to mobile scenarios, we introduce
MessageRewriteEval, a benchmark that focuses on text rewriting for messages
through natural language instructions. Through empirical experiments, we
demonstrate that our on-device model surpasses the current state-of-the-art
LLMs in text rewriting while maintaining a significantly reduced model size.
Notably, we show that our proposed cascading approach improves model
performance.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11814" title="Abstract">arXiv:2308.11814</a> [<a href="/pdf/2308.11814" title="Download PDF">pdf</a>, <a href="/format/2308.11814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Deep Neural Operator Models toward Ocean Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajagopal%2C+E">Ellery Rajagopal</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+N+S">Anantha N.S. Babu</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+T">Tony Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Haley%2C+P+J">Patrick J. Haley Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Mirabito%2C+C">Chris Mirabito</a>, 
<a href="/search/cs?searchtype=author&query=Lermusiaux%2C+P+F+J">Pierre F.J. Lermusiaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rajagopal, E., A.N.S. Babu, T. Ryu, P.J. Haley, Jr., C. Mirabito, and P.F.J. Lermusiaux, 2023. Evaluation of Deep Neural Operator Models toward Ocean Forecasting. In OCEANS' 23 IEEE/MTS Gulf Coast, 25-28 September 2023, in press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Atmospheric and Oceanic Physics (physics.ao-ph); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Data-driven, deep-learning modeling frameworks have been recently developed
for forecasting time series data. Such machine learning models may be useful in
multiple domains including the atmospheric and oceanic ones, and in general,
the larger fluids community. The present work investigates the possible
effectiveness of such deep neural operator models for reproducing and
predicting classic fluid flows and simulations of realistic ocean dynamics. We
first briefly evaluate the capabilities of such deep neural operator models
when trained on a simulated two-dimensional fluid flow past a cylinder. We then
investigate their application to forecasting ocean surface circulation in the
Middle Atlantic Bight and Massachusetts Bay, learning from high-resolution
data-assimilative simulations employed for real sea experiments. We confirm
that trained deep neural operator models are capable of predicting idealized
periodic eddy shedding. For realistic ocean surface flows and our preliminary
study, they can predict several of the features and show some skill, providing
potential for future research and applications.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11817" title="Abstract">arXiv:2308.11817</a> [<a href="/pdf/2308.11817" title="Download PDF">pdf</a>, <a href="/format/2308.11817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Honeypot Allocation for Cyber Deception in Dynamic Tactical Networks: A  Game Theoretic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Md Abu Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A+H">Ahmed H. Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Kiekintveld%2C+C">Christopher Kiekintveld</a>, 
<a href="/search/cs?searchtype=author&query=Kamhoua%2C+C">Charles Kamhoua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper accepted in 14th International Conference on Decision and Game Theory for Security, GameSec 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Honeypots play a crucial role in implementing various cyber deception
techniques as they possess the capability to divert attackers away from
valuable assets. Careful strategic placement of honeypots in networks should
consider not only network aspects but also attackers' preferences. The
allocation of honeypots in tactical networks under network mobility is of great
interest. To achieve this objective, we present a game-theoretic approach that
generates optimal honeypot allocation strategies within an attack/defense
scenario. Our proposed approach takes into consideration the changes in network
connectivity. In particular, we introduce a two-player dynamic game model that
explicitly incorporates the future state evolution resulting from changes in
network connectivity. The defender's objective is twofold: to maximize the
likelihood of the attacker hitting a honeypot and to minimize the cost
associated with deception and reconfiguration due to changes in network
topology. We present an iterative algorithm to find Nash equilibrium strategies
and analyze the scalability of the algorithm. Finally, we validate our approach
and present numerical results based on simulations, demonstrating that our game
model successfully enhances network security. Additionally, we have proposed
additional enhancements to improve the scalability of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11818" title="Abstract">arXiv:2308.11818</a> [<a href="/pdf/2308.11818" title="Download PDF">pdf</a>, <a href="/format/2308.11818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Nonlocal Traffic Flow Model in Physics-informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+A+J">Archie J. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Animesh Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shaurya Agarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This research contributes to the advancement of traffic state estimation
methods by leveraging the benefits of the nonlocal LWR model within a
physics-informed deep learning framework. The classical LWR model, while
useful, falls short of accurately representing real-world traffic flows. The
nonlocal LWR model addresses this limitation by considering the speed as a
weighted mean of the downstream traffic density. In this paper, we propose a
novel PIDL framework that incorporates the nonlocal LWR model. We introduce
both fixed-length and variable-length kernels and develop the required
mathematics. The proposed PIDL framework undergoes a comprehensive evaluation,
including various convolutional kernels and look-ahead windows, using data from
the NGSIM and CitySim datasets. The results demonstrate improvements over the
baseline PIDL approach using the local LWR model. The findings highlight the
potential of the proposed approach to enhance the accuracy and reliability of
traffic state estimation, enabling more effective traffic management
strategies.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11819" title="Abstract">arXiv:2308.11819</a> [<a href="/pdf/2308.11819" title="Download PDF">pdf</a>, <a href="/format/2308.11819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Health Disparity on Biased Electronic Health Records via  Deconfounder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Philip Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The fairness issue of clinical data modeling, especially on Electronic Health
Records (EHRs), is of utmost importance due to EHR's complex latent structure
and potential selection bias. It is frequently necessary to mitigate health
disparity while keeping the model's overall accuracy in practice. However,
traditional methods often encounter the trade-off between accuracy and
fairness, as they fail to capture the underlying factors beyond observed data.
To tackle this challenge, we propose a novel model called Fair Longitudinal
Medical Deconfounder (FLMD) that aims to achieve both fairness and accuracy in
longitudinal Electronic Health Records (EHR) modeling. Drawing inspiration from
the deconfounder theory, FLMD employs a two-stage training process. In the
first stage, FLMD captures unobserved confounders for each encounter, which
effectively represents underlying medical factors beyond observed EHR, such as
patient genotypes and lifestyle habits. This unobserved confounder is crucial
for addressing the accuracy/fairness dilemma. In the second stage, FLMD
combines the learned latent representation with other relevant features to make
predictions. By incorporating appropriate fairness criteria, such as
counterfactual fairness, FLMD ensures that it maintains high prediction
accuracy while simultaneously minimizing health disparities. We conducted
comprehensive experiments on two real-world EHR datasets to demonstrate the
effectiveness of FLMD. Apart from the comparison of baseline methods and FLMD
variants in terms of fairness and accuracy, we assessed the performance of all
models on disturbed/imbalanced and synthetic datasets to showcase the
superiority of FLMD across different settings and provide valuable insights
into its capabilities.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11821" title="Abstract">arXiv:2308.11821</a> [<a href="/pdf/2308.11821" title="Download PDF">pdf</a>, <a href="/format/2308.11821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-temporal decomposition for elastoplastic ratcheting solids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ulloa%2C+J">Jacinto Ulloa</a>, 
<a href="/search/math?searchtype=author&query=Degrande%2C+G">Geert Degrande</a>, 
<a href="/search/math?searchtype=author&query=Andrade%2C+J+E">Jos&#xe9; E. Andrade</a>, 
<a href="/search/math?searchtype=author&query=Fran%C3%A7ois%2C+S">Stijn Fran&#xe7;ois</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">This paper presents a multi-temporal formulation for simulating elastoplastic
solids under cyclic loading. We leverage the proper generalized decomposition
(PGD) to decompose the displacements into multiple time scales, separating the
spatial and intra-cyclic dependence from the inter-cyclic variation. In
contrast with the standard incremental approach, which solves the (non-linear
and computationally intensive) mechanical balance equations at every time step,
the proposed PGD approach allows the mechanical balance equations to be solved
exclusively for the small-time intra-cyclic response, while the large-time
inter-cyclic response is described by simple scalar algebraic equations.
Numerical simulations exhibiting complex cyclic responses, including a 2D
problem and an application to a monopile foundation, demonstrate that PGD
solutions with a limited number of space-time degrees of freedom may be
obtained numerically, only requiring a few modes to accurately capture the
reference response.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11822" title="Abstract">arXiv:2308.11822</a> [<a href="/pdf/2308.11822" title="Download PDF">pdf</a>, <a href="/format/2308.11822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatchBackdoor: Backdoor Attack against Deep Neural Networks without  Model Modification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yizhen Yuan</a> (1), 
<a href="/search/cs?searchtype=author&query=Kong%2C+R">Rui Kong</a> (3), 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shenghao Xie</a> (4), 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a> (1 and 2) ((1) Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China, (2) Shanghai AI Laboratory, Shanghai, China, (3) Shanghai Jiao Tong University, Shanghai, China, (4) Wuhan University, Wuhan, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Backdoor attack is a major threat to deep learning systems in safety-critical
scenarios, which aims to trigger misbehavior of neural network models under
attacker-controlled conditions. However, most backdoor attacks have to modify
the neural network models through training with poisoned data and/or direct
model editing, which leads to a common but false belief that backdoor attack
can be easily avoided by properly protecting the model. In this paper, we show
that backdoor attacks can be achieved without any model modification. Instead
of injecting backdoor logic into the training data or the model, we propose to
place a carefully-designed patch (namely backdoor patch) in front of the
camera, which is fed into the model together with the input images. The patch
can be trained to behave normally at most of the time, while producing wrong
prediction when the input image contains an attacker-controlled trigger object.
Our main techniques include an effective training method to generate the
backdoor patch and a digital-physical transformation modeling method to enhance
the feasibility of the patch in real deployments. Extensive experiments show
that PatchBackdoor can be applied to common deep learning models (VGG,
MobileNet, ResNet) with an attack success rate of 93% to 99% on classification
tasks. Moreover, we implement PatchBackdoor in real-world scenarios and show
that the attack is still threatening.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11825" title="Abstract">arXiv:2308.11825</a> [<a href="/pdf/2308.11825" title="Download PDF">pdf</a>, <a href="/format/2308.11825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accel-GCN: High-Performance GPU Accelerator Design for Graph Convolution  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Amit Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Haowen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+O">Omer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCAD 2023 accepted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Convolutional Networks (GCNs) are pivotal in extracting latent
information from graph data across various domains, yet their acceleration on
mainstream GPUs is challenged by workload imbalance and memory access
irregularity. To address these challenges, we present Accel-GCN, a GPU
accelerator architecture for GCNs. The design of Accel-GCN encompasses: (i) a
lightweight degree sorting stage to group nodes with similar degree; (ii) a
block-level partition strategy that dynamically adjusts warp workload sizes,
enhancing shared memory locality and workload balance, and reducing metadata
overhead compared to designs like GNNAdvisor; (iii) a combined warp strategy
that improves memory coalescing and computational parallelism in the column
dimension of dense matrices.
<br />Utilizing these principles, we formulated a kernel for sparse matrix
multiplication (SpMM) in GCNs that employs block-level partitioning and
combined warp strategy. This approach augments performance and multi-level
memory efficiency and optimizes memory bandwidth by exploiting memory
coalescing and alignment. Evaluation of Accel-GCN across 18 benchmark graphs
reveals that it outperforms cuSPARSE, GNNAdvisor, and graph-BLAST by factors of
1.17 times, 1.86 times, and 2.94 times respectively. The results underscore
Accel-GCN as an effective solution for enhancing GCN computational efficiency.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11827" title="Abstract">arXiv:2308.11827</a> [<a href="/pdf/2308.11827" title="Download PDF">pdf</a>, <a href="/format/2308.11827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study  of the Driver&#x27;s License Knowledge Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+S">Saba Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models such as Open AI's Generative Pre-trained Transformer
(GPT) models are proficient at answering questions, but their knowledge is
confined to the information present in their training data. This limitation
renders them ineffective when confronted with questions about recent
developments or non-public documents. Our research proposes a method that
enables GPT models to answer questions by employing context from an information
source not previously included in their training data. The methodology includes
preprocessing of contextual information, the embedding of contexts and queries,
constructing prompt through the integration of context embeddings, and
generating answers using GPT models. We applied this method in a controlled
test scenario using the California Driver's Handbook as the information source.
The GPT-3 model achieved a 96% passing score on a set of 50 sample driving
knowledge test questions. In contrast, without context, the model's passing
score fell to 82%. However, the model still fails to answer some questions
correctly even with providing library of context, highlighting room for
improvement. The research also examined the impact of prompt length and context
format, on the model's performance. Overall, the study provides insights into
the limitations and potential improvements for GPT models in question-answering
tasks.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11829" title="Abstract">arXiv:2308.11829</a> [<a href="/pdf/2308.11829" title="Download PDF">pdf</a>, <a href="/format/2308.11829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm-assisted discovery of an intrinsic order among mathematical  constants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elimelech%2C+R">Rotem Elimelech</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+O">Ofir David</a>, 
<a href="/search/cs?searchtype=author&query=De+la+Cruz+Mengual%2C+C">Carlos De la Cruz Mengual</a>, 
<a href="/search/cs?searchtype=author&query=Kalisch%2C+R">Rotem Kalisch</a>, 
<a href="/search/cs?searchtype=author&query=Berndt%2C+W">Wolfgang Berndt</a>, 
<a href="/search/cs?searchtype=author&query=Shalyt%2C+M">Michael Shalyt</a>, 
<a href="/search/cs?searchtype=author&query=Silberstein%2C+M">Mark Silberstein</a>, 
<a href="/search/cs?searchtype=author&query=Hadad%2C+Y">Yaron Hadad</a>, 
<a href="/search/cs?searchtype=author&query=Kaminer%2C+I">Ido Kaminer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, and 1 table; with 9 appendix sections totaling 12 pages, 1 figure, and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Number Theory (math.NT)

</div>
<p class="mathjax">In recent decades, a growing number of discoveries in fields of mathematics
have been assisted by computer algorithms, primarily for exploring large
parameter spaces that humans would take too long to investigate. As computers
and algorithms become more powerful, an intriguing possibility arises - the
interplay between human intuition and computer algorithms can lead to
discoveries of novel mathematical concepts that would otherwise remain elusive.
To realize this perspective, we have developed a massively parallel computer
algorithm that discovers an unprecedented number of continued fraction formulas
for fundamental mathematical constants. The sheer number of formulas discovered
by the algorithm unveils a novel mathematical structure that we call the
conservative matrix field. Such matrix fields (1) unify thousands of existing
formulas, (2) generate infinitely many new formulas, and most importantly, (3)
lead to unexpected relations between different mathematical constants,
including multiple integer values of the Riemann zeta function. Conservative
matrix fields also enable new mathematical proofs of irrationality. In
particular, we can use them to generalize the celebrated proof by Ap\'ery for
the irrationality of $\zeta(3)$. Utilizing thousands of personal computers
worldwide, our computer-supported research strategy demonstrates the power of
experimental mathematics, highlighting the prospects of large-scale
computational approaches to tackle longstanding open problems and discover
unexpected connections across diverse fields of science.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11834" title="Abstract">arXiv:2308.11834</a> [<a href="/pdf/2308.11834" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Comparison and Implementation of Bayesian Variants for  Network Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ige%2C+T">Tosin Ige</a>, 
<a href="/search/cs?searchtype=author&query=Kiekintveld%2C+C">Christopher Kiekintveld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Bayesian classifiers perform well when each of the features is completely
independent of the other which is not always valid in real world application.
The aim of this study is to implement and compare the performances of each
variant of Bayesian classifier (Multinomial, Bernoulli, and Gaussian) on
anomaly detection in network intrusion, and to investigate whether there is any
association between each variant assumption and their performance. Our
investigation showed that each variant of Bayesian algorithm blindly follows
its assumption regardless of feature property, and that the assumption is the
single most important factor that influences their accuracy. Experimental
results show that Bernoulli has accuracy of 69.9% test (71% train), Multinomial
has accuracy of 31.2% test (31.2% train), while Gaussian has accuracy of 81.69%
test (82.84% train). Going deeper, we investigated and found that each Naive
Bayes variants performances and accuracy is largely due to each classifier
assumption, Gaussian classifier performed best on anomaly detection due to its
assumption that features follow normal distributions which are continuous,
while multinomial classifier have a dismal performance as it simply assumes
discreet and multinomial distribution.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11838" title="Abstract">arXiv:2308.11838</a> [<a href="/pdf/2308.11838" title="Download PDF">pdf</a>, <a href="/format/2308.11838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark Study on Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Linwei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Younan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haolan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 35 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep neural networks are increasingly utilized in various machine learning
tasks. However, as these models grow in complexity, they often face calibration
issues, despite enhanced prediction accuracy. Many studies have endeavored to
improve calibration performance through data preprocessing, the use of specific
loss functions, and training frameworks. Yet, investigations into calibration
properties have been somewhat overlooked. Our study leverages the Neural
Architecture Search (NAS) search space, offering an exhaustive model
architecture space for thorough calibration properties exploration. We
specifically create a model calibration dataset. This dataset evaluates 90
bin-based and 12 additional calibration measurements across 117,702 unique
neural networks within the widely employed NATS-Bench search space. Our
analysis aims to answer several longstanding questions in the field, using our
proposed dataset: (i) Can model calibration be generalized across different
tasks? (ii) Can robustness be used as a calibration measurement? (iii) How
reliable are calibration metrics? (iv) Does a post-hoc calibration method
affect all models uniformly? (v) How does calibration interact with accuracy?
(vi) What is the impact of bin size on calibration measurement? (vii) Which
architectural designs are beneficial for calibration? Additionally, our study
bridges an existing gap by exploring calibration within NAS. By providing this
dataset, we enable further research into NAS calibration. As far as we are
aware, our research represents the first large-scale investigation into
calibration properties and the premier study of calibration issues within NAS.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11839" title="Abstract">arXiv:2308.11839</a> [<a href="/pdf/2308.11839" title="Download PDF">pdf</a>, <a href="/format/2308.11839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Learning for Dynamic Target Localization with Human-provided  Spatial Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Min-Won Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kia%2C+S+S">Solmaz S. Kia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper considers a human-autonomy collaborative sensor data fusion for
dynamic target localization in a Bayesian framework. To compensate for the
shortcomings of an autonomous tracking system, we propose to collect spatial
sensing information from human operators who visually monitor the target and
can provide target localization information in the form of free sketches
encircling the area where the target is located. Our focus in this paper is to
construct an adaptive probabilistic model for human-provided inputs where the
adaption terms capture the level of reliability of the human inputs. The next
contribution of this paper is a novel joint Bayesian learning method to fuse
human and autonomous sensor inputs in a manner that the dynamic changes in
human detection reliability are also captured and accounted for. A unique
aspect of this Bayesian modeling framework is its analytical closed-form update
equations, endowing our method with significant computational efficiency.
Simulations demonstrate our results.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11840" title="Abstract">arXiv:2308.11840</a> [<a href="/pdf/2308.11840" title="Download PDF">pdf</a>, <a href="/format/2308.11840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressed Models Decompress Race Biases: What Quantized Models Forget  for Fair Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neto%2C+P+C">Pedro C. Neto</a>, 
<a href="/search/cs?searchtype=author&query=Caldeira%2C+E">Eduarda Caldeira</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J+S">Jaime S. Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Sequeira%2C+A+F">Ana F. Sequeira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Oral at BIOSIG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the ever-growing complexity of deep learning models for face
recognition, it becomes hard to deploy these systems in real life. Researchers
have two options: 1) use smaller models; 2) compress their current models.
Since the usage of smaller models might lead to concerning biases, compression
gains relevance. However, compressing might be also responsible for an increase
in the bias of the final model. We investigate the overall performance, the
performance on each ethnicity subgroup and the racial bias of a
State-of-the-Art quantization approach when used with synthetic and real data.
This analysis provides a few more details on potential benefits of performing
quantization with synthetic data, for instance, the reduction of biases on the
majority of test scenarios. We tested five distinct architectures and three
different training datasets. The models were evaluated on a fourth dataset
which was collected to infer and compare the performance of face recognition
models on different ethnicity.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11841" title="Abstract">arXiv:2308.11841</a> [<a href="/pdf/2308.11841" title="Download PDF">pdf</a>, <a href="/format/2308.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey for Federated Learning Evaluations: Goals and Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+D">Di Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Evaluation is a systematic approach to assessing how well a system achieves
its intended purpose. Federated learning (FL) is a novel paradigm for
privacy-preserving machine learning that allows multiple parties to
collaboratively train models without sharing sensitive data. However,
evaluating FL is challenging due to its interdisciplinary nature and diverse
goals, such as utility, efficiency, and security. In this survey, we first
review the major evaluation goals adopted in the existing studies and then
explore the evaluation metrics used for each goal. We also introduce FedEval,
an open-source platform that provides a standardized and comprehensive
evaluation framework for FL algorithms in terms of their utility, efficiency,
and security. Finally, we discuss several challenges and future research
directions for FL evaluation.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11842" title="Abstract">arXiv:2308.11842</a> [<a href="/pdf/2308.11842" title="Download PDF">pdf</a>, <a href="/format/2308.11842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ${\rm E}(3)$-Equivariant Actor-Critic Methods for Cooperative  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dingyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Identification and analysis of symmetrical patterns in the natural world have
led to significant discoveries across various scientific fields, such as the
formulation of gravitational laws in physics and advancements in the study of
chemical structures. In this paper, we focus on exploiting Euclidean symmetries
inherent in certain cooperative multi-agent reinforcement learning (MARL)
problems and prevalent in many applications. We begin by formally
characterizing a subclass of Markov games with a general notion of symmetries
that admits the existence of symmetric optimal values and policies. Motivated
by these properties, we design neural network architectures with symmetric
constraints embedded as an inductive bias for multi-agent actor-critic methods.
This inductive bias results in superior performance in various cooperative MARL
benchmarks and impressive generalization capabilities such as zero-shot
learning and transfer learning in unseen scenarios with repeated symmetric
patterns. The code is available at: https://github.com/dchen48/E3AC.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11845" title="Abstract">arXiv:2308.11845</a> [<a href="/pdf/2308.11845" title="Download PDF">pdf</a>, <a href="/format/2308.11845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEA: Shareable and Explainable Attribution for Query-based Black-box  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+K">Kassem Fawaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine Learning (ML) systems are vulnerable to adversarial examples,
particularly those from query-based black-box attacks. Despite various efforts
to detect and prevent such attacks, there is a need for a more comprehensive
approach to logging, analyzing, and sharing evidence of attacks. While classic
security benefits from well-established forensics and intelligence sharing,
Machine Learning is yet to find a way to profile its attackers and share
information about them. In response, this paper introduces SEA, a novel ML
security system to characterize black-box attacks on ML systems for forensic
purposes and to facilitate human-explainable intelligence sharing. SEA
leverages the Hidden Markov Models framework to attribute the observed query
sequence to known attacks. It thus understands the attack's progression rather
than just focusing on the final adversarial examples. Our evaluations reveal
that SEA is effective at attack attribution, even on their second occurrence,
and is robust to adaptive strategies designed to evade forensics analysis.
Interestingly, SEA's explanations of the attack behavior allow us even to
fingerprint specific minor implementation bugs in attack libraries. For
example, we discover that the SignOPT and Square attacks implementation in ART
v1.14 sends over 50% specific zero difference queries. We thoroughly evaluate
SEA on a variety of settings and demonstrate that it can recognize the same
attack's second occurrence with 90+% Top-1 and 95+% Top-3 accuracy.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11849" title="Abstract">arXiv:2308.11849</a> [<a href="/pdf/2308.11849" title="Download PDF">pdf</a>, <a href="/format/2308.11849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep reinforcement learning approach for real-time demand-responsive  railway rescheduling to mitigate station overcrowding using mobile data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+E">Enze Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Zhiyuan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J+Y+T">Judith Y.T. Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages,16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-time railway rescheduling is a timely and flexible technique to
automatically alter the operation schedule in response to time-varying
conditions. Current research lacks data-driven approaches that capture
real-time passenger mobility during railway disruptions, relying mostly on
OD-based data and model-based methods for estimating demands of trains.
Meanwhile, the schedule-updating principles for a long-term disruption overlook
the uneven distribution of demand over time. To fill this gap, this paper
proposes a demand-responsive approach by inferring real-world passenger
mobility from mobile data (MD) to facilitate real-time rescheduling. Unlike
network-level approaches, this paper focuses on a heavy-demand station upstream
of the disrupted area. The objective is to reschedule all trains on multiple
routes passing through this target station, which have been affected by a
severe emergency event such as a natural disaster. Particular attention should
be given to avoiding the accumulation of overcrowded passengers at this
station, to prevent additional accidents arising from overcrowding. This
research addresses the challenges associated with this scenario, including the
dynamics of arriving and leaving of passengers, station overcrowding, rolling
stock shortage, open-ended disruption duration, integrated rescheduling on
multiple routes, and delays due to detours. A deep reinforcement learning (DRL)
framework is proposed to determine the optimal rescheduled timetable, route
stops, and rolling stock allocation, while considering real-time demand
satisfaction, station overcrowding, train capacity utilization, and headway
safety.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11854" title="Abstract">arXiv:2308.11854</a> [<a href="/pdf/2308.11854" title="Download PDF">pdf</a>, <a href="/format/2308.11854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding the Perfect Fit: Applying Regression Models to ClimateBench v1.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaure%2C+A">Anmol Chaure</a>, 
<a href="/search/cs?searchtype=author&query=Behera%2C+A+K">Ashok Kumar Behera</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sudip Bhattacharya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Applications 185(29):31-39,
  August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Climate projections using data driven machine learning models acting as
emulators, is one of the prevailing areas of research to enable policy makers
make informed decisions. Use of machine learning emulators as surrogates for
computationally heavy GCM simulators reduces time and carbon footprints. In
this direction, ClimateBench [1] is a recently curated benchmarking dataset for
evaluating the performance of machine learning emulators designed for climate
data. Recent studies have reported that despite being considered fundamental,
regression models offer several advantages pertaining to climate emulations. In
particular, by leveraging the kernel trick, regression models can capture
complex relationships and improve their predictive capabilities. This study
focuses on evaluating non-linear regression models using the aforementioned
dataset. Specifically, we compare the emulation capabilities of three
non-linear regression models. Among them, Gaussian Process Regressor
demonstrates the best-in-class performance against standard evaluation metrics
used for climate field emulation studies. However, Gaussian Process Regression
suffers from being computational resource hungry in terms of space and time
complexity. Alternatively, Support Vector and Kernel Ridge models also deliver
competitive results and but there are certain trade-offs to be addressed.
Additionally, we are actively investigating the performance of composite
kernels and techniques such as variational inference to further enhance the
performance of the regression models and effectively model complex non-linear
patterns, including phenomena like precipitation.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11857" title="Abstract">arXiv:2308.11857</a> [<a href="/pdf/2308.11857" title="Download PDF">pdf</a>, <a href="/format/2308.11857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoC-GAN: Employing Context Cluster for Unveiling a New Pathway in Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziyu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image generation tasks are traditionally undertaken using Convolutional
Neural Networks (CNN) or Transformer architectures for feature aggregating and
dispatching. Despite the frequent application of convolution and attention
structures, these structures are not fundamentally required to solve the
problem of instability and the lack of interpretability in image generation. In
this paper, we propose a unique image generation process premised on the
perspective of converting images into a set of point clouds. In other words, we
interpret an image as a set of points. As such, our methodology leverages
simple clustering methods named Context Clustering (CoC) to generate images
from unordered point sets, which defies the convention of using convolution or
attention mechanisms. Hence, we exclusively depend on this clustering
technique, combined with the multi-layer perceptron (MLP) in a generative
model. Furthermore, we implement the integration of a module termed the 'Point
Increaser' for the model. This module is just an MLP tasked with generating
additional points for clustering, which are subsequently integrated within the
paradigm of the Generative Adversarial Network (GAN). We introduce this model
with the novel structure as the Context Clustering Generative Adversarial
Network (CoC-GAN), which offers a distinctive viewpoint in the domain of
feature aggregating and dispatching. Empirical evaluations affirm that our
CoC-GAN, devoid of convolution and attention mechanisms, exhibits outstanding
performance. Its interpretability, endowed by the CoC module, also allows for
visualization in our experiments. The promising results underscore the
feasibility of our method and thus warrant future investigations of applying
Context Clustering to more novel and interpretable image generation.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11862" title="Abstract">arXiv:2308.11862</a> [<a href="/pdf/2308.11862" title="Download PDF">pdf</a>, <a href="/format/2308.11862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Analysis of Software Vulnerabilities Causing Timing Side  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kholoosi%2C+M+M">M. Mehdi Kholoosi</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+M+A">M. Ali Babar</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+C">Cemal Yilmaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Timing attacks are considered one of the most damaging side-channel attacks.
These attacks exploit timing fluctuations caused by certain operations to
disclose confidential information to an attacker. For instance, in asymmetric
encryption, operations such as multiplication and division can cause
time-varying execution times that can be ill-treated to obtain an encryption
key. Whilst several efforts have been devoted to exploring the various aspects
of timing attacks, particularly in cryptography, little attention has been paid
to empirically studying the timing attack-related vulnerabilities in
non-cryptographic software. By inspecting these software vulnerabilities, this
study aims to gain an evidence-based understanding of weaknesses in
non-cryptographic software that may help timing attacks succeed. We used
qualitative and quantitative research approaches to systematically study the
timing attack-related vulnerabilities reported in the National Vulnerability
Database (NVD) from March 2003 to December 2022. Our analysis was focused on
the modifications made to the code for patching the identified vulnerabilities.
We found that a majority of the timing attack-related vulnerabilities were
introduced due to not following known secure coding practices. The findings of
this study are expected to help the software security community gain
evidence-based information about the nature and causes of the vulnerabilities
related to timing attacks.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11870" title="Abstract">arXiv:2308.11870</a> [<a href="/pdf/2308.11870" title="Download PDF">pdf</a>, <a href="/format/2308.11870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-object Detection, Tracking and Prediction in Rugged Dynamic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Junyuan Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 8 figures, submitted to ROBIO2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-object tracking (MOT) has important applications in monitoring,
logistics, and other fields. This paper develops a real-time multi-object
tracking and prediction system in rugged environments. A 3D object detection
algorithm based on Lidar-camera fusion is designed to detect the target
objects. Based on the Hungarian algorithm, this paper designs a 3D multi-object
tracking algorithm with an adaptive threshold to realize the stable matching
and tracking of the objects. We combine Memory Augmented Neural Networks (MANN)
and Kalman filter to achieve 3D trajectory prediction on rugged terrains.
Besides, we realize a new dynamic SLAM by using the results of multi-object
tracking to remove dynamic points for better SLAM performance and static map.
To verify the effectiveness of the proposed multi-object tracking and
prediction system, several simulations and physical experiments are conducted.
The results show that the proposed system can track dynamic objects and provide
future trajectory and a more clean static map in real-time.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11873" title="Abstract">arXiv:2308.11873</a> [<a href="/pdf/2308.11873" title="Download PDF">pdf</a>, <a href="/format/2308.11873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Large Language Models into the Debugging C Compiler for  generating contextual error explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taylor%2C+A">Andrew Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Vassar%2C+A">Alexandra Vassar</a>, 
<a href="/search/cs?searchtype=author&query=Renzella%2C+J">Jake Renzella</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+H">Hammond Pearce</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">This paper introduces a method for Large Language Models (LLM) to produce
enhanced compiler error explanations, in simple language, within our Debugging
C Compiler (DCC). It is well documented that compiler error messages have been
known to present a barrier for novices learning how to program. Although our
initial use of DCC in introductory programming (CS1) has been instrumental in
teaching C to novice programmers by providing safeguards to commonly occurring
errors and translating the usually cryptic compiler error messages at both
compile- and run-time, we proposed that incorporating LLM-generated
explanations would further enhance the learning experience for novice
programmers. Through an expert evaluation, we observed that LLM-generated
explanations for compiler errors were conceptually accurate in 90% of
compile-time errors, and 75% of run-time errors. Additionally, the new DCC-help
tool has been increasingly adopted by students, with an average of 1047 unique
runs per week, demonstrating a promising initial assessment of using LLMs to
complement compiler output to enhance programming education for beginners. We
release our tool as open-source to the community.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11874" title="Abstract">arXiv:2308.11874</a> [<a href="/pdf/2308.11874" title="Download PDF">pdf</a>, <a href="/format/2308.11874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Learning via Weight-aware Distillation under Class  Distribution Mismatch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Pan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Suyun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Z">Zisen Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cuiping Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-Supervised Learning (SSL) under class distribution mismatch aims to
tackle a challenging problem wherein unlabeled data contain lots of unknown
categories unseen in the labeled ones. In such mismatch scenarios, traditional
SSL suffers severe performance damage due to the harmful invasion of the
instances with unknown categories into the target classifier. In this study, by
strict mathematical reasoning, we reveal that the SSL error under class
distribution mismatch is composed of pseudo-labeling error and invasion error,
both of which jointly bound the SSL population risk. To alleviate the SSL
error, we propose a robust SSL framework called Weight-Aware Distillation (WAD)
that, by weights, selectively transfers knowledge beneficial to the target task
from unsupervised contrastive representation to the target classifier.
Specifically, WAD captures adaptive weights and high-quality pseudo labels to
target instances by exploring point mutual information (PMI) in representation
space to maximize the role of unlabeled data and filter unknown categories.
Theoretically, we prove that WAD has a tight upper bound of population risk
under class distribution mismatch. Experimentally, extensive results
demonstrate that WAD outperforms five state-of-the-art SSL approaches and one
standard baseline on two benchmark datasets, CIFAR10 and CIFAR100, and an
artificial cross-dataset. The code is available at
https://github.com/RUC-DWBI-ML/research/tree/main/WAD-master.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11875" title="Abstract">arXiv:2308.11875</a> [<a href="/pdf/2308.11875" title="Download PDF">pdf</a>, <a href="/format/2308.11875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-to-Matching: A Mixed Paradigm for 3D Single Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yubo Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D single object tracking with LiDAR points is an important task in the
computer vision field. Previous methods usually adopt the matching-based or
motion-centric paradigms to estimate the current target status. However, the
former is sensitive to the similar distractors and the sparseness of point
cloud due to relying on appearance matching, while the latter usually focuses
on short-term motion clues (eg. two frames) and ignores the long-term motion
pattern of target. To address these issues, we propose a mixed paradigm with
two stages, named MTM-Tracker, which combines motion modeling with feature
matching into a single network. Specifically, in the first stage, we exploit
the continuous historical boxes as motion prior and propose an encoder-decoder
structure to locate target coarsely. Then, in the second stage, we introduce a
feature interaction module to extract motion-aware features from consecutive
point clouds and match them to refine target movement as well as regress other
target states. Extensive experiments validate that our paradigm achieves
competitive performance on large-scale datasets (70.9% in KITTI and 51.70% in
NuScenes). The code will be open soon at
https://github.com/LeoZhiheng/MTM-Tracker.git.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11877" title="Abstract">arXiv:2308.11877</a> [<a href="/pdf/2308.11877" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Image and Location Analysis for Wound Classification: A Deep  Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+Y">Yash Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+T">Tirth Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dhar%2C+M+K">Mrinal Kanti Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niezgoda%2C+J">Jeffrey Niezgoda</a>, 
<a href="/search/cs?searchtype=author&query=Gopalkrishnan%2C+S">Sandeep Gopalkrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zeyun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The global burden of acute and chronic wounds presents a compelling case for
enhancing wound classification methods, a vital step in diagnosing and
determining optimal treatments. Recognizing this need, we introduce an
innovative multi-modal network based on a deep convolutional neural network for
categorizing wounds into four categories: diabetic, pressure, surgical, and
venous ulcers. Our multi-modal network uses wound images and their
corresponding body locations for more precise classification. A unique aspect
of our methodology is incorporating a body map system that facilitates accurate
wound location tagging, improving upon traditional wound image classification
techniques. A distinctive feature of our approach is the integration of models
such as VGG16, ResNet152, and EfficientNet within a novel architecture. This
architecture includes elements like spatial and channel-wise
Squeeze-and-Excitation modules, Axial Attention, and an Adaptive Gated
Multi-Layer Perceptron, providing a robust foundation for classification. Our
multi-modal network was trained and evaluated on two distinct datasets
comprising relevant images and corresponding location information. Notably, our
proposed network outperformed traditional methods, reaching an accuracy range
of 74.79% to 100% for Region of Interest (ROI) without location
classifications, 73.98% to 100% for ROI with location classifications, and
78.10% to 100% for whole image classifications. This marks a significant
enhancement over previously reported performance metrics in the literature. Our
results indicate the potential of our multi-modal network as an effective
decision-support tool for wound image classification, paving the way for its
application in various clinical contexts.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11878" title="Abstract">arXiv:2308.11878</a> [<a href="/pdf/2308.11878" title="Download PDF">pdf</a>, <a href="/format/2308.11878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cabrita: closing the gap for foreign languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Larcher%2C+C">Celio Larcher</a>, 
<a href="/search/cs?searchtype=author&query=Piau%2C+M">Marcos Piau</a>, 
<a href="/search/cs?searchtype=author&query=Finardi%2C+P">Paulo Finardi</a>, 
<a href="/search/cs?searchtype=author&query=Gengo%2C+P">Pedro Gengo</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+P">Piero Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Carid%C3%A1%2C+V">Vinicius Carid&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The strategy of training the model from scratch in a specific language or
domain serves two essential purposes: i) enhancing performance in the
particular linguistic or domain context, and ii) ensuring effective
tokenization. The main limitation inherent to this approach lies in the
associated cost, which can reach six to seven-digit dollar values, depending on
the model size and the number of parameters involved.
<br />The main solution to overcome the cost challenge is to rely on available
pre-trained models, which, despite recent advancements such as the LLaMA and
LLaMA-2 models, still demonstrate inefficiency for certain specific domain
problems or prove ineffective in scenarios involving conversational memory
resources, given the large number of tokens required to represent text.
<br />To overcome this issue, we present a methodology named Cabrita, which, as our
research demonstrates, successfully addresses the performance and efficient
tokenization problem, all at an affordable cost. We believe that this
methodology can be applied to any transformer-like architecture model. To
validate the study, we conducted continuous pre-training exclusively using
Portuguese text on a 3-billion-parameter model known as OpenLLaMA, resulting in
a model named openCabrita 3B. The openCabrita 3B also features a new tokenizer
that results in a significant reduction in the number of tokens required to
represent the text. In our assessment, for few-shot learning tasks, we achieved
similar results with this 3B model compared to a traditional continuous
pre-training approach as well as to 7B models English pre-trained models.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11880" title="Abstract">arXiv:2308.11880</a> [<a href="/pdf/2308.11880" title="Download PDF">pdf</a>, <a href="/format/2308.11880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal  Targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simons%2C+C">Cody Simons</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+D+S">Dripta S. Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+M">Sk Miraj Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Suya You</a>, 
<a href="/search/cs?searchtype=author&query=Karydis%2C+K">Konstantinos Karydis</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 9 tables, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Scene understanding using multi-modal data is necessary in many applications,
e.g., autonomous navigation. To achieve this in a variety of situations,
existing models must be able to adapt to shifting data distributions without
arduous data annotation. Current approaches assume that the source data is
available during adaptation and that the source consists of paired multi-modal
data. Both these assumptions may be problematic for many applications. Source
data may not be available due to privacy, security, or economic concerns.
Assuming the existence of paired multi-modal data for training also entails
significant data collection costs and fails to take advantage of widely
available freely distributed pre-trained uni-modal models. In this work, we
relax both of these assumptions by addressing the problem of adapting a set of
models trained independently on uni-modal data to a target domain consisting of
unlabeled multi-modal data, without having access to the original source
dataset. Our proposed approach solves this problem through a switching
framework which automatically chooses between two complementary methods of
cross-modal pseudo-label fusion -- agreement filtering and entropy weighting --
based on the estimated domain gap. We demonstrate our work on the semantic
segmentation problem. Experiments across seven challenging adaptation scenarios
verify the efficacy of our approach, achieving results comparable to, and in
some cases outperforming, methods which assume access to source data. Our
method achieves an improvement in mIoU of up to 12% over competing baselines.
Our code is publicly available at https://github.com/csimo005/SUMMIT.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11881" title="Abstract">arXiv:2308.11881</a> [<a href="/pdf/2308.11881" title="Download PDF">pdf</a>, <a href="/format/2308.11881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Training Using Feedback Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rafid%2C+A+H+M">Ali Haisam Muhammad Rafid</a>, 
<a href="/search/cs?searchtype=author&query=Sandu%2C+A">Adrian Sandu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks (DNN) have found wide applicability in numerous fields
due to their ability to accurately learn very complex input-output relations.
Despite their accuracy and extensive use, DNNs are highly susceptible to
adversarial attacks due to limited generalizability. For future progress in the
field, it is essential to build DNNs that are robust to any kind of
perturbations to the data points. In the past, many techniques have been
proposed to robustify DNNs using first-order derivative information of the
network.
<br />This paper proposes a new robustification approach based on control theory. A
neural network architecture that incorporates feedback control, named Feedback
Neural Networks, is proposed. The controller is itself a neural network, which
is trained using regular and adversarial data such as to stabilize the system
outputs. The novel adversarial training approach based on the feedback control
architecture is called Feedback Looped Adversarial Training (FLAT). Numerical
results on standard test problems empirically show that our FLAT method is more
effective than the state-of-the-art to guard against adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11882" title="Abstract">arXiv:2308.11882</a> [<a href="/pdf/2308.11882" title="Download PDF">pdf</a>, <a href="/format/2308.11882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The macroscopic finite-difference scheme and modified equations of the  general propagation multiple-relaxation-time lattice Boltzmann model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+Z">Zhenhua Chai</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Baochang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this paper, we first present the general propagation
multiple-relaxation-time lattice Boltzmann (GPMRT-LB) model and obtain the
corresponding macroscopic finite-difference (GPMFD) scheme on conservative
moments. Then based on the Maxwell iteration method, we conduct the analysis on
the truncation errors and modified equations (MEs) of the GPMRT-LB model and
GPMFD scheme at both diffusive and acoustic scalings. For the nonlinear
anisotropic convection-diffusion equation (NACDE) and Navier-Stokes equations
(NSEs), we also derive the first- and second-order MEs of the GPMRT-LB model
and GPMFD scheme. In particular, for the one-dimensional convection-diffusion
equation (CDE) with the constant velocity and diffusion coefficient, we can
develop a fourth-order GPMRT-LB (F-GPMRT-LB) model and the corresponding
fourth-order GPMFD (F-GPMFD) scheme at the diffusive scaling. Finally, two
benchmark problems, Gauss hill problem and Poiseuille flow in two-dimensional
space, are used to test the GPMRT-LB model and GPMFD scheme, and it is found
that the numerical results are not only in good agreement with corresponding
analytical solutions, but also have a second-order convergence rate in space.
Additionally, a numerical study on one-dimensional CDE also demonstrates that
the F-GPMRT-LB model and F-GPMFD scheme can achieve a fourth-order accuracy in
space, which is consistent with our theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11884" title="Abstract">arXiv:2308.11884</a> [<a href="/pdf/2308.11884" title="Download PDF">pdf</a>, <a href="/ps/2308.11884" title="Download PostScript">ps</a>, <a href="/format/2308.11884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating the Wikidata Taxonomy into YAGO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suchanek%2C+F">Fabian Suchanek</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M">Mehwish Alam</a>, 
<a href="/search/cs?searchtype=author&query=Bonald%2C+T">Thomas Bonald</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+P">Pierre-Henri Paris</a>, 
<a href="/search/cs?searchtype=author&query=Soria%2C+J">Jules Soria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Wikidata is one of the largest public general-purpose Knowledge Bases (KBs).
Yet, due to its collaborative nature, its schema and taxonomy have become
convoluted. For the YAGO 4 KB, we combined Wikidata with the ontology from
Schema.org, which reduced and cleaned up the taxonomy and constraints and made
it possible to run automated reasoners on the data. However, it also cut away
large parts of the Wikidata taxonomy. In this paper, we present our effort to
merge the entire Wikidata taxonomy into the YAGO KB as much as possible. We pay
particular attention to logical constraints and a careful distinction of
classes and instances. Our work creates YAGO 4.5, which adds a rich layer of
informative classes to YAGO, while at the same time keeping the KB logically
consistent.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11887" title="Abstract">arXiv:2308.11887</a> [<a href="/pdf/2308.11887" title="Download PDF">pdf</a>, <a href="/format/2308.11887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for 3D Point Cloud Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haojia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yongdong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+F">Fei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Taisong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Donghao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liujuan Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D point cloud visual grounding plays a critical role in 3D scene
comprehension, encompassing 3D referring expression comprehension (3DREC) and
segmentation (3DRES). We argue that 3DREC and 3DRES should be unified in one
framework, which is also a natural progression in the community. To explain,
3DREC can help 3DRES locate the referent, while 3DRES can also facilitate 3DREC
via more finegrained language-visual alignment. To achieve this, this paper
takes the initiative step to integrate 3DREC and 3DRES into a unified
framework, termed 3D Referring Transformer (3DRefTR). Its key idea is to build
upon a mature 3DREC model and leverage ready query embeddings and visual tokens
from the 3DREC model to construct a dedicated mask branch. Specially, we
propose Superpoint Mask Branch, which serves a dual purpose: i) By leveraging
the heterogeneous CPU-GPU parallelism, while the GPU is occupied generating
visual tokens, the CPU concurrently produces superpoints, equivalently
accomplishing the upsampling computation; ii) By harnessing on the inherent
association between the superpoints and point cloud, it eliminates the heavy
computational overhead on the high-resolution visual features for upsampling.
This elegant design enables 3DRefTR to achieve both well-performing 3DRES and
3DREC capacities with only a 6% additional latency compared to the original
3DREC model. Empirical evaluations affirm the superiority of 3DRefTR.
Specifically, on the ScanRefer dataset, 3DRefTR surpasses the state-of-the-art
3DRES method by 12.43% in mIoU and improves upon the SOTA 3DREC method by 0.6%
Acc@0.25IoU.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11890" title="Abstract">arXiv:2308.11890</a> [<a href="/pdf/2308.11890" title="Download PDF">pdf</a>, <a href="/format/2308.11890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-conditioned 3D Molecule Generation via Equivariant Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Parthasarathy%2C+S">Srinivasan Parthasarathy</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xia Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Ligand-based drug design aims to identify novel drug candidates of similar
shapes with known active molecules. In this paper, we formulated an in silico
shape-conditioned molecule generation problem to generate 3D molecule
structures conditioned on the shape of a given molecule. To address this
problem, we developed a translation- and rotation-equivariant shape-guided
generative model ShapeMol. ShapeMol consists of an equivariant shape encoder
that maps molecular surface shapes into latent embeddings, and an equivariant
diffusion model that generates 3D molecules based on these embeddings.
Experimental results show that ShapeMol can generate novel, diverse, drug-like
molecules that retain 3D molecular shapes similar to the given shape condition.
These results demonstrate the potential of ShapeMol in designing drug
candidates of desired 3D shapes binding to protein target pockets.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11891" title="Abstract">arXiv:2308.11891</a> [<a href="/pdf/2308.11891" title="Download PDF">pdf</a>, <a href="/format/2308.11891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap: Deciphering Tabular Data Using Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+P">Peng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zongcheng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of natural language processing, the understanding of tabular
data has perpetually stood as a focal point of scholarly inquiry. The emergence
of expansive language models, exemplified by the likes of ChatGPT, has ushered
in a wave of endeavors wherein researchers aim to harness these models for
tasks related to table-based question answering. Central to our investigative
pursuits is the elucidation of methodologies that amplify the aptitude of such
large language models in discerning both the structural intricacies and
inherent content of tables, ultimately facilitating their capacity to provide
informed responses to pertinent queries. To this end, we have architected a
distinctive module dedicated to the serialization of tables for seamless
integration with expansive language models. Additionally, we've instituted a
corrective mechanism within the model to rectify potential inaccuracies.
Experimental results indicate that, although our proposed method trails the
SOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about
1.2% in tests on specific datasets. This research marks the first application
of large language models to table-based question answering tasks, enhancing the
model's comprehension of both table structures and content.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11894" title="Abstract">arXiv:2308.11894</a> [<a href="/pdf/2308.11894" title="Download PDF">pdf</a>, <a href="/format/2308.11894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Physical Adversarial Example Really Matter to Autonomous Driving?  Towards System-Level Effect of Adversarial Object Evasion Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunpeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+T">Takami Sato</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+A">Qi Alfred Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In autonomous driving (AD), accurate perception is indispensable to achieving
safe and secure driving. Due to its safety-criticality, the security of AD
perception has been widely studied. Among different attacks on AD perception,
the physical adversarial object evasion attacks are especially severe. However,
we find that all existing literature only evaluates their attack effect at the
targeted AI component level but not at the system level, i.e., with the entire
system semantics and context such as the full AD pipeline. Thereby, this raises
a critical research question: can these existing researches effectively achieve
system-level attack effects (e.g., traffic rule violations) in the real-world
AD context? In this work, we conduct the first measurement study on whether and
how effectively the existing designs can lead to system-level effects,
especially for the STOP sign-evasion attacks due to their popularity and
severity. Our evaluation results show that all the representative prior works
cannot achieve any system-level effects. We observe two design limitations in
the prior works: 1) physical model-inconsistent object size distribution in
pixel sampling and 2) lack of vehicle plant model and AD system model
consideration. Then, we propose SysAdv, a novel system-driven attack design in
the AD context and our evaluation results show that the system-level effects
can be significantly improved, i.e., the violation rate increases by around
70%.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11896" title="Abstract">arXiv:2308.11896</a> [<a href="/pdf/2308.11896" title="Download PDF">pdf</a>, <a href="/format/2308.11896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age Prediction From Face Images Via Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chae%2C+Y">Yeongnam Chae</a>, 
<a href="/search/cs?searchtype=author&query=Raha%2C+P">Poulami Raha</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mijung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Stenger%2C+B">Bjorn Stenger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MVA2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel approach for accurately estimating age from face
images, which overcomes the challenge of collecting a large dataset of
individuals with the same identity at different ages. Instead, we leverage
readily available face datasets of different people at different ages and aim
to extract age-related features using contrastive learning. Our method
emphasizes these relevant features while suppressing identity-related features
using a combination of cosine similarity and triplet margin losses. We
demonstrate the effectiveness of our proposed approach by achieving
state-of-the-art performance on two public datasets, FG-NET and MORPH-II.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11897" title="Abstract">arXiv:2308.11897</a> [<a href="/pdf/2308.11897" title="Download PDF">pdf</a>, <a href="/format/2308.11897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tau Prolog: A Prolog interpreter for the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valverde%2C+J+A+R">Jos&#xe9; Antonio Riaza Valverde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures, under consideration in Theory and Practice of Logic Programming (TPLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Tau Prolog is a client-side Prolog interpreter fully implemented in
JavaScript, which aims at implementing the ISO Prolog Standard. Tau Prolog has
been developed to be used with either Node.js or a browser seamlessly, and
therefore, it has been developed following a non-blocking, callback-based
approach to avoid blocking web browsers. Taking the best from JavaScript and
Prolog, Tau Prolog allows the programmer to handle browser events and
manipulate the Document Object Model (DOM) of a web using Prolog predicates. In
this paper we describe the architecture of Tau Prolog and its main packages for
interacting with the Web, and we present its programming environment. Under
consideration in Theory and Practice of Logic Programming (TPLP).
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11898" title="Abstract">arXiv:2308.11898</a> [<a href="/pdf/2308.11898" title="Download PDF">pdf</a>, <a href="/format/2308.11898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Optimization Objective of One-Class Classification for  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Han Gao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Huiyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Fei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengtao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 paegs, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One-class classification (OCC) is a longstanding method for anomaly
detection. With the powerful representation capability of the pre-trained
backbone, OCC methods have witnessed significant performance improvements.
Typically, most of these OCC methods employ transfer learning to enhance the
discriminative nature of the pre-trained backbone's features, thus achieving
remarkable efficacy. While most current approaches emphasize feature transfer
strategies, we argue that the optimization objective space within OCC methods
could also be an underlying critical factor influencing performance. In this
work, we conducted a thorough investigation into the optimization objective of
OCC. Through rigorous theoretical analysis and derivation, we unveil a key
insights: any space with the suitable norm can serve as an equivalent
substitute for the hypersphere center, without relying on the distribution
assumption of training samples. Further, we provide guidelines for determining
the feasible domain of norms for the OCC optimization objective. This novel
insight sparks a simple and data-agnostic deep one-class classification method.
Our method is straightforward, with a single 1x1 convolutional layer as a
trainable projector and any space with suitable norm as the optimization
objective. Extensive experiments validate the reliability and efficacy of our
findings and the corresponding methodology, resulting in state-of-the-art
performance in both one-class classification and industrial vision anomaly
detection and segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11900" title="Abstract">arXiv:2308.11900</a> [<a href="/pdf/2308.11900" title="Download PDF">pdf</a>, <a href="/format/2308.11900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HashReID: Dynamic Network with Binary Codes for Efficient Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikhal%2C+K">Kshitij Nikhal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yujunrong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+S+S">Shuvra S. Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Riggan%2C+B+S">Benjamin S. Riggan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Biometric applications, such as person re-identification (ReID), are often
deployed on energy constrained devices. While recent ReID methods prioritize
high retrieval performance, they often come with large computational costs and
high search time, rendering them less practical in real-world settings. In this
work, we propose an input-adaptive network with multiple exit blocks, that can
terminate computation early if the retrieval is straightforward or noisy,
saving a lot of computation. To assess the complexity of the input, we
introduce a temporal-based classifier driven by a new training strategy.
Furthermore, we adopt a binary hash code generation approach instead of relying
on continuous-valued features, which significantly improves the search process
by a factor of 20. To ensure similarity preservation, we utilize a new ranking
regularizer that bridges the gap between continuous and binary features.
Extensive analysis of our proposed method is conducted on three datasets:
Market1501, MSMT17 (Multi-Scene Multi-Time), and the BGC1 (BRIAR Government
Collection). Using our approach, more than 70% of the samples with compact hash
codes exit early on the Market1501 dataset, saving 80% of the networks
computational cost and improving over other hash-based methods by 60%. These
results demonstrate a significant improvement over dynamic networks and
showcase comparable accuracy performance to conventional ReID methods. Code
will be made available.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11901" title="Abstract">arXiv:2308.11901</a> [<a href="/pdf/2308.11901" title="Download PDF">pdf</a>, <a href="/format/2308.11901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera-Driven Representation Learning for Unsupervised Domain Adaptive  Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dohyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Younghoon Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+Y">Yongsang Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+B">Bumsub Ham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel unsupervised domain adaption method for person
re-identification (reID) that generalizes a model trained on a labeled source
domain to an unlabeled target domain. We introduce a camera-driven curriculum
learning (CaCL) framework that leverages camera labels of person images to
transfer knowledge from source to target domains progressively. To this end, we
divide target domain dataset into multiple subsets based on the camera labels,
and initially train our model with a single subset (i.e., images captured by a
single camera). We then gradually exploit more subsets for training, according
to a curriculum sequence obtained with a camera-driven scheduling rule. The
scheduler considers maximum mean discrepancies (MMD) between each subset and
the source domain dataset, such that the subset closer to the source domain is
exploited earlier within the curriculum. For each curriculum sequence, we
generate pseudo labels of person images in a target domain to train a reID
model in a supervised way. We have observed that the pseudo labels are highly
biased toward cameras, suggesting that person images obtained from the same
camera are likely to have the same pseudo labels, even for different IDs. To
address the camera bias problem, we also introduce a camera-diversity (CD) loss
encouraging person images of the same pseudo label, but captured across various
cameras, to involve more for discriminative feature learning, providing person
representations robust to inter-camera variations. Experimental results on
standard benchmarks, including real-to-real and synthetic-to-real scenarios,
demonstrate the effectiveness of our framework.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11903" title="Abstract">arXiv:2308.11903</a> [<a href="/pdf/2308.11903" title="Download PDF">pdf</a>, <a href="/format/2308.11903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Data Perturbation and Model Stabilization for Semi-supervised  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Meng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and logs are available at <a href="https://github.com/ZhenZHAO/DPMS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Studies on semi-supervised medical image segmentation (SSMIS) have seen fast
progress recently. Due to the limited labelled data, SSMIS methods mainly focus
on effectively leveraging unlabeled data to enhance the segmentation
performance. However, despite their promising performance, current
state-of-the-art methods often prioritize integrating complex techniques and
loss terms rather than addressing the core challenges of semi-supervised
scenarios directly. We argue that the key to SSMIS lies in generating
substantial and appropriate prediction disagreement on unlabeled data. To this
end, we emphasize the crutiality of data perturbation and model stabilization
in semi-supervised segmentation, and propose a simple yet effective approach to
boost SSMIS performance significantly, dubbed DPMS. Specifically, we first
revisit SSMIS from three distinct perspectives: the data, the model, and the
loss, and conduct a comprehensive study of corresponding strategies to examine
their effectiveness. Based on these examinations, we then propose DPMS, which
adopts a plain teacher-student framework with a standard supervised loss and
unsupervised consistency loss. To produce appropriate prediction disagreements,
DPMS perturbs the unlabeled data via strong augmentations to enlarge prediction
disagreements considerably. On the other hand, using EMA teacher when strong
augmentation is applied does not necessarily improve performance. DPMS further
utilizes a forwarding-twice and momentum updating strategies for normalization
statistics to stabilize the training on unlabeled data effectively. Despite its
simplicity, DPMS can obtain new state-of-the-art performance on the public 2D
ACDC and 3D LA datasets across various semi-supervised settings, e.g. obtaining
a remarkable 22.62% improvement against previous SOTA on ACDC with 5% labels.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11905" title="Abstract">arXiv:2308.11905</a> [<a href="/pdf/2308.11905" title="Download PDF">pdf</a>, <a href="/format/2308.11905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Admissible Bounds for Heuristic Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%BA%C3%B1ez-Molina%2C+C">Carlos N&#xfa;&#xf1;ez-Molina</a>, 
<a href="/search/cs?searchtype=author&query=Asai%2C+M">Masataro Asai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While learning a heuristic function for forward search algorithms with modern
machine learning techniques has been gaining interest in recent years, there
has been little theoretical understanding of \emph{what} they should learn,
\emph{how} to train them, and \emph{why} we do so. This lack of understanding
leads to various literature performing an ad-hoc selection of datasets
(suboptimal vs optimal costs or admissible vs inadmissible heuristics) and
optimization metrics (e.g., squared vs absolute errors). Moreover, due to the
lack of admissibility of the resulting trained heuristics, little focus has
been put on the role of admissibility \emph{during} learning. This paper
articulates the role of admissible heuristics in supervised heuristic learning
using them as parameters of Truncated Gaussian distributions, which tightens
the hypothesis space compared to ordinary Gaussian distributions. We argue that
this mathematical model faithfully follows the principle of maximum entropy and
empirically show that, as a result, it yields more accurate heuristics and
converges faster during training.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11909" title="Abstract">arXiv:2308.11909</a> [<a href="/pdf/2308.11909" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-aware Hard Clustering Graph Pooling for Brain Imaging Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Cheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiayi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Ping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Graph Convolutional Networks (GCNs) can capture non-Euclidean spatial
dependence between different brain regions, and the graph pooling operator in
GCNs is key to enhancing the representation learning capability and acquiring
abnormal brain maps. However, the majority of existing research designs graph
pooling operators only from the perspective of nodes while disregarding the
original edge features, in a way that not only confines graph pooling
application scenarios, but also diminishes its ability to capture critical
substructures. In this study, a clustering graph pooling method that first
supports multidimensional edge features, called Edge-aware hard clustering
graph pooling (EHCPool), is developed. EHCPool proposes the first
'Edge-to-node' score evaluation criterion based on edge features to assess node
feature significance. To more effectively capture the critical subgraphs, a
novel Iteration n-top strategy is further designed to adaptively learn sparse
hard clustering assignments for graphs. Subsequently, an innovative N-E
Aggregation strategy is presented to aggregate node and edge feature
information in each independent subgraph. The proposed model was evaluated on
multi-site brain imaging public datasets and yielded state-of-the-art
performance. We believe this method is the first deep learning tool with the
potential to probe different types of abnormal functional brain networks from
data-driven perspective.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11911" title="Abstract">arXiv:2308.11911</a> [<a href="/pdf/2308.11911" title="Download PDF">pdf</a>, <a href="/format/2308.11911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACLS: Adaptive and Conditional Label Smoothing for Network Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyekang Park</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+J">Jongyoun Noh</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Youngmin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+D">Donghyeon Baek</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+B">Bumsub Ham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the problem of network calibration adjusting miscalibrated
confidences of deep neural networks. Many approaches to network calibration
adopt a regularization-based method that exploits a regularization term to
smooth the miscalibrated confidences. Although these approaches have shown the
effectiveness on calibrating the networks, there is still a lack of
understanding on the underlying principles of regularization in terms of
network calibration. We present in this paper an in-depth analysis of existing
regularization-based methods, providing a better understanding on how they
affect to network calibration. Specifically, we have observed that 1) the
regularization-based methods can be interpreted as variants of label smoothing,
and 2) they do not always behave desirably. Based on the analysis, we introduce
a novel loss function, dubbed ACLS, that unifies the merits of existing
regularization methods, while avoiding the limitations. We show extensive
experimental results for image classification and semantic segmentation on
standard benchmarks, including CIFAR10, Tiny-ImageNet, ImageNet, and PASCAL
VOC, demonstrating the effectiveness of our loss function.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11912" title="Abstract">arXiv:2308.11912</a> [<a href="/pdf/2308.11912" title="Download PDF">pdf</a>, <a href="/format/2308.11912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise  Aggregate Influence Function Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Soonwoo Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sojung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Suyeong An</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyuseok Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Computerized Adaptive Testing (CAT) is a widely used, efficient test mode
that adapts to the examinee's proficiency level in the test domain. CAT
requires pre-trained item profiles, for CAT iteratively assesses the student
real-time based on the registered items' profiles, and selects the next item to
administer using candidate items' profiles. However, obtaining such item
profiles is a costly process that involves gathering a large, dense
item-response data, then training a diagnostic model on the collected data. In
this paper, we explore the possibility of leveraging response data collected in
the CAT service. We first show that this poses a unique challenge due to the
inherent selection bias introduced by CAT, i.e., more proficient students will
receive harder questions. Indeed, when naively training the diagnostic model
using CAT response data, we observe that item profiles deviate significantly
from the ground-truth. To tackle the selection bias issue, we propose the
user-wise aggregate influence function method. Our intuition is to filter out
users whose response data is heavily biased in an aggregate manner, as judged
by how much perturbation the added data will introduce during parameter
estimation. This way, we may enhance the performance of CAT while introducing
minimal bias to the item profiles. We provide extensive experiments to
demonstrate the superiority of our proposed method based on the three public
datasets and one dataset that contains real-world CAT response data.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11914" title="Abstract">arXiv:2308.11914</a> [<a href="/pdf/2308.11914" title="Download PDF">pdf</a>, <a href="/format/2308.11914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge  Reasoning via Promoting Causal Consistency in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Ziyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures. 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Despite advancements in LLMs, knowledge-based reasoning remains a
longstanding issue due to the fragility of knowledge recall and inference.
Existing methods primarily encourage LLMs to autonomously plan and solve
problems or to extensively sample reasoning chains without addressing the
conceptual and inferential fallacies. Attempting to alleviate inferential
fallacies and drawing inspiration from multi-agent collaboration, we present a
framework to increase faithfulness and causality for knowledge-based reasoning.
Specifically, we propose to employ multiple intelligent agents (i.e., reasoner
and causal evaluator) to work collaboratively in a reasoning-and-consensus
paradigm for elevated reasoning faithfulness. The reasoners focus on providing
solutions with human-like causality to solve open-domain problems. On the other
hand, the causal evaluator agent scrutinizes if the answer in a solution is
causally deducible from the question and vice versa, with a counterfactual
answer replacing the original. According to the extensive and comprehensive
evaluations on a variety of knowledge reasoning tasks (e.g., science question
answering and commonsense reasoning), our framework outperforms all compared
state-of-the-art approaches by large margins.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11915" title="Abstract">arXiv:2308.11915</a> [<a href="/pdf/2308.11915" title="Download PDF">pdf</a>, <a href="/format/2308.11915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Encoding Strategies for Erasing-Based Lossless Floating-Point  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Lossless floating-point time series compression is crucial for a wide range
of critical scenarios. Nevertheless, it is a big challenge to compress time
series losslessly due to the complex underlying layouts of floating-point
values. The state-of-the-art erasing-based compression algorithm Elf
demonstrates a rather impressive performance. We give an in-depth exploration
of the encoding strategies of Elf, and find that there is still much room for
improvement. In this paper, we propose Elf*, which employs a set of
optimizations for leading zeros, center bits and sharing condition.
Specifically, we develop a dynamic programming algorithm with a set of pruning
strategies to compute the adaptive approximation rules efficiently. We
theoretically prove that the adaptive approximation rules are globally optimal.
We further extend Elf* to Streaming Elf*, i.e., SElf*, which achieves almost
the same compression ratio as Elf*, while enjoying even higher efficiency in
streaming scenarios. We compare Elf* and SElf* with 8 competitors using 22
datasets. The results demonstrate that SElf* achieves 9.2% relative compression
ratio improvement over the best streaming competitor while maintaining similar
efficiency, and that Elf* ranks among the most competitive batch compressors.
All source codes are publicly released.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11916" title="Abstract">arXiv:2308.11916</a> [<a href="/pdf/2308.11916" title="Download PDF">pdf</a>, <a href="/format/2308.11916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Implicit Template Learning via Part Deformation  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sihyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+M">Minseok Joo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Juyeon Ko</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Juhan Cha</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning implicit templates as neural fields has recently shown impressive
performance in unsupervised shape correspondence. Despite the success, we
observe current approaches, which solely rely on geometric information, often
learn suboptimal deformation across generic object shapes, which have high
structural variability. In this paper, we highlight the importance of part
deformation consistency and propose a semantic-aware implicit template learning
framework to enable semantically plausible deformation. By leveraging semantic
prior from a self-supervised feature extractor, we suggest local conditioning
with novel semantic-aware deformation code and deformation consistency
regularizations regarding part deformation, global deformation, and global
scaling. Our extensive experiments demonstrate the superiority of the proposed
method over baselines in various tasks: keypoint transfer, part label transfer,
and texture transfer. More interestingly, our framework shows a larger
performance gain under more challenging settings. We also provide qualitative
analyses to validate the effectiveness of semantic-aware deformation. The code
is available at https://github.com/mlvlab/PDC.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11917" title="Abstract">arXiv:2308.11917</a> [<a href="/pdf/2308.11917" title="Download PDF">pdf</a>, <a href="/format/2308.11917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFS-GAN: Lifelong Few-Shot Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Juwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Ji-Su Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyeong-Moon Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 19 figures, 14 tables, ICCV 2023 Poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We address a challenging lifelong few-shot image generation task for the
first time. In this situation, a generative model learns a sequence of tasks
using only a few samples per task. Consequently, the learned model encounters
both catastrophic forgetting and overfitting problems at a time. Existing
studies on lifelong GANs have proposed modulation-based methods to prevent
catastrophic forgetting. However, they require considerable additional
parameters and cannot generate high-fidelity and diverse images from limited
data. On the other hand, the existing few-shot GANs suffer from severe
catastrophic forgetting when learning multiple tasks. To alleviate these
issues, we propose a framework called Lifelong Few-Shot GAN (LFS-GAN) that can
generate high-quality and diverse images in lifelong few-shot image generation
task. Our proposed framework learns each task using an efficient task-specific
modulator - Learnable Factorized Tensor (LeFT). LeFT is rank-constrained and
has a rich representation ability due to its unique reconstruction technique.
Furthermore, we propose a novel mode seeking loss to improve the diversity of
our model in low-data circumstances. Extensive experiments demonstrate that the
proposed LFS-GAN can generate high-fidelity and diverse images without any
forgetting and mode collapse in various domains, achieving state-of-the-art in
lifelong few-shot image generation task. Surprisingly, we find that our LFS-GAN
even outperforms the existing few-shot GANs in the few-shot image generation
task. The code is available at Github.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11918" title="Abstract">arXiv:2308.11918</a> [<a href="/pdf/2308.11918" title="Download PDF">pdf</a>, <a href="/format/2308.11918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-Man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">ChunLe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a novel Amplitude-Modulated Stochastic Perturbation
and Vortex Convolutional Network, AMSP-UOD, designed for underwater object
detection. AMSP-UOD specifically addresses the impact of non-ideal imaging
factors on detection accuracy in complex underwater environments. To mitigate
the influence of noise on object detection performance, we propose AMSP Vortex
Convolution (AMSP-VConv) to disrupt the noise distribution, enhance feature
extraction capabilities, effectively reduce parameters, and improve network
robustness. We design the Feature Association Decoupling Cross Stage Partial
(FAD-CSP) module, which strengthens the association of long and short-range
features, improving the network performance in complex underwater environments.
Additionally, our sophisticated post-processing method, based on non-maximum
suppression with aspect-ratio similarity thresholds, optimizes detection in
dense scenes, such as waterweed and schools of fish, improving object detection
accuracy. Extensive experiments on the URPC and RUOD datasets demonstrate that
our method outperforms existing state-of-the-art methods in terms of accuracy
and noise immunity. AMSP-UOD proposes an innovative solution with the potential
for real-world applications. Code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11920" title="Abstract">arXiv:2308.11920</a> [<a href="/pdf/2308.11920" title="Download PDF">pdf</a>, <a href="/format/2308.11920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Bottleneck with Visual Concept Filtering for Explainable Medical  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Injae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongha Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Joonmyung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to MedAGI Workshop at MICCAI 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interpretability is a crucial factor in building reliable models for various
medical applications. Concept Bottleneck Models (CBMs) enable interpretable
image classification by utilizing human-understandable concepts as intermediate
targets. Unlike conventional methods that require extensive human labor to
construct the concept set, recent works leveraging Large Language Models (LLMs)
for generating concepts made automatic concept generation possible. However,
those methods do not consider whether a concept is visually relevant or not,
which is an important factor in computing meaningful concept scores. Therefore,
we propose a visual activation score that measures whether the concept contains
visual cues or not, which can be easily computed with unlabeled image data.
Computed visual activation scores are then used to filter out the less visible
concepts, thus resulting in a final concept set with visually meaningful
concepts. Our experimental results show that adopting the proposed visual
activation score for concept filtering consistently boosts performance compared
to the baseline. Moreover, qualitative analyses also validate that visually
relevant concepts are successfully selected with the visual activation score.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11921" title="Abstract">arXiv:2308.11921</a> [<a href="/pdf/2308.11921" title="Download PDF">pdf</a>, <a href="/format/2308.11921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARseL: Towards a Verified Root-of-Trust over seL4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Oliveira+Nunes%2C+I">Ivan De Oliveira Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seoyeon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jakkamsetti%2C+S">Sashidhar Jakkamsetti</a>, 
<a href="/search/cs?searchtype=author&query=Rattanavipanon%2C+N">Norrathep Rattanavipanon</a>, 
<a href="/search/cs?searchtype=author&query=Tsudik%2C+G">Gene Tsudik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages and 8 figures. To be published at IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Widespread adoption and growing popularity of embedded/IoT/CPS devices make
them attractive attack targets. On low-to-mid-range devices, security features
are typically few or none due to various constraints. Such devices are thus
subject to malware-based compromise. One popular defensive measure is Remote
Attestation (RA) which allows a trusted entity to determine the current
software integrity of an untrusted remote device.
<br />For higher-end devices, RA is achievable via secure hardware components. For
low-end (bare metal) devices, minimalistic hybrid (hardware/software) RA is
effective, which incurs some hardware modifications. That leaves certain
mid-range devices (e.g., ARM Cortex-A family) equipped with standard hardware
components, e.g., a memory management unit (MMU) and perhaps a secure boot
facility. In this space, seL4 (a verified microkernel with guaranteed process
isolation) is a promising platform for attaining RA. HYDRA made a first step
towards this, albeit without achieving any verifiability or provable
guarantees.
<br />This paper picks up where HYDRA left off by constructing a PARseL
architecture, that separates all user-dependent components from the TCB. This
leads to much stronger isolation guarantees, based on seL4 alone, and
facilitates formal verification. In PARseL, We use formal verification to
obtain several security properties for the isolated RA TCB, including: memory
safety, functional correctness, and secret independence. We implement PARseL in
F* and specify/prove expected properties using Hoare logic. Next, we
automatically translate the F* implementation to C using KaRaMeL, which
preserves verified properties of PARseL C implementation (atop seL4). Finally,
we instantiate and evaluate PARseL on a commodity platform -- a SabreLite
embedded device.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11924" title="Abstract">arXiv:2308.11924</a> [<a href="/pdf/2308.11924" title="Download PDF">pdf</a>, <a href="/format/2308.11924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Policies Converge in Reward-free Markov Decision Processe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Fanqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Weiwei Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning has achieved great success in many decision-making
tasks, and traditional reinforcement learning algorithms are mainly designed
for obtaining a single optimal solution. However, recent works show the
importance of developing diverse policies, which makes it an emerging research
topic. Despite the variety of diversity reinforcement learning algorithms that
have emerged, none of them theoretically answer the question of how the
algorithm converges and how efficient the algorithm is. In this paper, we
provide a unified diversity reinforcement learning framework and investigate
the convergence of training diverse policies. Under such a framework, we also
propose a provably efficient diversity reinforcement learning algorithm.
Finally, we verify the effectiveness of our method through numerical
experiments.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11928" title="Abstract">arXiv:2308.11928</a> [<a href="/pdf/2308.11928" title="Download PDF">pdf</a>, <a href="/format/2308.11928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OFVL-MS: Once for Visual Localization across Multiple Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+K">Kun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Siyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jinghan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dedong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lijun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruifeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we seek to predict camera poses across scenes with a multi-task
learning manner, where we view the localization of each scene as a new task. We
propose OFVL-MS, a unified framework that dispenses with the traditional
practice of training a model for each individual scene and relieves gradient
conflict induced by optimizing multiple scenes collectively, enabling efficient
storage yet precise visual localization for all scenes. Technically, in the
forward pass of OFVL-MS, we design a layer-adaptive sharing policy with a
learnable score for each layer to automatically determine whether the layer is
shared or not. Such sharing policy empowers us to acquire task-shared
parameters for a reduction of storage cost and task-specific parameters for
learning scene-related features to alleviate gradient conflict. In the backward
pass of OFVL-MS, we introduce a gradient normalization algorithm that
homogenizes the gradient magnitude of the task-shared parameters so that all
tasks converge at the same pace. Furthermore, a sparse penalty loss is applied
on the learnable scores to facilitate parameter sharing for all tasks without
performance degradation. We conduct comprehensive experiments on multiple
benchmarks and our new released indoor dataset LIVL, showing that OFVL-MS
families significantly outperform the state-of-the-arts with fewer parameters.
We also verify that OFVL-MS can generalize to a new scene with much few
parameters while gaining superior localization performance.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11929" title="Abstract">arXiv:2308.11929</a> [<a href="/pdf/2308.11929" title="Download PDF">pdf</a>, <a href="/format/2308.11929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic landslide susceptibility mapping over recent three decades to  uncover variations in landslide causes in subtropical urban mountainous areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Peifeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yulin Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Landslide susceptibility assessment (LSA) is of paramount importance in
mitigating landslide risks. Recently, there has been a surge in the utilization
of data-driven methods for predicting landslide susceptibility due to the
growing availability of aerial and satellite data. Nonetheless, the rapid
oscillations within the landslide-inducing environment (LIE), primarily due to
significant changes in external triggers such as rainfall, pose difficulties
for contemporary data-driven LSA methodologies to accommodate LIEs over diverse
timespans. This study presents dynamic landslide susceptibility mapping that
simply employs multiple predictive models for annual LSA. In practice, this
will inevitably encounter small sample problems due to the limited number of
landslide samples in certain years. Another concern arises owing to the
majority of the existing LSA approaches train black-box models to fit distinct
datasets, yet often failing in generalization and providing comprehensive
explanations concerning the interactions between input features and
predictions. Accordingly, we proposed to meta-learn representations with fast
adaptation ability using a few samples and gradient updates; and apply SHAP for
each model interpretation and landslide feature permutation. Additionally, we
applied MT-InSAR for LSA result enhancement and validation. The chosen study
area is Lantau Island, Hong Kong, where we conducted a comprehensive dynamic
LSA spanning from 1992 to 2019. The model interpretation results demonstrate
that the primary factors responsible for triggering landslides in Lantau Island
are terrain slope and extreme rainfall. The results also indicate that the
variation in landslide causes can be primarily attributed to extreme rainfall
events, which result from global climate change, and the implementation of the
Landslip Prevention and Mitigation Programme (LPMitP) by the Hong Kong
government.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11932" title="Abstract">arXiv:2308.11932</a> [<a href="/pdf/2308.11932" title="Download PDF">pdf</a>, <a href="/format/2308.11932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Multiscale Detail Refinement via Intrinsic Supervision for  Underwater Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">ChunLe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual restoration of underwater scenes is crucial for visual tasks, and
avoiding interference from underwater media has become a prominent concern. In
this work, we present a synergistic multiscale detail refinement via intrinsic
supervision (SMDR-IS) to recover underwater scene details. The low-degradation
stage provides multiscale detail for original stage, which achieves synergistic
multiscale detail refinement through feature propagation via the adaptive
selective intrinsic supervised feature module (ASISF), which achieves
synergistic multiscale detail refinement. ASISF is developed using intrinsic
supervision to precisely control and guide feature transmission in the
multi-degradation stages. ASISF improves the multiscale detail refinement while
reducing interference from irrelevant scene information from the
low-degradation stage. Additionally, within the multi-degradation
encoder-decoder of SMDR-IS, we introduce a bifocal intrinsic-context attention
module (BICA). This module is designed to effectively leverage multi-scale
scene information found in images, using intrinsic supervision principles as
its foundation. BICA facilitates the guidance of higher-resolution spaces by
leveraging lower-resolution spaces, considering the significant dependency of
underwater image restoration on spatial contextual relationships. During the
training process, the network gains advantages from the integration of a
multi-degradation loss function. This function serves as a constraint, enabling
the network to effectively exploit information across various scales. When
compared with state-of-the-art methods, SMDR-IS demonstrates its outstanding
performance. Code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11933" title="Abstract">arXiv:2308.11933</a> [<a href="/pdf/2308.11933" title="Download PDF">pdf</a>, <a href="/format/2308.11933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Identification for Continuous-time Linear Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halmos%2C+P">Peter Halmos</a>, 
<a href="/search/cs?searchtype=author&query=Pillow%2C+J">Jonathan Pillow</a>, 
<a href="/search/cs?searchtype=author&query=Knowles%2C+D+A">David A. Knowles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The problem of system identification for the Kalman filter, relying on the
expectation-maximization (EM) procedure to learn the underlying parameters of a
dynamical system, has largely been studied assuming that observations are
sampled at equally-spaced time points. However, in many applications this is a
restrictive and unrealistic assumption. This paper addresses system
identification for the continuous-discrete filter, with the aim of generalizing
learning for the Kalman filter by relying on a solution to a continuous-time
It\^o stochastic differential equation (SDE) for the latent state and
covariance dynamics. We introduce a novel two-filter, analytical form for the
posterior with a Bayesian derivation, which yields analytical updates which do
not require the forward-pass to be pre-computed. Using this analytical and
efficient computation of the posterior, we provide an EM procedure which
estimates the parameters of the SDE, naturally incorporating irregularly
sampled measurements. Generalizing the learning of latent linear dynamical
systems (LDS) to continuous-time may extend the use of the hybrid Kalman filter
to data which is not regularly sampled or has intermittent missing values, and
can extend the power of non-linear system identification methods such as
switching LDS (SLDS), which rely on EM for the linear discrete-time Kalman
filter as a sub-unit for learning locally linearized behavior of a non-linear
system. We apply the method by learning the parameters of a latent,
multivariate Fokker-Planck SDE representing a toggle-switch genetic circuit
using biologically realistic parameters, and compare the efficacy of learning
relative to the discrete-time Kalman filter as the step-size irregularity and
spectral-radius of the dynamics-matrix increases.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11934" title="Abstract">arXiv:2308.11934</a> [<a href="/pdf/2308.11934" title="Download PDF">pdf</a>, <a href="/format/2308.11934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An EEP-based robust beamforming approach for superdirective antenna  arrays and experimental validations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mengying Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haifan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Liangcheng Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A superdirective antenna array has the potential to achieve an array gain
proportional to the square of the number of antennas, making it of great value
for future wireless communications. However, designing the superdirective
beamformer while considering the complicated mutual-coupling effect is a
practical challenge. Moreover, the superdirective antenna array is highly
sensitive to excitation errors, especially when the number of antennas is large
or the antenna spacing is very small, necessitating demanding and precise
control over excitations. To address these problems, we first propose a novel
superdirective beamforming approach based on the embedded element pattern
(EEP), which contains the coupling information. The closed-form solution to the
beamforming vector and the corresponding directivity factor are derived. This
method relies on the beam coupling factors (BCFs) between the antennas, which
are provided in closed form. To address the high sensitivity problem, we
formulate a constrained optimization problem and propose an EEP-aided
orthogonal complement-based robust beamforming (EEP-OCRB) algorithm. Full-wave
simulation results validate our proposed methods. Finally, we build a prototype
of a 5-dipole superdirective antenna array and conduct real-world experiments.
The measurement results demonstrate the realization of the superdirectivity
with our EEP-based method, as well as the robustness of the proposed EEP-OCRB
algorithm to excitation errors.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11937" title="Abstract">arXiv:2308.11937</a> [<a href="/pdf/2308.11937" title="Download PDF">pdf</a>, <a href="/format/2308.11937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Bottleneck Transformer for Event Image-Voxel Feature Fusion  based Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chengguo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongzhen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fanting Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yangzirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by PRCV-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recognizing target objects using an event-based camera draws more and more
attention in recent years. Existing works usually represent the event streams
into point-cloud, voxel, image, etc, and learn the feature representations
using various deep neural networks. Their final results may be limited by the
following factors: monotonous modal expressions and the design of the network
structure. To address the aforementioned challenges, this paper proposes a
novel dual-stream framework for event representation, extraction, and fusion.
This framework simultaneously models two common representations: event images
and event voxels. By utilizing Transformer and Structured Graph Neural Network
(GNN) architectures, spatial information and three-dimensional stereo
information can be learned separately. Additionally, a bottleneck Transformer
is introduced to facilitate the fusion of the dual-stream information.
Extensive experiments demonstrate that our proposed framework achieves
state-of-the-art performance on two widely used event-based classification
datasets. The source code of this work is available at:
\url{https://github.com/Event-AHU/EFV_event_classification}
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11939" title="Abstract">arXiv:2308.11939</a> [<a href="/pdf/2308.11939" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retail Demand Forecasting: A Comparative Study for Multivariate Time  Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haque%2C+M+S">Md Sabbirul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+M+S">Md Shahedul Amin</a>, 
<a href="/search/cs?searchtype=author&query=Miah%2C+J">Jonayet Miah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">Accurate demand forecasting in the retail industry is a critical determinant
of financial performance and supply chain efficiency. As global markets become
increasingly interconnected, businesses are turning towards advanced prediction
models to gain a competitive edge. However, existing literature mostly focuses
on historical sales data and ignores the vital influence of macroeconomic
conditions on consumer spending behavior. In this study, we bridge this gap by
enriching time series data of customer demand with macroeconomic variables,
such as the Consumer Price Index (CPI), Index of Consumer Sentiment (ICS), and
unemployment rates. Leveraging this comprehensive dataset, we develop and
compare various regression and machine learning models to predict retail demand
accurately.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11940" title="Abstract">arXiv:2308.11940</a> [<a href="/pdf/2308.11940" title="Download PDF">pdf</a>, <a href="/format/2308.11940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Generation with Multiple Conditional Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhifang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jianguo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Rui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ouchi%2C+K">Kazushige Ouchi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Text-based audio generation models have limitations as they cannot encompass
all the information in audio, leading to restricted controllability when
relying solely on text. To address this issue, we propose a novel model that
enhances the controllability of existing pre-trained text-to-audio models by
incorporating additional conditions including content (timestamp) and style
(pitch contour and energy contour) as supplements to the text. This approach
achieves fine-grained control over the temporal order, pitch, and energy of
generated audio. To preserve the diversity of generation, we employ a trainable
control condition encoder that is enhanced by a large language model and a
trainable Fusion-Net to encode and fuse the additional conditions while keeping
the weights of the pre-trained text-to-audio model frozen. Due to the lack of
suitable datasets and evaluation metrics, we consolidate existing datasets into
a new dataset comprising the audio and corresponding conditions and use a
series of evaluation metrics to evaluate the controllability performance.
Experimental results demonstrate that our model successfully achieves
fine-grained control to accomplish controllable audio generation. Audio samples
and our dataset are publicly available at
https://conditionaudiogen.github.io/conditionaudiogen/
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11941" title="Abstract">arXiv:2308.11941</a> [<a href="/pdf/2308.11941" title="Download PDF">pdf</a>, <a href="/format/2308.11941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Diffusion Models with an Adaptive Momentum Sampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+A">Anh-Dung Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daochang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion probabilistic models (DPMs) have been shown to generate
high-quality images without the need for delicate adversarial training.
However, the current sampling process in DPMs is prone to violent shaking. In
this paper, we present a novel reverse sampler for DPMs inspired by the
widely-used Adam optimizer. Our proposed sampler can be readily applied to a
pre-trained diffusion model, utilizing momentum mechanisms and adaptive
updating to smooth the reverse sampling process and ensure stable generation,
resulting in outputs of enhanced quality. By implicitly reusing update
directions from early steps, our proposed sampler achieves a better balance
between high-level semantics and low-level details. Additionally, this sampler
is flexible and can be easily integrated into pre-trained DPMs regardless of
the sampler used during training. Our experimental results on multiple
benchmarks demonstrate that our proposed reverse sampler yields remarkable
improvements over different baselines. We will make the source code available.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11943" title="Abstract">arXiv:2308.11943</a> [<a href="/pdf/2308.11943" title="Download PDF">pdf</a>, <a href="/format/2308.11943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RamseyRL: A Framework for Intelligent Ramsey Number Counterexample  Searching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vott%2C+S">Steve Vott</a>, 
<a href="/search/cs?searchtype=author&query=Lehavi%2C+A+M">Adam M. Lehavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, submitted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Ramsey number is the minimum number of nodes, $n = R(s, t)$, such that
all undirected simple graphs of order $n$, contain a clique of order $s$, or an
independent set of order $t$. This paper explores the application of a best
first search algorithm and reinforcement learning (RL) techniques to find
counterexamples to specific Ramsey numbers. We incrementally improve over prior
search methods such as random search by introducing a graph vectorization and
deep neural network (DNN)-based heuristic, which gauge the likelihood of a
graph being a counterexample. The paper also proposes algorithmic optimizations
to confine a polynomial search runtime. This paper does not aim to present new
counterexamples but rather introduces and evaluates a framework supporting
Ramsey counterexample exploration using other heuristics. Code and methods are
made available through a PyPI package and GitHub repository.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11945" title="Abstract">arXiv:2308.11945</a> [<a href="/pdf/2308.11945" title="Download PDF">pdf</a>, <a href="/format/2308.11945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LongDanceDiff: Long-term Dance Generation with Conditional Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Siqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zejun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhisheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dancing with music is always an essential human art form to express emotion.
Due to the high temporal-spacial complexity, long-term 3D realist dance
generation synchronized with music is challenging. Existing methods suffer from
the freezing problem when generating long-term dances due to error accumulation
and training-inference discrepancy. To address this, we design a conditional
diffusion model, LongDanceDiff, for this sequence-to-sequence long-term dance
generation, addressing the challenges of temporal coherency and spatial
constraint. LongDanceDiff contains a transformer-based diffusion model, where
the input is a concatenation of music, past motions, and noised future motions.
This partial noising strategy leverages the full-attention mechanism and learns
the dependencies among music and past motions. To enhance the diversity of
generated dance motions and mitigate the freezing problem, we introduce a
mutual information minimization objective that regularizes the dependency
between past and future motions. We also address common visual quality issues
in dance generation, such as foot sliding and unsmooth motion, by incorporating
spatial constraints through a Global-Trajectory Modulation (GTM) layer and
motion perceptual losses, thereby improving the smoothness and naturalness of
motion generation. Extensive experiments demonstrate a significant improvement
in our approach over the existing state-of-the-art methods. We plan to release
our codes and models soon.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11946" title="Abstract">arXiv:2308.11946</a> [<a href="/pdf/2308.11946" title="Download PDF">pdf</a>, <a href="/format/2308.11946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Transformer Pyramid Networks for Multivariate Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dascalu%2C+S+M">Sergiu M. Dascalu</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+F+C">Frederick C. Harris Jr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multivariate Time Series (MTS) forecasting involves modeling temporal
dependencies within historical records. Transformers have demonstrated
remarkable performance in MTS forecasting due to their capability to capture
long-term dependencies. However, prior work has been confined to modeling
temporal dependencies at either a fixed scale or multiple scales that
exponentially increase (most with base 2). This limitation hinders their
effectiveness in capturing diverse seasonalities, such as hourly and daily
patterns. In this paper, we introduce a dimension invariant embedding technique
that captures short-term temporal dependencies and projects MTS data into a
higher-dimensional space, while preserving the dimensions of time steps and
variables in MTS data. Furthermore, we present a novel Multi-scale Transformer
Pyramid Network (MTPNet), specifically designed to effectively capture temporal
dependencies at multiple unconstrained scales. The predictions are inferred
from multi-scale latent representations obtained from transformers at various
scales. Extensive experiments on nine benchmark datasets demonstrate that the
proposed MTPNet outperforms recent state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11948" title="Abstract">arXiv:2308.11948</a> [<a href="/pdf/2308.11948" title="Download PDF">pdf</a>, <a href="/format/2308.11948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Transfer Learning in Diffusion Models via Adversarial Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Baijiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daochang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion Probabilistic Models (DPMs) have demonstrated substantial promise
in image generation tasks but heavily rely on the availability of large amounts
of training data. Previous works, like GANs, have tackled the limited data
problem by transferring pre-trained models learned with sufficient data.
However, those methods are hard to be utilized in DPMs since the distinct
differences between DPM-based and GAN-based methods, showing in the unique
iterative denoising process integral and the need for many timesteps with
no-targeted noise in DPMs. In this paper, we propose a novel DPMs-based
transfer learning method, TAN, to address the limited data problem. It includes
two strategies: similarity-guided training, which boosts transfer with a
classifier, and adversarial noise selection which adaptive chooses targeted
noise based on the input image. Extensive experiments in the context of
few-shot image generation tasks demonstrate that our method is not only
efficient but also excels in terms of image quality and diversity when compared
to existing GAN-based and DDPM-based methods.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11949" title="Abstract">arXiv:2308.11949</a> [<a href="/pdf/2308.11949" title="Download PDF">pdf</a>, <a href="/format/2308.11949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-quality Image Dehazing with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaiwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Man Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image dehazing is quite challenging in dense-haze scenarios, where quite less
original information remains in the hazy image. Though previous methods have
made marvelous progress, they still suffer from information loss in content and
color in dense-haze scenarios. The recently emerged Denoising Diffusion
Probabilistic Model (DDPM) exhibits strong generation ability, showing
potential for solving this problem. However, DDPM fails to consider the physics
property of dehazing task, limiting its information completion capacity. In
this work, we propose DehazeDDPM: A DDPM-based and physics-aware image dehazing
framework that applies to complex hazy scenarios. Specifically, DehazeDDPM
works in two stages. The former stage physically models the dehazing task with
the Atmospheric Scattering Model (ASM), pulling the distribution closer to the
clear data and endowing DehazeDDPM with fog-aware ability. The latter stage
exploits the strong generation ability of DDPM to compensate for the
haze-induced huge information loss, by working in conjunction with the physical
modelling. Extensive experiments demonstrate that our method attains
state-of-the-art performance on both synthetic and real-world hazy datasets.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11951" title="Abstract">arXiv:2308.11951</a> [<a href="/pdf/2308.11951" title="Download PDF">pdf</a>, <a href="/format/2308.11951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Modulated Avatars from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chunjin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wandt%2C+B">Bastian Wandt</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+H">Helge Rhodin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">It is now possible to reconstruct dynamic human motion and shape from a
sparse set of cameras using Neural Radiance Fields (NeRF) driven by an
underlying skeleton. However, a challenge remains to model the deformation of
cloth and skin in relation to skeleton pose. Unlike existing avatar models that
are learned implicitly or rely on a proxy surface, our approach is motivated by
the observation that different poses necessitate unique frequency assignments.
Neglecting this distinction yields noisy artifacts in smooth areas or blurs
fine-grained texture and shape details in sharp regions. We develop a
two-branch neural network that is adaptive and explicit in the frequency
domain. The first branch is a graph neural network that models correlations
among body parts locally, taking skeleton pose as input. The second branch
combines these correlation features to a set of global frequencies and then
modulates the feature encoding. Our experiments demonstrate that our network
outperforms state-of-the-art methods in terms of preserving details and
generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11953" title="Abstract">arXiv:2308.11953</a> [<a href="/pdf/2308.11953" title="Download PDF">pdf</a>, <a href="/format/2308.11953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When MiniBatch SGD Meets SplitFed Learning:Convergence Analysis and  Performance Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Geng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) enables collaborative model training across
distributed clients (e.g., edge devices) without sharing raw data. Yet, FL can
be computationally expensive as the clients need to train the entire model
multiple times. SplitFed learning (SFL) is a recent distributed approach that
alleviates computation workload at the client device by splitting the model at
a cut layer into two parts, where clients only need to train part of the model.
However, SFL still suffers from the \textit{client drift} problem when clients'
data are highly non-IID. To address this issue, we propose MiniBatch-SFL. This
algorithm incorporates MiniBatch SGD into SFL, where the clients train the
client-side model in an FL fashion while the server trains the server-side
model similar to MiniBatch SGD. We analyze the convergence of MiniBatch-SFL and
show that the bound of the expected loss can be obtained by analyzing the
expected server-side and client-side model updates, respectively. The
server-side updates do not depend on the non-IID degree of the clients'
datasets and can potentially mitigate client drift. However, the client-side
model relies on the non-IID degree and can be optimized by properly choosing
the cut layer. Perhaps counter-intuitive, our empirical result shows that a
latter position of the cut layer leads to a smaller average gradient divergence
and a better algorithm performance. Moreover, numerical results show that
MiniBatch-SFL achieves higher accuracy than conventional SFL and FL. The
accuracy improvement can be up to 24.1\% and 17.1\% with highly non-IID data,
respectively.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11957" title="Abstract">arXiv:2308.11957</a> [<a href="/pdf/2308.11957" title="Download PDF">pdf</a>, <a href="/format/2308.11957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CED: Consistent ensemble distillation for audio tagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+H">Heinrich Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiyong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Augmentation and knowledge distillation (KD) are well-established techniques
employed in the realm of audio classification tasks, aimed at enhancing
performance and reducing model sizes on the widely recognized Audioset (AS)
benchmark. Although both techniques are effective individually, their combined
use, called consistent teaching, hasn't been explored before. This paper
proposes CED, a simple training framework that distils student models from
large teacher ensembles with consistent teaching. To achieve this, CED
efficiently stores logits as well as the augmentation methods on disk, making
it scalable to large-scale datasets. Central to CED's efficacy is its
label-free nature, meaning that only the stored logits are used for the
optimization of a student model only requiring 0.3\% additional disk space for
AS. The study trains various transformer-based models, including a 10M
parameter model achieving a 49.0 mean average precision (mAP) on AS. Pretrained
models and code are available at https://github.com/RicherMans/CED.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11958" title="Abstract">arXiv:2308.11958</a> [<a href="/pdf/2308.11958" title="Download PDF">pdf</a>, <a href="/format/2308.11958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maintaining Plasticity via Regenerative Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Saurabh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Marklund%2C+H">Henrik Marklund</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In continual learning, plasticity refers to the ability of an agent to
quickly adapt to new information. Neural networks are known to lose plasticity
when processing non-stationary data streams. In this paper, we propose L2 Init,
a very simple approach for maintaining plasticity by incorporating in the loss
function L2 regularization toward initial parameters. This is very similar to
standard L2 regularization (L2), the only difference being that L2 regularizes
toward the origin. L2 Init is simple to implement and requires selecting only a
single hyper-parameter. The motivation for this method is the same as that of
methods that reset neurons or parameter values. Intuitively, when recent losses
are insensitive to particular parameters, these parameters drift toward their
initial values. This prepares parameters to adapt quickly to new tasks. On
simple problems representative of different types of nonstationarity in
continual learning, we demonstrate that L2 Init consistently mitigates
plasticity loss. We additionally find that our regularization term reduces
parameter magnitudes and maintains a high effective feature rank.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11959" title="Abstract">arXiv:2308.11959</a> [<a href="/pdf/2308.11959" title="Download PDF">pdf</a>, <a href="/format/2308.11959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable &#x3b4;-Level Coherent State Synchronization of Multi-Agent  Systems in the Presence of Bounded Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nojavanzadeh%2C+D">Donya Nojavanzadeh</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhenwei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Saberi%2C+A">Ali Saberi</a>, 
<a href="/search/eess?searchtype=author&query=Stoorvogel%2C+A+A">Anton A. Stoorvogel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, This is a preprint of a paper "Scalable {\delta}-Level Coherent State Synchronization of Multi-Agent Systems with Adaptive Protocols and Bounded Disturbances" submitted to International Journal of Robust and Nonlinear Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we study scalable {\delta}-Level coherent state
synchronization for multi-agent systems (MAS) where the agents are subject to
bounded disturbances/noises. We propose a scale-free framework designed solely
based on the knowledge of agent models and agnostic to the communication graphs
and size of the network. We define the level of coherency for each agent as the
norm of the weighted sum of the disagreement dynamics with its neighbors. The
objective is to restrict the level of coherency of the network to {\delta}
without a-priori information about the disturbances.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11961" title="Abstract">arXiv:2308.11961</a> [<a href="/pdf/2308.11961" title="Download PDF">pdf</a>, <a href="/format/2308.11961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value of Assistance for Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amuzig%2C+A">Adi Amuzig</a>, 
<a href="/search/cs?searchtype=author&query=Dovrat%2C+D">David Dovrat</a>, 
<a href="/search/cs?searchtype=author&query=Keren%2C+S">Sarah Keren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023. git repository: <a href="https://github.com/CLAIR-LAB-TECHNION/VOA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mobile robotic agents often suffer from localization uncertainty which grows
with time and with the agents' movement. This can hinder their ability to
accomplish their task. In some settings, it may be possible to perform
assistive actions that reduce uncertainty about a robot's location. For
example, in a collaborative multi-robot system, a wheeled robot can request
assistance from a drone that can fly to its estimated location and reveal its
exact location on the map or accompany it to its intended location. Since
assistance may be costly and limited, and may be requested by different members
of a team, there is a need for principled ways to support the decision of which
assistance to provide to an agent and when, as well as to decide which agent to
help within a team. For this purpose, we propose Value of Assistance (VOA) to
represent the expected cost reduction that assistance will yield at a given
point of execution. We offer ways to compute VOA based on estimations of the
robot's future uncertainty, modeled as a Gaussian process. We specify
conditions under which our VOA measures are valid and empirically demonstrate
the ability of our measures to predict the agent's average cost reduction when
receiving assistance in both simulated and real-world robotic settings.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11962" title="Abstract">arXiv:2308.11962</a> [<a href="/pdf/2308.11962" title="Download PDF">pdf</a>, <a href="/format/2308.11962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Questions about the Visualization of Sociodemographic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabric%2C+F">Florent Cabric</a> (AVIZ), 
<a href="/search/cs?searchtype=author&query=Bjarnad%C3%B3ttir%2C+M+V">Margr&#xe9;t Vilborg Bjarnad&#xf3;ttir</a>, 
<a href="/search/cs?searchtype=author&query=Cabouat%2C+A">Anne-Flore Cabouat</a> (AVIZ), 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+P">Petra Isenberg</a> (AVIZ)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Workshop on Visualization for Social Good (VIS4Good), Oct
  2023, Melbourne, Australia. pp.5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper collects a set of open research questions on how to visualize
sociodemographic data. Sociodemographic data is a common part of datasets
related to people, including institutional censuses, health data systems, and
human-resources fles. This data is sensitive, and its collection, sharing, and
analysis require careful consideration. For instance, the European Union,
through the General Data Protection Regulation (GDPR), protects the collection
and processing of any personal data, including sexual orientation, ethnicity,
and religion. Data visualization of sociodemographic data can reinforce
stereotypes, marginalize groups, and lead to biased decision-making. It is,
therefore, critical that these visualizations are created based on good,
equitable design principles. In this paper, we discuss and provide a set of
open research questions around the visualization of sociodemographic data. Our
work contributes to an ongoing refection on representing data about people and
highlights some important future research directions for the VIS community. A
version of this paper and its fgures are available online at osf.io/a2u9c.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11964" title="Abstract">arXiv:2308.11964</a> [<a href="/pdf/2308.11964" title="Download PDF">pdf</a>, <a href="/format/2308.11964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computation of the Logarithm of the Modified Bessel Function of  the Second Kind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cuingnet%2C+R">Remi Cuingnet</a> (VeRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The modified Bessel function of the second kind K$\nu$ appears in a wide
variety of applied scientific fields. While its use is greatly facilitated by
an implementation in most numerical libraries, overflow issues can be
encountered especially for large value of $\nu$. After giving some necessary
and sufficient conditions for their occurrences, this technical note shows that
they can mostly be avoided by directly computing the logarithm of K$\nu$ thanks
to a simple and stable forward recursion. A statistical examples based on the
Gil-Pelaez inversion formula is given to illustrate the recursive method.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11965" title="Abstract">arXiv:2308.11965</a> [<a href="/pdf/2308.11965" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding differences of the OA uptake within the Germany university  landscape (2010-2020) -- Part 2: repository-provided OA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taubert%2C+N">Niels Taubert</a>, 
<a href="/search/cs?searchtype=author&query=Hobert%2C+A">Anne Hobert</a>, 
<a href="/search/cs?searchtype=author&query=Jahn%2C+N">Najko Jahn</a>, 
<a href="/search/cs?searchtype=author&query=Bruns%2C+A">Andre Bruns</a>, 
<a href="/search/cs?searchtype=author&query=Iravani%2C+E">Elham Iravani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 tables. arXiv admin note: text overlap with <a href="/abs/2209.12505">arXiv:2209.12505</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This study investigates the determinants for the uptake of institutional and
subject repository Open Access (OA) in the university landscape of Germany and
considers three factors: the disciplinary profile of universities, their OA
infrastructures and services and large transformative agreements. The uptake of
OA as well as the determinants are measured by combining several data sources
(incl. Web of Science, Unpaywall, an authority file of standardised German
affiliation information, the ISSN-Gold-OA 4.0 list, and lists of publications
covered by transformative agreements). For universities OA infrastructures and
services, a structured data collection was created by harvesting different
sources of information and by manual online search. To determine the
explanatory power of the different factors, a series of regression analyses was
performed for different periods and for both institutional as well as subject
repository OA. As a result of the regression analyses, the most determining
factor for the explanation of differences in the uptake of both repository
OA-types turned out to be the disciplinary profile, whereas all variables that
capture local infrastructural support and services for OA turned out to be
non-significant. The outcome of the regression analyses is contextualised by an
interview study conducted with 20 OA officers of German universities. The
contextualisation provides hints that the original function of institutional
repositories, offering a channel for secondary publishing is vanishing, while a
new function of aggregation of metadata and full texts is becoming of
increasing importance.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11970" title="Abstract">arXiv:2308.11970</a> [<a href="/pdf/2308.11970" title="Download PDF">pdf</a>, <a href="/ps/2308.11970" title="Download PostScript">ps</a>, <a href="/format/2308.11970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing CFI Graphs and Lower Bounds for the Weisfeiler-Leman  Refinements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>, 
<a href="/search/cs?searchtype=author&query=Lichter%2C+M">Moritz Lichter</a>, 
<a href="/search/cs?searchtype=author&query=Neuen%2C+D">Daniel Neuen</a>, 
<a href="/search/cs?searchtype=author&query=Schweitzer%2C+P">Pascal Schweitzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, full version of a paper accepted at FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The $k$-dimensional Weisfeiler-Leman ($k$-WL) algorithm is a simple
combinatorial algorithm that was originally designed as a graph isomorphism
heuristic. It naturally finds applications in Babai's quasipolynomial time
isomorphism algorithm, practical isomorphism solvers, and algebraic graph
theory. However, it also has surprising connections to other areas such as
logic, proof complexity, combinatorial optimization, and machine learning.
<br />The algorithm iteratively computes a coloring of the $k$-tuples of vertices
of a graph. Since F\"urer's linear lower bound [ICALP 2001], it has been an
open question whether there is a super-linear lower bound for the iteration
number for $k$-WL on graphs. We answer this question affirmatively,
establishing an $\Omega(n^{k/2})$-lower bound for all $k$.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11971" title="Abstract">arXiv:2308.11971</a> [<a href="/pdf/2308.11971" title="Download PDF">pdf</a>, <a href="/format/2308.11971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVE: Efficient Vision-Language Pre-training with Masked Prediction and  Modality-Aware MoE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longteng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zehuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Building scalable vision-language models to learn from diverse, multimodal
data remains an open challenge. In this paper, we introduce an Efficient
Vision-languagE foundation model, namely EVE, which is one unified multimodal
Transformer pre-trained solely by one unified pre-training task. Specifically,
EVE encodes both vision and language within a shared Transformer network
integrated with modality-aware sparse Mixture-of-Experts (MoE) modules, which
capture modality-specific information by selectively switching to different
experts. To unify pre-training tasks of vision and language, EVE performs
masked signal modeling on image-text pairs to reconstruct masked signals, i.e.,
image pixels and text tokens, given visible signals. This simple yet effective
pre-training objective accelerates training by 3.5x compared to the model
pre-trained with Image-Text Contrastive and Image-Text Matching losses. Owing
to the combination of the unified architecture and pre-training task, EVE is
easy to scale up, enabling better downstream performance with fewer resources
and faster training speed. Despite its simplicity, EVE achieves
state-of-the-art performance on various vision-language downstream tasks,
including visual question answering, visual reasoning, and image-text
retrieval.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11974" title="Abstract">arXiv:2308.11974</a> [<a href="/pdf/2308.11974" title="Download PDF">pdf</a>, <a href="/format/2308.11974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hyeonseop Song</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seokhun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+H">Hoseok Do</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehyeong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Text-driven localized editing of 3D objects is particularly difficult as
locally mixing the original 3D object with the intended new object and style
effects without distorting the object's form is not a straightforward process.
To address this issue, we propose a novel NeRF-based model, Blending-NeRF,
which consists of two NeRF networks: pretrained NeRF and editable NeRF.
Additionally, we introduce new blending operations that allow Blending-NeRF to
properly edit target regions which are localized by text. By using a pretrained
vision-language aligned model, CLIP, we guide Blending-NeRF to add new objects
with varying colors and densities, modify textures, and remove parts of the
original object. Our extensive experiments demonstrate that Blending-NeRF
produces naturally and locally edited 3D objects from various text prompts.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11975" title="Abstract">arXiv:2308.11975</a> [<a href="/pdf/2308.11975" title="Download PDF">pdf</a>, <a href="/format/2308.11975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Score-based Explanation Techniques Using Conformal  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alkhatib%2C+A">Amr Alkhatib</a>, 
<a href="/search/cs?searchtype=author&query=Bostr%C3%B6m%2C+H">Henrik Bostr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Ennadir%2C+S">Sofiane Ennadir</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+U">Ulf Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures, The 12th Symposium on Conformal and Probabilistic Prediction with Applications (COPA 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of Machine Learning Research (PMLR) Volume 204, Year
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based explainable machine-learning techniques are often used to
understand the logic behind black-box models. However, such explanation
techniques are often computationally expensive, which limits their application
in time-critical contexts. Therefore, we propose and investigate the use of
computationally less costly regression models for approximating the output of
score-based explanation techniques, such as SHAP. Moreover, validity guarantees
for the approximated values are provided by the employed inductive conformal
prediction framework. We propose several non-conformity measures designed to
take the difficulty of approximating the explanations into account while
keeping the computational cost low. We present results from a large-scale
empirical investigation, in which the approximate explanations generated by our
proposed models are evaluated with respect to efficiency (interval size). The
results indicate that the proposed method can significantly improve execution
time compared to the fast version of SHAP, TreeSHAP. The results also suggest
that the proposed method can produce tight intervals, while providing validity
guarantees. Moreover, the proposed approach allows for comparing explanations
of different approximation methods and selecting a method based on how
informative (tight) are the predicted intervals.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11977" title="Abstract">arXiv:2308.11977</a> [<a href="/pdf/2308.11977" title="Download PDF">pdf</a>, <a href="/format/2308.11977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESTA: An Efficient Spatial-Temporal Range Aggregation Query Processing  Algorithm for UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+W">Wenbin Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Youwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wanying Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicle (UAV) networks have been widely used in both military
and civilian scenarios. When users are interested in the statistical
information of the historical sensory data in a certain region during a certain
time period, they will send an aggregation query request with a
spatial-temporal constraint to target UAVs which store the qualified data.
Then, the target UAVs will return the query results to users. Meanwhile, the
query results can be aggregated within the network during transmission to save
energy and bandwidth resources, which are typically scarce in UAV networks.
However, due to the unique characteristics of UAV networks, it is difficult to
perform efficient in-network aggregation of query results without the sacrifice
of the user query delay. To the best of our knowledge, there is no research on
spatial-temporal range aggregation query in UAV networks. In this paper, we
propose an Efficient Spatial-Temporal range Aggregation query processing (ESTA)
algorithm for UAV networks. First, a topology change graph is constructed based
on the pre-planned trajectory information. Meanwhile, an efficient shortest
path algorithm is proposed to obtain the user query delay. Then, on the basis
of ensuring the user query delay, ESTA transforms the aggregation processing of
query results into recursively solving the set cover problem, thereby
constructing a spatial-temporal aggregation tree (STAT), based on which an
efficient in-network aggregation routing path for query results can be found.
Through extensive simulation, we demonstrate that ESTA can save more than 50%
of the energy consumption compared with the baseline algorithm.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11978" title="Abstract">arXiv:2308.11978</a> [<a href="/pdf/2308.11978" title="Download PDF">pdf</a>, <a href="/format/2308.11978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Will More Expressive Graph Neural Networks do Better on Generative  Tasks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xiandong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Machine Learning (stat.ML)

</div>
<p class="mathjax">Graph generation poses a significant challenge as it involves predicting a
complete graph with multiple nodes and edges based on simply a given label.
This task also carries fundamental importance to numerous real-world
applications, including de-novo drug and molecular design. In recent years,
several successful methods have emerged in the field of graph generation.
However, these approaches suffer from two significant shortcomings: (1) the
underlying Graph Neural Network (GNN) architectures used in these methods are
often underexplored; and (2) these methods are often evaluated on only a
limited number of metrics. To fill this gap, we investigate the expressiveness
of GNNs under the context of the molecular graph generation task, by replacing
the underlying GNNs of graph generative models with more expressive GNNs.
Specifically, we analyse the performance of six GNNs in two different
generative frameworks (GCPN and GraphAF), on six different molecular generative
objectives on the ZINC-250k dataset. Through our extensive experiments, we
demonstrate that advanced GNNs can indeed improve the performance of GCPN and
GraphAF on molecular generation tasks, but GNN expressiveness is not a
necessary condition for a good GNN-based generative model. Moreover, we show
that GCPN and GraphAF with advanced GNNs can achieve state-of-the-art results
across 17 other non-GNN-based graph generative approaches, such as variational
autoencoders and Bayesian optimisation models, on the proposed molecular
generative objectives (DRD2, Median1, Median2), which are important metrics for
de-novo molecular design.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11979" title="Abstract">arXiv:2308.11979</a> [<a href="/pdf/2308.11979" title="Download PDF">pdf</a>, <a href="/format/2308.11979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotation-Invariant Completion Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Pengcheng Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, accepted to PRCV 2023 (The 6th Chinese Conference on Pattern Recognition and Computer Vision)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-world point clouds usually suffer from incompleteness and display
different poses. While current point cloud completion methods excel in
reproducing complete point clouds with consistent poses as seen in the training
set, their performance tends to be unsatisfactory when handling point clouds
with diverse poses. We propose a network named Rotation-Invariant Completion
Network (RICNet), which consists of two parts: a Dual Pipeline Completion
Network (DPCNet) and an enhancing module. Firstly, DPCNet generates a coarse
complete point cloud. The feature extraction module of DPCNet can extract
consistent features, no matter if the input point cloud has undergone rotation
or translation. Subsequently, the enhancing module refines the fine-grained
details of the final generated point cloud. RICNet achieves better rotation
invariance in feature extraction and incorporates structural relationships in
man-made objects. To assess the performance of RICNet and existing methods on
point clouds with various poses, we applied random transformations to the point
clouds in the MVP dataset and conducted experiments on them. Our experiments
demonstrate that RICNet exhibits superior completion performance compared to
existing methods.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11981" title="Abstract">arXiv:2308.11981</a> [<a href="/pdf/2308.11981" title="Download PDF">pdf</a>, <a href="/format/2308.11981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Semi-Supervised and Semi-Asynchronous Learning for Anomaly  Detection in IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+W">Wenbin Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Youwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wanying Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Existing FL-based approaches are based on the unrealistic assumption that the
data on the client-side is fully annotated with ground truths. Furthermore, it
is a great challenge how to improve the training efficiency while ensuring the
detection accuracy in the highly heterogeneous and resource-constrained IoT
networks. Meanwhile, the communication cost between clients and the server is
also a problem that can not be ignored. Therefore, in this paper, we propose a
Federated Semi-Supervised and Semi-Asynchronous (FedS3A) learning for anomaly
detection in IoT networks. First, we consider a more realistic assumption that
labeled data is only available at the server, and pseudo-labeling is utilized
to implement federated semi-supervised learning, in which a dynamic weight of
supervised learning is exploited to balance the supervised learning at the
server and unsupervised learning at clients. Then, we propose a
semi-asynchronous model update and staleness tolerant distribution scheme to
achieve a trade-off between the round efficiency and detection accuracy.
Meanwhile, the staleness of local models and the participation frequency of
clients are considered to adjust their contributions to the global model. In
addition, a group-based aggregation function is proposed to deal with the
non-IID distribution of the data. Finally, the difference transmission based on
the sparse matrix is adopted to reduce the communication cost. Extensive
experimental results show that FedS3A can achieve greater than 98% accuracy
even when the data is non-IID and is superior to the classic FL-based
algorithms in terms of both detection performance and round efficiency,
achieving a win-win situation. Meanwhile, FedS3A successfully reduces the
communication cost by higher than 50%.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11983" title="Abstract">arXiv:2308.11983</a> [<a href="/pdf/2308.11983" title="Download PDF">pdf</a>, <a href="/format/2308.11983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Multi-Task (3MT) Road Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milli%2C+E">Erkan Milli</a>, 
<a href="/search/cs?searchtype=author&query=Erkent%2C+%C3%96">&#xd6;zg&#xfc;r Erkent</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1lmaz%2C+A+E">As&#x131;m Egemen Y&#x131;lmaz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Robotics and Automation Letters, vol. 8, no. 9, pp.
  5408-5415, Sept. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-modal systems have the capacity of producing more reliable results than
systems with a single modality in road detection due to perceiving different
aspects of the scene. We focus on using raw sensor inputs instead of, as it is
typically done in many SOTA works, leveraging architectures that require high
pre-processing costs such as surface normals or dense depth predictions. By
using raw sensor inputs, we aim to utilize a low-cost model thatminimizes both
the pre-processing andmodel computation costs. This study presents a
cost-effective and highly accurate solution for road segmentation by
integrating data from multiple sensorswithin a multi-task learning
architecture.Afusion architecture is proposed in which RGB and LiDAR depth
images constitute the inputs of the network. Another contribution of this study
is to use IMU/GNSS (inertial measurement unit/global navigation satellite
system) inertial navigation system whose data is collected synchronously and
calibrated with a LiDAR-camera to compute aggregated dense LiDAR depth images.
It has been demonstrated by experiments on the KITTI dataset that the proposed
method offers fast and high-performance solutions. We have also shown the
performance of our method on Cityscapes where raw LiDAR data is not available.
The segmentation results obtained for both full and half resolution images are
competitive with existing methods. Therefore, we conclude that our method is
not dependent only on raw LiDAR data; rather, it can be used with different
sensor modalities. The inference times obtained in all experiments are very
promising for real-time experiments.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11985" title="Abstract">arXiv:2308.11985</a> [<a href="/pdf/2308.11985" title="Download PDF">pdf</a>, <a href="/format/2308.11985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSSP: A Distributed, SLO-aware, Sensing-domain-privacy-Preserving  Architecture for Sensing-as-a-Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Rosenkrantz%2C+T">Todd Rosenkrantz</a>, 
<a href="/search/cs?searchtype=author&query=Enganti%2C+P">Prathyusha Enganti</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+H">Hao Che</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xukai Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">In this paper, we propose DSSP, a Distributed, SLO-aware,
Sensing-domain-privacy-Preserving architecture for Sensing-as-a-Service (SaS).
DSSP addresses four major limitations of the current SaS architecture. First,
to improve sensing quality and enhance geographic coverage, DSSP allows
Independent sensing Administrative Domains (IADs) to participate in sensing
services, while preserving the autonomy of control and privacy for individual
domains. Second, DSSP enables a marketplace in which a sensing data seller
(i.e., an IAD) can sell its sensing data to more than one buyer (i.e., cloud
service provider (CSP)), rather than being locked in with just one CSP. Third,
DSSP enables per-query tail-latency service-level-objective (SLO) guaranteed
SaS. Fourth, DSSP enables distributed, rather than centralized, query
scheduling, making SaS highly scalable. At the core of DSSP is the design of a
budget decomposition technique that translates: (a) a query tail-latency SLO
into exact task response time budgets for sensing tasks of the query dispatched
to individual IADs; and (b) the task budget for a task arrived at an IAD into
exact subtask queuing deadlines for subtasks of the task dispatched to
individual edge nodes in each IAD. This enables IADs to allocate their internal
resources independently and accurately to meet the task budgets and hence,
query tail-latency SLO, based on a simple subtask-budget-aware
earliest-deadline-first queuing (EDFQ) policy for all the subtasks. The
performance and scalability of DSSP are evaluated and verified by both
on-campus testbed experiment at small scale and simulation at large scale.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11990" title="Abstract">arXiv:2308.11990</a> [<a href="/pdf/2308.11990" title="Download PDF">pdf</a>, <a href="/format/2308.11990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankMixup: Ranking-Based Mixup Training for Network Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noh%2C+J">Jongyoun Noh</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyekang Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junghyup Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+B">Bumsub Ham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Network calibration aims to accurately estimate the level of confidences,
which is particularly important for employing deep neural networks in
real-world systems. Recent approaches leverage mixup to calibrate the network's
predictions during training. However, they do not consider the problem that
mixtures of labels in mixup may not accurately represent the actual
distribution of augmented samples. In this paper, we present RankMixup, a novel
mixup-based framework alleviating the problem of the mixture of labels for
network calibration. To this end, we propose to use an ordinal ranking
relationship between raw and mixup-augmented samples as an alternative
supervisory signal to the label mixtures for network calibration. We
hypothesize that the network should estimate a higher level of confidence for
the raw samples than the augmented ones (Fig.1). To implement this idea, we
introduce a mixup-based ranking loss (MRL) that encourages lower confidences
for augmented samples compared to raw ones, maintaining the ranking
relationship. We also propose to leverage the ranking relationship among
multiple mixup-augmented samples to further improve the calibration capability.
Augmented samples with larger mixing coefficients are expected to have higher
confidences and vice versa (Fig.1). That is, the order of confidences should be
aligned with that of mixing coefficients. To this end, we introduce a novel
loss, M-NDCG, in order to reduce the number of misaligned pairs of the
coefficients and confidences. Extensive experimental results on standard
benchmarks for network calibration demonstrate the effectiveness of RankMixup.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11991" title="Abstract">arXiv:2308.11991</a> [<a href="/pdf/2308.11991" title="Download PDF">pdf</a>, <a href="/format/2308.11991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relational Concept Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/cs?searchtype=author&query=Giannini%2C+F">Francesco Giannini</a>, 
<a href="/search/cs?searchtype=author&query=Ciravegna%2C+G">Gabriele Ciravegna</a>, 
<a href="/search/cs?searchtype=author&query=Diligenti%2C+M">Michelangelo Diligenti</a>, 
<a href="/search/cs?searchtype=author&query=Marra%2C+G">Giuseppe Marra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The design of interpretable deep learning models working in relational
domains poses an open challenge: interpretable deep learning methods, such as
Concept-Based Models (CBMs), are not designed to solve relational problems,
while relational models are not as interpretable as CBMs. To address this
problem, we propose Relational Concept-Based Models, a family of relational
deep learning methods providing interpretable task predictions. Our
experiments, ranging from image classification to link prediction in knowledge
graphs, show that relational CBMs (i) match generalization performance of
existing relational black-boxes (as opposed to non-relational CBMs), (ii)
support the generation of quantified concept-based explanations, (iii)
effectively respond to test-time interventions, and (iv) withstand demanding
settings including out-of-distribution scenarios, limited training data
regimes, and scarce concept supervisions.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11994" title="Abstract">arXiv:2308.11994</a> [<a href="/pdf/2308.11994" title="Download PDF">pdf</a>, <a href="/format/2308.11994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Feature Mining and External Knowledge-Assisted  Text-Pedestrian Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shedan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-Pedestrian Image Retrieval aims to use the text describing pedestrian
appearance to retrieve the corresponding pedestrian image. This task involves
not only modality discrepancy, but also the challenge of the textual diversity
of pedestrians with the same identity. At present, although existing research
progress has been made in text-pedestrian image retrieval, these methods do not
comprehensively consider the above-mentioned problems. Considering these, this
paper proposes a progressive feature mining and external knowledge-assisted
feature purification method. Specifically, we use a progressive mining mode to
enable the model to mine discriminative features from neglected information,
thereby avoiding the loss of discriminative information and improving the
expression ability of features. In addition, to further reduce the negative
impact of modal discrepancy and text diversity on cross-modal matching, we
propose to use other sample knowledge of the same modality, i.e., external
knowledge to enhance identity-consistent features and weaken
identity-inconsistent features. This process purifies features and alleviates
the interference caused by textual diversity and negative sample correlation
features of the same modal. Extensive experiments on three challenging datasets
demonstrate the effectiveness and superiority of the proposed method, and the
retrieval performance even surpasses that of the large-scale model-based method
on large-scale datasets.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11995" title="Abstract">arXiv:2308.11995</a> [<a href="/pdf/2308.11995" title="Download PDF">pdf</a>, <a href="/format/2308.11995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Karthik Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Hedayatnia%2C+B">Behnam Hedayatnia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinlang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gottardi%2C+A">Anna Gottardi</a>, 
<a href="/search/cs?searchtype=author&query=Kwatra%2C+S">Sanjeev Kwatra</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+A">Anu Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+R">Raefer Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Hakkani-Tur%2C+D">Dilek Hakkani-Tur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiving an old paper accepted at INTERSPEECH 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Building socialbots that can have deep, engaging open-domain conversations
with humans is one of the grand challenges of artificial intelligence (AI). To
this end, bots need to be able to leverage world knowledge spanning several
domains effectively when conversing with humans who have their own world
knowledge. Existing knowledge-grounded conversation datasets are primarily
stylized with explicit roles for conversation partners. These datasets also do
not explore depth or breadth of topical coverage with transitions in
conversations. We introduce Topical-Chat, a knowledge-grounded human-human
conversation dataset where the underlying knowledge spans 8 broad topics and
conversation partners don't have explicitly defined roles, to help further
research in open-domain conversational AI. We also train several
state-of-the-art encoder-decoder conversational models on Topical-Chat and
perform automated and human evaluation for benchmarking.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11998" title="Abstract">arXiv:2308.11998</a> [<a href="/pdf/2308.11998" title="Download PDF">pdf</a>, <a href="/format/2308.11998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Economic Recommender Systems -- A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Biasio%2C+A">Alvise De Biasio</a>, 
<a href="/search/cs?searchtype=author&query=Navarin%2C+N">Nicol&#xf2; Navarin</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Many of today's online services provide personalized recommendations to their
users. Such recommendations are typically designed to serve certain user needs,
e.g., to quickly find relevant content in situations of information overload.
Correspondingly, the academic literature in the field largely focuses on the
value of recommender systems for the end user. In this context, one underlying
assumption is that the improved service that is achieved through the
recommendations will in turn positively impact the organization's goals, e.g.,
in the form of higher customer retention or loyalty. However, in reality,
recommender systems can be used to target organizational economic goals more
directly by incorporating monetary considerations such as price awareness and
profitability aspects into the underlying recommendation models. In this work,
we survey the existing literature on what we call Economic Recommender Systems
based on a systematic review approach that helped us identify 133 relevant
papers. We first categorize existing works along different dimensions and then
review the most important technical approaches from the literature.
Furthermore, we discuss common methodologies to evaluate such systems and
finally outline the limitations of today's research and future directions.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12001" title="Abstract">arXiv:2308.12001</a> [<a href="/pdf/2308.12001" title="Download PDF">pdf</a>, <a href="/format/2308.12001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Distortion Aware Efficient Transformer Adaptation for Image  Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kangmin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image Quality Assessment (IQA) constitutes a fundamental task within the
field of computer vision, yet it remains an unresolved challenge, owing to the
intricate distortion conditions, diverse image contents, and limited
availability of data. Recently, the community has witnessed the emergence of
numerous large-scale pretrained foundation models, which greatly benefit from
dramatically increased data and parameter capacities. However, it remains an
open problem whether the scaling law in high-level tasks is also applicable to
IQA task which is closely related to low-level clues. In this paper, we
demonstrate that with proper injection of local distortion features, a larger
pretrained and fixed foundation model performs better in IQA tasks.
Specifically, for the lack of local distortion structure and inductive bias of
vision transformer (ViT), alongside the large-scale pretrained ViT, we use
another pretrained convolution neural network (CNN), which is well known for
capturing the local structure, to extract multi-scale image features. Further,
we propose a local distortion extractor to obtain local distortion features
from the pretrained CNN and a local distortion injector to inject the local
distortion features into ViT. By only training the extractor and injector, our
method can benefit from the rich knowledge in the powerful foundation models
and achieve state-of-the-art performance on popular IQA datasets, indicating
that IQA is not only a low-level problem but also benefits from stronger
high-level features drawn from large-scale pretrained models.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12002" title="Abstract">arXiv:2308.12002</a> [<a href="/pdf/2308.12002" title="Download PDF">pdf</a>, <a href="/format/2308.12002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural oscillators for magnetic hysteresis modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandra%2C+A">Abhishek Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+T">Taniya Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Daniels%2C+B">Bram Daniels</a>, 
<a href="/search/cs?searchtype=author&query=Curti%2C+M">Mitrofan Curti</a>, 
<a href="/search/cs?searchtype=author&query=Tiels%2C+K">Koen Tiels</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+D+M">Daniel M. Tartakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Lomonova%2C+E+A">Elena A. Lomonova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Hysteresis is a ubiquitous phenomenon in science and engineering; its
modeling and identification are crucial for understanding and optimizing the
behavior of various systems. We develop an ordinary differential equation-based
recurrent neural network (RNN) approach to model and quantify the hysteresis,
which manifests itself in sequentiality and history-dependence. Our neural
oscillator, HystRNN, draws inspiration from coupled-oscillatory RNN and
phenomenological hysteresis models to update the hidden states. The performance
of HystRNN is evaluated to predict generalized scenarios, involving first-order
reversal curves and minor loops. The findings show the ability of HystRNN to
generalize its behavior to previously untrained regions, an essential feature
that hysteresis models must have. This research highlights the advantage of
neural oscillators over the traditional RNN-based methods in capturing complex
hysteresis patterns in magnetic materials, where traditional rate-dependent
methods are inadequate to capture intrinsic nonlinearity.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12006" title="Abstract">arXiv:2308.12006</a> [<a href="/pdf/2308.12006" title="Download PDF">pdf</a>, <a href="/format/2308.12006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stage Factorized Spatio-Temporal Representation for RGB-D Action  and Gesture Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yujun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Benjia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pichao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM'23 has accepted this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGB-D action and gesture recognition remain an interesting topic in
human-centered scene understanding, primarily due to the multiple granularities
and large variation in human motion. Although many RGB-D based action and
gesture recognition approaches have demonstrated remarkable results by
utilizing highly integrated spatio-temporal representations across multiple
modalities (i.e., RGB and depth data), they still encounter several challenges.
Firstly, vanilla 3D convolution makes it hard to capture fine-grained motion
differences between local clips under different modalities. Secondly, the
intricate nature of highly integrated spatio-temporal modeling can lead to
optimization difficulties. Thirdly, duplicate and unnecessary information can
add complexity and complicate entangled spatio-temporal modeling. To address
the above issues, we propose an innovative heuristic architecture called
Multi-stage Factorized Spatio-Temporal (MFST) for RGB-D action and gesture
recognition. The proposed MFST model comprises a 3D Central Difference
Convolution Stem (CDC-Stem) module and multiple factorized spatio-temporal
stages. The CDC-Stem enriches fine-grained temporal perception, and the
multiple hierarchical spatio-temporal stages construct dimension-independent
higher-order semantic primitives. Specifically, the CDC-Stem module captures
bottom-level spatio-temporal features and passes them successively to the
following spatio-temporal factored stages to capture the hierarchical spatial
and temporal features through the Multi- Scale Convolution and Transformer
(MSC-Trans) hybrid block and Weight-shared Multi-Scale Transformer (WMS-Trans)
block. The seamless integration of these innovative designs results in a robust
spatio-temporal representation that outperforms state-of-the-art approaches on
RGB-D action and gesture recognition datasets.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12008" title="Abstract">arXiv:2308.12008</a> [<a href="/pdf/2308.12008" title="Download PDF">pdf</a>, <a href="/format/2308.12008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graecia capta ferum victorem cepit. Detecting Latin Allusions to Ancient  Greek Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riemenschneider%2C+F">Frederick Riemenschneider</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted for publication at the First Workshop on Ancient Language Processing (ALP) 2023; 9 pages, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Intertextual allusions hold a pivotal role in Classical Philology, with Latin
authors frequently referencing Ancient Greek texts. Until now, the automatic
identification of these intertextual references has been constrained to
monolingual approaches, seeking parallels solely within Latin or Greek texts.
In this study, we introduce SPhilBERTa, a trilingual Sentence-RoBERTa model
tailored for Classical Philology, which excels at cross-lingual semantic
comprehension and identification of identical sentences across Ancient Greek,
Latin, and English. We generate new training data by automatically translating
English texts into Ancient Greek. Further, we present a case study,
demonstrating SPhilBERTa's capability to facilitate automated detection of
intertextual parallels. Our models and resources are available at
https://github.com/Heidelberg-NLP/ancient-language-models.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12009" title="Abstract">arXiv:2308.12009</a> [<a href="/pdf/2308.12009" title="Download PDF">pdf</a>, <a href="/format/2308.12009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StofNet: Super-resolution Time of Flight Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahne%2C+C">Christopher Hahne</a>, 
<a href="/search/cs?searchtype=author&query=Hayoz%2C+M">Michel Hayoz</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Time of Flight (ToF) is a prevalent depth sensing technology in the fields of
robotics, medical imaging, and non-destructive testing. Yet, ToF sensing faces
challenges from complex ambient conditions making an inverse modelling from the
sparse temporal information intractable. This paper highlights the potential of
modern super-resolution techniques to learn varying surroundings for a reliable
and accurate ToF detection. Unlike existing models, we tailor an architecture
for sub-sample precise semi-global signal localization by combining
super-resolution with an efficient residual contraction block to balance
between fine signal details and large scale contextual information. We
consolidate research on ToF by conducting a benchmark comparison against six
state-of-the-art methods for which we employ two publicly available datasets.
This includes the release of our SToF-Chirp dataset captured by an airborne
ultrasound transducer. Results showcase the superior performance of our
proposed StofNet in terms of precision, reliability and model complexity. Our
code is available at https://github.com/hahnec/stofnet.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12014" title="Abstract">arXiv:2308.12014</a> [<a href="/pdf/2308.12014" title="Download PDF">pdf</a>, <a href="/format/2308.12014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Instructions to Intrinsic Human Values -- A Survey of Alignment  Goals for Big Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Big models, exemplified by Large Language Models (LLMs), are models typically
pre-trained on massive data and comprised of enormous parameters, which not
only obtain significantly improved performance across diverse tasks but also
present emergent capabilities absent in smaller models. However, the growing
intertwining of big models with everyday human lives poses potential risks and
might cause serious social harm. Therefore, many efforts have been made to
align LLMs with humans to make them better follow user instructions and satisfy
human preferences. Nevertheless, `what to align with' has not been fully
discussed, and inappropriate alignment goals might even backfire. In this
paper, we conduct a comprehensive survey of different alignment goals in
existing work and trace their evolution paths to help identify the most
essential goal. Particularly, we investigate related works from two
perspectives: the definition of alignment goals and alignment evaluation. Our
analysis encompasses three distinct levels of alignment goals and reveals a
goal transformation from fundamental abilities to value orientation, indicating
the potential of intrinsic human values as the alignment goal for enhanced
LLMs. Based on such results, we further discuss the challenges of achieving
such intrinsic value alignment and provide a collection of available resources
for future research on the alignment of big models.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12017" title="Abstract">arXiv:2308.12017</a> [<a href="/pdf/2308.12017" title="Download PDF">pdf</a>, <a href="/format/2308.12017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Aware Calibration for Object Detection with Noisy Bounding  Boxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Donghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bin-Bin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale well-annotated datasets are of great importance for training an
effective object detector. However, obtaining accurate bounding box annotations
is laborious and demanding. Unfortunately, the resultant noisy bounding boxes
could cause corrupt supervision signals and thus diminish detection
performance. Motivated by the observation that the real ground-truth is usually
situated in the aggregation region of the proposals assigned to a noisy
ground-truth, we propose DIStribution-aware CalibratiOn (DISCO) to model the
spatial distribution of proposals for calibrating supervision signals. In
DISCO, spatial distribution modeling is performed to statistically extract the
potential locations of objects. Based on the modeled distribution, three
distribution-aware techniques, i.e., distribution-aware proposal augmentation
(DA-Aug), distribution-aware box refinement (DA-Ref), and distribution-aware
confidence estimation (DA-Est), are developed to improve classification,
localization, and interpretability, respectively. Extensive experiments on
large-scale noisy image datasets (i.e., Pascal VOC and MS-COCO) demonstrate
that DISCO can achieve state-of-the-art detection performance, especially at
high noise levels.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12018" title="Abstract">arXiv:2308.12018</a> [<a href="/pdf/2308.12018" title="Download PDF">pdf</a>, <a href="/format/2308.12018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-Aware Minimisation: Understanding and Mitigating Estimator Bias in  Private SGD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knolle%2C+M">Moritz Knolle</a>, 
<a href="/search/cs?searchtype=author&query=Dorfman%2C+R">Robert Dorfman</a>, 
<a href="/search/cs?searchtype=author&query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Theory and Practice of Differential Privacy (TPDP) Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differentially private SGD (DP-SGD) holds the promise of enabling the safe
and responsible application of machine learning to sensitive datasets. However,
DP-SGD only provides a biased, noisy estimate of a mini-batch gradient. This
renders optimisation steps less effective and limits model utility as a result.
With this work, we show a connection between per-sample gradient norms and the
estimation bias of the private gradient oracle used in DP-SGD. Here, we propose
Bias-Aware Minimisation (BAM) that allows for the provable reduction of private
gradient estimator bias. We show how to efficiently compute quantities needed
for BAM to scale to large neural networks and highlight similarities to closely
related methods such as Sharpness-Aware Minimisation. Finally, we provide
empirical evidence that BAM not only reduces bias but also substantially
improves privacy-utility trade-offs on the CIFAR-10, CIFAR-100, and ImageNet-32
datasets.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12021" title="Abstract">arXiv:2308.12021</a> [<a href="/pdf/2308.12021" title="Download PDF">pdf</a>, <a href="/format/2308.12021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARC: Multipolicy and Risk-aware Contingency Planning for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sikang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Generating safe and non-conservative behaviors in dense, dynamic environments
remains challenging for automated vehicles due to the stochastic nature of
traffic participants' behaviors and their implicit interaction with the ego
vehicle. This paper presents a novel planning framework, Multipolicy And
Risk-aware Contingency planning (MARC), that systematically addresses these
challenges by enhancing the multipolicy-based pipelines from both behavior and
motion planning aspects. Specifically, MARC realizes a critical scenario set
that reflects multiple possible futures conditioned on each semantic-level ego
policy. Then, the generated policy-conditioned scenarios are further formulated
into a tree-structured representation with a dynamic branchpoint based on the
scene-level divergence. Moreover, to generate diverse driving maneuvers, we
introduce risk-aware contingency planning, a bi-level optimization algorithm
that simultaneously considers multiple future scenarios and user-defined risk
tolerance levels. Owing to the more unified combination of behavior and motion
planning layers, our framework achieves efficient decision-making and
human-like driving maneuvers. Comprehensive experimental results demonstrate
superior performance to other strong baselines in various environments.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12022" title="Abstract">arXiv:2308.12022</a> [<a href="/pdf/2308.12022" title="Download PDF">pdf</a>, <a href="/format/2308.12022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reranking Passages with Coarse-to-Fine Neural Retriever using  List-Context Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Passage reranking is a crucial task in many applications, particularly when
dealing with large-scale documents. Traditional neural architectures are
limited in retrieving the best passage for a question because they usually
match the question to each passage separately, seldom considering contextual
information in other passages that can provide comparison and reference
information. This paper presents a list-context attention mechanism to augment
the passage representation by incorporating the list-context information from
other candidates. The proposed coarse-to-fine (C2F) neural retriever addresses
the out-of-memory limitation of the passage attention mechanism by dividing the
list-context modeling process into two sub-processes, allowing for efficient
encoding of context information from a large number of candidate answers. This
method can be generally used to encode context information from any number of
candidate answers in one pass. Different from most multi-stage information
retrieval architectures, this model integrates the coarse and fine rankers into
the joint optimization process, allowing for feedback between the two layers to
update the model simultaneously. Experiments demonstrate the effectiveness of
the proposed approach.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12025" title="Abstract">arXiv:2308.12025</a> [<a href="/pdf/2308.12025" title="Download PDF">pdf</a>, <a href="/format/2308.12025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-injected Prompt Learning for Chinese Biomedical Entity  Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songhua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuxiang Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Biomedical Entity Normalization (BEN) task aims to align raw,
unstructured medical entities to standard entities, thus promoting data
coherence and facilitating better downstream medical applications. Recently,
prompt learning methods have shown promising results in this task. However,
existing research falls short in tackling the more complex Chinese BEN task,
especially in the few-shot scenario with limited medical data, and the vast
potential of the external medical knowledge base has yet to be fully harnessed.
To address these challenges, we propose a novel Knowledge-injected Prompt
Learning (PL-Knowledge) method. Specifically, our approach consists of five
stages: candidate entity matching, knowledge extraction, knowledge encoding,
knowledge injection, and prediction output. By effectively encoding the
knowledge items contained in medical entities and incorporating them into our
tailor-made knowledge-injected templates, the additional knowledge enhances the
model's ability to capture latent relationships between medical entities, thus
achieving a better match with the standard entities. We extensively evaluate
our model on a benchmark dataset in both few-shot and full-scale scenarios. Our
method outperforms existing baselines, with an average accuracy boost of
12.96\% in few-shot and 0.94\% in full-data cases, showcasing its excellence in
the BEN task.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12028" title="Abstract">arXiv:2308.12028</a> [<a href="/pdf/2308.12028" title="Download PDF">pdf</a>, <a href="/format/2308.12028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LKPNR: LLM and KG for Personalized News Recommendation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=hao%2C+C">Chen hao</a>, 
<a href="/search/cs?searchtype=author&query=Runfeng%2C+X">Xie Runfeng</a>, 
<a href="/search/cs?searchtype=author&query=Xiangyang%2C+C">Cui Xiangyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+W">Wang Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhanwei%2C+X">Xuan Zhanwei</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+Z">Zhang Kai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurately recommending candidate news articles to users is a basic challenge
faced by personalized news recommendation systems. Traditional methods are
usually difficult to grasp the complex semantic information in news texts,
resulting in unsatisfactory recommendation results. Besides, these traditional
methods are more friendly to active users with rich historical behaviors.
However, they can not effectively solve the "long tail problem" of inactive
users. To address these issues, this research presents a novel general
framework that combines Large Language Models (LLM) and Knowledge Graphs (KG)
into semantic representations of traditional methods. In order to improve
semantic understanding in complex news texts, we use LLMs' powerful text
understanding ability to generate news representations containing rich semantic
information. In addition, our method combines the information about news
entities and mines high-order structural information through multiple hops in
KG, thus alleviating the challenge of long tail distribution. Experimental
results demonstrate that compared with various traditional models, the
framework significantly improves the recommendation effect. The successful
integration of LLM and KG in our framework has established a feasible path for
achieving more accurate personalized recommendations in the news field. Our
code is available at https://github.com/Xuan-ZW/LKPNR.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12029" title="Abstract">arXiv:2308.12029</a> [<a href="/pdf/2308.12029" title="Download PDF">pdf</a>, <a href="/format/2308.12029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scale-Invariant Task Balancing Approach for Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Baijiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weisen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Feiyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-task learning (MTL), a learning paradigm to learn multiple related
tasks simultaneously, has achieved great success in various fields. However,
task-balancing remains a significant challenge in MTL, with the disparity in
loss/gradient scales often leading to performance compromises. In this paper,
we propose a Scale-Invariant Multi-Task Learning (SI-MTL) method to alleviate
the task-balancing problem from both loss and gradient perspectives.
Specifically, SI-MTL contains a logarithm transformation which is performed on
all task losses to ensure scale-invariant at the loss level, and a gradient
balancing method, SI-G, which normalizes all task gradients to the same
magnitude as the maximum gradient norm. Extensive experiments conducted on
several benchmark datasets consistently demonstrate the effectiveness of SI-G
and the state-of-the-art performance of SI-MTL.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12030" title="Abstract">arXiv:2308.12030</a> [<a href="/pdf/2308.12030" title="Download PDF">pdf</a>, <a href="/format/2308.12030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Based Length Controlled Generation with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jie%2C+R">Renlong Jie</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiaojun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, large language models (LLMs) like ChatGPT and GPT-4 have attracted
great attention given their surprising improvement and performance. Length
controlled generation of LLMs emerges as an important topic, which also enables
users to fully leverage the capability of LLMs in more real-world scenarios
like generating a proper answer or essay of a desired length. In addition, the
autoregressive generation in LLMs is extremely time-consuming, while the
ability of controlling this generated length can arbitrarily reduce the
inference cost by limiting the length, and thus satisfy different needs.
Therefore, we aim to propose a prompt-based length control method to achieve
this length controlled generation, which can also be widely applied in
GPT-style LLMs. In particular, we adopt reinforcement learning with the reward
signal given by either trainable or rule-based reward model, which further
affects the generation of LLMs via rewarding a pre-defined target length.
Experiments show that our method significantly improves the accuracy of
prompt-based length control for summarization task on popular datasets like
CNNDM and NYT. We believe this length-controllable ability can provide more
potentials towards the era of LLMs.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12031" title="Abstract">arXiv:2308.12031</a> [<a href="/pdf/2308.12031" title="Download PDF">pdf</a>, <a href="/format/2308.12031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CACTUS: a Comprehensive Abstraction and Classification Tool for  Uncovering Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gherardini%2C+L">Luca Gherardini</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+V+R">Varun Ravi Varma</a>, 
<a href="/search/cs?searchtype=author&query=Capala%2C+K">Karol Capala</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+R">Roger Woods</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+J">Jose Sousa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The availability of large data sets is providing an impetus for driving
current artificial intelligent developments. There are, however, challenges for
developing solutions with small data sets due to practical and cost-effective
deployment and the opacity of deep learning models. The Comprehensive
Abstraction and Classification Tool for Uncovering Structures called CACTUS is
presented for improved secure analytics by effectively employing explainable
artificial intelligence. It provides additional support for categorical
attributes, preserving their original meaning, optimising memory usage, and
speeding up the computation through parallelisation. It shows to the user the
frequency of the attributes in each class and ranks them by their
discriminative power. Its performance is assessed by application to the
Wisconsin diagnostic breast cancer and Thyroid0387 data sets.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12032" title="Abstract">arXiv:2308.12032</a> [<a href="/pdf/2308.12032" title="Download PDF">pdf</a>, <a href="/format/2308.12032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Quantity to Quality: Boosting LLM Performance with Self-Guided Data  Selection for Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the realm of Large Language Models, the balance between instruction data
quality and quantity has become a focal point. Recognizing this, we introduce a
self-guided methodology for LLMs to autonomously discern and select cherry
samples from vast open-source datasets, effectively minimizing manual curation
and potential cost for instruction tuning an LLM. Our key innovation, the
Instruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to
identify discrepancies between a model's expected responses and its autonomous
generation prowess. Through the adept application of IFD, cherry samples are
pinpointed, leading to a marked uptick in model training efficiency. Empirical
validations on renowned datasets like Alpaca and WizardLM underpin our
findings; with a mere 10% of conventional data input, our strategy showcases
improved results. This synthesis of self-guided cherry-picking and the IFD
metric signifies a transformative leap in the optimization of LLMs, promising
both efficiency and resource-conscious advancements.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12033" title="Abstract">arXiv:2308.12033</a> [<a href="/pdf/2308.12033" title="Download PDF">pdf</a>, <a href="/format/2308.12033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PREFER: Prompt Ensemble Learning via Feedback-Reflect-Refine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingchen Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As an effective tool for eliciting the power of Large Language Models (LLMs),
prompting has recently demonstrated unprecedented abilities across a variety of
complex tasks. To further improve the performance, prompt ensemble has
attracted substantial interest for tackling the hallucination and instability
of LLMs. However, existing methods usually adopt a two-stage paradigm, which
requires a pre-prepared set of prompts with substantial manual effort, and is
unable to perform directed optimization for different weak learners. In this
paper, we propose a simple, universal, and automatic method named PREFER (Pompt
Ensemble learning via Feedback-Reflect-Refine) to address the stated
limitations. Specifically, given the fact that weak learners are supposed to
focus on hard examples during boosting, PREFER builds a feedback mechanism for
reflecting on the inadequacies of existing weak learners. Based on this, the
LLM is required to automatically synthesize new prompts for iterative
refinement. Moreover, to enhance stability of the prompt effect evaluation, we
propose a novel prompt bagging method involving forward and backward thinking,
which is superior to majority voting and is beneficial for both feedback and
weight calculation in boosting. Extensive experiments demonstrate that our
PREFER achieves state-of-the-art performance in multiple types of tasks by a
significant margin. We have made our code publicly available.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12035" title="Abstract">arXiv:2308.12035</a> [<a href="/pdf/2308.12035" title="Download PDF">pdf</a>, <a href="/format/2308.12035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RefEgo: Referring Expression Comprehension Dataset from First-Person  Perception of Ego4D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurita%2C+S">Shuhei Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Katsura%2C+N">Naoki Katsura</a>, 
<a href="/search/cs?searchtype=author&query=Onami%2C+E">Eri Onami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures. ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Grounding textual expressions on scene objects from first-person views is a
truly demanding capability in developing agents that are aware of their
surroundings and behave following intuitive text instructions. Such capability
is of necessity for glass-devices or autonomous robots to localize referred
objects in the real-world. In the conventional referring expression
comprehension tasks of images, however, datasets are mostly constructed based
on the web-crawled data and don't reflect diverse real-world structures on the
task of grounding textual expressions in diverse objects in the real world.
Recently, a massive-scale egocentric video dataset of Ego4D was proposed. Ego4D
covers around the world diverse real-world scenes including numerous indoor and
outdoor situations such as shopping, cooking, walking, talking, manufacturing,
etc. Based on egocentric videos of Ego4D, we constructed a broad coverage of
the video-based referring expression comprehension dataset: RefEgo. Our dataset
includes more than 12k video clips and 41 hours for video-based referring
expression comprehension annotation. In experiments, we combine the
state-of-the-art 2D referring expression comprehension models with the object
tracking algorithm, achieving the video-wise referred object tracking even in
difficult conditions: the referred object becomes out-of-frame in the middle of
the video or multiple similar objects are presented in the video.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12038" title="Abstract">arXiv:2308.12038</a> [<a href="/pdf/2308.12038" title="Download PDF">pdf</a>, <a href="/format/2308.12038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Multilingual Models Pivot Zero-Shot Multimodal Learning across  Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yinxu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dahai Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/OpenBMB/VisCPM.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently there has been a significant surge in multimodal learning in terms
of both image-to-text and text-to-image generation. However, the success is
typically limited to English, leaving other languages largely behind. Building
a competitive counterpart in other languages is highly challenging due to the
low-resource nature of non-English multimodal data (i.e., lack of large-scale,
high-quality image-text data). In this work, we propose MPM, an effective
training paradigm for training large multimodal models in low-resource
languages. MPM demonstrates that Multilingual language models can Pivot
zero-shot Multimodal learning across languages. Specifically, based on a strong
multilingual large language model, multimodal models pretrained on English-only
image-text data can well generalize to other languages in a zero-shot manner
for both image-to-text and text-to-image generation, even surpassing models
trained on image-text data in native languages. Taking Chinese as a practice of
MPM, we build large multimodal models VisCPM in image-to-text and text-to-image
generation, which achieve state-of-the-art (open-source) performance in
Chinese. To facilitate future research, we open-source codes and model weights
at https://github.com/OpenBMB/VisCPM.git.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12039" title="Abstract">arXiv:2308.12039</a> [<a href="/pdf/2308.12039" title="Download PDF">pdf</a>, <a href="/format/2308.12039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Retrieval and Multi-stage Text Ranking Solution at TREC 2022 Deep  Learning Track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yangzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+D">Dingkun Long</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruijie Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TREC 2022 Deep Learning Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large-scale text retrieval technology has been widely used in various
practical business scenarios. This paper presents our systems for the TREC 2022
Deep Learning Track. We explain the hybrid text retrieval and multi-stage text
ranking method adopted in our solution. The retrieval stage combined the two
structures of traditional sparse retrieval and neural dense retrieval. In the
ranking stage, in addition to the full interaction-based ranking model built on
large pre-trained language model, we also proposes a lightweight sub-ranking
module to further enhance the final text ranking performance. Evaluation
results demonstrate the effectiveness of our proposed approach. Our models
achieve the 1st and 4th rank on the test set of passage ranking and document
ranking respectively.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12043" title="Abstract">arXiv:2308.12043</a> [<a href="/pdf/2308.12043" title="Download PDF">pdf</a>, <a href="/format/2308.12043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IncreLoRA: Incremental Parameter Allocation Method for  Parameter-Efficient Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhouqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yiming Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the increasing size of pre-trained language models (PLMs), fine-tuning
all the parameters in the model is not efficient, especially when there are a
large number of downstream tasks, which incur significant training and storage
costs. Many parameter-efficient fine-tuning (PEFT) approaches have been
proposed, among which, Low-Rank Adaptation (LoRA) is a representative approach
that injects trainable rank decomposition matrices into every target module.
Yet LoRA ignores the importance of parameters in different modules. To address
this problem, many works have been proposed to prune the parameters of LoRA.
However, under limited training conditions, the upper bound of the rank of the
pruned parameter matrix is still affected by the preset values. We, therefore,
propose IncreLoRA, an incremental parameter allocation method that adaptively
adds trainable parameters during training based on the importance scores of
each module. This approach is different from the pruning method as it is not
limited by the initial number of training parameters, and each parameter matrix
has a higher rank upper bound for the same training overhead. We conduct
extensive experiments on GLUE to demonstrate the effectiveness of IncreLoRA.
The results show that our method owns higher parameter efficiency, especially
when under the low-resource settings where our method significantly outperforms
the baselines. Our code is publicly available.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12044" title="Abstract">arXiv:2308.12044</a> [<a href="/pdf/2308.12044" title="Download PDF">pdf</a>, <a href="/format/2308.12044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multiobjective continuation method to compute the regularization path  of deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amakor%2C+A+C">Augustina C. Amakor</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+K">Konstantin Sontag</a>, 
<a href="/search/cs?searchtype=author&query=Peitz%2C+S">Sebastian Peitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Sparsity is a highly desired feature in deep neural networks (DNNs) since it
ensures numerical efficiency, improves the interpretability of models (due to
the smaller number of relevant features), and robustness. In machine learning
approaches based on linear models, it is well known that there exists a
connecting path between the sparsest solution in terms of the $\ell^1$ norm
(i.e., zero weights) and the non-regularized solution, which is called the
regularization path. Very recently, there was a first attempt to extend the
concept of regularization paths to DNNs by means of treating the empirical loss
and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the
resulting multiobjective optimization problem. However, due to the
non-smoothness of the $\ell^1$ norm and the high number of parameters, this
approach is not very efficient from a computational perspective. To overcome
this limitation, we present an algorithm that allows for the approximation of
the entire Pareto front for the above-mentioned objectives in a very efficient
manner. We present numerical examples using both deterministic and stochastic
gradients. We furthermore demonstrate that knowledge of the regularization path
allows for a well-generalizing network parametrization.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12045" title="Abstract">arXiv:2308.12045</a> [<a href="/pdf/2308.12045" title="Download PDF">pdf</a>, <a href="/format/2308.12045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CgT-GAN: CLIP-guided Text GAN for Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiarui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanbin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">The large-scale visual-language pre-trained model, Contrastive Language-Image
Pre-training (CLIP), has significantly improved image captioning for scenarios
without human-annotated image-caption pairs. Recent advanced CLIP-based image
captioning without human annotations follows a text-only training paradigm,
i.e., reconstructing text from shared embedding space. Nevertheless, these
approaches are limited by the training/inference gap or huge storage
requirements for text embeddings. Given that it is trivial to obtain images in
the real world, we propose CLIP-guided text GAN (CgT-GAN), which incorporates
images into the training process to enable the model to "see" real visual
modality. Particularly, we use adversarial training to teach CgT-GAN to mimic
the phrases of an external text corpus and CLIP-based reward to provide
semantic guidance. The caption generator is jointly rewarded based on the
caption naturalness to human language calculated from the GAN's discriminator
and the semantic guidance reward computed by the CLIP-based reward module. In
addition to the cosine similarity as the semantic guidance reward (i.e.,
CLIP-cos), we further introduce a novel semantic guidance reward called
CLIP-agg, which aligns the generated caption with a weighted text embedding by
attentively aggregating the entire corpus. Experimental results on three
subtasks (ZS-IC, In-UIC and Cross-UIC) show that CgT-GAN outperforms
state-of-the-art methods significantly across all metrics. Code is available at
https://github.com/Lihr747/CgtGAN.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12048" title="Abstract">arXiv:2308.12048</a> [<a href="/pdf/2308.12048" title="Download PDF">pdf</a>, <a href="/ps/2308.12048" title="Download PostScript">ps</a>, <a href="/format/2308.12048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Head-Tail Cooperative Learning Network for Unbiased Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zejian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Badong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene Graph Generation (SGG) as a critical task in image understanding,
facing the challenge of head-biased prediction caused by the long-tail
distribution of predicates. However, current unbiased SGG methods can easily
prioritize improving the prediction of tail predicates while ignoring the
substantial sacrifice in the prediction of head predicates, leading to a shift
from head bias to tail bias. To address this issue, we propose a model-agnostic
Head-Tail Collaborative Learning (HTCL) network that includes head-prefer and
tail-prefer feature representation branches that collaborate to achieve
accurate recognition of both head and tail predicates. We also propose a
self-supervised learning approach to enhance the prediction ability of the
tail-prefer feature representation branch by constraining tail-prefer predicate
features. Specifically, self-supervised learning converges head predicate
features to their class centers while dispersing tail predicate features as
much as possible through contrast learning and head center loss. We demonstrate
the effectiveness of our HTCL by applying it to various SGG models on VG150,
Open Images V6 and GQA200 datasets. The results show that our method achieves
higher mean Recall with a minimal sacrifice in Recall and achieves a new
state-of-the-art overall performance. Our code is available at
https://github.com/wanglei0618/HTCL.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12049" title="Abstract">arXiv:2308.12049</a> [<a href="/pdf/2308.12049" title="Download PDF">pdf</a>, <a href="/format/2308.12049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Privacy-Supporting Fall Detection via Deep Unsupervised  RGB2Depth Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hejun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiangsheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg1%2C+A">Alina Roitberg1</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fall detection is a vital task in health monitoring, as it allows the system
to trigger an alert and therefore enabling faster interventions when a person
experiences a fall. Although most previous approaches rely on standard RGB
video data, such detailed appearance-aware monitoring poses significant privacy
concerns. Depth sensors, on the other hand, are better at preserving privacy as
they merely capture the distance of objects from the sensor or camera, omitting
color and texture information. In this paper, we introduce a privacy-supporting
solution that makes the RGB-trained model applicable in depth domain and
utilizes depth data at test time for fall detection. To achieve cross-modal
fall detection, we present an unsupervised RGB to Depth (RGB2Depth) cross-modal
domain adaptation approach that leverages labelled RGB data and unlabelled
depth data during training. Our proposed pipeline incorporates an intermediate
domain module for feature bridging, modality adversarial loss for modality
discrimination, classification loss for pseudo-labeled depth data and labeled
source data, triplet loss that considers both source and target domains, and a
novel adaptive loss weight adjustment method for improved coordination among
various losses. Our approach achieves state-of-the-art results in the
unsupervised RGB2Depth domain adaptation task for fall detection. Code is
available at https://github.<a href="/abs/com/1015206">com/1015206</a>533/privacy_supporting_fall_detection.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12050" title="Abstract">arXiv:2308.12050</a> [<a href="/pdf/2308.12050" title="Download PDF">pdf</a>, <a href="/format/2308.12050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Language Models with Offline Reinforcement Learning from Human  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Li Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">June Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chandler Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning from human preferences is crucial for language models (LMs) to
effectively cater to human needs and societal values. Previous research has
made notable progress by leveraging human feedback to follow instructions.
However, these approaches rely primarily on online reinforcement learning (RL)
techniques like Proximal Policy Optimization (PPO), which have been proven
unstable and challenging to tune for language models. Moreover, PPO requires
complex distributed system implementation, hindering the efficiency of
large-scale distributed training. In this study, we propose an offline
reinforcement learning from human feedback (RLHF) framework to align LMs using
pre-generated samples without interacting with RL environments. Specifically,
we explore maximum likelihood estimation (MLE) with filtering, reward-weighted
regression (RWR), and Decision Transformer (DT) to align language models to
human preferences. By employing a loss function similar to supervised
fine-tuning, our methods ensure more stable model training than PPO with a
simple machine learning system~(MLSys) and much fewer (around 12.3\%) computing
resources. Experimental results demonstrate the DT alignment outperforms other
Offline RLHF methods and is better than PPO.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12053" title="Abstract">arXiv:2308.12053</a> [<a href="/pdf/2308.12053" title="Download PDF">pdf</a>, <a href="/format/2308.12053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise Feedback Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+L">Leander Weber</a>, 
<a href="/search/cs?searchtype=author&query=Berend%2C+J">Jim Berend</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+A">Alexander Binder</a>, 
<a href="/search/cs?searchtype=author&query=Wiegand%2C+T">Thomas Wiegand</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In this paper, we present Layer-wise Feedback Propagation (LFP), a novel
training approach for neural-network-like predictors that utilizes
explainability, specifically Layer-wise Relevance Propagation(LRP), to assign
rewards to individual connections based on their respective contributions to
solving a given task. This differs from traditional gradient descent, which
updates parameters towards anestimated loss minimum. LFP distributes a reward
signal throughout the model without the need for gradient computations. It then
strengthens structures that receive positive feedback while reducingthe
influence of structures that receive negative feedback. We establish the
convergence of LFP theoretically and empirically, and demonstrate its
effectiveness in achieving comparable performance to gradient descent on
various models and datasets. Notably, LFP overcomes certain limitations
associated with gradient-based methods, such as reliance on meaningful
derivatives. We further investigate how the different LRP-rules can be extended
to LFP, what their effects are on training, as well as potential applications,
such as training models with no meaningful derivatives, e.g., step-function
activated Spiking Neural Networks (SNNs), or for transfer learning, to
efficiently utilize existing knowledge.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12054" title="Abstract">arXiv:2308.12054</a> [<a href="/pdf/2308.12054" title="Download PDF">pdf</a>, <a href="/format/2308.12054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity of Robust Learning against Evasion Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gourdeau%2C+P">Pascale Gourdeau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DPhil (PhD) Thesis - University of Oxford
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">It is becoming increasingly important to understand the vulnerability of
machine learning models to adversarial attacks. One of the fundamental problems
in adversarial machine learning is to quantify how much training data is needed
in the presence of evasion attacks, where data is corrupted at test time. In
this thesis, we work with the exact-in-the-ball notion of robustness and study
the feasibility of adversarially robust learning from the perspective of
learning theory, considering sample complexity.
<br />We first explore the setting where the learner has access to random examples
only, and show that distributional assumptions are essential. We then focus on
learning problems with distributions on the input data that satisfy a Lipschitz
condition and show that robustly learning monotone conjunctions has sample
complexity at least exponential in the adversary's budget (the maximum number
of bits it can perturb on each input). However, if the adversary is restricted
to perturbing $O(\log n)$ bits, then one can robustly learn conjunctions and
decision lists w.r.t. log-Lipschitz distributions.
<br />We then study learning models where the learner is given more power. We first
consider local membership queries, where the learner can query the label of
points near the training sample. We show that, under the uniform distribution,
the exponential dependence on the adversary's budget to robustly learn
conjunctions remains inevitable. We then introduce a local equivalence query
oracle, which returns whether the hypothesis and target concept agree in a
given region around a point in the training sample, and a counterexample if it
exists. We show that if the query radius is equal to the adversary's budget, we
can develop robust empirical risk minimization algorithms in the
distribution-free setting. We give general query complexity upper and lower
bounds, as well as for concrete concept classes.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12058" title="Abstract">arXiv:2308.12058</a> [<a href="/pdf/2308.12058" title="Download PDF">pdf</a>, <a href="/format/2308.12058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DR-Tune: Improving Fine-tuning of Pretrained Visual Models by  Distribution Regularization with Semantic Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Nan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The visual models pretrained on large-scale benchmarks encode general
knowledge and prove effective in building more powerful representations for
downstream tasks. Most existing approaches follow the fine-tuning paradigm,
either by initializing or regularizing the downstream model based on the
pretrained one. The former fails to retain the knowledge in the successive
fine-tuning phase, thereby prone to be over-fitting, and the latter imposes
strong constraints to the weights or feature maps of the downstream model
without considering semantic drift, often incurring insufficient optimization.
To deal with these issues, we propose a novel fine-tuning framework, namely
distribution regularization with semantic calibration (DR-Tune). It employs
distribution regularization by enforcing the downstream task head to decrease
its classification error on the pretrained feature distribution, which prevents
it from over-fitting while enabling sufficient training of downstream encoders.
Furthermore, to alleviate the interference by semantic drift, we develop the
semantic calibration (SC) module to align the global shape and class centers of
the pretrained and downstream feature distributions. Extensive experiments on
widely used image classification datasets show that DR-Tune consistently
improves the performance when combing with various backbones under different
pretraining strategies. Code is available at:
https://github.com/weeknan/DR-Tune.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12059" title="Abstract">arXiv:2308.12059</a> [<a href="/pdf/2308.12059" title="Download PDF">pdf</a>, <a href="/format/2308.12059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulating Embeddings of Stable Diffusion Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deckers%2C+N">Niklas Deckers</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Julia Peters</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative text-to-image models such as Stable Diffusion allow users to
generate images based on a textual description, the prompt. Changing the prompt
is still the primary means for the user to change a generated image as desired.
However, changing the image by reformulating the prompt remains a difficult
process of trial and error, which has led to the emergence of prompt
engineering as a new field of research. We propose and analyze methods to
change the embedding of a prompt directly instead of the prompt text. It allows
for more fine-grained and targeted control that takes into account user
intentions. Our approach treats the generative text-to-image model as a
continuous function and passes gradients between the image space and the prompt
embedding space. By addressing different user interaction problems, we can
apply this idea in three scenarios: (1) Optimization of a metric defined in
image space that could measure, for example, image style. (2) Assistance of
users in creative tasks by enabling them to navigate the image space along a
selection of directions of "near" prompt embeddings. (3) Changing the embedding
of the prompt to include information that the user has seen in a particular
seed but finds difficult to describe in the prompt. Our experiments demonstrate
the feasibility of the described methods.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12060" title="Abstract">arXiv:2308.12060</a> [<a href="/pdf/2308.12060" title="Download PDF">pdf</a>, <a href="/format/2308.12060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Sunqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhichao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge base question answering (KBQA) is a critical yet challenging task
due to the vast number of entities within knowledge bases and the diversity of
natural language questions posed by users. Unfortunately, the performance of
most KBQA models tends to decline significantly in real-world scenarios where
high-quality annotated data is insufficient. To mitigate the burden associated
with manual annotation, we introduce FlexKBQA by utilizing Large Language
Models (LLMs) as program translators for addressing the challenges inherent in
the few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms
to sample diverse programs, such as SPARQL queries, from the knowledge base,
which are subsequently converted into natural language questions via LLMs. This
synthetic dataset facilitates training a specialized lightweight model for the
KB. Additionally, to reduce the barriers of distribution shift between
synthetic data and real user questions, FlexKBQA introduces an executionguided
self-training method to iterative leverage unlabeled user questions.
Furthermore, we explore harnessing the inherent reasoning capability of LLMs to
enhance the entire framework. Consequently, FlexKBQA delivers substantial
flexibility, encompassing data annotation, deployment, and being domain
agnostic. Through extensive experiments on GrailQA, WebQSP, and KQA Pro, we
observe that under the few-shot even the more challenging zero-shot scenarios,
FlexKBQA achieves impressive results with a few annotations, surpassing all
previous baselines and even approaching the performance of supervised models,
achieving a remarkable 93% performance relative to the fully-supervised models.
We posit that FlexKBQA represents a significant advancement towards exploring
better integration of large and lightweight models. The code is open-sourced.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12061" title="Abstract">arXiv:2308.12061</a> [<a href="/pdf/2308.12061" title="Download PDF">pdf</a>, <a href="/format/2308.12061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using  Harvest Piles and Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jonathan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Elmustafa%2C+A">Amna Elmustafa</a>, 
<a href="/search/cs?searchtype=author&query=Weldegebriel%2C+L">Liya Weldegebriel</a>, 
<a href="/search/cs?searchtype=author&query=Negash%2C+E">Emnet Negash</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Richard Lee</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Lobell%2C+D">David Lobell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Small farms contribute to a large share of the productive land in developing
countries. In regions such as sub-Saharan Africa, where 80% of farms are small
(under 2 ha in size), the task of mapping smallholder cropland is an important
part of tracking sustainability measures such as crop productivity. However,
the visually diverse and nuanced appearance of small farms has limited the
effectiveness of traditional approaches to cropland mapping. Here we introduce
a new approach based on the detection of harvest piles characteristic of many
smallholder systems throughout the world. We present HarvestNet, a dataset for
mapping the presence of farms in the Ethiopian regions of Tigray and Amhara
during 2020-2023, collected using expert knowledge and satellite images,
totaling 7k hand-labeled images and 2k ground collected labels. We also
benchmark a set of baselines including SOTA models in remote sensing with our
best models having around 80% classification performance on hand labelled data
and 90%, 98% accuracy on ground truth data for Tigray, Amhara respectively. We
also perform a visual comparison with a widely used pre-existing coverage map
and show that our model detects an extra 56,621 hectares of cropland in Tigray.
We conclude that remote sensing of harvest piles can contribute to more timely
and accurate cropland assessments in food insecure region.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12063" title="Abstract">arXiv:2308.12063</a> [<a href="/pdf/2308.12063" title="Download PDF">pdf</a>, <a href="/format/2308.12063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metaplasticity: Unifying Learning and Homeostatic Plasticity in Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The natural evolution of the human brain has given rise to multiple forms of
synaptic plasticity, allowing for dynamic changes to adapt to an ever-evolving
world. The evolutionary development of synaptic plasticity has spurred our
exploration of biologically plausible optimization and learning algorithms for
Spiking Neural Networks (SNNs). Present neural networks rely on the direct
training of synaptic weights, which ultimately leads to fixed connections and
hampers their ability to adapt to dynamic real-world environments. To address
this challenge, we introduce the application of metaplasticity -- a
sophisticated mechanism involving the learning of plasticity rules rather than
direct modifications of synaptic weights. Metaplasticity dynamically combines
different plasticity rules, effectively enhancing working memory, multitask
generalization, and adaptability while uncovering potential associations
between various forms of plasticity and cognitive functions. By integrating
metaplasticity into SNNs, we demonstrate the enhanced adaptability and
cognitive capabilities within artificial intelligence systems. This
computational perspective unveils the learning mechanisms of the brain, marking
a significant step in the profound intersection of neuroscience and artificial
intelligence.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12064" title="Abstract">arXiv:2308.12064</a> [<a href="/pdf/2308.12064" title="Download PDF">pdf</a>, <a href="/format/2308.12064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SILT: Shadow-aware Iterative Label Tuning for Learning to Detect Shadows  from Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Han Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chi-Wing Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing shadow detection datasets often contain missing or mislabeled
shadows, which can hinder the performance of deep learning models trained
directly on such data. To address this issue, we propose SILT, the Shadow-aware
Iterative Label Tuning framework, which explicitly considers noise in shadow
labels and trains the deep model in a self-training manner. Specifically, we
incorporate strong data augmentations with shadow counterfeiting to help the
network better recognize non-shadow regions and alleviate overfitting. We also
devise a simple yet effective label tuning strategy with global-local fusion
and shadow-aware filtering to encourage the network to make significant
refinements on the noisy labels. We evaluate the performance of SILT by
relabeling the test set of the SBU dataset and conducting various experiments.
Our results show that even a simple U-Net trained with SILT can outperform all
state-of-the-art methods by a large margin. When trained on SBU / UCF / ISTD,
our network can successfully reduce the Balanced Error Rate by 25.2% / 36.9% /
21.3% over the best state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12065" title="Abstract">arXiv:2308.12065</a> [<a href="/pdf/2308.12065" title="Download PDF">pdf</a>, <a href="/format/2308.12065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensembling Uncertainty Measures to Improve Safety of Black-Box  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zoppi%2C+T">Tommaso Zoppi</a>, 
<a href="/search/cs?searchtype=author&query=Ceccarelli%2C+A">Andrea Ceccarelli</a>, 
<a href="/search/cs?searchtype=author&query=Bondavalli%2C+A">Andrea Bondavalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ECAI23 in October23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Machine Learning (ML) algorithms that perform classification may predict the
wrong class, experiencing misclassifications. It is well-known that
misclassifications may have cascading effects on the encompassing system,
possibly resulting in critical failures. This paper proposes SPROUT, a Safety
wraPper thROugh ensembles of UncertainTy measures, which suspects
misclassifications by computing uncertainty measures on the inputs and outputs
of a black-box classifier. If a misclassification is detected, SPROUT blocks
the propagation of the output of the classifier to the encompassing system. The
resulting impact on safety is that SPROUT transforms erratic outputs
(misclassifications) into data omission failures, which can be easily managed
at the system level. SPROUT has a broad range of applications as it fits binary
and multi-class classification, comprising image and tabular datasets. We
experimentally show that SPROUT always identifies a huge fraction of the
misclassifications of supervised classifiers, and it is able to detect all
misclassifications in specific cases. SPROUT implementation contains
pre-trained wrappers, it is publicly available and ready to be deployed with
minimal effort.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12066" title="Abstract">arXiv:2308.12066</a> [<a href="/pdf/2308.12066" title="Download PDF">pdf</a>, <a href="/format/2308.12066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-gated MoE: An Algorithm-System Co-Design for Fast and Scalable  Mixture-of-Expert Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+R">Ranggi Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jianyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shijie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+C">Changho Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Ting Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Rhu%2C+M">Minsoo Rhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Large language models (LLMs) based on transformers have made significant
strides in recent years, the success of which is driven by scaling up their
model size. Despite their high algorithmic performance, the computational and
memory requirements of LLMs present unprecedented challenges. To tackle the
high compute requirements of LLMs, the Mixture-of-Experts (MoE) architecture
was introduced which is able to scale its model size without proportionally
scaling up its computational requirements. Unfortunately, MoE's high memory
demands and dynamic activation of sparse experts restrict its applicability to
real-world problems. Previous solutions that offload MoE's memory-hungry expert
parameters to CPU memory fall short because the latency to migrate activated
experts from CPU to GPU incurs high performance overhead. Our proposed
Pre-gated MoE system effectively tackles the compute and memory challenges of
conventional MoE architectures using our algorithm-system co-design. Pre-gated
MoE employs our novel pre-gating function which alleviates the dynamic nature
of sparse expert activation, allowing our proposed system to address the large
memory footprint of MoEs while also achieving high performance. We demonstrate
that Pre-gated MoE is able to improve performance, reduce GPU memory
consumption, while also maintaining the same level of model quality. These
features allow our Pre-gated MoE system to cost-effectively deploy large-scale
LLMs using just a single GPU with high performance.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12067" title="Abstract">arXiv:2308.12067</a> [<a href="/pdf/2308.12067" title="Download PDF">pdf</a>, <a href="/format/2308.12067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zihao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multimodal large language models acquire their instruction-following
capabilities through a two-stage training process: pre-training on image-text
pairs and fine-tuning on supervised vision-language instruction data. Recent
studies have shown that large language models can achieve satisfactory results
even with a limited amount of high-quality instruction-following data. In this
paper, we introduce InstructionGPT-4, which is fine-tuned on a small dataset
comprising only 200 examples, amounting to approximately 6% of the
instruction-following data used in the alignment dataset for MiniGPT-4. We
first propose several metrics to access the quality of multimodal instruction
data. Based on these metrics, we present a simple and effective data selector
to automatically identify and filter low-quality vision-language data. By
employing this method, InstructionGPT-4 outperforms the original MiniGPT-4 on
various evaluations (e.g., visual question answering, GPT-4 preference).
Overall, our findings demonstrate that less but high-quality instruction tuning
data is efficient to enable multimodal large language models to generate better
output.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12068" title="Abstract">arXiv:2308.12068</a> [<a href="/pdf/2308.12068" title="Download PDF">pdf</a>, <a href="/format/2308.12068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State Merging with Quantifiers in Symbolic Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trabish%2C+D">David Trabish</a>, 
<a href="/search/cs?searchtype=author&query=Rinetzky%2C+N">Noam Rinetzky</a>, 
<a href="/search/cs?searchtype=author&query=Shoham%2C+S">Sharon Shoham</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vaibhav Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We address the problem of constraint encoding explosion which hinders the
applicability of state merging in symbolic execution. Specifically, our goal is
to reduce the number of disjunctions and \emph{if-then-else} expressions
introduced during state merging. The main idea is to dynamically partition the
symbolic states into merging groups according to a similar uniform structure
detected in their path constraints, which allows to efficiently encode the
merged path constraint and memory using quantifiers. To address the added
complexity of solving quantified constraints, we propose a specialized solving
procedure that reduces the solving time in many cases. Our evaluation shows
that our approach can lead to significant performance gains.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12069" title="Abstract">arXiv:2308.12069</a> [<a href="/pdf/2308.12069" title="Download PDF">pdf</a>, <a href="/ps/2308.12069" title="Download PostScript">ps</a>, <a href="/format/2308.12069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Reaction-Aware Driving Styles of Stochastic Model Predictive  Controlled Vehicles by Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+N">Ni Dang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zengjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wanxin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Leibold%2C+M">Marion Leibold</a>, 
<a href="/search/cs?searchtype=author&query=Buss%2C+M">Martin Buss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The driving style of an Autonomous Vehicle (AV) refers to how it behaves and
interacts with other AVs. In a multi-vehicle autonomous driving system, an AV
capable of identifying the driving styles of its nearby AVs can reliably
evaluate the risk of collisions and make more reasonable driving decisions.
However, there has not been a consistent definition of driving styles for an AV
in the literature, although it is considered that the driving style is encoded
in the AV's trajectories and can be identified using Maximum Entropy Inverse
Reinforcement Learning (ME-IRL) methods as a cost function. Nevertheless, an
important indicator of the driving style, i.e., how an AV reacts to its nearby
AVs, is not fully incorporated in the feature design of previous ME-IRL
methods. In this paper, we describe the driving style as a cost function of a
series of weighted features. We design additional novel features to capture the
AV's reaction-aware characteristics. Then, we identify the driving styles from
the demonstration trajectories generated by the Stochastic Model Predictive
Control (SMPC) using a modified ME-IRL method with our newly proposed features.
The proposed method is validated using MATLAB simulation and an off-the-shelf
experiment.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12072" title="Abstract">arXiv:2308.12072</a> [<a href="/pdf/2308.12072" title="Download PDF">pdf</a>, <a href="/format/2308.12072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing IoT Security: Assessing the Effectiveness of Best Practices  in Protecting Against Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%BCtz%2C+P">Philipp P&#xfc;tz</a>, 
<a href="/search/cs?searchtype=author&query=Mitev%2C+R">Richard Mitev</a>, 
<a href="/search/cs?searchtype=author&query=Miettinen%2C+M">Markus Miettinen</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) market is rapidly growing and is expected to
double from 2020 to 2025. The increasing use of IoT devices, particularly in
smart homes, raises crucial concerns about user privacy and security as these
devices often handle sensitive and critical information. Inadequate security
designs and implementations by IoT vendors can lead to significant
vulnerabilities.
<br />To address these IoT device vulnerabilities, institutions, and organizations
have published IoT security best practices (BPs) to guide manufacturers in
ensuring the security of their products. However, there is currently no
standardized approach for evaluating the effectiveness of individual BP
recommendations. This leads to manufacturers investing effort in implementing
less effective BPs while potentially neglecting measures with greater impact.
<br />In this paper, we propose a methodology for evaluating the security impact of
IoT BPs and ranking them based on their effectiveness in protecting against
security threats. Our approach involves translating identified BPs into
concrete test cases that can be applied to real-world IoT devices to assess
their effectiveness in mitigating vulnerabilities. We applied this methodology
to evaluate the security impact of nine commodity IoT products, discovering 18
vulnerabilities. By empirically assessing the actual impact of BPs on device
security, IoT designers and implementers can prioritize their security
investments more effectively, improving security outcomes and optimizing
limited security budgets.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12073" title="Abstract">arXiv:2308.12073</a> [<a href="/pdf/2308.12073" title="Download PDF">pdf</a>, <a href="/format/2308.12073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance for Ellipsoidal Rigid Bodies with Control Barrier  Functions Designed from Rotating Supporting Hyperplanes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Funada%2C+R">Riku Funada</a>, 
<a href="/search/eess?searchtype=author&query=Nishimoto%2C+K">Koju Nishimoto</a>, 
<a href="/search/eess?searchtype=author&query=Ibuki%2C+T">Tatsuya Ibuki</a>, 
<a href="/search/eess?searchtype=author&query=Sampei%2C+M">Mitsuji Sampei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper proposes a collision avoidance method for ellipsoidal rigid
bodies, which utilizes a control barrier function (CBF) designed from a
supporting hyperplane. We formulate the problem in the Special Euclidean Group
SE(2) and SE(3), where the dynamics are described as rigid body motion (RBM).
Then, we consider the condition for separating two ellipsoidal rigid bodies by
employing a signed distance from a supporting hyperplane of a rigid body to the
other rigid body. Although the positive value of this signed distance implies
that two rigid bodies are collision-free, a naively prepared supporting
hyperplane yields a smaller value than the actual distance. To avoid such a
conservative evaluation, the supporting hyperplane is rotated so that the
signed distance from the supporting hyperplane to the other rigid body is
maximized. We prove that the maximum value of this optimization problem is
equal to the actual distance between two ellipsoidal rigid bodies, hence
eliminating excessive conservativeness. We leverage this signed distance as a
CBF to prevent collision while the supporting hyperplane is rotated via a
gradient-based input. The designed CBF is integrated into a quadratic
programming (QP) problem, where each rigid body calculates its collision-free
input in a distributed manner, given communication among rigid bodies. The
proposed method is demonstrated with simulations. Finally, we exemplify our
method can be extended to a vehicle having nonholonomic dynamics.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12074" title="Abstract">arXiv:2308.12074</a> [<a href="/pdf/2308.12074" title="Download PDF">pdf</a>, <a href="/format/2308.12074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Analysis of Behavioral Patterns During Prolonged Work in VR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biener%2C+V">Verena Biener</a>, 
<a href="/search/cs?searchtype=author&query=Farzinnejad%2C+F">Forouzan Farzinnejad</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+R">Rinaldo Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Tabaei%2C+S">Seyedmasih Tabaei</a>, 
<a href="/search/cs?searchtype=author&query=Lindlein%2C+L">Leon Lindlein</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinghui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nouri%2C+N">Negar Nouri</a>, 
<a href="/search/cs?searchtype=author&query=Dudley%2C+J+J">John J. Dudley</a>, 
<a href="/search/cs?searchtype=author&query=Kristensson%2C+P+O">Per Ola Kristensson</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">J&#xf6;rg M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Grubert%2C+J">Jens Grubert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">VR has recently been promoted as a tool for knowledge workers and studies
have shown that it has the potential to improve knowledge work. However,
studies on its prolonged use have been scarce. A prior study compared working
in VR for one week to working in a physical environment, focusing on
performance measures and subjective feedback. However, a nuanced understanding
and comparison of participants' behavior in VR and the physical environment is
still missing. To this end, we analyzed video material made available from this
previously conducted experiment, carried out over a working week, and present
our findings on comparing the behavior of participants while working in VR and
in a physical environment.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12075" title="Abstract">arXiv:2308.12075</a> [<a href="/pdf/2308.12075" title="Download PDF">pdf</a>, <a href="/format/2308.12075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing RNN Gradients through Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herranz-Celotti%2C+L">Luca Herranz-Celotti</a>, 
<a href="/search/cs?searchtype=author&query=Rouat%2C+J">Jean Rouat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Numerous theories of learning suggest to prevent the gradient variance from
exponential growth with depth or time, to stabilize and improve training.
Typically, these analyses are conducted on feed-forward fully-connected neural
networks or single-layer recurrent neural networks, given their mathematical
tractability. In contrast, this study demonstrates that pre-training the
network to local stability can be effective whenever the architectures are too
complex for an analytical initialization. Furthermore, we extend known
stability theories to encompass a broader family of deep recurrent networks,
requiring minimal assumptions on data and parameter distribution, a theory that
we refer to as the Local Stability Condition (LSC). Our investigation reveals
that the classical Glorot, He, and Orthogonal initialization schemes satisfy
the LSC when applied to feed-forward fully-connected neural networks. However,
analysing deep recurrent networks, we identify a new additive source of
exponential explosion that emerges from counting gradient paths in a
rectangular grid in depth and time. We propose a new approach to mitigate this
issue, that consists on giving a weight of a half to the time and depth
contributions to the gradient, instead of the classical weight of one. Our
empirical results confirm that pre-training both feed-forward and recurrent
networks to fulfill the LSC often results in improved final performance across
models. This study contributes to the field by providing a means to stabilize
networks of any complexity. Our approach can be implemented as an additional
step before pre-training on large augmented datasets, and as an alternative to
finding stable initializations analytically.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12079" title="Abstract">arXiv:2308.12079</a> [<a href="/pdf/2308.12079" title="Download PDF">pdf</a>, <a href="/format/2308.12079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using the TypeScript compiler to fix erroneous Node.js snippets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reid%2C+B">Brittany Reid</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+M">Markus Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 23rd IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Most online code snippets do not run. This means that developers looking to
reuse code from online sources must manually find and fix errors. We present an
approach for automatically evaluating and correcting errors in Node.js code
snippets: Node Code Correction (NCC). NCC leverages the ability of the
TypeScript compiler to generate errors and inform code corrections through the
combination of TypeScript's built-in codefixes, our own targeted fixes, and
deletion of erroneous lines. Compared to existing approaches using linters, our
findings suggest that NCC is capable of detecting a larger number of errors per
snippet and more error types, and it is more efficient at fixing snippets. We
find that 73.7% of the code snippets in NPM documentation have errors; with the
use of NCC's corrections, this number was reduced to 25.1%. Our evaluation
confirms that the use of the TypeScript compiler to inform code corrections is
a promising strategy to aid in the reuse of code snippets from online sources.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12082" title="Abstract">arXiv:2308.12082</a> [<a href="/pdf/2308.12082" title="Download PDF">pdf</a>, <a href="/format/2308.12082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path-Constrained State Estimation for Rail Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=von+Einem%2C+C">Cornelius von Einem</a>, 
<a href="/search/cs?searchtype=author&query=Cramariuc%2C+A">Andrei Cramariuc</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Cadena%2C+C">Cesar Cadena</a>, 
<a href="/search/cs?searchtype=author&query=Tschopp%2C+F">Florian Tschopp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Globally rising demand for transportation by rail is pushing existing
infrastructure to its capacity limits, necessitating the development of
accurate, robust, and high-frequency positioning systems to ensure safe and
efficient train operation. As individual sensor modalities cannot satisfy the
strict requirements of robustness and safety, a combination thereof is
required. We propose a path-constrained sensor fusion framework to integrate
various modalities while leveraging the unique characteristics of the railway
network. To reflect the constrained motion of rail vehicles along their tracks,
the state is modeled in 1D along the track geometry. We further leverage the
limited action space of a train by employing a novel multi-hypothesis tracking
to account for multiple possible trajectories a vehicle can take through the
railway network. We demonstrate the reliability and accuracy of our fusion
framework on multiple tram datasets recorded in the city of Zurich, utilizing
Visual-Inertial Odometry for local motion estimation and a standard GNSS for
global localization. We evaluate our results using ground truth localizations
recorded with a RTK-GNSS, and compare our method to standard baselines. A Root
Mean Square Error of 4.78 m and a track selectivity score of up to 94.9 % have
been achieved.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12083" title="Abstract">arXiv:2308.12083</a> [<a href="/pdf/2308.12083" title="Download PDF">pdf</a>, <a href="/format/2308.12083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boratto%2C+L">Ludovico Boratto</a>, 
<a href="/search/cs?searchtype=author&query=Fabbri%2C+F">Francesco Fabbri</a>, 
<a href="/search/cs?searchtype=author&query=Fenu%2C+G">Gianni Fenu</a>, 
<a href="/search/cs?searchtype=author&query=Marras%2C+M">Mirko Marras</a>, 
<a href="/search/cs?searchtype=author&query=Medda%2C+G">Giacomo Medda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a short paper at CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In recommendation literature, explainability and fairness are becoming two
prominent perspectives to consider. However, prior works have mostly addressed
them separately, for instance by explaining to consumers why a certain item was
recommended or mitigating disparate impacts in recommendation utility. None of
them has leveraged explainability techniques to inform unfairness mitigation.
In this paper, we propose an approach that relies on counterfactual
explanations to augment the set of user-item interactions, such that using them
while inferring recommendations leads to fairer outcomes. Modeling user-item
interactions as a bipartite graph, our approach augments the latter by
identifying new user-item edges that not only can explain the original
unfairness by design, but can also mitigate it. Experiments on two public data
sets show that our approach effectively leads to a better trade-off between
fairness and recommendation utility compared with state-of-the-art mitigation
procedures. We further analyze the characteristics of added edges to highlight
key unfairness patterns. Source code available at
https://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12086" title="Abstract">arXiv:2308.12086</a> [<a href="/pdf/2308.12086" title="Download PDF">pdf</a>, <a href="/format/2308.12086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of the Cage: How Stochastic Parrots Win in Cyber Security  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigaki%2C+M">Maria Rigaki</a>, 
<a href="/search/cs?searchtype=author&query=Luk%C3%A1%C5%A1%2C+O">Ond&#x159;ej Luk&#xe1;&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Catania%2C+C+A">Carlos A. Catania</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+S">Sebastian Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. 10 pages plus appendices, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have gained widespread popularity across diverse
domains involving text generation, summarization, and various natural language
processing tasks. Despite their inherent limitations, LLM-based designs have
shown promising capabilities in planning and navigating open-world scenarios.
This paper introduces a novel application of pre-trained LLMs as agents within
cybersecurity network environments, focusing on their utility for sequential
decision-making processes.
<br />We present an approach wherein pre-trained LLMs are leveraged as attacking
agents in two reinforcement learning environments. Our proposed agents
demonstrate similar or better performance against state-of-the-art agents
trained for thousands of episodes in most scenarios and configurations. In
addition, the best LLM agents perform similarly to human testers of the
environment without any additional training process. This design highlights the
potential of LLMs to efficiently address complex decision-making tasks within
cybersecurity.
<br />Furthermore, we introduce a new network security environment named
NetSecGame. The environment is designed to eventually support complex
multi-agent scenarios within the network security domain. The proposed
environment mimics real network attacks and is designed to be highly modular
and adaptable for various scenarios.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12088" title="Abstract">arXiv:2308.12088</a> [<a href="/pdf/2308.12088" title="Download PDF">pdf</a>, <a href="/format/2308.12088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Tracking Control of Dual-PAM Soft Actuator with Hysteresis  Compensator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Miyazaki%2C+T">Tetsuro Miyazaki</a>, 
<a href="/search/cs?searchtype=author&query=Ohno%2C+S">Shingo Ohno</a>, 
<a href="/search/cs?searchtype=author&query=Sogabe%2C+M">Maina Sogabe</a>, 
<a href="/search/cs?searchtype=author&query=Kawashima%2C+K">Kenji Kawashima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Soft robotics is an emergent and swiftly evolving field. Pneumatic actuators
are suitable for driving soft robots because of their superior performance.
However, their control is not easy due to their hysteresis characteristics. In
response to these challenges, we propose an adaptive control method to
compensate hysteresis of a soft actuator. Employing a novel dual pneumatic
artificial muscle (PAM) bending actuator, the innovative control strategy
abates hysteresis effects by dynamically modulating gains within a traditional
PID controller corresponding with the predicted motion of the reference
trajectory. Through comparative experimental evaluation, we found that the new
control method outperforms its conventional counterparts regarding tracking
accuracy and response speed. Our work reveals a new direction for advancing
control in soft actuators.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12093" title="Abstract">arXiv:2308.12093</a> [<a href="/pdf/2308.12093" title="Download PDF">pdf</a>, <a href="/format/2308.12093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cached Operator Reordering: A Unified View for Fast GNN Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazinska%2C+J">Julia Bazinska</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+A">Andrei Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Nun%2C+T">Tal Ben-Nun</a>, 
<a href="/search/cs?searchtype=author&query=Dryden%2C+N">Nikoli Dryden</a>, 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) are a powerful tool for handling structured
graph data and addressing tasks such as node classification, graph
classification, and clustering. However, the sparse nature of GNN computation
poses new challenges for performance optimization compared to traditional deep
neural networks. We address these challenges by providing a unified view of GNN
computation, I/O, and memory. By analyzing the computational graphs of the
Graph Convolutional Network (GCN) and Graph Attention (GAT) layers -- two
widely used GNN layers -- we propose alternative computation strategies. We
present adaptive operator reordering with caching, which achieves a speedup of
up to 2.43x for GCN compared to the current state-of-the-art. Furthermore, an
exploration of different caching schemes for GAT yields a speedup of up to
1.94x. The proposed optimizations save memory, are easily implemented across
various hardware platforms, and have the potential to alleviate performance
bottlenecks in training large-scale GNN models.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12095" title="Abstract">arXiv:2308.12095</a> [<a href="/pdf/2308.12095" title="Download PDF">pdf</a>, <a href="/format/2308.12095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Using Information Retrieval to Recommend Machine Learning Good  Practices for Software Engineers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabra-Acela%2C+L">Laura Cabra-Acela</a>, 
<a href="/search/cs?searchtype=author&query=Mojica-Hanke%2C+A">Anamaria Mojica-Hanke</a>, 
<a href="/search/cs?searchtype=author&query=Linares-V%C3%A1squez%2C+M">Mario Linares-V&#xe1;squez</a>, 
<a href="/search/cs?searchtype=author&query=Herbold%2C+S">Steffen Herbold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Publication at ESEC/FSE demonstrations track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Machine learning (ML) is nowadays widely used for different purposes and in
several disciplines. From self-driving cars to automated medical diagnosis,
machine learning models extensively support users' daily activities, and
software engineering tasks are no exception. Not embracing good ML practices
may lead to pitfalls that hinder the performance of an ML system and
potentially lead to unexpected results. Despite the existence of documentation
and literature about ML best practices, many non-ML experts turn towards gray
literature like blogs and Q&amp;A systems when looking for help and guidance when
implementing ML systems. To better aid users in distilling relevant knowledge
from such sources, we propose a recommender system that recommends ML practices
based on the user's context. As a first step in creating a recommender system
for machine learning practices, we implemented Idaka. A tool that provides two
different approaches for retrieving/generating ML best practices: i) an
information retrieval (IR) engine and ii) a large language model. The IR-engine
uses BM25 as the algorithm for retrieving the practices, and a large language
model, in our case Alpaca. The platform has been designed to allow comparative
studies of best practices retrieval tools. Idaka is publicly available at
GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12097" title="Abstract">arXiv:2308.12097</a> [<a href="/pdf/2308.12097" title="Download PDF">pdf</a>, <a href="/format/2308.12097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Position Matters in Sequence Generation with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yijin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianfeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes and results are at <a href="https://github.com/Adaxry/Post-Instruction/tree/main">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are capable of performing conditional sequence
generation tasks, such as translation or summarization, through instruction
fine-tuning. The fine-tuning data is generally sequentially concatenated from a
specific task instruction, an input sentence, and the corresponding response.
Considering the locality modeled by the self-attention mechanism of LLMs, these
models face the risk of instruction forgetting when generating responses for
long input sentences. To mitigate this issue, we propose enhancing the
instruction-following capability of LLMs by shifting the position of task
instructions after the input sentences. Theoretical analysis suggests that our
straightforward method can alter the model's learning focus, thereby
emphasizing the training of instruction-following capabilities. Concurrently,
experimental results demonstrate that our approach consistently outperforms
traditional settings across various model scales (1B / 7B / 13B) and different
sequence generation tasks (translation and summarization), without any
additional data or annotation costs. Notably, our method significantly improves
the zero-shot performance on conditional sequence generation, e.g., up to 9.7
BLEU points on WMT zero-shot translation tasks.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12104" title="Abstract">arXiv:2308.12104</a> [<a href="/pdf/2308.12104" title="Download PDF">pdf</a>, <a href="/format/2308.12104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Modeling of Coupled Interactions of Fluid Membranes with  Embedded Filaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sharma%2C+B+L">Basant Lal Sharma</a>, 
<a href="/search/math?searchtype=author&query=Perotti%2C+L+E">Luigi E. Perotti</a>, 
<a href="/search/math?searchtype=author&query=Dharmavaram%2C+S">Sanjay Dharmavaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
<p class="mathjax">In this work, we present a computational formulation based on continuum
mechanics to study the interaction of fluid membranes embedded with
semiflexible filaments. This is motivated by systems in membrane biology, such
as cytoskeletal networks and protein filaments aiding the cell fission process.
We model the membrane as a fluid shell via the Helfrich-Canham energy and the
filament as a one-dimensional Cosserat continuum. We assume the filament to be
tethered to the surface of the membrane in a way that it is allowed to float on
the surface freely. The novel filament-membrane coupling, which is anticipated
to yield interesting physics, also gives rise to unique computational
challenges, which we address in this work. We present validation results and
apply the formulation to certain problems inspired by cellular biology.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12106" title="Abstract">arXiv:2308.12106</a> [<a href="/pdf/2308.12106" title="Download PDF">pdf</a>, <a href="/format/2308.12106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Linear Precoder Design for MIMO-OFDM Integrated Sensing and  Communications Based on Bayesian Cram&#xe9;r-Rao Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Andrei%2C+V+C">Vlad Costin Andrei</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6nich%2C+U+J">Ullrich J M&#xf6;nich</a>, 
<a href="/search/cs?searchtype=author&query=Boche%2C+H">Holger Boche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate the fundamental limits of MIMO-OFDM integrated
sensing and communications (ISAC) systems based on a Bayesian Cram\'er-Rao
bound (BCRB) analysis. We derive the BCRB for joint channel parameter
estimation and data symbol detection, in which a performance trade-off between
both functionalities is observed. We formulate the optimization problem for a
linear precoder design and propose the stochastic Riemannian gradient descent
(SRGD) approach to solve the non-convex problem. We analyze the optimality
conditions and show that SRGD ensures convergence with high probability. The
simulation results verify our analyses and also demonstrate a fast convergence
speed. Finally, the performance trade-off is illustrated and investigated.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12110" title="Abstract">arXiv:2308.12110</a> [<a href="/pdf/2308.12110" title="Download PDF">pdf</a>, <a href="/format/2308.12110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Stein Variational Trajectory Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Power%2C+T">Thomas Power</a>, 
<a href="/search/cs?searchtype=author&query=Berenson%2C+D">Dmitry Berenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present Constrained Stein Variational Trajectory Optimization (CSVTO), an
algorithm for performing trajectory optimization with constraints on a set of
trajectories in parallel. We frame constrained trajectory optimization as a
novel form of constrained functional minimization over trajectory
distributions, which avoids treating the constraints as a penalty in the
objective and allows us to generate diverse sets of constraint-satisfying
trajectories. Our method uses Stein Variational Gradient Descent (SVGD) to find
a set of particles that approximates a distribution over low-cost trajectories
while obeying constraints. CSVTO is applicable to problems with arbitrary
equality and inequality constraints and includes a novel particle resampling
step to escape local minima. By explicitly generating diverse sets of
trajectories, CSVTO is better able to avoid poor local minima and is more
robust to initialization. We demonstrate that CSVTO outperforms baselines in
challenging highly-constrained tasks, such as a 7DoF wrench manipulation task,
where CSVTO succeeds in 20/20 trials vs 13/20 for the closest baseline. Our
results demonstrate that generating diverse constraint-satisfying trajectories
improves robustness to disturbances and initialization over baselines.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12111" title="Abstract">arXiv:2308.12111</a> [<a href="/pdf/2308.12111" title="Download PDF">pdf</a>, <a href="/format/2308.12111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modality Proposal-guided Feature Mining for Unregistered  RGB-Thermal Pedestrian Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaojun Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenyu He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGB-Thermal (RGB-T) pedestrian detection aims to locate the pedestrians in
RGB-T image pairs to exploit the complementation between the two modalities for
improving detection robustness in extreme conditions. Most existing algorithms
assume that the RGB-T image pairs are well registered, while in the real world
they are not aligned ideally due to parallax or different field-of-view of the
cameras. The pedestrians in misaligned image pairs may locate at different
positions in two images, which results in two challenges: 1) how to achieve
inter-modality complementation using spatially misaligned RGB-T pedestrian
patches, and 2) how to recognize the unpaired pedestrians at the boundary. To
deal with these issues, we propose a new paradigm for unregistered RGB-T
pedestrian detection, which predicts two separate pedestrian locations in the
RGB and thermal images, respectively. Specifically, we propose a cross-modality
proposal-guided feature mining (CPFM) mechanism to extract the two precise
fusion features for representing the pedestrian in the two modalities, even if
the RGB-T image pair is unaligned. It enables us to effectively exploit the
complementation between the two modalities. With the CPFM mechanism, we build a
two-stream dense detector; it predicts the two pedestrian locations in the two
modalities based on the corresponding fusion feature mined by the CPFM
mechanism. Besides, we design a data augmentation method, named Homography, to
simulate the discrepancy in scales and views between images. We also
investigate two non-maximum suppression (NMS) methods for post-processing.
Favorable experimental results demonstrate the effectiveness and robustness of
our method in dealing with unregistered pedestrians with different shifts.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12112" title="Abstract">arXiv:2308.12112</a> [<a href="/pdf/2308.12112" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Continual Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marczak%2C+D">Daniel Marczak</a>, 
<a href="/search/cs?searchtype=author&query=Rype%C5%9B%C4%87%2C+G">Grzegorz Rype&#x15b;&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Most of Continual Learning (CL) methods push the limit of supervised learning
settings, where an agent is expected to learn new labeled tasks and not forget
previous knowledge. However, these settings are not well aligned with real-life
scenarios, where a learning agent has access to a vast amount of unlabeled data
encompassing both novel (entirely unlabeled) classes and examples from known
classes. Drawing inspiration from Generalized Category Discovery (GCD), we
introduce a novel framework that relaxes this assumption. Precisely, in any
task, we allow for the existence of novel and known classes, and one must use
continual version of unsupervised learning methods to discover them. We call
this setting Generalized Continual Category Discovery (GCCD). It unifies CL and
GCD, bridging the gap between synthetic benchmarks and real-life scenarios.
With a series of experiments, we present that existing methods fail to
accumulate knowledge from subsequent tasks in which unlabeled samples of novel
classes are present. In light of these limitations, we propose a method that
incorporates both supervised and unsupervised signals and mitigates the
forgetting through the use of centroid adaptation. Our method surpasses strong
CL methods adopted for GCD techniques and presents a superior representation
learning performance.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12113" title="Abstract">arXiv:2308.12113</a> [<a href="/pdf/2308.12113" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Point Cloud Data Augmentation for Deep Learning: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qinfeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+N">Ningxin Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud has a wide range of applications in areas such as autonomous
driving, mapping, navigation, scene reconstruction, and medical imaging. Due to
its great potentials in these applications, point cloud processing has gained
great attention in the field of computer vision. Among various point cloud
processing techniques, deep learning (DL) has become one of the mainstream and
effective methods for tasks such as detection, segmentation and classification.
To reduce overfitting during training DL models and improve model performance
especially when the amount and/or diversity of training data are limited,
augmentation is often crucial. Although various point cloud data augmentation
methods have been widely used in different point cloud processing tasks, there
are currently no published systematic surveys or reviews of these methods.
Therefore, this article surveys and discusses these methods and categorizes
them into a taxonomy framework. Through the comprehensive evaluation and
comparison of the augmentation methods, this article identifies their
potentials and limitations and suggests possible future research directions.
This work helps researchers gain a holistic understanding of the current status
of point cloud data augmentation and promotes its wider application and
development.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12114" title="Abstract">arXiv:2308.12114</a> [<a href="/pdf/2308.12114" title="Download PDF">pdf</a>, <a href="/format/2308.12114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More -- Towards parsimonious multi-task models using structured  sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+R">Richa Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Phlypo%2C+R">Ronald Phlypo</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+R">Rajkumar Saini</a>, 
<a href="/search/cs?searchtype=author&query=Liwicki%2C+M">Marcus Liwicki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Group sparsity in Machine Learning (ML) encourages simpler, more
interpretable models with fewer active parameter groups. This work aims to
incorporate structured group sparsity into the shared parameters of a
Multi-Task Learning (MTL) framework, to develop parsimonious models that can
effectively address multiple tasks with fewer parameters while maintaining
comparable or superior performance to a dense model. Sparsifying the model
during training helps decrease the model's memory footprint, computation
requirements, and prediction time during inference. We use channel-wise l1/l2
group sparsity in the shared layers of the Convolutional Neural Network (CNN).
This approach not only facilitates the elimination of extraneous groups
(channels) but also imposes a penalty on the weights, thereby enhancing the
learning of all tasks. We compare the outcomes of single-task and multi-task
experiments under group sparsity on two publicly available MTL datasets, NYU-v2
and CelebAMask-HQ. We also investigate how changing the sparsification degree
impacts both the performance of the model and the sparsity of groups.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12115" title="Abstract">arXiv:2308.12115</a> [<a href="/pdf/2308.12115" title="Download PDF">pdf</a>, <a href="/format/2308.12115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory vs. Practice in Modeling Edge Storage Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolosov%2C+O">Oleg Kolosov</a>, 
<a href="/search/cs?searchtype=author&query=Aktas%2C+M+F">Mehmet Fatih Aktas</a>, 
<a href="/search/cs?searchtype=author&query=Soljanin%2C+E">Emina Soljanin</a>, 
<a href="/search/cs?searchtype=author&query=Yadgar%2C+G">Gala Yadgar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2023 IEEE International Performance, Computing, and Communications Conference (IPCCC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Edge systems promise to bring data and computing closer to the users of
time-critical applications. Specifically, edge storage systems are emerging as
a new system paradigm, where users can retrieve data from small-scale servers
inter-operating at the network's edge. The analysis, design, and optimization
of such systems require a tractable model that will reflect their costs and
bottlenecks. Alas, most existing mathematical models for edge systems focus on
stateless tasks, network performance, or isolated nodes and are inapplicable
for evaluating edge-based storage performance.
<br />We analyze the capacity-region model - the most promising model proposed so
far for edge storage systems. The model addresses the system's ability to serve
a set of user demands. Our analysis reveals five inherent gaps between this
model and reality, demonstrating the significant remaining challenges in
modeling storage service at the edge.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12116" title="Abstract">arXiv:2308.12116</a> [<a href="/pdf/2308.12116" title="Download PDF">pdf</a>, <a href="/format/2308.12116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The TYC Dataset for Understanding Instance-Level Semantics and Motions  of Cells in Microstructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/cs?searchtype=author&query=Prangemeier%2C+T">Tim Prangemeier</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 Workshop on BioImage Computing. Project page (with links to the dataset and code): <a href="https://christophreich1996.github.io/tyc_dataset/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmenting cells and tracking their motion over time is a common task in
biomedical applications. However, predicting accurate instance-wise
segmentation and cell motions from microscopy imagery remains a challenging
task. Using microstructured environments for analyzing single cells in a
constant flow of media adds additional complexity. While large-scale labeled
microscopy datasets are available, we are not aware of any large-scale dataset,
including both cells and microstructures. In this paper, we introduce the
trapped yeast cell (TYC) dataset, a novel dataset for understanding
instance-level semantics and motions of cells in microstructures. We release
$105$ dense annotated high-resolution brightfield microscopy images, including
about $19$k instance masks. We also release $261$ curated video clips composed
of $1293$ high-resolution microscopy images to facilitate unsupervised
understanding of cell motions and morphology. TYC offers ten times more
instance annotations than the previously largest dataset, including cells and
microstructures. Our effort also exceeds previous attempts in terms of
microstructure variability, resolution, complexity, and capturing device
(microscopy) variability. We facilitate a unified comparison on our novel
dataset by introducing a standardized evaluation strategy. TYC and evaluation
code are publicly available under CC BY 4.0 license.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12117" title="Abstract">arXiv:2308.12117</a> [<a href="/pdf/2308.12117" title="Download PDF">pdf</a>, <a href="/format/2308.12117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS  Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Meng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A reliable communication network is essential for multiple UAVs operating
within obstacle-cluttered environments, where limited communication due to
obstructions often occurs. A common solution is to deploy intermediate UAVs to
relay information via a multi-hop network, which introduces two challenges: (i)
how to design the structure of multi-hop networks; and (ii) how to maintain
connectivity during collaborative motion. To this end, this work first proposes
an efficient constrained search method based on the minimum-edge RRT$^\star$
algorithm, to find a spanning-tree topology that requires a less number of UAVs
for the deployment task. To achieve this deployment, a distributed model
predictive control strategy is proposed for the online motion coordination. It
explicitly incorporates not only the inter-UAV and UAV-obstacle distance
constraints, but also the line-of-sight (LOS) connectivity constraint. These
constraints are well-known to be nonlinear and often tackled by various
approximations. In contrast, this work provides a theoretical guarantee that
all agent trajectories are ensured to be collision-free with a team-wise LOS
connectivity at all time. Numerous simulations are performed in 3D valley-like
environments, while hardware experiments validate its dynamic adaptation when
the deployment position changes online.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12120" title="Abstract">arXiv:2308.12120</a> [<a href="/pdf/2308.12120" title="Download PDF">pdf</a>, <a href="/format/2308.12120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open-Source ML-Based Full-Stack Optimization Framework for Machine  Learning Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeilzadeh%2C+H">Hadi Esmaeilzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Ghodrati%2C+S">Soroush Ghodrati</a>, 
<a href="/search/cs?searchtype=author&query=Kahng%2C+A+B">Andrew B. Kahng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+K">Joon Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kinzer%2C+S">Sean Kinzer</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Sayak Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Mahapatra%2C+R">Rohan Mahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Manasi%2C+S+D">Susmita Dey Manasi</a>, 
<a href="/search/cs?searchtype=author&query=Sapatnekar%2C+S">Sachin Sapatnekar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziqing Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of our work titled "Physically Accurate Learning-based Performance Prediction of Hardware-accelerated ML Algorithms" published in MLCAD 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Parameterizable machine learning (ML) accelerators are the product of recent
breakthroughs in ML. To fully enable their design space exploration (DSE), we
propose a physical-design-driven, learning-based prediction framework for
hardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. It
adopts a unified approach that combines backend power, performance, and area
(PPA) analysis with frontend performance simulation, thereby achieving a
realistic estimation of both backend PPA and system metrics such as runtime and
energy. In addition, our framework includes a fully automated DSE technique,
which optimizes backend and system metrics through an automated search of
architectural and backend parameters. Experimental studies show that our
approach consistently predicts backend PPA and system metrics with an average
7% or less prediction error for the ASIC implementation of two deep learning
accelerator platforms, VTA and VeriGOOD-ML, in both a commercial 12 nm process
and a research-oriented 45 nm process.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12127" title="Abstract">arXiv:2308.12127</a> [<a href="/pdf/2308.12127" title="Download PDF">pdf</a>, <a href="/format/2308.12127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masking Strategies for Background Bias Removal in Computer Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aniraj%2C+A">Ananthu Aniraj</a>, 
<a href="/search/cs?searchtype=author&query=Dantas%2C+C+F">Cassio F. Dantas</a>, 
<a href="/search/cs?searchtype=author&query=Ienco%2C+D">Dino Ienco</a>, 
<a href="/search/cs?searchtype=author&query=Marcos%2C+D">Diego Marcos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2023 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) on Out Of Distribution Generalization in Computer Vision (OOD-CV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Models for fine-grained image classification tasks, where the difference
between some classes can be extremely subtle and the number of samples per
class tends to be low, are particularly prone to picking up background-related
biases and demand robust methods to handle potential examples with
out-of-distribution (OOD) backgrounds. To gain deeper insights into this
critical problem, our research investigates the impact of background-induced
bias on fine-grained image classification, evaluating standard backbone models
such as Convolutional Neural Network (CNN) and Vision Transformers (ViT). We
explore two masking strategies to mitigate background-induced bias: Early
masking, which removes background information at the (input) image level, and
late masking, which selectively masks high-level spatial features corresponding
to the background. Extensive experiments assess the behavior of CNN and ViT
models under different masking strategies, with a focus on their generalization
to OOD backgrounds. The obtained findings demonstrate that both proposed
strategies enhance OOD performance compared to the baseline models, with early
masking consistently exhibiting the best OOD performance. Notably, a ViT
variant employing GAP-Pooled Patch token-based classification combined with
early masking achieves the highest OOD robustness.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12129" title="Abstract">arXiv:2308.12129</a> [<a href="/pdf/2308.12129" title="Download PDF">pdf</a>, <a href="/format/2308.12129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resiliency Analysis of LLM generated models for Industrial Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ogundare%2C+O">Oluwatosin Ogundare</a>, 
<a href="/search/cs?searchtype=author&query=Araya%2C+G+Q">Gustavo Quiros Araya</a>, 
<a href="/search/cs?searchtype=author&query=Akrotirianakis%2C+I">Ioannis Akrotirianakis</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+A">Ankit Shukla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, Conference Manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper proposes a study of the resilience and efficiency of automatically
generated industrial automation and control systems using Large Language Models
(LLMs). The approach involves modeling the system using percolation theory to
estimate its resilience and formulating the design problem as an optimization
problem subject to constraints. Techniques from stochastic optimization and
regret analysis are used to find a near-optimal solution with provable regret
bounds. The study aims to provide insights into the effectiveness and
reliability of automatically generated systems in industrial automation and
control, and to identify potential areas for improvement in their design and
implementation.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12130" title="Abstract">arXiv:2308.12130</a> [<a href="/pdf/2308.12130" title="Download PDF">pdf</a>, <a href="/format/2308.12130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time hybridizable discontinuous Galerkin method for  advection-diffusion on deforming domains: The advection-dominated regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/math?searchtype=author&query=Rhebergen%2C+S">Sander Rhebergen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We analyze a space-time hybridizable discontinuous Galerkin method to solve
the time-dependent advection-diffusion equation on deforming domains. We prove
stability of the discretization in the advection-dominated regime by using
weighted test functions and derive a priori space-time error estimates. A
numerical example illustrates the theoretical results.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12131" title="Abstract">arXiv:2308.12131</a> [<a href="/pdf/2308.12131" title="Download PDF">pdf</a>, <a href="/format/2308.12131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Change Detection for the Romanian Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truic%C4%83%2C+C">Ciprian-Octavian Truic&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Tudose%2C+V">Victor Tudose</a>, 
<a href="/search/cs?searchtype=author&query=Apostol%2C+E">Elena-Simona Apostol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automatic semantic change methods try to identify the changes that appear
over time in the meaning of words by analyzing their usage in diachronic
corpora. In this paper, we analyze different strategies to create static and
contextual word embedding models, i.e., Word2Vec and ELMo, on real-world
English and Romanian datasets. To test our pipeline and determine the
performance of our models, we first evaluate both word embedding models on an
English dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on a
Romanian dataset, and we underline different aspects of semantic changes in
this low-resource language, such as meaning acquisition and loss. The
experimental results show that, depending on the corpus, the most important
factors to consider are the choice of model and the distance to calculate a
score for detecting semantic change.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12133" title="Abstract">arXiv:2308.12133</a> [<a href="/pdf/2308.12133" title="Download PDF">pdf</a>, <a href="/format/2308.12133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lite-HRNet Plus: Fast and Accurate Facial Landmark Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+S">Sota Kato</a>, 
<a href="/search/cs?searchtype=author&query=Hotta%2C+K">Kazuhiro Hotta</a>, 
<a href="/search/cs?searchtype=author&query=Hatakeyama%2C+Y">Yuhki Hatakeyama</a>, 
<a href="/search/cs?searchtype=author&query=Konishi%2C+Y">Yoshinori Konishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICIP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial landmark detection is an essential technology for driver status
tracking and has been in demand for real-time estimations. As a landmark
coordinate prediction, heatmap-based methods are known to achieve a high
accuracy, and Lite-HRNet can achieve a fast estimation. However, with
Lite-HRNet, the problem of a heavy computational cost of the fusion block,
which connects feature maps with different resolutions, has yet to be solved.
In addition, the strong output module used in HRNetV2 is not applied to
Lite-HRNet. Given these problems, we propose a novel architecture called
Lite-HRNet Plus. Lite-HRNet Plus achieves two improvements: a novel fusion
block based on a channel attention and a novel output module with less
computational intensity using multi-resolution feature maps. Through
experiments conducted on two facial landmark datasets, we confirmed that
Lite-HRNet Plus further improved the accuracy in comparison with conventional
methods, and achieved a state-of-the-art accuracy with a computational
complexity with the range of 10M FLOPs.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12134" title="Abstract">arXiv:2308.12134</a> [<a href="/pdf/2308.12134" title="Download PDF">pdf</a>, <a href="/format/2308.12134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DarkDiff: Explainable web page similarity of TOR onion sites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartel%2C+P">Pieter Hartel</a>, 
<a href="/search/cs?searchtype=author&query=Haspels%2C+E">Eljo Haspels</a>, 
<a href="/search/cs?searchtype=author&query=van+Staalduinen%2C+M">Mark van Staalduinen</a>, 
<a href="/search/cs?searchtype=author&query=Texeira%2C+O">Octavio Texeira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In large-scale data analysis, near-duplicates are often a problem. For
example, with two near-duplicate phishing emails, a difference in the
salutation (Mr versus Ms) is not essential, but whether it is bank A or B is
important. The state-of-the-art in near-duplicate detection is a black box
approach (MinHash), so one only knows that emails are near-duplicates, but not
why. We present DarkDiff, which can efficiently detect near-duplicates while
providing the reason why there is a near-duplicate. We have developed DarkDiff
to detect near-duplicates of homepages on the Darkweb. DarkDiff works well on
those pages because they resemble the clear web of the past.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12138" title="Abstract">arXiv:2308.12138</a> [<a href="/pdf/2308.12138" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Select-and-Combine (SAC): A Novel Multi-Stereo Depth Fusion Algorithm  for Point Cloud Generation via Efficient Local Markov Netlets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elhashash%2C+M">Mostafa Elhashash</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Many practical systems for image-based surface reconstruction employ a
stereo/multi-stereo paradigm, due to its ability to scale for large scenes and
its ease of implementation for out-of-core operations. In this process,
multiple and abundant depth maps from stereo matching must be combined and
fused into a single, consistent, and clean point cloud. However, the noises and
outliers caused by stereo matching and the heterogenous geometric errors of the
poses present a challenge for existing fusion algorithms, since they mostly
assume Gaussian errors and predict fused results based on data from local
spatial neighborhoods, which may inherit uncertainties from multiple depths
resulting in lowered accuracy. In this paper, we propose a novel depth fusion
paradigm, that instead of numerically fusing points from multiple depth maps,
selects the best depth map per point, and combines them into a single and clean
point cloud. This paradigm, called select-and-combine (SAC), is achieved
through modeling the point level fusion using local Markov Netlets, a
micro-network over point across neighboring views for depth/view selection,
followed by a Netlets collapse process for point combination. The Markov
Netlets are optimized such that they can inherently leverage spatial
consistencies among depth maps of neighboring views, thus they can address
errors beyond Gaussian ones. Our experiment results show that our approach
outperforms existing depth fusion approaches by increasing the F1 score that
considers both accuracy and completeness by 2.07% compared to the best existing
method. Finally, our approach generates clearer point clouds that are 18% less
redundant while with a higher accuracy before fusion
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12139" title="Abstract">arXiv:2308.12139</a> [<a href="/pdf/2308.12139" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh Conflation of Oblique Photogrammetric Models using Virtual Cameras  and Truncated Signed Distance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuang Song</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conflating/stitching 2.5D raster digital surface models (DSM) into a large
one has been a running practice in geoscience applications, however, conflating
full-3D mesh models, such as those from oblique photogrammetry, is extremely
challenging. In this letter, we propose a novel approach to address this
challenge by conflating multiple full-3D oblique photogrammetric models into a
single, and seamless mesh for high-resolution site modeling. Given two or more
individually collected and created photogrammetric meshes, we first propose to
create a virtual camera field (with a panoramic field of view) to incubate
virtual spaces represented by Truncated Signed Distance Field (TSDF), an
implicit volumetric field friendly for linear 3D fusion; then we adaptively
leverage the truncated bound of meshes in TSDF to conflate them into a single
and accurate full 3D site model. With drone-based 3D meshes, we show that our
approach significantly improves upon traditional methods for model conflations,
to drive new potentials to create excessively large and accurate full 3D mesh
models in support of geoscience and environmental applications.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12141" title="Abstract">arXiv:2308.12141</a> [<a href="/pdf/2308.12141" title="Download PDF">pdf</a>, <a href="/format/2308.12141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aparecium: Revealing Secrets from Physical Photographs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhe Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingtao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Watermarking is a crucial tool for safeguarding copyrights and can serve as a
more aesthetically pleasing alternative to QR codes. In recent years,
watermarking methods based on deep learning have proved superior robustness
against complex physical distortions than traditional watermarking methods.
However, they have certain limitations that render them less effective in
practice. For instance, current solutions necessitate physical photographs to
be rectangular for accurate localization, cannot handle physical bending or
folding, and require the hidden area to be completely captured at a close
distance and small angle. To overcome these challenges, we propose a novel deep
watermarking framework dubbed \textit{Aparecium}. Specifically, we preprocess
secrets (i.e., watermarks) into a pattern and then embed it into the cover
image, which is symmetrical to the final decoding-then-extracting process. To
capture the watermarked region from complex physical scenarios, a locator is
also introduced. Besides, we adopt a three-stage training strategy for training
convergence. Extensive experiments demonstrate that \textit{Aparecium} is not
only robust against different digital distortions, but also can resist various
physical distortions, such as screen-shooting and printing-shooting, even in
severe cases including different shapes, curvature, folding, incompleteness,
long distances, and big angles while maintaining high visual quality.
Furthermore, some ablation studies are also conducted to verify our design.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12143" title="Abstract">arXiv:2308.12143</a> [<a href="/pdf/2308.12143" title="Download PDF">pdf</a>, <a href="/format/2308.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Fluctuation based Membership Inference Attack for  Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wenjie Fu</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huandong Wang</a> (2), 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a> (2), 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanghua Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a> (2), 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a> (1),  ((1) Huazhong University of Science and Technology, (2) Tsinghua University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Membership Inference Attack (MIA) identifies whether a record exists in a
machine learning model's training set by querying the model. MIAs on the
classic classification models have been well-studied, and recent works have
started to explore how to transplant MIA onto generative models. Our
investigation indicates that existing MIAs designed for generative models
mainly depend on the overfitting in target models. However, overfitting can be
avoided by employing various regularization techniques, whereas existing MIAs
demonstrate poor performance in practice. Unlike overfitting, memorization is
essential for deep learning models to attain optimal performance, making it a
more prevalent phenomenon. Memorization in generative models leads to an
increasing trend in the probability distribution of generating records around
the member record. Therefore, we propose a Probabilistic Fluctuation Assessing
Membership Inference Attack (PFAMI), a black-box MIA that infers memberships by
detecting these trends via analyzing the overall probabilistic fluctuations
around given records. We conduct extensive experiments across multiple
generative models and datasets, which demonstrate PFAMI can improve the attack
success rate (ASR) by about 27.9% when compared with the best baseline.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12145" title="Abstract">arXiv:2308.12145</a> [<a href="/pdf/2308.12145" title="Download PDF">pdf</a>, <a href="/format/2308.12145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling excitable cells with the EMI equations: spectral analysis and  iterative solution strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benedusi%2C+P">Pietro Benedusi</a>, 
<a href="/search/math?searchtype=author&query=Ferrari%2C+P">Paola Ferrari</a>, 
<a href="/search/math?searchtype=author&query=Rognes%2C+M">Marie Rognes</a>, 
<a href="/search/math?searchtype=author&query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work, we are interested in solving large linear systems stemming from
the Extra-Membrane-Intra (EMI) model, which is employed for simulating
excitable tissues at a cellular scale. After setting the related systems of
partial differential equations (PDEs) equipped with proper boundary conditions,
we provide numerical approximation schemes for the EMI PDEs and focus on the
resulting large linear systems. We first give a relatively complete spectral
analysis using tools from the theory of Generalized Locally Toeplitz matrix
sequences. The obtained spectral information is used for designing appropriate
(preconditioned) Krylov solvers. We show, through numerical experiments, that
the presented solution strategy is robust w.r.t. problem and discretization
parameters, efficient and scalable.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12147" title="Abstract">arXiv:2308.12147</a> [<a href="/pdf/2308.12147" title="Download PDF">pdf</a>, <a href="/format/2308.12147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of adaptive containerization architectures for HPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+T">Tiziano M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Mujkanovic%2C+N">Nina Mujkanovic</a>, 
<a href="/search/cs?searchtype=author&query=Durillo%2C+J+J">Juan J. Durillo</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+N">Nicolay Hammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 tables, 1 figure, submitted to the 5th International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Containers offer an array of advantages that benefit research reproducibility
and portability across groups and systems. As container tools mature, container
security improves, and High-performance computing (HPC) and cloud system tools
converge, supercomputing centers are increasingly integrating containers in
their workflows. The technology selection process requires sufficient
information on the diverse tools available, yet the majority of research into
containers still focuses on cloud environments. We consider an adaptive
containerization approach, with a focus on accelerating the deployment of
applications and workflows on HPC systems using containers. To this end, we
discuss the specific HPC requirements regarding container tools, and analyze
the entire containerization stack, including container engines and registries,
in-depth. Finally, we consider various orchestrator and HPC workload manager
integration scenarios.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12152" title="Abstract">arXiv:2308.12152</a> [<a href="/pdf/2308.12152" title="Download PDF">pdf</a>, <a href="/format/2308.12152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geo-Sketcher: Rapid 3D Geological Modeling using Geological and  Topographic Map Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amorim%2C+R">Ronan Amorim</a>, 
<a href="/search/cs?searchtype=author&query=Brazil%2C+E+V">Emilio Vital Brazil</a>, 
<a href="/search/cs?searchtype=author&query=Samavati%2C+F">Faramarz Samavati</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+M+C">Mario Costa Sousa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 30 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">The construction of 3D geological models is an essential task in oil/gas
exploration, development and production. However, it is a cumbersome,
time-consuming and error-prone task mainly because of the model's geometric and
topological complexity. The models construction is usually separated into
interpretation and 3D modeling, performed by different highly specialized
individuals, which leads to inconsistencies and intensifies the challenges. In
addition, the creation of models following geological rules is paramount for
properly depicting static and dynamic properties of oil/gas reservoirs. In this
work, we propose a sketch-based approach to expedite the creation of valid 3D
geological models by mimicking how domain experts interpret geological
structures, allowing creating models directly from interpretation sketches. Our
sketch-based modeler (Geo-Sketcher) is based on sketches of standard 2D
topographic and geological maps, comprised of lines, symbols and annotations.
We developed a graph-based representation to enable (1) the automatic
computation of the relative ages of rock series and layers, and (2) the
embedding of specific geological rules directly in the sketching. We introduce
the use of Hermite-Birkhoff Radial Basis Functions to interpolate the
geological map constraints, and demonstrate the capabilities of our approach
with a variety of results with different levels of complexity.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12156" title="Abstract">arXiv:2308.12156</a> [<a href="/pdf/2308.12156" title="Download PDF">pdf</a>, <a href="/format/2308.12156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Latent Emotion Recognition from Micro-expression and  Physiological Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yifei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Arandjelovic%2C+O">Ognjen Arandjelovic</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Anthony Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper discusses the benefits of incorporating multimodal data for
improving latent emotion recognition accuracy, focusing on micro-expression
(ME) and physiological signals (PS). The proposed approach presents a novel
multimodal learning framework that combines ME and PS, including a 1D separable
and mixable depthwise inception network, a standardised normal distribution
weighted feature fusion method, and depth/physiology guided attention modules
for multimodal learning. Experimental results show that the proposed approach
outperforms the benchmark method, with the weighted fusion method and guided
attention modules both contributing to enhanced performance.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12157" title="Abstract">arXiv:2308.12157</a> [<a href="/pdf/2308.12157" title="Download PDF">pdf</a>, <a href="/format/2308.12157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Faithfulness Using the Longest Supported Subsequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Anirudh Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Schick%2C+T">Timo Schick</a>, 
<a href="/search/cs?searchtype=author&query=Artetxe%2C+M">Mikel Artetxe</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi-Yu%2C+J">Jane Dwivedi-Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As increasingly sophisticated language models emerge, their trustworthiness
becomes a pivotal issue, especially in tasks such as summarization and
question-answering. Ensuring their responses are contextually grounded and
faithful is challenging due to the linguistic diversity and the myriad of
possible answers. In this paper, we introduce a novel approach to evaluate
faithfulness of machine-generated text by computing the longest noncontinuous
substring of the claim that is supported by the context, which we refer to as
the Longest Supported Subsequence (LSS). Using a new human-annotated dataset,
we finetune a model to generate LSS. We introduce a new method of evaluation
and demonstrate that these metrics correlate better with human ratings when LSS
is employed, as opposed to when it is not. Our proposed metric demonstrates an
18% enhancement over the prevailing state-of-the-art metric for faithfulness on
our dataset. Our metric consistently outperforms other metrics on a
summarization dataset across six different models. Finally, we compare several
popular Large Language Models (LLMs) for faithfulness using this metric. We
release the human-annotated dataset built for predicting LSS and our fine-tuned
model for evaluating faithfulness.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12158" title="Abstract">arXiv:2308.12158</a> [<a href="/pdf/2308.12158" title="Download PDF">pdf</a>, <a href="/format/2308.12158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Visualization System for Hexahedral Mesh Quality Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lei Si</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoning Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper contain 4 pages, 1 reference pace. supplemental include 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we introduce a new 3D hex mesh visual analysis system that
emphasizes poor-quality areas with an aggregated glyph, highlights overlapping
elements, and provides detailed boundary error inspection in three forms. By
supporting multi-level analysis through multiple views, our system effectively
evaluates various mesh models and compares the performance of mesh generation
and optimization algorithms for hexahedral meshes.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12162" title="Abstract">arXiv:2308.12162</a> [<a href="/pdf/2308.12162" title="Download PDF">pdf</a>, <a href="/ps/2308.12162" title="Download PostScript">ps</a>, <a href="/format/2308.12162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Property Directed Reachability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blankestijn%2C+M">Max Blankestijn</a>, 
<a href="/search/cs?searchtype=author&query=Laarman%2C+A">Alfons Laarman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Property Directed Reachability (PDR) is a widely used technique for formal
verification of hardware and software systems. This paper presents an
incremental version of PDR (IPDR), which enables the automatic verification of
system instances of incremental complexity. The proposed algorithm leverages
the concept of incremental SAT solvers to reuse verification results from
previously verified system instances, thereby accelerating the verification
process. The new algorithm supports both incremental constraining and relaxing;
i.e., starting from an over-constrained instance that is gradually relaxed.
<br />To validate the effectiveness of the proposed algorithm, we implemented IPDR
and experimentally evaluate it on two different problem domains. First, we
consider a circuit pebbling problem, where the number of pebbles is both
constrained and relaxed. Second, we explore parallel program instances,
progressively increasing the allowed number of interleavings. The experimental
results demonstrate significant performance improvements compared to Z3's PDR
implementation SPACER. Experiments also show that the incremental approach
succeeds in reusing a substantial amount of clauses between instances, for both
the constraining and relaxing algorithm.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12163" title="Abstract">arXiv:2308.12163</a> [<a href="/pdf/2308.12163" title="Download PDF">pdf</a>, <a href="/format/2308.12163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPF-200: A Multi-Modal Eye Fixation Dataset and Method for  Non-Photorealistic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sucheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Nanxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shengfeng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Non-photorealistic videos are in demand with the wave of the metaverse, but
lack of sufficient research studies. This work aims to take a step forward to
understand how humans perceive non-photorealistic videos with eye fixation
(\ie, saliency detection), which is critical for enhancing media production,
artistic design, and game user experience. To fill in the gap of missing a
suitable dataset for this research line, we present NPF-200, the first
large-scale multi-modal dataset of purely non-photorealistic videos with eye
fixations. Our dataset has three characteristics: 1) it contains soundtracks
that are essential according to vision and psychological studies; 2) it
includes diverse semantic content and videos are of high-quality; 3) it has
rich motions across and within videos. We conduct a series of analyses to gain
deeper insights into this task and compare several state-of-the-art methods to
explore the gap between natural images and non-photorealistic data.
Additionally, as the human attention system tends to extract visual and audio
features with different frequencies, we propose a universal frequency-aware
multi-modal non-photorealistic saliency detection model called NPSNet,
demonstrating the state-of-the-art performance of our task. The results uncover
strengths and weaknesses of multi-modal network design and multi-domain
training, opening up promising directions for future works. {Our dataset and
code can be found at \url{https://github.com/Yangziyu/NPF200}}.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12164" title="Abstract">arXiv:2308.12164</a> [<a href="/pdf/2308.12164" title="Download PDF">pdf</a>, <a href="/ps/2308.12164" title="Download PostScript">ps</a>, <a href="/format/2308.12164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust family of exponential attractors for a linear time  discretization of the Cahn-Hilliard equation with a source term
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dor%2C+D">Dieunel Dor</a>, 
<a href="/search/math?searchtype=author&query=Pierre%2C+M">Morgan Pierre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider a linear implicit-explicit (IMEX) time discretization of the
Cahn-Hilliard equation with a source term, endowed with Dirichlet boundary
conditions. For every time step small enough, we build an exponential attractor
of the discrete-in-time dynamical system associated to the discretization. We
prove that, as the time step tends to 0, this attractor converges for the
symmmetric Hausdorff distance to an exponential attractor of the
continuous-in-time dynamical system associated with the PDE. We also prove that
the fractal dimension of the exponential attractor (and consequently, of the
global attractor) is bounded by a constant independent of the time step. The
results also apply to the classical Cahn-Hilliard equation with Neumann
boundary conditions.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12170" title="Abstract">arXiv:2308.12170</a> [<a href="/pdf/2308.12170" title="Download PDF">pdf</a>, <a href="/ps/2308.12170" title="Download PostScript">ps</a>, <a href="/format/2308.12170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model reference adaptive control for state and input constrained linear  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chattopadhyay%2C+S">Sudipta Chattopadhyay</a>, 
<a href="/search/eess?searchtype=author&query=Sukumar%2C+S">Srikant Sukumar</a>, 
<a href="/search/eess?searchtype=author&query=Natarajan%2C+V">Vivek Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">State and input constraints are ubiquitous in all engineering systems. In
this article, we derive adaptive controllers for uncertain linear systems under
pre-specified state and input constraints. Several modifications of the model
reference adaptive control (MRAC) framework have been proposed to address input
constraints in uncertain linear systems. Considering the infeasibility of
arbitrary reference trajectories, reference modification has been implemented
in the case of input constraints in literature. The resulting conditions on the
reference and input signals are difficult to verify online. Similar results on
state and input constraints together have also been proposed, albeit resulting
in more complex and unverifiable conditions on the control. The primary
objective of this article is therefore to account for state and input
constraints in uncertain linear systems by providing easily verifiable
conditions on the control and reference. A combination of reference
modification and barrier Lyapunov methods in adaptive control are employed to
arrive at these results.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12175" title="Abstract">arXiv:2308.12175</a> [<a href="/pdf/2308.12175" title="Download PDF">pdf</a>, <a href="/format/2308.12175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised anomalies detection in IIoT edge devices networks using  federated learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thamar%2C+N">Niyomukiza Thamar</a>, 
<a href="/search/cs?searchtype=author&query=Sharara%2C+H+S+E">Hossam Samy Elsaid Sharara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for PuBlication in machine learning journals
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In a connection of many IoT devices that each collect data, normally training
a machine learning model would involve transmitting the data to a central
server which requires strict privacy rules. However, some owners are reluctant
of availing their data out of the company due to data security concerns.
Federated learning(FL) as a distributed machine learning approach performs
training of a machine learning model on the device that gathered the data
itself. In this scenario, data is not share over the network for training
purpose. Fedavg as one of FL algorithms permits a model to be copied to
participating devices during a training session. The devices could be chosen at
random, and a device can be aborted. The resulting models are sent to the
coordinating server and then average models from the devices that finished
training. The process is repeated until a desired model accuracy is achieved.
By doing this, FL approach solves the privacy problem for IoT/ IIoT devices
that held sensitive data for the owners. In this paper, we leverage the
benefits of FL and implemented Fedavg algorithm on a recent dataset that
represent the modern IoT/ IIoT device networks. The results were almost the
same as the centralized machine learning approach. We also evaluated some
shortcomings of Fedavg such as unfairness that happens during the training when
struggling devices do not participate for every stage of training. This
inefficient training of local or global model could lead in a high number of
false alarms in intrusion detection systems for IoT/IIoT gadgets developed
using Fedavg. Hence, after evaluating the FedAv deep auto encoder with
centralized deep auto encoder ML, we further proposed and designed a Fair
Fedavg algorithm that will be evaluated in the future work.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12177" title="Abstract">arXiv:2308.12177</a> [<a href="/pdf/2308.12177" title="Download PDF">pdf</a>, <a href="/ps/2308.12177" title="Download PostScript">ps</a>, <a href="/format/2308.12177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of EFX (and Pareto-Optimal) Allocations for Binary  Chores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+B">Biaoshuai Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaowei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shengwei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the problem of allocating a group of indivisible chores among agents
while each chore has a binary marginal. We focus on the fairness criteria of
envy-freeness up to any item (EFX) and investigate the existence of EFX
allocations. We show that when agents have additive binary cost functions,
there exist EFX and Pareto-optimal (PO) allocations that can be computed in
polynomial time. To the best of our knowledge, this is the first setting of a
general number of agents that admits EFX and PO allocations, before which EFX
and PO allocations have only been shown to exist for three bivalued agents. We
further consider more general cost functions: cancelable and general monotone
(both with binary marginal). We show that EFX allocations exist and can be
computed for binary cancelable chores, but EFX is incompatible with PO. For
general binary marginal functions, we propose an algorithm that computes
(partial) envy-free (EF) allocations with at most $n-1$ unallocated items.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12178" title="Abstract">arXiv:2308.12178</a> [<a href="/pdf/2308.12178" title="Download PDF">pdf</a>, <a href="/format/2308.12178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Hand Cube Reconfiguration: Simplified
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patidar%2C+S">Sumit Patidar</a>, 
<a href="/search/cs?searchtype=author&query=Sieler%2C+A">Adrian Sieler</a>, 
<a href="/search/cs?searchtype=author&query=Brock%2C+O">Oliver Brock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a simple approach to in-hand cube reconfiguration. By simplifying
planning, control, and perception as much as possible, while maintaining robust
and general performance, we gain insights into the inherent complexity of
in-hand cube reconfiguration. We also demonstrate the effectiveness of
combining GOFAI-based planning with the exploitation of environmental
constraints and inherently compliant end-effectors in the context of dexterous
manipulation. The proposed system outperforms a substantially more complex
system for cube reconfiguration based on deep learning and accurate physical
simulation, contributing arguments to the discussion about what the most
promising approach to general manipulation might be. Project website:
https://rbo.gitlab-pages.tu-berlin.de/robotics/simpleIHM/
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12188" title="Abstract">arXiv:2308.12188</a> [<a href="/pdf/2308.12188" title="Download PDF">pdf</a>, <a href="/format/2308.12188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and external validation of a lung cancer risk estimation  tool using gradient-boosting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benveniste%2C+P">Pierre-Louis Benveniste</a>, 
<a href="/search/cs?searchtype=author&query=Alberge%2C+J">Julie Alberge</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Lei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Bibault%2C+J">Jean-Emmanuel Bibault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 4 tables, 1 Github repository, see <a href="http://github.com/plbenveniste/LungCancerRisk">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Lung cancer is a significant cause of mortality worldwide, emphasizing the
importance of early detection for improved survival rates. In this study, we
propose a machine learning (ML) tool trained on data from the PLCO Cancer
Screening Trial and validated on the NLST to estimate the likelihood of lung
cancer occurrence within five years. The study utilized two datasets, the PLCO
(n=55,161) and NLST (n=48,595), consisting of comprehensive information on risk
factors, clinical measurements, and outcomes related to lung cancer. Data
preprocessing involved removing patients who were not current or former smokers
and those who had died of causes unrelated to lung cancer. Additionally, a
focus was placed on mitigating bias caused by censored data. Feature selection,
hyper-parameter optimization, and model calibration were performed using
XGBoost, an ensemble learning algorithm that combines gradient boosting and
decision trees. The ML model was trained on the pre-processed PLCO dataset and
tested on the NLST dataset. The model incorporated features such as age,
gender, smoking history, medical diagnoses, and family history of lung cancer.
The model was well-calibrated (Brier score=0.044). ROC-AUC was 82% on the PLCO
dataset and 70% on the NLST dataset. PR-AUC was 29% and 11% respectively. When
compared to the USPSTF guidelines for lung cancer screening, our model provided
the same recall with a precision of 13.1% vs. 9.3% on the PLCO dataset and 3.2%
vs. 3.1% on the NLST dataset. The developed ML tool provides a freely available
web application for estimating the likelihood of developing lung cancer within
five years. By utilizing risk factors and clinical data, individuals can assess
their risk and make informed decisions regarding lung cancer screening. This
research contributes to the efforts in early detection and prevention
strategies, aiming to reduce lung cancer-related mortality rates.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12191" title="Abstract">arXiv:2308.12191</a> [<a href="/pdf/2308.12191" title="Download PDF">pdf</a>, <a href="/format/2308.12191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sign Language Translation with Iterative Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huijie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hezhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents IP-SLT, a simple yet effective framework for sign
language translation (SLT). Our IP-SLT adopts a recurrent structure and
enhances the semantic representation (prototype) of the input sign language
video via an iterative refinement manner. Our idea mimics the behavior of human
reading, where a sentence can be digested repeatedly, till reaching accurate
understanding. Technically, IP-SLT consists of feature extraction, prototype
initialization, and iterative prototype refinement. The initialization module
generates the initial prototype based on the visual feature extracted by the
feature extraction module. Then, the iterative refinement module leverages the
cross-attention mechanism to polish the previous prototype by aggregating it
with the original video feature. Through repeated refinement, the prototype
finally converges to a more stable and accurate state, leading to a fluent and
appropriate translation. In addition, to leverage the sequential dependence of
prototypes, we further propose an iterative distillation loss to compress the
knowledge of the final iteration into previous ones. As the autoregressive
decoding process is executed only once in inference, our IP-SLT is ready to
improve various SLT systems with acceptable overhead. Extensive experiments are
conducted on public benchmarks to demonstrate the effectiveness of the IP-SLT.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12192" title="Abstract">arXiv:2308.12192</a> [<a href="/pdf/2308.12192" title="Download PDF">pdf</a>, <a href="/format/2308.12192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Analysis of Continuous-Depth Models with Lagrangian  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neubauer%2C+S+A">Sophie A. Neubauer</a> (n&#xe9;e Gruenbacher), 
<a href="/search/cs?searchtype=author&query=Grosu%2C+R">Radu Grosu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2107.08467">arXiv:2107.08467</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J.-F. Raskin and K. Chatterjee (Eds.): Principles of Systems
  Design, LNCS 13660, pp. 625-649, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents, in a unified fashion, deterministic as well as
statistical Lagrangian-verification techniques. They formally quantify the
behavioral robustness of any time-continuous process, formulated as a
continuous-depth model. To this end, we review LRT-NG, SLR, and GoTube,
algorithms for constructing a tight reachtube, that is, an over-approximation
of the set of states reachable within a given time-horizon, and provide
guarantees for the reachtube bounds. We compare the usage of the variational
equations, associated to the system equations, the mean value theorem, and the
Lipschitz constants, in achieving deterministic and statistical guarantees. In
LRT-NG, the Lipschitz constant is used as a bloating factor of the initial
perturbation, to compute the radius of an ellipsoid in an optimal metric, which
over-approximates the set of reachable states. In SLR and GoTube, we get
statistical guarantees, by using the Lipschitz constants to compute local balls
around samples. These are needed to calculate the probability of having found
an upper bound, of the true maximum perturbation at every timestep. Our
experiments demonstrate the superior performance of Lagrangian techniques, when
compared to LRT, Flow*, and CAPD, and illustrate their use in the robustness
analysis of various continuous-depth models.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12194" title="Abstract">arXiv:2308.12194</a> [<a href="/pdf/2308.12194" title="Download PDF">pdf</a>, <a href="/format/2308.12194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Human Intentions from Predicted Action Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Predicting the next action that a human is most likely to perform is key to
human-AI collaboration and has consequently attracted increasing research
interests in recent years. An important factor for next action prediction are
human intentions: If the AI agent knows the intention it can predict future
actions and plan collaboration more effectively. Existing Bayesian methods for
this task struggle with complex visual input while deep neural network (DNN)
based methods do not provide uncertainty quantifications. In this work we
combine both approaches for the first time and show that the predicted next
action probabilities contain information that can be used to infer the
underlying intention. We propose a two-step approach to human intention
prediction: While a DNN predicts the probabilities of the next action,
MCMC-based Bayesian inference is used to infer the underlying intention from
these predictions. This approach not only allows for independent design of the
DNN architecture but also the subsequently fast, design-independent inference
of human intentions. We evaluate our method using a series of experiments on
the Watch-And-Help (WAH) and a keyboard and mouse interaction dataset. Our
results show that our approach can accurately predict human intentions from
observed actions and the implicit information contained in next action
probabilities. Furthermore, we show that our approach can predict the correct
intention even if only few actions have been observed.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12199" title="Abstract">arXiv:2308.12199</a> [<a href="/pdf/2308.12199" title="Download PDF">pdf</a>, <a href="/format/2308.12199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-Time Analysis of Broadcast Badminton Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilesh%2C+N">Nitin Nilesh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tushar Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Anurag Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C. V. Jawahar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Analysis of player movements is a crucial subset of sports analysis. Existing
player movement analysis methods use recorded videos after the match is over.
In this work, we propose an end-to-end framework for player movement analysis
for badminton matches on live broadcast match videos. We only use the visual
inputs from the match and, unlike other approaches which use multi-modal sensor
data, our approach uses only visual cues. We propose a method to calculate the
on-court distance covered by both the players from the video feed of a live
broadcast badminton match. To perform this analysis, we focus on the gameplay
by removing replays and other redundant parts of the broadcast match. We then
perform player tracking to identify and track the movements of both players in
each frame. Finally, we calculate the distance covered by each player and the
average speed with which they move on the court. We further show a heatmap of
the areas covered by the player on the court which is useful for analyzing the
gameplay of the player. Our proposed framework was successfully used to analyze
live broadcast matches in real-time during the Premier Badminton League 2019
(PBL 2019), with commentators and broadcasters appreciating the utility.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12201" title="Abstract">arXiv:2308.12201</a> [<a href="/pdf/2308.12201" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A foolish consistency? Aligning interface objects hinders location  recall and may induce collinear errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zelchenko%2C+P">Peter Zelchenko</a>, 
<a href="/search/cs?searchtype=author&query=Xiangqian%2C+L">Li Xiangqian</a>, 
<a href="/search/cs?searchtype=author&query=Xiaohan%2C+F">Fu Xiaohan</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+A">Alex Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhenyu Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">During our nearly constant use of digital devices, perhaps our most frequent
need is to visually identify icons representing our content and invoke the
actions to manipulate them. Almost since the inception of user interface design
in the 1970s, with rare exception it has become the tendency for programmers to
prescribe the arrangement these things in uniform rectilinear rows and columns.
This was imported from theories for print design and ultimately brought into
widespread practice for graphical user interfaces (GUIs). Whether consistent
rectilinearity actually does better than less rectilinear arrangements to
maximize selection efficiency has not been challenged on considerations of
speed or any other measure. In a series of four experiments, we explore how
alignment may in fact discourage easy recallability of screen object locations
and hence increase search intensity. A second objective is to present a
methodological model where we deliberately attempt to begin with psychophysical
cognitive evidence at the environmental schematic low end (beginning with
contextual cueing paradigm), then move progressively upwards in naturalism in
the experiments to something that approximates actual human work at the higher
end, all along attempting to keep one important environmental property
constant. Two experiments using contextual cueing paradigm confirm that
collinearly aligned arrays do not encourage recallability of location, while
noncollinear arrays appear to create traces that can be recalled automatically.
Two other experiments give further demonstration of explicit recollection and
location recall, showing that collinear arrangements may in fact induce
location recall errors to neighboring collinear objects. We discuss surrounding
theoretical, historical, and practical questions.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12202" title="Abstract">arXiv:2308.12202</a> [<a href="/pdf/2308.12202" title="Download PDF">pdf</a>, <a href="/format/2308.12202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning with Adam: The Devil Is in the Wrong Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+L">Lucas Weber</a>, 
<a href="/search/cs?searchtype=author&query=Jumelet%2C+J">Jaap Jumelet</a>, 
<a href="/search/cs?searchtype=author&query=Michel%2C+P">Paul Michel</a>, 
<a href="/search/cs?searchtype=author&query=Bruni%2C+E">Elia Bruni</a>, 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Curriculum learning (CL) posits that machine learning models -- similar to
humans -- may learn more efficiently from data that match their current
learning progress. However, CL methods are still poorly understood and, in
particular for natural language processing (NLP), have achieved only limited
success. In this paper, we explore why. Starting from an attempt to replicate
and extend a number of recent curriculum methods, we find that their results
are surprisingly brittle when applied to NLP. A deep dive into the
(in)effectiveness of the curricula in some scenarios shows us why: when
curricula are employed in combination with the popular Adam optimisation
algorithm, they oftentimes learn to adapt to suboptimally chosen optimisation
parameters for this algorithm. We present a number of different case studies
with different common hand-crafted and automated CL approaches to illustrate
this phenomenon, and we find that none of them outperforms optimisation with
only Adam with well-chosen hyperparameters. As such, our results contribute to
understanding why CL methods work, but at the same time urge caution when
claiming positive results.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12209" title="Abstract">arXiv:2308.12209</a> [<a href="/pdf/2308.12209" title="Download PDF">pdf</a>, <a href="/format/2308.12209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Heuristic Informative-Path-Planning Algorithm for Autonomous Mapping  of Unknown Areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orisatoki%2C+M+O">Mobolaji O. Orisatoki</a>, 
<a href="/search/cs?searchtype=author&query=Amouzadi%2C+M">Mahdi Amouzadi</a>, 
<a href="/search/cs?searchtype=author&query=Dizqah%2C+A+M">Arash M. Dizqah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 Pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Informative path planning algorithms are of paramount importance in
applications like disaster management to efficiently gather information through
a priori unknown environments. This is, however, a complex problem that
involves finding a globally optimal path that gathers the maximum amount of
information (e.g., the largest map with a minimum travelling distance) while
using partial and uncertain local measurements. This paper addresses this
problem by proposing a novel heuristic algorithm that continuously estimates
the potential mapping gain for different sub-areas across the partially created
map, and then uses these estimations to locally navigate the robot.
Furthermore, this paper presents a novel algorithm to calculate a benchmark
solution, where the map is a priori known to the planar, to evaluate the
efficacy of the developed heuristic algorithm over different test scenarios.
The findings indicate that the efficiency of the proposed algorithm, measured
in terms of the mapped area per unit of travelling distance, ranges from 70% to
80% of the benchmark solution in various test scenarios. In essence, the
algorithm demonstrates the capability to generate paths that come close to the
globally optimal path provided by the benchmark solution.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12210" title="Abstract">arXiv:2308.12210</a> [<a href="/pdf/2308.12210" title="Download PDF">pdf</a>, <a href="/format/2308.12210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ULDP-FL: Federated Learning with Across Silo User-Level Differential  Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+F">Fumiyuki Kato</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+S">Shun Takagi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+M">Masatoshi Yoshikawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differentially Private Federated Learning (DP-FL) has garnered attention as a
collaborative machine learning approach that ensures formal privacy. Most DP-FL
approaches ensure DP at the record-level within each silo for cross-silo FL.
However, a single user's data may extend across multiple silos, and the desired
user-level DP guarantee for such a setting remains unknown. In this study, we
present ULDP-FL, a novel FL framework designed to guarantee user-level DP in
cross-silo FL where a single user's data may belong to multiple silos. Our
proposed algorithm directly ensures user-level DP through per-user weighted
clipping, departing from group-privacy approaches. We provide a theoretical
analysis of the algorithm's privacy and utility. Additionally, we enhance the
algorithm's utility and showcase its private implementation using cryptographic
building blocks. Empirical experiments on real-world datasets show substantial
improvements in our methods in privacy-utility trade-offs under user-level DP
compared to baseline methods. To the best of our knowledge, our work is the
first FL framework that effectively provides user-level DP in the general
cross-silo FL setting.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12211" title="Abstract">arXiv:2308.12211</a> [<a href="/pdf/2308.12211" title="Download PDF">pdf</a>, <a href="/format/2308.12211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recording of 50 Business Assignments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sroka%2C+M">Michal Sroka</a>, 
<a href="/search/cs?searchtype=author&query=Sani%2C+M+F">Mohammadreza Fani Sani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. Describes a dataset published in github
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the main use cases of process mining is to discover and analyze how
users follow business assignments, providing valuable insights into process
efficiency and optimization. In this paper, we present a comprehensive dataset
consisting of 50 real business processes. The dataset holds significant
potential for research in various applications, including task mining and
process automation which is a valuable resource for researchers and
practitioners.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12213" title="Abstract">arXiv:2308.12213</a> [<a href="/pdf/2308.12213" title="Download PDF">pdf</a>, <a href="/format/2308.12213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huifeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection refers to training the model on an
in-distribution (ID) dataset to classify whether the input images come from
unknown classes. Considerable effort has been invested in designing various OOD
detection methods based on either convolutional neural networks or
transformers. However, zero-shot OOD detection methods driven by CLIP, which
only require class names for ID, have received less attention. This paper
presents a novel method, namely CLIP saying "no" (\textbf{CLIPN}), which
empowers the logic of saying "no" within CLIP. Our key motivation is to equip
CLIP with the capability of distinguishing OOD and ID samples using
positive-semantic prompts and negation-semantic prompts. Specifically, we
design a novel learnable "no" prompt and a "no" text encoder to capture
negation semantics within images. Subsequently, we introduce two loss
functions: the image-text binary-opposite loss and the text semantic-opposite
loss, which we use to teach CLIPN to associate images with "no" prompts,
thereby enabling it to identify unknown samples. Furthermore, we propose two
threshold-free inference algorithms to perform OOD detection by utilizing
negation semantics from "no" prompts and the text encoder. Experimental results
on 9 benchmark datasets (3 ID datasets and 6 OOD datasets) for the OOD
detection task demonstrate that CLIPN, based on ViT-B-16, outperforms 7
well-used algorithms by at least 2.34\% and 11.64\% in terms of AUROC and FPR95
for zero-shot OOD detection on ImageNet-1K. Our CLIPN can serve as a solid
foundation for effectively leveraging CLIP in downstream OOD tasks. The code is
available on
https://github.com/xmed-lab/CLIPN}{https://github.com/xmed-lab/CLIPN.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12215" title="Abstract">arXiv:2308.12215</a> [<a href="/pdf/2308.12215" title="Download PDF">pdf</a>, <a href="/format/2308.12215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Challenges of Machine Learning for Trust and Safety: A Case Study on  Misinformation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Madelyne Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+J">Jonathan Mayer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">We examine the disconnect between scholarship and practice in applying
machine learning to trust and safety problems, using misinformation detection
as a case study. We systematize literature on automated detection of
misinformation across a corpus of 270 well-cited papers in the field. We then
examine subsets of papers for data and code availability, design missteps,
reproducibility, and generalizability. We find significant shortcomings in the
literature that call into question claimed performance and practicality.
Detection tasks are often meaningfully distinct from the challenges that online
services actually face. Datasets and model evaluation are often
non-representative of real-world contexts, and evaluation frequently is not
independent of model training. Data and code availability is poor. Models do
not generalize well to out-of-domain data. Based on these results, we offer
recommendations for evaluating machine learning applications to trust and
safety problems. Our aim is for future work to avoid the pitfalls that we
identify.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12216" title="Abstract">arXiv:2308.12216</a> [<a href="/pdf/2308.12216" title="Download PDF">pdf</a>, <a href="/format/2308.12216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SG-Former: Self-guided Transformer with Evolving Token Reallocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sucheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformer has demonstrated impressive success across various vision
tasks. However, its heavy computation cost, which grows quadratically with
respect to the token sequence length, largely limits its power in handling
large feature maps. To alleviate the computation cost, previous works rely on
either fine-grained self-attentions restricted to local small regions, or
global self-attentions but to shorten the sequence length resulting in coarse
granularity. In this paper, we propose a novel model, termed as Self-guided
Transformer~(SG-Former), towards effective global self-attention with adaptive
fine granularity. At the heart of our approach is to utilize a significance
map, which is estimated through hybrid-scale self-attention and evolves itself
during training, to reallocate tokens based on the significance of each region.
Intuitively, we assign more tokens to the salient regions for achieving
fine-grained attention, while allocating fewer tokens to the minor regions in
exchange for efficiency and global receptive fields. The proposed SG-Former
achieves performance superior to state of the art: our base size model achieves
\textbf{84.7\%} Top-1 accuracy on ImageNet-1K, \textbf{51.2mAP} bbAP on CoCo,
\textbf{52.7mIoU} on ADE20K surpassing the Swin Transformer by \textbf{+1.3\% /
+2.7 mAP/ +3 mIoU}, with lower computation costs and fewer parameters. The code
is available at
\href{https://github.com/OliverRensu/SG-Former}{https://github.com/OliverRensu/SG-Former}
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12218" title="Abstract">arXiv:2308.12218</a> [<a href="/pdf/2308.12218" title="Download PDF">pdf</a>, <a href="/format/2308.12218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIParsing: Unifying Causality Properties into Multiple Human Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuanhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">HenTao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing methods of multiple human parsing (MHP) apply statistical models to
acquire underlying associations between images and labeled body parts. However,
acquired associations often contain many spurious correlations that degrade
model generalization, leading statistical models to be vulnerable to visually
contextual variations in images (e.g., unseen image styles/external
interventions). To tackle this, we present a causality inspired parsing
paradigm termed CIParsing, which follows fundamental causal principles
involving two causal properties for human parsing (i.e., the causal diversity
and the causal invariance). Specifically, we assume that an input image is
constructed by a mix of causal factors (the characteristics of body parts) and
non-causal factors (external contexts), where only the former ones cause the
generation process of human parsing.Since causal/non-causal factors are
unobservable, a human parser in proposed CIParsing is required to construct
latent representations of causal factors and learns to enforce representations
to satisfy the causal properties. In this way, the human parser is able to rely
on causal factors w.r.t relevant evidence rather than non-causal factors w.r.t
spurious correlations, thus alleviating model degradation and yielding improved
parsing ability. Notably, the CIParsing is designed in a plug-and-play fashion
and can be integrated into any existing MHP models. Extensive experiments
conducted on two widely used benchmarks demonstrate the effectiveness and
generalizability of our method.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12219" title="Abstract">arXiv:2308.12219</a> [<a href="/pdf/2308.12219" title="Download PDF">pdf</a>, <a href="/format/2308.12219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Language Models Can Perform Many Tasks with Scaling and  Instruction-Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiasheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zaixiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yu Bao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Lihua Qian</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent surge of generative AI has been fueled by the generative power of
diffusion probabilistic models and the scalable capabilities of large language
models. Despite their potential, it remains elusive whether diffusion language
models can solve general language tasks comparable to their autoregressive
counterparts. This paper demonstrates that scaling diffusion models w.r.t.
data, sizes, and tasks can effectively make them strong language learners. We
build competent diffusion language models at scale by first acquiring knowledge
from massive data via masked language modeling pretraining thanks to their
intrinsic connections. We then reprogram pretrained masked language models into
diffusion language models via diffusive adaptation, wherein task-specific
finetuning and instruction finetuning are explored to unlock their versatility
in solving general language tasks. Experiments show that scaling diffusion
language models consistently improves performance across downstream language
tasks. We further discover that instruction finetuning can elicit zero-shot and
few-shot in-context learning abilities that help tackle many unseen tasks by
following natural language instructions, and show promise in advanced and
challenging abilities such as reasoning
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12221" title="Abstract">arXiv:2308.12221</a> [<a href="/pdf/2308.12221" title="Download PDF">pdf</a>, <a href="/format/2308.12221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Learning Periods Emerge Even in Deep Linear Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleinman%2C+M">Michael Kleinman</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Critical learning periods are periods early in development where temporary
sensory deficits can have a permanent effect on behavior and learned
representations. Despite the radical differences between biological and
artificial networks, critical learning periods have been empirically observed
in both systems. This suggests that critical periods may be fundamental to
learning and not an accident of biology. Yet, why exactly critical periods
emerge in deep networks is still an open question, and in particular it is
unclear whether the critical periods observed in both systems depend on
particular architectural or optimization details. To isolate the key underlying
factors, we focus on deep linear network models, and show that, surprisingly,
such networks also display much of the behavior seen in biology and artificial
networks, while being amenable to analytical treatment. We show that critical
periods depend on the depth of the model and structure of the data
distribution. We also show analytically and in simulations that the learning of
features is tied to competition between sources. Finally, we extend our
analysis to multi-task learning to show that pre-training on certain tasks can
damage the transfer performance on new tasks, and show how this depends on the
relationship between tasks and the duration of the pre-training stage. To the
best of our knowledge, our work provides the first analytically tractable model
that sheds light into why critical learning periods emerge in biological and
artificial networks.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12228" title="Abstract">arXiv:2308.12228</a> [<a href="/pdf/2308.12228" title="Download PDF">pdf</a>, <a href="/format/2308.12228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electromagnets Under the Table: an Unobtrusive Magnetic Navigation  System for Microsurgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schonewille%2C+A">Adam Schonewille</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Changyan He</a>, 
<a href="/search/cs?searchtype=author&query=Forbrigger%2C+C">Cameron Forbrigger</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Nancy Wu</a>, 
<a href="/search/cs?searchtype=author&query=Drake%2C+J">James Drake</a>, 
<a href="/search/cs?searchtype=author&query=Looi%2C+T">Thomas Looi</a>, 
<a href="/search/cs?searchtype=author&query=Diller%2C+E">Eric Diller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Miniature magnetic tools have the potential to enable minimally invasive
surgical techniques to be applied to space-restricted surgical procedures in
areas such as neurosurgery. However, typical magnetic navigation systems, which
create the magnetic fields to drive such tools, either cannot generate large
enough fields, or surround the patient in a way that obstructs surgeon access
to the patient. This paper introduces the design of a magnetic navigation
system with eight electromagnets arranged completely under the operating table,
to endow the system with maximal workspace accessibility, which allows the
patient to lie down on the top surface of the system without any constraints.
The found optimal geometric layout of the electromagnets maximizes the field
strength and uniformity over a reasonable neurosurgical operating volume. The
system can generate non-uniform magnetic fields up to 38 mT along the x and y
axes and 47 mT along the z axis at a working distance of 120 mm away from the
actuation system workbench, deep enough to deploy magnetic microsurgical tools
in the brain. The forces which can be exerted on millimeter-scale magnets used
in prototype neurosurgical tools are validated experimentally. Due to its large
workspace, this system could be used to control milli-robots in a variety of
surgical applications.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12234" title="Abstract">arXiv:2308.12234</a> [<a href="/pdf/2308.12234" title="Download PDF">pdf</a>, <a href="/format/2308.12234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolGrapher: Graph-based Visual Recognition of Chemical Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morin%2C+L">Lucas Morin</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Agea%2C+M+I">Maria Isabel Agea</a>, 
<a href="/search/cs?searchtype=author&query=Nassar%2C+A">Ahmed Nassar</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+V">Valery Weber</a>, 
<a href="/search/cs?searchtype=author&query=Meijer%2C+I">Ingmar Meijer</a>, 
<a href="/search/cs?searchtype=author&query=Staar%2C+P">Peter Staar</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The automatic analysis of chemical literature has immense potential to
accelerate the discovery of new materials and drugs. Much of the critical
information in patent documents and scientific articles is contained in
figures, depicting the molecule structures. However, automatically parsing the
exact chemical structure is a formidable challenge, due to the amount of
detailed information, the diversity of drawing styles, and the need for
training data. In this work, we introduce MolGrapher to recognize chemical
structures visually. First, a deep keypoint detector detects the atoms. Second,
we treat all candidate atoms and bonds as nodes and put them in a graph. This
construct allows a natural graph representation of the molecule. Last, we
classify atom and bond nodes in the graph with a Graph Neural Network. To
address the lack of real training data, we propose a synthetic data generation
pipeline producing diverse and realistic results. In addition, we introduce a
large-scale benchmark of annotated real molecule images, USPTO-30K, to spur
research on this critical topic. Extensive experiments on five datasets show
that our approach significantly outperforms classical and learning-based
methods in most settings. Code, models, and datasets are available.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12238" title="Abstract">arXiv:2308.12238</a> [<a href="/pdf/2308.12238" title="Download PDF">pdf</a>, <a href="/format/2308.12238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NimbRo wins ANA Avatar XPRIZE Immersive Telepresence Competition:  Human-Centric Evaluation and Lessons Learned
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lenz%2C+C">Christian Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+M">Max Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Rochow%2C+A">Andre Rochow</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A4tzold%2C+B">Bastian P&#xe4;tzold</a>, 
<a href="/search/cs?searchtype=author&query=Memmesheimer%2C+R">Raphael Memmesheimer</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+M">Michael Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> C. Lenz and M. Schwarz contributed equally. Accepted for International Journal of Social Robotics (SORO), Springer, to appear 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic avatar systems can enable immersive telepresence with locomotion,
manipulation, and communication capabilities. We present such an avatar system,
based on the key components of immersive 3D visualization and transparent
force-feedback telemanipulation. Our avatar robot features an anthropomorphic
upper body with dexterous hands. The remote human operator drives the arms and
fingers through an exoskeleton-based operator station, which provides force
feedback both at the wrist and for each finger. The robot torso is mounted on a
holonomic base, providing omnidirectional locomotion on flat floors, controlled
using a 3D rudder device. Finally, the robot features a 6D movable head with
stereo cameras, which stream images to a VR display worn by the operator.
Movement latency is hidden using spherical rendering. The head also carries a
telepresence screen displaying an animated image of the operator's face,
enabling direct interaction with remote persons. Our system won the \$10M ANA
Avatar XPRIZE competition, which challenged teams to develop intuitive and
immersive avatar systems that could be operated by briefly trained judges. We
analyze our successful participation in the semifinals and finals and provide
insight into our operator training and lessons learned. In addition, we
evaluate our system in a user study that demonstrates its intuitive and easy
usability.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12241" title="Abstract">arXiv:2308.12241</a> [<a href="/pdf/2308.12241" title="Download PDF">pdf</a>, <a href="/format/2308.12241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMRec: Benchmarking Large Language Models on Recommendation Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qichen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+D">Dading Chong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yueqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuwei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chenyu You</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S.Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, the fast development of Large Language Models (LLMs) such as
ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of
conversational models. However, the application of LLMs in the recommendation
domain has not been thoroughly investigated. To bridge this gap, we propose
LLMRec, a LLM-based recommender system designed for benchmarking LLMs on
various recommendation tasks. Specifically, we benchmark several popular
off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation
tasks, including rating prediction, sequential recommendation, direct
recommendation, explanation generation, and review summarization. Furthermore,
we investigate the effectiveness of supervised finetuning to improve LLMs'
instruction compliance ability. The benchmark results indicate that LLMs
displayed only moderate proficiency in accuracy-based tasks such as sequential
and direct recommendation. However, they demonstrated comparable performance to
state-of-the-art methods in explainability-based tasks. We also conduct
qualitative evaluations to further evaluate the quality of contents generated
by different models, and the results show that LLMs can truly understand the
provided information and generate clearer and more reasonable results. We
aspire that this benchmark will serve as an inspiration for researchers to
delve deeper into the potential of LLMs in enhancing recommendation
performance. Our codes, processed data and benchmark results are available at
https://github.com/williamliujl/LLMRec.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12242" title="Abstract">arXiv:2308.12242</a> [<a href="/pdf/2308.12242" title="Download PDF">pdf</a>, <a href="/ps/2308.12242" title="Download PostScript">ps</a>, <a href="/format/2308.12242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Developments in Pandora&#x27;s Box Problem: Variants and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beyhaghi%2C+H">Hedyeh Beyhaghi</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Linda Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The survey appears in ACM SIGecom Exchanges, Vol. 21, No. 1, June 2023. <a href="https://www.sigecom.org/exchanges/volume_21/1/BEYHAGHI.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">In 1979, Weitzman introduced Pandora's box problem as a framework for
sequential search with costly inspections. Recently, there has been a surge of
interest in Pandora's box problem, particularly among researchers working at
the intersection of economics and computation. This survey provides an overview
of the recent literature on Pandora's box problem, including its latest
extensions and applications in areas such as market design, decision theory,
and machine learning.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12243" title="Abstract">arXiv:2308.12243</a> [<a href="/pdf/2308.12243" title="Download PDF">pdf</a>, <a href="/format/2308.12243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Optimization for Sparse Deep Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hotegni%2C+S+S">S. S. Hotegni</a>, 
<a href="/search/cs?searchtype=author&query=Peitz%2C+S">S. Peitz</a>, 
<a href="/search/cs?searchtype=author&query=Berkemeier%2C+M">M. Berkemeier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Different conflicting optimization criteria arise naturally in various Deep
Learning scenarios. These can address different main tasks (i.e., in the
setting of Multi-Task Learning), but also main and secondary tasks such as loss
minimization versus sparsity. The usual approach is a simple weighting of the
criteria, which formally only works in the convex setting. In this paper, we
present a Multi-Objective Optimization algorithm using a modified Weighted
Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect
to several tasks. By employing this scalarization technique, the algorithm can
identify all optimal solutions of the original problem while reducing its
complexity to a sequence of single-objective problems. The simplified problems
are then solved using an Augmented Lagrangian method, enabling the use of
popular optimization techniques such as Adam and Stochastic Gradient Descent,
while efficaciously handling constraints. Our work aims to address the
(economical and also ecological) sustainability issue of DNN models, with a
particular focus on Deep Multi-Task models, which are typically designed with a
very large number of weights to perform equally well on multiple tasks. Through
experiments conducted on two Machine Learning datasets, we demonstrate the
possibility of adaptively sparsifying the model during training without
significantly impacting its performance, if we are willing to apply
task-specific adaptations to the network weights. Code is available at
https://github.com/salomonhotegni/MDMTN.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12247" title="Abstract">arXiv:2308.12247</a> [<a href="/pdf/2308.12247" title="Download PDF">pdf</a>, <a href="/format/2308.12247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Protect Copyright Data in Optimization of Large Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Timothy Chu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chiwun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) and generative AI have played a transformative
role in computer research and applications. Controversy has arisen as to
whether these models output copyrighted data, which can occur if the data the
models are trained on is copyrighted. LLMs are built on the transformer neural
network architecture, which in turn relies on a mathematical computation called
Attention that uses the softmax function.
<br />In this paper, we show that large language model training and optimization
can be seen as a softmax regression problem. We then establish a method of
efficiently performing softmax regression, in a way that prevents the
regression function from generating copyright data. This establishes a
theoretical method of training large language models in a way that avoids
generating copyright data.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12248" title="Abstract">arXiv:2308.12248</a> [<a href="/pdf/2308.12248" title="Download PDF">pdf</a>, <a href="/ps/2308.12248" title="Download PostScript">ps</a>, <a href="/format/2308.12248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holographic RIS Empowered THz Communications with Hardware Imperfections  under Adverse Weather Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Boulogeorgos%2C+A+A">Alexandros-Apostolos A. Boulogeorgos</a>, 
<a href="/search/eess?searchtype=author&query=Trevlakis%2C+S">Stylianos Trevlakis</a>, 
<a href="/search/eess?searchtype=author&query=Tsiftsis%2C+T+A">Theodoros A. Tsiftsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper focuses on providing a theoretical framework for the evaluation of
the performance of holographic reconfigurable intelligent surface (HRIS)
empowered terahertz (THz) wireless systems under fog conditions. In more
detail, we present a comprehensive methodology for evaluating the geometric
losses of the end-to-end channel. Moreover, the stochastic nature of the
end-to-end channel is characterized by novel closed-form probability density
and cumulative distribution functions. Building upon them, the outage
probability and the throughput of the system are extracted in closed form.
These formulas account for the impact of transceiver hardware imperfections and
are expected to become useful tools for the design of HRIS empowered THz
wireless systems due to its remarkable engineering insights.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12252" title="Abstract">arXiv:2308.12252</a> [<a href="/pdf/2308.12252" title="Download PDF">pdf</a>, <a href="/format/2308.12252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Safe Am I Given What I See? Calibrated Prediction of Safety Chances  for Image-Controlled Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhenjiang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Sobolewski%2C+C">Carson Sobolewski</a>, 
<a href="/search/cs?searchtype=author&query=Ruchkin%2C+I">Ivan Ruchkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">End-to-end learning has emerged as a major paradigm for developing autonomous
systems. Unfortunately, with its performance and convenience comes an even
greater challenge of safety assurance. A key factor of this challenge is the
absence of the notion of a low-dimensional and interpretable dynamical state,
around which traditional assurance methods revolve. Focusing on the online
safety prediction problem, this paper proposes a configurable family of
learning pipelines based on generative world models, which do not require
low-dimensional states. To implement these pipelines, we overcome the
challenges of learning safety-informed latent representations and missing
safety labels under prediction-induced distribution shift. These pipelines come
with statistical calibration guarantees on their safety chance predictions
based on conformal prediction. We perform an extensive evaluation of the
proposed learning pipelines on two case studies of image-controlled systems: a
racing car and a cartpole.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12255" title="Abstract">arXiv:2308.12255</a> [<a href="/pdf/2308.12255" title="Download PDF">pdf</a>, <a href="/format/2308.12255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Absorbing boundary conditions for the Helmholtz equation using  Gauss-Legendre quadrature reduced integrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sagiyama%2C+K">Koki Sagiyama</a>, 
<a href="/search/math?searchtype=author&query=Ham%2C+D+A">David A. Ham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Draft version for submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We introduce a new class of absorbing boundary conditions (ABCs) for the
Helmholtz equation. The proposed ABCs can be derived from a certain simple
class of perfectly matched layers using $L$ discrete layers and using the $Q_N$
Lagrange finite element in conjunction with the $N$-point Gauss-Legendre
quadrature reduced integration rule. The proposed ABCs are classified by a
tuple $(L,N)$, and achieve reflection error of order $O(R^{2LN})$ for some
$R&lt;1$. The new ABCs generalise the perfectly matched discrete layers proposed
by Guddati and Lim [Int. J. Numer. Meth. Engng 66 (6) (2006) 949-977],
including them as type $(L,1)$. An analysis of the proposed ABCs is performed
motivated by the work of Ainsworth [J. Comput. Phys. 198 (1) (2004) 106-130].
The new ABCs facilitate numerical implementations of the Helmholtz problem with
ABCs if $Q_N$ finite elements are used in the physical domain. Moreover, giving
more insight, the analysis presented in this work potentially aids with
developing ABCs in related areas.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12256" title="Abstract">arXiv:2308.12256</a> [<a href="/pdf/2308.12256" title="Download PDF">pdf</a>, <a href="/format/2308.12256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Negative User Feedback and Measuring Responsiveness for  Sequential Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yueqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+Y">Yoni Halpern</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shuo Chang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jingchen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+E+Y">Elaine Ya Le</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xujian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Min-Cheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shane Li</a>, 
<a href="/search/cs?searchtype=author&query=Beutel%2C+A">Alex Beutel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Shuchao Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RecSys 2023 Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sequential recommenders have been widely used in industry due to their
strength in modeling user preferences. While these models excel at learning a
user's positive interests, less attention has been paid to learning from
negative user feedback. Negative user feedback is an important lever of user
control, and comes with an expectation that recommenders should respond quickly
and reduce similar recommendations to the user. However, negative feedback
signals are often ignored in the training objective of sequential retrieval
models, which primarily aim at predicting positive user interactions. In this
work, we incorporate explicit and implicit negative user feedback into the
training objective of sequential recommenders in the retrieval stage using a
"not-to-recommend" loss function that optimizes for the log-likelihood of not
recommending items with negative feedback. We demonstrate the effectiveness of
this approach using live experiments on a large-scale industrial recommender
system. Furthermore, we address a challenge in measuring recommender
responsiveness to negative feedback by developing a counterfactual simulation
framework to compare recommender responses between different user actions,
showing improved responsiveness from the modeling change.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12258" title="Abstract">arXiv:2308.12258</a> [<a href="/pdf/2308.12258" title="Download PDF">pdf</a>, <a href="/format/2308.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovating Computer Programming Pedagogy: The AI-Lab Framework for  Generative AI Adoption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dickey%2C+E">Ethan Dickey</a>, 
<a href="/search/cs?searchtype=author&query=Bejarano%2C+A">Andres Bejarano</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+C">Chirayu Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages plus references and appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Over the last year, the ascent of Generative AI (GenAI) has raised concerns
about its impact on core skill development, such as problem-solving and
algorithmic thinking, in Computer Science students. Preliminary anonymous
surveys show that at least 48.5% of our students use GenAI for homework. With
the proliferation of these tools, the academic community must contemplate the
appropriate role of these tools in education. Neglecting this might culminate
in a phenomenon we term the "Junior-Year Wall," where students struggle in
advanced courses due to prior over-dependence on GenAI. Instead of discouraging
GenAI use, which may unintentionally foster covert usage, our research seeks to
answer: "How can educators guide students' interactions with GenAI to preserve
core skill development during their foundational academic years?"
<br />We introduce "AI-Lab," a pedagogical framework for guiding students in
effectively leveraging GenAI within core collegiate programming courses. This
framework accentuates GenAI's benefits and potential as a pedagogical
instrument. By identifying and rectifying GenAI's errors, students enrich their
learning process. Moreover, AI-Lab presents opportunities to use GenAI for
tailored support such as topic introductions, detailed examples, corner case
identification, rephrased explanations, and debugging assistance. Importantly,
the framework highlights the risks of GenAI over-dependence, aiming to
intrinsically motivate students towards balanced usage. This approach is
premised on the idea that mere warnings of GenAI's potential failures may be
misconstrued as instructional shortcomings rather than genuine tool
limitations.
<br />Additionally, AI-Lab offers strategies for formulating prompts to elicit
high-quality GenAI responses. For educators, AI-Lab provides mechanisms to
explore students' perceptions of GenAI's role in their learning experience.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12261" title="Abstract">arXiv:2308.12261</a> [<a href="/pdf/2308.12261" title="Download PDF">pdf</a>, <a href="/format/2308.12261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt2Model: Generating Deployable Models from Natural Language  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vijay Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bertsch%2C+A">Amanda Bertsch</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) enable system builders today to create competent
NLP systems through prompting, where they only need to describe the task in
natural language and provide a few examples. However, in other ways, LLMs are a
step backward from traditional special-purpose NLP models; they require
extensive computational resources for deployment and can be gated behind APIs.
In this paper, we propose Prompt2Model, a general-purpose method that takes a
natural language task description like the prompts provided to LLMs, and uses
it to train a special-purpose model that is conducive to deployment. This is
done through a multi-step process of retrieval of existing datasets and
pretrained models, dataset generation using LLMs, and supervised fine-tuning on
these retrieved and generated datasets. Over three tasks, we demonstrate that
given the same few-shot prompt as input, Prompt2Model trains models that
outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20%
while being up to 700 times smaller. We also show that this data can be used to
obtain reliable performance estimates of model performance, enabling model
developers to assess model reliability before deployment. Prompt2Model is
available open-source at https://github.com/neulab/prompt2model.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12264" title="Abstract">arXiv:2308.12264</a> [<a href="/pdf/2308.12264" title="Download PDF">pdf</a>, <a href="/format/2308.12264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+S">Saurabhsingh Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Widmayer%2C+T">Tim Widmayer</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziyuan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Kechagia%2C+M">Maria Kechagia</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tushar Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF); Software Engineering (cs.SE)

</div>
<p class="mathjax">With the increasing usage, scale, and complexity of Deep Learning (DL)
models, their rapidly growing energy consumption has become a critical concern.
Promoting green development and energy awareness at different granularities is
the need of the hour to limit carbon emissions of DL systems. However, the lack
of standard and repeatable tools to accurately measure and optimize energy
consumption at a fine granularity (e.g., at method level) hinders progress in
this area. In this paper, we introduce FECoM (Fine-grained Energy Consumption
Meter), a framework for fine-grained DL energy consumption measurement.
Specifically, FECoM provides researchers and developers a mechanism to profile
DL APIs. FECoM addresses the challenges of measuring energy consumption at
fine-grained level by using static instrumentation and considering various
factors, including computational load and temperature stability. We assess
FECoM's capability to measure fine-grained energy consumption for one of the
most popular open-source DL frameworks, namely TensorFlow. Using FECoM, we also
investigate the impact of parameter size and execution time on energy
consumption, enriching our understanding of TensorFlow APIs' energy profiles.
Furthermore, we elaborate on the considerations, issues, and challenges that
one needs to consider while designing and implementing a fine-grained energy
consumption measurement tool. We hope this work will facilitate further
advances in DL energy measurement and the development of energy-aware practices
for DL systems.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12265" title="Abstract">arXiv:2308.12265</a> [<a href="/pdf/2308.12265" title="Download PDF">pdf</a>, <a href="/format/2308.12265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Navigation with Online Delays is PSPACE-complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Depian%2C+T">Thomas Depian</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+C">Christoph Kern</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6der%2C+S">Sebastian R&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Terziadis%2C+S">Soeren Terziadis</a>, 
<a href="/search/cs?searchtype=author&query=Wallinger%2C+M">Markus Wallinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In public transport networks disruptions may occur and lead to travel delays.
It is thus interesting to determine whether a traveler can be resilient to
delays that occur unexpectedly, ensuring that they can reach their destination
in time regardless. We model this as a game between the traveler and a
delay-introducing adversary. We study the computational complexity of the
problem of deciding whether the traveler has a winning strategy in this game.
Our main result is that this problem is PSPACE-complete.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12266" title="Abstract">arXiv:2308.12266</a> [<a href="/pdf/2308.12266" title="Download PDF">pdf</a>, <a href="/format/2308.12266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age of Gossip on Generalized Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Arunabh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a gossip network consisting of a source forwarding updates and
$n$ nodes placed geometrically in a ring formation. Each node gossips with
$f(n)$ nodes on either side, thus communicating with $2f(n)$ nodes in total.
$f(n)$ is a sub-linear, non-decreasing and positive function. The source keeps
updates of a process, that might be generated or observed, and shares them with
the nodes in the ring network. The nodes in the ring network communicate with
their neighbors and disseminate these version updates using a push-style gossip
strategy. We use the version age metric to quantify the timeliness of
information at the nodes. Prior to this work, it was shown that the version age
scales as $O(n^{\frac{1}{2}})$ in a ring network, i.e., when $f(n)=1$, and as
$O(\log{n})$ in a fully-connected network, i.e., when $2f(n)=n-1$. In this
paper, we find an upper bound for the average version age for a set of nodes in
such a network in terms of the number of nodes $n$ and the number of gossiped
neighbors $2 f(n)$. We show that if $f(n) = \Omega(\frac{n}{\log^2{n}})$, then
the version age still scales as $\theta(\log{n})$. We also show that if $f(n)$
is a rational function, then the version age also scales as a rational
function. In particular, if $f(n)=n^\alpha$, then version age is
$O(n^\frac{1-\alpha}{2})$. Finally, through numerical calculations we verify
that, for all practical purposes, if $f(n) = \Omega(n^{0.6})$, the version age
scales as $O(\log{n})$.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12267" title="Abstract">arXiv:2308.12267</a> [<a href="/pdf/2308.12267" title="Download PDF">pdf</a>, <a href="/format/2308.12267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bugsplainer: Leveraging Code Structures to Explain Software Bugs with  Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahbub%2C+P">Parvez Mahbub</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Mohammad Masudur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Shuvo%2C+O">Ohiduzzaman Shuvo</a>, 
<a href="/search/cs?searchtype=author&query=Gopal%2C+A">Avinash Gopal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.04584">arXiv:2212.04584</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software bugs cost the global economy billions of dollars each year and take
up ~50% of the development time. Once a bug is reported, the assigned developer
attempts to identify and understand the source code responsible for the bug and
then corrects the code. Over the last five decades, there has been significant
research on automatically finding or correcting software bugs. However, there
has been little research on automatically explaining the bugs to the
developers, which is essential but a highly challenging task. In this paper, we
propose Bugsplainer, a novel web-based debugging solution that generates
natural language explanations for software bugs by learning from a large corpus
of bug-fix commits. Bugsplainer leverages code structures to reason about a bug
and employs the fine-tuned version of a text generation model, CodeT5, to
generate the explanations.
<br />Tool video: https://youtu.be/xga-ScvULpk
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12270" title="Abstract">arXiv:2308.12270</a> [<a href="/pdf/2308.12270" title="Download PDF">pdf</a>, <a href="/format/2308.12270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Reward Modulation for Pretraining Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adeniji%2C+A">Ademi Adeniji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+A">Amber Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sferrazza%2C+C">Carmelo Sferrazza</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Younggyo Seo</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Stephen James</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/ademiadeniji/lamp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Using learned reward functions (LRFs) as a means to solve sparse-reward
reinforcement learning (RL) tasks has yielded some steady progress in
task-complexity through the years. In this work, we question whether today's
LRFs are best-suited as a direct replacement for task rewards. Instead, we
propose leveraging the capabilities of LRFs as a pretraining signal for RL.
Concretely, we propose $\textbf{LA}$nguage Reward $\textbf{M}$odulated
$\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of
Vision-Language Models (VLMs) as a $\textit{pretraining}$ utility for RL as
opposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to
scalably generate noisy, albeit shaped exploration rewards by computing the
contrastive alignment between a highly diverse collection of language
instructions and the image observations of an agent in its pretraining
environment. LAMP optimizes these rewards in conjunction with standard
novelty-seeking exploration rewards with reinforcement learning to acquire a
language-conditioned, pretrained policy. Our VLM pretraining approach, which is
a departure from previous attempts to use LRFs, can warmstart sample-efficient
learning on robot manipulation tasks in RLBench.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12271" title="Abstract">arXiv:2308.12271</a> [<a href="/pdf/2308.12271" title="Download PDF">pdf</a>, <a href="/format/2308.12271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Approach for Image Registration of Visible-Thermal (VT)  Cancer Faces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ordun%2C+C">Catherine Ordun</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+A">Alexandra Cha</a>, 
<a href="/search/cs?searchtype=author&query=Raff%2C+E">Edward Raff</a>, 
<a href="/search/cs?searchtype=author&query=Purushotham%2C+S">Sanjay Purushotham</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+K">Karen Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Rule%2C+M">Mason Rule</a>, 
<a href="/search/cs?searchtype=author&query=Gulley%2C+J">James Gulley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2nd Annual Artificial Intelligence over Infrared Images for Medical Applications Workshop (AIIIMA) at the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2nd Annual Artificial Intelligence over Infrared Images for
  Medical Applications Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since thermal imagery offers a unique modality to investigate pain, the U.S.
National Institutes of Health (NIH) has collected a large and diverse set of
cancer patient facial thermograms for AI-based pain research. However,
differing angles from camera capture between thermal and visible sensors has
led to misalignment between Visible-Thermal (VT) images. We modernize the
classic computer vision task of image registration by applying and modifying a
generative alignment algorithm to register VT cancer faces, without the need
for a reference or alignment parameters. By registering VT faces, we
demonstrate that the quality of thermal images produced in the generative AI
downstream task of Visible-to-Thermal (V2T) image translation significantly
improves up to 52.5\%, than without registration. Images in this paper have
been approved by the NIH NCI for public dissemination.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12272" title="Abstract">arXiv:2308.12272</a> [<a href="/pdf/2308.12272" title="Download PDF">pdf</a>, <a href="/format/2308.12272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple is Better and Large is Not Enough: Towards Ensembling of  Foundational Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+N">Nancy Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Shiri%2C+A">Aidin Shiri</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Surjodeep Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Umrawal%2C+A+K">Abhishek Kumar Umrawal</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 10th Mid-Atlantic Student Colloquium on Speech, Language and Learning (MASC-SLL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Foundational Language Models (FLMs) have advanced natural language processing
(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,
T5) to enable contextualized language representation, classification, and
generation. While developing larger FLMs has been of significant advantage, it
is also a liability concerning hallucination and predictive uncertainty.
Fundamentally, larger FLMs are built on the same foundations as smaller FLMs
(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can
be realized through an ensemble. In the current research, we perform a reality
check on FLMs and their ensemble on benchmark and real-world datasets. We
hypothesize that the ensembling of FLMs can influence the individualistic
attention of FLMs and unravel the strength of coordination and cooperation of
different FLMs. We utilize BERT and define three other ensemble techniques:
{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a
knowledge-guided reinforcement learning approach. We discovered that the
suggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by
a factor of many times using datasets that show the usefulness of NLP in
sensitive fields, such as mental health.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12275" title="Abstract">arXiv:2308.12275</a> [<a href="/pdf/2308.12275" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compression Performance Analysis of Different File Formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Han Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+G">Guangjun Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yongqing Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In data storage and transmission, file compression is a common technique for
reducing the volume of data, reducing data storage space and transmission time
and bandwidth. However, there are significant differences in the compression
performance of different types of file formats, and the benefits vary. In this
paper, 22 file formats with approximately 178GB of data were collected and the
Zlib algorithm was used for compression experiments to compare performance in
order to investigate the compression gains of different file types. The
experimental results show that some file types are poorly compressed, with
almost constant file size and long compression time, resulting in lower gains;
some other file types are significantly reduced in file size and compression
time after compression, which can effectively reduce the data volume. Based on
the above experimental results, this paper will then selectively reduce the
data volume by compression in data storage and transmission for the file types
in order to obtain the maximum compression yield.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12276" title="Abstract">arXiv:2308.12276</a> [<a href="/pdf/2308.12276" title="Download PDF">pdf</a>, <a href="/format/2308.12276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model for Integrating Generative AI into Course Content Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dickey%2C+E">Ethan Dickey</a>, 
<a href="/search/cs?searchtype=author&query=Bejarano%2C+A">Andres Bejarano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages plus references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">As Generative AI (GenAI) models continue to gain prominence, a new frontier
is emerging in the field of computer science education. Results from initial
anonymous surveys reveal that nearly half (48.5%) of our students now turn to
GenAI for academic assignments, highlighting its growing role in modern
education. With educators facing challenges in creating dynamic and unique
course content, the potential of GenAI becomes evident. It offers not only a
quicker method for content development but also paves the way for diversified,
high-quality educational resources, countering traditional cheating methods and
catering to varied student needs. Key questions thus arise: "How can GenAI
assist instructors in creating meaningful content and problems quickly, and can
it reduce the instructional staff's workload?"
<br />Addressing the first question, we unveil the "GenAI Content Generation
Framework". This novel tool equips educators to tap into the prowess of GenAI
for course content design. The framework presents a systematic and practical
blueprint for generating university-level course material through chat-based
GenAI. Drawing from our first-hand experiences, we provide strategic guidance
on formulating inquiries and organizing GenAI sessions to elicit quality
content that aligns with specific educational goals and context.
<br />Our work stands apart by outlining a specific workflow and offering concrete
suggestions for harnessing GenAI in course material development, backed by a
strong case for its adoption. Armed with the framework and insights presented
in this paper, educators and course content developers can move forward with
assurance, tapping into GenAI's vast potential for innovative content creation.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12277" title="Abstract">arXiv:2308.12277</a> [<a href="/pdf/2308.12277" title="Download PDF">pdf</a>, <a href="/format/2308.12277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operational requirements for localization in autonomous vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusari%2C+A">Arpan Kusari</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Satabdi Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IROS 2023 Localization Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous vehicles (AVs) need to determine their position and orientation
accurately with respect to global coordinate system or local features under
different scene geometries, traffic conditions and environmental conditions.
\cite{reid2019localization} provides a comprehensive framework for the
localization requirements for AVs. However, the framework is too restrictive
whereby - (a) only a very small deviation from the lane is tolerated (one every
$10^{8}$ hours), (b) all roadway types are considered same without any
attention to restriction provided by the environment onto the localization and
(c) the temporal nature of the location and orientation is not considered in
the requirements. In this research, we present a more practical view of the
localization requirement aimed at keeping the AV safe during an operation. We
present the following novel contributions - (a) we propose a deviation penalty
as a cumulative distribution function of the Weibull distribution which starts
from the adjacent lane boundary, (b) we customize the parameters of the
deviation penalty according to the current roadway type, particular lane
boundary that the ego vehicle is against and roadway curvature and (c) we
update the deviation penalty based on the available gap in the adjacent lane.
We postulate that this formulation can provide a more robust and achievable
view of the localization requirements than previous research while focusing on
safety.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12279" title="Abstract">arXiv:2308.12279</a> [<a href="/pdf/2308.12279" title="Download PDF">pdf</a>, <a href="/format/2308.12279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-Manifold Projected Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahler%2C+A">Aaron Mahler</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+T">Tyrus Berry</a>, 
<a href="/search/cs?searchtype=author&query=Stephens%2C+T">Tom Stephens</a>, 
<a href="/search/cs?searchtype=author&query=Antil%2C+H">Harbir Antil</a>, 
<a href="/search/cs?searchtype=author&query=Merritt%2C+M">Michael Merritt</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+J">Jeanie Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I">Ioannis Kevrekidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work provides a computable, direct, and mathematically rigorous
approximation to the differential geometry of class manifolds for
high-dimensional data, along with nonlinear projections from input space onto
these class manifolds. The tools are applied to the setting of neural network
image classifiers, where we generate novel, on-manifold data samples, and
implement a projected gradient descent algorithm for on-manifold adversarial
training. The susceptibility of neural networks (NNs) to adversarial attack
highlights the brittle nature of NN decision boundaries in input space.
Introducing adversarial examples during training has been shown to reduce the
susceptibility of NNs to adversarial attack; however, it has also been shown to
reduce the accuracy of the classifier if the examples are not valid examples
for that class. Realistic "on-manifold" examples have been previously generated
from class manifolds in the latent of an autoencoder. Our work explores these
phenomena in a geometric and computational setting that is much closer to the
raw, high-dimensional input space than can be provided by VAE or other black
box dimensionality reductions. We employ conformally invariant diffusion maps
(CIDM) to approximate class manifolds in diffusion coordinates, and develop the
Nystr\"{o}m projection to project novel points onto class manifolds in this
setting. On top of the manifold approximation, we leverage the spectral
exterior calculus (SEC) to determine geometric quantities such as tangent
vectors of the manifold. We use these tools to obtain adversarial examples that
reside on a class manifold, yet fool a classifier. These misclassifications
then become explainable in terms of human-understandable manipulations within
the data, by expressing the on-manifold adversary in the semantic basis on the
manifold.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12280" title="Abstract">arXiv:2308.12280</a> [<a href="/pdf/2308.12280" title="Download PDF">pdf</a>, <a href="/format/2308.12280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss  via Area Under the Curve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%2C+G">Gokulprasath R</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This research enhances linear regression models by integrating a Kalman
filter and analysing curve areas to minimize loss. The goal is to develop an
optimal linear regression equation using stochastic gradient descent (SGD) for
weight updating. Our approach involves a stepwise process, starting with
user-defined parameters. The linear regression model is trained using SGD,
tracking weights and loss separately and zipping them finally. A Kalman filter
is then trained based on weight and loss arrays to predict the next
consolidated weights. Predictions result from multiplying input averages with
weights, evaluated for loss to form a weight-versus-loss curve. The curve's
equation is derived using the two-point formula, and area under the curve is
calculated via integration. The linear regression equation with minimum area
becomes the optimal curve for prediction. Benefits include avoiding constant
weight updates via gradient descent and working with partial datasets, unlike
methods needing the entire set. However, computational complexity should be
considered. The Kalman filter's accuracy might diminish beyond a certain
prediction range.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12284" title="Abstract">arXiv:2308.12284</a> [<a href="/pdf/2308.12284" title="Download PDF">pdf</a>, <a href="/format/2308.12284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D4: Improving LLM Pretraining via Document De-Duplication and  Diversification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirumala%2C+K">Kushal Tirumala</a>, 
<a href="/search/cs?searchtype=author&query=Simig%2C+D">Daniel Simig</a>, 
<a href="/search/cs?searchtype=author&query=Aghajanyan%2C+A">Armen Aghajanyan</a>, 
<a href="/search/cs?searchtype=author&query=Morcos%2C+A+S">Ari S. Morcos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Over recent years, an increasing amount of compute and data has been poured
into training large language models (LLMs), usually by doing one-pass learning
on as many tokens as possible randomly selected from large-scale web corpora.
While training on ever-larger portions of the internet leads to consistent
performance improvements, the size of these improvements diminishes with scale,
and there has been little work exploring the effect of data selection on
pre-training and downstream performance beyond simple de-duplication methods
such as MinHash. Here, we show that careful data selection (on top of
de-duplicated data) via pre-trained model embeddings can speed up training (20%
efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up
to 2%) at the 6.7B model scale. Furthermore, we show that repeating data
intelligently consistently outperforms baseline training (while repeating
random data performs worse than baseline training). Our results indicate that
clever data selection can significantly improve LLM pre-training, calls into
question the common practice of training for a single epoch on as much data as
possible, and demonstrates a path to keep improving our models past the limits
of randomly sampling web data.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12287" title="Abstract">arXiv:2308.12287</a> [<a href="/pdf/2308.12287" title="Download PDF">pdf</a>, <a href="/format/2308.12287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Devising and Detecting Phishing: large language models vs. Smaller Human  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heiding%2C+F">Fredrik Heiding</a>, 
<a href="/search/cs?searchtype=author&query=Schneier%2C+B">Bruce Schneier</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+A">Arun Vishwanath</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+J">Jeremy Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">AI programs, built using large language models, make it possible to
automatically create phishing emails based on a few data points about a user.
They stand in contrast to traditional phishing emails that hackers manually
design using general rules gleaned from experience. The V-Triad is an advanced
set of rules for manually designing phishing emails to exploit our cognitive
heuristics and biases. In this study, we compare the performance of phishing
emails created automatically by GPT-4 and manually using the V-Triad. We also
combine GPT-4 with the V-Triad to assess their combined potential. A fourth
group, exposed to generic phishing emails, was our control group. We utilized a
factorial approach, sending emails to 112 randomly selected participants
recruited for the study. The control group emails received a click-through rate
between 19-28%, the GPT-generated emails 30-44%, emails generated by the
V-Triad 69-79%, and emails generated by GPT and the V-Triad 43-81%. Each
participant was asked to explain for why they pressed or did not press a link
in the email. These answers often contradict each other, highlighting the need
for personalized content. The cues that make one person avoid phishing emails
make another person fall for them. Next, we used four popular large language
models (GPT, Claude, PaLM, and LLaMA) to detect the intention of phishing
emails and compare the results to human detection. The language models
demonstrated a strong ability to detect malicious intent, even in non-obvious
phishing emails. They sometimes surpassed human detection, although often being
slightly less accurate than humans.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12288" title="Abstract">arXiv:2308.12288</a> [<a href="/pdf/2308.12288" title="Download PDF">pdf</a>, <a href="/format/2308.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from  Unbounded Synthesized Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sookwan Han</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral Presentation). Project Page: <a href="https://jellyheadandrew.github.io/projects/chorus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a method for teaching machines to understand and model the
underlying spatial common sense of diverse human-object interactions in 3D in a
self-supervised way. This is a challenging task, as there exist specific
manifolds of the interactions that can be considered human-like and natural,
but the human pose and the geometry of objects can vary even for similar
interactions. Such diversity makes the annotating task of 3D interactions
difficult and hard to scale, which limits the potential to reason about that in
a supervised way. One way of learning the 3D spatial relationship between
humans and objects during interaction is by showing multiple 2D images captured
from different viewpoints when humans interact with the same type of objects.
The core idea of our method is to leverage a generative model that produces
high-quality 2D images from an arbitrary text prompt input as an "unbounded"
data generator with effective controllability and view diversity. Despite its
imperfection of the image quality over real images, we demonstrate that the
synthesized images are sufficient to learn the 3D human-object spatial
relations. We present multiple strategies to leverage the synthesized images,
including (1) the first method to leverage a generative image model for 3D
human-object spatial relation learning; (2) a framework to reason about the 3D
spatial relations from inconsistent 2D cues in a self-supervised manner via 3D
occupancy reasoning with pose canonicalization; (3) semantic clustering to
disambiguate different types of interactions with the same object types; and
(4) a novel metric to assess the quality of 3D spatial learning of interaction.
Project Page: https://jellyheadandrew.github.io/projects/chorus
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 24 Aug 23</h3>
<dl>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11627" title="Abstract">arXiv:2308.11627</a> (cross-list from eess.SP) [<a href="/pdf/2308.11627" title="Download PDF">pdf</a>, <a href="/format/2308.11627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Intrusive Electric Load Monitoring Approach Based on Current Feature  Visualization for Smart Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yiwen Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dengfeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Liangtao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Zhiquan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+T">Tiesong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Kwong%2C+S">Sam Kwong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">The state-of-the-art smart city has been calling for an economic but
efficient energy management over large-scale network, especially for the
electric power system. It is a critical issue to monitor, analyze and control
electric loads of all users in system. In this paper, we employ the popular
computer vision techniques of AI to design a non-invasive load monitoring
method for smart electric energy management. First of all, we utilize both
signal transforms (including wavelet transform and discrete Fourier transform)
and Gramian Angular Field (GAF) methods to map one-dimensional current signals
onto two-dimensional color feature images. Second, we propose to recognize all
electric loads from color feature images using a U-shape deep neural network
with multi-scale feature extraction and attention mechanism. Third, we design
our method as a cloud-based, non-invasive monitoring of all users, thereby
saving energy cost during electric power system control. Experimental results
on both public and our private datasets have demonstrated our method achieves
superior performances than its peers, and thus supports efficient energy
management over large-scale Internet of Things (IoT).
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11631" title="Abstract">arXiv:2308.11631</a> (cross-list from eess.SP) [<a href="/pdf/2308.11631" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning-based flow disaggregation for hydropower plant management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Duo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">High temporal resolution data is a vital resource for hydropower plant
management. Currently, only daily resolution data are available for most of
Norwegian hydropower plant, however, to achieve more accurate management,
sub-daily resolution data are often required. To deal with the wide absence of
sub-daily data, time series disaggregation is a potential tool. In this study,
we proposed a time series disaggregation model based on deep learning, the
model is tested using flow data from a Norwegian flow station, to disaggregate
the daily flow into hourly flow. Preliminary results show some promising
aspects for the proposed model.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11633" title="Abstract">arXiv:2308.11633</a> (cross-list from eess.SP) [<a href="/pdf/2308.11633" title="Download PDF">pdf</a>, <a href="/format/2308.11633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data  Processing, Classification, and Pattern Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sheffield%2C+B">Brandon Sheffield</a>, 
<a href="/search/eess?searchtype=author&query=Bobe%2C+F+E">Frank E. Bobe III</a>, 
<a href="/search/eess?searchtype=author&query=Marchand%2C+B">Bradley Marchand</a>, 
<a href="/search/eess?searchtype=author&query=Emigh%2C+M+S">Matthew S. Emigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Synthetic Aperture Sonar (SAS) imaging has become a crucial technology for
underwater exploration because of its unique ability to maintain resolution at
increasing ranges, a characteristic absent in conventional sonar techniques.
However, the effective application of deep learning to SAS data processing is
often limited due to the scarcity of labeled data. To address this challenge,
this paper proposes MoCo-SAS that leverages self-supervised learning (SSL) for
SAS data processing, classification, and pattern recognition. The experimental
results demonstrate that MoCo-SAS significantly outperforms traditional
supervised learning methods, as evidenced by significant improvements observed
in terms of the F1-score. These findings highlight the potential of SSL in
advancing the state-of-the-art in SAS data processing, offering promising
avenues for enhanced underwater object detection and classification.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11635" title="Abstract">arXiv:2308.11635</a> (cross-list from eess.SP) [<a href="/pdf/2308.11635" title="Download PDF">pdf</a>, <a href="/format/2308.11635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive  Learning for Cross-Subject EEG-based Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ye%2C+W">Weishan Ye</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhiguo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Linling Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+G">Gan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianhong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+Z">Zhen Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.06496">arXiv:2304.06496</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electroencephalography (EEG) is an objective tool for emotion recognition
with promising applications. However, the scarcity of labeled data remains a
major challenge in this field, limiting the widespread use of EEG-based emotion
recognition. In this paper, a semi-supervised Dual-stream Self-Attentive
Adversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed
to tackle the challenge of limited labeled data in cross-subject EEG-based
emotion recognition. The DS-AGC framework includes two parallel streams for
extracting non-structural and structural EEG features. The non-structural
stream incorporates a semi-supervised multi-domain adaptation method to
alleviate distribution discrepancy among labeled source domain, unlabeled
source domain, and unknown target domain. The structural stream develops a
graph contrastive learning method to extract effective graph-based feature
representation from multiple EEG channels in a semi-supervised manner. Further,
a self-attentive fusion module is developed for feature fusion, sample
selection, and emotion recognition, which highlights EEG features more relevant
to emotions and data samples in the labeled source domain that are closer to
the target domain. Extensive experiments conducted on two benchmark databases
(SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out
cross-validation evaluation scheme show that the proposed model outperforms
existing methods under different incomplete label conditions (with an average
improvement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its
effectiveness in addressing the label scarcity problem in cross-subject
EEG-based emotion recognition.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11636" title="Abstract">arXiv:2308.11636</a> (cross-list from eess.SP) [<a href="/pdf/2308.11636" title="Download PDF">pdf</a>, <a href="/format/2308.11636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregating Intrinsic Information to Enhance BCI Performance through  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuanyuan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+A">Anran Li</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+Y">Yi Ding</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+C">Cuntai Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Insufficient data is a long-standing challenge for Brain-Computer Interface
(BCI) to build a high-performance deep learning model. Though numerous research
groups and institutes collect a multitude of EEG datasets for the same BCI
task, sharing EEG data from multiple sites is still challenging due to the
heterogeneity of devices. The significance of this challenge cannot be
overstated, given the critical role of data diversity in fostering model
robustness. However, existing works rarely discuss this issue, predominantly
centering their attention on model training within a single dataset, often in
the context of inter-subject or inter-session settings. In this work, we
propose a hierarchical personalized Federated Learning EEG decoding (FLEEG)
framework to surmount this challenge. This innovative framework heralds a new
learning paradigm for BCI, enabling datasets with disparate data formats to
collaborate in the model training process. Each client is assigned a specific
dataset and trains a hierarchical personalized model to manage diverse data
formats and facilitate information exchange. Meanwhile, the server coordinates
the training procedure to harness knowledge gleaned from all datasets, thus
elevating overall performance. The framework has been evaluated in Motor
Imagery (MI) classification with nine EEG datasets collected by different
devices but implementing the same MI task. Results demonstrate that the
proposed frame can boost classification performance up to 16.7% by enabling
knowledge sharing between multiple datasets, especially for smaller datasets.
Visualization results also indicate that the proposed framework can empower the
local models to put a stable focus on task-related areas, yielding better
performance. To the best of our knowledge, this is the first end-to-end
solution to address this important challenge.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11638" title="Abstract">arXiv:2308.11638</a> (cross-list from eess.SP) [<a href="/pdf/2308.11638" title="Download PDF">pdf</a>, <a href="/format/2308.11638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoT Data Trust Evaluation via Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tadj%2C+T">Timothy Tadj</a>, 
<a href="/search/eess?searchtype=author&query=Arablouei%2C+R">Reza Arablouei</a>, 
<a href="/search/eess?searchtype=author&query=Dedeoglu%2C+V">Volkan Dedeoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Various approaches based on supervised or unsupervised machine learning (ML)
have been proposed for evaluating IoT data trust. However, assessing their
real-world efficacy is hard mainly due to the lack of related
publicly-available datasets that can be used for benchmarking. Since obtaining
such datasets is challenging, we propose a data synthesis method, called random
walk infilling (RWI), to augment IoT time-series datasets by synthesizing
untrustworthy data from existing trustworthy data. Thus, RWI enables us to
create labeled datasets that can be used to develop and validate ML models for
IoT data trust evaluation. We also extract new features from IoT time-series
sensor data that effectively capture its auto-correlation as well as its
cross-correlation with the data of the neighboring (peer) sensors. These
features can be used to learn ML models for recognizing the trustworthiness of
IoT sensor data. Equipped with our synthesized ground-truth-labeled datasets
and informative correlation-based feature, we conduct extensive experiments to
critically examine various approaches to evaluating IoT data trust via ML. The
results reveal that commonly used ML-based approaches to IoT data trust
evaluation, which rely on unsupervised cluster analysis to assign trust labels
to unlabeled data, perform poorly. This poor performance can be attributed to
the underlying unsubstantiated assumption that clustering provides reliable
labels for data trust, a premise that is found to be untenable. The results
also show that the ML models learned from datasets augmented via RWI while
using the proposed features generalize well to unseen data and outperform
existing related approaches. Moreover, we observe that a semi-supervised ML
approach that requires only about 10% of the data labeled offers competitive
performance while being practically more appealing compared to the
fully-supervised approaches.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11639" title="Abstract">arXiv:2308.11639</a> (cross-list from eess.SP) [<a href="/pdf/2308.11639" title="Download PDF">pdf</a>, <a href="/format/2308.11639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing  S-Parameter Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kang%2C+T+Y">Tae Yeob Kang</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Haebom Lee</a>, 
<a href="/search/eess?searchtype=author&query=Suh%2C+S">Sungho Suh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of optoelectronics, indium tin oxide (ITO) electrodes play a
crucial role in various applications, such as displays, sensors, and solar
cells. Effective fault detection and diagnosis of the ITO electrodes are
essential to ensure the performance and reliability of the devices. However,
traditional visual inspection is challenging with transparent ITO electrodes,
and existing fault detection methods have limitations in determining the root
causes of the defects, often requiring destructive evaluations. In this study,
an in situ fault diagnosis method is proposed using scattering parameter
(S-parameter) signal processing, offering early detection, high diagnostic
accuracy, noise robustness, and root cause analysis. A comprehensive
S-parameter pattern database is obtained according to defect states. Deep
learning (DL) approaches, including multilayer perceptron (MLP), convolutional
neural network (CNN), and transformer, are then used to simultaneously analyze
the cause and severity of defects. Notably, it is demonstrated that the
diagnostic performance under additive noise levels can be significantly
enhanced by combining different channels of the S-parameters as input to the
learning algorithms, as confirmed through the t-distributed stochastic neighbor
embedding (t-SNE) dimension reduction visualization.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11642" title="Abstract">arXiv:2308.11642</a> (cross-list from eess.SP) [<a href="/pdf/2308.11642" title="Download PDF">pdf</a>, <a href="/format/2308.11642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gesture Recognition based on Long-Short Term Memory Cells using  Smartphone IMUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Govindarajulu%2C+Y">Yuvaraj Govindarajulu</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+R+R+R">Raja Rajeshwari Raj Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of Fachpraktikum Interaktive Systeme (FIS 18), FIS 18, Summer 2018, University of Stuttgart, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Over the last few decades, Smartphone technology has seen significant
improvements. Enhancements specific to built-in Inertial Measurement Units
(IMUs) and other dedicated sensors of the smartphones(which are often available
as default) such as- Accelerometer, Gyroscope, Magnetometer, Fingerprint
reader, Proximity and Ambient light sensors have made devices smarter and the
interaction seamless. Gesture recognition using these smart phones have been
experimented with many techniques. In this solution, a Recurrent Neural Network
(RNN) approach, LSTM (Long-Short Term Memory Cells) has been used to classify
ten different gestures based on data from Accelerometer and Gyroscope.
Selection of sensor data (Accelerometer and Gyroscope) was based on the ones
that provided maximum information regarding the movement and orientation of the
phone. Various models were experimented in this project, the results of which
are presented in the later sections. Furthermore, the properties and
characteristics of the collected data were studied and a set of improvements
have been suggested in the future work section.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11644" title="Abstract">arXiv:2308.11644</a> (cross-list from eess.SP) [<a href="/pdf/2308.11644" title="Download PDF">pdf</a>, <a href="/format/2308.11644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Signal Denoising for Multimodal Time Series of Structure  Vibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Han Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Structural Health Monitoring (SHM) plays an indispensable role in ensuring
the longevity and safety of infrastructure. With the rapid growth of sensor
technology, the volume of data generated from various structures has seen an
unprecedented surge, bringing forth challenges in efficient analysis and
interpretation. This paper introduces a novel deep learning algorithm tailored
for the complexities inherent in multimodal vibration signals prevalent in SHM.
By amalgamating convolutional and recurrent architectures, the algorithm
adeptly captures both localized and prolonged structural behaviors. The pivotal
integration of attention mechanisms further enhances the model's capability,
allowing it to discern and prioritize salient structural responses from
extraneous noise. Our results showcase significant improvements in predictive
accuracy, early damage detection, and adaptability across multiple SHM
scenarios. In light of the critical nature of SHM, the proposed approach not
only offers a robust analytical tool but also paves the way for more
transparent and interpretable AI-driven SHM solutions. Future prospects include
real-time processing, integration with external environmental factors, and a
deeper emphasis on model interpretability.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11645" title="Abstract">arXiv:2308.11645</a> (cross-list from eess.SP) [<a href="/pdf/2308.11645" title="Download PDF">pdf</a>, <a href="/format/2308.11645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using  EEG Data: A Dynamic Survival Analysis Framework with Competing Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+X">Xiaobin Shen</a>, 
<a href="/search/eess?searchtype=author&query=Elmer%2C+J">Jonathan Elmer</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G+H">George H. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Healthcare conference (MLHC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Patients resuscitated from cardiac arrest who enter a coma are at high risk
of death. Forecasting neurological outcomes of these patients (the task of
neurological prognostication) could help with treatment decisions. In this
paper, we propose, to the best of our knowledge, the first dynamic framework
for neurological prognostication of post-cardiac-arrest comatose patients using
EEG data: our framework makes predictions for a patient over time as more EEG
data become available, and different training patients' available EEG time
series could vary in length. Predictions are phrased in terms of either
time-to-event outcomes (time-to-awakening or time-to-death) or as the patient's
probability of awakening or of dying across multiple time horizons. Our
framework uses any dynamic survival analysis model that supports competing
risks in the form of estimating patient-level cumulative incidence functions.
We consider three competing risks as to what happens first to a patient:
awakening, being withdrawn from life-sustaining therapies (and thus
deterministically dying), or dying (by other causes). We demonstrate our
framework by benchmarking three existing dynamic survival analysis models that
support competing risks on a real dataset of 922 patients. Our main
experimental findings are that: (1) the classical Fine and Gray model which
only uses a patient's static features and summary statistics from the patient's
latest hour's worth of EEG data is highly competitive, achieving accuracy
scores as high as the recently developed Dynamic-DeepHit model that uses
substantially more of the patient's EEG data; and (2) in an ablation study, we
show that our choice of modeling three competing risks results in a model that
is at least as accurate while learning more information than simpler models
(using two competing risks or a standard survival analysis setup with no
competing risks).
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11647" title="Abstract">arXiv:2308.11647</a> (cross-list from eess.SP) [<a href="/pdf/2308.11647" title="Download PDF">pdf</a>, <a href="/ps/2308.11647" title="Download PostScript">ps</a>, <a href="/format/2308.11647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optically-Transparent EM Skins for Outdoor-to-Indoor mm-Wave Wireless  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oliveri%2C+G">Giacomo Oliveri</a>, 
<a href="/search/eess?searchtype=author&query=Zardi%2C+F">Francesco Zardi</a>, 
<a href="/search/eess?searchtype=author&query=Massa%2C+A">Andrea Massa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Optically-transparent opportunistic electromagnetic skins (OTO-EMSs) are
proposed to enable outdoor-to-indoor (O2I) millimiter-wave (mmW) wireless
communications with existing windows/glass-panels. More in detail, static
passive EMSs consisting of optically-transparent conducting patterned layers
attached to standard glass-panels are designed. Towards this end, both the
phase coverage and the optical transparency of a meshed copper-based meta-atom
printed on a non-dedicated insulated glass substrate are optimized.
Successively, the feasibility of OTO-EMSs able to support mmW high-efficiency
O2I transmissions along non-Snell refraction directions is numerically
demonstrated.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11651" title="Abstract">arXiv:2308.11651</a> (cross-list from eess.SP) [<a href="/pdf/2308.11651" title="Download PDF">pdf</a>, <a href="/format/2308.11651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Cross Subject EEG Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duan%2C+T">Tiehang Duan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhenyi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fang Li</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+C">Cui Tao</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, deep learning has shown to be effective for Electroencephalography
(EEG) decoding tasks. Yet, its performance can be negatively influenced by two
key factors: 1) the high variance and different types of corruption that are
inherent in the signal, 2) the EEG datasets are usually relatively small given
the acquisition cost, annotation cost and amount of effort needed. Data
augmentation approaches for alleviation of this problem have been empirically
studied, with augmentation operations on spatial domain, time domain or
frequency domain handcrafted based on expertise of domain knowledge. In this
work, we propose a principled approach to perform dynamic evolution on the data
for improvement of decoding robustness. The approach is based on
distributionally robust optimization and achieves robustness by optimizing on a
family of evolved data distributions instead of the single training data
distribution. We derived a general data evolution framework based on
Wasserstein gradient flow (WGF) and provides two different forms of evolution
within the framework. Intuitively, the evolution process helps the EEG decoder
to learn more robust and diverse features. It is worth mentioning that the
proposed approach can be readily integrated with other data augmentation
approaches for further improvements. We performed extensive experiments on the
proposed approach and tested its performance on different types of corrupted
EEG signals. The model significantly outperforms competitive baselines on
challenging decoding scenarios.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11654" title="Abstract">arXiv:2308.11654</a> (cross-list from eess.SP) [<a href="/pdf/2308.11654" title="Download PDF">pdf</a>, <a href="/format/2308.11654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Transformers are Better EEG Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bingxin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+X">Xiaowen Fu</a>, 
<a href="/search/eess?searchtype=author&query=Lan%2C+Y">Yuan Lan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Luchan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained large transformer models have achieved remarkable performance in
the fields of natural language processing and computer vision. Since the
magnitude of available labeled electroencephalogram (EEG) data is much lower
than that of text and image data, it is difficult for transformer models
pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash
the potential of this architecture. In this paper, we show that transformers
pre-trained from images as well as text can be directly fine-tuned for
EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for
Converting EEG data into image as well as text forms, to fine-tune pre-trained
vision and language transformers. The proposed AdaCE module is highly effective
for fine-tuning pre-trained transformers while achieving state-of-the-art
performance on diverse EEG-based prediction tasks. For example, AdaCE on the
pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%,
on the EEG-decoding task of human activity recognition (UCI HAR). Furthermore,
we empirically show that applying the proposed AdaCE to fine-tune larger
pre-trained models can achieve better performance on EEG-based predicting
tasks, indicating the potential of our adapters for even larger transformers.
The plug-and-play AdaCE module can be applied to fine-tuning most of the
popular pre-trained transformers on many other time-series data with multiple
channels, not limited to EEG data and the models we use. Our code will be
available at https://github.com/wangbxj1234/AdaCE.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11666" title="Abstract">arXiv:2308.11666</a> (cross-list from physics.soc-ph) [<a href="/pdf/2308.11666" title="Download PDF">pdf</a>, <a href="/format/2308.11666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized dimension reduction approach for heterogeneous networked  systems with time-delay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ma%2C+C">Cheng Ma</a>, 
<a href="/search/physics?searchtype=author&query=Korniss%2C+G">Gyorgy Korniss</a>, 
<a href="/search/physics?searchtype=author&query=Szymanski%2C+B+K">Boleslaw K. Szymanski</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+J">Jianxi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Multiagent Systems (cs.MA); Computational Physics (physics.comp-ph); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Networks of interconnected agents are essential to study complex networked
systems' state evolution, stability, resilience, and control. Nevertheless, the
high dimensionality and nonlinear dynamics are vital factors preventing us from
theoretically analyzing them. Recently, the dimension-reduction approaches
reduced the system's size by mapping the original system to a one-dimensional
system such that only one effective representative can capture its macroscopic
dynamics. However, the approaches dramatically fail as the network becomes
heterogeneous and has multiple community structures. Here, we bridge the gap by
developing a generalized dimension reduction approach, which enables us to map
the original system to a $m$-dimensional system that consists of $m$
interacting components. Notably, by validating it on various dynamical models,
this approach accurately predicts the original system state and the tipping
point, if any. Furthermore, the numerical results demonstrate that this
approach approximates the system evolution and identifies the critical points
for complex networks with time delay.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11670" title="Abstract">arXiv:2308.11670</a> (cross-list from eess.SP) [<a href="/pdf/2308.11670" title="Download PDF">pdf</a>, <a href="/format/2308.11670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-based Positioning using Multivariate Time Series  Classification for Factory Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Badu%2C+N+H+M">Nisal Hemadasa Manikku Badu</a>, 
<a href="/search/eess?searchtype=author&query=Venzke%2C+M">Marcus Venzke</a>, 
<a href="/search/eess?searchtype=author&query=Turau%2C+V">Volker Turau</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yanqiu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Indoor Positioning Systems (IPS) gained importance in many industrial
applications. State-of-the-art solutions heavily rely on external
infrastructures and are subject to potential privacy compromises, external
information requirements, and assumptions, that make it unfavorable for
environments demanding privacy and prolonged functionality. In certain
environments deploying supplementary infrastructures for indoor positioning
could be infeasible and expensive. Recent developments in machine learning (ML)
offer solutions to address these limitations relying only on the data from
onboard sensors of IoT devices. However, it is unclear which model fits best
considering the resource constraints of IoT devices. This paper presents a
machine learning-based indoor positioning system, using motion and ambient
sensors, to localize a moving entity in privacy concerned factory environments.
The problem is formulated as a multivariate time series classification (MTSC)
and a comparative analysis of different machine learning models is conducted in
order to address it. We introduce a novel time series dataset emulating the
assembly lines of a factory. This dataset is utilized to assess and compare the
selected models in terms of accuracy, memory footprint and inference speed. The
results illustrate that all evaluated models can achieve accuracies above 80 %.
CNN-1D shows the most balanced performance, followed by MLP. DT was found to
have the lowest memory footprint and inference latency, indicating its
potential for a deployment in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11671" title="Abstract">arXiv:2308.11671</a> (cross-list from q-bio.GN) [<a href="/pdf/2308.11671" title="Download PDF">pdf</a>, <a href="/format/2308.11671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalising sequence models for epigenome predictions with tissue and  assay embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Deasy%2C+J">Jacob Deasy</a>, 
<a href="/search/q-bio?searchtype=author&query=Schwessinger%2C+R">Ron Schwessinger</a>, 
<a href="/search/q-bio?searchtype=author&query=Gonzalez%2C+F">Ferran Gonzalez</a>, 
<a href="/search/q-bio?searchtype=author&query=Young%2C+S">Stephen Young</a>, 
<a href="/search/q-bio?searchtype=author&query=Branson%2C+K">Kim Branson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sequence modelling approaches for epigenetic profile prediction have recently
expanded in terms of sequence length, model size, and profile diversity.
However, current models cannot infer on many experimentally feasible tissue and
assay pairs due to poor usage of contextual information, limiting $\textit{in
silico}$ understanding of regulatory genomics. We demonstrate that strong
correlation can be achieved across a large range of experimental conditions by
integrating tissue and assay embeddings into a Contextualised Genomic Network
(CGN). In contrast to previous approaches, we enhance long-range sequence
embeddings with contextual information in the input space, rather than
expanding the output space. We exhibit the efficacy of our approach across a
broad set of epigenetic profiles and provide the first insights into the effect
of genetic variants on epigenetic sequence model training. Our general approach
to context integration exceeds state of the art in multiple settings while
employing a more rigorous validation procedure.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11673" title="Abstract">arXiv:2308.11673</a> (cross-list from eess.SP) [<a href="/pdf/2308.11673" title="Download PDF">pdf</a>, <a href="/format/2308.11673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WEARS: Wearable Emotion AI with Real-time Sensor data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Limbani%2C+D">Dhruv Limbani</a>, 
<a href="/search/eess?searchtype=author&query=Yatin%2C+D">Daketi Yatin</a>, 
<a href="/search/eess?searchtype=author&query=Chaturvedi%2C+N">Nitish Chaturvedi</a>, 
<a href="/search/eess?searchtype=author&query=Moorthy%2C+V">Vaishnavi Moorthy</a>, 
<a href="/search/eess?searchtype=author&query=M%2C+P">Pushpalatha M</a>, 
<a href="/search/eess?searchtype=author&query=BSS%2C+H">Harichandana BSS</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Emotion prediction is the field of study to understand human emotions.
Existing methods focus on modalities like text, audio, facial expressions,
etc., which could be private to the user. Emotion can be derived from the
subject's psychological data as well. Various approaches that employ
combinations of physiological sensors for emotion recognition have been
proposed. Yet, not all sensors are simple to use and handy for individuals in
their daily lives. Thus, we propose a system to predict user emotion using
smartwatch sensors. We design a framework to collect ground truth in real-time
utilizing a mix of English and regional language-based videos to invoke
emotions in participants and collect the data. Further, we modeled the problem
as binary classification due to the limited dataset size and experimented with
multiple machine-learning models. We also did an ablation study to understand
the impact of features including Heart Rate, Accelerometer, and Gyroscope
sensor data on mood. From the experimental results, Multi-Layer Perceptron has
shown a maximum accuracy of 93.75 percent for pleasant-unpleasant (high/low
valence classification) moods.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11676" title="Abstract">arXiv:2308.11676</a> (cross-list from stat.ME) [<a href="/pdf/2308.11676" title="Download PDF">pdf</a>, <a href="/format/2308.11676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Impact of Non-confounding Covariates on the Inferential  Performance of Methods based on the Potential Outcome Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhao%2C+Y">Yonghe Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Fu%2C+S">Shuai Fu</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+H">Huiyan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Potential Outcome Framework (POF) plays a prominent role in the field of
causal inference. Most causal inference models based on the POF (CIMs-B-POF)
are designed for eliminating confounding bias and default to an underlying
assumption of Confounding Covariates. This assumption posits that the
covariates consist solely of confounders. However, the assumption of
Confounding Covariates is challenging to maintain in practice, particularly
when dealing with high-dimensional covariates. While certain methods have been
proposed to differentiate the distinct components of covariates prior to
conducting causal inference, the consequences of treating non-confounding
covariates as confounders remain unclear. This ambiguity poses a potential risk
when applying the CIMs-B-POF in practical scenarios. In this paper, we present
a unified graphical framework for the CIMs-B-POF, which greatly enhances the
comprehension of these models' underlying principles. Using this graphical
framework, we quantitatively analyze the extent to which the inference
performance of CIMs-B-POF is influenced when incorporating various types of
non-confounding covariates, such as instrumental variables, mediators,
colliders, and adjustment variables. The key findings are: in the task of
eliminating confounding bias, the optimal scenario is for the covariates to
exclusively encompass confounders; in the subsequent task of inferring
counterfactual outcomes, the adjustment variables contribute to more accurate
inferences. Furthermore, extensive experiments conducted on synthetic datasets
consistently validate these theoretical conclusions.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11691" title="Abstract">arXiv:2308.11691</a> (cross-list from eess.SP) [<a href="/pdf/2308.11691" title="Download PDF">pdf</a>, <a href="/format/2308.11691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Insights on Incremental Learning of New Human Physical  Activity on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Arvanitakis%2C+G">George Arvanitakis</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+J">Jingwei Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Ndhlovu%2C+M">Mthandazo Ndhlovu</a>, 
<a href="/search/eess?searchtype=author&query=Hacid%2C+H">Hakim Hacid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by DSAA 2023 (Industrial Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Edge Machine Learning (Edge ML), which shifts computational intelligence from
cloud-based systems to edge devices, is attracting significant interest due to
its evident benefits including reduced latency, enhanced data privacy, and
decreased connectivity reliance. While these advantages are compelling, they
introduce unique challenges absent in traditional cloud-based approaches. In
this paper, we delve into the intricacies of Edge-based learning, examining the
interdependencies among: (i) constrained data storage on Edge devices, (ii)
limited computational power for training, and (iii) the number of learning
classes. Through experiments conducted using our MAGNETO system, that focused
on learning human activities via data collected from mobile sensors, we
highlight these challenges and offer valuable perspectives on Edge ML.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11700" title="Abstract">arXiv:2308.11700</a> (cross-list from physics.ins-det) [<a href="/pdf/2308.11700" title="Download PDF">pdf</a>, <a href="/format/2308.11700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperCalo: Calorimeter shower super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pang%2C+I">Ian Pang</a>, 
<a href="/search/physics?searchtype=author&query=Raine%2C+J+A">John Andrew Raine</a>, 
<a href="/search/physics?searchtype=author&query=Shih%2C+D">David Shih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Calorimeter shower simulation is a major bottleneck in the Large Hadron
Collider computational pipeline. There have been recent efforts to employ
deep-generative surrogate models to overcome this challenge. However, many of
best performing models have training and generation times that do not scale
well to high-dimensional calorimeter showers. In this work, we introduce
SuperCalo, a flow-based super-resolution model, and demonstrate that
high-dimensional fine-grained calorimeter showers can be quickly upsampled from
coarse-grained showers. This novel approach presents a way to reduce
computational cost, memory requirements and generation time associated with
fast calorimeter simulation models. Additionally, we show that the showers
upsampled by SuperCalo possess a high degree of variation. This allows a large
number of high-dimensional calorimeter showers to be upsampled from much fewer
coarse showers with high-fidelity, which results in additional reduction in
generation time.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11711" title="Abstract">arXiv:2308.11711</a> (cross-list from eess.IV) [<a href="/pdf/2308.11711" title="Download PDF">pdf</a>, <a href="/format/2308.11711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity analysis of AI-based algorithms for autonomous driving on  optical wavefront aberrations induced by the windshield
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wolf%2C+D+W">Dominik Werner Wolf</a>, 
<a href="/search/eess?searchtype=author&query=Ulrich%2C+M">Markus Ulrich</a>, 
<a href="/search/eess?searchtype=author&query=Kapoor%2C+N">Nikhil Kapoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE ICCV 2023 - BRAVO workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autonomous driving perception techniques are typically based on supervised
machine learning models that are trained on real-world street data. A typical
training process involves capturing images with a single car model and
windshield configuration. However, deploying these trained models on different
car types can lead to a domain shift, which can potentially hurt the neural
networks performance and violate working ADAS requirements. To address this
issue, this paper investigates the domain shift problem further by evaluating
the sensitivity of two perception models to different windshield
configurations. This is done by evaluating the dependencies between neural
network benchmark metrics and optical merit functions by applying a Fourier
optics based threat model. Our results show that there is a performance gap
introduced by windshields and existing optical metrics used for posing
requirements might not be sufficient.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11724" title="Abstract">arXiv:2308.11724</a> (cross-list from physics.comp-ph) [<a href="/pdf/2308.11724" title="Download PDF">pdf</a>, <a href="/format/2308.11724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolSieve: A Progressive Visual Analytics System for Molecular Dynamics  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hnatyshyn%2C+R">Rostyslav Hnatyshyn</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+J">Jieqiong Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Perez%2C+D">Danny Perez</a>, 
<a href="/search/physics?searchtype=author&query=Ahrens%2C+J">James Ahrens</a>, 
<a href="/search/physics?searchtype=author&query=Maciejewski%2C+R">Ross Maciejewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Molecular Dynamics (MD) simulations are ubiquitous in cutting-edge
physio-chemical research. They provide critical insights into how a physical
system evolves over time given a model of interatomic interactions.
Understanding a system's evolution is key to selecting the best candidates for
new drugs, materials for manufacturing, and countless other practical
applications. With today's technology, these simulations can encompass millions
of unit transitions between discrete molecular structures, spanning up to
several milliseconds of real time. Attempting to perform a brute-force analysis
with data-sets of this size is not only computationally impractical, but would
not shed light on the physically-relevant features of the data. Moreover, there
is a need to analyze simulation ensembles in order to compare similar processes
in differing environments. These problems call for an approach that is
analytically transparent, computationally efficient, and flexible enough to
handle the variety found in materials based research. In order to address these
problems, we introduce MolSieve, a progressive visual analytics system that
enables the comparison of multiple long-duration simulations. Using MolSieve,
analysts are able to quickly identify and compare regions of interest within
immense simulations through its combination of control charts, data-reduction
techniques, and highly informative visual components. A simple programming
interface is provided which allows experts to fit MolSieve to their needs. To
demonstrate the efficacy of our approach, we present two case studies of
MolSieve and report on findings from domain collaborators.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11736" title="Abstract">arXiv:2308.11736</a> (cross-list from quant-ph) [<a href="/pdf/2308.11736" title="Download PDF">pdf</a>, <a href="/format/2308.11736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth min-entropy lower bounds for approximation chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Marwah%2C+A">Ashutosh Marwah</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dupuis%2C+F">Fr&#xe9;d&#xe9;ric Dupuis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> comments welcome; sections on approximate EAT and source correlation can be read independently; total number of pages= 83, pages 55-78 are appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">For a state $\rho_{A_1^n B}$, we call a sequence of states $(\sigma_{A_1^k
B}^{(k)})_{k=1}^n$ an approximation chain if for every $1 \leq k \leq n$,
$\rho_{A_1^k B} \approx_\epsilon \sigma_{A_1^k B}^{(k)}$. In general, it is not
possible to lower bound the smooth min-entropy of such a $\rho_{A_1^n B}$, in
terms of the entropies of $\sigma_{A_1^k B}^{(k)}$ without incurring very large
penalty factors. In this paper, we study such approximation chains under
additional assumptions. We begin by proving a simple entropic triangle
inequality, which allows us to bound the smooth min-entropy of a state in terms
of the R\'enyi entropy of an arbitrary auxiliary state while taking into
account the smooth max-relative entropy between the two. Using this triangle
inequality, we create lower bounds for the smooth min-entropy of a state in
terms of the entropies of its approximation chain in various scenarios. In
particular, utilising this approach, we prove an approximate version of entropy
accumulation and also provide a solution to the source correlation problem in
quantum key distribution.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11763" title="Abstract">arXiv:2308.11763</a> (cross-list from physics.data-an) [<a href="/pdf/2308.11763" title="Download PDF">pdf</a>, <a href="/format/2308.11763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient set-theoretic algorithm for high-order Forman-Ricci  curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=de+Souza%2C+D+B">Danillo Barros de Souza</a>, 
<a href="/search/physics?searchtype=author&query=da+Cunha%2C+J+T+S">Jonatas T. S. da Cunha</a>, 
<a href="/search/physics?searchtype=author&query=Moreira%2C+R+A">Rodrigo A. Moreira</a>, 
<a href="/search/physics?searchtype=author&query=Santos%2C+F+A+N">Fernando A. N. Santos</a>, 
<a href="/search/physics?searchtype=author&query=Rodrigues%2C+S">Serafim Rodrigues</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Discrete Mathematics (cs.DM); Performance (cs.PF); Combinatorics (math.CO)

</div>
<p class="mathjax">Differential geometric approaches are ubiquitous in several fields of
mathematics, physics and engineering, and their discretizations enable the
development of network-based mathematical and computational frameworks, which
are essential for large-scale data science. The Forman-Ricci curvature (FRC) -
a statistical measure based on Riemannian geometry and designed for networks -
is known for its high capacity for extracting geometric information from
complex networks. However, extracting information from dense networks is still
challenging due to the combinatorial explosion of high-order network
structures. Motivated by this challenge we sought a set-theoretic
representation theory for high-order network cells and FRC, as well as their
associated concepts and properties, which together provide an alternative and
efficient formulation for computing high-order FRC in complex networks. We
provide a pseudo-code, a software implementation coined FastForman, as well as
a benchmark comparison with alternative implementations. Crucially, our
representation theory reveals previous computational bottlenecks and also
accelerates the computation of FRC. As a consequence, our findings open new
research possibilities in complex systems where higher-order geometric
computations are required.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11791" title="Abstract">arXiv:2308.11791</a> (cross-list from stat.ML) [<a href="/pdf/2308.11791" title="Download PDF">pdf</a>, <a href="/format/2308.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Assimilation for Sign-indefinite Priors: A generalization of  Sinkhorn&#x27;s algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dong%2C+A">Anqi Dong</a>, 
<a href="/search/stat?searchtype=author&query=Georgiou%2C+T+T">Tryphon T. Georgiou</a>, 
<a href="/search/stat?searchtype=author&query=Tannenbaum%2C+A">Allen Tannenbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The purpose of this work is to develop a framework to calibrate signed
datasets so as to be consistent with specified marginals by suitably extending
the Schr\"odinger-Fortet-Sinkhorn paradigm. Specifically, we seek to revise
sign-indefinite multi-dimensional arrays in a way that the updated values agree
with specified marginals. Our approach follows the rationale in Schr\"odinger's
problem, aimed at updating a "prior" probability measure to agree with marginal
distributions. The celebrated Sinkhorn's algorithm (established earlier by R.\
Fortet) that solves Schr\"odinger's problem found early applications in
calibrating contingency tables in statistics and, more recently, multi-marginal
problems in machine learning and optimal transport. Herein, we postulate a
sign-indefinite prior in the form of a multi-dimensional array, and propose an
optimization problem to suitably update this prior to ensure consistency with
given marginals. The resulting algorithm generalizes the Sinkhorn algorithm in
that it amounts to iterative scaling of the entries of the array along
different coordinate directions. The scaling is multiplicative but also, in
contrast to Sinkhorn, inverse-multiplicative depending on the sign of the
entries. Our algorithm reduces to the classical Sinkhorn algorithm when the
entries of the prior are positive.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11809" title="Abstract">arXiv:2308.11809</a> (cross-list from q-bio.NC) [<a href="/pdf/2308.11809" title="Download PDF">pdf</a>, <a href="/format/2308.11809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive probabilistic sampling in recurrent neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S">Shirui Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+L+P">Linxin Preston Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Rao%2C+R+P+N">Rajesh P. N. Rao</a>, 
<a href="/search/q-bio?searchtype=author&query=Shea-Brown%2C+E">Eric Shea-Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In sampling-based Bayesian models of brain function, neural activities are
assumed to be samples from probability distributions that the brain uses for
probabilistic computation. However, a comprehensive understanding of how
mechanistic models of neural dynamics can sample from arbitrary distributions
is still lacking. We use tools from functional analysis and stochastic
differential equations to explore the minimum architectural requirements for
$\textit{recurrent}$ neural circuits to sample from complex distributions. We
first consider the traditional sampling model consisting of a network of
neurons whose outputs directly represent the samples (sampler-only network). We
argue that synaptic current and firing-rate dynamics in the traditional model
have limited capacity to sample from a complex probability distribution. We
show that the firing rate dynamics of a recurrent neural circuit with a
separate set of output units can sample from an arbitrary probability
distribution. We call such circuits reservoir-sampler networks (RSNs). We
propose an efficient training procedure based on denoising score matching that
finds recurrent and output weights such that the RSN implements Langevin
sampling. We empirically demonstrate our model's ability to sample from several
complex data distributions using the proposed neural dynamics and discuss its
applicability to developing the next generation of sampling-based brain models.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11836" title="Abstract">arXiv:2308.11836</a> (cross-list from q-bio.NC) [<a href="/pdf/2308.11836" title="Download PDF">pdf</a>, <a href="/format/2308.11836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing normal perinatal development of the human brain  structural connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+Y">Yihan Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Vasung%2C+L">Lana Vasung</a>, 
<a href="/search/q-bio?searchtype=author&query=Calixto%2C+C">Camilo Calixto</a>, 
<a href="/search/q-bio?searchtype=author&query=Gholipour%2C+A">Ali Gholipour</a>, 
<a href="/search/q-bio?searchtype=author&query=Karimi%2C+D">Davood Karimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Early brain development is characterized by the formation of a highly
organized structural connectome. The interconnected nature of this connectome
underlies the brain's cognitive abilities and influences its response to
diseases and environmental factors. Hence, quantitative assessment of
structural connectivity in the perinatal stage is useful for studying normal
and abnormal neurodevelopment. However, estimation of the connectome from
diffusion MRI data involves complex computations. For the perinatal period,
these computations are further challenged by the rapid brain development and
imaging difficulties. Combined with high inter-subject variability, these
factors make it difficult to chart the normal development of the structural
connectome. As a result, there is a lack of reliable normative baselines of
structural connectivity metrics at this critical stage in brain development. In
this study, we developed a computational framework, based on spatio-temporal
averaging, for determining such baselines. We used this framework to analyze
the structural connectivity between 33 and 44 postmenstrual weeks using data
from 166 subjects. Our results unveiled clear and strong trends in the
development of structural connectivity in perinatal stage. Connection weighting
based on fractional anisotropy and neurite density produced the most consistent
results. We observed increases in global and local efficiency, a decrease in
characteristic path length, and widespread strengthening of the connections
within and across brain lobes and hemispheres. We also observed asymmetry
patterns that were consistent between different connection weighting
approaches. The new computational method and results are useful for assessing
normal and abnormal development of the structural connectome early in life.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11859" title="Abstract">arXiv:2308.11859</a> (cross-list from eess.AS) [<a href="/pdf/2308.11859" title="Download PDF">pdf</a>, <a href="/format/2308.11859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Example-Based Framework for Perceptually Guided Audio Texture Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kamath%2C+P">Purnima Kamath</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+C">Chitralekha Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Wyse%2C+L">Lonce Wyse</a>, 
<a href="/search/eess?searchtype=author&query=Nanayakkara%2C+S">Suranga Nanayakkara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Generative models for synthesizing audio textures explicitly encode
controllability by conditioning the model with labelled data. While datasets
for audio textures can be easily recorded in-the-wild, semantically labeling
them is expensive, time-consuming, and prone to errors due to human annotator
subjectivity. Thus, to control generation, there is a need to automatically
infer user-defined perceptual factors of variation in the latent space of a
generative model while modelling unlabeled textures. In this paper, we propose
an example-based framework to determine vectors to guide texture generation
based on user-defined semantic attributes. By synthesizing a few synthetic
examples to indicate the presence or absence of a semantic attribute, we can
infer the guidance vectors in the latent space of a generative model to control
that attribute during generation. Our results show that our method is capable
of finding perceptually relevant and deterministic guidance vectors for
controllable generation for both discrete as well as continuous textures.
Furthermore, we demonstrate the application of this method to other tasks such
as selective semantic attribute transfer.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11863" title="Abstract">arXiv:2308.11863</a> (cross-list from eess.AS) [<a href="/pdf/2308.11863" title="Download PDF">pdf</a>, <a href="/format/2308.11863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KinSPEAK: Improving speech recognition for Kinyarwanda via  semi-supervised learning methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nzeyimana%2C+A">Antoine Nzeyimana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Despite recent availability of large transcribed Kinyarwanda speech data,
achieving robust speech recognition for Kinyarwanda is still challenging. In
this work, we show that using self-supervised pre-training, following a simple
curriculum schedule during fine-tuning and using semi-supervised learning to
leverage large unlabelled speech data significantly improve speech recognition
performance for Kinyarwanda. Our approach focuses on using public domain data
only. A new studio-quality speech dataset is collected from a public website,
then used to train a clean baseline model. The clean baseline model is then
used to rank examples from a more diverse and noisy public dataset, defining a
simple curriculum training schedule. Finally, we apply semi-supervised learning
to label and learn from large unlabelled data in four successive generations.
Our final model achieves 3.2% word error rate (WER) on the new dataset and
15.9% WER on Mozilla Common Voice benchmark, which is state-of-the-art to the
best of our knowledge. Our experiments also indicate that using syllabic rather
than character-based tokenization results in better speech recognition
performance for Kinyarwanda.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11876" title="Abstract">arXiv:2308.11876</a> (cross-list from math.OC) [<a href="/pdf/2308.11876" title="Download PDF">pdf</a>, <a href="/ps/2308.11876" title="Download PostScript">ps</a>, <a href="/format/2308.11876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First-Order Algorithm for Decentralised Min-Max Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Malitsky%2C+Y">Yura Malitsky</a>, 
<a href="/search/math?searchtype=author&query=Tam%2C+M+K">Matthew K. Tam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this work, we consider a connected network of finitely many agents working
cooperatively to solve a min-max problem with convex-concave structure. We
propose a decentralised first-order algorithm which can be viewed as a
non-trivial combination of two algorithms: PG-EXTRA for decentralised
minimisation problems and the forward reflected backward method for
(non-distributed) min-max problems. In each iteration of our algorithm, each
agent computes the gradient of the smooth component of its local objective
function as well as the proximal operator of its nonsmooth component, following
by a round of communication with its neighbours. Our analysis shows that the
sequence generated by the method converges under standard assumptions with
non-decaying stepsize.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11892" title="Abstract">arXiv:2308.11892</a> (cross-list from physics.comp-ph) [<a href="/pdf/2308.11892" title="Download PDF">pdf</a>, <a href="/format/2308.11892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Pressure-Temperature Residual (CPTR) Preconditioner  Performance for Large-Scale Thermal CO2 Injection Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cremon%2C+M+A">Matthias A. Cremon</a>, 
<a href="/search/physics?searchtype=author&query=Franc%2C+J">Jacques Franc</a>, 
<a href="/search/physics?searchtype=author&query=Hamon%2C+F+P">Francois P. Hamon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work studies the performance of a novel preconditioner, designed for
thermal reservoir simulation cases and recently introduced in Roy et al. (2020)
and Cremon et al. (2020), on large-scale thermal CO2 injection cases. For
Carbon Capture and Sequestration (CCS) projects, injecting CO2 under
supercritical conditions is typically tens of degrees colder than the reservoir
temperature. Thermal effects can have a significant impact on the simulation
results, but they also add many challenges for the solvers. More specifically,
the usual combination of an iterative linear solver (such as GMRES) and the
Constrained Pressure Residual (CPR) physics-based block-preconditioner is known
to perform rather poorly or fail to converge when thermal effects play a
significant role. The Constrained Pressure-Temperature Residual (CPTR)
preconditioner retains the 2x2 block structure (elliptic/hyperbolic) of CPR but
includes the temperature in the elliptic subsystem. The elliptic subsystem is
now formed by two equations, and is dealt with by the system-solver of
BoomerAMG (from the HYPRE library). Then a global smoother, ILU(0), is applied
to the full system to handle the local, hyperbolic temperature fronts. We
implemented CPTR in the multi-physics solver GEOS and present results on
various large-scale thermal CCS simulation cases, including both Cartesian and
fully unstructured meshes, up to tens of millions of degrees of freedom. The
CPTR preconditioner severely reduces the number of GMRES iterations and the
runtime, with cases timing out in 24h with CPR now requiring a few hours with
CPTR. We present strong scaling results using hundreds of CPU cores for
multiple cases, and show close to linear scaling. CPTR is also virtually
insensitive to the thermal Peclet number (which compares advection and
diffusion effects) and is suitable to any thermal regime.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11923" title="Abstract">arXiv:2308.11923</a> (cross-list from eess.AS) [<a href="/pdf/2308.11923" title="Download PDF">pdf</a>, <a href="/format/2308.11923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Difference Captioning Utilizing Similarity-Discrepancy  Disentanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Takeuchi%2C+D">Daiki Takeuchi</a>, 
<a href="/search/eess?searchtype=author&query=Ohishi%2C+Y">Yasunori Ohishi</a>, 
<a href="/search/eess?searchtype=author&query=Niizumi%2C+D">Daisuke Niizumi</a>, 
<a href="/search/eess?searchtype=author&query=Harada%2C+N">Noboru Harada</a>, 
<a href="/search/eess?searchtype=author&query=Kashino%2C+K">Kunio Kashino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to DCASE2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We proposed Audio Difference Captioning (ADC) as a new extension task of
audio captioning for describing the semantic differences between input pairs of
similar but slightly different audio clips. The ADC solves the problem that
conventional audio captioning sometimes generates similar captions for similar
audio clips, failing to describe the difference in content. We also propose a
cross-attention-concentrated transformer encoder to extract differences by
comparing a pair of audio clips and a similarity-discrepancy disentanglement to
emphasize the difference in the latent space. To evaluate the proposed methods,
we built an AudioDiffCaps dataset consisting of pairs of similar but slightly
different audio clips with human-annotated descriptions of their differences.
The experiment with the AudioDiffCaps dataset showed that the proposed methods
solve the ADC task effectively and improve the attention weights to extract the
difference by visualizing them in the transformer encoder.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11925" title="Abstract">arXiv:2308.11925</a> (cross-list from math.OC) [<a href="/pdf/2308.11925" title="Download PDF">pdf</a>, <a href="/format/2308.11925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Elliptic Optimal Control Problems using Physics Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/math?searchtype=author&query=Sau%2C+R">Ramesh Sau</a>, 
<a href="/search/math?searchtype=author&query=Yin%2C+L">Luowei Yin</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work, we present and analyze a numerical solver for optimal control
problems (without / with box constraint) for linear and semilinear second-order
elliptic problems. The approach is based on a coupled system derived from the
first-order optimality system of the optimal control problem, and applies
physics informed neural networks (PINNs) to solve the coupled system. We
present an error analysis of the numerical scheme, and provide $L^2(\Omega)$
error bounds on the state, control and adjoint state in terms of deep neural
network parameters (e.g., depth, width, and parameter bounds) and the number of
sampling points in the domain and on the boundary. The main tools in the
analysis include offset Rademacher complexity and boundedness and Lipschitz
continuity of neural network functions. We present several numerical examples
to illustrate the approach and compare it with three existing approaches.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11927" title="Abstract">arXiv:2308.11927</a> (cross-list from q-bio.QM) [<a href="/pdf/2308.11927" title="Download PDF">pdf</a>, <a href="/format/2308.11927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering a Molecule&#x27;s 3D Dynamics from Liquid-phase Electron  Microscopy Movies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+E">Enze Ye</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Y">Yiqin Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Sun%2C+H">He Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The dynamics of biomolecules are crucial for our understanding of their
functioning in living systems. However, current 3D imaging techniques, such as
cryogenic electron microscopy (cryo-EM), require freezing the sample, which
limits the observation of their conformational changes in real time. The
innovative liquid-phase electron microscopy (liquid-phase EM) technique allows
molecules to be placed in the native liquid environment, providing a unique
opportunity to observe their dynamics. In this paper, we propose TEMPOR, a
Temporal Electron MicroscoPy Object Reconstruction algorithm for liquid-phase
EM that leverages an implicit neural representation (INR) and a dynamical
variational auto-encoder (DVAE) to recover time series of molecular structures.
We demonstrate its advantages in recovering different motion dynamics from two
simulated datasets, 7bcq and Cas9. To our knowledge, our work is the first
attempt to directly recover 3D structures of a temporally-varying particle from
liquid-phase EM movies. It provides a promising new approach for studying
molecules' 3D dynamics in structural biology.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11967" title="Abstract">arXiv:2308.11967</a> (cross-list from math.CT) [<a href="/pdf/2308.11967" title="Download PDF">pdf</a>, <a href="/ps/2308.11967" title="Download PostScript">ps</a>, <a href="/format/2308.11967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duality for Clans: a Refinement of Gabriel-Ulmer Duality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frey%2C+J">Jonas Frey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
<p class="mathjax">Clans are representations of generalized algebraic theories that contain more
information than the finite-limit categories associated to the l.f.p.
categories of models via Gabriel-Ulmer duality. Refining Gabriel-Ulmer duality
to account for this additional information, this article presents a duality
theory between clans and l.f.p. categories equipped with a weak factorization
system subject to axioms.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11969" title="Abstract">arXiv:2308.11969</a> (cross-list from eess.IV) [<a href="/pdf/2308.11969" title="Download PDF">pdf</a>, <a href="/format/2308.11969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic Hybrid Networks for liver tumor segmentation with  uncertainty quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lambert%2C+B">Benjamin Lambert</a>, 
<a href="/search/eess?searchtype=author&query=Roca%2C+P">Pauline Roca</a>, 
<a href="/search/eess?searchtype=author&query=Forbes%2C+F">Florence Forbes</a>, 
<a href="/search/eess?searchtype=author&query=Doyle%2C+S">Senan Doyle</a>, 
<a href="/search/eess?searchtype=author&query=Dojat%2C+M">Michel Dojat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at MICCAI Workshop on 2nd Resource-Efficient Medical Image Analysis (REMIA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The burden of liver tumors is important, ranking as the fourth leading cause
of cancer mortality. In case of hepatocellular carcinoma (HCC), the delineation
of liver and tumor on contrast-enhanced magnetic resonance imaging (CE-MRI) is
performed to guide the treatment strategy. As this task is time-consuming,
needs high expertise and could be subject to inter-observer variability there
is a strong need for automatic tools. However, challenges arise from the lack
of available training data, as well as the high variability in terms of image
resolution and MRI sequence. In this work we propose to compare two different
pipelines based on anisotropic models to obtain the segmentation of the liver
and tumors. The first pipeline corresponds to a baseline multi-class model that
performs the simultaneous segmentation of the liver and tumor classes. In the
second approach, we train two distinct binary models, one segmenting the liver
only and the other the tumors. Our results show that both pipelines exhibit
different strengths and weaknesses. Moreover we propose an uncertainty
quantification strategy allowing the identification of potential false positive
tumor lesions. Both solutions were submitted to the MICCAI 2023 Atlas challenge
regarding liver and tumor segmentation.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11980" title="Abstract">arXiv:2308.11980</a> (cross-list from eess.AS) [<a href="/pdf/2308.11980" title="Download PDF">pdf</a>, <a href="/format/2308.11980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Prediction of Audio Event and Annoyance Rating in an Urban  Soundscape by Hierarchical Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hou%2C+Y">Yuanbo Hou</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Siyang Song</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+C">Cheng Luo</a>, 
<a href="/search/eess?searchtype=author&query=Mitchell%2C+A">Andrew Mitchell</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Q">Qiaoqiao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+W">Weicheng Xie</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+J">Jian Kang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Botteldooren%2C+D">Dick Botteldooren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023, Code and models: <a href="https://github.com/Yuanbo2020/HGRL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Sound events in daily life carry rich information about the objective world.
The composition of these sounds affects the mood of people in a soundscape.
Most previous approaches only focus on classifying and detecting audio events
and scenes, but may ignore their perceptual quality that may impact humans'
listening mood for the environment, e.g. annoyance. To this end, this paper
proposes a novel hierarchical graph representation learning (HGRL) approach
which links objective audio events (AE) with subjective annoyance ratings (AR)
of the soundscape perceived by humans. The hierarchical graph consists of
fine-grained event (fAE) embeddings with single-class event semantics,
coarse-grained event (cAE) embeddings with multi-class event semantics, and AR
embeddings. Experiments show the proposed HGRL successfully integrates AE with
AR for AEC and ARP tasks, while coordinating the relations between cAE and fAE
and further aligning the two different grains of AE information with the AR.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11984" title="Abstract">arXiv:2308.11984</a> (cross-list from math.OC) [<a href="/pdf/2308.11984" title="Download PDF">pdf</a>, <a href="/ps/2308.11984" title="Download PostScript">ps</a>, <a href="/format/2308.11984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-ergodic linear convergence property of the delayed gradient descent  under the strongly convexity and the Polyak-&#x141;ojasiewicz condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choi%2C+H+J">Hyung Jun Choi</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+W">Woocheol Choi</a>, 
<a href="/search/math?searchtype=author&query=Seok%2C+J">Jinmyoung Seok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this work, we establish the linear convergence estimate for the gradient
descent involving the delay $\tau\in\mathbb{N}$ when the cost function is
$\mu$-strongly convex and $L$-smooth. This result improves upon the well-known
estimates in Arjevani et al. \cite{ASS} and Stich-Karmireddy \cite{SK} in the
sense that it is non-ergodic and is still established in spite of weaker
constraint of cost function. Also, the range of learning rate $\eta$ can be
extended from $\eta\leq 1/(10L\tau)$ to $\eta\leq 1/(4L\tau)$ for $\tau =1$ and
$\eta\leq 3/(10L\tau)$ for $\tau \geq 2$, where $L &gt;0$ is the Lipschitz
continuity constant of the gradient of cost function. In a further research, we
show the linear convergence of cost function under the
Polyak-{\L}ojasiewicz\,(PL) condition, for which the available choice of
learning rate is further improved as $\eta\leq 9/(10L\tau)$ for the large delay
$\tau$. Finally, some numerical experiments are provided in order to confirm
the reliability of the analyzed results.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11992" title="Abstract">arXiv:2308.11992</a> (cross-list from q-bio.TO) [<a href="/pdf/2308.11992" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Evaluation of Artificial Intelligence as Digital Twin of  Pathologist for Prostate Cancer Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Eminaga%2C+O">Okyaz Eminaga</a>, 
<a href="/search/q-bio?searchtype=author&query=Abbas%2C+M">Mahmoud Abbas</a>, 
<a href="/search/q-bio?searchtype=author&query=Kunder%2C+C">Christian Kunder</a>, 
<a href="/search/q-bio?searchtype=author&query=Tolkach%2C+Y">Yuri Tolkach</a>, 
<a href="/search/q-bio?searchtype=author&query=Han%2C+R">Ryan Han</a>, 
<a href="/search/q-bio?searchtype=author&query=Brooks%2C+J+D">James D. Brooks</a>, 
<a href="/search/q-bio?searchtype=author&query=Nolley%2C+R">Rosalie Nolley</a>, 
<a href="/search/q-bio?searchtype=author&query=Semjonow%2C+A">Axel Semjonow</a>, 
<a href="/search/q-bio?searchtype=author&query=Boegemann%2C+M">Martin Boegemann</a>, 
<a href="/search/q-bio?searchtype=author&query=West%2C+R">Robert West</a>, 
<a href="/search/q-bio?searchtype=author&query=Long%2C+J">Jin Long</a>, 
<a href="/search/q-bio?searchtype=author&query=Fan%2C+R">Richard Fan</a>, 
<a href="/search/q-bio?searchtype=author&query=Bettendorf%2C+O">Olaf Bettendorf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Prostate cancer pathology plays a crucial role in clinical management but is
time-consuming. Artificial intelligence (AI) shows promise in detecting
prostate cancer and grading patterns. We tested an AI-based digital twin of a
pathologist, vPatho, on 2,603 histology images of prostate tissue stained with
hematoxylin and eosin. We analyzed various factors influencing tumor-grade
disagreement between vPatho and six human pathologists. Our results
demonstrated that vPatho achieved comparable performance in prostate cancer
detection and tumor volume estimation, as reported in the literature.
Concordance levels between vPatho and human pathologists were examined.
Notably, moderate to substantial agreement was observed in identifying
complementary histological features such as ductal, cribriform, nerve, blood
vessels, and lymph cell infiltrations. However, concordance in tumor grading
showed a decline when applied to prostatectomy specimens (kappa = 0.44)
compared to biopsy cores (kappa = 0.70). Adjusting the decision threshold for
the secondary Gleason pattern from 5% to 10% improved the concordance level
between pathologists and vPatho for tumor grading on prostatectomy specimens
(kappa from 0.44 to 0.64). Potential causes of grade discordance included the
vertical extent of tumors toward the prostate boundary and the proportions of
slides with prostate cancer. Gleason pattern 4 was particularly associated with
discordance. Notably, grade discordance with vPatho was not specific to any of
the six pathologists involved in routine clinical grading. In conclusion, our
study highlights the potential utility of AI in developing a digital twin of a
pathologist. This approach can help uncover limitations in AI adoption and the
current grading system for prostate cancer pathology.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12000" title="Abstract">arXiv:2308.12000</a> (cross-list from stat.ML) [<a href="/pdf/2308.12000" title="Download PDF">pdf</a>, <a href="/ps/2308.12000" title="Download PostScript">ps</a>, <a href="/format/2308.12000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed  Bandits with Fixed Budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+P">Po-An Wang</a>, 
<a href="/search/stat?searchtype=author&query=Ariu%2C+K">Kaito Ariu</a>, 
<a href="/search/stat?searchtype=author&query=Proutiere%2C+A">Alexandre Proutiere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the problem of best-arm identification with fixed budget in
stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly,
there is no algorithm that (i) performs as well as the algorithm sampling each
arm equally (this algorithm is referred to as the {\it uniform sampling}
algorithm) on all instances, and that (ii) strictly outperforms this algorithm
on at least one instance. In short, there is no algorithm better than the
uniform sampling algorithm. Towards this result, we introduce the natural class
of {\it consistent} and {\it stable} algorithms, and show that any algorithm
that performs as well as the uniform sampling algorithm on all instances
belongs to this class. The proof is completed by deriving a lower bound on the
error rate satisfied by any consistent and stable algorithm, and by showing
that the uniform sampling algorithm matches this lower bound. Our results
provide a solution to the two open problems presented in \cite{qin2022open}.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12013" title="Abstract">arXiv:2308.12013</a> (cross-list from quant-ph) [<a href="/pdf/2308.12013" title="Download PDF">pdf</a>, <a href="/format/2308.12013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Noise-driven Generative Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Parigi%2C+M">Marco Parigi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martina%2C+S">Stefano Martina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caruso%2C+F">Filippo Caruso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Generative models realized with machine learning techniques are powerful
tools to infer complex and unknown data distributions from a finite number of
training samples in order to produce new synthetic data. Diffusion models are
an emerging framework that have recently overcome the performance of the
generative adversarial networks in creating synthetic text and high-quality
images. Here, we propose and discuss the quantum generalization of diffusion
models, i.e., three quantum-noise-driven generative diffusion models that could
be experimentally tested on real quantum systems. The idea is to harness unique
quantum features, in particular the non-trivial interplay among coherence,
entanglement and noise that the currently available noisy quantum processors do
unavoidably suffer from, in order to overcome the main computational burdens of
classical diffusion models during inference. Hence, we suggest to exploit
quantum noise not as an issue to be detected and solved but instead as a very
remarkably beneficial key ingredient to generate much more complex probability
distributions that would be difficult or even impossible to express
classically, and from which a quantum processor might sample more efficiently
than a classical one. Therefore, our results are expected to pave the way for
new quantum-inspired or quantum-based generative diffusion algorithms
addressing more powerfully classical tasks as data generation/prediction with
widespread real-world applications ranging from climate forecasting to
neuroscience, from traffic flow analysis to financial forecasting.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12016" title="Abstract">arXiv:2308.12016</a> (cross-list from stat.ML) [<a href="/pdf/2308.12016" title="Download PDF">pdf</a>, <a href="/ps/2308.12016" title="Download PostScript">ps</a>, <a href="/format/2308.12016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MKL-$L_{0/1}$-SVM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+Y">Yijie Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages in the JMLR template, 4 figures, and 2 tables. arXiv admin note: substantial text overlap with <a href="/abs/2303.04445">arXiv:2303.04445</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework
for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some
first-order optimality conditions are given and then exploited to develop a
fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem.
Extensive numerical experiments on synthetic and real datasets show that the
performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading
approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and
Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12077" title="Abstract">arXiv:2308.12077</a> (cross-list from eess.AS) [<a href="/pdf/2308.12077" title="Download PDF">pdf</a>, <a href="/format/2308.12077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of XLS-R for Speech Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tamm%2C+B">Bastiaan Tamm</a>, 
<a href="/search/eess?searchtype=author&query=Vandenberghe%2C+R">Rik Vandenberghe</a>, 
<a href="/search/eess?searchtype=author&query=Van+hamme%2C+H">Hugo Van hamme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to WASPAA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In online conferencing applications, estimating the perceived quality of an
audio signal is crucial to ensure high quality of experience for the end user.
The most reliable way to assess the quality of a speech signal is through human
judgments in the form of the mean opinion score (MOS) metric. However, such an
approach is labor intensive and not feasible for large-scale applications. The
focus has therefore shifted towards automated speech quality assessment through
end-to-end training of deep neural networks. Recently, it was shown that
leveraging pre-trained wav2vec-based XLS-R embeddings leads to state-of-the-art
performance for the task of speech quality prediction. In this paper, we
perform an in-depth analysis of the pre-trained model. First, we analyze the
performance of embeddings extracted from each layer of XLS-R and also for each
size of the model (300M, 1B, 2B parameters). Surprisingly, we find two optimal
regions for feature extraction: one in the lower-level features and one in the
high-level features. Next, we investigate the reason for the two distinct
optima. We hypothesize that the lower-level features capture characteristics of
noise and room acoustics, whereas the high-level features focus on speech
content and intelligibility. To investigate this, we analyze the sensitivity of
the MOS predictions with respect to different levels of corruption in each
category. Afterwards, we try fusing the two optimal feature depths to determine
if they contain complementary information for MOS prediction. Finally, we
compare the performance of the proposed models and assess the generalizability
of the models on unseen datasets.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12084" title="Abstract">arXiv:2308.12084</a> (cross-list from eess.IV) [<a href="/pdf/2308.12084" title="Download PDF">pdf</a>, <a href="/format/2308.12084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISGAN: Wavelet-informed Discriminator Guides GAN to MRI  Super-resolution with Noise Cleaning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Mahler%2C+L">Lucas Mahler</a>, 
<a href="/search/eess?searchtype=author&query=Steiglechner%2C+J">Julius Steiglechner</a>, 
<a href="/search/eess?searchtype=author&query=Birk%2C+F">Florian Birk</a>, 
<a href="/search/eess?searchtype=author&query=Scheffler%2C+K">Klaus Scheffler</a>, 
<a href="/search/eess?searchtype=author&query=Lohmann%2C+G">Gabriele Lohmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">MRI super-resolution (SR) and denoising tasks are fundamental challenges in
the field of deep learning, which have traditionally been treated as distinct
tasks with separate paired training data. In this paper, we propose an
innovative method that addresses both tasks simultaneously using a single deep
learning model, eliminating the need for explicitly paired noisy and clean
images during training. Our proposed model is primarily trained for SR, but
also exhibits remarkable noise-cleaning capabilities in the super-resolved
images. Instead of conventional approaches that introduce frequency-related
operations into the generative process, our novel approach involves the use of
a GAN model guided by a frequency-informed discriminator. To achieve this, we
harness the power of the 3D Discrete Wavelet Transform (DWT) operation as a
frequency constraint within the GAN framework for the SR task on magnetic
resonance imaging (MRI) data. Specifically, our contributions include: 1) a 3D
generator based on residual-in-residual connected blocks; 2) the integration of
the 3D DWT with $1\times 1$ convolution into a DWT+conv unit within a 3D Unet
for the discriminator; 3) the use of the trained model for high-quality image
SR, accompanied by an intrinsic denoising process. We dub the model "Denoising
Induced Super-resolution GAN (DISGAN)" due to its dual effects of SR image
generation and simultaneous denoising. Departing from the traditional approach
of training SR and denoising tasks as separate models, our proposed DISGAN is
trained only on the SR task, but also achieves exceptional performance in
denoising. The model is trained on 3D MRI data from dozens of subjects from the
Human Connectome Project (HCP) and further evaluated on previously unseen MRI
data from subjects with brain tumours and epilepsy to assess its denoising and
SR performance.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12108" title="Abstract">arXiv:2308.12108</a> (cross-list from stat.ML) [<a href="/pdf/2308.12108" title="Download PDF">pdf</a>, <a href="/format/2308.12108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying degeneracy in singular models via the learning coefficient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lau%2C+E">Edmund Lau</a>, 
<a href="/search/stat?searchtype=author&query=Murfet%2C+D">Daniel Murfet</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+S">Susan Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNN) are singular statistical models which exhibit
complex degeneracies. In this work, we illustrate how a quantity known as the
\emph{learning coefficient} introduced in singular learning theory quantifies
precisely the degree of degeneracy in deep neural networks. Importantly, we
will demonstrate that degeneracy in DNN cannot be accounted for by simply
counting the number of "flat" directions. We propose a computationally scalable
approximation of a localized version of the learning coefficient using
stochastic gradient Langevin dynamics. To validate our approach, we demonstrate
its accuracy in low-dimensional models with known theoretical values.
Importantly, the local learning coefficient can correctly recover the ordering
of degeneracy between various parameter regions of interest. An experiment on
MNIST shows the local learning coefficient can reveal the inductive bias of
stochastic opitmizers for more or less degenerate critical points.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12126" title="Abstract">arXiv:2308.12126</a> (cross-list from math.OC) [<a href="/pdf/2308.12126" title="Download PDF">pdf</a>, <a href="/format/2308.12126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accelerated Block Proximal Framework with Adaptive Momentum for  Nonconvex and Nonsmooth Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+W">Weifeng Yang</a>, 
<a href="/search/math?searchtype=author&query=Min%2C+W">Wenwen Min</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose an accelerated block proximal linear framework with adaptive
momentum (ABPL$^+$) for nonconvex and nonsmooth optimization. We analyze the
potential causes of the extrapolation step failing in some algorithms, and
resolve this issue by enhancing the comparison process that evaluates the
trade-off between the proximal gradient step and the linear extrapolation step
in our algorithm. Furthermore, we extends our algorithm to any scenario
involving updating block variables with positive integers, allowing each cycle
to randomly shuffle the update order of the variable blocks. Additionally,
under mild assumptions, we prove that ABPL$^+$ can monotonically decrease the
function value without strictly restricting the extrapolation parameters and
step size, demonstrates the viability and effectiveness of updating these
blocks in a random order, and we also more obviously and intuitively
demonstrate that the derivative set of the sequence generated by our algorithm
is a critical point set. Moreover, we demonstrate the global convergence as
well as the linear and sublinear convergence rates of our algorithm by
utilizing the Kurdyka-Lojasiewicz (K{\L}) condition. To enhance the
effectiveness and flexibility of our algorithm, we also expand the study to the
imprecise version of our algorithm and construct an adaptive extrapolation
parameter strategy, which improving its overall performance. We apply our
algorithm to multiple non-negative matrix factorization with the $\ell_0$ norm,
nonnegative tensor decomposition with the $\ell_0$ norm, and perform extensive
numerical experiments to validate its effectiveness and efficiency.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12161" title="Abstract">arXiv:2308.12161</a> (cross-list from math.OC) [<a href="/pdf/2308.12161" title="Download PDF">pdf</a>, <a href="/format/2308.12161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven decision-focused surrogate modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gupta%2C+R">Rishabh Gupta</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce the concept of decision-focused surrogate modeling for solving
computationally challenging nonlinear optimization problems in real-time
settings. The proposed data-driven framework seeks to learn a simpler, e.g.
convex, surrogate optimization model that is trained to minimize the decision
prediction error, which is defined as the difference between the optimal
solutions of the original and the surrogate optimization models. The learning
problem, formulated as a bilevel program, can be viewed as a data-driven
inverse optimization problem to which we apply a decomposition-based solution
algorithm from previous work. We validate our framework through numerical
experiments involving the optimization of common nonlinear chemical processes
such as chemical reactors, heat exchanger networks, and material blending
systems. We also present a detailed comparison of decision-focused surrogate
modeling with standard data-driven surrogate modeling methods and demonstrate
that our approach is significantly more data-efficient while producing simple
surrogate models with high decision prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12168" title="Abstract">arXiv:2308.12168</a> (cross-list from eess.IV) [<a href="/pdf/2308.12168" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tumor-Centered Patching for Enhanced Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asghar%2C+M">Mutyyba Asghar</a> (1), 
<a href="/search/eess?searchtype=author&query=Shahid%2C+A+R">Ahmad Raza Shahid</a> (1), 
<a href="/search/eess?searchtype=author&query=Jamil%2C+A">Akhtar Jamil</a> (1), 
<a href="/search/eess?searchtype=author&query=Aftab%2C+K">Kiran Aftab</a> (2), 
<a href="/search/eess?searchtype=author&query=Enam%2C+S+A">Syed Ather Enam</a> (2) ((1) National University of Computer and Emerging Sciences, (2) The Aga Khan University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The realm of medical image diagnosis has advanced significantly with the
integration of computer-aided diagnosis and surgical systems. However,
challenges persist, particularly in achieving precise image segmentation. While
deep learning techniques show potential, obstacles like limited resources, slow
convergence, and class imbalance impede their effectiveness. Traditional
patch-based methods, though common, struggle to capture intricate tumor
boundaries and often lead to redundant samples, compromising computational
efficiency and feature quality. To tackle these issues, this research
introduces an innovative approach centered on the tumor itself for patch-based
image analysis. This novel tumor-centered patching method aims to address the
class imbalance and boundary deficiencies, enabling focused and accurate tumor
segmentation. By aligning patches with the tumor's anatomical context, this
technique enhances feature extraction accuracy and reduces computational load.
Experimental results demonstrate improved class imbalance, with segmentation
scores of 0.78, 0.76, and 0.71 for whole, core, and enhancing tumors,
respectively using a lightweight simple U-Net. This approach shows potential
for enhancing medical image segmentation and improving computer-aided diagnosis
systems.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12193" title="Abstract">arXiv:2308.12193</a> (cross-list from physics.geo-ph) [<a href="/pdf/2308.12193" title="Download PDF">pdf</a>, <a href="/format/2308.12193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Knowledge-Driven Deep Learning for 3D Magnetic Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+Y">Yinshuo Li</a>, 
<a href="/search/physics?searchtype=author&query=Jia%2C+Z">Zhuo Jia</a>, 
<a href="/search/physics?searchtype=author&query=Lu%2C+W">Wenkai Lu</a>, 
<a href="/search/physics?searchtype=author&query=Song%2C+C">Cao Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The magnetic inversion method is one of the non-destructive geophysical
methods, which aims to estimate the subsurface susceptibility distribution from
surface magnetic anomaly data. Recently, supervised deep learning methods have
been widely utilized in lots of geophysical fields including magnetic
inversion. However, these methods rely heavily on synthetic training data,
whose performance is limited since the synthetic data is not independently and
identically distributed with the field data. Thus, we proposed to realize
magnetic inversion by self-supervised deep learning. The proposed
self-supervised knowledge-driven 3D magnetic inversion method (SSKMI) learns on
the target field data by a closed loop of the inversion and forward models.
Given that the parameters of the forward model are preset, SSKMI can optimize
the inversion model by minimizing the mean absolute error between observed and
re-estimated surface magnetic anomalies. Besides, there is a knowledge-driven
module in the proposed inversion model, which makes the deep learning method
more explicable. Meanwhile, comparative experiments demonstrate that the
knowledge-driven module can accelerate the training of the proposed method and
achieve better results. Since magnetic inversion is an ill-pose task, SSKMI
proposed to constrain the inversion model by a guideline in the auxiliary loop.
The experimental results demonstrate that the proposed method is a reliable
magnetic inversion method with outstanding performance.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12198" title="Abstract">arXiv:2308.12198</a> (cross-list from eess.SP) [<a href="/pdf/2308.12198" title="Download PDF">pdf</a>, <a href="/format/2308.12198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Beam Alignment for Millimeter-Wave Communication Systems: A  Deep Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Junyi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+W">Weifeng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+M">Meixia Tao</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+S">Shu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 figures, to appear in Transactions on Wireless Communications. arXiv admin note: text overlap with <a href="/abs/2209.03643">arXiv:2209.03643</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Fast and precise beam alignment is crucial for high-quality data transmission
in millimeter-wave (mmWave) communication systems, where large-scale antenna
arrays are utilized to overcome the severe propagation loss. To tackle the
challenging problem, we propose a novel deep learning-based hierarchical beam
alignment method for both multiple-input single-output (MISO) and
multiple-input multiple-output (MIMO) systems, which learns two tiers of
probing codebooks (PCs) and uses their measurements to predict the optimal beam
in a coarse-to-fine search manner. Specifically, a hierarchical beam alignment
network (HBAN) is developed for MISO systems, which first performs coarse
channel measurement using a tier-1 PC, then selects a tier-2 PC for fine
channel measurement, and finally predicts the optimal beam based on both coarse
and fine measurements. The propounded HBAN is trained in two steps: the tier-1
PC and the tier-2 PC selector are first trained jointly, followed by the joint
training of all the tier-2 PCs and beam predictors. Furthermore, an HBAN for
MIMO systems is proposed to directly predict the optimal beam pair without
performing beam alignment individually at the transmitter and receiver.
Numerical results demonstrate that the proposed HBANs are superior to the
state-of-art methods in both alignment accuracy and signaling overhead
reduction.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12212" title="Abstract">arXiv:2308.12212</a> (cross-list from q-fin.PM) [<a href="/pdf/2308.12212" title="Download PDF">pdf</a>, <a href="/format/2308.12212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Learn Financial Networks for Optimising Momentum Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Xingyue">Xingyue</a> (Stacy)Pu, 
<a href="/search/q-fin?searchtype=author&query=Zohren%2C+S">Stefan Zohren</a>, 
<a href="/search/q-fin?searchtype=author&query=Roberts%2C+S">Stephen Roberts</a>, 
<a href="/search/q-fin?searchtype=author&query=Dong%2C+X">Xiaowen Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Trading and Market Microstructure (q-fin.TR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Network momentum provides a novel type of risk premium, which exploits the
interconnections among assets in a financial network to predict future returns.
However, the current process of constructing financial networks relies heavily
on expensive databases and financial expertise, limiting accessibility for
small-sized and academic institutions. Furthermore, the traditional approach
treats network construction and portfolio optimisation as separate tasks,
potentially hindering optimal portfolio performance. To address these
challenges, we propose L2GMOM, an end-to-end machine learning framework that
simultaneously learns financial networks and optimises trading signals for
network momentum strategies. The model of L2GMOM is a neural network with a
highly interpretable forward propagation architecture, which is derived from
algorithm unrolling. The L2GMOM is flexible and can be trained with diverse
loss functions for portfolio performance, e.g. the negative Sharpe ratio.
Backtesting on 64 continuous future contracts demonstrates a significant
improvement in portfolio profitability and risk control, with a Sharpe ratio of
1.74 across a 20-year period.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12224" title="Abstract">arXiv:2308.12224</a> (cross-list from q-bio.QM) [<a href="/pdf/2308.12224" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing cardiovascular risk prediction through AI-enabled  calcium-omics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hoori%2C+A">Ammar Hoori</a>, 
<a href="/search/q-bio?searchtype=author&query=Al-Kindi%2C+S">Sadeer Al-Kindi</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Song%2C+Y">Yingnan Song</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+J">Juhwan Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Tashtish%2C+N">Nour Tashtish</a>, 
<a href="/search/q-bio?searchtype=author&query=Fu%2C+P">Pingfu Fu</a>, 
<a href="/search/q-bio?searchtype=author&query=Gilkeson%2C+R">Robert Gilkeson</a>, 
<a href="/search/q-bio?searchtype=author&query=Rajagopalan%2C+S">Sanjay Rajagopalan</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilson%2C+D+L">David L. Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 2 tables, 4 pages supplemental, journal paper format (under review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Background. Coronary artery calcium (CAC) is a powerful predictor of major
adverse cardiovascular events (MACE). Traditional Agatston score simply sums
the calcium, albeit in a non-linear way, leaving room for improved
calcification assessments that will more fully capture the extent of disease.
<br />Objective. To determine if AI methods using detailed calcification features
(i.e., calcium-omics) can improve MACE prediction.
<br />Methods. We investigated additional features of calcification including
assessment of mass, volume, density, spatial distribution, territory, etc. We
used a Cox model with elastic-net regularization on 2457 CT calcium score
(CTCS) enriched for MACE events obtained from a large no-cost CLARIFY program
(ClinicalTri-als.gov Identifier: NCT04075162). We employed sampling techniques
to enhance model training. We also investigated Cox models with selected
features to identify explainable high-risk characteristics.
<br />Results. Our proposed calcium-omics model with modified synthetic down
sampling and up sampling gave C-index (80.5%/71.6%) and two-year AUC
(82.4%/74.8%) for (80:20, training/testing), respectively (sampling was applied
to the training set only). Results compared favorably to Agatston which gave
C-index (71.3%/70.3%) and AUC (71.8%/68.8%), respectively. Among calcium-omics
features, numbers of calcifications, LAD mass, and diffusivity (a measure of
spatial distribution) were important determinants of increased risk, with dense
calcification (&gt;1000HU) associated with lower risk. The calcium-omics model
reclassified 63% of MACE patients to the high risk group in a held-out test.
The categorical net-reclassification index was NRI=0.153.
<br />Conclusions. AI analysis of coronary calcification can lead to improved
results as compared to Agatston scoring. Our findings suggest the utility of
calcium-omics in improved prediction of risk.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12231" title="Abstract">arXiv:2308.12231</a> (cross-list from eess.IV) [<a href="/pdf/2308.12231" title="Download PDF">pdf</a>, <a href="/format/2308.12231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+W">Wenwei Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+X">Xueyao Bao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Haoran Chen</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+W">Wenting Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Image segmentation plays an essential role in nuclei image analysis.
Recently, the segment anything model has made a significant breakthrough in
such tasks. However, the current model exists two major issues for cell
segmentation: (1) the image encoder of the segment anything model involves a
large number of parameters. Retraining or even fine-tuning the model still
requires expensive computational resources. (2) in point prompt mode, points
are sampled from the center of the ground truth and more than one set of points
is expected to achieve reliable performance, which is not efficient for
practical applications. In this paper, a single-point prompt network is
proposed for nuclei image segmentation, called SPPNet. We replace the original
image encoder with a lightweight vision transformer. Also, an effective
convolutional block is added in parallel to extract the low-level semantic
information from the image and compensate for the performance degradation due
to the small image encoder. We propose a new point-sampling method based on the
Gaussian kernel. The proposed model is evaluated on the MoNuSeg-2018 dataset.
The result demonstrated that SPPNet outperforms existing U-shape architectures
and shows faster convergence in training. Compared to the segment anything
model, SPPNet shows roughly 20 times faster inference, with 1/70 parameters and
computational cost. Particularly, only one set of points is required in both
the training and inference phases, which is more reasonable for clinical
applications. The code for our work and more technical details can be found at
https://github.com/xq141839/SPPNet.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12259" title="Abstract">arXiv:2308.12259</a> (cross-list from eess.SP) [<a href="/pdf/2308.12259" title="Download PDF">pdf</a>, <a href="/format/2308.12259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Identification Using the Signed Cumulative Distribution Transform  In Structural Health Monitoring Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rubaiyat%2C+A+H+M">Abu Hasnat Mohammad Rubaiyat</a>, 
<a href="/search/eess?searchtype=author&query=Thai%2C+D+H">Duy H. Thai</a>, 
<a href="/search/eess?searchtype=author&query=Nichols%2C+J+M">Jonathan M. Nichols</a>, 
<a href="/search/eess?searchtype=author&query=Hutchinson%2C+M+N">Meredith N. Hutchinson</a>, 
<a href="/search/eess?searchtype=author&query=Wallen%2C+S+P">Samuel P. Wallen</a>, 
<a href="/search/eess?searchtype=author&query=Naify%2C+C+J">Christina J. Naify</a>, 
<a href="/search/eess?searchtype=author&query=Geib%2C+N">Nathan Geib</a>, 
<a href="/search/eess?searchtype=author&query=Haberman%2C+M+R">Michael R. Haberman</a>, 
<a href="/search/eess?searchtype=author&query=Rohde%2C+G+K">Gustavo K. Rohde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a novel, data-driven approach to identifying partial
differential equation (PDE) parameters of a dynamical system in structural
health monitoring applications. Specifically, we adopt a mathematical
"transport" model of the sensor data that allows us to accurately estimate the
model parameters, including those associated with structural damage. This is
accomplished by means of a newly-developed transform, the signed cumulative
distribution transform (SCDT), which is shown to convert the general, nonlinear
parameter estimation problem into a simple linear regression. This approach has
the additional practical advantage of requiring no a priori knowledge of the
source of the excitation (or, alternatively, the initial conditions). By using
training sensor data, we devise a coarse regression procedure to recover
different PDE parameters from a single sensor measurement. Numerical
experiments show that the proposed regression procedure is capable of detecting
and estimating PDE parameters with superior accuracy compared to a number of
recently developed "Deep Learning" methods. The Python implementation of the
proposed system identification technique is integrated as a part of the
software package PyTransKit (https://github.com/rohdelab/PyTransKit).
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12273" title="Abstract">arXiv:2308.12273</a> (cross-list from math.CO) [<a href="/pdf/2308.12273" title="Download PDF">pdf</a>, <a href="/ps/2308.12273" title="Download PostScript">ps</a>, <a href="/format/2308.12273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assouad-Nagata dimension of minor-closed metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Chun-Hung Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2007.08771">arXiv:2007.08771</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Group Theory (math.GR); Geometric Topology (math.GT); Metric Geometry (math.MG)

</div>
<p class="mathjax">Assouad-Nagata dimension addresses both large and small scale behaviors of
metric spaces and is a refinement of Gromov's asymptotic dimension. A metric
space $M$ is a minor-closed metric if there exists an (edge)-weighted graph $G$
in a fixed minor-closed family such that the underlying space of $M$ is the
vertex-set of $G$, and the metric of $M$ is the distance function in $G$.
Minor-closed metrics naturally arise when removing redundant edges of the
underlying graphs by using edge-deletion and edge-contraction. In this paper,
we determine the Assouad-Nagata dimension of every minor-closed metric. It is a
common generalization of known results for the asymptotic dimension of
$H$-minor free unweighted graphs and the Assouad-Nagata dimension of some
2-dimensional continuous spaces (e.g.\ complete Rienmannian surfaces with
finite Euler genus) and their corollaries.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 24 Aug 23</h3>
<dl>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1711.02695" title="Abstract">arXiv:1711.02695</a> (replaced) [<a href="/pdf/1711.02695" title="Download PDF">pdf</a>, <a href="/ps/1711.02695" title="Download PostScript">ps</a>, <a href="/format/1711.02695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limits of Citation Counts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mac%C3%A9%2C+A">Antonin Mac&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.05621" title="Abstract">arXiv:2103.05621</a> (replaced) [<a href="/pdf/2103.05621" title="Download PDF">pdf</a>, <a href="/format/2103.05621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Common Intuition to Transfer Learning Can Win or Lose: Case Studies  for Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dar%2C+Y">Yehuda Dar</a>, 
<a href="/search/cs?searchtype=author&query=LeJeune%2C+D">Daniel LeJeune</a>, 
<a href="/search/cs?searchtype=author&query=Baraniuk%2C+R+G">Richard G. Baraniuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.02461" title="Abstract">arXiv:2104.02461</a> (replaced) [<a href="/pdf/2104.02461" title="Download PDF">pdf</a>, <a href="/ps/2104.02461" title="Download PostScript">ps</a>, <a href="/format/2104.02461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorted Range Reporting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akram%2C+W">Waseem Akram</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Sanjeev Saxena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.07463" title="Abstract">arXiv:2104.07463</a> (replaced) [<a href="/pdf/2104.07463" title="Download PDF">pdf</a>, <a href="/format/2104.07463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Single-Exponential Time 2-Approximation Algorithm for Treewidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+T">Tuukka Korhonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures. FOCS 2021, to appear in SICOMP special issue for FOCS 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.09462" title="Abstract">arXiv:2104.09462</a> (replaced) [<a href="/pdf/2104.09462" title="Download PDF">pdf</a>, <a href="/format/2104.09462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heads in the Clouds: Measuring the Implications of Universities  Migrating to Public Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiebig%2C+T">Tobias Fiebig</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrses%2C+S">Seda G&#xfc;rses</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C3%B1%C3%A1n%2C+C+H">Carlos H. Ga&#xf1;&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Kotkamp%2C+E">Erna Kotkamp</a>, 
<a href="/search/cs?searchtype=author&query=Kuipers%2C+F">Fernando Kuipers</a>, 
<a href="/search/cs?searchtype=author&query=Lindorfer%2C+M">Martina Lindorfer</a>, 
<a href="/search/cs?searchtype=author&query=Prisse%2C+M">Menghua Prisse</a>, 
<a href="/search/cs?searchtype=author&query=Sari%2C+T">Taritha Sari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update 3: Final version published at PETS'23/PoPETS 2023(2). Now includes data up until October 2022 and an extended discussion, as well as a new appendix comprehensively describing how DNS works
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings on Privacy Enhancing Technologies Symposium,
  2023(2). 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.11342" title="Abstract">arXiv:2106.11342</a> (replaced) [<a href="/pdf/2106.11342" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dive into Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aston Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mu Li</a>, 
<a href="/search/cs?searchtype=author&query=Smola%2C+A+J">Alexander J. Smola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (HTML) <a href="https://D2L.ai">this https URL</a> (GitHub) <a href="https://github.com/d2l-ai/d2l-en/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00259" title="Abstract">arXiv:2108.00259</a> (replaced) [<a href="/pdf/2108.00259" title="Download PDF">pdf</a>, <a href="/format/2108.00259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How much pre-training is enough to discover a good subnetwork?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wolfe%2C+C+R">Cameron R. Wolfe</a>, 
<a href="/search/stat?searchtype=author&query=Liao%2C+F">Fangshuo Liao</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Q">Qihan Wang</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+J+L">Junhyung Lyle Kim</a>, 
<a href="/search/stat?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.03006" title="Abstract">arXiv:2110.03006</a> (replaced) [<a href="/pdf/2110.03006" title="Download PDF">pdf</a>, <a href="/format/2110.03006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Selective Labeling for More Effective Semi-Supervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+L">Long Lian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ECCV 2022; Fixed a few typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.01575" title="Abstract">arXiv:2112.01575</a> (replaced) [<a href="/pdf/2112.01575" title="Download PDF">pdf</a>, <a href="/format/2112.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interactive Reinforcement Learning with Intrinsic Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poole%2C+B">Benjamin Poole</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minwoo Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Name change and vast rewrites of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06714" title="Abstract">arXiv:2201.06714</a> (replaced) [<a href="/pdf/2201.06714" title="Download PDF">pdf</a>, <a href="/format/2201.06714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaTerm: Adaptive T-Distribution Estimated Robust Moments for  Noise-Robust Stochastic Gradient Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ilboudo%2C+W+E+L">Wendyam Eric Lionel Ilboudo</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+T">Taisuke Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+T">Takamitsu Matsubara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages; Final version accepted by Elsevier Neurocomputing Journal (2023-08; <a href="https://doi.org/10.1016/j.neucom.2023.126692">this https URL</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing 2023-08
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.04311" title="Abstract">arXiv:2202.04311</a> (replaced) [<a href="/pdf/2202.04311" title="Download PDF">pdf</a>, <a href="/format/2202.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Backdoor Attacks in Federated Learning via Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+Y">Yuxi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jihong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuigeng Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> APWeb-WAIM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.07328" title="Abstract">arXiv:2202.07328</a> (replaced) [<a href="/pdf/2202.07328" title="Download PDF">pdf</a>, <a href="/ps/2202.07328" title="Download PostScript">ps</a>, <a href="/format/2202.07328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Beamforming Design for Rate-Splitting Multiple Access in  Multi-antenna Broadcast Channel with Confidential Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Huiyun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaokang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuai Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2201.08472">arXiv:2201.08472</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08434" title="Abstract">arXiv:2203.08434</a> (replaced) [<a href="/pdf/2203.08434" title="Download PDF">pdf</a>, <a href="/format/2203.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Residual Error and Bag-of-Tricks Learning for Gravitational Wave  Surrogate Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Fragkouli%2C+S">Styliani-Christina Fragkouli</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nousi%2C+P">Paraskevi Nousi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Passalis%2C+N">Nikolaos Passalis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Iosif%2C+P">Panagiotis Iosif</a>, 
<a href="/search/astro-ph?searchtype=author&query=Stergioulas%2C+N">Nikolaos Stergioulas</a>, 
<a href="/search/astro-ph?searchtype=author&query=Tefas%2C+A">Anastasios Tefas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> j.asoc.2023.110746
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Machine Learning (cs.LG); General Relativity and Quantum Cosmology (gr-qc)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16475" title="Abstract">arXiv:2203.16475</a> (replaced) [<a href="/pdf/2203.16475" title="Download PDF">pdf</a>, <a href="/format/2203.16475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Evolution in Deep Learning Training: A Unified Interpretation  Framework and Discoveries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Haekyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hoover%2C+B">Benjamin Hoover</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+A+P">Austin P. Wright</a>, 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+O">Omar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Duggal%2C+R">Rahul Duggal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+N">Nilaksh Das</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kevin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CIKM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07728" title="Abstract">arXiv:2204.07728</a> (replaced) [<a href="/pdf/2204.07728" title="Download PDF">pdf</a>, <a href="/ps/2204.07728" title="Download PostScript">ps</a>, <a href="/format/2204.07728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FTMPST: Fault-Tolerant Multiparty Session Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+K">Kirstin Peters</a>, 
<a href="/search/cs?searchtype=author&query=Nestmann%2C+U">Uwe Nestmann</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C">Christoph Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint for submission to LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11418" title="Abstract">arXiv:2204.11418</a> (replaced) [<a href="/pdf/2204.11418" title="Download PDF">pdf</a>, <a href="/format/2204.11418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Hamiltonian methods for min-max optimization on manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+A">Andi Han</a>, 
<a href="/search/math?searchtype=author&query=Mishra%2C+B">Bamdev Mishra</a>, 
<a href="/search/math?searchtype=author&query=Jawanpuria%2C+P">Pratik Jawanpuria</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+P">Pawan Kumar</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM Journal on Optimization, 33(3), pp.1797-1827, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03977" title="Abstract">arXiv:2205.03977</a> (replaced) [<a href="/pdf/2205.03977" title="Download PDF">pdf</a>, <a href="/format/2205.03977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structured Span Selector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y+E">Yuchen Eleanor Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NAACL 2022 camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12423" title="Abstract">arXiv:2205.12423</a> (replaced) [<a href="/pdf/2205.12423" title="Download PDF">pdf</a>, <a href="/format/2205.12423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deletion and Insertion Tests in Regression Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hama%2C+N">Naofumi Hama</a>, 
<a href="/search/cs?searchtype=author&query=Mase%2C+M">Masayoshi Mase</a>, 
<a href="/search/cs?searchtype=author&query=Owen%2C+A+B">Art B. Owen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00309" title="Abstract">arXiv:2206.00309</a> (replaced) [<a href="/pdf/2206.00309" title="Download PDF">pdf</a>, <a href="/format/2206.00309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-Efficient Online Continual Object Detection in Streaming Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wynne Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02667" title="Abstract">arXiv:2206.02667</a> (replaced) [<a href="/pdf/2206.02667" title="Download PDF">pdf</a>, <a href="/format/2206.02667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent segmentation from participation dynamics and multi-learner  retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dean%2C+S">Sarah Dean</a>, 
<a href="/search/cs?searchtype=author&query=Curmei%2C+M">Mihaela Curmei</a>, 
<a href="/search/cs?searchtype=author&query=Ratliff%2C+L+J">Lillian J. Ratliff</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstern%2C+J">Jamie Morgenstern</a>, 
<a href="/search/cs?searchtype=author&query=Fazel%2C+M">Maryam Fazel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05184" title="Abstract">arXiv:2206.05184</a> (replaced) [<a href="/pdf/2206.05184" title="Download PDF">pdf</a>, <a href="/format/2206.05184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERE: Exploring Feature Self-relation for Self-supervised Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong-Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08955" title="Abstract">arXiv:2206.08955</a> (replaced) [<a href="/pdf/2206.08955" title="Download PDF">pdf</a>, <a href="/ps/2206.08955" title="Download PostScript">ps</a>, <a href="/format/2206.08955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making first order linear logic a generating grammar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slavnov%2C+S">Sergey Slavnov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised and extended version with detailed proofs. arXiv admin note: substantial text overlap with <a href="/abs/2112.15253">arXiv:2112.15253</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14981" title="Abstract">arXiv:2206.14981</a> (replaced) [<a href="/pdf/2206.14981" title="Download PDF">pdf</a>, <a href="/format/2206.14981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Coordinate Subgradient Method for Nonsmooth Composite  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+D">Ding Chen</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+D">Daoli Zhu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02552" title="Abstract">arXiv:2207.02552</a> (replaced) [<a href="/pdf/2207.02552" title="Download PDF">pdf</a>, <a href="/format/2207.02552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Construction of Type-II ZCCS for the MC-CDMA System with Low PMEPR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rajen Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S+K">Sushant Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+P+K">Prashant Kumar Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Majhi%2C+S">Sudhan Majhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03364" title="Abstract">arXiv:2207.03364</a> (replaced) [<a href="/pdf/2207.03364" title="Download PDF">pdf</a>, <a href="/format/2207.03364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Equality in Adaptive Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jing Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by INFORMS Journal on Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03678" title="Abstract">arXiv:2207.03678</a> (replaced) [<a href="/pdf/2207.03678" title="Download PDF">pdf</a>, <a href="/format/2207.03678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Aggregation Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parada-Mayorga%2C+A">Alejandro Parada-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gama%2C+F">Fernando Gama</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04594" title="Abstract">arXiv:2207.04594</a> (replaced) [<a href="/pdf/2207.04594" title="Download PDF">pdf</a>, <a href="/format/2207.04594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster Resource Management for Dynamic Workloads by Online Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alfares%2C+N">Nader Alfares</a>, 
<a href="/search/cs?searchtype=author&query=Kesidis%2C+G">George Kesidis</a>, 
<a href="/search/cs?searchtype=author&query=Baarzi%2C+A+F">Ata Fatahi Baarzi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aman Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12916" title="Abstract">arXiv:2207.12916</a> (replaced) [<a href="/pdf/2207.12916" title="Download PDF">pdf</a>, <a href="/ps/2207.12916" title="Download PostScript">ps</a>, <a href="/format/2207.12916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-element discretization of the smectic density equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farrell%2C+P+E">Patrick E. Farrell</a>, 
<a href="/search/math?searchtype=author&query=Hamdan%2C+A">Abdalaziz Hamdan</a>, 
<a href="/search/math?searchtype=author&query=MacLachlan%2C+S+P">Scott P. MacLachlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01368" title="Abstract">arXiv:2208.01368</a> (replaced) [<a href="/pdf/2208.01368" title="Download PDF">pdf</a>, <a href="/format/2208.01368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyABSA: A Modularized Framework for Reproducible Aspect-based Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Heng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05776" title="Abstract">arXiv:2208.05776</a> (replaced) [<a href="/pdf/2208.05776" title="Download PDF">pdf</a>, <a href="/format/2208.05776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks for Scalar Input and Functional Output
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+S">Sidi Wu</a>, 
<a href="/search/stat?searchtype=author&query=Beaulac%2C+C">C&#xe9;dric Beaulac</a>, 
<a href="/search/stat?searchtype=author&query=Cao%2C+J">Jiguo Cao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Stat Comput 33:118 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13930" title="Abstract">arXiv:2208.13930</a> (replaced) [<a href="/pdf/2208.13930" title="Download PDF">pdf</a>, <a href="/format/2208.13930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAFE: Sensitivity-Aware Features for Out-of-Distribution Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilson%2C+S">Samuel Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+D">Dimity Miller</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCnderhauf%2C+N">Niko S&#xfc;nderhauf</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Computer Vision 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01566" title="Abstract">arXiv:2209.01566</a> (replaced) [<a href="/pdf/2209.01566" title="Download PDF">pdf</a>, <a href="/format/2209.01566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Top-Down Automated Development in Limited Scopes: A  Neuro-Symbolic Framework from Expressibles to Executables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+H+C">Harald C. Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables, accepted by ESEC/FSE 2023, the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07003" title="Abstract">arXiv:2209.07003</a> (replaced) [<a href="/pdf/2209.07003" title="Download PDF">pdf</a>, <a href="/format/2209.07003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-aided UAV navigation and dynamic obstacle avoidance using  gradient-based B-spline trajectory optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08258" title="Abstract">arXiv:2209.08258</a> (replaced) [<a href="/pdf/2209.08258" title="Download PDF">pdf</a>, <a href="/format/2209.08258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A real-time dynamic obstacle tracking and mapping system for UAV  navigation and collision avoidance with an RGB-D camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08996" title="Abstract">arXiv:2209.08996</a> (replaced) [<a href="/pdf/2209.08996" title="Download PDF">pdf</a>, <a href="/format/2209.08996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDO-Net: Learning Elastic Properties of Deformable Objects from Graph  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Longhini%2C+A">Alberta Longhini</a>, 
<a href="/search/cs?searchtype=author&query=Moletta%2C+M">Marco Moletta</a>, 
<a href="/search/cs?searchtype=author&query=Reichlin%2C+A">Alfredo Reichlin</a>, 
<a href="/search/cs?searchtype=author&query=Welle%2C+M+C">Michael C. Welle</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09245" title="Abstract">arXiv:2209.09245</a> (replaced) [<a href="/pdf/2209.09245" title="Download PDF">pdf</a>, <a href="/format/2209.09245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting the Mechanism of Synergism for Drug Combinations Using  Attention-Based Hierarchical Graph Pooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+H">Heming Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Payne%2C+P+R+O">Philip R.O. Payne</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+F">Fuhai Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cancers 2023, 15(17), 4210
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11355" title="Abstract">arXiv:2209.11355</a> (replaced) [<a href="/pdf/2209.11355" title="Download PDF">pdf</a>, <a href="/format/2209.11355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Interpretable Dynamics from Images of a Freely Rotating 3D  Rigid Body
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mason%2C+J">Justice Mason</a>, 
<a href="/search/cs?searchtype=author&query=Allen-Blanchette%2C+C">Christine Allen-Blanchette</a>, 
<a href="/search/cs?searchtype=author&query=Zolman%2C+N">Nicholas Zolman</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+E">Elizabeth Davison</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+N">Naomi Leonard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12244" title="Abstract">arXiv:2209.12244</a> (replaced) [<a href="/pdf/2209.12244" title="Download PDF">pdf</a>, <a href="/format/2209.12244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Channel-Mixing: Channel and Spatial Masked AutoEncoder on  Facial Action Unit Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Taoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lijun Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01055" title="Abstract">arXiv:2210.01055</a> (replaced) [<a href="/pdf/2210.01055" title="Download PDF">pdf</a>, <a href="/format/2210.01055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01860" title="Abstract">arXiv:2210.01860</a> (replaced) [<a href="/pdf/2210.01860" title="Download PDF">pdf</a>, <a href="/format/2210.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoBandit: Efficient Prototype Selection via Multi-Armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+A+R">Arghya Roy Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Jawanpuria%2C+P">Pratik Jawanpuria</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+B">Bamdev Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Erratum corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13708" title="Abstract">arXiv:2210.13708</a> (replaced) [<a href="/pdf/2210.13708" title="Download PDF">pdf</a>, <a href="/format/2210.13708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARLlib: A Scalable and Efficient Multi-agent Reinforcement Learning  Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yifan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Minquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14055" title="Abstract">arXiv:2210.14055</a> (replaced) [<a href="/pdf/2210.14055" title="Download PDF">pdf</a>, <a href="/format/2210.14055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy-Guided Lazy Search with Feedback for Task and Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khodeir%2C+M">Mohamed Khodeir</a>, 
<a href="/search/cs?searchtype=author&query=Sonwane%2C+A">Atharv Sonwane</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+R">Ruthrash Hari</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA), London, United Kingdom, 2023, pp. 3743-3749
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14598" title="Abstract">arXiv:2210.14598</a> (replaced) [<a href="/pdf/2210.14598" title="Download PDF">pdf</a>, <a href="/format/2210.14598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Manifold Gaussian Variational Bayes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Magris%2C+M">Martin Magris</a>, 
<a href="/search/stat?searchtype=author&query=Shabani%2C+M">Mostafa Shabani</a>, 
<a href="/search/stat?searchtype=author&query=Iosifidis%2C+A">Alexandros Iosifidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06924" title="Abstract">arXiv:2211.06924</a> (replaced) [<a href="/pdf/2211.06924" title="Download PDF">pdf</a>, <a href="/format/2211.06924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tale of Two Graphs: Freezing and Denoising Graph Structures for  Multimodal Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqi Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Multimedia (MM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07026" title="Abstract">arXiv:2211.07026</a> (replaced) [<a href="/pdf/2211.07026" title="Download PDF">pdf</a>, <a href="/format/2211.07026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehension from Chaos: Towards Informed Consent for Private  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacsmar%2C+B">Bailey Kacsmar</a>, 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Tilbury%2C+K">Kyle Tilbury</a>, 
<a href="/search/cs?searchtype=author&query=Ur%2C+B">Blase Ur</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08772" title="Abstract">arXiv:2211.08772</a> (replaced) [<a href="/pdf/2211.08772" title="Download PDF">pdf</a>, <a href="/format/2211.08772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMT: Multi-Illuminant Color Constancy via Multi-Task Local Surface and  Light Color Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+M+S">Michael S. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13579" title="Abstract">arXiv:2211.13579</a> (replaced) [<a href="/pdf/2211.13579" title="Download PDF">pdf</a>, <a href="/format/2211.13579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Federated Active Learning with Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu-Tong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Baosheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures, ICCV23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15323" title="Abstract">arXiv:2211.15323</a> (replaced) [<a href="/pdf/2211.15323" title="Download PDF">pdf</a>, <a href="/format/2211.15323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Analysis of the Consumer Remote SIM Provisioning Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A+S">Abu Shohel Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Peltonen%2C+A">Aleksi Peltonen</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+M">Mohit Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Aura%2C+T">Tuomas Aura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 9 figures, Associated ProVerif model files located at <a href="https://github.com/peltona/rsp_model">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15498" title="Abstract">arXiv:2211.15498</a> (replaced) [<a href="/pdf/2211.15498" title="Download PDF">pdf</a>, <a href="/format/2211.15498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural networks with unknown measurement noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pilar%2C+P">Philipp Pilar</a>, 
<a href="/search/stat?searchtype=author&query=Wahlstr%C3%B6m%2C+N">Niklas Wahlstr&#xf6;m</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04871" title="Abstract">arXiv:2212.04871</a> (replaced) [<a href="/pdf/2212.04871" title="Download PDF">pdf</a>, <a href="/format/2212.04871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spurious Features Everywhere -- Large-Scale Detection of Harmful  Spurious Features in ImageNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neuhaus%2C+Y">Yannic Neuhaus</a>, 
<a href="/search/cs?searchtype=author&query=Augustin%2C+M">Maximilian Augustin</a>, 
<a href="/search/cs?searchtype=author&query=Boreiko%2C+V">Valentyn Boreiko</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07771" title="Abstract">arXiv:2212.07771</a> (replaced) [<a href="/pdf/2212.07771" title="Download PDF">pdf</a>, <a href="/format/2212.07771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Saliency Detection Towards Explainable Transformer-based  Timeseries Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong-Trung%2C+N">Nghia Duong-Trung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Manh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le-Phuoc%2C+D">Danh Le-Phuoc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08171" title="Abstract">arXiv:2212.08171</a> (replaced) [<a href="/pdf/2212.08171" title="Download PDF">pdf</a>, <a href="/format/2212.08171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphon Pooling for Reducing Dimensionality of Signals and Convolutional  Operators on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parada-Mayorga%2C+A">Alejandro Parada-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08663" title="Abstract">arXiv:2212.08663</a> (replaced) [<a href="/pdf/2212.08663" title="Download PDF">pdf</a>, <a href="/format/2212.08663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Quantization: A Generic Augmentation for Data Agnostic  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huimin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chenyang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng-Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Stephen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhirong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. The code is available at https: //github.com/microsoft/random_quantize
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08986" title="Abstract">arXiv:2212.08986</a> (replaced) [<a href="/pdf/2212.08986" title="Download PDF">pdf</a>, <a href="/format/2212.08986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Authorship Style Transfer: Can Non-Famous Authors Be  Imitated?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Ajay Patel</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+N">Nicholas Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10135" title="Abstract">arXiv:2212.10135</a> (replaced) [<a href="/pdf/2212.10135" title="Download PDF">pdf</a>, <a href="/format/2212.10135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Witten Laplacians to locate index-1 saddle points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Leli%C3%A8vre%2C+T">Tony Leli&#xe8;vre</a>, 
<a href="/search/math?searchtype=author&query=Parpas%2C+P">Panos Parpas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02992" title="Abstract">arXiv:2301.02992</a> (replaced) [<a href="/pdf/2301.02992" title="Download PDF">pdf</a>, <a href="/format/2301.02992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimates of the time-splitting methods for the nonlinear  Schr&#xf6;dinger equation with semi-smooth nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bao%2C+W">Weizhu Bao</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Chushan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04785" title="Abstract">arXiv:2301.04785</a> (replaced) [<a href="/pdf/2301.04785" title="Download PDF">pdf</a>, <a href="/format/2301.04785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-shifted Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeachan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+I">Ihyeok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+B">Bonggun Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Uncertainty in Artificial Intelligence, 2023 (UAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05763" title="Abstract">arXiv:2301.05763</a> (replaced) [<a href="/pdf/2301.05763" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Rigorous Uncertainty-Aware Quantification Framework Is Essential for  Reproducible and Replicable Machine Learning Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pouchard%2C+L">Line Pouchard</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+K+G">Kristofer G. Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Alexander%2C+F+J">Francis J. Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+B">Byung-Jun Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07524" title="Abstract">arXiv:2301.07524</a> (replaced) [<a href="/pdf/2301.07524" title="Download PDF">pdf</a>, <a href="/format/2301.07524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Analysis of Empirical Software Engineering Data: The  Impact of Programming Languages on Coding Competitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furia%2C+C+A">Carlo A. Furia</a>, 
<a href="/search/cs?searchtype=author&query=Torkar%2C+R">Richard Torkar</a>, 
<a href="/search/cs?searchtype=author&query=Feldt%2C+R">Robert Feldt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09091" title="Abstract">arXiv:2301.09091</a> (replaced) [<a href="/pdf/2301.09091" title="Download PDF">pdf</a>, <a href="/format/2301.09091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BallGAN: 3D-aware Image Synthesis with a Spherical Background
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Minjung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yunji Seo</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Jeongmin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y+S">Young Sun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hyeran Byun</a>, 
<a href="/search/cs?searchtype=author&query=Uh%2C+Y">Youngjung Uh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project Page: <a href="https://minjung-s.github.io/ballgan">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10137" title="Abstract">arXiv:2301.10137</a> (replaced) [<a href="/pdf/2301.10137" title="Download PDF">pdf</a>, <a href="/format/2301.10137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirac signal processing of higher-order topological signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Calmon%2C+L">Lucille Calmon</a>, 
<a href="/search/eess?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>, 
<a href="/search/eess?searchtype=author&query=Bianconi%2C+G">Ginestra Bianconi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (26 pages, 12 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11004" title="Abstract">arXiv:2301.11004</a> (replaced) [<a href="/pdf/2301.11004" title="Download PDF">pdf</a>, <a href="/format/2301.11004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+M">Muskan Garg</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+C">Chandni Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Naseem%2C+U">Usman Naseem</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+B+J">Bonnie J Dorr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11117" title="Abstract">arXiv:2301.11117</a> (replaced) [<a href="/pdf/2301.11117" title="Download PDF">pdf</a>, <a href="/format/2301.11117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kanghee Park</a>, 
<a href="/search/cs?searchtype=author&query=D%27Antoni%2C+L">Loris D&#x27;Antoni</a>, 
<a href="/search/cs?searchtype=author&query=Reps%2C+T">Thomas Reps</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12685" title="Abstract">arXiv:2301.12685</a> (replaced) [<a href="/pdf/2301.12685" title="Download PDF">pdf</a>, <a href="/ps/2301.12685" title="Download PostScript">ps</a>, <a href="/format/2301.12685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Matrix Computations with Low-weight Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A+B">Anindya Bijoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthy%2C+A">Aditya Ramamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+D+J">David J. Love</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03307" title="Abstract">arXiv:2302.03307</a> (replaced) [<a href="/pdf/2302.03307" title="Download PDF">pdf</a>, <a href="/ps/2302.03307" title="Download PostScript">ps</a>, <a href="/format/2302.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Landscape of High-performance Python to Develop Data Science and Machine  Learning Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+O">Oscar Castro</a>, 
<a href="/search/cs?searchtype=author&query=Bruneau%2C+P">Pierrick Bruneau</a>, 
<a href="/search/cs?searchtype=author&query=Sottet%2C+J">Jean-S&#xe9;bastien Sottet</a>, 
<a href="/search/cs?searchtype=author&query=Torregrossa%2C+D">Dario Torregrossa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, accepted for publication in ACM Computing Surveys on 21/08/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05601" title="Abstract">arXiv:2302.05601</a> (replaced) [<a href="/pdf/2302.05601" title="Download PDF">pdf</a>, <a href="/format/2302.05601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning Deep Neural Networks from a Sparsity Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+E">Enmao Diao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ganghua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jiawei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jie Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tarokh%2C+V">Vahid Tarokh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06845" title="Abstract">arXiv:2302.06845</a> (replaced) [<a href="/pdf/2302.06845" title="Download PDF">pdf</a>, <a href="/format/2302.06845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEAM: Searching Transferable Mixed-Precision Quantization Policy through  Large Margin Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+K">Kai Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Zenghao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunpeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06912" title="Abstract">arXiv:2302.06912</a> (replaced) [<a href="/pdf/2302.06912" title="Download PDF">pdf</a>, <a href="/format/2302.06912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret-Based Optimization for Robust Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belaire%2C+R">Roman Belaire</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08835" title="Abstract">arXiv:2302.08835</a> (replaced) [<a href="/pdf/2302.08835" title="Download PDF">pdf</a>, <a href="/format/2302.08835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> h-analysis and data-parallel physics-informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Escapil-Inchausp%C3%A9%2C+P">Paul Escapil-Inchausp&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Ruz%2C+G+A">Gonzalo A. Ruz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10898" title="Abstract">arXiv:2302.10898</a> (replaced) [<a href="/pdf/2302.10898" title="Download PDF">pdf</a>, <a href="/format/2302.10898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Driver Personality Traits from On-Road Driving Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kimura%2C+R">Ryusei Kimura</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Takahiro Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yoshihara%2C+Y">Yuki Yoshihara</a>, 
<a href="/search/cs?searchtype=author&query=Fujikake%2C+K">Kazuhiro Fujikake</a>, 
<a href="/search/cs?searchtype=author&query=Kanamori%2C+H">Hitoshi Kanamori</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+S">Shogo Okada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13991" title="Abstract">arXiv:2302.13991</a> (replaced) [<a href="/pdf/2302.13991" title="Download PDF">pdf</a>, <a href="/format/2302.13991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generalize towards Unseen Domains via a Content-Aware Style  Invariant Model for Disease Detection from Chest X-rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunaed%2C+M">Mohammad Zunaed</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+M+A">Md. Aynal Haque</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+T">Taufiq Hasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02206" title="Abstract">arXiv:2303.02206</a> (replaced) [<a href="/pdf/2303.02206" title="Download PDF">pdf</a>, <a href="/format/2303.02206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Specific Question Answering Over Knowledge Graphs Using Logical  Programming and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madani%2C+N">Navid Madani</a>, 
<a href="/search/cs?searchtype=author&query=Srihari%2C+R+K">Rohini K. Srihari</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+K">Kenneth Joseph</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06840" title="Abstract">arXiv:2303.06840</a> (replaced) [<a href="/pdf/2303.06840" title="Download PDF">pdf</a>, <a href="/format/2303.06840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zixiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haowen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanzhi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangshe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06980" title="Abstract">arXiv:2303.06980</a> (replaced) [<a href="/pdf/2303.06980" title="Download PDF">pdf</a>, <a href="/format/2303.06980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised learning based general laboratory progress pretrained  model for cardiovascular event detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li-Chin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+K">Kuo-Hsuan Hung</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+Y">Yi-Ju Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hsin-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tse-Min Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei-Chieh Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in IEEE Journal of Translational Engineering in Health &amp; Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08334" title="Abstract">arXiv:2303.08334</a> (replaced) [<a href="/pdf/2303.08334" title="Download PDF">pdf</a>, <a href="/ps/2303.08334" title="Download PostScript">ps</a>, <a href="/format/2303.08334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvement of selection formulas of mesh size and truncation numbers  for the DE-Sinc approximation and its theoretical error bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Okayama%2C+T">Tomoaki Okayama</a>, 
<a href="/search/math?searchtype=author&query=Ogawa%2C+S">Shota Ogawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Sinc approximation, double-exponential transformation, error bound, mesh size, truncation number
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08743" title="Abstract">arXiv:2303.08743</a> (replaced) [<a href="/pdf/2303.08743" title="Download PDF">pdf</a>, <a href="/format/2303.08743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Solution of Bimaterial Riemann Problems for Compressible  Multi-Material Flow Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ma%2C+W">Wentao Ma</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+X">Xuning Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Islam%2C+S">Shafquat Islam</a>, 
<a href="/search/physics?searchtype=author&query=Narkhede%2C+A">Aditya Narkhede</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+K">Kevin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08942" title="Abstract">arXiv:2303.08942</a> (replaced) [<a href="/pdf/2303.08942" title="Download PDF">pdf</a>, <a href="/format/2303.08942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spherical Space Feature Decomposition for Guided Depth Map  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zixiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangshe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chengli Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09482" title="Abstract">arXiv:2303.09482</a> (replaced) [<a href="/pdf/2303.09482" title="Download PDF">pdf</a>, <a href="/format/2303.09482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive rational Krylov methods for exponential Runge--Kutta  integrators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bergermann%2C+K">Kai Bergermann</a>, 
<a href="/search/math?searchtype=author&query=Stoll%2C+M">Martin Stoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09953" title="Abstract">arXiv:2303.09953</a> (replaced) [<a href="/pdf/2303.09953" title="Download PDF">pdf</a>, <a href="/ps/2303.09953" title="Download PostScript">ps</a>, <a href="/format/2303.09953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher order derivatives of the adjugate matrix and the Jordan form
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rubiano-Murcia%2C+J+I">Jorge I. Rubiano-Murcia</a>, 
<a href="/search/math?searchtype=author&query=Galvis%2C+J">Juan Galvis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10762" title="Abstract">arXiv:2303.10762</a> (replaced) [<a href="/pdf/2303.10762" title="Download PDF">pdf</a>, <a href="/format/2303.10762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Image Fingerprint: Towards Low Budget Synthetic Image Detection and  Model Lineage Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinitsa%2C+S">Sergey Sinitsa</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+O">Ohad Fried</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10891" title="Abstract">arXiv:2303.10891</a> (replaced) [<a href="/pdf/2303.10891" title="Download PDF">pdf</a>, <a href="/format/2303.10891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Exemplar Online Class-incremental Continual Learning via  Dual-prototype Self-augment and Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huo%2C+F">Fushuo Huo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenchao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yunfeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11225" title="Abstract">arXiv:2303.11225</a> (replaced) [<a href="/pdf/2303.11225" title="Download PDF">pdf</a>, <a href="/format/2303.11225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFace: High-Fidelity 3D Face Reconstruction by Learning Static and  Dynamic Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Zenghao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Baltru%C5%A1aitis%2C+T">Tadas Baltru&#x161;aitis</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">HsiangTao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, camera-ready version; Project page: <a href="https://project-hiface.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11579" title="Abstract">arXiv:2303.11579</a> (replaced) [<a href="/pdf/2303.11579" title="Download PDF">pdf</a>, <a href="/format/2303.11579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis  Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+W">Wenkang Shan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shanshe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wen Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11702" title="Abstract">arXiv:2303.11702</a> (replaced) [<a href="/pdf/2303.11702" title="Download PDF">pdf</a>, <a href="/format/2303.11702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the link between generative semi-supervised learning and generative  open-set recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engelbrecht%2C+E+R">Emile Reyn Engelbrecht</a>, 
<a href="/search/cs?searchtype=author&query=Preez%2C+J+d">Johan du Preez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15749" title="Abstract">arXiv:2303.15749</a> (replaced) [<a href="/pdf/2303.15749" title="Download PDF">pdf</a>, <a href="/format/2303.15749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iteratively Coupled Multiple Instance Learning from Instance to Bag  Classifier for Whole Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+R">Ruofeng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lanfen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17155" title="Abstract">arXiv:2303.17155</a> (replaced) [<a href="/pdf/2303.17155" title="Download PDF">pdf</a>, <a href="/format/2303.17155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Class Tokens for Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+I">Idan Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Sn%C3%A6bjarnarson%2C+V">V&#xe9;steinn Sn&#xe6;bjarnarson</a>, 
<a href="/search/cs?searchtype=author&query=Chefer%2C+H">Hila Chefer</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Benaim%2C+S">Sagie Benaim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17618" title="Abstract">arXiv:2303.17618</a> (replaced) [<a href="/pdf/2303.17618" title="Download PDF">pdf</a>, <a href="/format/2303.17618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven abstractions via adaptive refinements and a Kantorovich  metric [extended version]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banse%2C+A">Adrien Banse</a>, 
<a href="/search/cs?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/cs?searchtype=author&query=Jungers%2C+R+M">Rapha&#xeb;l M. Jungers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is an extended version of a CDC2023 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17806" title="Abstract">arXiv:2303.17806</a> (replaced) [<a href="/pdf/2303.17806" title="Download PDF">pdf</a>, <a href="/format/2303.17806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Microfacet Fields for Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+A">Alexander Mai</a>, 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Kuester%2C+F">Falko Kuester</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+S">Sara Fridovich-Keil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://half-potato.gitlab.io/posts/nmf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02051" title="Abstract">arXiv:2304.02051</a> (replaced) [<a href="/pdf/2304.02051" title="Download PDF">pdf</a>, <a href="/format/2304.02051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Garment Designer: Human-Centric Latent Diffusion Models for  Fashion Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldrati%2C+A">Alberto Baldrati</a>, 
<a href="/search/cs?searchtype=author&query=Morelli%2C+D">Davide Morelli</a>, 
<a href="/search/cs?searchtype=author&query=Cartella%2C+G">Giuseppe Cartella</a>, 
<a href="/search/cs?searchtype=author&query=Cornia%2C+M">Marcella Cornia</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Cucchiara%2C+R">Rita Cucchiara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03578" title="Abstract">arXiv:2304.03578</a> (replaced) [<a href="/pdf/2304.03578" title="Download PDF">pdf</a>, <a href="/format/2304.03578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined Registration and Fusion of Evidential Occupancy Grid Maps for  Live Digital Twins of Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Kempen%2C+R">Raphael van Kempen</a>, 
<a href="/search/cs?searchtype=author&query=Heidrich%2C+L+A">Laurenz Adrian Heidrich</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+B">Bastian Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Woopen%2C+T">Timo Woopen</a>, 
<a href="/search/cs?searchtype=author&query=Eckstein%2C+L">Lutz Eckstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as part of the 2023 IEEE Intelligent Vehicles Symposium (IV), Anchorage, Alaska, USA, June 4-7, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04521" title="Abstract">arXiv:2304.04521</a> (replaced) [<a href="/pdf/2304.04521" title="Download PDF">pdf</a>, <a href="/format/2304.04521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyai%2C+A">Atsuyuki Miyai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+G">Go Irie</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: I fixed some typos from v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07037" title="Abstract">arXiv:2304.07037</a> (replaced) [<a href="/pdf/2304.07037" title="Download PDF">pdf</a>, <a href="/format/2304.07037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Easy Way Out: the Effectiveness of Deplatforming an Extremist Forum  to Suppress Hate and Harassment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+A+V">Anh V. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hutchings%2C+A">Alice Hutchings</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10410" title="Abstract">arXiv:2304.10410</a> (replaced) [<a href="/pdf/2304.10410" title="Download PDF">pdf</a>, <a href="/format/2304.10410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radar-Camera Fusion for Object Detection and Semantic Segmentation in  Autonomous Driving: A Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanliang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Runwei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+X">Xiangyu Sha</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E+G">Eng Gee Lim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+H">Hyungjoon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+K+L">Ka Lok Man</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaohui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yutao Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Intelligent Vehicles (T-IV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13014" title="Abstract">arXiv:2304.13014</a> (replaced) [<a href="/pdf/2304.13014" title="Download PDF">pdf</a>, <a href="/format/2304.13014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods and datasets for segmentation of minimally invasive surgical  instruments in endoscopic images and videos: A review of the state of the art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+T">Tobias Rueckert</a> (1), 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Palm%2C+C">Christoph Palm</a> (1 and 4) ((1) Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Germany, (2) Artificial Intelligence in Healthcare and Medicine, Klinikum rechts der Isar, Technical University of Munich, Germany, (3) Department of Computing, Imperial College London, UK, (4) Regensburg Center of Health Sciences and Technology (RCHST), OTH Regensburg, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01975" title="Abstract">arXiv:2305.01975</a> (replaced) [<a href="/pdf/2305.01975" title="Download PDF">pdf</a>, <a href="/format/2305.01975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Dataset Distillation: Approaches, Applications and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+J">Jiahui Geng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongxiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuandou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Woisetschlaeger%2C+H">Herbert Woisetschlaeger</a>, 
<a href="/search/cs?searchtype=author&query=Schimmler%2C+S">Sonja Schimmler</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+C">Chunming Rong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05237" title="Abstract">arXiv:2305.05237</a> (replaced) [<a href="/pdf/2305.05237" title="Download PDF">pdf</a>, <a href="/format/2305.05237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Forecasting on New Roads Unseen in the Training Data Using  Spatial Contrastive Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabowo%2C+A">Arian Prabowo</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Koniusz%2C+P">Piotr Koniusz</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages including reference, an additional 3 pages of appendix, 8 figures. ECML PKDD 2023 Journal track special issue: Data Mining and Knowledge Discovery (DAMI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05286" title="Abstract">arXiv:2305.05286</a> (replaced) [<a href="/pdf/2305.05286" title="Download PDF">pdf</a>, <a href="/format/2305.05286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Check Belief Propagation Decoding of LDPC Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Wu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Liping Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE transactions on communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06788" title="Abstract">arXiv:2305.06788</a> (replaced) [<a href="/pdf/2305.06788" title="Download PDF">pdf</a>, <a href="/format/2305.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Quantization with Error Uniformly Distributed over an Arbitrary  Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+W">Chih Wei Ling</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C+T">Cheuk Ting Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figure. Short version presented at 2023 IEEE International Symposium on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07881" title="Abstract">arXiv:2305.07881</a> (replaced) [<a href="/pdf/2305.07881" title="Download PDF">pdf</a>, <a href="/format/2305.07881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-box Source-free Domain Adaptation via Two-stage Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zipei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shitong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The short version is accepted by IJCAI 1st International Workshop on Generalizing from Limited Resources in the Open World. (This version is long version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15259" title="Abstract">arXiv:2305.15259</a> (replaced) [<a href="/pdf/2305.15259" title="Download PDF">pdf</a>, <a href="/format/2305.15259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Sensitivity Analysis for Probabilistic Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moosbrugger%2C+M">Marcel Moosbrugger</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCllner%2C+J">Julian M&#xfc;llner</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17410" title="Abstract">arXiv:2305.17410</a> (replaced) [<a href="/pdf/2305.17410" title="Download PDF">pdf</a>, <a href="/format/2305.17410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nested Game for Coupled Power System with Energy Sharing and  Transportation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+D">Dongxiang Yan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tongxin Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Changhong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yue Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19301" title="Abstract">arXiv:2305.19301</a> (replaced) [<a href="/pdf/2305.19301" title="Download PDF">pdf</a>, <a href="/format/2305.19301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Choice of Perception Loss Function for Learned Video Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salehkalaibar%2C+S">Sadaf Salehkalaibar</a>, 
<a href="/search/eess?searchtype=author&query=Phan%2C+B">Buu Phan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Khisti%2C+A">Ashish Khisti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01792" title="Abstract">arXiv:2306.01792</a> (replaced) [<a href="/pdf/2306.01792" title="Download PDF">pdf</a>, <a href="/format/2306.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Relation-aware Continual User Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sein Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namkyeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Minchul Yang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02551" title="Abstract">arXiv:2306.02551</a> (replaced) [<a href="/pdf/2306.02551" title="Download PDF">pdf</a>, <a href="/format/2306.02551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Predictive Safety Filter for RL Controllers in Dynamic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strawn%2C+K+J">Kegan J. Strawn</a>, 
<a href="/search/cs?searchtype=author&query=Ayanian%2C+N">Nora Ayanian</a>, 
<a href="/search/cs?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04647" title="Abstract">arXiv:2306.04647</a> (replaced) [<a href="/pdf/2306.04647" title="Download PDF">pdf</a>, <a href="/format/2306.04647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressed Sensing: A Discrete Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/eess?searchtype=author&query=Johnson%2C+N+A+G">Nicholas A. G. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06304" title="Abstract">arXiv:2306.06304</a> (replaced) [<a href="/pdf/2306.06304" title="Download PDF">pdf</a>, <a href="/format/2306.06304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite element interpolated neural networks for solving forward and  inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Badia%2C+S">Santiago Badia</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/math?searchtype=author&query=Mart%C3%ADn%2C+A+F">Alberto F. Mart&#xed;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06770" title="Abstract">arXiv:2306.06770</a> (replaced) [<a href="/pdf/2306.06770" title="Download PDF">pdf</a>, <a href="/format/2306.06770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Knowledge Extraction from LLMs for Task Learning through Agent  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirk%2C+J+R">James R. Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Wray%2C+R+E">Robert E. Wray</a>, 
<a href="/search/cs?searchtype=author&query=Lindes%2C+P">Peter Lindes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, 3 tables, bibliography, appendix (34 pages total). Text revised and results extended with additional tasks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08913" title="Abstract">arXiv:2306.08913</a> (replaced) [<a href="/pdf/2306.08913" title="Download PDF">pdf</a>, <a href="/format/2306.08913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Volumetric Medical Image Segmentation via Global-Local Masked  Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jia-Xin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12001" title="Abstract">arXiv:2306.12001</a> (replaced) [<a href="/pdf/2306.12001" title="Download PDF">pdf</a>, <a href="/format/2306.12001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of Catastrophic AI Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Woodside%2C+T">Thomas Woodside</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14062" title="Abstract">arXiv:2306.14062</a> (replaced) [<a href="/pdf/2306.14062" title="Download PDF">pdf</a>, <a href="/format/2306.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Uses of Large Language Models to Interpret Ambiguous Cyberattack  Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fayyazi%2C+R">Reza Fayyazi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+J">Shanchieh Jay Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14122" title="Abstract">arXiv:2306.14122</a> (replaced) [<a href="/pdf/2306.14122" title="Download PDF">pdf</a>, <a href="/format/2306.14122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Thought Prompt Distillation for Multimodal Named Entity  Recognition and Multimodal Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yujian Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> modification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14538" title="Abstract">arXiv:2306.14538</a> (replaced) [<a href="/pdf/2306.14538" title="Download PDF">pdf</a>, <a href="/format/2306.14538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learnable Differencing Center for Nighttime Depth Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yupeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14574" title="Abstract">arXiv:2306.14574</a> (replaced) [<a href="/pdf/2306.14574" title="Download PDF">pdf</a>, <a href="/format/2306.14574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-TOE: Universal TinyML On-board Evaluation Toolkit for Low-Power IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaolan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zandberg%2C+K">Koen Zandberg</a>, 
<a href="/search/cs?searchtype=author&query=Schleiser%2C+K">Kaspar Schleiser</a>, 
<a href="/search/cs?searchtype=author&query=Baccelli%2C+E">Emmanuel Baccelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in the proceedings of IFIP/IEEE PEMWN 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14937" title="Abstract">arXiv:2306.14937</a> (replaced) [<a href="/pdf/2306.14937" title="Download PDF">pdf</a>, <a href="/format/2306.14937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Description Length Clustering to Measure Meaningful Image  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahon%2C+L">Louis Mahon</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15782" title="Abstract">arXiv:2306.15782</a> (replaced) [<a href="/pdf/2306.15782" title="Download PDF">pdf</a>, <a href="/format/2306.15782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UTRNet: High-Resolution Urdu Text Recognition In Printed Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Abdur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Arjun Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 17th International Conference on Document Analysis and Recognition (ICDAR 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Document Analysis and Recognition - ICDAR 2023 (2023) 305-324
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16016" title="Abstract">arXiv:2306.16016</a> (replaced) [<a href="/pdf/2306.16016" title="Download PDF">pdf</a>, <a href="/ps/2306.16016" title="Download PostScript">ps</a>, <a href="/format/2306.16016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive Label Is All You Need for Multi-Label Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhixiang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00009" title="Abstract">arXiv:2307.00009</a> (replaced) [<a href="/pdf/2307.00009" title="Download PDF">pdf</a>, <a href="/format/2307.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Machine Learning Methods for Assigning Software Issues to  Team Members
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabak%2C+B">B&#xfc;&#x15f;ra Tabak</a>, 
<a href="/search/cs?searchtype=author&query=Aydemir%2C+F+B">Fatma Ba&#x15f;ak Aydemir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00252" title="Abstract">arXiv:2307.00252</a> (replaced) [<a href="/pdf/2307.00252" title="Download PDF">pdf</a>, <a href="/format/2307.00252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An ML approach to resolution of singularities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9rczi%2C+G">Gergely B&#xe9;rczi</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Honglu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+M">Mingcong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings of the 40th International Conference on Machine Learning TAG Workshop (ICML-TAG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00390" title="Abstract">arXiv:2307.00390</a> (replaced) [<a href="/pdf/2307.00390" title="Download PDF">pdf</a>, <a href="/format/2307.00390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PersonaGen: A Tool for Generating Personas from User Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xishuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+A">Anqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03833" title="Abstract">arXiv:2307.03833</a> (replaced) [<a href="/pdf/2307.03833" title="Download PDF">pdf</a>, <a href="/format/2307.03833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhuoran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06680" title="Abstract">arXiv:2307.06680</a> (replaced) [<a href="/pdf/2307.06680" title="Download PDF">pdf</a>, <a href="/format/2307.06680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic control of three-phase AC/DC converter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grosso%2C+M">Maxime Grosso</a>, 
<a href="/search/eess?searchtype=author&query=Riedinger%2C+P">Pierre Riedinger</a>, 
<a href="/search/eess?searchtype=author&query=Daafouz%2C+J">Jamal Daafouz</a>, 
<a href="/search/eess?searchtype=author&query=Pierfederici%2C+S">Serge Pierfederici</a>, 
<a href="/search/eess?searchtype=author&query=Janati-Idrissi%2C+H">Hicham Janati-Idrissi</a>, 
<a href="/search/eess?searchtype=author&query=Lap%C3%B4tre%2C+B">Blaise Lap&#xf4;tre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print, submitted to TSCT, currently in review. 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06857" title="Abstract">arXiv:2307.06857</a> (replaced) [<a href="/pdf/2307.06857" title="Download PDF">pdf</a>, <a href="/format/2307.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-consistency for open-ended generations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddhartha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaofei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deoras%2C+A">Anoop Deoras</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+B">Bing Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10652" title="Abstract">arXiv:2307.10652</a> (replaced) [<a href="/pdf/2307.10652" title="Download PDF">pdf</a>, <a href="/format/2307.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Landscape of Natural Language Processing Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Arabi%2C+K">Karim Arabi</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper published at the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12694" title="Abstract">arXiv:2307.12694</a> (replaced) [<a href="/pdf/2307.12694" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State Estimator Design: Addressing General Delay Structures with  Dissipative Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+Q">Qian Feng</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+F">Feng Xiao</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaoyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12907" title="Abstract">arXiv:2307.12907</a> (replaced) [<a href="/pdf/2307.12907" title="Download PDF">pdf</a>, <a href="/format/2307.12907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GridMM: Grid Memory Map for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiahao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yeqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuqiang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. The code is available at <a href="https://github.com/MrZihan/GridMM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16680" title="Abstract">arXiv:2307.16680</a> (replaced) [<a href="/pdf/2307.16680" title="Download PDF">pdf</a>, <a href="/ps/2307.16680" title="Download PostScript">ps</a>, <a href="/format/2307.16680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trustworthiness Landscape of State-of-the-art Generative Models:  A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Draft Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01095" title="Abstract">arXiv:2308.01095</a> (replaced) [<a href="/pdf/2308.01095" title="Download PDF">pdf</a>, <a href="/format/2308.01095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoPoster: A Highly Automatic and Content-aware Design System for  Advertising Poster Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinpeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Min Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Ye Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yifan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+C">Chenxi Fei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yangjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02237" title="Abstract">arXiv:2308.02237</a> (replaced) [<a href="/pdf/2308.02237" title="Download PDF">pdf</a>, <a href="/format/2308.02237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSECNet: Accurate and Robust Normal Estimation for 3D Point Clouds by  Multi-Scale Edge Conditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiu%2C+H">Haoyi Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyoung-Sook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Matsuoka%2C+M">Masashi Matsuoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02989" title="Abstract">arXiv:2308.02989</a> (replaced) [<a href="/pdf/2308.02989" title="Download PDF">pdf</a>, <a href="/format/2308.02989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Class Discovery for Long-tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuyu%2C+Z">Zhang Chuyu</a>, 
<a href="/search/cs?searchtype=author&query=Ruijie%2C+X">Xu Ruijie</a>, 
<a href="/search/cs?searchtype=author&query=Xuming%2C+H">He Xuming</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR2023, Final version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05876" title="Abstract">arXiv:2308.05876</a> (replaced) [<a href="/pdf/2308.05876" title="Download PDF">pdf</a>, <a href="/format/2308.05876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Decision-Making in Multi-Agent Domains: A Weighted Potential  Dynamic Game Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+M">Maulik Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Mehr%2C+N">Negar Mehr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06266" title="Abstract">arXiv:2308.06266</a> (replaced) [<a href="/pdf/2308.06266" title="Download PDF">pdf</a>, <a href="/format/2308.06266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $n$ Walks in the Fictional Woods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schetinger%2C+V">Victor Schetinger</a>, 
<a href="/search/cs?searchtype=author&query=Di+Bartolomeo%2C+S">Sara Di Bartolomeo</a>, 
<a href="/search/cs?searchtype=author&query=de+Lima%2C+E+S">Edirlei Soares de Lima</a>, 
<a href="/search/cs?searchtype=author&query=Meinecke%2C+C">Christofer Meinecke</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+R">Rudolf Rosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> this is a submission for IEEE alt.vis 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06644" title="Abstract">arXiv:2308.06644</a> (replaced) [<a href="/pdf/2308.06644" title="Download PDF">pdf</a>, <a href="/format/2308.06644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Diffusion-based Combinatorial Optimization Solvers by  Progressive Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICML 2023, Sampling and Optimization in Discrete Space Workshop. The implementation is at <a href="https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07056" title="Abstract">arXiv:2308.07056</a> (replaced) [<a href="/pdf/2308.07056" title="Download PDF">pdf</a>, <a href="/format/2308.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxBlink: X-Large Speaker Verification Dataset on Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuke Lin</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoyi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guoqing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07057" title="Abstract">arXiv:2308.07057</a> (replaced) [<a href="/pdf/2308.07057" title="Download PDF">pdf</a>, <a href="/format/2308.07057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Hackers&#x27; Work: An Empirical Study of Offensive Security  Practitioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Happe%2C+A">Andreas Happe</a>, 
<a href="/search/cs?searchtype=author&query=Cito%2C+J">J&#xfc;rgen Cito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07221" title="Abstract">arXiv:2308.07221</a> (replaced) [<a href="/pdf/2308.07221" title="Download PDF">pdf</a>, <a href="/format/2308.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudioFormer: Audio Transformer learns audio feature representations from  discrete acoustic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinghua Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07229" title="Abstract">arXiv:2308.07229</a> (replaced) [<a href="/pdf/2308.07229" title="Download PDF">pdf</a>, <a href="/format/2308.07229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional nonlinear audio signal processing with Volterra series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Araujo-Simon%2C+J">Jake Araujo-Simon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version differs from the previous one in that an assertion which was made there - namely, that the Volterra series is a functor - but for which no proof was provided, is here reframed as a conjecture
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07758" title="Abstract">arXiv:2308.07758</a> (replaced) [<a href="/pdf/2308.07758" title="Download PDF">pdf</a>, <a href="/format/2308.07758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward-Backward Reasoning in Large Language Models for Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weisen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Han Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Longhui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J+T">James T. Kwok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08133" title="Abstract">arXiv:2308.08133</a> (replaced) [<a href="/pdf/2308.08133" title="Download PDF">pdf</a>, <a href="/ps/2308.08133" title="Download PostScript">ps</a>, <a href="/format/2308.08133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating the probe and singular sources methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ikehata%2C+M">Masaru Ikehata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, corrected several typos on pages 7, 11, 32; revised Remark 1.2 and Remark 3.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08210" title="Abstract">arXiv:2308.08210</a> (replaced) [<a href="/pdf/2308.08210" title="Download PDF">pdf</a>, <a href="/format/2308.08210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spherical Harmonics for structurally coherent continuous  representation of diffusion MRI signal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hendriks%2C+T">Tom Hendriks</a>, 
<a href="/search/eess?searchtype=author&query=Vilanova%2C+A">Anna Vilanova</a>, 
<a href="/search/eess?searchtype=author&query=Chamberland%2C+M">Maxime Chamberland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, accepted for cdMRI workshop at MICCAI 2023 Updated to fix typo in author name (Villanova -&amp;gt; Vilanova)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08239" title="Abstract">arXiv:2308.08239</a> (replaced) [<a href="/pdf/2308.08239" title="Download PDF">pdf</a>, <a href="/format/2308.08239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain  Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junru Lu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Siyu An</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pergola%2C+G">Gabriele Pergola</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunsheng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08345" title="Abstract">arXiv:2308.08345</a> (replaced) [<a href="/pdf/2308.08345" title="Download PDF">pdf</a>, <a href="/format/2308.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+R">Ruiqiang Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+Z">Zhuoyue Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2004.03696">arXiv:2004.03696</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09239" title="Abstract">arXiv:2308.09239</a> (replaced) [<a href="/pdf/2308.09239" title="Download PDF">pdf</a>, <a href="/format/2308.09239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHAPFUZZ: Efficient Fuzzing via Shapley-Guided Byte Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaogang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xiao Xi</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+S">Sheng Wen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Network and Distributed System Security (NDSS) Symposium 2024, 26
  February - 1 March 2024, San Diego, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09662" title="Abstract">arXiv:2308.09662</a> (replaced) [<a href="/pdf/2308.09662" title="Download PDF">pdf</a>, <a href="/format/2308.09662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Red-Teaming Large Language Models using Chain of Utterances for  Safety-Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+R">Rishabh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09839" title="Abstract">arXiv:2308.09839</a> (replaced) [<a href="/pdf/2308.09839" title="Download PDF">pdf</a>, <a href="/format/2308.09839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performant low-order matrix-free finite element kernels on GPU  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Settgast%2C+R+R">Randolph R. Settgast</a>, 
<a href="/search/math?searchtype=author&query=Dudouit%2C+Y">Yohann Dudouit</a>, 
<a href="/search/math?searchtype=author&query=Castelletto%2C+N">Nicola Castelletto</a>, 
<a href="/search/math?searchtype=author&query=Tobin%2C+W+R">William R. Tobin</a>, 
<a href="/search/math?searchtype=author&query=Corbett%2C+B+C">Benjamin C. Corbett</a>, 
<a href="/search/math?searchtype=author&query=Klevtsov%2C+S">Sergey Klevtsov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09917" title="Abstract">arXiv:2308.09917</a> (replaced) [<a href="/pdf/2308.09917" title="Download PDF">pdf</a>, <a href="/format/2308.09917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09991" title="Abstract">arXiv:2308.09991</a> (replaced) [<a href="/pdf/2308.09991" title="Download PDF">pdf</a>, <a href="/format/2308.09991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AltDiffusion: A Multilingual Text-to-Image Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fulong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinya Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Ledell Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10261" title="Abstract">arXiv:2308.10261</a> (replaced) [<a href="/pdf/2308.10261" title="Download PDF">pdf</a>, <a href="/format/2308.10261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good Are Large Language Models at Out-of-Distribution Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+L">Liming Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zexin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yujie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10276" title="Abstract">arXiv:2308.10276</a> (replaced) [<a href="/pdf/2308.10276" title="Download PDF">pdf</a>, <a href="/format/2308.10276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimalist Traffic Prediction: Linear Layer Is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+W">Wenying Duan</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+H">Hong Rao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxi He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10380" title="Abstract">arXiv:2308.10380</a> (replaced) [<a href="/pdf/2308.10380" title="Download PDF">pdf</a>, <a href="/format/2308.10380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-on-the-Loop Optimization Autoformalism Approach for  Sustainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Sel%2C+B">Bilgehan Sel</a>, 
<a href="/search/cs?searchtype=author&query=Hardeep%2C+F">Fnu Hardeep</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wotao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10522" title="Abstract">arXiv:2308.10522</a> (replaced) [<a href="/pdf/2308.10522" title="Download PDF">pdf</a>, <a href="/format/2308.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Theory-Guided Heuristic Progressive Multi-View Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by the jourcal of Neural Networks (Elsevier) by 2023. arXiv admin note: substantial text overlap with <a href="/abs/2109.02344">arXiv:2109.02344</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10592" title="Abstract">arXiv:2308.10592</a> (replaced) [<a href="/pdf/2308.10592" title="Download PDF">pdf</a>, <a href="/format/2308.10592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content  from Wykop.pl web service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okulska%2C+I">Inez Okulska</a>, 
<a href="/search/cs?searchtype=author&query=G%C5%82%C4%85bi%C5%84ska%2C+K">Kinga G&#x142;&#x105;bi&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Ko%C5%82os%2C+A">Anna Ko&#x142;os</a>, 
<a href="/search/cs?searchtype=author&query=Karli%C5%84ska%2C+A">Agnieszka Karli&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Wi%C5%9Bnios%2C+E">Emilia Wi&#x15b;nios</a>, 
<a href="/search/cs?searchtype=author&query=Nowakowski%2C+A">Adam Nowakowski</a>, 
<a href="/search/cs?searchtype=author&query=Ellerik%2C+P">Pawe&#x142; Ellerik</a>, 
<a href="/search/cs?searchtype=author&query=Pra%C5%82at%2C+A">Andrzej Pra&#x142;at</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10600" title="Abstract">arXiv:2308.10600</a> (replaced) [<a href="/pdf/2308.10600" title="Download PDF">pdf</a>, <a href="/format/2308.10600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+C">Cornelius Brand</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6der%2C+S">Sebastian R&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Schager%2C+F">Florian Schager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10632" title="Abstract">arXiv:2308.10632</a> (replaced) [<a href="/pdf/2308.10632" title="Download PDF">pdf</a>, <a href="/format/2308.10632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model-oriented Robustness: Robust Image Model Evaluation with  Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaozhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10651" title="Abstract">arXiv:2308.10651</a> (replaced) [<a href="/pdf/2308.10651" title="Download PDF">pdf</a>, <a href="/format/2308.10651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research Challenges in Orchestration Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basile%2C+D">Davide Basile</a> (Formal Methods and Tools lab, ISTI-CNR, Pisa, Italy), 
<a href="/search/cs?searchtype=author&query=ter+Beek%2C+M+H">Maurice H. ter Beek</a> (Formal Methods and Tools lab, ISTI-CNR, Pisa, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 73-90
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10718" title="Abstract">arXiv:2308.10718</a> (replaced) [<a href="/pdf/2308.10718" title="Download PDF">pdf</a>, <a href="/format/2308.10718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdooring Textual Inversion for Concept Censorship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11217" title="Abstract">arXiv:2308.11217</a> (replaced) [<a href="/pdf/2308.11217" title="Download PDF">pdf</a>, <a href="/format/2308.11217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning in Big Model Era: Domain-Specific Multimodal Large  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zengxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhaoxiang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Longfei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zelei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11234" title="Abstract">arXiv:2308.11234</a> (replaced) [<a href="/pdf/2308.11234" title="Download PDF">pdf</a>, <a href="/format/2308.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Harabor%2C+D">Daniel Harabor</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Stuckey%2C+P+J">Peter J. Stuckey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11236" title="Abstract">arXiv:2308.11236</a> (replaced) [<a href="/pdf/2308.11236" title="Download PDF">pdf</a>, <a href="/format/2308.11236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROSGPT_Vision: Commanding Robots Using Only Language Models&#x27; Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benjdira%2C+B">Bilel Benjdira</a>, 
<a href="/search/cs?searchtype=author&query=Koubaa%2C+A">Anis Koubaa</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+M">Anas M. Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11289" title="Abstract">arXiv:2308.11289</a> (replaced) [<a href="/pdf/2308.11289" title="Download PDF">pdf</a>, <a href="/format/2308.11289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-User Modular XL-MIMO Communications: Near-Field Beam Focusing  Pattern and User Grouping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenjun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11298" title="Abstract">arXiv:2308.11298</a> (replaced) [<a href="/pdf/2308.11298" title="Download PDF">pdf</a>, <a href="/format/2308.11298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BHSD: A 3D Multi-Class Brain Hemorrhage Segmentation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jinchao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yaxley%2C+K">Kaspar Yaxley</a>, 
<a href="/search/cs?searchtype=author&query=Bahadir%2C+S">Suzan Bahadir</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=To%2C+M">Minh-Son To</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MLMI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11406" title="Abstract">arXiv:2308.11406</a> (replaced) [<a href="/pdf/2308.11406" title="Download PDF">pdf</a>, <a href="/format/2308.11406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing an attack-defense game: how to increase robustness of  financial transaction models via a competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>, 
<a href="/search/cs?searchtype=author&query=Natekin%2C+A">Alex Natekin</a>, 
<a href="/search/cs?searchtype=author&query=Vorsin%2C+E">Evgeni Vorsin</a>, 
<a href="/search/cs?searchtype=author&query=Smirnov%2C+V">Valerii Smirnov</a>, 
<a href="/search/cs?searchtype=author&query=Smirnov%2C+G">Georgii Smirnov</a>, 
<a href="/search/cs?searchtype=author&query=Sidorshin%2C+O">Oleg Sidorshin</a>, 
<a href="/search/cs?searchtype=author&query=Senin%2C+A">Alexander Senin</a>, 
<a href="/search/cs?searchtype=author&query=Dudin%2C+A">Alexander Dudin</a>, 
<a href="/search/cs?searchtype=author&query=Berestnev%2C+D">Dmitry Berestnev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Statistical Finance (q-fin.ST)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11466" title="Abstract">arXiv:2308.11466</a> (replaced) [<a href="/pdf/2308.11466" title="Download PDF">pdf</a>, <a href="/format/2308.11466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SONAR: Sentence-Level Multimodal and Language-Agnostic Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duquenne%2C+P">Paul-Ambroise Duquenne</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+H">Holger Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Sagot%2C+B">Beno&#xee;t Sagot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11489" title="Abstract">arXiv:2308.11489</a> (replaced) [<a href="/pdf/2308.11489" title="Download PDF">pdf</a>, <a href="/format/2308.11489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Semantic Alignment between Unpaired Multiviews for  Egocentric Video Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangzhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of IEEE International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11534" title="Abstract">arXiv:2308.11534</a> (replaced) [<a href="/pdf/2308.11534" title="Download PDF">pdf</a>, <a href="/format/2308.11534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model as a User Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Chuyi Kong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yaxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11561" title="Abstract">arXiv:2308.11561</a> (replaced) [<a href="/pdf/2308.11561" title="Download PDF">pdf</a>, <a href="/format/2308.11561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Grounded Graph-Aware Transformer for Aerial Vision-and-Dialog  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yifei Su</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+D">Dong An</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kehan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11601" title="Abstract">arXiv:2308.11601</a> (replaced) [<a href="/pdf/2308.11601" title="Download PDF">pdf</a>, <a href="/format/2308.11601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tryage: Real-time, intelligent Routing of User Prompts to Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+N">Surya Narayanan Hari</a>, 
<a href="/search/cs?searchtype=author&query=Thomson%2C+M">Matt Thomson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item285">Cross-lists</a></li>
<li><a href="#item340">Replacements</a></li>
</ul>
<small>[ total of 505 entries:  <b>1-505</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2308">2308</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
