<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 15 Aug 23  to  Wed 16 Aug 23, announced Thu, 17 Aug 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item249">Cross-lists</a></li>
<li><a href="#item304">Replacements</a></li>
</ul>
<small>[ total of 481 entries:  <b>1-481</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 17 Aug 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07927" title="Abstract">arXiv:2308.07927</a> [<a href="/pdf/2308.07927" title="Download PDF">pdf</a>, <a href="/ps/2308.07927" title="Download PostScript">ps</a>, <a href="/format/2308.07927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Modeling of Menstrual Cycle Length: A Time Series Forecasting  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rego%2C+R+C+B">Rosana C. B. Rego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A proper forecast of the menstrual cycle is meaningful for women's health, as
it allows individuals to take preventive actions to minimize cycle-associated
discomforts. In addition, precise prediction can be useful for planning
important events in a woman's life, such as family planning. In this work, we
explored the use of machine learning techniques to predict regular and
irregular menstrual cycles. We implemented some time series forecasting
algorithm approaches, such as AutoRegressive Integrated Moving Average, Huber
Regression, Lasso Regression, Orthogonal Matching Pursuit, and Long Short-Term
Memory Network. Moreover, we generated synthetic data to achieve our purposes.
The results showed that it is possible to accurately predict the onset and
duration of menstrual cycles using machine learning techniques.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07928" title="Abstract">arXiv:2308.07928</a> [<a href="/pdf/2308.07928" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the generalized vectorization and its inverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Curtarelli%2C+V">Vitor Curtarelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Although the vectorization operation is known and well defined, it is only
defined for 2-D matrices, and its inverse isn't as well popularized. This work
proposes to generalize the vectorization to higher dimensions, and define
mathematically its inverse operation.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07929" title="Abstract">arXiv:2308.07929</a> [<a href="/pdf/2308.07929" title="Download PDF">pdf</a>, <a href="/format/2308.07929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image  Classification and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallego%2C+V">Victor Gallego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to EYSM23 proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, large multimodal models, such as CLIP and Stable Diffusion have
experimented tremendous successes in both foundations and applications.
However, as these models increase in parameter size and computational
requirements, it becomes more challenging for users to personalize them for
specific tasks or preferences. In this work, we address the problem of adapting
the previous models towards sets of particular human preferences, aligning the
retrieved or generated images with the preferences of the user. We leverage the
Bradley-Terry preference model to develop a fast adaptation method that
efficiently fine-tunes the original model, with few examples and with minimal
computing resources. Extensive evidence of the capabilities of this framework
is provided through experiments in different domains related to multimodal text
and image understanding, including preference prediction as a reward model, and
generation tasks.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07930" title="Abstract">arXiv:2308.07930</a> [<a href="/pdf/2308.07930" title="Download PDF">pdf</a>, <a href="/format/2308.07930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Black-Box Checking via Active MDP Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shijubo%2C+J">Junya Shijubo</a>, 
<a href="/search/cs?searchtype=author&query=Waga%2C+M">Masaki Waga</a>, 
<a href="/search/cs?searchtype=author&query=Suenaga%2C+K">Kohei Suenaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMSOFT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Formal Languages and Automata Theory (cs.FL); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We introduce a novel methodology for testing stochastic black-box systems,
frequently encountered in embedded systems. Our approach enhances the
established black-box checking (BBC) technique to address stochastic behavior.
Traditional BBC primarily involves iteratively identifying an input that
breaches the system's specifications by executing the following three phases:
the learning phase to construct an automaton approximating the black box's
behavior, the synthesis phase to identify a candidate counterexample from the
learned automaton, and the validation phase to validate the obtained candidate
counterexample and the learned automaton against the original black-box system.
Our method, ProbBBC, refines the conventional BBC approach by (1) employing an
active Markov Decision Process (MDP) learning method during the learning phase,
(2) incorporating probabilistic model checking in the synthesis phase, and (3)
applying statistical hypothesis testing in the validation phase. ProbBBC
uniquely integrates these techniques rather than merely substituting each
method in the traditional BBC; for instance, the statistical hypothesis testing
and the MDP learning procedure exchange information regarding the black-box
system's observation with one another. The experiment results suggest that
ProbBBC outperforms an existing method, especially for systems with limited
observation.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07931" title="Abstract">arXiv:2308.07931</a> [<a href="/pdf/2308.07931" title="Download PDF">pdf</a>, <a href="/format/2308.07931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">William Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Ge Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Alan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+J">Jansen Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website at <a href="https://f3rm.csail.mit.edu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Self-supervised and language-supervised image models contain rich knowledge
of the world that is important for generalization. Many robotic tasks, however,
require a detailed understanding of 3D geometry, which is often lacking in 2D
image features. This work bridges this 2D-to-3D gap for robotic manipulation by
leveraging distilled feature fields to combine accurate 3D geometry with rich
semantics from 2D foundation models. We present a few-shot learning method for
6-DOF grasping and placing that harnesses these strong spatial and semantic
priors to achieve in-the-wild generalization to unseen objects. Using features
distilled from a vision-language model, CLIP, we present a way to designate
novel objects for manipulation via free-text natural language, and demonstrate
its ability to generalize to unseen expressions and novel categories of
objects.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07932" title="Abstract">arXiv:2308.07932</a> [<a href="/pdf/2308.07932" title="Download PDF">pdf</a>, <a href="/format/2308.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced Butterfly Counting in Bipartite-Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Apurba Das</a>, 
<a href="/search/cs?searchtype=author&query=Abidi%2C+A">Aman Abidi</a>, 
<a href="/search/cs?searchtype=author&query=Shingane%2C+A">Ajinkya Shingane</a>, 
<a href="/search/cs?searchtype=author&query=Kiran%2C+M">Mekala Kiran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Bipartite graphs offer a powerful framework for modeling complex
relationships between two distinct types of vertices, incorporating
probabilistic, temporal, and rating-based information. While the research
community has extensively explored various types of bipartite relationships,
there has been a notable gap in studying Signed Bipartite Graphs, which capture
liking / disliking interactions in real-world networks such as
customer-rating-product and senator-vote-bill. Balance butterflies,
representing 2 x 2 bicliques, provide crucial insights into antagonistic
groups, balance theory, and fraud detection by leveraging the signed
information. However, such applications require counting balance butterflies
which remains unexplored. In this paper, we propose a new problem: counting
balance butterflies in a signed bipartite graph. To address this problem, we
adopt state-of-the-art algorithms for butterfly counting, establishing a smart
baseline that reduces the time complexity for solving our specific problem. We
further introduce a novel bucket approach specifically designed to count
balanced butterflies efficiently. We propose a parallelized version of the
bucketing approach to enhance performance. Extensive experimental studies on
nine real-world datasets demonstrate that our proposed bucket-based algorithm
is up to 120x faster over the baseline, and the parallel implementation of the
bucket-based algorithm is up to 45x faster over the single core execution.
Moreover, a real-world case study showcases the practical application and
relevance of counting balanced butterflies.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07933" title="Abstract">arXiv:2308.07933</a> [<a href="/pdf/2308.07933" title="Download PDF">pdf</a>, <a href="/format/2308.07933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Picture Description Speech for Dementia Detection using  Image-text Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Youxiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Nana Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaohui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Batsis%2C+J+A">John A. Batsis</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+R+M">Robert M. Roth</a>, 
<a href="/search/cs?searchtype=author&query=MacWhinney%2C+B">Brian MacWhinney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Using picture description speech for dementia detection has been studied for
30 years. Despite the long history, previous models focus on identifying the
differences in speech patterns between healthy subjects and patients with
dementia but do not utilize the picture information directly. In this paper, we
propose the first dementia detection models that take both the picture and the
description texts as inputs and incorporate knowledge from large pre-trained
image-text alignment models. We observe the difference between dementia and
healthy samples in terms of the text's relevance to the picture and the focused
area of the picture. We thus consider such a difference could be used to
enhance dementia detection accuracy. Specifically, we use the text's relevance
to the picture to rank and filter the sentences of the samples. We also
identified focused areas of the picture as topics and categorized the sentences
according to the focused areas. We propose three advanced models that
pre-processed the samples based on their relevance to the picture, sub-image,
and focused areas. The evaluation results show that our advanced models, with
knowledge of the picture and large image-text alignment models, achieve
state-of-the-art performance with the best detection accuracy at 83.44%, which
is higher than the text-only baseline model at 79.91%. Lastly, we visualize the
sample and picture results to explain the advantages of our models.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07934" title="Abstract">arXiv:2308.07934</a> [<a href="/pdf/2308.07934" title="Download PDF">pdf</a>, <a href="/format/2308.07934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianshuo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zeqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted by the ICCV 2023. 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) are widely deployed on real-world devices.
Concerns regarding their security have gained great attention from researchers.
Recently, a new weight modification attack called bit flip attack (BFA) was
proposed, which exploits memory fault inject techniques such as row hammer to
attack quantized models in the deployment stage. With only a few bit flips, the
target model can be rendered useless as a random guesser or even be implanted
with malicious functionalities. In this work, we seek to further reduce the
number of bit flips. We propose a training-assisted bit flip attack, in which
the adversary is involved in the training stage to build a high-risk model to
release. This high-risk model, obtained coupled with a corresponding malicious
model, behaves normally and can escape various detection methods. The results
on benchmark datasets show that an adversary can easily convert this high-risk
but normal model to a malicious one on victim's side by \textbf{flipping only
one critical bit} on average in the deployment stage. Moreover, our attack
still poses a significant threat even when defenses are employed. The codes for
reproducing main experiments are available at
\url{https://github.com/jianshuod/TBA}.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07935" title="Abstract">arXiv:2308.07935</a> [<a href="/pdf/2308.07935" title="Download PDF">pdf</a>, <a href="/format/2308.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming Sentiment Analysis in the Financial Domain with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatouros%2C+G">Georgios Fatouros</a>, 
<a href="/search/cs?searchtype=author&query=Soldatos%2C+J">John Soldatos</a>, 
<a href="/search/cs?searchtype=author&query=Kouroumali%2C+K">Kalliopi Kouroumali</a>, 
<a href="/search/cs?searchtype=author&query=Makridis%2C+G">Georgios Makridis</a>, 
<a href="/search/cs?searchtype=author&query=Kyriazis%2C+D">Dimosthenis Kyriazis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, Preprint submitted to Machine Learning with Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Financial sentiment analysis plays a crucial role in decoding market trends
and guiding strategic trading decisions. Despite the deployment of advanced
deep learning techniques and language models to refine sentiment analysis in
finance, this study breaks new ground by investigating the potential of large
language models, particularly ChatGPT 3.5, in financial sentiment analysis,
with a strong emphasis on the foreign exchange market (forex). Employing a
zero-shot prompting approach, we examine multiple ChatGPT prompts on a
meticulously curated dataset of forex-related news headlines, measuring
performance using metrics such as precision, recall, f1-score, and Mean
Absolute Error (MAE) of the sentiment class. Additionally, we probe the
correlation between predicted sentiment and market returns as an additional
evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment
analysis model for financial texts, exhibited approximately 35\% enhanced
performance in sentiment classification and a 36\% higher correlation with
market returns. By underlining the significance of prompt engineering,
particularly in zero-shot contexts, this study spotlights ChatGPT's potential
to substantially boost sentiment analysis in financial applications. By sharing
the utilized dataset, our intention is to stimulate further research and
advancements in the field of financial services.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07937" title="Abstract">arXiv:2308.07937</a> [<a href="/pdf/2308.07937" title="Download PDF">pdf</a>, <a href="/format/2308.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Testing and Improvement of Named Entity Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Boxi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yiyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mang%2C+Q">Qiuyang Mang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenhan Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ESEC/FSE'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Named entity recognition (NER) systems have seen rapid progress in recent
years due to the development of deep neural networks. These systems are widely
used in various natural language processing applications, such as information
extraction, question answering, and sentiment analysis. However, the complexity
and intractability of deep neural networks can make NER systems unreliable in
certain circumstances, resulting in incorrect predictions. For example, NER
systems may misidentify female names as chemicals or fail to recognize the
names of minority groups, leading to user dissatisfaction. To tackle this
problem, we introduce TIN, a novel, widely applicable approach for
automatically testing and repairing various NER systems. The key idea for
automated testing is that the NER predictions of the same named entities under
similar contexts should be identical. The core idea for automated repairing is
that similar named entities should have the same NER prediction under the same
context. We use TIN to test two SOTA NER models and two commercial NER APIs,
i.e., Azure NER and AWS NER. We manually verify 784 of the suspicious issues
reported by TIN and find that 702 are erroneous issues, leading to high
precision (85.0%-93.4%) across four categories of NER errors: omission,
over-labeling, incorrect category, and range error. For automated repairing,
TIN achieves a high error reduction rate (26.8%-50.6%) over the four systems
under test, which successfully repairs 1,056 out of the 1,877 reported NER
errors.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07938" title="Abstract">arXiv:2308.07938</a> [<a href="/pdf/2308.07938" title="Download PDF">pdf</a>, <a href="/format/2308.07938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Aided Design and Grading for an Electronic Functional  Programming Exam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BCbke%2C+O">Ole L&#xfc;bke</a> (TUHH), 
<a href="/search/cs?searchtype=author&query=Fuger%2C+K">Konrad Fuger</a> (TUHH), 
<a href="/search/cs?searchtype=author&query=Bahnsen%2C+F+H">Fin Hendrik Bahnsen</a> (UK-Essen), 
<a href="/search/cs?searchtype=author&query=Billerbeck%2C+K">Katrin Billerbeck</a> (TUHH), 
<a href="/search/cs?searchtype=author&query=Schupp%2C+S">Sibylle Schupp</a> (TUHH)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings TFPIE 2023, <a href="/abs/2308.06110">arXiv:2308.06110</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 382, 2023, pp. 22-44
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Electronic exams (e-exams) have the potential to substantially reduce the
effort required for conducting an exam through automation. Yet, care must be
taken to sacrifice neither task complexity nor constructive alignment nor
grading fairness in favor of automation. To advance automation in the design
and fair grading of (functional programming) e-exams, we introduce the
following: A novel algorithm to check Proof Puzzles based on finding correct
sequences of proof lines that improves fairness compared to an existing, edit
distance based algorithm; an open-source static analysis tool to check source
code for task relevant features by traversing the abstract syntax tree; a
higher-level language and open-source tool to specify regular expressions that
makes creating complex regular expressions less error-prone. Our findings are
embedded in a complete experience report on transforming a paper exam to an
e-exam. We evaluated the resulting e-exam by analyzing the degree of automation
in the grading process, asking students for their opinion, and critically
reviewing our own experiences. Almost all tasks can be graded automatically at
least in part (correct solutions can almost always be detected as such), the
students agree that an e-exam is a fitting examination format for the course
but are split on how well they can express their thoughts compared to a paper
exam, and examiners enjoy a more time-efficient grading process while the point
distribution in the exam results was almost exactly the same compared to a
paper exam.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07939" title="Abstract">arXiv:2308.07939</a> [<a href="/pdf/2308.07939" title="Download PDF">pdf</a>, <a href="/format/2308.07939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ada-QPacknet -- adaptive pruning with bit width reduction as an  efficient continual learning method without forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pietro%C5%84%2C+M">Marcin Pietro&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BBurek%2C+D">Dominik &#x17b;urek</a>, 
<a href="/search/cs?searchtype=author&query=Faber%2C+K">Kamil Faber</a>, 
<a href="/search/cs?searchtype=author&query=Corizzo%2C+R">Roberto Corizzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continual Learning (CL) is a process in which there is still huge gap between
human and deep learning model efficiency. Recently, many CL algorithms were
designed. Most of them have many problems with learning in dynamic and complex
environments. In this work new architecture based approach Ada-QPacknet is
described. It incorporates the pruning for extracting the sub-network for each
task. The crucial aspect in architecture based CL methods is theirs capacity.
In presented method the size of the model is reduced by efficient linear and
nonlinear quantisation approach. The method reduces the bit-width of the
weights format. The presented results shows that hybrid 8 and 4-bit
quantisation achieves similar accuracy as floating-point sub-network on a
well-know CL scenarios. To our knowledge it is the first CL strategy which
incorporates both compression techniques pruning and quantisation for
generating task sub-networks. The presented algorithm was tested on well-known
episode combinations and compared with most popular algorithms. Results show
that proposed approach outperforms most of the CL strategies in task and class
incremental scenarios.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07940" title="Abstract">arXiv:2308.07940</a> [<a href="/pdf/2308.07940" title="Download PDF">pdf</a>, <a href="/ps/2308.07940" title="Download PostScript">ps</a>, <a href="/format/2308.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Individual Trajectories Using GPT-2 Trained from Scratch on  Encoded Spatiotemporal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horikomi%2C+T">Taizo Horikomi</a>, 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+S">Shouji Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+A">Atushi Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Mizuno%2C+T">Takayuki Mizuno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Following Mizuno, Fujimoto, and Ishikawa's research (Front. Phys. 2022), we
transpose geographical coordinates expressed in latitude and longitude into
distinctive location tokens that embody positions across varied spatial scales.
We encapsulate an individual daily trajectory as a sequence of tokens by adding
unique time interval tokens to the location tokens. Using the architecture of
an autoregressive language model, GPT-2, this sequence of tokens is trained
from scratch, allowing us to construct a deep learning model that sequentially
generates an individual daily trajectory. Environmental factors such as
meteorological conditions and individual attributes such as gender and age are
symbolized by unique special tokens, and by training these tokens and
trajectories on the GPT-2 architecture, we can generate trajectories that are
influenced by both environmental factors and individual attributes.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07942" title="Abstract">arXiv:2308.07942</a> [<a href="/pdf/2308.07942" title="Download PDF">pdf</a>, <a href="/format/2308.07942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anil%2C+A">Akash Anil</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez-Basulto%2C+V">V&#xed;ctor Guti&#xe9;rrez-Basulto</a>, 
<a href="/search/cs?searchtype=author&query=Iba%C3%B1%C3%A9z-Garc%C3%ADa%2C+Y">Yazm&#xed;n Iba&#xf1;&#xe9;z-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The task of inductive knowledge graph completion requires models to learn
inference patterns from a training graph, which can then be used to make
predictions on a disjoint test graph. Rule-based methods seem like a natural
fit for this task, but in practice they significantly underperform
state-of-the-art methods based on Graph Neural Networks (GNNs), such as NBFNet.
We hypothesise that the underperformance of rule-based methods is due to two
factors: (i) implausible entities are not ranked at all and (ii) only the most
informative path is taken into account when determining the confidence in a
given link prediction answer. To analyse the impact of these factors, we study
a number of variants of a rule-based approach, which are specifically aimed at
addressing the aforementioned issues. We find that the resulting models can
achieve a performance which is close to that of NBFNet. Crucially, the
considered variants only use a small fraction of the evidence that NBFNet
relies on, which means that they largely keep the interpretability advantage of
rule-based methods. Moreover, we show that a further variant, which does look
at the full KG, consistently outperforms NBFNet.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07948" title="Abstract">arXiv:2308.07948</a> [<a href="/pdf/2308.07948" title="Download PDF">pdf</a>, <a href="/format/2308.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Symmetries in Pick and Place
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tangri%2C+A">Arsh Tangri</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Platt%2C+R">Robert Platt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2202.09400">arXiv:2202.09400</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robotic pick and place tasks are symmetric under translations and rotations
of both the object to be picked and the desired place pose. For example, if the
pick object is rotated or translated, then the optimal pick action should also
rotate or translate. The same is true for the place pose; if the desired place
pose changes, then the place action should also transform accordingly. A
recently proposed pick and place framework known as Transporter Net captures
some of these symmetries, but not all. This paper analytically studies the
symmetries present in planar robotic pick and place and proposes a method of
incorporating equivariant neural models into Transporter Net in a way that
captures all symmetries. The new model, which we call Equivariant Transporter
Net, is equivariant to both pick and place symmetries and can immediately
generalize pick and place knowledge to different pick and place poses. We
evaluate the new model empirically and show that it is much more sample
efficient than the non-symmetric version, resulting in a system that can
imitate demonstrated pick and place behavior using very few human
demonstrations on a variety of imitation learning tasks.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07949" title="Abstract">arXiv:2308.07949</a> [<a href="/pdf/2308.07949" title="Download PDF">pdf</a>, <a href="/format/2308.07949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzing for CPS Mutation Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaekwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Vigan%C3%B2%2C+E">Enrico Vigan&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Cornejo%2C+O">Oscar Cornejo</a>, 
<a href="/search/cs?searchtype=author&query=Pastore%2C+F">Fabrizio Pastore</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is the camera-ready version for ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mutation testing can help reduce the risks of releasing faulty software. For
such reason, it is a desired practice for the development of embedded software
running in safety-critical cyber-physical systems (CPS). Unfortunately,
state-of-the-art test data generation techniques for mutation testing of C and
C++ software, two typical languages for CPS software, rely on symbolic
execution, whose limitations often prevent its application (e.g., it cannot
test black-box components).
<br />We propose a mutation testing approach that leverages fuzz testing, which has
proved effective with C and C++ software. Fuzz testing automatically generates
diverse test inputs that exercise program branches in a varied number of ways
and, therefore, exercise statements in different program states, thus
maximizing the likelihood of killing mutants, our objective.
<br />We performed an empirical assessment of our approach with software components
used in satellite systems currently in orbit. Our empirical evaluation shows
that mutation testing based on fuzz testing kills a significantly higher
proportion of live mutants than symbolic execution (i.e., up to an additional
47 percentage points). Further, when symbolic execution cannot be applied, fuzz
testing provides significant benefits (i.e., up to 41% mutants killed). Our
study is the first one comparing fuzz testing and symbolic execution for
mutation testing; our results provide guidance towards the development of fuzz
testing tools dedicated to mutation testing.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07966" title="Abstract">arXiv:2308.07966</a> [<a href="/pdf/2308.07966" title="Download PDF">pdf</a>, <a href="/format/2308.07966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding DNS Query Composition at B-Root
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ginesin%2C+J">Jacob Ginesin</a>, 
<a href="/search/cs?searchtype=author&query=Mirkovic%2C+J">Jelena Mirkovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages with 18 figures and 1 table. Published and presented at the 2022 IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Domain Name System (DNS) is part of critical internet infrastructure, as
DNS is invoked whenever a remote server is accessed (an URL is visited, an API
request is made, etc.) by any application. DNS queries are served in
hierarchical manner, with most queries served locally from cached data, and a
small fraction propagating to the top of the hierarchy - DNS root name servers.
Our research aims to provide a comprehensive, longitudinal characterization of
DNS queries received at B-Root over ten years. We sampled and analyzed a
28-billion-query large dataset from the ten annual Day in the Life of the
Internet (DITL) experiments from 2013 through 2022. We sought to identify and
quantify unexpected DNS queries, establish longitudinal trends, and compare our
findings with published results of others. We found that unexpected query
traffic increased from 39.57% in 2013 to 67.91% in 2022, with 36.55% of queries
being priming queries. We also observed growth and decline of
Chromium-initiated, random DNS queries. Finally, we analyzed the largest DNS
query senders and established that most of their traffic consists of unexpected
queries.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07967" title="Abstract">arXiv:2308.07967</a> [<a href="/pdf/2308.07967" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Cross-Quality Face Verification using Blind Face Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bengherabi%2C+M">Messaoud Bengherabi</a>, 
<a href="/search/cs?searchtype=author&query=Laib%2C+D">Douaa Laib</a>, 
<a href="/search/cs?searchtype=author&query=Lasnami%2C+F+S">Fella Souhila Lasnami</a>, 
<a href="/search/cs?searchtype=author&query=Boussaha%2C+R">Ryma Boussaha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper accepted at BIOSIG 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, various Blind Face Restoration (BFR) techniques were
developed. These techniques transform low quality faces suffering from multiple
degradations to more realistic and natural face images with high perceptual
quality. However, it is crucial for the task of face verification to not only
enhance the perceptual quality of the low quality images but also to improve
the biometric-utility face quality metrics. Furthermore, preserving the
valuable identity information is of great importance. In this paper, we
investigate the impact of applying three state-of-the-art blind face
restoration techniques namely, GFP-GAN, GPEN and SGPN on the performance of
face verification system under very challenging environment characterized by
very low quality images. Extensive experimental results on the recently
proposed cross-quality LFW database using three state-of-the-art deep face
recognition models demonstrate the effectiveness of GFP-GAN in boosting
significantly the face verification accuracy.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07968" title="Abstract">arXiv:2308.07968</a> [<a href="/pdf/2308.07968" title="Download PDF">pdf</a>, <a href="/format/2308.07968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teach LLMs to Personalize -- An Approach inspired by Writing Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hombaiah%2C+S+A">Spurthi Amba Hombaiah</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Personalized text generation is an emerging research area that has attracted
much attention in recent years. Most studies in this direction focus on a
particular domain by designing bespoke features or models. In this work, we
propose a general approach for personalized text generation using large
language models (LLMs). Inspired by the practice of writing education, we
develop a multistage and multitask framework to teach LLMs for personalized
generation. In writing instruction, the task of writing from sources is often
decomposed into multiple steps that involve finding, evaluating, summarizing,
synthesizing, and integrating information. Analogously, our approach to
personalized text generation consists of multiple stages: retrieval, ranking,
summarization, synthesis, and generation. In addition, we introduce a multitask
setting that helps the model improve its generation ability further, which is
inspired by the observation in education that a student's reading proficiency
and writing ability are often correlated. We evaluate our approach on three
public datasets, each of which covers a different and representative domain.
Our results show significant improvements over a variety of baselines.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07970" title="Abstract">arXiv:2308.07970</a> [<a href="/pdf/2308.07970" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing a New Evaluation Criteria for EMD-Base Steganography Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rafiee%2C+H">Hanieh Rafiee</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+M">Mojtaba Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=NaghshNilchi%2C+A">AhmadReza NaghshNilchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Steganography is a technique to hide the presence of secret communication.
When one of the communication elements is under the influence of the enemy, it
can be used. The main measure to evaluate steganography methods in a certain
capacity is security. Therefore, in a certain capacity, reducing the amount of
changes in the cover media, creates a higher embedding efficiency and thus more
security of an steganography method. Mostly, security and capacity are in
conflict with each other, the increase of one lead to the decrease of the
other. The presence of a single criterion that represents security and capacity
at the same time be useful in comparing steganography methods. EMD and the
relevant methods are a group of steganography techniques, which optimize the
amount of changes resulting from embedding (security). The present paper is
aimed to provide an evaluation criterion for this group of steganography
methods. In this study, after a general review and comparison of EMD-based
steganography techniques, we present a method to compare them exactly, from the
perspective of embedding efficiency. First, a formula is presented to determine
the value of embedding efficiency, which indicates the effect of one or more
changes on one or more pixels. The results demonstrate that the proposed
embedding efficiency formula shows the performance of the methods better when
several changes are made on a pixel compared to the existing criteria. In the
second step, we have obtained an upper bound, which determines the best
efficiency for each certain capacity. Finally, based on the introduced bound,
another evaluation criterion for a better comparison of the methods is
presented.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07971" title="Abstract">arXiv:2308.07971</a> [<a href="/pdf/2308.07971" title="Download PDF">pdf</a>, <a href="/format/2308.07971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiSChuBERT: Effective Multimodal Fusion for Scholarly Document  Quality Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Buy+Wenniger%2C+G+M">Gideon Maillette de Buy Wenniger</a>, 
<a href="/search/cs?searchtype=author&query=van+Dongen%2C+T">Thomas van Dongen</a>, 
<a href="/search/cs?searchtype=author&query=Schomaker%2C+L">Lambert Schomaker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automatic assessment of the quality of scholarly documents is a difficult
task with high potential impact. Multimodality, in particular the addition of
visual information next to text, has been shown to improve the performance on
scholarly document quality prediction (SDQP) tasks. We propose the multimodal
predictive model MultiSChuBERT. It combines a textual model based on chunking
full paper text and aggregating computed BERT chunk-encodings (SChuBERT), with
a visual model based on Inception V3.Our work contributes to the current
state-of-the-art in SDQP in three ways. First, we show that the method of
combining visual and textual embeddings can substantially influence the
results. Second, we demonstrate that gradual-unfreezing of the weights of the
visual sub-model, reduces its tendency to ovefit the data, improving results.
Third, we show the retained benefit of multimodality when replacing standard
BERT$_{\textrm{BASE}}$ embeddings with more recent state-of-the-art text
embedding models.
<br />Using BERT$_{\textrm{BASE}}$ embeddings, on the (log) number of citations
prediction task with the ACL-BiblioMetry dataset, our MultiSChuBERT
(text+visual) model obtains an $R^{2}$ score of 0.454 compared to 0.432 for the
SChuBERT (text only) model. Similar improvements are obtained on the PeerRead
accept/reject prediction task. In our experiments using SciBERT, scincl,
SPECTER and SPECTER2.0 embeddings, we show that each of these tailored
embeddings adds further improvements over the standard BERT$_{\textrm{BASE}}$
embeddings, with the SPECTER2.0 embeddings performing best.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07972" title="Abstract">arXiv:2308.07972</a> [<a href="/pdf/2308.07972" title="Download PDF">pdf</a>, <a href="/ps/2308.07972" title="Download PostScript">ps</a>, <a href="/format/2308.07972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PKE-RRT: Efficient Multi-Goal Path Finding Algorithm Driven by  Multi-Task Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+C">Cheng-Tien Tsao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+K">Kairui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hee-Hyol Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-goal path finding (MGPF) aims to find a closed and collision-free path
to visit a sequence of goals orderly. As a physical travelling salesman
problem, an undirected complete graph with accurate weights is crucial for
determining the visiting order. Lack of prior knowledge of local paths between
vertices poses challenges in meeting the optimality and efficiency requirements
of algorithms. In this study, a multi-task learning model designated Prior
Knowledge Extraction (PKE), is designed to estimate the local path length
between pairwise vertices as the weights of the graph. Simultaneously, a
promising region and a guideline are predicted as heuristics for the
path-finding process. Utilizing the outputs of the PKE model, a variant of
Rapidly-exploring Random Tree (RRT) is proposed known as PKE-RRT. It
effectively tackles the MGPF problem by a local planner incorporating a
prioritized visiting order, which is obtained from the complete graph.
Furthermore, the predicted region and guideline facilitate efficient
exploration of the tree structure, enabling the algorithm to rapidly provide a
sub-optimal solution. Extensive numerical experiments demonstrate the
outstanding performance of the PKE-RRT for the MGPF problem with a different
number of goals, in terms of calculation time, path cost, sample number, and
success rate.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07973" title="Abstract">arXiv:2308.07973</a> [<a href="/pdf/2308.07973" title="Download PDF">pdf</a>, <a href="/format/2308.07973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Beware of deception&quot;: Detecting Half-Truth and Debunking it through  Controlled Claim Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singamsetty%2C+S">Sandeep Singamsetty</a>, 
<a href="/search/cs?searchtype=author&query=Madaan%2C+N">Nishtha Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sameep Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+V">Varad Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The prevalence of half-truths, which are statements containing some truth but
that are ultimately deceptive, has risen with the increasing use of the
internet. To help combat this problem, we have created a comprehensive pipeline
consisting of a half-truth detection model and a claim editing model. Our
approach utilizes the T5 model for controlled claim editing; "controlled" here
means precise adjustments to select parts of a claim. Our methodology achieves
an average BLEU score of 0.88 (on a scale of 0-1) and a disinfo-debunk score of
85% on edited claims. Significantly, our T5-based approach outperforms other
Language Models such as GPT2, RoBERTa, PEGASUS, and Tailor, with average
improvements of 82%, 57%, 42%, and 23% in disinfo-debunk scores, respectively.
By extending the LIAR PLUS dataset, we achieve an F1 score of 82% for the
half-truth detection model, setting a new benchmark in the field. While
previous attempts have been made at half-truth detection, our approach is, to
the best of our knowledge, the first to attempt to debunk half-truths.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07974" title="Abstract">arXiv:2308.07974</a> [<a href="/pdf/2308.07974" title="Download PDF">pdf</a>, <a href="/format/2308.07974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Network-Driven Method for Optimal Path Planning via High-Accuracy  Region Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+C">Cheng-Tien Tsao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tianyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hee-Hyol Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Sampling-based path planning algorithms suffer from heavy reliance on uniform
sampling, which accounts for unreliable and time-consuming performance,
especially in complex environments. Recently, neural-network-driven methods
predict regions as sampling domains to realize a non-uniform sampling and
reduce calculation time. However, the accuracy of region prediction hinders
further improvement. We propose a sampling-based algorithm, abbreviated to
Region Prediction Neural Network RRT* (RPNN-RRT*), to rapidly obtain the
optimal path based on a high-accuracy region prediction. First, we implement a
region prediction neural network (RPNN), to predict accurate regions for the
RPNN-RRT*. A full-layer channel-wise attention module is employed to enhance
the feature fusion in the concatenation between the encoder and decoder.
Moreover, a three-level hierarchy loss is designed to learn the pixel-wise,
map-wise, and patch-wise features. A dataset, named Complex Environment Motion
Planning, is established to test the performance in complex environments.
Ablation studies and test results show that a high accuracy of 89.13% is
achieved by the RPNN for region prediction, compared with other region
prediction models. In addition, the RPNN-RRT* performs in different complex
scenarios, demonstrating significant and reliable superiority in terms of the
calculation time, sampling efficiency, and success rate for optimal path
planning.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07977" title="Abstract">arXiv:2308.07977</a> [<a href="/pdf/2308.07977" title="Download PDF">pdf</a>, <a href="/format/2308.07977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YODA: You Only Diffuse Areas. An Area-Masked Diffusion Approach For  Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moser%2C+B+B">Brian B. Moser</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+S">Stanislav Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Raue%2C+F">Federico Raue</a>, 
<a href="/search/cs?searchtype=author&query=Palacio%2C+S">Sebastian Palacio</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Brian B. Moser and Stanislav Frolov contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work introduces "You Only Diffuse Areas" (YODA), a novel method for
partial diffusion in Single-Image Super-Resolution (SISR). The core idea is to
utilize diffusion selectively on spatial regions based on attention maps
derived from the low-resolution image and the current time step in the
diffusion process. This time-dependent targeting enables a more effective
conversion to high-resolution outputs by focusing on areas that benefit the
most from the iterative refinement process, i.e., detail-rich objects. We
empirically validate YODA by extending leading diffusion-based SISR methods SR3
and SRDiff. Our experiments demonstrate new state-of-the-art performance gains
in face and general SR across PSNR, SSIM, and LPIPS metrics. A notable finding
is YODA's stabilization effect on training by reducing color shifts, especially
when induced by small batch sizes, potentially contributing to
resource-constrained scenarios. The proposed spatial and temporal adaptive
diffusion mechanism opens promising research directions, including developing
enhanced attention map extraction techniques and optimizing inference latency
based on sparser diffusion.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07980" title="Abstract">arXiv:2308.07980</a> [<a href="/pdf/2308.07980" title="Download PDF">pdf</a>, <a href="/format/2308.07980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Approach for Probabilistic Wind Power Forecasting Based on  Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+Z">Zichao Meng</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongbin Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies an adaptive approach for probabilistic wind power
forecasting (WPF) including offline and online learning procedures. In the
offline learning stage, a base forecast model is trained via inner and outer
loop updates of meta-learning, which endows the base forecast model with
excellent adaptability to different forecast tasks, i.e., probabilistic WPF
with different lead times or locations. In the online learning stage, the base
forecast model is applied to online forecasting combined with incremental
learning techniques. On this basis, the online forecast takes full advantage of
recent information and the adaptability of the base forecast model. Two
applications are developed based on our proposed approach concerning
forecasting with different lead times (temporal adaptation) and forecasting for
newly established wind farms (spatial adaptation), respectively. Numerical
tests were conducted on real-world wind power data sets. Simulation results
validate the advantages in adaptivity of the proposed methods compared with
existing alternatives.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07984" title="Abstract">arXiv:2308.07984</a> [<a href="/pdf/2308.07984" title="Download PDF">pdf</a>, <a href="/format/2308.07984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anaphoric Structure Emerges Between Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edwards%2C+N">Nicholas Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Rohde%2C+H">Hannah Rohde</a>, 
<a href="/search/cs?searchtype=author&query=Conklin%2C+H">Henry Conklin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at the Annual Meeting of the Cognitive Science Society 2023: 6 Pages, 3 Figures, code available at <a href="https://github.com/hcoxec/emerge">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pragmatics is core to natural language, enabling speakers to communicate
efficiently with structures like ellipsis and anaphora that can shorten
utterances without loss of meaning. These structures require a listener to
interpret an ambiguous form - like a pronoun - and infer the speaker's intended
meaning - who that pronoun refers to. Despite potential to introduce ambiguity,
anaphora is ubiquitous across human language. In an effort to better understand
the origins of anaphoric structure in natural language, we look to see if
analogous structures can emerge between artificial neural networks trained to
solve a communicative task. We show that: first, despite the potential for
increased ambiguity, languages with anaphoric structures are learnable by
neural models. Second, anaphoric structures emerge between models 'naturally'
without need for additional constraints. Finally, introducing an explicit
efficiency pressure on the speaker increases the prevalence of these
structures. We conclude that certain pragmatic structures straightforwardly
emerge between neural networks, without explicit efficiency pressures, but that
the competing needs of speakers and listeners conditions the degree and nature
of their emergence.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07987" title="Abstract">arXiv:2308.07987</a> [<a href="/pdf/2308.07987" title="Download PDF">pdf</a>, <a href="/format/2308.07987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Subsampled Quantile Randomized Kaczmarz
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haddock%2C+J">Jamie Haddock</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+A">Anna Ma</a>, 
<a href="/search/math?searchtype=author&query=Rebrova%2C+E">Elizaveta Rebrova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">When solving noisy linear systems Ax = b + c, the theoretical and empirical
performance of stochastic iterative methods, such as the Randomized Kaczmarz
algorithm, depends on the noise level. However, if there are a small number of
highly corrupt measurements, one can instead use quantile-based methods to
guarantee convergence to the solution x of the system, despite the presence of
noise. Such methods require the computation of the entire residual vector,
which may not be desirable or even feasible in some cases. In this work, we
analyze the sub-sampled quantile Randomized Kaczmarz (sQRK) algorithm for
solving large-scale linear systems which utilize a sub-sampled residual to
approximate the quantile threshold. We prove that this method converges to the
unique solution to the linear system and provide numerical experiments that
support our theoretical findings. We additionally remark on the extremely small
sample size case and demonstrate the importance of interplay between the choice
of quantile and subset size.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07988" title="Abstract">arXiv:2308.07988</a> [<a href="/pdf/2308.07988" title="Download PDF">pdf</a>, <a href="/format/2308.07988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning  Questions to Facilitate Deeper Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+L+R">Liam Richards Maldonado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I'd like to acknowledge my two thesis advisors: Azza Abouzied and Nancy W. Gleason
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Academic reading is a key component of higher education, and serves as a
basis for critical thinking, knowledge acquisition and effective communication.
Research shows many students struggle with comprehension and analysis tasks
with academic texts, despite the central importance of academic reading to
success in higher education. Undergraduates and researchers need to internalize
dense literature to scaffold their own work upon it. This reading task is
time-consuming and difficult to do. Oftentimes, students struggle to actively
and critically engage and as a result attain merely a cursory understanding of
a paper's contents, or worse, incorrectly interpret the text. How, then, can we
provide a means to more easily digest a text whilst also facilitating
meaningful, critical engagement and understanding? This paper locates itself
within the broader field of Human-Computer Interaction (HCI) to implement an
augmented reading interface that leverages the power of ChatGPT to
intelligently generate and co-locate comprehension and analysis questions in an
academic paper, thereby making the paper more digestible with the end goal of
facilitating deeper understanding, and developing critical reading skills.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07997" title="Abstract">arXiv:2308.07997</a> [<a href="/pdf/2308.07997" title="Download PDF">pdf</a>, <a href="/format/2308.07997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting  Vision-and-Language Ability of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+H">Hongyan Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+R">Runhao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+H">Thomas H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We study the task of zero-shot vision-and-language navigation (ZS-VLN), a
practical yet challenging problem in which an agent learns to navigate
following a path described by language instructions without requiring any
path-instruction annotation data. Normally, the instructions have complex
grammatical structures and often contain various action descriptions (e.g.,
"proceed beyond", "depart from"). How to correctly understand and execute these
action demands is a critical problem, and the absence of annotated data makes
it even more challenging. Note that a well-educated human being can easily
understand path instructions without the need for any special training. In this
paper, we propose an action-aware zero-shot VLN method ($A^2$Nav) by exploiting
the vision-and-language ability of foundation models. Specifically, the
proposed method consists of an instruction parser and an action-aware
navigation policy. The instruction parser utilizes the advanced reasoning
ability of large language models (e.g., GPT-3) to decompose complex navigation
instructions into a sequence of action-specific object navigation sub-tasks.
Each sub-task requires the agent to localize the object and navigate to a
specific goal position according to the associated action demand. To accomplish
these sub-tasks, an action-aware navigation policy is learned from freely
collected action-specific datasets that reveal distinct characteristics of each
action demand. We use the learned navigation policy for executing sub-tasks
sequentially to follow the navigation instruction. Extensive experiments show
$A^2$Nav achieves promising ZS-VLN performance and even surpasses the
supervised learning methods on R2R-Habitat and RxR-Habitat datasets.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08002" title="Abstract">arXiv:2308.08002</a> [<a href="/pdf/2308.08002" title="Download PDF">pdf</a>, <a href="/ps/2308.08002" title="Download PostScript">ps</a>, <a href="/format/2308.08002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying OpenMP: Statistical Insights into Usage and Adoption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadosh%2C+T">Tal Kadosh</a>, 
<a href="/search/cs?searchtype=author&query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+T">Timothy Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
<p class="mathjax">In high-performance computing (HPC), the demand for efficient parallel
programming models has grown dramatically since the end of Dennard Scaling and
the subsequent move to multi-core CPUs. OpenMP stands out as a popular choice
due to its simplicity and portability, offering a directive-driven approach for
shared-memory parallel programming. Despite its wide adoption, however, there
is a lack of comprehensive data on the actual usage of OpenMP constructs,
hindering unbiased insights into its popularity and evolution. This paper
presents a statistical analysis of OpenMP usage and adoption trends based on a
novel and extensive database, HPCORPUS, compiled from GitHub repositories
containing C, C++, and Fortran code. The results reveal that OpenMP is the
dominant parallel programming model, accounting for 45% of all analyzed
parallel APIs. Furthermore, it has demonstrated steady and continuous growth in
popularity over the past decade. Analyzing specific OpenMP constructs, the
study provides in-depth insights into their usage patterns and preferences
across the three languages. Notably, we found that while OpenMP has a strong
"common core" of constructs in common usage (while the rest of the API is less
used), there are new adoption trends as well, such as simd and target
directives for accelerated computing and task for irregular parallelism.
Overall, this study sheds light on OpenMP's significance in HPC applications
and provides valuable data for researchers and practitioners. It showcases
OpenMP's versatility, evolving adoption, and relevance in contemporary parallel
programming, underlining its continued role in HPC applications and beyond.
These statistical insights are essential for making informed decisions about
parallelization strategies and provide a foundation for further advancements in
parallel programming models and techniques.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08003" title="Abstract">arXiv:2308.08003</a> [<a href="/pdf/2308.08003" title="Download PDF">pdf</a>, <a href="/format/2308.08003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BI-LAVA: Biocuration with Hierarchical Image Labeling through Active  Learning and Visual Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trelles%2C+J">Juan Trelles</a>, 
<a href="/search/cs?searchtype=author&query=Wentzel%2C+A">Andrew Wentzel</a>, 
<a href="/search/cs?searchtype=author&query=Berrios%2C+W">William Berrios</a>, 
<a href="/search/cs?searchtype=author&query=Marai%2C+G+E">G. Elisabeta Marai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the biomedical domain, taxonomies organize the acquisition modalities of
scientific images in hierarchical structures. Such taxonomies leverage large
sets of correct image labels and provide essential information about the
importance of a scientific publication, which could then be used in biocuration
tasks. However, the hierarchical nature of the labels, the overhead of
processing images, the absence or incompleteness of labeled data, and the
expertise required to label this type of data impede the creation of useful
datasets for biocuration. From a multi-year collaboration with biocurators and
text-mining researchers, we derive an iterative visual analytics and active
learning strategy to address these challenges. We implement this strategy in a
system called BI-LAVA Biocuration with Hierarchical Image Labeling through
Active Learning and Visual Analysis. BI-LAVA leverages a small set of image
labels, a hierarchical set of image classifiers, and active learning to help
model builders deal with incomplete ground-truth labels, target a hierarchical
taxonomy of image modalities, and classify a large pool of unlabeled images.
BI-LAVA's front end uses custom encodings to represent data distributions,
taxonomies, image projections, and neighborhoods of image thumbnails, which
help model builders explore an unfamiliar image dataset and taxonomy and
correct and generate labels. An evaluation with machine learning practitioners
shows that our mixed human-machine approach successfully supports domain
experts in understanding the characteristics of classes within the taxonomy, as
well as validating and improving data quality in labeled and unlabeled
collections.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08005" title="Abstract">arXiv:2308.08005</a> [<a href="/pdf/2308.08005" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the complex nexus: cybersecurity in political landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nkongolo%2C+M">Mike Nkongolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Cybersecurity in politics has emerged as a critical and intricate realm
intersecting technology, governance, and international relations. In this
interconnected digital context, political entities confront unparalleled
challenges in securing sensitive data, upholding democratic procedures, and
countering cyber threats. This study delves into the multifaceted landscape of
political cybersecurity, examining the evolving landscape of cyberattacks,
their impact on political stability, and strategies for bolstering digital
resilience. The intricate interplay between state-sponsored hacking,
disinformation campaigns, and eroding public trust underscores the imperative
for robust cybersecurity measures to safeguard political system integrity.
Through an extensive exploration of real-world case studies, policy frameworks,
and collaborative initiatives, this research illuminates the intricate network
of technological vulnerabilities, geopolitical dynamics, and ethical concerns
that shape the dynamic evolution of cybersecurity in politics. Amidst evolving
digital landscapes, the imperative for agile and preemptive cybersecurity
strategies is paramount for upholding the stability and credibility of
political institutions.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08009" title="Abstract">arXiv:2308.08009</a> [<a href="/pdf/2308.08009" title="Download PDF">pdf</a>, <a href="/format/2308.08009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Degrees of Freedom and Eigenfunctions of Line-of-Sight  Holographic MIMO Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Sicilia%2C+J+C">Juan Carlos Ruiz-Sicilia</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Migliore%2C+M+D">Marco Donald Migliore</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a line-of-sight communication link between two holographic
surfaces (HoloSs). We provide a closed-form expression for the number of
effective degrees of freedom (eDoF), i.e., the number of orthogonal
communication modes that can be established between the HoloSs. The framework
can be applied to general network deployments beyond the widely studied
paraxial setting. This is obtained by utilizing a quartic approximation for the
wavefront of the electromagnetic waves, and by proving that the number of eDoF
corresponds to an instance of Landau's eigenvalue problem applied to a
bandlimited kernel determined by the quartic approximation of the wavefront.
The proposed approach overcomes the limitations of the widely utilized
parabolic approximation for the wavefront, which provides inaccurate estimates
in non-paraxial deployments. We specialize the framework to typical network
deployments, and provide analytical expressions for the optimal, according to
Kolmogorov's $N$-width criterion, basis functions (communication waveforms) for
optimal data encoding and decoding. With the aid of numerical analysis, we
validate the accuracy of the closed-form expressions for the number of eDoF and
waveforms.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08010" title="Abstract">arXiv:2308.08010</a> [<a href="/pdf/2308.08010" title="Download PDF">pdf</a>, <a href="/format/2308.08010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRINN: A Physics-Informed Neural Network for solving hydrodynamic  systems in the presence of self-gravity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auddy%2C+S">Sayantan Auddy</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+R">Ramit Dey</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+N+J">Neal J. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+S">Shantanu Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modeling self-gravitating gas flows is essential to answering many
fundamental questions in astrophysics. This spans many topics including
planet-forming disks, star-forming clouds, galaxy formation, and the
development of large-scale structures in the Universe. However, the nonlinear
interaction between gravity and fluid dynamics offers a formidable challenge to
solving the resulting time-dependent partial differential equations (PDEs) in
three dimensions (3D). By leveraging the universal approximation capabilities
of a neural network within a mesh-free framework, physics informed neural
networks (PINNs) offer a new way of addressing this challenge. We introduce the
gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D
self-gravitating hydrodynamic systems. Here, we specifically study
gravitational instability and wave propagation in an isothermal gas. Our
results match a linear analytic solution to within 1\% in the linear regime and
a conventional grid code solution to within 5\% as the disturbance grows into
the nonlinear regime. We find that the computation time of the GRINN does not
scale with the number of dimensions. This is in contrast to the scaling of the
grid-based code for the hydrodynamic and self-gravity calculations as the
number of dimensions is increased. Our results show that the GRINN computation
time is longer than the grid code in one- and two- dimensional calculations but
is an order of magnitude lesser than the grid code in 3D with similar accuracy.
Physics-informed neural networks like GRINN thus show promise for advancing our
ability to model 3D astrophysical flows.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08011" title="Abstract">arXiv:2308.08011</a> [<a href="/pdf/2308.08011" title="Download PDF">pdf</a>, <a href="/format/2308.08011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortcut-V2V: Compression Framework for Video-to-Video Translation based  on Temporal Redundancy Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+C">Chaeyeon Chung</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yeojeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seunghwan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ganbat%2C+M">Munkhsoyol Ganbat</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video-to-video translation aims to generate video frames of a target domain
from an input video. Despite its usefulness, the existing networks require
enormous computations, necessitating their model compression for wide use.
While there exist compression methods that improve computational efficiency in
various image/video tasks, a generally-applicable compression method for
video-to-video translation has not been studied much. In response, we present
Shortcut-V2V, a general-purpose compression framework for video-to-video
translation. Shourcut-V2V avoids full inference for every neighboring video
frame by approximating the intermediate features of a current frame from those
of the previous frame. Moreover, in our framework, a newly-proposed block
called AdaBD adaptively blends and deforms features of neighboring frames,
which makes more accurate predictions of the intermediate features possible. We
conduct quantitative and qualitative evaluations using well-known
video-to-video translation models on various tasks to demonstrate the general
applicability of our framework. The results show that Shourcut-V2V achieves
comparable performance compared to the original video-to-video translation
model while saving 3.2-5.7x computational cost and 7.8-44x memory at test time.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08012" title="Abstract">arXiv:2308.08012</a> [<a href="/pdf/2308.08012" title="Download PDF">pdf</a>, <a href="/ps/2308.08012" title="Download PostScript">ps</a>, <a href="/format/2308.08012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Analysis of Network Robustness Evaluation Based on  Convolutional Neural Networks with Spatial Pyramid Pooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tianlong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuanfu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zong-fu Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures, 7 tables, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Connectivity robustness, a crucial aspect for understanding, optimizing, and
repairing complex networks, has traditionally been evaluated through
time-consuming and often impractical simulations. Fortunately, machine learning
provides a new avenue for addressing this challenge. However, several key
issues remain unresolved, including the performance in more general edge
removal scenarios, capturing robustness through attack curves instead of
directly training for robustness, scalability of predictive tasks, and
transferability of predictive capabilities. In this paper, we address these
challenges by designing a convolutional neural networks (CNN) model with
spatial pyramid pooling networks (SPP-net), adapting existing evaluation
metrics, redesigning the attack modes, introducing appropriate filtering rules,
and incorporating the value of robustness as training data. The results
demonstrate the thoroughness of the proposed CNN framework in addressing the
challenges of high computational time across various network types, failure
component types and failure scenarios. However, the performance of the proposed
CNN model varies: for evaluation tasks that are consistent with the trained
network type, the proposed CNN model consistently achieves accurate evaluations
of both attack curves and robustness values across all removal scenarios. When
the predicted network type differs from the trained network, the CNN model
still demonstrates favorable performance in the scenario of random node
failure, showcasing its scalability and performance transferability.
Nevertheless, the performance falls short of expectations in other removal
scenarios. This observed scenario-sensitivity in the evaluation of network
features has been overlooked in previous studies and necessitates further
attention and optimization. Lastly, we discuss important unresolved questions
and further investigation.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08017" title="Abstract">arXiv:2308.08017</a> [<a href="/pdf/2308.08017" title="Download PDF">pdf</a>, <a href="/format/2308.08017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Inverse Learning in Stackelberg Trajectory Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+J">Jacob Levy</a>, 
<a href="/search/cs?searchtype=author&query=Mehr%2C+N">Negar Mehr</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Game-theoretic inverse learning is the problem of inferring the players'
objectives from their actions. We formulate an inverse learning problem in a
Stackelberg game between a leader and a follower, where each player's action is
the trajectory of a dynamical system. We propose an active inverse learning
method for the leader to infer which hypothesis among a finite set of
candidates describes the follower's objective function. Instead of using
passively observed trajectories like existing methods, the proposed method
actively maximizes the differences in the follower's trajectories under
different hypotheses to accelerate the leader's inference. We demonstrate the
proposed method in a receding-horizon repeated trajectory game. Compared with
uniformly random inputs, the leader inputs provided by the proposed method
accelerate the convergence of the probability of different hypotheses
conditioned on the follower's trajectory by orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08023" title="Abstract">arXiv:2308.08023</a> [<a href="/pdf/2308.08023" title="Download PDF">pdf</a>, <a href="/format/2308.08023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Deterministic Observer for Inertial Navigation using  Ultra-wideband and IMU Sensor Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hashim%2C+H+A">Hashim A. Hashim</a>, 
<a href="/search/eess?searchtype=author&query=Eltoukhy%2C+A+E+E">Abdelrahman E. E. Eltoukhy</a>, 
<a href="/search/eess?searchtype=author&query=Vamvoudakis%2C+K+G">Kyriakos G. Vamvoudakis</a>, 
<a href="/search/eess?searchtype=author&query=Abouheaf%2C+M+I">Mohammed I. Abouheaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Navigation in Global Positioning Systems (GPS)-denied environments requires
robust estimators reliant on fusion of inertial sensors able to estimate
rigid-body's orientation, position, and linear velocity. Ultra-wideband (UWB)
and Inertial Measurement Unit (IMU) represent low-cost measurement technology
that can be utilized for successful Inertial Navigation. This paper presents a
nonlinear deterministic navigation observer in a continuous form that directly
employs UWB and IMU measurements. The estimator is developed on the extended
Special Euclidean Group $\mathbb{SE}_{2}\left(3\right)$ and ensures exponential
convergence of the closed loop error signals starting from almost any initial
condition. The discrete version of the proposed observer is tested using a
publicly available real-world dataset of a drone flight. Keywords:
Ultra-wideband, Inertial measurement unit, Sensor Fusion, Positioning system,
GPS-denied navigation.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08028" title="Abstract">arXiv:2308.08028</a> [<a href="/pdf/2308.08028" title="Download PDF">pdf</a>, <a href="/ps/2308.08028" title="Download PostScript">ps</a>, <a href="/format/2308.08028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Analysis of the Impact of COVID-19 on Emergency Housing Shelter  Access Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Messier%2C+G+G">Geoffrey G. Messier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper investigates how COVID-19 disrupted emergency housing shelter
access patterns in Calgary, Canada and what aspects of these changes persist to
the present day. This analysis will utilize aggregated shelter access data for
over 40,000 individuals from seven major urban shelters dating from 2018 to the
present. A graph theoretic approach will be used to examine the journeys of
individuals between shelters before, during and after the COVID-19 lockdown
period. This approach treats shelters as nodes in a graph and a person's
transition between shelter as an arrow or edge between nodes. This perspective
is used to create both timeline and network diagrams that visualize shelter use
and the flow of people between shelters. Statistical results are also presented
that illustrate the differences between the cohorts of people who only used
shelter pre/post-lockdown, people who stayed in shelter during lockdown and
people who used shelter for the first time during lockdown. The results
demonstrate not only how a complex system of care responded to the pandemic but
also the characteristics of the people most likely to continue to rely on that
system during an emergency.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08029" title="Abstract">arXiv:2308.08029</a> [<a href="/pdf/2308.08029" title="Download PDF">pdf</a>, <a href="/format/2308.08029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning to Learn: A Novel Algorithm for Active Learning during  Model-Based Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hodson%2C+R">Rowan Hodson</a>, 
<a href="/search/cs?searchtype=author&query=Bassett%2C+B">Bruce Bassett</a>, 
<a href="/search/cs?searchtype=author&query=van+Hoof%2C+C">Charel van Hoof</a>, 
<a href="/search/cs?searchtype=author&query=Rosman%2C+B">Benjamin Rosman</a>, 
<a href="/search/cs?searchtype=author&query=Solms%2C+M">Mark Solms</a>, 
<a href="/search/cs?searchtype=author&query=Shock%2C+J+P">Jonathan P. Shock</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+R">Ryan Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Active Inference is a recent framework for modeling planning under
uncertainty. Empirical and theoretical work have now begun to evaluate the
strengths and weaknesses of this approach and how it might be improved. A
recent extension - the sophisticated inference (SI) algorithm - improves
performance on multi-step planning problems through recursive decision tree
search. However, little work to date has been done to compare SI to other
established planning algorithms. SI was also developed with a focus on
inference as opposed to learning. The present paper has two aims. First, we
compare performance of SI to Bayesian reinforcement learning (RL) schemes
designed to solve similar problems. Second, we present an extension of SI -
sophisticated learning (SL) - that more fully incorporates active learning
during planning. SL maintains beliefs about how model parameters would change
under the future observations expected under each policy. This allows a form of
counterfactual retrospective inference in which the agent considers what could
be learned from current or past observations given different future
observations. To accomplish these aims, we make use of a novel, biologically
inspired environment designed to highlight the problem structure for which SL
offers a unique solution. Here, an agent must continually search for available
(but changing) resources in the presence of competing affordances for
information gain. Our simulations show that SL outperforms all other algorithms
in this context - most notably, Bayes-adaptive RL and upper confidence bound
algorithms, which aim to solve multi-step planning problems using similar
principles (i.e., directed exploration and counterfactual reasoning). These
results provide added support for the utility of Active Inference in solving
this class of biologically-relevant problems and offer added tools for testing
hypotheses about human cognition.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08032" title="Abstract">arXiv:2308.08032</a> [<a href="/pdf/2308.08032" title="Download PDF">pdf</a>, <a href="/format/2308.08032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Artificial Populations to Study Psychological Phenomena in Neural  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J">Jesse Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kyle Moore</a>, 
<a href="/search/cs?searchtype=author&query=Wilenzick%2C+D">Drew Wilenzick</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+D">Doug Fisher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recent proliferation of research into transformer based natural language
processing has led to a number of studies which attempt to detect the presence
of human-like cognitive behavior in the models. We contend that, as is true of
human psychology, the investigation of cognitive behavior in language models
must be conducted in an appropriate population of an appropriate size for the
results to be meaningful. We leverage work in uncertainty estimation in a novel
approach to efficiently construct experimental populations. The resultant tool,
PopulationLM, has been made open source. We provide theoretical grounding in
the uncertainty estimation literature and motivation from current cognitive
work regarding language models. We discuss the methodological lessons from
other scientific communities and attempt to demonstrate their application to
two artificial population studies. Through population based experimentation we
find that language models exhibit behavior consistent with typicality effects
among categories highly represented in training. However, we find that language
models don't tend to exhibit structural priming effects. Generally, our results
show that single models tend to over estimate the presence of cognitive
behaviors in neural models.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08033" title="Abstract">arXiv:2308.08033</a> [<a href="/pdf/2308.08033" title="Download PDF">pdf</a>, <a href="/format/2308.08033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Test Case Generation Using Code Models and Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashtroudi%2C+S">Sepehr Hashtroudi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jiho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Hemmati%2C+H">Hadi Hemmati</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + reference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">State-of-the-art automated test generation techniques, such as search-based
testing, are usually ignorant about what a developer would create as a test
case. Therefore, they typically create tests that are not human-readable and
may not necessarily detect all types of complex bugs developer-written tests
would do. In this study, we leverage Transformer-based code models to generate
unit tests that can complement search-based test generation. Specifically, we
use CodeT5, i.e., a state-of-the-art large code model, and fine-tune it on the
test generation downstream task. For our analysis, we use the Methods2test
dataset for fine-tuning CodeT5 and Defects4j for project-level domain
adaptation and evaluation. The main contribution of this study is proposing a
fully automated testing framework that leverages developer-written tests and
available code models to generate compilable, human-readable unit tests.
Results show that our approach can generate new test cases that cover lines
that were not covered by developer-written tests. Using domain adaptation, we
can also increase line coverage of the model-generated unit tests by 49.9% and
54% in terms of mean and median (compared to the model without domain
adaptation). We can also use our framework as a complementary solution
alongside common search-based methods to increase the overall coverage with
mean and median of 25.3% and 6.3%. It can also increase the mutation score of
search-based methods by killing extra mutants (up to 64 new mutants were killed
per project in our experiments).
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08035" title="Abstract">arXiv:2308.08035</a> [<a href="/pdf/2308.08035" title="Download PDF">pdf</a>, <a href="/format/2308.08035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gain coefficients for scrambled Halton points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Owen%2C+A+B">Art B. Owen</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+Z">Zexin Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computation (stat.CO)

</div>
<p class="mathjax">Randomized quasi-Monte Carlo, via certain scramblings of digital nets,
produces unbiased estimates of
$\int_{[0,1]^d}f(\boldsymbol{x})\,\mathrm{d}\boldsymbol{x}$ with a variance
that is $o(1/n)$ for any $f\in L^2[0,1]^d$. It also satisfies some
non-asymptotic bounds where the variance is no larger than some $\Gamma&lt;\infty$
times the ordinary Monte Carlo variance. For scrambled Sobol' points, this
quantity $\Gamma$ grows exponentially in $d$. For scrambled Faure points,
$\Gamma \leqslant \exp(1)\doteq 2.718$ in any dimension, but those points are
awkward to use for large $d$. This paper shows that certain scramblings of
Halton sequences have gains below an explicit bound that is $O(\log d)$ but not
$O( (\log d)^{1-\epsilon})$ for any $\epsilon&gt;0$ as $d\to\infty$. For
$6\leqslant d\leqslant 10^6$, the upper bound on the gain coefficient is never
larger than $3/2+\log(d/2)$.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08043" title="Abstract">arXiv:2308.08043</a> [<a href="/pdf/2308.08043" title="Download PDF">pdf</a>, <a href="/format/2308.08043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiagGPT: An LLM-based Chatbot with Automatic Topic Management for  Task-Oriented Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs), such as ChatGPT, are becoming increasingly
sophisticated, demonstrating capabilities that closely resemble those of
humans. These AI models are playing an essential role in assisting humans with
a wide array of tasks in daily life. A significant application of AI is its use
as a chat agent, responding to human inquiries across various domains. Current
LLMs have shown proficiency in answering general questions. However, basic
question-answering dialogue often falls short in complex diagnostic scenarios,
such as legal or medical consultations. These scenarios typically necessitate
Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively
pose questions and guide users towards specific task completion. Previous
fine-tuning models have underperformed in TOD, and current LLMs do not
inherently possess this capability. In this paper, we introduce DiagGPT
(Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD
scenarios. Our experiments reveal that DiagGPT exhibits outstanding performance
in conducting TOD with users, demonstrating its potential for practical
applications.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08045" title="Abstract">arXiv:2308.08045</a> [<a href="/pdf/2308.08045" title="Download PDF">pdf</a>, <a href="/format/2308.08045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Coalitions in Multi-Agent Systems: Quantifying the Strong  Price of Anarchy for Resource Allocation Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+B+L">Bryce L. Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Paccagnan%2C+D">Dario Paccagnan</a>, 
<a href="/search/cs?searchtype=author&query=Pradelski%2C+B+S+R">Bary S. R. Pradelski</a>, 
<a href="/search/cs?searchtype=author&query=Marden%2C+J+R">Jason R. Marden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The emergence of new communication technologies allows us to expand our
understanding of distributed control and consider collaborative decision-making
paradigms. With collaborative algorithms, certain local decision-making
entities (or agents) are enabled to communicate and collaborate on their
actions with one another to attain better system behavior. By limiting the
amount of communication, these algorithms exist somewhere between centralized
and fully distributed approaches. To understand the possible benefits of this
inter-agent collaboration, we model a multi-agent system as a common-interest
game in which groups of agents can collaborate on their actions to jointly
increase the system welfare. We specifically consider $k$-strong Nash
equilibria as the emergent behavior of these systems and address how well these
states approximate the system optimal, formalized by the $k$-strong price of
anarchy ratio. Our main contributions are in generating tight bounds on the
$k$-strong price of anarchy in finite resource allocation games as the solution
to a tractable linear program. By varying $k$ --the maximum size of a
collaborative coalition--we observe exactly how much performance is gained from
inter-agent collaboration. To investigate further opportunities for
improvement, we generate upper bounds on the maximum attainable $k$-strong
price of anarchy when the agents' utility function can be designed.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08046" title="Abstract">arXiv:2308.08046</a> [<a href="/pdf/2308.08046" title="Download PDF">pdf</a>, <a href="/ps/2308.08046" title="Download PostScript">ps</a>, <a href="/format/2308.08046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Lower Bounds in Multi-agent Multi-armed Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengfan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-armed Bandit motivates methods with provable upper bounds on regret and
also the counterpart lower bounds have been extensively studied in this
context. Recently, Multi-agent Multi-armed Bandit has gained significant
traction in various domains, where individual clients face bandit problems in a
distributed manner and the objective is the overall system performance,
typically measured by regret. While efficient algorithms with regret upper
bounds have emerged, limited attention has been given to the corresponding
regret lower bounds, except for a recent lower bound for adversarial settings,
which, however, has a gap with let known upper bounds. To this end, we herein
provide the first comprehensive study on regret lower bounds across different
settings and establish their tightness. Specifically, when the graphs exhibit
good connectivity properties and the rewards are stochastically distributed, we
demonstrate a lower bound of order $O(\log T)$ for instance-dependent bounds
and $\sqrt{T}$ for mean-gap independent bounds which are tight. Assuming
adversarial rewards, we establish a lower bound $O(T^{\frac{2}{3}})$ for
connected graphs, thereby bridging the gap between the lower and upper bound in
the prior work. We also show a linear regret lower bound when the graph is
disconnected. While previous works have explored these settings with upper
bounds, we provide a thorough study on tight lower bounds.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08047" title="Abstract">arXiv:2308.08047</a> [<a href="/pdf/2308.08047" title="Download PDF">pdf</a>, <a href="/ps/2308.08047" title="Download PostScript">ps</a>, <a href="/format/2308.08047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlated vs. Uncorrelated Randomness in Adversarial Congestion Team  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orzech%2C+I">Idan Orzech</a>, 
<a href="/search/cs?searchtype=author&query=Rinard%2C+M">Martin Rinard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We consider team zero-sum network congestion games with $n$ senders playing
against $k$ interceptors over a graph $G$. The senders aim to minimize their
collective cost of sending messages over paths in $G$, which is an aggregation
of edge costs, while the interceptors aim to maximize the collective cost by
increasing some of these edge costs. To evade the interceptors, the senders
will usually use randomized strategies. We consider two cases, the correlated
case when senders have access to a shared source of randomness, and the
uncorrelated case, when each sender has access to only its own source of
randomness. We study the additional cost that uncorrelated senders have to
bear, specifically by comparing the costs incurred by senders in cost-minimal
Nash Equilibria when senders can and cannot share randomness.
<br />We prove that for an intuitive strict subset of cost functions, the ratio
between correlated and uncorrelated costs at equilibrium is
$O(\min(m_c(G),n))$, where $m_c(G)$ is the mincut size of $G$. This bound is
much milder compared to the most general case, where an upper bound of
$\Omega((m_c(G))^{n-1})$ on the ratio is known. We show that the senders can
approximate their optimal play by playing simple strategies which select paths
uniformly at random from subsets of disjoint paths. We then focus on two
natural cost functions. For the first, we prove that one of the simple
strategies above is an optimal strategy for senders over graphs with disjoint
paths. In complete contrast, for the second cost function we prove that none of
these simple strategies is optimal for the senders over these graphs, unless
the game instance admits a trivial optimal senders strategy.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08051" title="Abstract">arXiv:2308.08051</a> [<a href="/pdf/2308.08051" title="Download PDF">pdf</a>, <a href="/format/2308.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the  Bank Loan Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gal%2C+E">Elena Gal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shaun Singh</a>, 
<a href="/search/cs?searchtype=author&query=Pacchiano%2C+A">Aldo Pacchiano</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+B">Ben Walker</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In many real world settings binary classification decisions are made based on
limited data in near real-time, e.g. when assessing a loan application. We
focus on a class of these problems that share a common feature: the true label
is only observed when a data point is assigned a positive label by the
principal, e.g. we only find out whether an applicant defaults if we accepted
their loan application. As a consequence, the false rejections become
self-reinforcing and cause the labelled training set, that is being
continuously updated by the model decisions, to accumulate bias. Prior work
mitigates this effect by injecting optimism into the model, however this comes
at the cost of increased false acceptance rate. We introduce adversarial
optimism (AdOpt) to directly address bias in the training set using adversarial
domain adaptation. The goal of AdOpt is to learn an unbiased but informative
representation of past data, by reducing the distributional shift between the
set of accepted data points and all data points seen thus far. AdOpt
significantly exceeds state-of-the-art performance on a set of challenging
benchmark problems. Our experiments also provide initial evidence that the
introduction of adversarial domain adaptation improves fairness in this
setting.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08053" title="Abstract">arXiv:2308.08053</a> [<a href="/pdf/2308.08053" title="Download PDF">pdf</a>, <a href="/format/2308.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Evolution Strategies as a Black Box Estimator for Stochastic  Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amin%2C+A+A">Ahmad Ayaz Amin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Stochastic variational inference and its derivatives in the form of
variational autoencoders enjoy the ability to perform Bayesian inference on
large datasets in an efficient manner. However, performing inference with a VAE
requires a certain design choice (i.e. reparameterization trick) to allow
unbiased and low variance gradient estimation, restricting the types of models
that can be created. To overcome this challenge, an alternative estimator based
on natural evolution strategies is proposed. This estimator does not make
assumptions about the kind of distributions used, allowing for the creation of
models that would otherwise not have been possible under the VAE framework.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08055" title="Abstract">arXiv:2308.08055</a> [<a href="/pdf/2308.08055" title="Download PDF">pdf</a>, <a href="/ps/2308.08055" title="Download PostScript">ps</a>, <a href="/format/2308.08055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple online learning with consistency oracle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kozachinskiy%2C+A">Alexander Kozachinskiy</a>, 
<a href="/search/cs?searchtype=author&query=Steifer%2C+T">Tomasz Steifer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider online learning in the model where a learning algorithm can
access the class only via the consistency oracle -- an oracle, that, at any
moment, can give a function from the class that agrees with all examples seen
so far. This model was recently considered by Assos et al. (COLT'23). It is
motivated by the fact that standard methods of online learning rely on
computing the Littlestone dimension of subclasses, a problem that is
computationally intractable. Assos et al. gave an online learning algorithm in
this model that makes at most $C^d$ mistakes on classes of Littlestone
dimension $d$, for some absolute unspecified constant $C &gt; 0$. We give a novel
algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly
simpler and uses only very basic properties of the Littlestone dimension. We
also observe that there exists no algorithm in this model that makes at most
$2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the
algorithm of Assos et al.) solves an open problem by Hasrati and Ben-David
(ALT'23). Namely, it demonstrates that every class of finite Littlestone
dimension with recursively enumerable representation admits a computable online
learner (that may be undefined on unrealizable samples).
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08057" title="Abstract">arXiv:2308.08057</a> [<a href="/pdf/2308.08057" title="Download PDF">pdf</a>, <a href="/ps/2308.08057" title="Download PostScript">ps</a>, <a href="/format/2308.08057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Floating-Point Secure Implementation of the Report Noisy Max with Gap  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zeyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Durrell%2C+J">John Durrell</a>, 
<a href="/search/cs?searchtype=author&query=Kifer%2C+D">Daniel Kifer</a>, 
<a href="/search/cs?searchtype=author&query=Protivash%2C+P">Prottay Protivash</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yingtai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Danfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The Noisy Max mechanism and its variations are fundamental private selection
algorithms that are used to select items from a set of candidates (such as the
most common diseases in a population), while controlling the privacy leakage in
the underlying data. A recently proposed extension, Noisy Top-k with Gap,
provides numerical information about how much better the selected items are
compared to the non-selected items (e.g., how much more common are the selected
diseases). This extra information comes at no privacy cost but crucially relies
on infinite precision for the privacy guarantees. In this paper, we provide a
finite-precision secure implementation of this algorithm that takes advantage
of integer arithmetic.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08058" title="Abstract">arXiv:2308.08058</a> [<a href="/pdf/2308.08058" title="Download PDF">pdf</a>, <a href="/format/2308.08058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-Drive: Visible-Short Wave Infrared Hyperspectral Imaging Datasets  for Robots in Unstructured Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanson%2C+N">Nathaniel Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Pyatski%2C+B">Benjamin Pyatski</a>, 
<a href="/search/cs?searchtype=author&query=Hibbard%2C+S">Samuel Hibbard</a>, 
<a href="/search/cs?searchtype=author&query=DiMarzio%2C+C">Charles DiMarzio</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C4%B1r%2C+T">Ta&#x15f;k&#x131;n Pad&#x131;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Hyperspectral sensors have enjoyed widespread use in the realm of remote
sensing; however, they must be adapted to a format in which they can be
operated onboard mobile robots. In this work, we introduce a first-of-its-kind
system architecture with snapshot hyperspectral cameras and point spectrometers
to efficiently generate composite datacubes from a robotic base. Our system
collects and registers datacubes spanning the visible to shortwave infrared
(660-1700 nm) spectrum while simultaneously capturing the ambient solar
spectrum reflected off a white reference tile. We collect and disseminate a
large dataset of more than 500 labeled datacubes from on-road and off-road
terrain compliant with the ATLAS ontology to further the integration and
demonstration of hyperspectral imaging (HSI) as beneficial in terrain class
separability. Our analysis of this data demonstrates that HSI is a significant
opportunity to increase understanding of scene composition from a robot-centric
context. All code and data are open source online:
https://river-lab.github.io/hyper_drive_data
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08061" title="Abstract">arXiv:2308.08061</a> [<a href="/pdf/2308.08061" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Costly Dilemma: Generalization, Evaluation and Cost-Optimal  Deployment of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aryan%2C+A">Abi Aryan</a>, 
<a href="/search/cs?searchtype=author&query=Nain%2C+A+K">Aakash Kumar Nain</a>, 
<a href="/search/cs?searchtype=author&query=McMahon%2C+A">Andrew McMahon</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+L+A">Lucas Augusto Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Sahota%2C+H+S">Harpreet Singh Sahota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">When deploying machine learning models in production for any
product/application, there are three properties that are commonly desired.
First, the models should be generalizable, in that we can extend it to further
use cases as our knowledge of the domain area develops. Second they should be
evaluable, so that there are clear metrics for performance and the calculation
of those metrics in production settings are feasible. Finally, the deployment
should be cost-optimal as far as possible. In this paper we propose that these
three objectives (i.e. generalization, evaluation and cost-optimality) can
often be relatively orthogonal and that for large language models, despite
their performance over conventional NLP models, enterprises need to carefully
assess all the three factors before making substantial investments in this
technology. We propose a framework for generalization, evaluation and
cost-modeling specifically tailored to large language models, offering insights
into the intricacies of development, deployment and management for these large
language models.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08069" title="Abstract">arXiv:2308.08069</a> [<a href="/pdf/2308.08069" title="Download PDF">pdf</a>, <a href="/format/2308.08069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement Learning Approach for Performance-aware Reduction in  Power Consumption of Data Center Compute Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Akhilesh Raj</a>, 
<a href="/search/cs?searchtype=author&query=Perarnau%2C+S">Swann Perarnau</a>, 
<a href="/search/cs?searchtype=author&query=Gokhale%2C+A">Aniruddha Gokhale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript consists of a total of 10 pages with 8 figures and 3 tables and is awaiting its publication at IC2E-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">As Exascale computing becomes a reality, the energy needs of compute nodes in
cloud data centers will continue to grow. A common approach to reducing this
energy demand is to limit the power consumption of hardware components when
workloads are experiencing bottlenecks elsewhere in the system. However,
designing a resource controller capable of detecting and limiting power
consumption on-the-fly is a complex issue and can also adversely impact
application performance. In this paper, we explore the use of Reinforcement
Learning (RL) to design a power capping policy on cloud compute nodes using
observations on current power consumption and instantaneous application
performance (heartbeats). By leveraging the Argo Node Resource Management (NRM)
software stack in conjunction with the Intel Running Average Power Limit (RAPL)
hardware control mechanism, we design an agent to control the maximum supplied
power to processors without compromising on application performance. Employing
a Proximal Policy Optimization (PPO) agent to learn an optimal policy on a
mathematical model of the compute nodes, we demonstrate and evaluate using the
STREAM benchmark how a trained agent running on actual hardware can take
actions by balancing power consumption and application performance.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08071" title="Abstract">arXiv:2308.08071</a> [<a href="/pdf/2308.08071" title="Download PDF">pdf</a>, <a href="/ps/2308.08071" title="Download PostScript">ps</a>, <a href="/format/2308.08071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via  Dynamic Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiashu Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The delayed feedback problem is one of the most pressing challenges in
predicting the conversion rate since users' conversions are always delayed in
online commercial systems. Although new data are beneficial for continuous
training, without complete feedback information, i.e., conversion labels,
training algorithms may suffer from overwhelming fake negatives. Existing
methods tend to use multitask learning or design data pipelines to solve the
delayed feedback problem. However, these methods have a trade-off between data
freshness and label accuracy. In this paper, we propose Delayed Feedback
Modeling by Dynamic Graph Neural Network (DGDFEM). It includes three stages,
i.e., preparing a data pipeline, building a dynamic graph, and training a CVR
prediction model. In the model training, we propose a novel graph convolutional
method named HLGCN, which leverages both high-pass and low-pass filters to deal
with conversion and non-conversion relationships. The proposed method achieves
both data freshness and label accuracy. We conduct extensive experiments on
three industry datasets, which validate the consistent superiority of our
method.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08072" title="Abstract">arXiv:2308.08072</a> [<a href="/pdf/2308.08072" title="Download PDF">pdf</a>, <a href="/format/2308.08072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Graph Neural Network for Privacy-Preserving Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiashu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Building a graph neural network (GNN)-based recommender system without
violating user privacy proves challenging. Existing methods can be divided into
federated GNNs and decentralized GNNs. But both methods have undesirable
effects, i.e., low communication efficiency and privacy leakage. This paper
proposes DGREC, a novel decentralized GNN for privacy-preserving
recommendations, where users can choose to publicize their interactions. It
includes three stages, i.e., graph construction, local gradient calculation,
and global gradient passing. The first stage builds a local inner-item
hypergraph for each user and a global inter-user graph. The second stage models
user preference and calculates gradients on each local device. The third stage
designs a local differential privacy mechanism named secure gradient-sharing,
which proves strong privacy-preserving of users' private data. We conduct
extensive experiments on three public datasets to validate the consistent
superiority of our framework.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08074" title="Abstract">arXiv:2308.08074</a> [<a href="/pdf/2308.08074" title="Download PDF">pdf</a>, <a href="/format/2308.08074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Numerical Differentiation of Sampled Data Using Adaptive Input  and State Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verma%2C+S">Shashank Verma</a>, 
<a href="/search/eess?searchtype=author&query=Sanjeevini%2C+S">Sneha Sanjeevini</a>, 
<a href="/search/eess?searchtype=author&query=Sumer%2C+E+D">E. Dogan Sumer</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under review at the International Journal of Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Real-time numerical differentiation plays a crucial role in many digital
control algorithms, such as PID control, which requires numerical
differentiation to implement derivative action. This paper addresses the
problem of numerical differentiation for real-time implementation with minimal
prior information about the signal and noise using adaptive input and state
estimation. Adaptive input estimation with adaptive state estimation (AIE/ASE)
is based on retrospective cost input estimation, while adaptive state
estimation is based on an adaptive Kalman filter in which the input-estimation
error covariance and the measurement-noise covariance are updated online. The
accuracy of AIE/ASE is compared numerically to several conventional numerical
differentiation methods. Finally, AIE/ASE is applied to simulated vehicle
position data generated from CarSim.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08079" title="Abstract">arXiv:2308.08079</a> [<a href="/pdf/2308.08079" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rigid Transformations for Stabilized Lower Dimensional Space to Support  Subsurface Uncertainty Quantification and Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mabadeje%2C+A+O">Ademide O. Mabadeje</a>, 
<a href="/search/cs?searchtype=author&query=Pyrcz%2C+M+J">Michael J. Pyrcz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 17 figures, Submitted to Computational Geosciences Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Subsurface datasets inherently possess big data characteristics such as vast
volume, diverse features, and high sampling speeds, further compounded by the
curse of dimensionality from various physical, engineering, and geological
inputs. Among the existing dimensionality reduction (DR) methods, nonlinear
dimensionality reduction (NDR) methods, especially Metric-multidimensional
scaling (MDS), are preferred for subsurface datasets due to their inherent
complexity. While MDS retains intrinsic data structure and quantifies
uncertainty, its limitations include unstabilized unique solutions invariant to
Euclidean transformations and an absence of out-of-sample points (OOSP)
extension. To enhance subsurface inferential and machine learning workflows,
datasets must be transformed into stable, reduced-dimension representations
that accommodate OOSP.
<br />Our solution employs rigid transformations for a stabilized Euclidean
invariant representation for LDS. By computing an MDS input dissimilarity
matrix, and applying rigid transformations on multiple realizations, we ensure
transformation invariance and integrate OOSP. This process leverages a convex
hull algorithm and incorporates loss function and normalized stress for
distortion quantification. We validate our approach with synthetic data,
varying distance metrics, and real-world wells from the Duvernay Formation.
Results confirm our method's efficacy in achieving consistent LDS
representations. Furthermore, our proposed "stress ratio" (SR) metric provides
insight into uncertainty, beneficial for model adjustments and inferential
analysis. Consequently, our workflow promises enhanced repeatability and
comparability in NDR for subsurface energy resource engineering and associated
big data workflows.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08086" title="Abstract">arXiv:2308.08086</a> [<a href="/pdf/2308.08086" title="Download PDF">pdf</a>, <a href="/format/2308.08086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Filter Design for Neural Network Systems via Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shaoru Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chee%2C+K+Y">Kong Yao Chee</a>, 
<a href="/search/eess?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>, 
<a href="/search/eess?searchtype=author&query=Hsieh%2C+M+A">M. Ani Hsieh</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to the 2023 62nd IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">With the increase in data availability, it has been widely demonstrated that
neural networks (NN) can capture complex system dynamics precisely in a
data-driven manner. However, the architectural complexity and nonlinearity of
the NNs make it challenging to synthesize a provably safe controller. In this
work, we propose a novel safety filter that relies on convex optimization to
ensure safety for a NN system, subject to additive disturbances that are
capable of capturing modeling errors. Our approach leverages tools from NN
verification to over-approximate NN dynamics with a set of linear bounds,
followed by an application of robust linear MPC to search for controllers that
can guarantee robust constraint satisfaction. We demonstrate the efficacy of
the proposed framework numerically on a nonlinear pendulum system.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08088" title="Abstract">arXiv:2308.08088</a> [<a href="/pdf/2308.08088" title="Download PDF">pdf</a>, <a href="/format/2308.08088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hee%2C+M+S">Ming Shan Hee</a>, 
<a href="/search/cs?searchtype=author&query=Kuek%2C+A">Adriel Kuek</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+W">Wen-Haw Chong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+K">Roy Ka-Wei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready for 23, ACM MM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Multimedia (cs.MM)

</div>
<p class="mathjax">Hateful meme detection is a challenging multimodal task that requires
comprehension of both vision and language, as well as cross-modal interactions.
Recent studies have tried to fine-tune pre-trained vision-language models
(PVLMs) for this task. However, with increasing model sizes, it becomes
important to leverage powerful PVLMs more efficiently, rather than simply
fine-tuning them. Recently, researchers have attempted to convert meme images
into textual captions and prompt language models for predictions. This approach
has shown good performance but suffers from non-informative image captions.
Considering the two factors mentioned above, we propose a probing-based
captioning approach to leverage PVLMs in a zero-shot visual question answering
(VQA) manner. Specifically, we prompt a frozen PVLM by asking hateful
content-related questions and use the answers as image captions (which we call
Pro-Cap), so that the captions contain information critical for hateful content
detection. The good performance of models with Pro-Cap on three benchmarks
validates the effectiveness and generalization of the proposed method.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08089" title="Abstract">arXiv:2308.08089</a> [<a href="/pdf/2308.08089" title="Download PDF">pdf</a>, <a href="/format/2308.08089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DragNUWA: Fine-grained Control in Video Generation by Integrating Text,  Image, and Trajectory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shengming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+G">Gong Ming</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Controllable video generation has gained significant attention in recent
years. However, two main limitations persist: Firstly, most existing works
focus on either text, image, or trajectory-based control, leading to an
inability to achieve fine-grained control in videos. Secondly, trajectory
control research is still in its early stages, with most experiments being
conducted on simple datasets like Human3.6M. This constraint limits the models'
capability to process open-domain images and effectively handle complex curved
trajectories. In this paper, we propose DragNUWA, an open-domain
diffusion-based video generation model. To tackle the issue of insufficient
control granularity in existing works, we simultaneously introduce text, image,
and trajectory information to provide fine-grained control over video content
from semantic, spatial, and temporal perspectives. To resolve the problem of
limited open-domain trajectory control in current research, We propose
trajectory modeling with three aspects: a Trajectory Sampler (TS) to enable
open-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to
control trajectories in different granularities, and an Adaptive Training (AT)
strategy to generate consistent videos following trajectories. Our experiments
validate the effectiveness of DragNUWA, demonstrating its superior performance
in fine-grained control in video generation. The homepage link is
\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08090" title="Abstract">arXiv:2308.08090</a> [<a href="/pdf/2308.08090" title="Download PDF">pdf</a>, <a href="/format/2308.08090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separate the Wheat from the Chaff: Model Deficiency Unlearning via  Parameter-Efficient Module Operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinshuo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zihao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have been widely used in various applications
but are known to suffer from issues related to untruthfulness and toxicity.
While parameter-efficient modules (PEMs) have demonstrated their effectiveness
in equipping models with new skills, leveraging PEMs for deficiency unlearning
remains underexplored. In this work, we propose a PEMs operation approach,
namely Extraction-before-Subtraction (Ext-Sub), to enhance the truthfulness and
detoxification of LLMs through the integration of ``expert'' PEM and
``anti-expert'' PEM. Remarkably, even anti-expert PEM possess valuable
capabilities due to their proficiency in generating fabricated content, which
necessitates language modeling and logical narrative competence. Rather than
merely negating the parameters, our approach involves extracting and
eliminating solely the deficiency capability within anti-expert PEM while
preserving the general capabilities. To evaluate the effectiveness of our
approach in terms of truthfulness and detoxification, we conduct extensive
experiments on LLMs, encompassing additional abilities such as language
modeling and mathematical reasoning. Our empirical results demonstrate that our
approach effectively improves truthfulness and detoxification, while largely
preserving the fundamental abilities of LLMs.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08096" title="Abstract">arXiv:2308.08096</a> [<a href="/pdf/2308.08096" title="Download PDF">pdf</a>, <a href="/format/2308.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges with Passwordless FIDO2 in an Enterprise Setting: A Usability  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kepkowski%2C+M">Michal Kepkowski</a>, 
<a href="/search/cs?searchtype=author&query=Machulak%2C+M">Maciej Machulak</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+I">Ian Wood</a>, 
<a href="/search/cs?searchtype=author&query=Kaafar%2C+D">Dali Kaafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in the IEEE Secure Development Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fast Identity Online 2 (FIDO2), a modern authentication protocol, is gaining
popularity as a default strong authentication mechanism. It has been recognized
as a leading candidate to overcome limitations (e.g., phishing resistance) of
existing authentication solutions. However, the task of deprecating weak
methods such as password-based authentication is not trivial and requires a
comprehensive approach. While security, privacy, and end-user usability of
FIDO2 have been addressed in both academic and industry literature, the
difficulties associated with its integration with production environments, such
as solution completeness or edge-case support, have received little attention.
In particular, complex environments such as enterprise identity management pose
unique challenges for any authentication system. In this paper, we identify
challenging enterprise identity lifecycle use cases (e.g., remote workforce and
legacy systems) by conducting a usability study, in which over 100
cybersecurity professionals shared their perception of challenges to FIDO2
integration from their hands-on field experience. Our analysis of the user
study results revealed serious gaps such as account recovery (selected by over
60% of our respondents), and identify priority development areas for the FIDO2
community.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08097" title="Abstract">arXiv:2308.08097</a> [<a href="/pdf/2308.08097" title="Download PDF">pdf</a>, <a href="/format/2308.08097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-Mixup: Structural Mixup for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junghurn Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sukwon Yun</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023 (Short Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing studies for applying the mixup technique on graphs mainly focus on
graph classification tasks, while the research in node classification is still
under-explored. In this paper, we propose a novel mixup augmentation for node
classification called Structural Mixup (S-Mixup). The core idea is to take into
account the structural information while mixing nodes. Specifically, S-Mixup
obtains pseudo-labels for unlabeled nodes in a graph along with their
prediction confidence via a Graph Neural Network (GNN) classifier. These serve
as the criteria for the composition of the mixup pool for both inter and
intra-class mixups. Furthermore, we utilize the edge gradient obtained from the
GNN training and propose a gradient-based edge selection strategy for selecting
edges to be attached to the nodes generated by the mixup. Through extensive
experiments on real-world benchmark datasets, we demonstrate the effectiveness
of S-Mixup evaluated on the node classification task. We observe that S-Mixup
enhances the robustness and generalization performance of GNNs, especially in
heterophilous situations. The source code of S-Mixup can be found at
\url{https://github.com/SukwonYun/S-Mixup}
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08102" title="Abstract">arXiv:2308.08102</a> [<a href="/pdf/2308.08102" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatLogo: A Large Language Model-Driven Hybrid Natural-Programming  Language Interface for Agent-based Modeling and Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">John Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wilensky%2C+U">Uri Wilensky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Constructionism 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Building on Papert (1980)'s idea of children talking to computers, we propose
ChatLogo, a hybrid natural-programming language interface for agent-based
modeling and programming. We build upon previous efforts to scaffold ABM &amp; P
learning and recent development in leveraging large language models (LLMs) to
support the learning of computational programming. ChatLogo aims to support
conversations with computers in a mix of natural and programming languages,
provide a more user-friendly interface for novice learners, and keep the
technical system from over-reliance on any single LLM. We introduced the main
elements of our design: an intelligent command center, and a conversational
interface to support creative expression. We discussed the presentation format
and future work. Responding to the challenges of supporting open-ended
constructionist learning of ABM &amp; P and leveraging LLMs for educational
purposes, we contribute to the field by proposing the first constructionist
LLM-driven interface to support computational and complex systems thinking.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08104" title="Abstract">arXiv:2308.08104</a> [<a href="/pdf/2308.08104" title="Download PDF">pdf</a>, <a href="/format/2308.08104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConservationBots: Autonomous Aerial Robot for Fast Robust Wildlife  Tracking in Complex Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+H">Hoa Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Taggart%2C+D+A">David A. Taggart</a>, 
<a href="/search/cs?searchtype=author&query=Falkner%2C+K">Katrina Falkner</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+S+H">S. Hamid Rezatofighi</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 21 figures, submitted to Journal of Field Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Today, the most widespread, widely applicable technology for gathering data
relies on experienced scientists armed with handheld radio telemetry equipment
to locate low-power radio transmitters attached to wildlife from the ground.
Although aerial robots can transform labor-intensive conservation tasks, the
realization of autonomous systems for tackling task complexities under
real-world conditions remains a challenge. We developed ConservationBots-small
aerial robots for tracking multiple, dynamic, radio-tagged wildlife. The aerial
robot achieves robust localization performance and fast task completion times
-- significant for energy-limited aerial systems while avoiding close
encounters with potential, counter-productive disturbances to wildlife. Our
approach overcomes the technical and practical problems posed by combining a
lightweight sensor with new concepts: i) planning to determine both trajectory
and measurement actions guided by an information-theoretic objective, which
allows the robot to strategically select near-instantaneous range-only
measurements to achieve faster localization, and time-consuming sensor rotation
actions to acquire bearing measurements and achieve robust tracking
performance; ii) a bearing detector more robust to noise and iii) a tracking
algorithm formulation robust to missed and false detections experienced in
real-world conditions. We conducted extensive studies: simulations built upon
complex signal propagation over high-resolution elevation data on diverse
geographical terrains; field testing; studies with wombats (Lasiorhinus
latifrons; nocturnal, vulnerable species dwelling in underground warrens) and
tracking comparisons with a highly experienced biologist to validate the
effectiveness of our aerial robot and demonstrate the significant advantages
over the manual method.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08106" title="Abstract">arXiv:2308.08106</a> [<a href="/pdf/2308.08106" title="Download PDF">pdf</a>, <a href="/format/2308.08106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient relaxation scheme for the SIR and related compartmental models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Khoa%2C+V+A">Vo Anh Khoa</a>, 
<a href="/search/math?searchtype=author&query=Quan%2C+P+M">Pham Minh Quan</a>, 
<a href="/search/math?searchtype=author&query=Allen%2C+J">Ja&#x27;Niyah Allen</a>, 
<a href="/search/math?searchtype=author&query=Blayneh%2C+K+W">Kbenesh W. Blayneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 21 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this paper, we introduce a novel numerical approach for approximating the
SIR model in epidemiology. Our method enhances the existing linearization
procedure by incorporating a suitable relaxation term to tackle the
transcendental equation of nonlinear type. Developed within the continuous
framework, our relaxation method is explicit and easy to implement, relying on
a sequence of linear differential equations. This approach yields accurate
approximations in both discrete and analytical forms. Through rigorous
analysis, we prove that, with an appropriate choice of the relaxation
parameter, our numerical scheme is non-negativity-preserving and globally
strongly convergent towards the true solution. These theoretical findings have
not received sufficient attention in various existing SIR solvers. We also
extend the applicability of our relaxation method to handle some variations of
the traditional SIR model. Finally, we present numerical examples using
simulated data to demonstrate the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08110" title="Abstract">arXiv:2308.08110</a> [<a href="/pdf/2308.08110" title="Download PDF">pdf</a>, <a href="/format/2308.08110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View Consistent Purification for Accurate Cross-View Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Perincherry%2C+A">Akhil Perincherry</a>, 
<a href="/search/cs?searchtype=author&query=Vora%2C+A">Ankit Vora</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a fine-grained self-localization method for outdoor
robotics that utilizes a flexible number of onboard cameras and readily
accessible satellite images. The proposed method addresses limitations in
existing cross-view localization methods that struggle to handle noise sources
such as moving objects and seasonal variations. It is the first sparse
visual-only method that enhances perception in dynamic environments by
detecting view-consistent key points and their corresponding deep features from
ground and satellite views, while removing off-the-ground objects and
establishing homography transformation between the two views. Moreover, the
proposed method incorporates a spatial embedding approach that leverages camera
intrinsic and extrinsic information to reduce the ambiguity of purely visual
matching, leading to improved feature matching and overall pose estimation
accuracy. The method exhibits strong generalization and is robust to
environmental changes, requiring only geo-poses as ground truth. Extensive
experiments on the KITTI and Ford Multi-AV Seasonal datasets demonstrate that
our proposed method outperforms existing state-of-the-art methods, achieving
median spatial accuracy errors below $0.5$ meters along the lateral and
longitudinal directions, and a median orientation accuracy error below 2
degrees.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08111" title="Abstract">arXiv:2308.08111</a> [<a href="/pdf/2308.08111" title="Download PDF">pdf</a>, <a href="/format/2308.08111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Circuit Design Optimization under Variation  Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yifan Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zichang He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+N">Nanlin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICCAD 2023, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Due to the significant process variations, designers have to optimize the
statistical performance distribution of nano-scale IC design in most cases.
This problem has been investigated for decades under the formulation of
stochastic optimization, which minimizes the expected value of a performance
metric while assuming that the distribution of process variation is exactly
given. This paper rethinks the variation-aware circuit design optimization from
a new perspective. First, we discuss the variation shift problem, which means
that the actual density function of process variations almost always differs
from the given model and is often unknown. Consequently, we propose to
formulate the variation-aware circuit design optimization as a distributionally
robust optimization problem, which does not require the exact distribution of
process variations. By selecting an appropriate uncertainty set for the
probability density function of process variations, we solve the shift-aware
circuit optimization problem using distributionally robust Bayesian
optimization. This method is validated with both a photonic IC and an
electronics IC. Our optimized circuits show excellent robustness against
variation shifts: the optimized circuit has excellent performance under many
possible distributions of process variations that differ from the given
statistical model. This work has the potential to enable a new research
direction and inspire subsequent research at different levels of the EDA flow
under the setting of variation shift.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08114" title="Abstract">arXiv:2308.08114</a> [<a href="/pdf/2308.08114" title="Download PDF">pdf</a>, <a href="/format/2308.08114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+H">Hao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Qie%2C+X">Xiaohu Qie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Omnidirectional images (ODIs) have become increasingly popular, as their
large field-of-view (FoV) can offer viewers the chance to freely choose the
view directions in immersive environments such as virtual reality. The M\"obius
transformation is typically employed to further provide the opportunity for
movement and zoom on ODIs, but applying it to the image level often results in
blurry effect and aliasing problem. In this paper, we propose a novel deep
learning-based approach, called \textbf{OmniZoomer}, to incorporate the
M\"obius transformation into the network for movement and zoom on ODIs. By
learning various transformed feature maps under different conditions, the
network is enhanced to handle the increasing edge curvatures, which alleviates
the blurry effect. Moreover, to address the aliasing problem, we propose two
key components. Firstly, to compensate for the lack of pixels for describing
curves, we enhance the feature maps in the high-resolution (HR) space and
calculate the transformed index map with a spatial index generation module.
Secondly, considering that ODIs are inherently represented in the spherical
space, we propose a spherical resampling module that combines the index map and
HR feature maps to transform the feature maps for better spherical correlation.
The transformed feature maps are decoded to output a zoomed ODI. Experiments
show that our method can produce HR and high-quality ODIs with the flexibility
to move and zoom in to the object of interest. Project page is available at
<a href="http://vlislab22.github.io/OmniZoomer/.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08120" title="Abstract">arXiv:2308.08120</a> [<a href="/pdf/2308.08120" title="Download PDF">pdf</a>, <a href="/format/2308.08120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering User Interest from Biased and Noised Watch Time in Video  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guohao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Recsys'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In the video recommendation, watch time is commonly adopted as an indicator
of user interest. However, watch time is not only influenced by the matching of
users' interests but also by other factors, such as duration bias and noisy
watching. Duration bias refers to the tendency for users to spend more time on
videos with longer durations, regardless of their actual interest level. Noisy
watching, on the other hand, describes users taking time to determine whether
they like a video or not, which can result in users spending time watching
videos they do not like. Consequently, the existence of duration bias and noisy
watching make watch time an inadequate label for indicating user interest.
Furthermore, current methods primarily address duration bias and ignore the
impact of noisy watching, which may limit their effectiveness in uncovering
user interest from watch time. In this study, we first analyze the generation
mechanism of users' watch time from a unified causal viewpoint. Specifically,
we considered the watch time as a mixture of the user's actual interest level,
the duration-biased watch time, and the noisy watch time. To mitigate both the
duration bias and noisy watching, we propose Debiased and Denoised watch time
Correction (D$^2$Co), which can be divided into two steps: First, we employ a
duration-wise Gaussian Mixture Model plus frequency-weighted moving average for
estimating the bias and noise terms; then we utilize a sensitivity-controlled
correction function to separate the user interest from the watch time, which is
robust to the estimation error of bias and noise terms. The experiments on two
public video recommendation datasets and online A/B testing indicate the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08125" title="Abstract">arXiv:2308.08125</a> [<a href="/pdf/2308.08125" title="Download PDF">pdf</a>, <a href="/format/2308.08125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Running Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiangtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ngai%2C+E+C+H">Edith C.H. Ngai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (ACM IMWUT/UbiComp 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Millimeter wave (mmWave) based speech recognition provides more possibility
for audio-related applications, such as conference speech transcription and
eavesdropping. However, considering the practicality in real scenarios, latency
and recognizable vocabulary size are two critical factors that cannot be
overlooked. In this paper, we propose Radio2Text, the first mmWave-based system
for streaming automatic speech recognition (ASR) with a vocabulary size
exceeding 13,000 words. Radio2Text is based on a tailored streaming Transformer
that is capable of effectively learning representations of speech-related
features, paving the way for streaming ASR with a large vocabulary. To
alleviate the deficiency of streaming networks unable to access entire future
inputs, we propose the Guidance Initialization that facilitates the transfer of
feature knowledge related to the global context from the non-streaming
Transformer to the tailored streaming Transformer through weight inheritance.
Further, we propose a cross-modal structure based on knowledge distillation
(KD), named cross-modal KD, to mitigate the negative effect of low quality
mmWave signals on recognition performance. In the cross-modal KD, the audio
streaming Transformer provides feature and response guidance that inherit
fruitful and accurate speech information to supervise the training of the
tailored radio streaming Transformer. The experimental results show that our
Radio2Text can achieve a character error rate of 5.7% and a word error rate of
9.4% for the recognition of a vocabulary consisting of over 13,000 words.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08128" title="Abstract">arXiv:2308.08128</a> [<a href="/pdf/2308.08128" title="Download PDF">pdf</a>, <a href="/format/2308.08128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Mask in Error Correction Code Transformer: Systematic and Double  Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seong-Joon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+H">Hee-Youl Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Hyo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongjune Kim</a>, 
<a href="/search/cs?searchtype=author&query=No%2C+J">Jong-Seon No</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">In communication and storage systems, error correction codes (ECCs) are
pivotal in ensuring data reliability. As deep learning's applicability has
broadened across diverse domains, there is a growing research focus on neural
network-based decoders that outperform traditional decoding algorithms. Among
these neural decoders, Error Correction Code Transformer (ECCT) has achieved
the state-of-the-art performance, outperforming other methods by large margins.
To further enhance the performance of ECCT, we propose two novel methods.
First, leveraging the systematic encoding technique of ECCs, we introduce a new
masking matrix for ECCT, aiming to improve the performance and reduce the
computational complexity. Second, we propose a novel transformer architecture
of ECCT called a double-masked ECCT. This architecture employs two different
mask matrices in a parallel manner to learn more diverse features of the
relationship between codeword bits in the masked self-attention blocks.
Extensive simulation results show that the proposed double-masked ECCT
outperforms the conventional ECCT, achieving the state-of-the-art decoding
performance with significant margins.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08129" title="Abstract">arXiv:2308.08129</a> [<a href="/pdf/2308.08129" title="Download PDF">pdf</a>, <a href="/format/2308.08129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Self-Supervised Pretraining Good for Extrapolation in Molecular  Property Prediction?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takashige%2C+S">Shun Takashige</a>, 
<a href="/search/cs?searchtype=author&query=Hanai%2C+M">Masatoshi Hanai</a>, 
<a href="/search/cs?searchtype=author&query=Suzumura%2C+T">Toyotaro Suzumura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Taura%2C+K">Kenjiro Taura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The prediction of material properties plays a crucial role in the development
and discovery of materials in diverse applications, such as batteries,
semiconductors, catalysts, and pharmaceuticals. Recently, there has been a
growing interest in employing data-driven approaches by using machine learning
technologies, in combination with conventional theoretical calculations. In
material science, the prediction of unobserved values, commonly referred to as
extrapolation, is particularly critical for property prediction as it enables
researchers to gain insight into materials beyond the limits of available data.
However, even with the recent advancements in powerful machine learning models,
accurate extrapolation is still widely recognized as a significantly
challenging problem. On the other hand, self-supervised pretraining is a
machine learning technique where a model is first trained on unlabeled data
using relatively simple pretext tasks before being trained on labeled data for
target tasks. As self-supervised pretraining can effectively utilize material
data without observed property values, it has the potential to improve the
model's extrapolation ability. In this paper, we clarify how such
self-supervised pretraining can enhance extrapolation performance.We propose an
experimental framework for the demonstration and empirically reveal that while
models were unable to accurately extrapolate absolute property values,
self-supervised pretraining enables them to learn relative tendencies of
unobserved property values and improve extrapolation performance.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08131" title="Abstract">arXiv:2308.08131</a> [<a href="/pdf/2308.08131" title="Download PDF">pdf</a>, <a href="/format/2308.08131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking-aware Uncertainty for Text-guided Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hanjiang Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-guided image retrieval is to incorporate conditional text to better
capture users' intent. Traditionally, the existing methods focus on minimizing
the embedding distances between the source inputs and the targeted image, using
the provided triplets $\langle$source image, source text, target
image$\rangle$. However, such triplet optimization may limit the learned
retrieval model to capture more detailed ranking information, e.g., the
triplets are one-to-one correspondences and they fail to account for
many-to-many correspondences arising from semantic diversity in feedback
languages and images. To capture more ranking information, we propose a novel
ranking-aware uncertainty approach to model many-to-many correspondences by
only using the provided triplets. We introduce uncertainty learning to learn
the stochastic ranking list of features. Specifically, our approach mainly
comprises three components: (1) In-sample uncertainty, which aims to capture
semantic diversity using a Gaussian distribution derived from both combined and
target features; (2) Cross-sample uncertainty, which further mines the ranking
information from other samples' distributions; and (3) Distribution
regularization, which aligns the distributional representations of source
inputs and targeted image. Compared to the existing state-of-the-art methods,
our proposed method achieves significant results on two public datasets for
composed image retrieval.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08137" title="Abstract">arXiv:2308.08137</a> [<a href="/pdf/2308.08137" title="Download PDF">pdf</a>, <a href="/format/2308.08137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYENet: A Simple Yet Effective Network for Multiple Low-Level Vision  Tasks with Real-time Performance on Mobile Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+W">Weiran Gou</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Ziyao Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaoqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zibin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Dehui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid development of AI hardware accelerators, applying deep
learning-based algorithms to solve various low-level vision tasks on mobile
devices has gradually become possible. However, two main problems still need to
be solved: task-specific algorithms make it difficult to integrate them into a
single neural network architecture, and large amounts of parameters make it
difficult to achieve real-time inference. To tackle these problems, we propose
a novel network, SYENet, with only $~$6K parameters, to handle multiple
low-level vision tasks on mobile devices in a real-time manner. The SYENet
consists of two asymmetrical branches with simple building blocks. To
effectively connect the results by asymmetrical branches, a Quadratic
Connection Unit(QCU) is proposed. Furthermore, to improve performance, a new
Outlier-Aware Loss is proposed to process the image. The proposed method proves
its superior performance with the best PSNR as compared with other networks in
real-time applications such as Image Signal Processing(ISP), Low-Light
Enhancement(LLE), and Super-Resolution(SR) with 2K60FPS throughput on Qualcomm
8 Gen 1 mobile SoC(System-on-Chip). Particularly, for ISP task, SYENet got the
highest score in MAI 2022 Learned Smartphone ISP challenge.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08138" title="Abstract">arXiv:2308.08138</a> [<a href="/pdf/2308.08138" title="Download PDF">pdf</a>, <a href="/ps/2308.08138" title="Download PostScript">ps</a>, <a href="/format/2308.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Control for Linear Dynamics: A Data-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zishun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yongxin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper considers an online control problem over a linear time-invariant
system with unknown dynamics, bounded disturbance, and adversarial cost. We
propose a data-driven strategy to reduce the regret of the controller. Unlike
model-based methods, our algorithm does not identify the system model, instead,
it leverages a single noise-free trajectory to calculate the accumulation of
disturbance and makes decisions using the accumulated disturbance action
controller we design, whose parameters are updated by online gradient descent.
We prove that the regret of our algorithm is $\mathcal{O}(\sqrt{T})$ under mild
assumptions, suggesting that its performance is on par with model-based
methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08140" title="Abstract">arXiv:2308.08140</a> [<a href="/pdf/2308.08140" title="Download PDF">pdf</a>, <a href="/format/2308.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain  Adaptive 3D Object Detection from Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tongtong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Bingbing%2C+L">Liu Bingbing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR-based 3D detection has made great progress in recent years. However,
the performance of 3D detectors is considerably limited when deployed in unseen
environments, owing to the severe domain gap problem. Existing domain adaptive
3D detection methods do not adequately consider the problem of the
distributional discrepancy in feature space, thereby hindering generalization
of detectors across domains. In this work, we propose a novel unsupervised
domain adaptive \textbf{3D} detection framework, namely \textbf{G}eometry-aware
\textbf{P}rototype \textbf{A}lignment (\textbf{GPA-3D}), which explicitly
leverages the intrinsic geometric relationship from point cloud objects to
reduce the feature discrepancy, thus facilitating cross-domain transferring.
Specifically, GPA-3D assigns a series of tailored and learnable prototypes to
point cloud objects with distinct geometric structures. Each prototype aligns
BEV (bird's-eye-view) features derived from corresponding point cloud objects
on source and target domains, reducing the distributional discrepancy and
achieving better adaptation. The evaluation results obtained on various
benchmarks, including Waymo, nuScenes and KITTI, demonstrate the superiority of
our GPA-3D over the state-of-the-art approaches for different adaptation
scenarios. The MindSpore version code will be publicly available at
\url{https://github.com/Liz66666/GPA3D}.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08142" title="Abstract">arXiv:2308.08142</a> [<a href="/pdf/2308.08142" title="Download PDF">pdf</a>, <a href="/format/2308.08142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and  Blind Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+M">Minghao She</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wendong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Huihong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nowadays, deep learning based methods have demonstrated impressive
performance on ideal super-resolution (SR) datasets, but most of these methods
incur dramatically performance drops when directly applied in real-world SR
reconstruction tasks with unpredictable blur kernels. To tackle this issue,
blind SR methods are proposed to improve the visual results on random blur
kernels, which causes unsatisfactory reconstruction effects on ideal
low-resolution images similarly. In this paper, we propose a double-win
framework for ideal and blind SR task, named S2R, including a light-weight
transformer-based SR model (S2R transformer) and a novel coarse-to-fine
training strategy, which can achieve excellent visual results on both ideal and
random fuzzy conditions. On algorithm level, S2R transformer smartly combines
some efficient and light-weight blocks to enhance the representation ability of
extracted features with relatively low number of parameters. For training
strategy, a coarse-level learning process is firstly performed to improve the
generalization of the network with the help of a large-scale external dataset,
and then, a fast fine-tune process is developed to transfer the pre-trained
model to real-world SR tasks by mining the internal features of the image.
Experimental results show that the proposed S2R outperforms other single-image
SR models in ideal SR condition with only 578K parameters. Meanwhile, it can
achieve better visual results than regular blind SR models in blind fuzzy
conditions with only 10 gradient updates, which improve convergence speed by
300 times, significantly accelerating the transfer-learning process in
real-world situations.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08143" title="Abstract">arXiv:2308.08143</a> [<a href="/pdf/2308.08143" title="Download PDF">pdf</a>, <a href="/format/2308.08143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Runxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaolin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The integration of different modalities, such as audio and visual
information, plays a crucial role in human perception of the surrounding
environment. Recent research has made significant progress in designing fusion
modules for audio-visual speech separation. However, they predominantly focus
on multi-modal fusion architectures situated either at the top or bottom
positions, rather than comprehensively considering multi-modal fusion at
various hierarchical positions within the network. In this paper, we propose a
novel model called self- and cross-attention network (SCANet), which leverages
the attention mechanism for efficient audio-visual feature fusion. SCANet
consists of two types of attention blocks: self-attention (SA) and
cross-attention (CA) blocks, where the CA blocks are distributed at the top
(TCA), middle (MCA) and bottom (BCA) of SCANet. These blocks maintain the
ability to learn modality-specific features and enable the extraction of
different semantics from audio-visual features. Comprehensive experiments on
three standard audio-visual separation benchmarks (LRS2, LRS3, and VoxCeleb2)
demonstrate the effectiveness of SCANet, outperforming existing
state-of-the-art (SOTA) methods while maintaining comparable inference time.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08144" title="Abstract">arXiv:2308.08144</a> [<a href="/pdf/2308.08144" title="Download PDF">pdf</a>, <a href="/format/2308.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeakPair: Proactive Repairing of Memory Leaks in Single Page Web  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahoor%2C+A">Arooba Shahoor</a>, 
<a href="/search/cs?searchtype=author&query=Khamit%2C+A+Y">Askar Yeltayuly Khamit</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jooyong Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongsun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures, Accepted for ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Modern web applications often resort to application development frameworks
such as React, Vue.js, and Angular. While the frameworks facilitate the
development of web applications with several useful components, they are
inevitably vulnerable to unmanaged memory consumption since the frameworks
often produce Single Page Applications (SPAs). Web applications can be alive
for hours and days with behavior loops, in such cases, even a single memory
leak in a SPA app can cause performance degradation on the client side.
However, recent debugging techniques for web applications still focus on memory
leak detection, which requires manual tasks and produces imprecise results.
<br />We propose LeakPair, a technique to repair memory leaks in single page
applications. Given the insight that memory leaks are mostly non-functional
bugs and fixing them might not change the behavior of an application, the
technique is designed to proactively generate patches to fix memory leaks,
without leak detection, which is often heavy and tedious. To generate effective
patches, LeakPair follows the idea of pattern-based program repair since the
automated repair strategy shows successful results in many recent studies. We
evaluate the technique on more than 20 open-source projects without using
explicit leak detection. The patches generated by our technique are also
submitted to the projects as pull requests. The results show that LeakPair can
generate effective patches to reduce memory consumption that are acceptable to
developers. In addition, we execute the test suites given by the projects after
applying the patches, and it turns out that the patches do not cause any
functionality breakage; this might imply that LeakPair can generate
non-intrusive patches for memory leaks.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08147" title="Abstract">arXiv:2308.08147</a> [<a href="/pdf/2308.08147" title="Download PDF">pdf</a>, <a href="/format/2308.08147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDDial: A Multi-turn Differential Diagnosis Dialogue Dataset with  Reliability Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macherla%2C+S">Srija Macherla</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Man Luo</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Mihir Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dialogue systems for Automatic Differential Diagnosis (ADD) have a wide range
of real-life applications. These dialogue systems are promising for providing
easy access and reducing medical costs. Building end-to-end ADD dialogue
systems requires dialogue training datasets. However, to the best of our
knowledge, there is no publicly available ADD dialogue dataset in English
(although non-English datasets exist). Driven by this, we introduce MDDial, the
first differential diagnosis dialogue dataset in English which can aid to build
and evaluate end-to-end ADD dialogue systems. Additionally, earlier studies
present the accuracy of diagnosis and symptoms either individually or as a
combined weighted score. This method overlooks the connection between the
symptoms and the diagnosis. We introduce a unified score for the ADD system
that takes into account the interplay between symptoms and diagnosis. This
score also indicates the system's reliability. To the end, we train two
moderate-size of language models on MDDial. Our experiments suggest that while
these language models can perform well on many natural language understanding
tasks, including dialogue tasks in the general domain, they struggle to relate
relevant symptoms and disease and thus have poor performance on MDDial. MDDial
will be released publicly to aid the study of ADD dialogue research.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08148" title="Abstract">arXiv:2308.08148</a> [<a href="/pdf/2308.08148" title="Download PDF">pdf</a>, <a href="/format/2308.08148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Topological Ordering with Conditional Independence Test for  Limited Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anpeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Keli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Learning directed acyclic graphs (DAGs) to identify causal relations
underlying observational data is crucial but also poses significant challenges.
Recently, topology-based methods have emerged as a two-step approach to
discovering DAGs by first learning the topological ordering of variables and
then eliminating redundant edges, while ensuring that the graph remains
acyclic. However, one limitation is that these methods would generate numerous
spurious edges that require subsequent pruning. To overcome this limitation, in
this paper, we propose an improvement to topology-based methods by introducing
limited time series data, consisting of only two cross-sectional records that
need not be adjacent in time and are subject to flexible timing. By
incorporating conditional instrumental variables as exogenous interventions, we
aim to identify descendant nodes for each variable. Following this line, we
propose a hierarchical topological ordering algorithm with conditional
independence test (HT-CIT), which enables the efficient learning of sparse DAGs
with a smaller search space compared to other popular approaches. The HT-CIT
algorithm greatly reduces the number of edges that need to be pruned. Empirical
results from synthetic and real-world datasets demonstrate the superiority of
the proposed HT-CIT algorithm.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08151" title="Abstract">arXiv:2308.08151</a> [<a href="/pdf/2308.08151" title="Download PDF">pdf</a>, <a href="/format/2308.08151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Kinematic Design of a Robotic Lizard using Four-Bar and Five-Bar  Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+R+V">Rajashekhar V S</a>, 
<a href="/search/cs?searchtype=author&query=Ghose%2C+D">Debasish Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Doss%2C+A+S+A">Arockia Selvakumar Arockia Doss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures, Submitted for iNaCoMM 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Designing a mechanism to mimic the motion of a common house gecko is the
objective of this work. The body of the robot is designed using four five-bar
mechanisms (2-RRRRR and 2-RRPRR) and the leg is designed using four four-bar
mechanisms. The 2-RRRRR five-bar mechanisms form the head and tail of the
robotic lizard. The 2-RRPRR five-bar mechanisms form the left and right sides
of the body in the robotic lizard. The four five-bar mechanisms are actuated by
only four rotary actuators. Of these, two actuators control the head movements
and the other two control the tail movements. The RRPRR five-bar mechanism is
controlled by one actuator from the head five-bar mechanism and the other by
the tail five-bar mechanism. A tension spring connects each active link to a
link in the four bar mechanism. When the robot is actuated, the head, tail and
the body moves, and simultaneously each leg moves accordingly. This kind of
actuation where the motion transfer occurs from body of the robot to the leg is
the novelty in our design. The dimensional synthesis of the robotic lizard is
done and presented. Then the forward and inverse kinematics of the mechanism,
and configuration space singularities identification for the robot are
presented. The gait exhibited by the gecko is studied and then simulated. A
computer aided design of the robotic lizard is created and a prototype is made
by 3D printing the parts. The prototype is controlled using Arduino UNO as a
micro-controller. The experimental results are finally presented based on the
gait analysis that was done earlier. The forward walking, and turning motion
are done and snapshots are presented.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08153" title="Abstract">arXiv:2308.08153</a> [<a href="/pdf/2308.08153" title="Download PDF">pdf</a>, <a href="/format/2308.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Training of NMT Model with Data Sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rim%2C+D+N">Daniela N. Rim</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+K">Kimera Richard</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Heeyoul Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Transformer model has revolutionized Natural Language Processing tasks
such as Neural Machine Translation, and many efforts have been made to study
the Transformer architecture, which increased its efficiency and accuracy. One
potential area for improvement is to address the computation of empty tokens
that the Transformer computes only to discard them later, leading to an
unnecessary computational burden. To tackle this, we propose an algorithm that
sorts translation sentence pairs based on their length before batching,
minimizing the waste of computing power. Since the amount of sorting could
violate the independent and identically distributed (i.i.d) data assumption, we
sort the data partially. In experiments, we apply the proposed method to
English-Korean and English-Luganda language pairs for machine translation and
show that there are gains in computational time while maintaining the
performance. Our method is independent of architectures, so that it can be
easily integrated into any training process with flexible data lengths.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08155" title="Abstract">arXiv:2308.08155</a> [<a href="/pdf/2308.08155" title="Download PDF">pdf</a>, <a href="/format/2308.08155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+G">Gagan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaokun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">Erkang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Beibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Li Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This technical report presents AutoGen, a new framework that enables
development of LLM applications using multiple agents that can converse with
each other to solve tasks. AutoGen agents are customizable, conversable, and
seamlessly allow human participation. They can operate in various modes that
employ combinations of LLMs, human inputs, and tools. AutoGen's design offers
multiple advantages: a) it gracefully navigates the strong but imperfect
generation and reasoning abilities of these LLMs; b) it leverages human
understanding and intelligence, while providing valuable automation through
conversations between agents; c) it simplifies and unifies the implementation
of complex LLM workflows as automated agent chats. We provide many diverse
examples of how developers can easily use AutoGen to effectively solve tasks or
build applications, ranging from coding, mathematics, operations research,
entertainment, online decision-making, question answering, etc.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08156" title="Abstract">arXiv:2308.08156</a> [<a href="/pdf/2308.08156" title="Download PDF">pdf</a>, <a href="/format/2308.08156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sarcasm Detection in a Disaster Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sosea%2C+T">Tiberiu Sosea</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+J">Junyi Jessy Li</a>, 
<a href="/search/cs?searchtype=author&query=Caragea%2C+C">Cornelia Caragea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">During natural disasters, people often use social media platforms such as
Twitter to ask for help, to provide information about the disaster situation,
or to express contempt about the unfolding event or public policies and
guidelines. This contempt is in some cases expressed as sarcasm or irony.
Understanding this form of speech in a disaster-centric context is essential to
improving natural language understanding of disaster-related tweets. In this
paper, we introduce HurricaneSARC, a dataset of 15,000 tweets annotated for
intended sarcasm, and provide a comprehensive investigation of sarcasm
detection using pre-trained language models. Our best model is able to obtain
as much as 0.70 F1 on our dataset. We also demonstrate that the performance on
HurricaneSARC can be improved by leveraging intermediate task transfer
learning. We release our data and code at
https://github.com/tsosea2/HurricaneSarc.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08157" title="Abstract">arXiv:2308.08157</a> [<a href="/pdf/2308.08157" title="Download PDF">pdf</a>, <a href="/format/2308.08157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Semantic Layouts for Higher Text-Image  Correspondence in Text-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minho Park</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Jooyeol Yun</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seunghwan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing text-to-image generation approaches have set high standards for
photorealism and text-image correspondence, largely benefiting from web-scale
text-image datasets, which can include up to 5~billion pairs. However,
text-to-image generation models trained on domain-specific datasets, such as
urban scenes, medical images, and faces, still suffer from low text-image
correspondence due to the lack of text-image pairs. Additionally, collecting
billions of text-image pairs for a specific domain can be time-consuming and
costly. Thus, ensuring high text-image correspondence without relying on
web-scale text-image datasets remains a challenging task. In this paper, we
present a novel approach for enhancing text-image correspondence by leveraging
available semantic layouts. Specifically, we propose a Gaussian-categorical
diffusion process that simultaneously generates both images and corresponding
layout pairs. Our experiments reveal that we can guide text-to-image generation
models to be aware of the semantics of different image regions, by training the
model to generate semantic labels for each pixel. We demonstrate that our
approach achieves higher text-image correspondence compared to existing
text-to-image generation approaches in the Multi-Modal CelebA-HQ and the
Cityscapes dataset, where text-image pairs are scarce. Codes are available in
this https://pmh9960.github.io/research/GCDP
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08158" title="Abstract">arXiv:2308.08158</a> [<a href="/pdf/2308.08158" title="Download PDF">pdf</a>, <a href="/format/2308.08158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Imputation Model for Missing Not At Random Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jialei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Data analysis usually suffers from the Missing Not At Random (MNAR) problem,
where the cause of the value missing is not fully observed. Compared to the
naive Missing Completely At Random (MCAR) problem, it is more in line with the
realistic scenario whereas more complex and challenging. Existing statistical
methods model the MNAR mechanism by different decomposition of the joint
distribution of the complete data and the missing mask. But we empirically find
that directly incorporating these statistical methods into deep generative
models is sub-optimal. Specifically, it would neglect the confidence of the
reconstructed mask during the MNAR imputation process, which leads to
insufficient information extraction and less-guaranteed imputation quality. In
this paper, we revisit the MNAR problem from a novel perspective that the
complete data and missing mask are two modalities of incomplete data on an
equal footing. Along with this line, we put forward a generative-model-specific
joint probability decomposition method, conjunction model, to represent the
distributions of two modalities in parallel and extract sufficient information
from both complete data and missing mask. Taking a step further, we exploit a
deep generative imputation model, namely GNR, to process the real-world missing
mechanism in the latent space and concurrently impute the incomplete data and
reconstruct the missing mask. The experimental results show that our GNR
surpasses state-of-the-art MNAR baselines with significant margins (averagely
improved from 9.9% to 18.8% in RMSE) and always gives a better mask
reconstruction accuracy which makes the imputation more principle.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08159" title="Abstract">arXiv:2308.08159</a> [<a href="/pdf/2308.08159" title="Download PDF">pdf</a>, <a href="/ps/2308.08159" title="Download PostScript">ps</a>, <a href="/format/2308.08159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolution of Near-Field Beamforming and Its Impact on NOMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The resolution of near-field beamforming is an important metric to measure
how effectively users with different locations can be located. This letter
identifies the condition under which the resolution of near-field beamforming
is not perfect. This imperfect resolution means that one user's near-field beam
can be still useful to other users, which motivates the application of
non-orthogonal multiple access (NOMA). Both the analytical and simulation
results are developed to demonstrate that those near-field beams preconfigured
for legacy users can indeed be used to effectively serve additional NOMA users,
which improves the overall connectivity and system throughput.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08160" title="Abstract">arXiv:2308.08160</a> [<a href="/pdf/2308.08160" title="Download PDF">pdf</a>, <a href="/format/2308.08160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Adversarial Robustness of Compressed Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vora%2C+B">Brijesh Vora</a>, 
<a href="/search/cs?searchtype=author&query=Patwari%2C+K">Kartik Patwari</a>, 
<a href="/search/cs?searchtype=author&query=Hafiz%2C+S+M">Syed Mahbub Hafiz</a>, 
<a href="/search/cs?searchtype=author&query=Shafiq%2C+Z">Zubair Shafiq</a>, 
<a href="/search/cs?searchtype=author&query=Chuah%2C+C">Chen-Nee Chuah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The increasing size of Deep Neural Networks (DNNs) poses a pressing need for
model compression, particularly when employed on resource constrained devices.
Concurrently, the susceptibility of DNNs to adversarial attacks presents
another significant hurdle. Despite substantial research on both model
compression and adversarial robustness, their joint examination remains
underexplored. Our study bridges this gap, seeking to understand the effect of
adversarial inputs crafted for base models on their pruned versions. To examine
this relationship, we have developed a comprehensive benchmark across diverse
adversarial attacks and popular DNN models. We uniquely focus on models not
previously exposed to adversarial training and apply pruning schemes optimized
for accuracy and performance. Our findings reveal that while the benefits of
pruning enhanced generalizability, compression, and faster inference times are
preserved, adversarial robustness remains comparable to the base model. This
suggests that model compression while offering its unique advantages, does not
undermine adversarial robustness.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08162" title="Abstract">arXiv:2308.08162</a> [<a href="/pdf/2308.08162" title="Download PDF">pdf</a>, <a href="/format/2308.08162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretability Benchmark for Evaluating Spatial Misalignment of  Prototypical Parts Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sacha%2C+M">Miko&#x142;aj Sacha</a>, 
<a href="/search/cs?searchtype=author&query=Jura%2C+B">Bartosz Jura</a>, 
<a href="/search/cs?searchtype=author&query=Rymarczyk%2C+D">Dawid Rymarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Struski%2C+%C5%81">&#x141;ukasz Struski</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Zieli%C5%84ski%2C+B">Bartosz Zieli&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Code will be release upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prototypical parts-based networks are becoming increasingly popular due to
their faithful self-explanations. However, their similarity maps are calculated
in the penultimate network layer. Therefore, the receptive field of the
prototype activation region often depends on parts of the image outside this
region, which can lead to misleading interpretations. We name this undesired
behavior a spatial explanation misalignment and introduce an interpretability
benchmark with a set of dedicated metrics for quantifying this phenomenon. In
addition, we propose a method for misalignment compensation and apply it to
existing state-of-the-art models. We show the expressiveness of our benchmark
and the effectiveness of the proposed compensation methodology through
extensive empirical studies.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08163" title="Abstract">arXiv:2308.08163</a> [<a href="/pdf/2308.08163" title="Download PDF">pdf</a>, <a href="/format/2308.08163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristics of networks generated by kernel growing neural gas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujita%2C+K">Kazuhisa Fujita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This research aims to develop kernel GNG, a kernelized version of the growing
neural gas (GNG) algorithm, and to investigate the features of the networks
generated by the kernel GNG. The GNG is an unsupervised artificial neural
network that can transform a dataset into an undirected graph, thereby
extracting the features of the dataset as a graph. The GNG is widely used in
vector quantization, clustering, and 3D graphics. Kernel methods are often used
to map a dataset to feature space, with support vector machines being the most
prominent application. This paper introduces the kernel GNG approach and
explores the characteristics of the networks generated by kernel GNG. Five
kernels, including Gaussian, Laplacian, Cauchy, inverse multiquadric, and log
kernels, are used in this study.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08164" title="Abstract">arXiv:2308.08164</a> [<a href="/pdf/2308.08164" title="Download PDF">pdf</a>, <a href="/ps/2308.08164" title="Download PostScript">ps</a>, <a href="/format/2308.08164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Push-Pull Method for Decentralized Optimization via  State Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheng%2C+H">Huqiang Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+X">Xiaofeng Liao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Huaqing Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">You Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Distributed optimization is manifesting great potential in multiple fields,
e.g., machine learning, control, and resource allocation. Existing
decentralized optimization algorithms require sharing explicit state
information among the agents, which raises the risk of private information
leakage. To ensure privacy security, combining information security mechanisms,
such as differential privacy and homomorphic encryption, with traditional
decentralized optimization algorithms is a commonly used means. However, this
would either sacrifice optimization accuracy or incur heavy computational
burden. To overcome these shortcomings, we develop a novel privacy-preserving
decentralized optimization algorithm, called PPSD, that combines gradient
tracking with a state decomposition mechanism. Specifically, each agent
decomposes its state associated with the gradient into two substates. One
substate is used for interaction with neighboring agents, and the other
substate containing private information acts only on the first substate and
thus is entirely agnostic to other agents. For the strongly convex and smooth
objective functions, PPSD attains a $R$-linear convergence rate. Moreover, the
algorithm can preserve the agents' private information from being leaked to
honest-but-curious neighbors. Simulations further confirm the results.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08168" title="Abstract">arXiv:2308.08168</a> [<a href="/pdf/2308.08168" title="Download PDF">pdf</a>, <a href="/format/2308.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Software Service Platform and its Application in a Smart  Mobility Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilken%2C+N">Nils Wilken</a>, 
<a href="/search/cs?searchtype=author&query=Knieke%2C+C">Christoph Knieke</a>, 
<a href="/search/cs?searchtype=author&query=Nyakam%2C+E">Eric Nyakam</a>, 
<a href="/search/cs?searchtype=author&query=Rausch%2C+A">Andreas Rausch</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+C">Christian Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Ziebura%2C+N">Nikolaus Ziebura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented on The Fifteenth International Conference on Adaptive and Self-Adaptive Systems and Applications (ADAPTIVE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The development dynamics of digital innovations for industry, business, and
society are producing complex system conglomerates that can no longer be
designed centrally and hierarchically in classic development processes.
Instead, systems are evolving in DevOps processes in which heterogeneous actors
act together on an open platform. Influencing and controlling such dynamically
and autonomously changing system landscapes is currently a major challenge and
a fundamental interest of service users and providers, as well as operators of
the platform infrastructures. In this paper, we propose an architecture for
such an emergent software service platform. A software platform that implements
this architecture with the underlying engineering methodology is demonstrated
by a smart parking lot scenario.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08169" title="Abstract">arXiv:2308.08169</a> [<a href="/pdf/2308.08169" title="Download PDF">pdf</a>, <a href="/format/2308.08169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Performance on Seen and Unseen Dialogue Scenarios using  Retrieval-Augmented End-to-End Task-Oriented System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Roller%2C+S">Stephen Roller</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+K">Kun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+R">Rui Meng</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIGDIAL 2023 as a long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">End-to-end task-oriented dialogue (TOD) systems have achieved promising
performance by leveraging sophisticated natural language understanding and
natural language generation capabilities of pre-trained models. This work
enables the TOD systems with more flexibility through a simple cache. The cache
provides the flexibility to dynamically update the TOD systems and handle both
existing and unseen dialogue scenarios. Towards this end, we first fine-tune a
retrieval module to effectively retrieve the most relevant information entries
from the cache. We then train end-to-end TOD models that can refer to and
ground on both dialogue history and retrieved information during TOD
generation. The cache is straightforward to construct, and the backbone models
of TOD systems are compatible with existing pre-trained generative models.
Extensive experiments demonstrate the superior performance of our framework,
with a notable improvement in non-empty joint goal accuracy by 6.7% compared to
strong baselines.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08173" title="Abstract">arXiv:2308.08173</a> [<a href="/pdf/2308.08173" title="Download PDF">pdf</a>, <a href="/format/2308.08173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressivity of Graph Neural Networks Through the Lens of Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campi%2C+F">Francesco Campi</a>, 
<a href="/search/cs?searchtype=author&query=Gosch%2C+L">Lukas Gosch</a>, 
<a href="/search/cs?searchtype=author&query=Wollschl%C3%A4ger%2C+T">Tom Wollschl&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ${2}^{nd}$ AdvML Frontiers workshop at ${40}^{th}$ International Conference on Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We perform the first adversarial robustness study into Graph Neural Networks
(GNNs) that are provably more powerful than traditional Message Passing Neural
Networks (MPNNs). In particular, we use adversarial robustness as a tool to
uncover a significant gap between their theoretically possible and empirically
achieved expressive power. To do so, we focus on the ability of GNNs to count
specific subgraph patterns, which is an established measure of expressivity,
and extend the concept of adversarial robustness to this task. Based on this,
we develop efficient adversarial attacks for subgraph counting and show that
more powerful GNNs fail to generalize even to small perturbations to the
graph's structure. Expanding on this, we show that such architectures also fail
to count substructures on out-of-distribution graphs.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08174" title="Abstract">arXiv:2308.08174</a> [<a href="/pdf/2308.08174" title="Download PDF">pdf</a>, <a href="/format/2308.08174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Generic Graph Neural Networks via Architecture, Compiler,  Partition Method Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jingwen Leng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yangjie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph neural networks (GNNs) have shown significant accuracy improvements in
a variety of graph learning domains, sparking considerable research interest.
To translate these accuracy improvements into practical applications, it is
essential to develop high-performance and efficient hardware acceleration for
GNN models. However, designing GNN accelerators faces two fundamental
challenges: the high bandwidth requirement of GNN models and the diversity of
GNN models. Previous works have addressed the first challenge by using more
expensive memory interfaces to achieve higher bandwidth. For the second
challenge, existing works either support specific GNN models or have generic
designs with poor hardware utilization.
<br />In this work, we tackle both challenges simultaneously. First, we identify a
new type of partition-level operator fusion, which we utilize to internally
reduce the high bandwidth requirement of GNNs. Next, we introduce
partition-level multi-threading to schedule the concurrent processing of graph
partitions, utilizing different hardware resources. To further reduce the extra
on-chip memory required by multi-threading, we propose fine-grained graph
partitioning to generate denser graph partitions. Importantly, these three
methods make no assumptions about the targeted GNN models, addressing the
challenge of model variety. We implement these methods in a framework called
SwitchBlade, consisting of a compiler, a graph partitioner, and a hardware
accelerator. Our evaluation demonstrates that SwitchBlade achieves an average
speedup of $1.85\times$ and energy savings of $19.03\times$ compared to the
NVIDIA V100 GPU. Additionally, SwitchBlade delivers performance comparable to
state-of-the-art specialized accelerators.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08176" title="Abstract">arXiv:2308.08176</a> [<a href="/pdf/2308.08176" title="Download PDF">pdf</a>, <a href="/format/2308.08176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSpell: Retrieval-augmented Framework for Domain Adaptive Chinese  Spelling Check
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Siqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+L">Lei Geng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziqiang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+G">Guohong Fu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NLPCC2023 oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chinese Spelling Check (CSC) refers to the detection and correction of
spelling errors in Chinese texts. In practical application scenarios, it is
important to make CSC models have the ability to correct errors across
different domains. In this paper, we propose a retrieval-augmented spelling
check framework called RSpell, which searches corresponding domain terms and
incorporates them into CSC models. Specifically, we employ pinyin fuzzy
matching to search for terms, which are combined with the input and fed into
the CSC model. Then, we introduce an adaptive process control mechanism to
dynamically adjust the impact of external knowledge on the model. Additionally,
we develop an iterative strategy for the RSpell framework to enhance reasoning
capabilities. We conducted experiments on CSC datasets in three domains: law,
medicine, and official document writing. The results demonstrate that RSpell
achieves state-of-the-art performance in both zero-shot and fine-tuning
scenarios, demonstrating the effectiveness of the retrieval-augmented CSC
framework. Our code is available at https://github.<a href="/abs/com/4777777">com/4777777</a>7/Rspell.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08179" title="Abstract">arXiv:2308.08179</a> [<a href="/pdf/2308.08179" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Integrated Multi-Strategy Bus Control System via Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nie%2C+Q">Qinghui Nie</a>, 
<a href="/search/eess?searchtype=author&query=Ou%2C+J">Jishun Ou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Haiyang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jiawei Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+H">Haotian Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">An efficient urban bus control system has the potential to significantly
reduce travel delays and streamline the allocation of transportation resources,
thereby offering enhanced and user-friendly transit services to passengers.
However, bus operation efficiency can be impacted by bus bunching. This problem
is notably exacerbated when the bus system operates along a signalized corridor
with unpredictable travel demand. To mitigate this challenge, we introduce a
multi-strategy fusion approach for the longitudinal control of connected and
automated buses. The approach is driven by a physics-informed deep
reinforcement learning (DRL) algorithm and takes into account a variety of
traffic conditions along urban signalized corridors. Taking advantage of
connected and autonomous vehicle (CAV) technology, the proposed approach can
leverage real-time information regarding bus operating conditions and road
traffic environment. By integrating the aforementioned information into the
DRL-based bus control framework, our designed physics-informed DRL state fusion
approach and reward function efficiently embed prior physics and leverage the
merits of equilibrium and consensus concepts from control theory. This
integration enables the framework to learn and adapt multiple control
strategies to effectively manage complex traffic conditions and fluctuating
passenger demands. Three control variables, i.e., dwell time at stops, speed
between stations, and signal priority, are formulated to minimize travel
duration and ensure bus stability with the aim of avoiding bus bunching. We
present simulation results to validate the effectiveness of the proposed
approach, underlining its superior performance when subjected to sensitivity
analysis, specifically considering factors such as traffic volume, desired
speed, and traffic signal conditions.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08181" title="Abstract">arXiv:2308.08181</a> [<a href="/pdf/2308.08181" title="Download PDF">pdf</a>, <a href="/ps/2308.08181" title="Download PostScript">ps</a>, <a href="/format/2308.08181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChinaTelecom System Description to VoxCeleb Speaker Recognition  Challenge 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengjie Du</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> System description of VoxSRC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This technical report describes ChinaTelecom system for Track 1 (closed) of
the VoxCeleb2023 Speaker Recognition Challenge (VoxSRC 2023). Our system
consists of several ResNet variants trained only on VoxCeleb2, which were fused
for better performance later. Score calibration was also applied for each
variant and the fused system. The final submission achieved minDCF of 0.1066
and EER of 1.980%.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08182" title="Abstract">arXiv:2308.08182</a> [<a href="/pdf/2308.08182" title="Download PDF">pdf</a>, <a href="/format/2308.08182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Domain Adaptive Detection with Network Stability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenzhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tiejian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCV,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain adaptive detection aims to improve the generality of a detector,
learned from the labeled source domain, on the unlabeled target domain. In this
work, drawing inspiration from the concept of stability from the control theory
that a robust system requires to remain consistent both externally and
internally regardless of disturbances, we propose a novel framework that
achieves unsupervised domain adaptive detection through stability analysis. In
specific, we treat discrepancies between images and regions from different
domains as disturbances, and introduce a novel simple but effective Network
Stability Analysis (NSA) framework that considers various disturbances for
domain adaptation. Particularly, we explore three types of perturbations
including heavy and light image-level disturbances and instancelevel
disturbance. For each type, NSA performs external consistency analysis on the
outputs from raw and perturbed images and/or internal consistency analysis on
their features, using teacher-student models. By integrating NSA into Faster
R-CNN, we immediately achieve state-of-the-art results. In particular, we set a
new record of 52.7% mAP on Cityscapes-to-FoggyCityscapes, showing the potential
of NSA for domain adaptive detection. It is worth noticing, our NSA is designed
for general purpose, and thus applicable to one-stage detection model (e.g.,
FCOS) besides the adopted one, as shown by experiments.
https://github.com/tiankongzhang/NSA.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08187" title="Abstract">arXiv:2308.08187</a> [<a href="/pdf/2308.08187" title="Download PDF">pdf</a>, <a href="/format/2308.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Endogenous Macrodynamics in Algorithmic Recourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altmeyer%2C+P">Patrick Altmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Angela%2C+G">Giovan Angela</a>, 
<a href="/search/cs?searchtype=author&query=Buszydlik%2C+A">Aleksander Buszydlik</a>, 
<a href="/search/cs?searchtype=author&query=Dobiczek%2C+K">Karol Dobiczek</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>, 
<a href="/search/cs?searchtype=author&query=Liem%2C+C+C+S">Cynthia C. S. Liem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures. Originally published at the 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). IEEE holds the copyright
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in 2023 IEEE Conference on Secure and Trustworthy Machine Learning
  (SaTML), Raleigh, NC, USA, 2023 pp. 418-431
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse
(AR) has largely focused on single individuals in a static environment: given
some estimated model, the goal is to find valid counterfactuals for an
individual instance that fulfill various desiderata. The ability of such
counterfactuals to handle dynamics like data and model drift remains a largely
unexplored research challenge. There has also been surprisingly little work on
the related question of how the actual implementation of recourse by one
individual may affect other individuals. Through this work, we aim to close
that gap. We first show that many of the existing methodologies can be
collectively described by a generalized framework. We then argue that the
existing framework does not account for a hidden external cost of recourse,
that only reveals itself when studying the endogenous dynamics of recourse at
the group level. Through simulation experiments involving various state-of
the-art counterfactual generators and several benchmark datasets, we generate
large numbers of counterfactuals and study the resulting domain and model
shifts. We find that the induced shifts are substantial enough to likely impede
the applicability of Algorithmic Recourse in some situations. Fortunately, we
find various strategies to mitigate these concerns. Our simulation framework
for studying recourse dynamics is fast and opensourced.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08190" title="Abstract">arXiv:2308.08190</a> [<a href="/pdf/2308.08190" title="Download PDF">pdf</a>, <a href="/format/2308.08190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling the Spread of COVID-19 in Indoor Spaces using Automated  Probabilistic Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harmanani%2C+M">Mohamed Harmanani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages. Presented at ICAPS 2023 Scheduling and Planning Applications woRKshop (SPARK 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The coronavirus disease 2019 (COVID-19) pandemic has been ongoing for around
3 years, and has infected over 750 million people and caused over 6 million
deaths worldwide at the time of writing. Throughout the pandemic, several
strategies for controlling the spread of the disease have been debated by
healthcare professionals, government authorities, and international bodies. To
anticipate the potential impact of the disease, and to simulate the
effectiveness of different mitigation strategies, a robust model of disease
spread is needed. In this work, we explore a novel approach based on
probabilistic planning and dynamic graph analysis to model the spread of
COVID-19 in indoor spaces. We endow the planner with means to control the
spread of the disease through non-pharmaceutical interventions (NPIs) such as
mandating masks and vaccines, and we compare the impact of crowds and capacity
limits on the spread of COVID-19 in these settings. We demonstrate that the use
of probabilistic planning is effective in predicting the amount of infections
that are likely to occur in shared spaces, and that automated planners have the
potential to design competent interventions to limit the spread of the disease.
Our code is fully open-source and is available at:
https://github.com/mharmanani/prob-planning-covid19 .
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08192" title="Abstract">arXiv:2308.08192</a> [<a href="/pdf/2308.08192" title="Download PDF">pdf</a>, <a href="/format/2308.08192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Vision-Based Parking Slot Detection and Occupancy  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grbi%C4%87%2C+R">Ratko Grbi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+B">Brando Koch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 8 figures, 9 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 225, 1 September 2023,
  120147
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Parking guidance information (PGI) systems are used to provide information to
drivers about the nearest parking lots and the number of vacant parking slots.
Recently, vision-based solutions started to appear as a cost-effective
alternative to standard PGI systems based on hardware sensors mounted on each
parking slot. Vision-based systems provide information about parking occupancy
based on images taken by a camera that is recording a parking lot. However,
such systems are challenging to develop due to various possible viewpoints,
weather conditions, and object occlusions. Most notably, they require manual
labeling of parking slot locations in the input image which is sensitive to
camera angle change, replacement, or maintenance. In this paper, the algorithm
that performs Automatic Parking Slot Detection and Occupancy Classification
(APSD-OC) solely on input images is proposed. Automatic parking slot detection
is based on vehicle detections in a series of parking lot images upon which
clustering is applied in bird's eye view to detect parking slots. Once the
parking slots positions are determined in the input image, each detected
parking slot is classified as occupied or vacant using a specifically trained
ResNet34 deep classifier. The proposed approach is extensively evaluated on
well-known publicly available datasets (PKLot and CNRPark+EXT), showing high
efficiency in parking slot detection and robustness to the presence of illegal
parking or passing vehicles. Trained classifier achieves high accuracy in
parking slot occupancy classification.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08198" title="Abstract">arXiv:2308.08198</a> [<a href="/pdf/2308.08198" title="Download PDF">pdf</a>, <a href="/format/2308.08198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chiyue Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages main text, 10 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Subgraph counting is the problem of counting the occurrences of a given query
graph in a large target graph. Large-scale subgraph counting is useful in
various domains, such as motif counting for social network analysis and loop
counting for money laundering detection on transaction networks. Recently, to
address the exponential runtime complexity of scalable subgraph counting,
neural methods are proposed. However, existing neural counting approaches fall
short in three aspects. Firstly, the counts of the same query can vary from
zero to millions on different target graphs, posing a much larger challenge
than most graph regression tasks. Secondly, current scalable graph neural
networks have limited expressive power and fail to efficiently distinguish
graphs in count prediction. Furthermore, existing neural approaches cannot
predict the occurrence position of queries in the target graph.
<br />Here we design DeSCo, a scalable neural deep subgraph counting pipeline,
which aims to accurately predict the query count and occurrence position on any
target graph after one-time training. Firstly, DeSCo uses a novel canonical
partition and divides the large target graph into small neighborhood graphs.
The technique greatly reduces the count variation while guaranteeing no missing
or double-counting. Secondly, neighborhood counting uses an expressive
subgraph-based heterogeneous graph neural network to accurately perform
counting in each neighborhood. Finally, gossip propagation propagates
neighborhood counts with learnable gates to harness the inductive biases of
motif counts. DeSCo is evaluated on eight real-world datasets from various
domains. It outperforms state-of-the-art neural methods with 137x improvement
in the mean squared error of count prediction, while maintaining the polynomial
runtime complexity.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08200" title="Abstract">arXiv:2308.08200</a> [<a href="/pdf/2308.08200" title="Download PDF">pdf</a>, <a href="/format/2308.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Ontology-Mediated Planning with OWL DL Ontologies (Extended  Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=John%2C+T">Tobias John</a>, 
<a href="/search/cs?searchtype=author&query=Koopmann%2C+P">Patrick Koopmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a paper accepted at 36th International Workshop on Description Logics (DL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">While classical planning languages make the closed-domain and closed-world
assumption, there have been various approaches to extend those with DL
reasoning, which is then interpreted under the usual open-world semantics.
Current approaches for planning with DL ontologies integrate the DL directly
into the planning language, and practical approaches have been developed based
on first-order rewritings or rewritings into datalog. We present here a new
approach in which the planning specification and ontology are kept separate,
and are linked together using an interface. This allows planning experts to
work in a familiar formalism, while existing ontologies can be easily
integrated and extended by ontology experts. Our approach for planning with
those ontology-mediated planning problems is optimized for cases with
comparatively small domains, and supports the whole OWL DL fragment. The idea
is to rewrite the ontology-mediated planning problem into a classical planning
problem to be processed by existing planning tools. Different to other
approaches, our rewriting is data-dependent. A first experimental evaluation of
our approach shows the potential and limitations of this approach.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08201" title="Abstract">arXiv:2308.08201</a> [<a href="/pdf/2308.08201" title="Download PDF">pdf</a>, <a href="/format/2308.08201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Polar Encoding with Applications in Non-Coherent Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mengfan Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In coding theory, an error-correcting code can be encoded either
systematically or non-systematically. In a systematic encode, the input data is
embedded in the encoded output. Conversely, in a non-systematic code, the
output does not contain the input symbols. In this paper, we propose a hybrid
encoding scheme for polar codes, in which some data bits are systematically
encoded while the rest are non-systematically encoded. Based on the proposed
scheme, we design a joint channel estimation and data decoding scheme. We use
the systematic bits in the hybrid encoding scheme as pilots for channel
estimation. To mitigate the code rate loss caused by the pilots and to provide
additional error detecting capability, we propose a dynamic pilot design by
building connections between the systematic bits and non-systematic bits.
Simulation results show that the performance of the proposed scheme approaches
that of the traditional non-systematic polar coding scheme with perfect channel
state information (CSI) with the increase of SNR.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08203" title="Abstract">arXiv:2308.08203</a> [<a href="/pdf/2308.08203" title="Download PDF">pdf</a>, <a href="/format/2308.08203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epicure: Distilling Sequence Model Predictions into Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allamanis%2C+M">Miltiadis Allamanis</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+E+T">Earl T. Barr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Most machine learning models predict a probability distribution over concrete
outputs and struggle to accurately predict names over high entropy sequence
distributions. Here, we explore finding abstract, high-precision patterns
intrinsic to these predictions in order to make abstract predictions that
usefully capture rare sequences. In this short paper, we present Epicure, a
method that distils the predictions of a sequence model, such as the output of
beam search, into simple patterns. Epicure maps a model's predictions into a
lattice that represents increasingly more general patterns that subsume the
concrete model predictions.
<br />On the tasks of predicting a descriptive name of a function given the source
code of its body and detecting anomalous names given a function, we show that
Epicure yields accurate naming patterns that match the ground truth more often
compared to just the highest probability model prediction. For a false alarm
rate of 10%, Epicure predicts patterns that match 61% more ground-truth names
compared to the best model prediction, making Epicure well-suited for scenarios
that require high precision.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08204" title="Abstract">arXiv:2308.08204</a> [<a href="/pdf/2308.08204" title="Download PDF">pdf</a>, <a href="/format/2308.08204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCoSA: Momentum Contrast for Knowledge Graph Completion with  Structure-Augmented Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabang He</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+L">Liu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts
within knowledge graphs and automatically infer missing links. Existing methods
can mainly be categorized into structure-based or description-based. On the one
hand, structure-based methods effectively represent relational facts in
knowledge graphs using entity embeddings. However, they struggle with
semantically rich real-world entities due to limited structural information and
fail to generalize to unseen entities. On the other hand, description-based
methods leverage pre-trained language models (PLMs) to understand textual
information. They exhibit strong robustness towards unseen entities. However,
they have difficulty with larger negative sampling and often lag behind
structure-based methods. To address these issues, in this paper, we propose
Momentum Contrast for knowledge graph completion with Structure-Augmented
pre-trained language models (MoCoSA), which allows the PLM to perceive the
structural information by the adaptable structure encoder. To improve learning
efficiency, we proposed momentum hard negative and intra-relation negative
sampling. Experimental results demonstrate that our approach achieves
state-of-the-art performance in terms of mean reciprocal rank (MRR), with
improvements of 2.5% on WN18RR and 21% on OpenBG500.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08206" title="Abstract">arXiv:2308.08206</a> [<a href="/pdf/2308.08206" title="Download PDF">pdf</a>, <a href="/format/2308.08206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Multi-View Deep Networks Methodology for Experimental  Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nadav Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Tzdaka%2C+M">Muriel Tzdaka</a>, 
<a href="/search/cs?searchtype=author&query=Sturm%2C+G">Galit Sturm</a>, 
<a href="/search/cs?searchtype=author&query=Lazovski%2C+G">Guy Lazovski</a>, 
<a href="/search/cs?searchtype=author&query=Bar%2C+G">Galit Bar</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gilad Oren</a>, 
<a href="/search/cs?searchtype=author&query=Gvishi%2C+R">Raz Gvishi</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Physical experiments often involve multiple imaging representations, such as
X-ray scans and microscopic images. Deep learning models have been widely used
for supervised analysis in these experiments. Combining different image
representations is frequently required to analyze and make a decision properly.
Consequently, multi-view data has emerged - datasets where each sample is
described by views from different angles, sources, or modalities. These
problems are addressed with the concept of multi-view learning. Understanding
the decision-making process of deep learning models is essential for reliable
and credible analysis. Hence, many explainability methods have been devised
recently. Nonetheless, there is a lack of proper explainability in multi-view
models, which are challenging to explain due to their architectures. In this
paper, we suggest different multi-view architectures for the vision domain,
each suited to another problem, and we also present a methodology for
explaining these models. To demonstrate the effectiveness of our methodology,
we focus on the domain of High Energy Density Physics (HEDP) experiments, where
multiple imaging representations are used to assess the quality of foam
samples. We apply our methodology to classify the foam samples quality using
the suggested multi-view architectures. Through experimental results, we
showcase the improvement of accurate architecture choice on both accuracy - 78%
to 84% and AUC - 83% to 93% and present a trade-off between performance and
explainability. Specifically, we demonstrate that our approach enables the
explanation of individual one-view models, providing insights into the
decision-making process of each view. This understanding enhances the
interpretability of the overall multi-view model. The sources of this work are
available at:
https://github.com/Scientific-Computing-Lab-NRCN/Multi-View-Explainability.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08213" title="Abstract">arXiv:2308.08213</a> [<a href="/pdf/2308.08213" title="Download PDF">pdf</a>, <a href="/format/2308.08213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for  Long-tailed Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Long-tailed distribution of semantic categories, which has been often ignored
in conventional methods, causes unsatisfactory performance in semantic
segmentation on tail categories. In this paper, we focus on the problem of
long-tailed semantic segmentation. Although some long-tailed recognition
methods (e.g., re-sampling/re-weighting) have been proposed in other problems,
they can probably compromise crucial contextual information and are thus hardly
adaptable to the problem of long-tailed semantic segmentation. To address this
issue, we propose MEDOE, a novel framework for long-tailed semantic
segmentation via contextual information ensemble-and-grouping. The proposed
two-sage framework comprises a multi-expert decoder (MED) and a multi-expert
output ensemble (MOE). Specifically, the MED includes several "experts". Based
on the pixel frequency distribution, each expert takes the dataset masked
according to the specific categories as input and generates contextual
information self-adaptively for classification; The MOE adopts learnable
decision weights for the ensemble of the experts' outputs. As a model-agnostic
framework, our MEDOE can be flexibly and efficiently coupled with various
popular deep neural networks (e.g., DeepLabv3+, OCRNet, and PSPNet) to improve
their performance in long-tailed semantic segmentation. Experimental results
show that the proposed framework outperforms the current methods on both
Cityscapes and ADE20K datasets by up to 1.78% in mIoU and 5.89% in mAcc.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08218" title="Abstract">arXiv:2308.08218</a> [<a href="/pdf/2308.08218" title="Download PDF">pdf</a>, <a href="/format/2308.08218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressivity of Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Manjot Singh</a>, 
<a href="/search/cs?searchtype=author&query=Fono%2C+A">Adalbert Fono</a>, 
<a href="/search/cs?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This article studies the expressive power of spiking neural networks where
information is encoded in the firing time of neurons. The implementation of
spiking neural networks on neuromorphic hardware presents a promising choice
for future energy-efficient AI applications. However, there exist very few
results that compare the computational power of spiking neurons to arbitrary
threshold circuits and sigmoidal neurons. Additionally, it has also been shown
that a network of spiking neurons is capable of approximating any continuous
function. By using the Spike Response Model as a mathematical model of a
spiking neuron and assuming a linear response function, we prove that the
mapping generated by a network of spiking neurons is continuous piecewise
linear. We also show that a spiking neural network can emulate the output of
any multi-layer (ReLU) neural network. Furthermore, we show that the maximum
number of linear regions generated by a spiking neuron scales exponentially
with respect to the input dimension, a characteristic that distinguishes it
significantly from an artificial (ReLU) neuron. Our results further extend the
understanding of the approximation properties of spiking neural networks and
open up new avenues where spiking neural networks can be deployed instead of
artificial neural networks without any performance loss.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08220" title="Abstract">arXiv:2308.08220</a> [<a href="/pdf/2308.08220" title="Download PDF">pdf</a>, <a href="/format/2308.08220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Light Image Enhancement with Illumination-Aware Gamma Correction and  Complete Image Modelling Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel network structure with illumination-aware gamma
correction and complete image modelling to solve the low-light image
enhancement problem. Low-light environments usually lead to less informative
large-scale dark areas, directly learning deep representations from low-light
images is insensitive to recovering normal illumination. We propose to
integrate the effectiveness of gamma correction with the strong modelling
capacities of deep networks, which enables the correction factor gamma to be
learned in a coarse to elaborate manner via adaptively perceiving the deviated
illumination. Because exponential operation introduces high computational
complexity, we propose to use Taylor Series to approximate gamma correction,
accelerating the training and inference speed. Dark areas usually occupy large
scales in low-light images, common local modelling structures, e.g., CNN,
SwinIR, are thus insufficient to recover accurate illumination across whole
low-light images. We propose a novel Transformer block to completely simulate
the dependencies of all pixels across images via a local-to-global hierarchical
attention mechanism, so that dark areas could be inferred by borrowing the
information from far informative regions in a highly effective manner.
Extensive experiments on several benchmark datasets demonstrate that our
approach outperforms state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08222" title="Abstract">arXiv:2308.08222</a> [<a href="/pdf/2308.08222" title="Download PDF">pdf</a>, <a href="/format/2308.08222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperSNN: A new efficient and robust deep learning model for resource  constrained control applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhanglu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kaiwen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W">Wong-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In light of the increasing adoption of edge computing in areas such as
intelligent furniture, robotics, and smart homes, this paper introduces
HyperSNN, an innovative method for control tasks that uses spiking neural
networks (SNNs) in combination with hyperdimensional computing. HyperSNN
substitutes expensive 32-bit floating point multiplications with 8-bit integer
additions, resulting in reduced energy consumption while enhancing robustness
and potentially improving accuracy. Our model was tested on AI Gym benchmarks,
including Cartpole, Acrobot, MountainCar, and Lunar Lander. HyperSNN achieves
control accuracies that are on par with conventional machine learning methods
but with only 1.36% to 9.96% of the energy expenditure. Furthermore, our
experiments showed increased robustness when using HyperSNN. We believe that
HyperSNN is especially suitable for interactive, mobile, and wearable devices,
promoting energy-efficient and robust system design. Furthermore, it paves the
way for the practical implementation of complex algorithms like model
predictive control (MPC) in real-world industrial scenarios.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08224" title="Abstract">arXiv:2308.08224</a> [<a href="/pdf/2308.08224" title="Download PDF">pdf</a>, <a href="/format/2308.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How To Overcome Confirmation Bias in Semi-Supervised Image  Classification By Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilhuber%2C+S">Sandra Gilhuber</a>, 
<a href="/search/cs?searchtype=author&query=Hvingelby%2C+R">Rasmus Hvingelby</a>, 
<a href="/search/cs?searchtype=author&query=Fok%2C+M+L+A">Mang Ling Ada Fok</a>, 
<a href="/search/cs?searchtype=author&query=Seidl%2C+T">Thomas Seidl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted @ ECML PKDD 2023. This is the author's version of the work. The definitive Version of Record will be published in the Proceedings of ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Do we need active learning? The rise of strong deep semi-supervised methods
raises doubt about the usability of active learning in limited labeled data
settings. This is caused by results showing that combining semi-supervised
learning (SSL) methods with a random selection for labeling can outperform
existing active learning (AL) techniques. However, these results are obtained
from experiments on well-established benchmark datasets that can overestimate
the external validity. However, the literature lacks sufficient research on the
performance of active semi-supervised learning methods in realistic data
scenarios, leaving a notable gap in our understanding. Therefore we present
three data challenges common in real-world applications: between-class
imbalance, within-class imbalance, and between-class similarity. These
challenges can hurt SSL performance due to confirmation bias. We conduct
experiments with SSL and AL on simulated data challenges and find that random
sampling does not mitigate confirmation bias and, in some cases, leads to worse
performance than supervised learning. In contrast, we demonstrate that AL can
overcome confirmation bias in SSL in these realistic settings. Our results
provide insights into the potential of combining active and semi-supervised
learning in the presence of common real-world challenges, which is a promising
direction for robust methods when learning with limited labeled data in
real-world applications.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08227" title="Abstract">arXiv:2308.08227</a> [<a href="/pdf/2308.08227" title="Download PDF">pdf</a>, <a href="/format/2308.08227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherent Redundancy in Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+M">Man Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiakui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guangshe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoqi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) are well known as a promising energy-efficient
alternative to conventional artificial neural networks. Subject to the
preconceived impression that SNNs are sparse firing, the analysis and
optimization of inherent redundancy in SNNs have been largely overlooked, thus
the potential advantages of spike-based neuromorphic computing in accuracy and
energy efficiency are interfered. In this work, we pose and focus on three key
questions regarding the inherent redundancy in SNNs. We argue that the
redundancy is induced by the spatio-temporal invariance of SNNs, which enhances
the efficiency of parameter utilization but also invites lots of noise spikes.
Further, we analyze the effect of spatio-temporal invariance on the
spatio-temporal dynamics and spike firing of SNNs. Then, motivated by these
analyses, we propose an Advance Spatial Attention (ASA) module to harness SNNs'
redundancy, which can adaptively optimize their membrane potential distribution
by a pair of individual spatial attention sub-modules. In this way, noise spike
features are accurately regulated. Experimental results demonstrate that the
proposed method can significantly drop the spike firing with better performance
than state-of-the-art SNN baselines. Our code is available in
\url{https://github.com/BICLab/ASA-SNN}.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08229" title="Abstract">arXiv:2308.08229</a> [<a href="/pdf/2308.08229" title="Download PDF">pdf</a>, <a href="/format/2308.08229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite Disturbance Filtering: A Novel State Estimation Scheme for  Systems With Multi-Source, Heterogeneous, and Isomeric Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Lei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wenshuo Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yukai Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zidong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State estimation has long been a fundamental problem in signal processing and
control areas. The main challenge is to design filters with ability to reject
or attenuate various disturbances. With the arrival of big data era, the
disturbances of complicated systems are physically multi-source, mathematically
heterogenous, affecting the system dynamics via isomeric (additive,
multiplicative and recessive) channels, and deeply coupled with each other. In
traditional filtering schemes, the multi-source heterogenous disturbances are
usually simplified as a lumped one so that the "single" disturbance can be
either rejected or attenuated. Since the pioneering work in 2012, a novel state
estimation methodology called {\it composite disturbance filtering} (CDF) has
been proposed, which deals with the multi-source, heterogenous, and isomeric
disturbances based on their specific characteristics. With the CDF, enhanced
anti-disturbance capability can be achieved via refined quantification,
effective separation, and simultaneous rejection and attenuation of the
disturbances. In this paper, an overview of the CDF scheme is provided, which
includes the basic principle, general design procedure, application scenarios
(e.g. alignment, localization and navigation), and future research directions.
In summary, it is expected that the CDF offers an effective tool for state
estimation, especially in the presence of multi-source heterogeneous
disturbances.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08230" title="Abstract">arXiv:2308.08230</a> [<a href="/pdf/2308.08230" title="Download PDF">pdf</a>, <a href="/format/2308.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Winograd Convolution for Cost-effective Neural Network Fault  Tolerance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xinghua Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haitong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Winograd is generally utilized to optimize convolution performance and
computational efficiency because of the reduced multiplication operations, but
the reliability issues brought by winograd are usually overlooked. In this
work, we observe the great potential of winograd convolution in improving
neural network (NN) fault tolerance. Based on the observation, we evaluate
winograd convolution fault tolerance comprehensively from different
granularities ranging from models, layers, and operation types for the first
time. Then, we explore the use of inherent fault tolerance of winograd
convolution for cost-effective NN protection against soft errors. Specifically,
we mainly investigate how winograd convolution can be effectively incorporated
with classical fault-tolerant design approaches including triple modular
redundancy (TMR), fault-aware retraining, and constrained activation functions.
According to our experiments, winograd convolution can reduce the
fault-tolerant design overhead by 55.77\% on average without any accuracy loss
compared to standard convolution, and further reduce the computing overhead by
17.24\% when the inherent fault tolerance of winograd convolution is
considered. When it is applied on fault-tolerant neural networks enhanced with
fault-aware retraining and constrained activation functions, the resulting
model accuracy generally shows significant improvement in presence of various
faults.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08231" title="Abstract">arXiv:2308.08231</a> [<a href="/pdf/2308.08231" title="Download PDF">pdf</a>, <a href="/format/2308.08231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDF-HO: Hand-Held Object Reconstruction via Conditional Directed  Distance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyangguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yan Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruida Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangyao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Manhardt%2C+F">Fabian Manhardt</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing hand-held objects from a single RGB image is an important and
challenging problem. Existing works utilizing Signed Distance Fields (SDF)
reveal limitations in comprehensively capturing the complex hand-object
interactions, since SDF is only reliable within the proximity of the target,
and hence, infeasible to simultaneously encode local hand and object cues. To
address this issue, we propose DDF-HO, a novel approach leveraging Directed
Distance Field (DDF) as the shape representation. Unlike SDF, DDF maps a ray in
3D space, consisting of an origin and a direction, to corresponding DDF values,
including a binary visibility signal determining whether the ray intersects the
objects and a distance value measuring the distance from origin to target in
the given direction. We randomly sample multiple rays and collect local to
global geometric features for them by introducing a novel 2D ray-based feature
aggregation scheme and a 3D intersection-aware hand pose embedding, combining
2D-3D features to model hand-object interactions. Extensive experiments on
synthetic and real-world datasets demonstrate that DDF-HO consistently
outperforms all baseline methods by a large margin, especially under Chamfer
Distance, with about 80% leap forward. Codes and trained models will be
released soon.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08234" title="Abstract">arXiv:2308.08234</a> [<a href="/pdf/2308.08234" title="Download PDF">pdf</a>, <a href="/format/2308.08234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Opportunities of Using Transformer-Based Multi-Task  Learning in NLP Through ML Lifecycle: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torbarina%2C+L">Lovre Torbarina</a>, 
<a href="/search/cs?searchtype=author&query=Ferkovic%2C+T">Tin Ferkovic</a>, 
<a href="/search/cs?searchtype=author&query=Roguski%2C+L">Lukasz Roguski</a>, 
<a href="/search/cs?searchtype=author&query=Mihelcic%2C+V">Velimir Mihelcic</a>, 
<a href="/search/cs?searchtype=author&query=Sarlija%2C+B">Bruno Sarlija</a>, 
<a href="/search/cs?searchtype=author&query=Kraljevic%2C+Z">Zeljko Kraljevic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing adoption of natural language processing (NLP) models across
industries has led to practitioners' need for machine learning systems to
handle these models efficiently, from training to serving them in production.
However, training, deploying, and updating multiple models can be complex,
costly, and time-consuming, mainly when using transformer-based pre-trained
language models. Multi-Task Learning (MTL) has emerged as a promising approach
to improve efficiency and performance through joint training, rather than
training separate models. Motivated by this, we first provide an overview of
transformer-based MTL approaches in NLP. Then, we discuss the challenges and
opportunities of using MTL approaches throughout typical ML lifecycle phases,
specifically focusing on the challenges related to data engineering, model
development, deployment, and monitoring phases. This survey focuses on
transformer-based MTL architectures and, to the best of our knowledge, is novel
in that it systematically analyses how transformer-based MTL in NLP fits into
ML lifecycle phases. Furthermore, we motivate research on the connection
between MTL and continual learning (CL), as this area remains unexplored. We
believe it would be practical to have a model that can handle both MTL and CL,
as this would make it easier to periodically re-train the model, update it due
to distribution shifts, and add new capabilities to meet real-world
requirements.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08235" title="Abstract">arXiv:2308.08235</a> [<a href="/pdf/2308.08235" title="Download PDF">pdf</a>, <a href="/format/2308.08235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Expressive Power of Graph Neural Networks: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bingxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Changjun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kuihua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jincai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural networks (GNNs) are effective machine learning models for many
graph-related applications. Despite their empirical success, many research
efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive
power. Early works in this domain mainly focus on studying the graph
isomorphism recognition ability of GNNs, and recent works try to leverage the
properties such as subgraph counting and connectivity learning to characterize
the expressive power of GNNs, which are more practical and closer to
real-world. However, no survey papers and open-source repositories
comprehensively summarize and discuss models in this important direction. To
fill the gap, we conduct a first survey for models for enhancing expressive
power under different forms of definition. Concretely, the models are reviewed
based on three categories, i.e., Graph feature enhancement, Graph topology
enhancement, and GNNs architecture enhancement.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08236" title="Abstract">arXiv:2308.08236</a> [<a href="/pdf/2308.08236" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redundancy-free integrated optical convolver for optical neural networks  based on arrayed waveguide grating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haojun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xueyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dingshan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianji Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinliang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Optical neural networks (ONNs) have gained significant attention due to their
potential for high-speed and energy-efficient computation in artificial
intelligence. The implementation of optical convolutions plays a vital role in
ONNs, as they are fundamental operations within neural network architectures.
However, state-of-the-art convolution architectures often suffer from redundant
inputs, leading to substantial resource waste. Here, we propose an integrated
optical convolution architecture that leverages the inherent routing principles
of arrayed waveguide grating (AWG) to execute the sliding of convolution kernel
and summation of results. M*N multiply-accumulate (MAC) operations are
facilitated by M+N units within a single clock cycle, thus eliminating the
redundancy. In the experiment, we achieved 5-bit precision and 91.9% accuracy
in the handwritten digit recognition task confirming the reliability of our
approach. Its redundancy-free architecture, low power consumption, high compute
density (8.53 teraOP mm^-2 s^-1) and scalability make it a valuable
contribution to the field of optical neural networks, thereby paving the way
for future advancements in high-performance computing and artificial
intelligence applications.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08239" title="Abstract">arXiv:2308.08239</a> [<a href="/pdf/2308.08239" title="Download PDF">pdf</a>, <a href="/format/2308.08239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain  Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junru Lu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Siyu An</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pergola%2C+G">Gabriele Pergola</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunsheng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes, data and models will be available soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose MemoChat, a pipeline for refining instructions that enables large
language models (LLMs) to effectively employ self-composed memos for
maintaining consistent long-range open-domain conversations. We demonstrate a
long-range open-domain conversation through iterative
"memorization-retrieval-response" cycles. This requires us to carefully design
tailored tuning instructions for each distinct stage. The instructions are
reconstructed from a collection of public datasets to teach the LLMs to
memorize and retrieve past dialogues with structured memos, leading to enhanced
consistency when participating in future conversations. We invite experts to
manually annotate a test set designed to evaluate the consistency of long-range
conversations questions. Experiments on three testing scenarios involving both
open-source and API-accessible chatbots at scale verify the efficacy of
MemoChat, which outperforms strong baselines.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08241" title="Abstract">arXiv:2308.08241</a> [<a href="/pdf/2308.08241" title="Download PDF">pdf</a>, <a href="/format/2308.08241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEST: Text Prototype Aligned Embedding to Activate LLM&#x27;s Ability for  Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work summarizes two strategies for completing time-series (TS) tasks
using today's language model (LLM): LLM-for-TS, design and train a fundamental
large model for TS data; TS-for-LLM, enable the pre-trained LLM to handle TS
data. Considering the insufficient data accumulation, limited resources, and
semantic context requirements, this work focuses on TS-for-LLM methods, where
we aim to activate LLM's ability for TS data by designing a TS embedding method
suitable for LLM. The proposed method is named TEST. It first tokenizes TS,
builds an encoder to embed them by instance-wise, feature-wise, and
text-prototype-aligned contrast, and then creates prompts to make LLM more open
to embeddings, and finally implements TS tasks. Experiments are carried out on
TS classification and forecasting tasks using 8 LLMs with different structures
and sizes. Although its results cannot significantly outperform the current
SOTA models customized for TS tasks, by treating LLM as the pattern machine, it
can endow LLM's ability to process TS data without compromising the language
ability. This paper is intended to serve as a foundational work that will
inspire further research.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08242" title="Abstract">arXiv:2308.08242</a> [<a href="/pdf/2308.08242" title="Download PDF">pdf</a>, <a href="/format/2308.08242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Lane Detection via cross-similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zoljodi%2C+A">Ali Zoljodi</a>, 
<a href="/search/cs?searchtype=author&query=Abadijou%2C+S">Sadegh Abadijou</a>, 
<a href="/search/cs?searchtype=author&query=Alibeigi%2C+M">Mina Alibeigi</a>, 
<a href="/search/cs?searchtype=author&query=Daneshtalab%2C+M">Masoud Daneshtalab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting road lanes is challenging due to intricate markings vulnerable to
unfavorable conditions. Lane markings have strong shape priors, but their
visibility is easily compromised. Factors like lighting, weather, vehicles,
pedestrians, and aging colors challenge the detection. A large amount of data
is required to train a lane detection approach that can withstand natural
variations caused by low visibility. This is because there are numerous lane
shapes and natural variations that exist. Our solution, Contrastive Learning
for Lane Detection via cross-similarity (CLLD), is a self-supervised learning
method that tackles this challenge by enhancing lane detection models
resilience to real-world conditions that cause lane low visibility. CLLD is a
novel multitask contrastive learning that trains lane detection approaches to
detect lane markings even in low visible situations by integrating local
feature contrastive learning (CL) with our new proposed operation
cross-similarity. Local feature CL focuses on extracting features for small
image parts, which is necessary to localize lane segments, while
cross-similarity captures global features to detect obscured lane segments
using their surrounding. We enhance cross-similarity by randomly masking parts
of input images for augmentation. Evaluated on benchmark datasets, CLLD
outperforms state-of-the-art contrastive learning, especially in
visibility-impairing conditions like shadows. Compared to supervised learning,
CLLD excels in scenarios like shadows and crowded scenes.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08244" title="Abstract">arXiv:2308.08244</a> [<a href="/pdf/2308.08244" title="Download PDF">pdf</a>, <a href="/format/2308.08244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Wireless Image Transmission Scheme with Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xueyan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnd%C3%BCz%2C+D">Deniz G&#xfc;nd&#xfc;z</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weichao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guohua Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose a hybrid joint source-channel coding (JSCC) scheme, in which the
conventional digital communication scheme is complemented with a generative
refinement component to improve the perceptual quality of the reconstruction.
The input image is decomposed into two components: the first is a coarse
compressed version, and is transmitted following the conventional separation
based approach. An additional component is obtained through the diffusion
process by adding independent Gaussian noise to the input image, and is
transmitted using DeepJSCC. The decoder combines the two signals to produce a
high quality reconstruction of the source. Experimental results show that the
hybrid design provides bandwidth savings and enables graceful performance
improvement as the channel quality improves.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08252" title="Abstract">arXiv:2308.08252</a> [<a href="/pdf/2308.08252" title="Download PDF">pdf</a>, <a href="/format/2308.08252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Description Logics Go Second-Order -- Extending EL with Universally  Quantified Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirschbrunn%2C+J">Joshua Hirschbrunn</a>, 
<a href="/search/cs?searchtype=author&query=Kazakov%2C+Y">Yevgeny Kazakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The study of Description Logics have been historically mostly focused on
features that can be translated to decidable fragments of first-order logic. In
this paper, we leave this restriction behind and look for useful and decidable
extensions outside first-order logic. We introduce universally quantified
concepts, which take the form of variables that can be replaced with arbitrary
concepts, and define two semantics of this extension. A schema semantics allows
replacements of concept variables only by concepts from a particular language,
giving us axiom schemata similar to modal logics. A second-order semantics
allows replacement of concept variables with arbitrary subsets of the domain,
which is similar to quantified predicates in second-order logic.
<br />To study the proposed semantics, we focus on the extension of the description
logic $\mathcal{EL}$. We show that for a useful fragment of the extension, the
conclusions entailed by the different semantics coincide, allowing us to use
classical $\mathcal{EL}$ reasoning algorithms even for the second-order
semantics. For a slightly smaller, but still useful, fragment, we were also
able to show polynomial decidability of the extension. This fragment, in
particular, can express a generalized form of role chain axioms, positive self
restrictions, and some forms of (local) role-value-maps from KL-ONE, without
requiring any additional constructors.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08253" title="Abstract">arXiv:2308.08253</a> [<a href="/pdf/2308.08253" title="Download PDF">pdf</a>, <a href="/format/2308.08253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Neural Network Generalization for Grammar Induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+N">Nur Lan</a>, 
<a href="/search/cs?searchtype=author&query=Chemla%2C+E">Emmanuel Chemla</a>, 
<a href="/search/cs?searchtype=author&query=Katzir%2C+R">Roni Katzir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 2 tables. Conference: Learning with Small Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">How well do neural networks generalize? Even for grammar induction tasks,
where the target generalization is fully known, previous works have left the
question open, testing very limited ranges beyond the training set and using
different success criteria. We provide a measure of neural network
generalization based on fully specified formal languages. Given a model and a
formal grammar, the method assigns a generalization score representing how well
a model generalizes to unseen samples in inverse relation to the amount of data
it was trained on. The benchmark includes languages such as $a^nb^n$,
$a^nb^nc^n$, $a^nb^mc^{n+m}$, and Dyck-1 and 2. We evaluate selected
architectures using the benchmark and find that networks trained with a Minimum
Description Length objective (MDL) generalize better and using less data than
networks trained using standard loss functions. The benchmark is available at
https://github.com/taucompling/bliss.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08256" title="Abstract">arXiv:2308.08256</a> [<a href="/pdf/2308.08256" title="Download PDF">pdf</a>, <a href="/format/2308.08256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiMediate&#x27;23: Engagement Estimation and Bodily Behaviour Recognition  in Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Philipp M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Balazia%2C+M">Michal Balazia</a>, 
<a href="/search/cs?searchtype=author&query=Baur%2C+T">Tobias Baur</a>, 
<a href="/search/cs?searchtype=author&query=Dietz%2C+M">Michael Dietz</a>, 
<a href="/search/cs?searchtype=author&query=Heimerl%2C+A">Alexander Heimerl</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+D">Dominik Schiller</a>, 
<a href="/search/cs?searchtype=author&query=Guermal%2C+M">Mohammed Guermal</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D">Dominike Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%A9mond%2C+F">Fran&#xe7;ois Br&#xe9;mond</a>, 
<a href="/search/cs?searchtype=author&query=Alexandersson%2C+J">Jan Alexandersson</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MultiMedia'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Automatic analysis of human behaviour is a fundamental prerequisite for the
creation of machines that can effectively interact with- and support humans in
social interactions. In MultiMediate'23, we address two key human social
behaviour analysis tasks for the first time in a controlled challenge:
engagement estimation and bodily behaviour recognition in social interactions.
This paper describes the MultiMediate'23 challenge and presents novel sets of
annotations for both tasks. For engagement estimation we collected novel
annotations on the NOvice eXpert Interaction (NOXI) database. For bodily
behaviour recognition, we annotated test recordings of the MPIIGroupInteraction
corpus with the BBSI annotation scheme. In addition, we present baseline
results for both challenge tasks.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08258" title="Abstract">arXiv:2308.08258</a> [<a href="/pdf/2308.08258" title="Download PDF">pdf</a>, <a href="/format/2308.08258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceNeRFlow: Time-Consistent Reconstruction of General Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tretschk%2C+E">Edith Tretschk</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Zollhoefer%2C+M">Michael Zollhoefer</a>, 
<a href="/search/cs?searchtype=author&query=Bozic%2C+A">Aljaz Bozic</a>, 
<a href="/search/cs?searchtype=author&query=Lassner%2C+C">Christoph Lassner</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vcai.mpi-inf.mpg.de/projects/scenerflow/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Existing methods for the 4D reconstruction of general, non-rigidly deforming
objects focus on novel-view synthesis and neglect correspondences. However,
time consistency enables advanced downstream tasks like 3D editing, motion
analysis, or virtual-asset creation. We propose SceNeRFlow to reconstruct a
general, non-rigid scene in a time-consistent manner. Our dynamic-NeRF method
takes multi-view RGB videos and background images from static cameras with
known camera parameters as input. It then reconstructs the deformations of an
estimated canonical model of the geometry and appearance in an online fashion.
Since this canonical model is time-invariant, we obtain correspondences even
for long-term, long-range motions. We employ neural scene representations to
parametrize the components of our method. Like prior dynamic-NeRF methods, we
use a backwards deformation model. We find non-trivial adaptations of this
model necessary to handle larger motions: We decompose the deformations into a
strongly regularized coarse component and a weakly regularized fine component,
where the coarse component also extends the deformation field into the space
surrounding the object, which enables tracking over time. We show
experimentally that, unlike prior work that only handles small motion, our
method enables the reconstruction of studio-scale motions.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08259" title="Abstract">arXiv:2308.08259</a> [<a href="/pdf/2308.08259" title="Download PDF">pdf</a>, <a href="/format/2308.08259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Relation Aware Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qinghua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weijieying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+W">Wei Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Continual graph learning (CGL) studies the problem of learning from an
infinite stream of graph data, consolidating historical knowledge, and
generalizing it to the future task. At once, only current graph data are
available. Although some recent attempts have been made to handle this task, we
still face two potential challenges: 1) most of existing works only manipulate
on the intermediate graph embedding and ignore intrinsic properties of graphs.
It is non-trivial to differentiate the transferred information across graphs.
2) recent attempts take a parameter-sharing policy to transfer knowledge across
time steps or progressively expand new architecture given shifted graph
distribution. Learning a single model could loss discriminative information for
each graph task while the model expansion scheme suffers from high model
complexity. In this paper, we point out that latent relations behind graph
edges can be attributed as an invariant factor for the evolving graphs and the
statistical information of latent relations evolves. Motivated by this, we
design a relation-aware adaptive model, dubbed as RAM-CG, that consists of a
relation-discovery modular to explore latent relations behind edges and a
task-awareness masking classifier to accounts for the shifted. Extensive
experiments show that RAM-CG provides significant 2.2%, 6.9% and 6.6% accuracy
improvements over the state-of-the-art results on CitationNet, OGBN-arxiv and
TWITCH dataset, respective.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08261" title="Abstract">arXiv:2308.08261</a> [<a href="/pdf/2308.08261" title="Download PDF">pdf</a>, <a href="/format/2308.08261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B-stability of numerical integrators on Riemannian manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arnold%2C+M">Martin Arnold</a>, 
<a href="/search/math?searchtype=author&query=Celledoni%2C+E">Elena Celledoni</a>, 
<a href="/search/math?searchtype=author&query=%C3%87okaj%2C+E">Ergys &#xc7;okaj</a>, 
<a href="/search/math?searchtype=author&query=Owren%2C+B">Brynjulf Owren</a>, 
<a href="/search/math?searchtype=author&query=Tumiotto%2C+D">Denise Tumiotto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a generalization of nonlinear stability of numerical one-step
integrators to Riemannian manifolds in the spirit of Butcher's notion of
B-stability. Taking inspiration from Simpson-Porco and Bullo, we introduce
non-expansive systems on such manifolds and define B-stability of integrators.
In this first exposition, we provide concrete results for a geodesic version of
the Implicit Euler (GIE) scheme. We prove that the GIE method is B-stable on
Riemannian manifolds with non-positive sectional curvature. We show through
numerical examples that the GIE method is expansive when applied to a certain
non-expansive vector field on the 2-sphere, and that the GIE method does not
necessarily possess a unique solution for large enough step sizes. Finally, we
derive a new improved global error estimate for general Lie group integrators.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08263" title="Abstract">arXiv:2308.08263</a> [<a href="/pdf/2308.08263" title="Download PDF">pdf</a>, <a href="/format/2308.08263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Commit Classification with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+J">Jiajun Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+X">Xiaobin Rui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Commit Classification (CC) is an important task in software maintenance,
which helps software developers classify code changes into different types
according to their nature and purpose. It allows developers to understand
better how their development efforts are progressing, identify areas where they
need improvement, and make informed decisions about when and how to release new
software versions. However, existing models need lots of manually labeled data
for fine-tuning processes, and ignore sentence-level semantic information,
which is often essential for discovering the difference between diverse
commits. Therefore, it is still challenging to solve CC in fewshot scenario.
<br />To solve the above problems, we propose a contrastive learning-based commit
classification framework. Firstly, we generate $K$ sentences and pseudo-labels
according to the labels of the dataset, which aims to enhance the dataset.
Secondly, we randomly group the augmented data $N$ times to compare their
similarity with the positive $T_p^{|C|}$ and negative $T_n^{|C|}$ samples. We
utilize individual pretrained sentence transformers (ST)s to efficiently obtain
the sentence-level embeddings from different features respectively. Finally, we
adopt the cosine similarity function to limit the distribution of vectors,
similar vectors are more adjacent. The light fine-tuned model is then applied
to the label prediction of incoming commits.
<br />Extensive experiments on two open available datasets demonstrate that our
framework can solve the CC problem simply but effectively in fewshot scenarios,
while achieving state-of-the-art(SOTA) performance and improving the
adaptability of the model without requiring a large number of training samples
for fine-tuning. The code, data, and trained models are available at
https://github.com/AppleMax1992/CommitFit.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08267" title="Abstract">arXiv:2308.08267</a> [<a href="/pdf/2308.08267" title="Download PDF">pdf</a>, <a href="/format/2308.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perpetual Reconfigurable Intelligent Surfaces Through In-Band Energy  Harvesting: Architectures, Protocols, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ntontin%2C+K">Konstantinos Ntontin</a>, 
<a href="/search/cs?searchtype=author&query=Boulogeorgos%2C+A+A">Alexandros-Apostolos A. Boulogeorgos</a>, 
<a href="/search/cs?searchtype=author&query=Abadal%2C+S">Sergi Abadal</a>, 
<a href="/search/cs?searchtype=author&query=Mesodiakaki%2C+A">Agapi Mesodiakaki</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>, 
<a href="/search/cs?searchtype=author&query=Ottersten%2C+B">Bj&#xf6;rn Ottersten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) are considered to be a key enabler
of highly energy-efficient 6G and beyond networks. This property arises from
the absence of power amplifiers in the structure, in contrast to active nodes,
such as small cells and relays. However, still an amount of power is required
for their operation. To improve their energy efficiency further, we propose the
notion of perpetual RISs, which secure the power needed to supply their
functionalities through wireless energy harvesting of the impinging transmitted
electromagnetic signals. Towards this, we initially explain the rationale
behind such RIS capability and proceed with the presentation of the main RIS
controller architecture that can realize this vision under an in-band energy
harvesting consideration. Furthermore, we present a typical energy-harvesting
architecture followed by two harvesting protocols. Subsequently, we study the
performance of the two protocols under a typical communications scenario.
Finally, we elaborate on the main research challenges governing the realization
of large-scale networks with perpetual RISs.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08268" title="Abstract">arXiv:2308.08268</a> [<a href="/pdf/2308.08268" title="Download PDF">pdf</a>, <a href="/format/2308.08268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It Ain&#x27;t That Bad: Understanding the Mysterious Performance Drop in OOD  Generalization for Generative Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingcheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zihao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanqing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Transformer-based models have achieved remarkable proficiency on
solving diverse problems. However, their generalization ability is not fully
understood and not always satisfying. Researchers take basic mathematical tasks
like n-digit addition or multiplication as important perspectives for
investigating their generalization behaviors. Curiously, it is observed that
when training on n-digit operations (e.g., additions) in which both input
operands are n-digit in length, models generalize successfully on unseen
n-digit inputs (in-distribution (ID) generalization), but fail miserably and
mysteriously on longer, unseen cases (out-of-distribution (OOD)
generalization). Studies try to bridge this gap with workarounds such as
modifying position embedding, fine-tuning, and priming with more extensive or
instructive data. However, without addressing the essential mechanism, there is
hardly any guarantee regarding the robustness of these solutions. We bring this
unexplained performance drop into attention and ask whether it is purely from
random errors. Here we turn to the mechanistic line of research which has
notable successes in model interpretability. We discover that the strong ID
generalization stems from structured representations, while behind the
unsatisfying OOD performance, the models still exhibit clear learned algebraic
structures. Specifically, these models map unseen OOD inputs to outputs with
equivalence relations in the ID domain. These highlight the potential of the
models to carry useful information for improved generalization.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08270" title="Abstract">arXiv:2308.08270</a> [<a href="/pdf/2308.08270" title="Download PDF">pdf</a>, <a href="/format/2308.08270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Benchmarking Power-Performance Characteristics of Federated  Learning Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pratik Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning and Networking Workshop, NetSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Federated Learning (FL) is a decentralized machine learning approach where
local models are trained on distributed clients, allowing privacy-preserving
collaboration by sharing model updates instead of raw data. However, the added
communication overhead and increased training time caused by heterogenous data
distributions results in higher energy consumption and carbon emissions for
achieving similar model performance than traditional machine learning. At the
same time, efficient usage of available energy is an important requirement for
battery constrained devices. Because of this, many different approaches on
energy-efficient and carbon-efficient FL scheduling and client selection have
been published in recent years. However, most of this research oversimplifies
power performance characteristics of clients by assuming that they always
require the same amount of energy per processed sample throughout training.
This overlooks real-world effects arising from operating devices under
different power modes or the side effects of running other workloads in
parallel. In this work, we take a first look on the impact of such factors and
discuss how better power-performance estimates can improve energy-efficient and
carbon-efficient FL scheduling.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08271" title="Abstract">arXiv:2308.08271</a> [<a href="/pdf/2308.08271" title="Download PDF">pdf</a>, <a href="/format/2308.08271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Olives with Synthetic or Real Data? Olive the Above
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karabatis%2C+Y">Yianni Karabatis</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaomin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sanket%2C+N+J">Nitin J. Sanket</a>, 
<a href="/search/cs?searchtype=author&query=Lagoudakis%2C+M+G">Michail G. Lagoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Aloimonos%2C+Y">Yiannis Aloimonos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of 2023 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Modern robotics has enabled the advancement in yield estimation for precision
agriculture. However, when applied to the olive industry, the high variation of
olive colors and their similarity to the background leaf canopy presents a
challenge. Labeling several thousands of very dense olive grove images for
segmentation is a labor-intensive task. This paper presents a novel approach to
detecting olives without the need to manually label data. In this work, we
present the world's first olive detection dataset comprised of synthetic and
real olive tree images. This is accomplished by generating an auto-labeled
photorealistic 3D model of an olive tree. Its geometry is then simplified for
lightweight rendering purposes. In addition, experiments are conducted with a
mix of synthetically generated and real images, yielding an improvement of up
to 66% compared to when only using a small sample of real data. When access to
real, human-labeled data is limited, a combination of mostly synthetic data and
a small amount of real data can enhance olive detection.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08276" title="Abstract">arXiv:2308.08276</a> [<a href="/pdf/2308.08276" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer vision-enriched discrete choice models, with an application to  residential location choice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Cranenburgh%2C+S">Sander van Cranenburgh</a>, 
<a href="/search/cs?searchtype=author&query=Garrido-Valenzuela%2C+F">Francisco Garrido-Valenzuela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Econometrics (econ.EM)

</div>
<p class="mathjax">Visual imagery is indispensable to many multi-attribute decision situations.
Examples of such decision situations in travel behaviour research include
residential location choices, vehicle choices, tourist destination choices, and
various safety-related choices. However, current discrete choice models cannot
handle image data and thus cannot incorporate information embedded in images
into their representations of choice behaviour. This gap between discrete
choice models' capabilities and the real-world behaviour it seeks to model
leads to incomplete and, possibly, misleading outcomes. To solve this gap, this
study proposes "Computer Vision-enriched Discrete Choice Models" (CV-DCMs).
CV-DCMs can handle choice tasks involving numeric attributes and images by
integrating computer vision and traditional discrete choice models. Moreover,
because CV-DCMs are grounded in random utility maximisation principles, they
maintain the solid behavioural foundation of traditional discrete choice
models. We demonstrate the proposed CV-DCM by applying it to data obtained
through a novel stated choice experiment involving residential location
choices. In this experiment, respondents faced choice tasks with trade-offs
between commute time, monthly housing cost and street-level conditions,
presented using images. As such, this research contributes to the growing body
of literature in the travel behaviour field that seeks to integrate discrete
choice modelling and machine learning.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08279" title="Abstract">arXiv:2308.08279</a> [<a href="/pdf/2308.08279" title="Download PDF">pdf</a>, <a href="/ps/2308.08279" title="Download PostScript">ps</a>, <a href="/format/2308.08279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning based Joint Spectrum Allocation and  Configuration Design for STAR-RIS-Assisted V2X Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aung%2C+P+S">Pyae Sone Aung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+X">Loc X. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+K">Yan Kyaw Tun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Vehicle-to-Everything (V2X) communications play a crucial role in ensuring
safe and efficient modern transportation systems. However, challenges arise in
scenarios with buildings, leading to signal obstruction and coverage
limitations. To alleviate these challenges, reconfigurable intelligent surface
(RIS) is regarded as an effective solution for communication performance by
tuning passive signal reflection. RIS has acquired prominence in 6G networks
due to its improved spectral efficiency, simple deployment, and
cost-effectiveness. Nevertheless, conventional RIS solutions have coverage
limitations. Therefore, researchers have started focusing on the promising
concept of simultaneously transmitting and reflecting RIS (STAR-RIS), which
provides 360\degree coverage while utilizing the advantages of RIS technology.
In this paper, a STAR-RIS-assisted V2X communication system is investigated. An
optimization problem is formulated to maximize the achievable data rate for
vehicle-to-infrastructure (V2I) users while satisfying the latency and
reliability requirements of vehicle-to-vehicle (V2V) pairs by jointly
optimizing the spectrum allocation, amplitudes, and phase shifts of STAR-RIS
elements, digital beamforming vectors for V2I links, and transmit power for V2V
pairs. Since it is challenging to solve in polynomial time, we decompose our
problem into two sub-problems. For the first sub-problem, we model the control
variables as a Markov Decision Process (MDP) and propose a combined double deep
Q-network (DDQN) with an attention mechanism so that the model can potentially
focus on relevant inputs. For the latter, a standard optimization-based
approach is implemented to provide a real-time solution, reducing computational
costs. Extensive numerical analysis is developed to demonstrate the superiority
of our proposed algorithm compared to benchmark schemes.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08285" title="Abstract">arXiv:2308.08285</a> [<a href="/pdf/2308.08285" title="Download PDF">pdf</a>, <a href="/format/2308.08285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training with Large Language Model-based Document Expansion for  Dense Passage Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guangyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 tables, 4 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, we systematically study the potential of pre-training with
Large Language Model(LLM)-based document expansion for dense passage retrieval.
Concretely, we leverage the capabilities of LLMs for document expansion, i.e.
query generation, and effectively transfer expanded knowledge to retrievers
using pre-training strategies tailored for passage retrieval. These strategies
include contrastive learning and bottlenecked query generation. Furthermore, we
incorporate a curriculum learning strategy to reduce the reliance on LLM
inferences. Experimental results demonstrate that pre-training with LLM-based
document expansion significantly boosts the retrieval performance on
large-scale web-search tasks. Our work shows strong zero-shot and out-of-domain
retrieval abilities, making it more widely applicable for retrieval when
initializing with no human-labeled data.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08287" title="Abstract">arXiv:2308.08287</a> [<a href="/pdf/2308.08287" title="Download PDF">pdf</a>, <a href="/format/2308.08287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expert opinions on making GDPR usable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johansen%2C+J">Johanna Johansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, with appendix and 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We present the results of a study done in order to validate concepts and
methods that have been introduced in (Johansen and Fischer-Hubner, 2020.
"Making GDPR Usable: A Model to Support Usability Evaluations of Privacy." in
IFIP AICT 576, 275-291). We use as respondents in our interviews experts
working across fields of relevance to these concepts, including law and data
protection/privacy, certifications and standardization, and usability (as
studied in the field of Human-Computer Interaction). We study the experts'
opinions about four new concepts, namely: (i) a definition of Usable Privacy,
(ii) 30 Usable Privacy Goals identified as excerpts from the GDPR (European
General Data Protection Regulation), (iii) a set of 25 corresponding Usable
Privacy Criteria together with their multiple measurable sub-criteria, and (iv)
the Usable Privacy Cube model, which puts all these together with the EuroPriSe
certification criteria, with the purpose of making explicit several aspects of
certification processes such as orderings of criteria, interactions between
these, different stakeholder perspectives, and context of use/processing.
<br />The expert opinions are varied, example-rich, and forward-looking, which
gives a impressive list of open problems where the above four concepts can work
as a foundation for further developments. We employed a critical qualitative
research, using theory triangulation to analyze the data representing three
groups of experts, categorized as 'certifications', 'law', and 'usability',
coming both from industry and academia. The results of our analysis show
agreement among the experts about the need for evaluations and measuring of
usability of privacy in order to allow for exercising data subjects' rights and
to evaluate the degree to which data controllers comply with the data
protection principles.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08288" title="Abstract">arXiv:2308.08288</a> [<a href="/pdf/2308.08288" title="Download PDF">pdf</a>, <a href="/format/2308.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Audio-Visual Segmentation with Bidirectional Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+D">Dawei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuxin Mao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowen He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dawei Hao and Yuxin Mao contribute equality to this paper. Yiran Zhong is the corresponding author. The code will be released at <a href="https://github.com/OpenNLPLab/AVS-bidirectional">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The aim of audio-visual segmentation (AVS) is to precisely differentiate
audible objects within videos down to the pixel level. Traditional approaches
often tackle this challenge by combining information from various modalities,
where the contribution of each modality is implicitly or explicitly modeled.
Nevertheless, the interconnections between different modalities tend to be
overlooked in audio-visual modeling. In this paper, inspired by the human
ability to mentally simulate the sound of an object and its visual appearance,
we introduce a bidirectional generation framework. This framework establishes
robust correlations between an object's visual characteristics and its
associated sound, thereby enhancing the performance of AVS. To achieve this, we
employ a visual-to-audio projection component that reconstructs audio features
from object segmentation masks and minimizes reconstruction errors. Moreover,
recognizing that many sounds are linked to object movements, we introduce an
implicit volumetric motion estimation module to handle temporal dynamics that
may be challenging to capture using conventional optical flow methods. To
showcase the effectiveness of our approach, we conduct comprehensive
experiments and analyses on the widely recognized AVSBench benchmark. As a
result, we establish a new state-of-the-art performance level in the AVS
benchmark, particularly excelling in the challenging MS3 subset which involves
segmenting multiple sound sources. To facilitate reproducibility, we plan to
release both the source code and the pre-trained model.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08290" title="Abstract">arXiv:2308.08290</a> [<a href="/pdf/2308.08290" title="Download PDF">pdf</a>, <a href="/format/2308.08290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFedADMM: Dual Constraints Controlled Model Inconsistency for  Decentralized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinglun Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">To address the communication burden issues associated with federated learning
(FL), decentralized federated learning (DFL) discards the central server and
establishes a decentralized communication network, where each client
communicates only with neighboring clients. However, existing DFL methods still
suffer from two major challenges: local inconsistency and local heterogeneous
overfitting, which have not been fundamentally addressed by existing DFL
methods. To tackle these issues, we propose novel DFL algorithms, DFedADMM and
its enhanced version DFedADMM-SAM, to enhance the performance of DFL. The
DFedADMM algorithm employs primal-dual optimization (ADMM) by utilizing dual
variables to control the model inconsistency raised from the decentralized
heterogeneous data distributions. The DFedADMM-SAM algorithm further improves
on DFedADMM by employing a Sharpness-Aware Minimization (SAM) optimizer, which
uses gradient perturbations to generate locally flat models and searches for
models with uniformly low loss values to mitigate local heterogeneous
overfitting. Theoretically, we derive convergence rates of $\small
\mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}\Big)$ and $\small
\mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}+
\frac{1}{T^{3/2}K^{1/2}}\Big)$ in the non-convex setting for DFedADMM and
DFedADMM-SAM, respectively, where $1 - \psi$ represents the spectral gap of the
gossip matrix. Empirically, extensive experiments on MNIST, CIFAR10 and
CIFAR100 datesets demonstrate that our algorithms exhibit superior performance
in terms of both generalization and convergence speed compared to existing
state-of-the-art (SOTA) optimizers in DFL.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08291" title="Abstract">arXiv:2308.08291</a> [<a href="/pdf/2308.08291" title="Download PDF">pdf</a>, <a href="/format/2308.08291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Bayesian Satisficing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saday%2C+A">Artun Saday</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1r%C4%B1m%2C+Y+C">Ya&#x15f;ar Cahit Y&#x131;ld&#x131;r&#x131;m</a>, 
<a href="/search/cs?searchtype=author&query=Tekin%2C+C">Cem Tekin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Distributional shifts pose a significant challenge to achieving robustness in
contemporary machine learning. To overcome this challenge, robust satisficing
(RS) seeks a robust solution to an unspecified distributional shift while
achieving a utility above a desired threshold. This paper focuses on the
problem of RS in contextual Bayesian optimization when there is a discrepancy
between the true and reference distributions of the context. We propose a novel
robust Bayesian satisficing algorithm called RoBOS for noisy black-box
optimization. Our algorithm guarantees sublinear lenient regret under certain
assumptions on the amount of distribution shift. In addition, we define a
weaker notion of regret called robust satisficing regret, in which our
algorithm achieves a sublinear upper bound independent of the amount of
distribution shift. To demonstrate the effectiveness of our method, we apply it
to various learning problems and compare it to other approaches, such as
distributionally robust optimization.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08292" title="Abstract">arXiv:2308.08292</a> [<a href="/pdf/2308.08292" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Techniques for Improving the Energy Efficiency of Mobile Apps: A  Taxonomy and Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huber%2C+S">Stefan Huber</a>, 
<a href="/search/cs?searchtype=author&query=Lorey%2C+T">Tobias Lorey</a>, 
<a href="/search/cs?searchtype=author&query=Felderer%2C+M">Michael Felderer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Building energy efficient software is an increasingly important task for
mobile developers. However, a cumulative body of knowledge of techniques that
support this goal does not exist. We conduct a systematic literature review to
gather information on existing techniques that allow developers to increase
energy efficiency in mobile apps. Based on a synthesis of the 91 included
primary studies, we propose a taxonomy of techniques for improving the energy
efficiency in mobile apps. The taxonomy includes seven main categories of
techniques and serves as a collection of available methods for developers and
as a reference guide for software testers when performing energy efficiency
testing by the means of benchmark tests.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08295" title="Abstract">arXiv:2308.08295</a> [<a href="/pdf/2308.08295" title="Download PDF">pdf</a>, <a href="/format/2308.08295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detoxify Language Model Step-by-Step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zecheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Keyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pinzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuyang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Minzhang">Minzhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Detoxification for LLMs is challenging since it requires models to avoid
generating harmful content while maintaining the generation capability. To
ensure the safety of generations, previous detoxification methods detoxify the
models by changing the data distributions or constraining the generations from
different aspects in a single-step manner. However, these approaches will
dramatically affect the generation quality of LLMs, e.g., discourse coherence
and semantic consistency, since language models tend to generate along the
toxic prompt while detoxification methods work in the opposite direction. To
handle such a conflict, we decompose the detoxification process into different
sub-steps, where the detoxification is concentrated in the input stage and the
subsequent continual generation is based on the non-toxic prompt. Besides, we
also calibrate the strong reasoning ability of LLMs by designing a Detox-Chain
to connect the above sub-steps in an orderly manner, which allows LLMs to
detoxify the text step-by-step. Automatic and human evaluation on two
benchmarks reveals that by training with Detox-Chain, six LLMs scaling from 1B
to 33B can obtain significant detoxification and generation improvement. Our
code and data are available at https://github.com/CODINNLG/Detox-CoT. Warning:
examples in the paper may contain uncensored offensive content.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08302" title="Abstract">arXiv:2308.08302</a> [<a href="/pdf/2308.08302" title="Download PDF">pdf</a>, <a href="/ps/2308.08302" title="Download PostScript">ps</a>, <a href="/format/2308.08302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSA Based Power Control for Cell-Free Massive MIMO under LoS/NLoS  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+P">Ashish Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chopra%2C+R">Ribhu Chopra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A primary design goal of the cell-free~(CF) massive MIMO architecture is to
provide uniformly good coverage to all the user equipments~(UEs) connected to
the network. However, it has been found that this requirement may not be
satisfied in case the channels between the access points~(APs) and the UEs are
mixed LoS/NLoS. In this paper, we try to address this issue via the use of
appropriate power control in both the uplink and downlink of a CF massive MIMO
system under mixed LoS/NLoS channels. We find that simplistic power control
techniques, such as channel inversion-based power control perform sub-optimally
as compared to max-min power control. As a consequence, we propose a particle
swarm algorithm~(PSA) based power control algorithm to optimize the performance
of the system under study. We then use numerical simulations to evaluate the
performance of the proposed PSA-based solution and show that it results in a
significant improvement in the fairness of the underlying system while
incurring a lower computational complexity.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08303" title="Abstract">arXiv:2308.08303</a> [<a href="/pdf/2308.08303" title="Download PDF">pdf</a>, <a href="/format/2308.08303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Next-Active Objects for Context-Aware Anticipation in  Egocentric Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+S">Sanket Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Beyan%2C+C">Cigdem Beyan</a>, 
<a href="/search/cs?searchtype=author&query=Morerio%2C+P">Pietro Morerio</a>, 
<a href="/search/cs?searchtype=author&query=Murino%2C+V">Vittorio Murino</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bue%2C+A">Alessio Del Bue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Objects are crucial for understanding human-object interactions. By
identifying the relevant objects, one can also predict potential future
interactions or actions that may occur with these objects. In this paper, we
study the problem of Short-Term Object interaction anticipation (STA) and
propose NAOGAT (Next-Active-Object Guided Anticipation Transformer), a
multi-modal end-to-end transformer network, that attends to objects in observed
frames in order to anticipate the next-active-object (NAO) and, eventually, to
guide the model to predict context-aware future actions. The task is
challenging since it requires anticipating future action along with the object
with which the action occurs and the time after which the interaction will
begin, a.k.a. the time to contact (TTC). Compared to existing video modeling
architectures for action anticipation, NAOGAT captures the relationship between
objects and the global scene context in order to predict detections for the
next active object and anticipate relevant future actions given these
detections, leveraging the objects' dynamics to improve accuracy. One of the
key strengths of our approach, in fact, is its ability to exploit the motion
dynamics of objects within a given clip, which is often ignored by other
models, and separately decoding the object-centric and motion-centric
information. Through our experiments, we show that our model outperforms
existing methods on two separate datasets, Ego4D and EpicKitchens-100 ("Unseen
Set"), as measured by several additional metrics, such as time to contact, and
next-active-object localization. The code will be available upon acceptance.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08307" title="Abstract">arXiv:2308.08307</a> [<a href="/pdf/2308.08307" title="Download PDF">pdf</a>, <a href="/format/2308.08307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating cognitive map learning and active inference for planning in  ambiguous environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+de+Maele%2C+T">Toon Van de Maele</a>, 
<a href="/search/cs?searchtype=author&query=Dhoedt%2C+B">Bart Dhoedt</a>, 
<a href="/search/cs?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/cs?searchtype=author&query=Pezzulo%2C+G">Giovanni Pezzulo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IWAI 2023 (International Workshop on Active Inference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Living organisms need to acquire both cognitive maps for learning the
structure of the world and planning mechanisms able to deal with the challenges
of navigating ambiguous environments. Although significant progress has been
made in each of these areas independently, the best way to integrate them is an
open research question. In this paper, we propose the integration of a
statistical model of cognitive map formation within an active inference agent
that supports planning under uncertainty. Specifically, we examine the
clone-structured cognitive graph (CSCG) model of cognitive map formation and
compare a naive clone graph agent with an active inference-driven clone graph
agent, in three spatial navigation scenarios. Our findings demonstrate that
while both agents are effective in simple scenarios, the active inference agent
is more effective when planning in challenging scenarios, in which sensory
observations provide ambiguous information about location.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08310" title="Abstract">arXiv:2308.08310</a> [<a href="/pdf/2308.08310" title="Download PDF">pdf</a>, <a href="/format/2308.08310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy at Risk: Exploiting Similarities in Health Data for Identity  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+L">Lucas Lange</a>, 
<a href="/search/cs?searchtype=author&query=Schreieder%2C+T">Tobias Schreieder</a>, 
<a href="/search/cs?searchtype=author&query=Christen%2C+V">Victor Christen</a>, 
<a href="/search/cs?searchtype=author&query=Rahm%2C+E">Erhard Rahm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Smartwatches enable the efficient collection of health data that can be used
for research and comprehensive analysis to improve the health of individuals.
In addition to the analysis capabilities, ensuring privacy when handling health
data is a critical concern as the collection and analysis of such data become
pervasive. Since health data contains sensitive information, it should be
handled with responsibility and is therefore often treated anonymously.
However, also the data itself can be exploited to reveal information and break
anonymity. We propose a novel similarity-based re-identification attack on
time-series health data and thereby unveil a significant vulnerability. Despite
privacy measures that remove identifying information, our attack demonstrates
that a brief amount of various sensor data from a target individual is adequate
to possibly identify them within a database of other samples, solely based on
sensor-level similarities. In our example scenario, where data owners leverage
health data from smartwatches, findings show that we are able to correctly link
the target data in two out of three cases. User privacy is thus already
inherently threatened by the data itself and even when removing personal
information.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08316" title="Abstract">arXiv:2308.08316</a> [<a href="/pdf/2308.08316" title="Download PDF">pdf</a>, <a href="/format/2308.08316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Stream Diffusion Net for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Binhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Anbo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the emerging diffusion models, recently, text-to-video generation has
aroused increasing attention. But an important bottleneck therein is that
generative videos often tend to carry some flickers and artifacts. In this
work, we propose a dual-stream diffusion net (DSDN) to improve the consistency
of content variations in generating videos. In particular, the designed two
diffusion streams, video content and motion branches, could not only run
separately in their private spaces for producing personalized video variations
as well as content, but also be well-aligned between the content and motion
domains through leveraging our designed cross-transformer interaction module,
which would benefit the smoothness of generated videos. Besides, we also
introduce motion decomposer and combiner to faciliate the operation on video
motion. Qualitative and quantitative experiments demonstrate that our method
could produce amazing continuous videos with fewer flickers.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08321" title="Abstract">arXiv:2308.08321</a> [<a href="/pdf/2308.08321" title="Download PDF">pdf</a>, <a href="/format/2308.08321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable and Causal Inference for Discriminative Self-supervised Deep  Visual Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuewei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, discriminative self-supervised methods have made significant
strides in advancing various visual tasks. The central idea of learning a data
encoder that is robust to data distortions/augmentations is straightforward yet
highly effective. Although many studies have demonstrated the empirical success
of various learning methods, the resulting learned representations can exhibit
instability and hinder downstream performance. In this study, we analyze
discriminative self-supervised methods from a causal perspective to explain
these unstable behaviors and propose solutions to overcome them. Our approach
draws inspiration from prior works that empirically demonstrate the ability of
discriminative self-supervised methods to demix ground truth causal sources to
some extent. Unlike previous work on causality-empowered representation
learning, we do not apply our solutions during the training process but rather
during the inference process to improve time efficiency. Through experiments on
both controlled image datasets and realistic image datasets, we show that our
proposed solutions, which involve tempering a linear transformation with
controlled synthetic data, are effective in addressing these issues.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08322" title="Abstract">arXiv:2308.08322</a> [<a href="/pdf/2308.08322" title="Download PDF">pdf</a>, <a href="/format/2308.08322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Valid and Reliable Privacy Concern Scales: The Example of  IUIPC-8
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gro%C3%9F%2C+T">Thomas Gro&#xdf;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Funded by the ERC Starting Grant CASCAde (GA no 716980). arXiv admin note: substantial text overlap with <a href="/abs/2011.11749">arXiv:2011.11749</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Valid and reliable measurement instruments are crucial for human factors in
privacy research. We expect them to measure what they purport to measure,
yielding validity, and to measure this consistently, offering us reliability.
While there is a range of privacy concern instruments available in the field
and their investigation continues unabated, we shall focus on a brief form of
the scale Internet Users? Information Privacy Concerns (IUIPC-8) as an example.
We not only present IUIPC-8 itself, but also consider methods for the
evaluation of valid and reliable measurement instruments. In this, confirmatory
factor analysis (CFA) serves us as a valuable tool. Our inquiry takes into
account the ordinal and non-normal data yielded by the IUIPC questionnaire,
compares multiple models to confirm the three-dimensionality of the scale,
examines global and local fit and, finally, estimates construct validity and
internal consistency reliability metrics. We offer a comparison between
IUIPC-10 and IUIPC-8 drawing on two independent samples. In conclusion, we
highlight properties of the scale and considerations for its use in practice.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08324" title="Abstract">arXiv:2308.08324</a> [<a href="/pdf/2308.08324" title="Download PDF">pdf</a>, <a href="/format/2308.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Collaborative Beam Alignment for Millimeter Wave Cell-Free  MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Leming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lujia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures, to appear in the IEEE Transactions on Communications, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Millimeter wave (mmWave) cell-free MIMO achieves an extremely high rate while
its beam alignment (BA) suffers from excessive overhead due to a large number
of transceivers. Recently, user location and probing measurements are utilized
for BA based on machine learning (ML) models, e.g., deep neural network (DNN).
However, most of these ML models are centralized with high communication and
computational overhead and give no specific consideration to practical issues,
e.g., limited training data and real-time model updates. In this paper, we
study the {probing} beam-based BA for mmWave cell-free MIMO downlink with the
help of broad learning (BL). For channels without and with uplink-downlink
reciprocity, we propose the user-side and base station (BS)-side BL-aided
incremental collaborative BA approaches. Via transforming the centralized BL
into a distributed learning with data and feature splitting respectively, the
user-side and BS-side schemes realize implicit sharing of multiple user data
and multiple BS features. Simulations confirm that the user-side scheme is
applicable to fast time-varying and/or non-stationary channels, while the
BS-side scheme is suitable for systems with low-bandwidth fronthaul links and a
central unit with limited computing power. The advantages of proposed schemes
are also demonstrated compared to traditional and DNN-aided BA schemes.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08325" title="Abstract">arXiv:2308.08325</a> [<a href="/pdf/2308.08325" title="Download PDF">pdf</a>, <a href="/format/2308.08325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually-Aware Context Modeling for News Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+T">Tingyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of News Image Captioning is to generate an image caption according
to the content of both a news article and an image. To leverage the visual
information effectively, it is important to exploit the connection between the
context in the articles/captions and the images. Psychological studies indicate
that human faces in images draw higher attention priorities. On top of that,
humans often play a central role in news stories, as also proven by the
face-name co-occurrence pattern we discover in existing News Image Captioning
datasets. Therefore, we design a face-naming module for faces in images and
names in captions/articles to learn a better name embedding. Apart from names,
which can be directly linked to an image area (faces), news image captions
mostly contain context information that can only be found in the article.
Humans typically address this by searching for relevant information from the
article based on the image. To emulate this thought process, we design a
retrieval strategy using CLIP to retrieve sentences that are semantically close
to the image. We conduct extensive experiments to demonstrate the efficacy of
our framework. Without using additional paired data, we establish the new
state-of-the-art performance on two News Image Captioning datasets, exceeding
the previous state-of-the-art by 5 CIDEr points. We will release code upon
acceptance.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08326" title="Abstract">arXiv:2308.08326</a> [<a href="/pdf/2308.08326" title="Download PDF">pdf</a>, <a href="/ps/2308.08326" title="Download PostScript">ps</a>, <a href="/format/2308.08326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft-Information Post-Processing for Chase-Pyndiah Decoding Based on  Generalized Mutual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stra%C3%9Fhofer%2C+A">Andreas Stra&#xdf;hofer</a>, 
<a href="/search/cs?searchtype=author&query=Lentner%2C+D">Diego Lentner</a>, 
<a href="/search/cs?searchtype=author&query=Liva%2C+G">Gianluigi Liva</a>, 
<a href="/search/cs?searchtype=author&query=Amat%2C+A+G+i">Alexandre Graell i Amat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, to be presented at ISTC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Chase-Pyndiah decoding is widely used for decoding product codes. However,
this method is suboptimal and requires scaling the soft information exchanged
during the iterative processing. In this paper, we propose a framework for
obtaining the scaling coefficients based on maximizing the generalized mutual
information. Our approach yields gains up to 0.11 dB for product codes with
two-error correcting extended BCH component codes over the binary-input
additive white Gaussian noise channel compared to the original Chase-Pyndiah
decoder with heuristically obtained coefficients. We also introduce an
extrinsic version of the Chase-Pyndiah decoder and associate product codes with
a turbo-like code ensemble to derive a Monte Carlo-based density evolution
analysis. The resulting iterative decoding thresholds accurately predict the
onset of the waterfall region.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08327" title="Abstract">arXiv:2308.08327</a> [<a href="/pdf/2308.08327" title="Download PDF">pdf</a>, <a href="/format/2308.08327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lianyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liqing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zekang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACMMM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Raw videos have been proven to own considerable feature redundancy where in
many cases only a portion of frames can already meet the requirements for
accurate recognition. In this paper, we are interested in whether such
redundancy can be effectively leveraged to facilitate efficient inference in
continuous sign language recognition (CSLR). We propose a novel adaptive model
(AdaBrowse) to dynamically select a most informative subsequence from input
video sequences by modelling this problem as a sequential decision task. In
specific, we first utilize a lightweight network to quickly scan input videos
to extract coarse features. Then these features are fed into a policy network
to intelligently select a subsequence to process. The corresponding subsequence
is finally inferred by a normal CSLR model for sentence prediction. As only a
portion of frames are processed in this procedure, the total computations can
be considerably saved. Besides temporal redundancy, we are also interested in
whether the inherent spatial redundancy can be seamlessly integrated together
to achieve further efficiency, i.e., dynamically selecting a lowest input
resolution for each sample, whose model is referred to as AdaBrowse+. Extensive
experimental results on four large-scale CSLR datasets, i.e., PHOENIX14,
PHOENIX14-T, CSL-Daily and CSL, demonstrate the effectiveness of AdaBrowse and
AdaBrowse+ by achieving comparable accuracy with state-of-the-art methods with
1.44$\times$ throughput and 2.12$\times$ fewer FLOPs. Comparisons with other
commonly-used 2D CNNs and adaptive efficient methods verify the effectiveness
of AdaBrowse. Code is available at
\url{https://github.com/hulianyuyy/AdaBrowse}.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08328" title="Abstract">arXiv:2308.08328</a> [<a href="/pdf/2308.08328" title="Download PDF">pdf</a>, <a href="/format/2308.08328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Retrieval with Background Information: Decreased References and  Efficient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+N">Ningyi Leng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongxia Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Fourier phase retrieval(PR) is a severely ill-posed inverse problem that
arises in various applications. To guarantee a unique solution and relieve the
dependence on the initialization, background information can be exploited as a
structural priors. However, the requirement for the background information may
be challenging when moving to the high-resolution imaging. At the same time,
the previously proposed projected gradient descent(PGD) method also demands
much background information.
<br />In this paper, we present an improved theoretical result about the demand for
the background information, along with two Douglas Rachford(DR) based methods.
Analytically, we demonstrate that the background required to ensure a unique
solution can be decreased by nearly $1/2$ for the 2-D signals compared to the
1-D signals. By generalizing the results into $d$-dimension, we show that the
length of the background information more than $(2^{\frac{d+1}{d}}-1)$ folds of
the signal is sufficient to ensure the uniqueness. At the same time, we also
analyze the stability and robustness of the model when measurements and
background information are corrupted by the noise. Furthermore, two methods
called Background Douglas-Rachford (BDR) and Convex Background Douglas-Rachford
(CBDR) are proposed. BDR which is a kind of non-convex method is proven to have
the local R-linear convergence rate under mild assumptions. Instead, CBDR
method uses the techniques of convexification and can be proven to own a global
convergence guarantee as long as the background information is sufficient. To
support this, a new property called F-RIP is established. We test the
performance of the proposed methods through simulations as well as real
experimental measurements, and demonstrate that they achieve a higher recovery
rate with less background information compared to the PGD method.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08333" title="Abstract">arXiv:2308.08333</a> [<a href="/pdf/2308.08333" title="Download PDF">pdf</a>, <a href="/format/2308.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Depth Gradient Continuity in Transformers: A Comparative Study  on Monocular Depth Estimation with CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation is an ongoing challenge in computer vision. Recent
progress with Transformer models has demonstrated notable advantages over
conventional CNNs in this area. However, there's still a gap in understanding
how these models prioritize different regions in 2D images and how these
regions affect depth estimation performance. To explore the differences between
Transformers and CNNs, we employ a sparse pixel approach to contrastively
analyze the distinctions between the two. Our findings suggest that while
Transformers excel in handling global context and intricate textures, they lag
behind CNNs in preserving depth gradient continuity. To further enhance the
performance of Transformer models in monocular depth estimation, we propose the
Depth Gradient Refinement (DGR) module that refines depth estimation through
high-order differentiation, feature fusion, and recalibration. Additionally, we
leverage optimal transport theory, treating depth maps as spatial probability
distributions, and employ the optimal transport distance as a loss function to
optimize our model. Experimental results demonstrate that models integrated
with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed
loss function enhance performance without increasing complexity and
computational costs. This research not only offers fresh insights into the
distinctions between Transformers and CNNs in depth estimation but also paves
the way for novel depth estimation methodologies.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08334" title="Abstract">arXiv:2308.08334</a> [<a href="/pdf/2308.08334" title="Download PDF">pdf</a>, <a href="/ps/2308.08334" title="Download PostScript">ps</a>, <a href="/format/2308.08334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Logic Programs by Discovering Higher-Order Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hocquette%2C+C">C&#xe9;line Hocquette</a>, 
<a href="/search/cs?searchtype=author&query=Duman%C4%8Di%C4%87%2C+S">Sebastijan Duman&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Discovering novel abstractions is important for human-level AI. We introduce
an approach to discover higher-order abstractions, such as map, filter, and
fold. We focus on inductive logic programming, which induces logic programs
from examples and background knowledge. We introduce the higher-order
refactoring problem, where the goal is to compress a logic program by
introducing higher-order abstractions. We implement our approach in STEVIE,
which formulates the higher-order refactoring problem as a constraint
optimisation problem. Our experimental results on multiple domains, including
program synthesis and visual reasoning, show that, compared to no refactoring,
STEVIE can improve predictive accuracies by 27% and reduce learning times by
47%. We also show that STEVIE can discover abstractions that transfer to
different domains
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08335" title="Abstract">arXiv:2308.08335</a> [<a href="/pdf/2308.08335" title="Download PDF">pdf</a>, <a href="/format/2308.08335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equilibrium-Independent Control of Continuous-Time Nonlinear Systems via  the LPV Framework -- Extended Version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Koelewijn%2C+P+J+W">Patrick J. W. Koelewijn</a>, 
<a href="/search/eess?searchtype=author&query=Weiland%2C+S">Siep Weiland</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B3th%2C+R">Roland T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Non-extended version submitted to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we consider the analysis and control of continuous-time
nonlinear systems to ensure universal shifted stability and performance, i.e.,
stability and performance w.r.t. each forced equilibrium point of the system.
This "equilibrium-free" concept is especially beneficial for control problems
that require the tracking of setpoints and rejection of persistent
disturbances, such as input loads. In this paper, we show how the velocity
form, i.e., the time-differentiated dynamics of the system, plays a crucial
role in characterizing these properties and how the analysis of it can be
solved by the application of Linear Parameter-Varying (LPV) methods in a
computationally efficient manner. Furthermore, by leveraging the properties of
the velocity form and the LPV framework, a novel controller synthesis method is
presented which ensures closed-loop universal shifted stability and
performance. The proposed controller design is verified in a simulation study
and also experimentally on a real system. Additionally, we compare the proposed
method to a standard LPV control design, demonstrating the improved stability
and performance guarantees of the new approach.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08343" title="Abstract">arXiv:2308.08343</a> [<a href="/pdf/2308.08343" title="Download PDF">pdf</a>, <a href="/format/2308.08343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Noise for $f$-Differential Privacy via Anti-Concentration and  Stochastic Dominance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Awan%2C+J">Jordan Awan</a>, 
<a href="/search/cs?searchtype=author&query=Ramasethu%2C+A">Aishwarya Ramasethu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages before appendix, 25 pages total, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper, we establish anti-concentration inequalities for additive
noise mechanisms which achieve $f$-differential privacy ($f$-DP), a notion of
privacy phrased in terms of a tradeoff function (a.k.a. ROC curve) $f$ which
limits the ability of an adversary to determine which individuals were in the
database. We show that canonical noise distributions (CNDs), proposed by Awan
and Vadhan (2023), match the anti-concentration bounds at half-integer values,
indicating that their tail behavior is near-optimal. We also show that all CNDs
are sub-exponential, regardless of the $f$-DP guarantee. In the case of
log-concave CNDs, we show that they are the stochastically smallest noise
compared to any other noise distributions with the same privacy guarantee. In
terms of integer-valued noise, we propose a new notion of discrete CND and
prove that a discrete CND always exists, can be constructed by rounding a
continuous CND, and that the discrete CND is unique when designed for a
statistic with sensitivity 1. We further show that the discrete CND at
sensitivity 1 is stochastically smallest compared to other integer-valued
noises. Our theoretical results shed light on the different types of privacy
guarantees possible in the $f$-DP framework and can be incorporated in more
complex mechanisms to optimize performance.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08344" title="Abstract">arXiv:2308.08344</a> [<a href="/pdf/2308.08344" title="Download PDF">pdf</a>, <a href="/format/2308.08344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Out-of-Distribution Generalization with Controllable Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Bin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+X">Xiaoying Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ze Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shiyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Luoyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph Neural Network (GNN) has demonstrated extraordinary performance in
classifying graph properties. However, due to the selection bias of training
and testing data (e.g., training on small graphs and testing on large graphs,
or training on dense graphs and testing on sparse graphs), distribution
deviation is widespread. More importantly, we often observe \emph{hybrid
structure distribution shift} of both scale and density, despite of one-sided
biased data partition. The spurious correlations over hybrid distribution
deviation degrade the performance of previous GNN methods and show large
instability among different datasets. To alleviate this problem, we propose
\texttt{OOD-GMixup} to jointly manipulate the training distribution with
\emph{controllable data augmentation} in metric space. Specifically, we first
extract the graph rationales to eliminate the spurious correlations due to
irrelevant information. Secondly, we generate virtual samples with perturbation
on graph rationale representation domain to obtain potential OOD training
samples. Finally, we propose OOD calibration to measure the distribution
deviation of virtual samples by leveraging Extreme Value Theory, and further
actively control the training distribution by emphasizing the impact of virtual
OOD samples. Extensive studies on several real-world datasets on graph
classification demonstrate the superiority of our proposed method over
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08347" title="Abstract">arXiv:2308.08347</a> [<a href="/pdf/2308.08347" title="Download PDF">pdf</a>, <a href="/ps/2308.08347" title="Download PostScript">ps</a>, <a href="/format/2308.08347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuing WebAssembly with Effect Handlers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phipps-Costin%2C+L">Luna Phipps-Costin</a>, 
<a href="/search/cs?searchtype=author&query=Rossberg%2C+A">Andreas Rossberg</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>, 
<a href="/search/cs?searchtype=author&query=Leijen%2C+D">Daan Leijen</a>, 
<a href="/search/cs?searchtype=author&query=Hillerstr%C3%B6m%2C+D">Daniel Hillerstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Sivaramakrishnan%2C+K">KC Sivaramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+S">Sam Lindley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">WebAssembly (Wasm) is a low-level portable code format offering near native
performance. It is intended as a compilation target for a wide variety of
source languages. However, Wasm provides no direct support for non-local
control flow features such as async/await, generators/iterators, lightweight
threads, first-class continuations, etc. This means that compilers for source
languages with such features must ceremoniously transform whole source programs
in order to target Wasm. We present WasmFX, an extension to Wasm which provides
a universal target for non-local control features via effect handlers, enabling
compilers to translate such features directly into Wasm. Our extension is
minimal and only adds three main instructions for creating, suspending, and
resuming continuations. Moreover, our primitive instructions are type-safe
providing typed continuations which are well-aligned with the design principles
of Wasm whose stacks are typed. We present a formal specification of WasmFX and
show that the extension is sound. We have implemented WasmFX as an extension to
the Wasm reference interpreter and also built a prototype WasmFX extension for
Wasmtime, a production-grade Wasm engine, piggybacking on Wasmtime's existing
fibers API. The preliminary performance results for our prototype are
encouraging, and we outline future plans to realise a native implementation
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08354" title="Abstract">arXiv:2308.08354</a> [<a href="/pdf/2308.08354" title="Download PDF">pdf</a>, <a href="/format/2308.08354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Meta-Learning the Right Approach for the Cold-Start Problem in  Recommender Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buffelli%2C+D">Davide Buffelli</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ashish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Strzalka%2C+A">Agnieszka Strzalka</a>, 
<a href="/search/cs?searchtype=author&query=Plachouras%2C+V">Vassilis Plachouras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommender systems have become fundamental building blocks of modern online
products and services, and have a substantial impact on user experience. In the
past few years, deep learning methods have attracted a lot of research, and are
now heavily used in modern real-world recommender systems. Nevertheless,
dealing with recommendations in the cold-start setting, e.g., when a user has
done limited interactions in the system, is a problem that remains far from
solved. Meta-learning techniques, and in particular optimization-based
meta-learning, have recently become the most popular approaches in the academic
research literature for tackling the cold-start problem in deep learning models
for recommender systems. However, current meta-learning approaches are not
practical for real-world recommender systems, which have billions of users and
items, and strict latency requirements. In this paper we show that it is
possible to obtaining similar, or higher, performance on commonly used
benchmarks for the cold-start problem without using meta-learning techniques.
In more detail, we show that, when tuned correctly, standard and widely adopted
deep learning models perform just as well as newer meta-learning models. We
further show that an extremely simple modular approach using common
representation learning techniques, can perform comparably to meta-learning
techniques specifically designed for the cold-start setting while being much
more easily deployable in real-world applications.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08356" title="Abstract">arXiv:2308.08356</a> [<a href="/pdf/2308.08356" title="Download PDF">pdf</a>, <a href="/format/2308.08356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating IP Blacklists Effectiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deri%2C+L">Luca Deri</a>, 
<a href="/search/cs?searchtype=author&query=Fusco%2C+F">Francesco Fusco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">IP blacklists are widely used to increase network security by preventing
communications with peers that have been marked as malicious. There are several
commercial offerings as well as several free-of-charge blacklists maintained by
volunteers on the web. Despite their wide adoption, the effectiveness of the
different IP blacklists in real-world scenarios is still not clear. In this
paper, we conduct a large-scale network monitoring study which provides
insightful findings regarding the effectiveness of blacklists. The results
collected over several hundred thousand IP hosts belonging to three distinct
large production networks highlight that blacklists are often tuned for
precision, with the result that many malicious activities, such as scanning,
are completely undetected. The proposed instrumentation approach to detect IP
scanning and suspicious activities is implemented with home-grown and
open-source software. Our tools enable the creation of blacklists without the
security risks posed by the deployment of honeypots.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08358" title="Abstract">arXiv:2308.08358</a> [<a href="/pdf/2308.08358" title="Download PDF">pdf</a>, <a href="/ps/2308.08358" title="Download PostScript">ps</a>, <a href="/format/2308.08358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Two-Layer Regression with Nonlinear Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yichuan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shenghao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Large language models (LLMs), such as ChatGPT and GPT4, have shown
outstanding performance in many human life task. Attention computation plays an
important role in training LLMs. Softmax unit and ReLU unit are the key
structure in attention computation. Inspired by them, we put forward a softmax
ReLU regression problem. Generally speaking, our goal is to find an optimal
solution to the regression problem involving the ReLU unit. In this work, we
calculate a close form representation for the Hessian of the loss function.
Under certain assumptions, we prove the Lipschitz continuous and the PSDness of
the Hessian. Then, we introduce an greedy algorithm based on approximate Newton
method, which converges in the sense of the distance to optimal solution. Last,
We relax the Lipschitz condition and prove the convergence in the sense of loss
value.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08359" title="Abstract">arXiv:2308.08359</a> [<a href="/pdf/2308.08359" title="Download PDF">pdf</a>, <a href="/format/2308.08359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Membrane Potential Batch Normalization for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yufei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaode Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhe Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As one of the energy-efficient alternatives of conventional neural networks
(CNNs), spiking neural networks (SNNs) have gained more and more interest
recently. To train the deep models, some effective batch normalization (BN)
techniques are proposed in SNNs. All these BNs are suggested to be used after
the convolution layer as usually doing in CNNs. However, the spiking neuron is
much more complex with the spatio-temporal dynamics. The regulated data flow
after the BN layer will be disturbed again by the membrane potential updating
operation before the firing function, i.e., the nonlinear activation.
Therefore, we advocate adding another BN layer before the firing function to
normalize the membrane potential again, called MPBN. To eliminate the induced
time cost of MPBN, we also propose a training-inference-decoupled
re-parameterization technique to fold the trained MPBN into the firing
threshold. With the re-parameterization technique, the MPBN will not introduce
any extra time burden in the inference. Furthermore, the MPBN can also adopt
the element-wised form, while these BNs after the convolution layer can only
use the channel-wised form. Experimental results show that the proposed MPBN
performs well on both popular non-spiking static and neuromorphic datasets. Our
code is open-sourced at \href{https://github.com/yfguo91/MPBN}{MPBN}.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08360" title="Abstract">arXiv:2308.08360</a> [<a href="/pdf/2308.08360" title="Download PDF">pdf</a>, <a href="/format/2308.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Independent Distribution Regularization for Private Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Learning graph embeddings is a crucial task in graph mining tasks. An
effective graph embedding model can learn low-dimensional representations from
graph-structured data for data publishing benefiting various downstream
applications such as node classification, link prediction, etc. However, recent
studies have revealed that graph embeddings are susceptible to attribute
inference attacks, which allow attackers to infer private node attributes from
the learned graph embeddings. To address these concerns, privacy-preserving
graph embedding methods have emerged, aiming to simultaneously consider primary
learning and privacy protection through adversarial learning. However, most
existing methods assume that representation models have access to all sensitive
attributes in advance during the training stage, which is not always the case
due to diverse privacy preferences. Furthermore, the commonly used adversarial
learning technique in privacy-preserving representation learning suffers from
unstable training issues. In this paper, we propose a novel approach called
Private Variational Graph AutoEncoders (PVGAE) with the aid of independent
distribution penalty as a regularization term. Specifically, we split the
original variational graph autoencoder (VGAE) to learn sensitive and
non-sensitive latent representations using two sets of encoders. Additionally,
we introduce a novel regularization to enforce the independence of the
encoders. We prove the theoretical effectiveness of regularization from the
perspective of mutual information. Experimental results on three real-world
datasets demonstrate that PVGAE outperforms other baselines in private
embedding learning regarding utility performance and privacy protection.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08361" title="Abstract">arXiv:2308.08361</a> [<a href="/pdf/2308.08361" title="Download PDF">pdf</a>, <a href="/format/2308.08361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Anbang Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research work was completed and submitted in early May 2023. Code and pre-trained models are available at <a href="https://github.com/OSVAI/KernelWarehouse">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dynamic convolution learns a linear mixture of $n$ static kernels weighted
with their sample-dependent attentions, demonstrating superior performance
compared to normal convolution. However, existing designs are
parameter-inefficient: they increase the number of convolutional parameters by
$n$ times. This and the optimization difficulty lead to no research progress in
dynamic convolution that can allow us to use a significant large value of $n$
(e.g., $n&gt;100$ instead of typical setting $n&lt;10$) to push forward the
performance boundary. In this paper, we propose $KernelWarehouse$, a more
general form of dynamic convolution, which can strike a favorable trade-off
between parameter efficiency and representation power. Its key idea is to
redefine the basic concepts of "$kernels$" and "$assembling$ $kernels$" in
dynamic convolution from the perspective of reducing kernel dimension and
increasing kernel number significantly. In principle, KernelWarehouse enhances
convolutional parameter dependencies within the same layer and across
successive layers via tactful kernel partition and warehouse sharing, yielding
a high degree of freedom to fit a desired parameter budget. We validate our
method on ImageNet and MS-COCO datasets with different ConvNet architectures,
and show that it attains state-of-the-art results. For instance, the
ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny model trained with KernelWarehouse
on ImageNet reaches 76.05%|81.05%|75.52%|82.51% top-1 accuracy. Thanks to its
flexible design, KernelWarehouse can even reduce the model size of a ConvNet
while improving the accuracy, e.g., our ResNet18 model with 36.45%|65.10%
parameter reduction to the baseline shows 2.89%|2.29% absolute improvement to
top-1 accuracy.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08362" title="Abstract">arXiv:2308.08362</a> [<a href="/pdf/2308.08362" title="Download PDF">pdf</a>, <a href="/format/2308.08362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Consistency across Retail Central Bank Digital Currency and  Commercial Bank Money
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braine%2C+L">Lee Braine</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+S">Shreepad Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Piyush Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Central banks are actively exploring central bank digital currencies (CBDCs)
by conducting research, proofs of concept and pilots. However, adoption of a
retail CBDC can risk fragmenting both payments markets and retail deposits if
the retail CBDC and commercial bank money do not have common operational
characteristics. In this paper, we focus on a potential UK retail CBDC, the
'digital pound', and the Bank of England's 'platform model'. We first explore
how the concept of functional consistency could mitigate the risk of
fragmentation. We next identify the common operational characteristics that are
required to achieve functional consistency across all forms of regulated retail
digital money. We identify four design options based on the provision of these
common operational characteristics by the central bank, payment interface
providers (PIPs), technical service providers (TSPs) or a financial market
infrastructure (FMI). We next identify architecturally-significant use cases
and select key capabilities that support these use cases and the common
operational characteristics. We evaluate the suitability of the design options
to provide these key capabilities and draw insights. We conclude that no single
design option could provide functional consistency across digital pounds and
commercial bank money and, instead, a complete solution would need to combine
the suitable design option(s) for each key capability and include common
ecosystem services provided by an FMI and TSPs.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08363" title="Abstract">arXiv:2308.08363</a> [<a href="/pdf/2308.08363" title="Download PDF">pdf</a>, <a href="/format/2308.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SummHelper: Collaborative Human-Computer Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slobodkin%2C+A">Aviv Slobodkin</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+N">Niv Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Amar%2C+S">Shmuel Amar</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+O">Ori Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current approaches for text summarization are predominantly automatic, with
rather limited space for human intervention and control over the process. In
this paper, we introduce SummHelper, a 2-phase summarization assistant designed
to foster human-machine collaboration. The initial phase involves content
selection, where the system recommends potential content, allowing users to
accept, modify, or introduce additional selections. The subsequent phase,
content consolidation, involves SummHelper generating a coherent summary from
these selections, which users can then refine using visual mappings between the
summary and the source text. Small-scale user studies reveal the effectiveness
of our application, with participants being especially appreciative of the
balance between automated guidance and opportunities for personal input.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08366" title="Abstract">arXiv:2308.08366</a> [<a href="/pdf/2308.08366" title="Download PDF">pdf</a>, <a href="/format/2308.08366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Branch Temperature Scaling Calibration for Long-Tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jialin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Z">Zhiqiang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The calibration for deep neural networks is currently receiving widespread
attention and research. Miscalibration usually leads to overconfidence of the
model. While, under the condition of long-tailed distribution of data, the
problem of miscalibration is more prominent due to the different confidence
levels of samples in minority and majority categories, and it will result in
more serious overconfidence. To address this problem, some current research
have designed diverse temperature coefficients for different categories based
on temperature scaling (TS) method. However, in the case of rare samples in
minority classes, the temperature coefficient is not generalizable, and there
is a large difference between the temperature coefficients of the training set
and the validation set. To solve this challenge, this paper proposes a
dual-branch temperature scaling calibration model (Dual-TS), which considers
the diversities in temperature parameters of different categories and the
non-generalizability of temperature parameters for rare samples in minority
classes simultaneously. Moreover, we noticed that the traditional calibration
evaluation metric, Excepted Calibration Error (ECE), gives a higher weight to
low-confidence samples in the minority classes, which leads to inaccurate
evaluation of model calibration. Therefore, we also propose Equal Sample Bin
Excepted Calibration Error (Esbin-ECE) as a new calibration evaluation metric.
Through experiments, we demonstrate that our model yields state-of-the-art in
both traditional ECE and Esbin-ECE metrics.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08367" title="Abstract">arXiv:2308.08367</a> [<a href="/pdf/2308.08367" title="Download PDF">pdf</a>, <a href="/format/2308.08367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Ran Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sanfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yanbing Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">To enhance the security of text CAPTCHAs, various methods have been employed,
such as adding the interference lines on the text, randomly distorting the
characters, and overlapping multiple characters. These methods partly increase
the difficulty of automated segmentation and recognition attacks. However,
facing the rapid development of the end-to-end breaking algorithms, their
security has been greatly weakened. The diffusion model is a novel image
generation model that can generate the text images with deep fusion of
characters and background images. In this paper, an image-click CAPTCHA scheme
called Diff-CAPTCHA is proposed based on denoising diffusion models. The
background image and characters of the CAPTCHA are treated as a whole to guide
the generation process of a diffusion model, thus weakening the character
features available for machine learning, enhancing the diversity of character
features in the CAPTCHA, and increasing the difficulty of breaking algorithms.
To evaluate the security of Diff-CAPTCHA, this paper develops several attack
methods, including end-to-end attacks based on Faster R-CNN and two-stage
attacks, and Diff-CAPTCHA is compared with three baseline schemes, including
commercial CAPTCHA scheme and security-enhanced CAPTCHA scheme based on style
transfer. The experimental results show that diffusion models can effectively
enhance CAPTCHA security while maintaining good usability in human testing.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08370" title="Abstract">arXiv:2308.08370</a> [<a href="/pdf/2308.08370" title="Download PDF">pdf</a>, <a href="/format/2308.08370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agglomerative Transformer for Human-Object Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+D">Danyang Tu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose an agglomerative Transformer (AGER) that enables Transformer-based
human-object interaction (HOI) detectors to flexibly exploit extra
instance-level cues in a single-stage and end-to-end manner for the first time.
AGER acquires instance tokens by dynamically clustering patch tokens and
aligning cluster centers to instances with textual guidance, thus enjoying two
benefits: 1) Integrality: each instance token is encouraged to contain all
discriminative feature regions of an instance, which demonstrates a significant
improvement in the extraction of different instance-level cues and subsequently
leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on
HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to
generate instance tokens jointly with the feature learning of the Transformer
encoder, eliminating the need of an additional object detector or instance
decoder in prior methods, thus allowing the extraction of desirable extra cues
for HOI detection in a single-stage and end-to-end pipeline. Concretely, AGER
reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla
DETR-like pipeline without extra cue extraction.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08371" title="Abstract">arXiv:2308.08371</a> [<a href="/pdf/2308.08371" title="Download PDF">pdf</a>, <a href="/format/2308.08371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDPK: A Framework to Synthesise Process Data and Corresponding  Procedural Knowledge for Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nordsieck%2C+R">Richard Nordsieck</a>, 
<a href="/search/cs?searchtype=author&query=Schweizer%2C+A">Andr&#xe9; Schweizer</a>, 
<a href="/search/cs?searchtype=author&query=Heider%2C+M">Michael Heider</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4hner%2C+J">J&#xf6;rg H&#xe4;hner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Procedural knowledge describes how to accomplish tasks and mitigate problems.
Such knowledge is commonly held by domain experts, e.g. operators in
manufacturing who adjust parameters to achieve quality targets. To the best of
our knowledge, no real-world datasets containing process data and corresponding
procedural knowledge are publicly available, possibly due to corporate
apprehensions regarding the loss of knowledge advances. Therefore, we provide a
framework to generate synthetic datasets that can be adapted to different
domains. The design choices are inspired by two real-world datasets of
procedural knowledge we have access to. Apart from containing representations
of procedural knowledge in Resource Description Framework (RDF)-compliant
knowledge graphs, the framework simulates parametrisation processes and
provides consistent process data. We compare established embedding methods on
the resulting knowledge graphs, detailing which out-of-the-box methods have the
potential to represent procedural knowledge. This provides a baseline which can
be used to increase the comparability of future work. Furthermore, we validate
the overall characteristics of a synthesised dataset by comparing the results
to those achievable on a real-world dataset. The framework and evaluation code,
as well as the dataset used in the evaluation, are available open source.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08373" title="Abstract">arXiv:2308.08373</a> [<a href="/pdf/2308.08373" title="Download PDF">pdf</a>, <a href="/ps/2308.08373" title="Download PostScript">ps</a>, <a href="/format/2308.08373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation Algorithms for Norm Multiway Cut
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carlson%2C+C">Charlie Carlson</a>, 
<a href="/search/cs?searchtype=author&query=Jafarov%2C+J">Jafar Jafarov</a>, 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+K">Konstantin Makarychev</a>, 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+Y">Yury Makarychev</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+L">Liren Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, ESA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider variants of the classic Multiway Cut problem. Multiway Cut asks
to partition a graph $G$ into $k$ parts so as to separate $k$ given terminals.
Recently, Chandrasekaran and Wang (ESA 2021) introduced $\ell_p$-norm Multiway,
a generalization of the problem, in which the goal is to minimize the $\ell_p$
norm of the edge boundaries of $k$ parts. We provide an $O(\log^{1/2}
n\log^{1/2+1/p} k)$ approximation algorithm for this problem, improving upon
the approximation guarantee of $O(\log^{3/2} n \log^{1/2} k)$ due to
Chandrasekaran and Wang.
<br />We also introduce and study Norm Multiway Cut, a further generalization of
Multiway Cut. We assume that we are given access to an oracle, which answers
certain queries about the norm. We present an $O(\log^{1/2} n \log^{7/2} k)$
approximation algorithm with a weaker oracle and an $O(\log^{1/2} n \log^{5/2}
k)$ approximation algorithm with a stronger oracle. Additionally, we show that
without any oracle access, there is no $n^{1/4-\varepsilon}$ approximation
algorithm for every $\varepsilon &gt; 0$ assuming the Hypergraph Dense-vs-Random
Conjecture.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08374" title="Abstract">arXiv:2308.08374</a> [<a href="/pdf/2308.08374" title="Download PDF">pdf</a>, <a href="/format/2308.08374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Patterns with Variables Under Simon&#x27;s Congruence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fleischmann%2C+P">Pamela Fleischmann</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ko%C3%9F%2C+T">Tore Ko&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Manea%2C+F">Florin Manea</a>, 
<a href="/search/cs?searchtype=author&query=Nowotka%2C+D">Dirk Nowotka</a>, 
<a href="/search/cs?searchtype=author&query=Siemer%2C+S">Stefan Siemer</a>, 
<a href="/search/cs?searchtype=author&query=Wiedenh%C3%B6ft%2C+M">Max Wiedenh&#xf6;ft</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We introduce and investigate a series of matching problems for patterns with
variables under Simon's congruence. Our results provide a thorough picture of
these problems' computational complexity.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08376" title="Abstract">arXiv:2308.08376</a> [<a href="/pdf/2308.08376" title="Download PDF">pdf</a>, <a href="/format/2308.08376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Semiconductor Defect Inspection in Scanning Electron  Microscope Images: a Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lechien%2C+T">Thibault Lechien</a>, 
<a href="/search/cs?searchtype=author&query=Dehaerne%2C+E">Enrique Dehaerne</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+B">Bappaditya Dey</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+V">Victor Blanco</a>, 
<a href="/search/cs?searchtype=author&query=De+Gendt%2C+S">Stefan De Gendt</a>, 
<a href="/search/cs?searchtype=author&query=Meert%2C+W">Wannes Meert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A growing need exists for efficient and accurate methods for detecting
defects in semiconductor materials and devices. These defects can have a
detrimental impact on the efficiency of the manufacturing process, because they
cause critical failures and wafer-yield limitations. As nodes and patterns get
smaller, even high-resolution imaging techniques such as Scanning Electron
Microscopy (SEM) produce noisy images due to operating close to sensitivity
levels and due to varying physical properties of different underlayers or
resist materials. This inherent noise is one of the main challenges for defect
inspection. One promising approach is the use of machine learning algorithms,
which can be trained to accurately classify and locate defects in semiconductor
samples. Recently, convolutional neural networks have proved to be particularly
useful in this regard. This systematic review provides a comprehensive overview
of the state of automated semiconductor defect inspection on SEM images,
including the most recent innovations and developments. 38 publications were
selected on this topic, indexed in IEEE Xplore and SPIE databases. For each of
these, the application, methodology, dataset, results, limitations and future
work were summarized. A comprehensive overview and analysis of their methods is
provided. Finally, promising avenues for future work in the field of SEM-based
defect inspection are suggested.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08378" title="Abstract">arXiv:2308.08378</a> [<a href="/pdf/2308.08378" title="Download PDF">pdf</a>, <a href="/format/2308.08378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing continual lifelong learning in neural information retrieval:  definition, dataset, framework, and empirical evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jingrui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cosma%2C+G">Georgina Cosma</a>, 
<a href="/search/cs?searchtype=author&query=Finke%2C+A">Axel Finke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Information Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Continual learning refers to the capability of a machine learning model to
learn and adapt to new information, without compromising its performance on
previously learned tasks. Although several studies have investigated continual
learning methods for information retrieval tasks, a well-defined task
formulation is still lacking, and it is unclear how typical learning strategies
perform in this context. To address this challenge, a systematic task
formulation of continual neural information retrieval is presented, along with
a multiple-topic dataset that simulates continuous information retrieval. A
comprehensive continual neural information retrieval framework consisting of
typical retrieval models and continual learning strategies is then proposed.
Empirical evaluations illustrate that the proposed framework can successfully
prevent catastrophic forgetting in neural information retrieval and enhance
performance on previously learned tasks. The results indicate that
embedding-based retrieval models experience a decline in their continual
learning performance as the topic shift distance and dataset volume of new
tasks increase. In contrast, pretraining-based models do not show any such
correlation. Adopting suitable learning strategies can mitigate the effects of
topic shift and data augmentation.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08379" title="Abstract">arXiv:2308.08379</a> [<a href="/pdf/2308.08379" title="Download PDF">pdf</a>, <a href="/format/2308.08379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A distributed neural network architecture for dynamic sensor selection  with application to bandwidth-constrained body-sensor networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strypsteen%2C+T">Thomas Strypsteen</a>, 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+A">Alexander Bertrand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose a dynamic sensor selection approach for deep neural networks
(DNNs), which is able to derive an optimal sensor subset selection for each
specific input sample instead of a fixed selection for the entire dataset. This
dynamic selection is jointly learned with the task model in an end-to-end way,
using the Gumbel-Softmax trick to allow the discrete decisions to be learned
through standard backpropagation. We then show how we can use this dynamic
selection to increase the lifetime of a wireless sensor network (WSN) by
imposing constraints on how often each node is allowed to transmit. We further
improve performance by including a dynamic spatial filter that makes the
task-DNN more robust against the fact that it now needs to be able to handle a
multitude of possible node subsets. Finally, we explain how the selection of
the optimal channels can be distributed across the different nodes in a WSN. We
validate this method on a use case in the context of body-sensor networks,
where we use real electroencephalography (EEG) sensor data to emulate an EEG
sensor network. We analyze the resulting trade-offs between transmission load
and task accuracy.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08380" title="Abstract">arXiv:2308.08380</a> [<a href="/pdf/2308.08380" title="Download PDF">pdf</a>, <a href="/format/2308.08380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Autonomous Vehicle Pursuit without Expert Steering Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiaxin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Changyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gladkova%2C+M">Mariia Gladkova</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+Q">Qadeer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, we present a learning method for lateral and longitudinal
motion control of an ego-vehicle for vehicle pursuit. The car being controlled
does not have a pre-defined route, rather it reactively adapts to follow a
target vehicle while maintaining a safety distance. To train our model, we do
not rely on steering labels recorded from an expert driver but effectively
leverage a classical controller as an offline label generation tool. In
addition, we account for the errors in the predicted control values, which can
lead to a loss of tracking and catastrophic crashes of the controlled vehicle.
To this end, we propose an effective data augmentation approach, which allows
to train a network capable of handling different views of the target vehicle.
During the pursuit, the target vehicle is firstly localized using a
Convolutional Neural Network. The network takes a single RGB image along with
cars' velocities and estimates the target vehicle's pose with respect to the
ego-vehicle. This information is then fed to a Multi-Layer Perceptron, which
regresses the control commands for the ego-vehicle, namely throttle and
steering angle. We extensively validate our approach using the CARLA simulator
on a wide range of terrains. Our method demonstrates real-time performance and
robustness to different scenarios including unseen trajectories and high route
completion. The project page containing code and multimedia can be publicly
accessed here: https://changyaozhou.github.io/Autonomous-Vehicle-Pursuit/.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08381" title="Abstract">arXiv:2308.08381</a> [<a href="/pdf/2308.08381" title="Download PDF">pdf</a>, <a href="/format/2308.08381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precision and Recall Reject Curves for Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+L">Lydia Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Wollstadt%2C+P">Patricia Wollstadt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">For some classification scenarios, it is desirable to use only those
classification instances that a trained model associates with a high certainty.
To obtain such high-certainty instances, previous work has proposed
accuracy-reject curves. Reject curves allow to evaluate and compare the
performance of different certainty measures over a range of thresholds for
accepting or rejecting classifications. However, the accuracy may not be the
most suited evaluation metric for all applications, and instead precision or
recall may be preferable. This is the case, for example, for data with
imbalanced class distributions. We therefore propose reject curves that
evaluate precision and recall, the recall-reject curve and the precision-reject
curve. Using prototype-based classifiers from learning vector quantization, we
first validate the proposed curves on artificial benchmark data against the
accuracy reject curve as a baseline. We then show on imbalanced benchmarks and
medical, real-world data that for these scenarios, the proposed precision- and
recall-curves yield more accurate insights into classifier performance than
accuracy reject curves.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08391" title="Abstract">arXiv:2308.08391</a> [<a href="/pdf/2308.08391" title="Download PDF">pdf</a>, <a href="/format/2308.08391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Uncertainty Quantification of Spent Nuclear Fuel with Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alb%C3%A0%2C+A">Arnau Alb&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Adelmann%2C+A">Andreas Adelmann</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCnster%2C+L">Lucas M&#xfc;nster</a>, 
<a href="/search/cs?searchtype=author&query=Rochman%2C+D">Dimitri Rochman</a>, 
<a href="/search/cs?searchtype=author&query=Boiger%2C+R">Romana Boiger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The accurate calculation and uncertainty quantification of the
characteristics of spent nuclear fuel (SNF) play a crucial role in ensuring the
safety, efficiency, and sustainability of nuclear energy production, waste
management, and nuclear safeguards. State of the art physics-based models,
while reliable, are computationally intensive and time-consuming. This paper
presents a surrogate modeling approach using neural networks (NN) to predict a
number of SNF characteristics with reduced computational costs compared to
physics-based models. An NN is trained using data generated from CASMO5 lattice
calculations. The trained NN accurately predicts decay heat and nuclide
concentrations of SNF, as a function of key input parameters, such as
enrichment, burnup, cooling time between cycles, mean boron concentration and
fuel temperature. The model is validated against physics-based decay heat
simulations and measurements of different uranium oxide fuel assemblies from
two different pressurized water reactors. In addition, the NN is used to
perform sensitivity analysis and uncertainty quantification. The results are in
very good alignment to CASMO5, while the computational costs (taking into
account the costs of generating training samples) are reduced by a factor of 10
or more. Our findings demonstrate the feasibility of using NNs as surrogate
models for fast characterization of SNF, providing a promising avenue for
improving computational efficiency in assessing nuclear fuel behavior and
associated risks.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08393" title="Abstract">arXiv:2308.08393</a> [<a href="/pdf/2308.08393" title="Download PDF">pdf</a>, <a href="/format/2308.08393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIGMA: Scale-Invariant Global Sparse Shape Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Maolin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Roetzer%2C+P">Paul Roetzer</a>, 
<a href="/search/cs?searchtype=author&query=Eisenberger%2C+M">Marvin Eisenberger</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4hner%2C+Z">Zorah L&#xe4;hner</a>, 
<a href="/search/cs?searchtype=author&query=Moeller%2C+M">Michael Moeller</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel mixed-integer programming (MIP) formulation for generating
precise sparse correspondences for highly non-rigid shapes. To this end, we
introduce a projected Laplace-Beltrami operator (PLBO) which combines intrinsic
and extrinsic geometric information to measure the deformation quality induced
by predicted correspondences. We integrate the PLBO, together with an
orientation-aware regulariser, into a novel MIP formulation that can be solved
to global optimality for many practical problems. In contrast to previous
methods, our approach is provably invariant to rigid transformations and global
scaling, initialisation-free, has optimality guarantees, and scales to high
resolution meshes with (empirically observed) linear time. We show
state-of-the-art results for sparse non-rigid matching on several challenging
3D datasets, including data with inconsistent meshing, as well as applications
in mesh-to-point-cloud matching.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08401" title="Abstract">arXiv:2308.08401</a> [<a href="/pdf/2308.08401" title="Download PDF">pdf</a>, <a href="/format/2308.08401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Simplest Walking Robot: A bipedal robot with one actuator and two  rigid bodies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kyle%2C+J">James Kyle</a>, 
<a href="/search/cs?searchtype=author&query=Yim%2C+J+K">Justin K. Yim</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+K">Kendall Hart</a>, 
<a href="/search/cs?searchtype=author&query=Bergbreiter%2C+S">Sarah Bergbreiter</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present the design and experimental results of the first 1-DOF,
hip-actuated bipedal robot. While passive dynamic walking is simple by nature,
many existing bipeds inspired by this form of walking are complex in control,
mechanical design, or both. Our design using only two rigid bodies connected by
a single motor aims to enable exploration of walking at smaller sizes where
more complex designs cannot be constructed. The walker, "Mugatu", is
self-contained and autonomous, open-loop stable over a range of input
parameters, able to stop and start from standing, and able to control its
heading left and right. We analyze the mechanical design and distill down a set
of design rules that enable these behaviors. Experimental evaluations measure
speed, energy consumption, and steering.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08404" title="Abstract">arXiv:2308.08404</a> [<a href="/pdf/2308.08404" title="Download PDF">pdf</a>, <a href="/ps/2308.08404" title="Download PostScript">ps</a>, <a href="/format/2308.08404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A topological counterpart of well-founded trees in dependent type theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maietti%2C+M+E">Maria Emilia Maietti</a>, 
<a href="/search/cs?searchtype=author&query=Sabelli%2C+P">Pietro Sabelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the post-proceedings of the 39th Conference on Mathematical Foundations of Programming Semantics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Within dependent type theory, we provide a topological counterpart of
well-founded trees (for short, W-types) by using a proof-relevant version of
the notion of inductively generated suplattices introduced in the context of
formal topology under the name of inductively generated basic covers. In more
detail, we show, firstly, that in Homotopy Type Theory, W-types and proof
relevant inductively generated basic covers are propositionally mutually
encodable. Secondly, we prove they are definitionally mutually encodable in the
Agda implementation of intensional Martin-Loef's type theory. Finally, we
reframe the equivalence in the Minimalist Foundation framework by introducing
well-founded predicates as the logical counterpart for predicates of dependent
W-types. All the results have been checked in the Agda proof-assistant.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08406" title="Abstract">arXiv:2308.08406</a> [<a href="/pdf/2308.08406" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content-based Recommendation Engine for Video Streaming Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khadka%2C+P">Puskal Khadka</a>, 
<a href="/search/cs?searchtype=author&query=Lamichhane%2C+P">Prabhav Lamichhane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommendation engine suggest content, product or services to the user by
using machine learning algorithm. This paper proposed a content-based
recommendation engine for providing video suggestion to the user based on their
previous interests and choices. We will use TF-IDF text vectorization method to
determine the relevance of words in a document. Then we will find out the
similarity between each content by calculating cosine similarity between them.
Finally, engine will recommend videos to the users based on the obtained
similarity score value. In addition, we will measure the engine's performance
by computing precision, recall, and F1 core of the proposed system.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08407" title="Abstract">arXiv:2308.08407</a> [<a href="/pdf/2308.08407" title="Download PDF">pdf</a>, <a href="/format/2308.08407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI for clinical risk prediction: a survey of concepts,  methods, and modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mesinovic%2C+M">Munib Mesinovic</a>, 
<a href="/search/cs?searchtype=author&query=Watkinson%2C+P">Peter Watkinson</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tingting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08413" title="Abstract">arXiv:2308.08413</a> [<a href="/pdf/2308.08413" title="Download PDF">pdf</a>, <a href="/format/2308.08413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiaying Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Te Chen</a>, 
<a href="/search/cs?searchtype=author&query=Eldardiry%2C+H">Hoda Eldardiry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, published in CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Existing attribute-value extraction (AVE) models require large quantities of
labeled data for training. However, new products with new attribute-value pairs
enter the market every day in real-world e-Commerce. Thus, we formulate AVE in
multi-label few-shot learning (FSL), aiming to extract unseen attribute value
pairs based on a small number of training examples. We propose a
Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks,
leveraging the generated label description and category information to learn
more discriminative prototypes. Besides, KEAF integrates with hybrid attention
to reduce noise and capture more informative semantics for each class by
calculating the label-relevant and query-related weights. To achieve
multi-label inference, KEAF further learns a dynamic threshold by integrating
the semantic information from both the support set and the query set. Extensive
experiments with ablation studies conducted on two datasets demonstrate that
KEAF outperforms other SOTA models for information extraction in FSL. The code
can be found at: https://github.com/gjiaying/KEAF
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08414" title="Abstract">arXiv:2308.08414</a> [<a href="/pdf/2308.08414" title="Download PDF">pdf</a>, <a href="/format/2308.08414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H.S.Torr</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video-language pre-trained models have shown remarkable success in guiding
video question-answering (VideoQA) tasks. However, due to the length of video
sequences, training large-scale video-based models incurs considerably higher
costs than training image-based ones. This motivates us to leverage the
knowledge from image-based pretraining, despite the obvious gaps between image
and video domains. To bridge these gaps, in this paper, we propose Tem-Adapter,
which enables the learning of temporal dynamics and complex semantics by a
visual Temporal Aligner and a textual Semantic Aligner. Unlike conventional
pretrained knowledge adaptation methods that only concentrate on the downstream
task objective, the Temporal Aligner introduces an extra language-guided
autoregressive task aimed at facilitating the learning of temporal
dependencies, with the objective of predicting future states based on
historical clues and language guidance that describes event progression.
Besides, to reduce the semantic gap and adapt the textual representation for
better event description, we introduce a Semantic Aligner that first designs a
template to fuse question and answer pairs as event descriptions and then
learns a Transformer decoder with the whole video sequence as guidance for
refinement. We evaluate Tem-Adapter and different pre-train transferring
methods on two VideoQA benchmarks, and the significant performance improvement
demonstrates the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08417" title="Abstract">arXiv:2308.08417</a> [<a href="/pdf/2308.08417" title="Download PDF">pdf</a>, <a href="/format/2308.08417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Porting Batched Iterative Solvers onto Intel GPUs with SYCL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+P">Pratik Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Anzt%2C+H">Hartwig Anzt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, submitted to the P3HPC Workshop at SC23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Batched linear solvers play a vital role in computational sciences,
especially in the fields of plasma physics and combustion simulations. With the
imminent deployment of the Aurora Supercomputer and other upcoming systems
equipped with Intel GPUs, there is a compelling demand to expand the
capabilities of these solvers for Intel GPU architectures. In this paper, we
present our efforts in porting and optimizing the batched iterative solvers on
Intel GPUs using the SYCL programming model. The SYCL-based implementation
exhibits impressive performance and scalability on the Intel GPU Max 1550s
(Ponte Vecchio GPUs). The solvers outperform our previous CUDA implementation
on NVIDIA H100 GPUs by an average of 2.4x for the PeleLM application inputs.
The batched solvers are ready for production use in real-world scientific
applications through the Ginkgo library.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08428" title="Abstract">arXiv:2308.08428</a> [<a href="/pdf/2308.08428" title="Download PDF">pdf</a>, <a href="/format/2308.08428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALIP: Adaptive Language-Image Pre-training with Synthetic Caption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xiang An</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Ziyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15pages, 10figures, ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP) has significantly boosted the
performance of various vision-language tasks by scaling up the dataset with
image-text pairs collected from the web. However, the presence of intrinsic
noise and unmatched image-text pairs in web data can potentially affect the
performance of representation learning. To address this issue, we first utilize
the OFA model to generate synthetic captions that focus on the image content.
The generated captions contain complementary information that is beneficial for
pre-training. Then, we propose an Adaptive Language-Image Pre-training (ALIP),
a bi-path model that integrates supervision from both raw text and synthetic
caption. As the core components of ALIP, the Language Consistency Gate (LCG)
and Description Consistency Gate (DCG) dynamically adjust the weights of
samples and image-text/caption pairs during the training process. Meanwhile,
the adaptive contrastive loss can effectively reduce the impact of noise data
and enhances the efficiency of pre-training data. We validate ALIP with
experiments on different scales of models and pre-training datasets.
Experiments results show that ALIP achieves state-of-the-art performance on
multiple downstream tasks including zero-shot image-text retrieval and linear
probe. To facilitate future research, the code and pre-trained models are
released at https://github.com/deepglint/ALIP.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08431" title="Abstract">arXiv:2308.08431</a> [<a href="/pdf/2308.08431" title="Download PDF">pdf</a>, <a href="/format/2308.08431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Visual and Semantic Similarity Using Hierarchies for Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+A">Aishwarya Venkataramanan</a>, 
<a href="/search/cs?searchtype=author&query=Laviale%2C+M">Martin Laviale</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">C&#xe9;dric Pradalier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICVS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most of the research in content-based image retrieval (CBIR) focus on
developing robust feature representations that can effectively retrieve
instances from a database of images that are visually similar to a query.
However, the retrieved images sometimes contain results that are not
semantically related to the query. To address this, we propose a method for
CBIR that captures both visual and semantic similarity using a visual
hierarchy. The hierarchy is constructed by merging classes with overlapping
features in the latent space of a deep neural network trained for
classification, assuming that overlapping classes share high visual and
semantic similarities. Finally, the constructed hierarchy is integrated into
the distance calculation metric for similarity search. Experiments on standard
datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom
microscopy images show that our method achieves superior performance compared
to the existing methods on image retrieval.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08433" title="Abstract">arXiv:2308.08433</a> [<a href="/pdf/2308.08433" title="Download PDF">pdf</a>, <a href="/ps/2308.08433" title="Download PostScript">ps</a>, <a href="/format/2308.08433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Relay Selection Schemes in Multi-Hop  Decode-and-Forward Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dayarathna%2C+S">Shalanika Dayarathna</a>, 
<a href="/search/cs?searchtype=author&query=Senanayake%2C+R">Rajitha Senanayake</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+J">Jamie Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper analyses the data rate achieved by various relay selection schemes
in a single-user multi-hop relay network with decode-and-forward (DF) relaying.
While the single-user relay selection problem is well studied in the
literature, research on achievable rate maximization is limited to dual-hop
networks and multi-hop networks with a single relay per hop. We fill this
important gap by focusing on achievable rate maximization in multi-hop,
multi-relay networks. First, we consider optimal relay selection and obtain two
approximations to the achievable rate. Next, we consider three existing
sub-optimal relay selection strategies namely hop-by-hop, ad-hoc and
block-by-block relay selection and obtain exact expressions for the achievable
rate under each of these strategies. We also extend the sliding window based
relay selection to the DF relay network and derive an approximation to the
achievable rate. Further, we investigate the impact of window size in sliding
window based relay selection and show that a window size of three is sufficient
to achieve most of the possible performance gains. Finally, we extend this
analysis to a noise limited multi-user network where the number of available
relay nodes is large compared to the number of users and derive approximations
to the achievable sum-rate.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08434" title="Abstract">arXiv:2308.08434</a> [<a href="/pdf/2308.08434" title="Download PDF">pdf</a>, <a href="/format/2308.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bi-Step Grounding Paradigm for Large Language Models in Recommendation  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yancheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnaan He</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">As the focus on Large Language Models (LLMs) in the field of recommendation
intensifies, the optimization of LLMs for recommendation purposes (referred to
as LLM4Rec) assumes a crucial role in augmenting their effectiveness in
providing recommendations. However, existing approaches for LLM4Rec often
assess performance using restricted sets of candidates, which may not
accurately reflect the models' overall ranking capabilities. In this paper, our
objective is to investigate the comprehensive ranking capacity of LLMs and
propose a two-step grounding framework known as BIGRec (Bi-step Grounding
Paradigm for Recommendation). It initially grounds LLMs to the recommendation
space by fine-tuning them to generate meaningful tokens for items and
subsequently identifies appropriate actual items that correspond to the
generated tokens. By conducting extensive experiments on two datasets, we
substantiate the superior performance, capacity for handling few-shot
scenarios, and versatility across multiple domains exhibited by BIGRec.
Furthermore, we observe that the marginal benefits derived from increasing the
quantity of training samples are modest for BIGRec, implying that LLMs possess
the limited capability to assimilate statistical information, such as
popularity and collaborative filtering, due to their robust semantic priors.
These findings also underline the efficacy of integrating diverse statistical
information into the LLM4Rec framework, thereby pointing towards a potential
avenue for future research. Our code and data are available at
https://github.com/SAI990323/Grounding4Rec.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08436" title="Abstract">arXiv:2308.08436</a> [<a href="/pdf/2308.08436" title="Download PDF">pdf</a>, <a href="/format/2308.08436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voxlines: Streamline Transparency through Voxelization and  View-Dependent Line Orders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osman%2C+B">Besm Osman</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+M">Mestiez Pereira</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Wetering%2C+H">Huub van de Wetering</a>, 
<a href="/search/cs?searchtype=author&query=Chamberland%2C+M">Maxime Chamberland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages. 4 figures. Accepted at Computational Diffusion MRI Workshop (CDMRI) at Medical Image Computing and Computer Assisted Intervention (MICCAI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">As tractography datasets continue to grow in size, there is a need for
improved visualization methods that can capture structural patterns occurring
in large tractography datasets. Transparency is an increasingly important
aspect of finding these patterns in large datasets but is inaccessible to
tractography due to performance limitations. In this paper, we propose a
rendering method that achieves performant rendering of transparent streamlines,
allowing for exploration of deeper brain structures interactively. The method
achieves this through a novel approximate order-independent transparency method
that utilizes voxelization and caching view-dependent line orders per voxel. We
compare our transparency method with existing tractography visualization
software in terms of performance and the ability to capture deeper structures
in the dataset.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08438" title="Abstract">arXiv:2308.08438</a> [<a href="/pdf/2308.08438" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate synthesis of Dysarthric Speech for ASR data augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soleymanpour%2C+M">Mohammad Soleymanpour</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M+T">Michael T. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Soleymanpour%2C+R">Rahim Soleymanpour</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+J">Jeffrey Berry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2201.11571">arXiv:2201.11571</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dysarthria is a motor speech disorder often characterized by reduced speech
intelligibility through slow, uncoordinated control of speech production
muscles. Automatic Speech recognition (ASR) systems can help dysarthric talkers
communicate more effectively. However, robust dysarthria-specific ASR requires
a significant amount of training speech, which is not readily available for
dysarthric talkers. This paper presents a new dysarthric speech synthesis
method for the purpose of ASR training data augmentation. Differences in
prosodic and acoustic characteristics of dysarthric spontaneous speech at
varying severity levels are important components for dysarthric speech
modeling, synthesis, and augmentation. For dysarthric speech synthesis, a
modified neural multi-talker TTS is implemented by adding a dysarthria severity
level coefficient and a pause insertion model to synthesize dysarthric speech
for varying severity levels. To evaluate the effectiveness for synthesis of
training data for ASR, dysarthria-specific speech recognition was used. Results
show that a DNN-HMM model trained on additional synthetic dysarthric speech
achieves WER improvement of 12.2% compared to the baseline, and that the
addition of the severity level and pause insertion controls decrease WER by
6.5%, showing the effectiveness of adding these parameters. Overall results on
the TORGO database demonstrate that using dysarthric synthetic speech to
increase the amount of dysarthric-patterned speech for training has significant
impact on the dysarthric ASR systems. In addition, we have conducted a
subjective evaluation to evaluate the dysarthric-ness and similarity of
synthesized speech. Our subjective evaluation shows that the perceived
dysartrhic-ness of synthesized speech is similar to that of true dysarthric
speech, especially for higher levels of dysarthria
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08441" title="Abstract">arXiv:2308.08441</a> [<a href="/pdf/2308.08441" title="Download PDF">pdf</a>, <a href="/format/2308.08441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Ray-Tracing Aided Positioning at mmWave frequencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Viet-Hoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Corlay%2C+V">Vincent Corlay</a>, 
<a href="/search/cs?searchtype=author&query=Gresset%2C+N">Nicolas Gresset</a>, 
<a href="/search/cs?searchtype=author&query=Ciochina%2C+C">Cristina Ciochina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the conference Indoor Positioning and Indoor Navigation (IPIN) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the following positioning problem where several base stations
(BS) try to locate a user equipment (UE): The UE sends a positioning signal to
several BS. Each BS performs Angle of Arrival (AoA) measurements on the
received signal. These AoA measurements as well as a 3D model of the
environment are then used to locate the UE. We propose a method to exploit not
only the geometrical characteristics of the environment by a ray-tracing
simulation, but also the statistical characteristics of the measurements to
enhance the positioning accuracy.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08442" title="Abstract">arXiv:2308.08442</a> [<a href="/pdf/2308.08442" title="Download PDF">pdf</a>, <a href="/format/2308.08442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P)  Transduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+E">Eunseop Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H+S">Hee Suk Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Gowda%2C+D">Dhananjaya Gowda</a>, 
<a href="/search/cs?searchtype=author&query=Eom%2C+S">SooHwan Eom</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daehyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Harvill%2C+J">John Harvill</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Heting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hasegawa-Johnson%2C+M">Mark Hasegawa-Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Text-to-Text Transfer Transformer (T5) has recently been considered for the
Grapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free
byte-level model based on T5 referred to as ByT5, recently gave promising
results on word-level G2P conversion by representing each input character with
its corresponding UTF-8 encoding. Although it is generally understood that
sentence-level or paragraph-level G2P can improve usability in real-world
applications as it is better suited to perform on heteronyms and linking sounds
between words, we find that using ByT5 for these scenarios is nontrivial. Since
ByT5 operates on the character level, it requires longer decoding steps, which
deteriorates the performance due to the exposure bias commonly observed in
auto-regressive generation models. This paper shows that the performance of
sentence-level and paragraph-level G2P can be improved by mitigating such
exposure bias using our proposed loss-based sampling method.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08443" title="Abstract">arXiv:2308.08443</a> [<a href="/pdf/2308.08443" title="Download PDF">pdf</a>, <a href="/format/2308.08443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement:  Establishing a Novel Baseline and Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Ben Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xuechao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Junliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+P">Pin Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The extraction of lakes from remote sensing images is a complex challenge due
to the varied lake shapes and data noise. Current methods rely on multispectral
image datasets, making it challenging to learn lake features accurately from
pixel arrangements. This, in turn, affects model learning and the creation of
accurate segmentation masks. This paper introduces a unified prompt-based
dataset construction approach that provides approximate lake locations using
point, box, and mask prompts. We also propose a two-stage prompt enhancement
framework, LEPrompter, which involves prompt-based and prompt-free stages
during training. The prompt-based stage employs a prompt encoder to extract
prior information, integrating prompt tokens and image embeddings through self-
and cross-attention in the prompt decoder. Prompts are deactivated once the
model is trained to ensure independence during inference, enabling automated
lake extraction. Evaluations on Surface Water and Qinghai-Tibet Plateau Lake
datasets show consistent performance improvements compared to the previous
state-of-the-art method. LEPrompter achieves mIoU scores of 91.48% and 97.43%
on the respective datasets without introducing additional parameters or GFLOPs.
Supplementary materials provide the source code, pre-trained models, and
detailed user studies.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08446" title="Abstract">arXiv:2308.08446</a> [<a href="/pdf/2308.08446" title="Download PDF">pdf</a>, <a href="/format/2308.08446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction  in On-Demand Food Delivery Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+R">Rongrong Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xingliang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guodong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+N">Ning Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Click-through rate (CTR) prediction is a crucial task in the context of an
online on-demand food delivery (OFD) platform for precisely estimating the
probability of a user clicking on food items. Unlike universal e-commerce
platforms such as Taobao and Amazon, user behaviors and interests on the OFD
platform are more location and time-sensitive due to limited delivery ranges
and regional commodity supplies. However, existing CTR prediction algorithms in
OFD scenarios concentrate on capturing interest from historical behavior
sequences, which fails to effectively model the complex spatiotemporal
information within features, leading to poor performance. To address this
challenge, this paper introduces the Contrastive Sres under different search
states using three modules: contrastive spatiotemporal representation learning
(CSRL), spatiotemporal preference extractor (StPE), and spatiotemporal
information filter (StIF). CSRL utilizes a contrastive learning framework to
generate a spatiotemporal activation representation (SAR) for the search
action. StPE employs SAR to activate users' diverse preferences related to
location and time from the historical behavior sequence field, using a
multi-head attention mechanism. StIF incorporates SAR into a gating network to
automatically capture important features with latent spatiotemporal effects.
Extensive experiments conducted on two large-scale industrial datasets
demonstrate the state-of-the-art performance of CSPM. Notably, CSPM has been
successfully deployed in Alibaba's online OFD platform Ele.me, resulting in a
significant 0.88% lift in CTR, which has substantial business implications.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08449" title="Abstract">arXiv:2308.08449</a> [<a href="/pdf/2308.08449" title="Download PDF">pdf</a>, <a href="/ps/2308.08449" title="Download PostScript">ps</a>, <a href="/format/2308.08449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving CTC-AED model with integrated-CTC and auxiliary loss  regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Daobin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiangdong Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Connectionist temporal classification (CTC) and attention-based encoder
decoder (AED) joint training has been widely applied in automatic speech
recognition (ASR). Unlike most hybrid models that separately calculate the CTC
and AED losses, our proposed integrated-CTC utilizes the attention mechanism of
AED to guide the output of CTC. In this paper, we employ two fusion methods,
namely direct addition of logits (DAL) and preserving the maximum probability
(PMP). We achieve dimensional consistency by adaptively affine transforming the
attention results to match the dimensions of CTC. To accelerate model
convergence and improve accuracy, we introduce auxiliary loss regularization
for accelerated convergence. Experimental results demonstrate that the DAL
method performs better in attention rescoring, while the PMP method excels in
CTC prefix beam search and greedy search.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08451" title="Abstract">arXiv:2308.08451</a> [<a href="/pdf/2308.08451" title="Download PDF">pdf</a>, <a href="/format/2308.08451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIGC In China: Current Developments And Future Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuqing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenghui Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The increasing attention given to AI Generated Content (AIGC) has brought a
profound impact on various aspects of daily life, industrial manufacturing, and
the academic sector. Recognizing the global trends and competitiveness in AIGC
development, this study aims to analyze China's current status in the field.
The investigation begins with an overview of the foundational technologies and
current applications of AIGC. Subsequently, the study delves into the market
status, policy landscape, and development trajectory of AIGC in China,
utilizing keyword searches to identify relevant scholarly papers. Furthermore,
the paper provides a comprehensive examination of AIGC products and their
corresponding ecosystem, emphasizing the ecological construction of AIGC.
Finally, this paper discusses the challenges and risks faced by the AIGC
industry while presenting a forward-looking perspective on the industry's
future based on competitive insights in AIGC.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08453" title="Abstract">arXiv:2308.08453</a> [<a href="/pdf/2308.08453" title="Download PDF">pdf</a>, <a href="/format/2308.08453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tightest Admissible Shortest Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weiss%2C+E">Eyal Weiss</a>, 
<a href="/search/cs?searchtype=author&query=Felner%2C+A">Ariel Felner</a>, 
<a href="/search/cs?searchtype=author&query=Kaminka%2C+G+A">Gal A. Kaminka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.11489">arXiv:2208.11489</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The shortest path problem in graphs is fundamental to AI. Nearly all variants
of the problem and relevant algorithms that solve them ignore edge-weight
computation time and its common relation to weight uncertainty. This implies
that taking these factors into consideration can potentially lead to a
performance boost in relevant applications. Recently, a generalized framework
for weighted directed graphs was suggested, where edge-weight can be computed
(estimated) multiple times, at increasing accuracy and run-time expense. We
build on this framework to introduce the problem of finding the tightest
admissible shortest path (TASP); a path with the tightest suboptimality bound
on the optimal cost. This is a generalization of the shortest path problem to
bounded uncertainty, where edge-weight uncertainty can be traded for
computational cost. We present a complete algorithm for solving TASP, with
guarantees on solution quality. Empirical evaluation supports the effectiveness
of this approach.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08459" title="Abstract">arXiv:2308.08459</a> [<a href="/pdf/2308.08459" title="Download PDF">pdf</a>, <a href="/format/2308.08459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Prompt-tuning for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Jianyang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chang-Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained language models (PLMs) have demonstrated strong performance in
sequential recommendation (SR), which are utilized to extract general
knowledge. However, existing methods still lack domain knowledge and struggle
to capture users' fine-grained preferences. Meanwhile, many traditional SR
methods improve this issue by integrating side information while suffering from
information loss. To summarize, we believe that a good recommendation system
should utilize both general and domain knowledge simultaneously. Therefore, we
introduce an external knowledge base and propose Knowledge Prompt-tuning for
Sequential Recommendation (\textbf{KP4SR}). Specifically, we construct a set of
relationship templates and transform a structured knowledge graph (KG) into
knowledge prompts to solve the problem of the semantic gap. However, knowledge
prompts disrupt the original data structure and introduce a significant amount
of noise. We further construct a knowledge tree and propose a knowledge tree
mask, which restores the data structure in a mask matrix form, thus mitigating
the noise problem. We evaluate KP4SR on three real-world datasets, and
experimental results show that our approach outperforms state-of-the-art
methods on multiple evaluation metrics. Specifically, compared with PLM-based
methods, our method improves NDCG@5 and HR@5 by \textcolor{red}{40.65\%} and
\textcolor{red}{36.42\%} on the books dataset, \textcolor{red}{11.17\%} and
\textcolor{red}{11.47\%} on the music dataset, and \textcolor{red}{22.17\%} and
\textcolor{red}{19.14\%} on the movies dataset, respectively. Our code is
publicly available at the link:
\href{https://github.com/zhaijianyang/KP4SR}{\textcolor{blue}{https://github.com/zhaijianyang/KP4SR}.}
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08460" title="Abstract">arXiv:2308.08460</a> [<a href="/pdf/2308.08460" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiayi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Neville%2C+J">Jennifer Neville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in KDD'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Email platforms need to generate personalized rankings of emails that satisfy
user preferences, which may vary over time. We approach this as a
recommendation problem based on three criteria: closeness (how relevant the
sender and topic are to the user), timeliness (how recent the email is), and
conciseness (how brief the email is). We propose MOSR (Multi-Objective
Stationary Recommender), a novel online algorithm that uses an adaptive control
model to dynamically balance these criteria and adapt to preference changes. We
evaluate MOSR on the Enron Email Dataset, a large collection of real emails,
and compare it with other baselines. The results show that MOSR achieves better
performance, especially under non-stationary preferences, where users value
different criteria more or less over time. We also test MOSR's robustness on a
smaller down-sampled dataset that exhibits high variance in email
characteristics, and show that it maintains stable rankings across different
samples. Our work offers novel insights into how to design email re-ranking
systems that account for multiple objectives impacting user satisfaction.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08461" title="Abstract">arXiv:2308.08461</a> [<a href="/pdf/2308.08461" title="Download PDF">pdf</a>, <a href="/format/2308.08461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDR: Conservative Doubly Robust Learning for Debiased Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">ZiJie Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">JiaWei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">QiHao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recommendation systems (RS), user behavior data is observational rather
than experimental, resulting in widespread bias in the data. Consequently,
tackling bias has emerged as a major challenge in the field of recommendation
systems. Recently, Doubly Robust Learning (DR) has gained significant attention
due to its remarkable performance and robust properties. However, our
experimental findings indicate that existing DR methods are severely impacted
by the presence of so-called Poisonous Imputation, where the imputation
significantly deviates from the truth and becomes counterproductive.
<br />To address this issue, this work proposes Conservative Doubly Robust strategy
(CDR) which filters imputations by scrutinizing their mean and variance.
Theoretical analyses show that CDR offers reduced variance and improved tail
bounds.In addition, our experimental investigations illustrate that CDR
significantly enhances performance and can indeed reduce the frequency of
poisonous imputation.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08468" title="Abstract">arXiv:2308.08468</a> [<a href="/pdf/2308.08468" title="Download PDF">pdf</a>, <a href="/format/2308.08468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Expert&#x27;s Guide to Training Physics-informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sankaran%2C+S">Shyam Sankaran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Perdikaris%2C+P">Paris Perdikaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 25 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) have been popularized as a deep
learning framework that can seamlessly synthesize observational data and
partial differential equation (PDE) constraints. Their practical effectiveness
however can be hampered by training pathologies, but also oftentimes by poor
choices made by users who lack deep learning expertise. In this paper we
present a series of best practices that can significantly improve the training
efficiency and overall accuracy of PINNs. We also put forth a series of
challenging benchmark problems that highlight some of the most prominent
difficulties in training PINNs, and present comprehensive and fully
reproducible ablation studies that demonstrate how different architecture
choices and training strategies affect the test accuracy of the resulting
models. We show that the methods and guiding principles put forth in this study
lead to state-of-the-art results and provide strong baselines that future
studies should use for comparison purposes. To this end, we also release a
highly optimized library in JAX that can be used to reproduce all results
reported in this paper, enable future research studies, as well as facilitate
easy adaptation to new use-case scenarios.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08469" title="Abstract">arXiv:2308.08469</a> [<a href="/pdf/2308.08469" title="Download PDF">pdf</a>, <a href="/format/2308.08469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with  Pre-Trained LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tien-Fu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this work, we leverage pre-trained Large Language Models (LLMs) to enhance
time-series forecasting. Mirroring the growing interest in unifying models for
Natural Language Processing and Computer Vision, we envision creating an
analogous model for long-term time-series forecasting. Due to limited
large-scale time-series data for building robust foundation models, our
approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By
combining time-series patching with temporal encoding, we have enhanced the
capability of LLMs to handle time-series data effectively. Inspired by the
supervised fine-tuning in chatbot domains, we prioritize a two-stage
fine-tuning process: first conducting supervised fine-tuning to orient the LLM
towards time-series data, followed by task-specific downstream fine-tuning.
Furthermore, to unlock the flexibility of pre-trained LLMs without extensive
parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)
techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art
results in long-term forecasting. Our model has also shown exceptional
capabilities as both a robust representation learner and an effective few-shot
learner, thanks to the knowledge transferred from the pre-trained LLM.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08471" title="Abstract">arXiv:2308.08471</a> [<a href="/pdf/2308.08471" title="Download PDF">pdf</a>, <a href="/format/2308.08471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certifying Stability and Performance of Uncertain Differential-Algebraic  Systems: A Dissipativity Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jensen%2C+E">Emily Jensen</a>, 
<a href="/search/eess?searchtype=author&query=Junnarkar%2C+N">Neelay Junnarkar</a>, 
<a href="/search/eess?searchtype=author&query=Arcak%2C+M">Murat Arcak</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaofan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Gumussoy%2C+S">Suat Gumussoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel framework for characterizing dissipativity of
uncertain dynamical systems subject to algebraic constraints. The main results
provide sufficient conditions for dissipativity when uncertainties are
characterized by integral quadratic constraints. For polynomial or linear
dynamics, these conditions can be efficiently verified through sum-of-squares
or semidefinite programming. The practical impact of this work is illustrated
through a case study that examines performance of the IEEE 39-bus power network
with uncertainties used to model a set of potential line failures.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08472" title="Abstract">arXiv:2308.08472</a> [<a href="/pdf/2308.08472" title="Download PDF">pdf</a>, <a href="/format/2308.08472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ambient Intelligence-based Approach For Longitudinal Monitoring of  Verbal and Vocal Depression Symptoms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Othmani%2C+A">Alice Othmani</a>, 
<a href="/search/cs?searchtype=author&query=Muzammel%2C+M">Muhammad Muzammel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Automatic speech recognition (ASR) technology can aid in the detection,
monitoring, and assessment of depressive symptoms in individuals. ASR systems
have been used as a tool to analyze speech patterns and characteristics that
are indicative of depression. Depression affects not only a person's mood but
also their speech patterns. Individuals with depression may exhibit changes in
speech, such as slower speech rate, longer pauses, reduced pitch variability,
and decreased overall speech fluency. Despite the growing use of machine
learning in diagnosing depression, there is a lack of studies addressing the
issue of relapse. Furthermore, previous research on relapse prediction has
primarily focused on clinical variables and has not taken into account other
factors such as verbal and non-verbal cues. Another major challenge in
depression relapse research is the scarcity of publicly available datasets. To
overcome these issues, we propose a one-shot learning framework for detecting
depression relapse from speech. We define depression relapse as the similarity
between the speech audio and textual encoding of a subject and that of a
depressed individual. To detect depression relapse based on this definition, we
employ a Siamese neural network that models the similarity between of two
instances. Our proposed approach shows promising results and represents a new
advancement in the field of automatic depression relapse detection and mental
disorders monitoring.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08473" title="Abstract">arXiv:2308.08473</a> [<a href="/pdf/2308.08473" title="Download PDF">pdf</a>, <a href="/format/2308.08473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataRaceBench V1.4.1 and DataRaceBench-ML V0.1: Benchmark Suites for  Data Race Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+S+F">Stephen F. Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pei-Hung Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chunhua Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Data races pose a significant threat in multi-threaded parallel applications
due to their negative impact on program correctness. DataRaceBench, an
open-source benchmark suite, is specifically crafted to assess these data race
detection tools in a systematic and measurable manner. Machine learning
techniques have recently demonstrated considerable potential in
high-performance computing (HPC) program analysis and optimization. However,
these techniques require specialized data formats for training and refinement.
This paper presents the latest update to DataRaceBench, incorporating new data
race contributions from Wu et al. \cite{wu2023model}, and introduces a derived
dataset named DataRaceBench-ML (DRB-ML) \cite{drbml}. DRB-ML aligns with the
emerging trend of machine learning and large language models. Originating from
DataRaceBench, this dataset includes detailed labels that denote the presence
of a data race and provides comprehensive details of associated variables, such
as variable names, line numbers, and the operation (read/write). Unique to
DRB-ML, we have also integrated a series of tailored prompt-response pairs
specifically designed for LLM fine-tuning.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08475" title="Abstract">arXiv:2308.08475</a> [<a href="/pdf/2308.08475" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Navigator: An accessibility-centered data navigation toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elavsky%2C+F">Frank Elavsky</a>, 
<a href="/search/cs?searchtype=author&query=Nadolskis%2C+L">Lucas Nadolskis</a>, 
<a href="/search/cs?searchtype=author&query=Moritz%2C+D">Dominik Moritz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Making data visualizations accessible for people with disabilities remains a
significant challenge in current practitioner efforts. Existing visualizations
often lack an underlying navigable structure, fail to engage necessary input
modalities, and rely heavily on visual-only rendering practices. These
limitations exclude people with disabilities, especially users of assistive
technologies. To address these challenges, we present Data Navigator: a system
built on a dynamic graph structure, enabling developers to construct navigable
lists, trees, graphs, and flows as well as spatial, diagrammatic, and
geographic relations. Data Navigator supports a wide range of input modalities:
screen reader, keyboard, speech, gesture detection, and even fabricated
assistive devices. We present 3 case examples with Data Navigator,
demonstrating we can provide accessible navigation structures on top of raster
images, integrate with existing toolkits at scale, and rapidly develop novel
prototypes. Data Navigator is a step towards making accessible data
visualizations easier to design and implement.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08476" title="Abstract">arXiv:2308.08476</a> [<a href="/pdf/2308.08476" title="Download PDF">pdf</a>, <a href="/format/2308.08476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification Committee for Active Deep Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In object detection, the cost of labeling is much high because it needs not
only to confirm the categories of multiple objects in an image but also to
accurately determine the bounding boxes of each object. Thus, integrating
active learning into object detection will raise pretty positive significance.
In this paper, we propose a classification committee for active deep object
detection method by introducing a discrepancy mechanism of multiple classifiers
for samples' selection when training object detectors. The model contains a
main detector and a classification committee. The main detector denotes the
target object detector trained from a labeled pool composed of the selected
informative images. The role of the classification committee is to select the
most informative images according to their uncertainty values from the view of
classification, which is expected to focus more on the discrepancy and
representative of instances. Specifically, they compute the uncertainty for a
specified instance within the image by measuring its discrepancy output by the
committee pre-trained via the proposed Maximum Classifiers Discrepancy Group
Loss (MCDGL). The most informative images are finally determined by selecting
the ones with many high-uncertainty instances. Besides, to mitigate the impact
of interference instances, we design a Focus on Positive Instances Loss (FPIL)
to make the committee the ability to automatically focus on the representative
instances as well as precisely encode their discrepancies for the same
instance. Experiments are conducted on Pascal VOC and COCO datasets versus some
popular object detectors. And results show that our method outperforms the
state-of-the-art active learning methods, which verifies the effectiveness of
the proposed method.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08479" title="Abstract">arXiv:2308.08479</a> [<a href="/pdf/2308.08479" title="Download PDF">pdf</a>, <a href="/format/2308.08479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeDoDe: Detect, Don&#x27;t Describe -- Describe, Don&#x27;t Detect for Local  Feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Keypoint detection is a pivotal step in 3D reconstruction, whereby sets of
(up to) K points are detected in each view of a scene. Crucially, the detected
points need to be consistent between views, i.e., correspond to the same 3D
point in the scene. One of the main challenges with keypoint detection is the
formulation of the learning objective. Previous learning-based methods
typically jointly learn descriptors with keypoints, and treat the keypoint
detection as a binary classification task on mutual nearest neighbours.
However, basing keypoint detection on descriptor nearest neighbours is a proxy
task, which is not guaranteed to produce 3D-consistent keypoints. Furthermore,
this ties the keypoints to a specific descriptor, complicating downstream
usage. In this work, we instead learn keypoints directly from 3D consistency.
To this end, we train the detector to detect tracks from large-scale SfM. As
these points are often overly sparse, we derive a semi-supervised two-view
detection objective to expand this set to a desired number of detections. To
train a descriptor, we maximize the mutual nearest neighbour objective over the
keypoints with a separate network. Results show that our approach, DeDoDe,
achieves significant gains on multiple geometry benchmarks. Code is provided at
https://github.com/Parskatt/DeDoDe .
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08480" title="Abstract">arXiv:2308.08480</a> [<a href="/pdf/2308.08480" title="Download PDF">pdf</a>, <a href="/format/2308.08480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Propagation Techniques for Artifact Detection in Imbalanced  Classes using Photoplethysmogram Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macabiau%2C+C">Clara Macabiau</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thanh-Dung Le</a>, 
<a href="/search/cs?searchtype=author&query=Albert%2C+K">Kevin Albert</a>, 
<a href="/search/cs?searchtype=author&query=Jouvet%2C+P">Philippe Jouvet</a>, 
<a href="/search/cs?searchtype=author&query=Noumeir%2C+R">Rita Noumeir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under preparation to submit to IEEE for possible publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring
vital signs, but they are susceptible to motion artifacts that can lead to
inaccurate interpretations. In this study, the use of label propagation
techniques to propagate labels among PPG samples is explored, particularly in
imbalanced class scenarios where clean PPG samples are significantly
outnumbered by artifact-contaminated samples. With a precision of 91%, a recall
of 90% and an F1 score of 90% for the class without artifacts, the results
demonstrate its effectiveness in labeling a medical dataset, even when clean
samples are rare. For the classification of artifacts our study compares
supervised classifiers such as conventional classifiers and neural networks
(MLP, Transformers, FCN) with the semi-supervised label propagation algorithm.
With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN
supervised model gives good results, but the semi-supervised algorithm performs
better in detecting artifacts. The findings suggest that the semi-supervised
algorithm label propagation hold promise for artifact detection in PPG signals,
which can enhance the reliability of PPG-based health monitoring systems in
real-world applications.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08482" title="Abstract">arXiv:2308.08482</a> [<a href="/pdf/2308.08482" title="Download PDF">pdf</a>, <a href="/format/2308.08482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention  with Shortcut Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongmei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2211.01253">arXiv:2211.01253</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Machine learning models often learn to make predictions that rely on
sensitive social attributes like gender and race, which poses significant
fairness risks, especially in societal applications, such as hiring, banking,
and criminal justice. Existing work tackles this issue by minimizing the
employed information about social attributes in models for debiasing. However,
the high correlation between target task and these social attributes makes
learning on the target task incompatible with debiasing. Given that model bias
arises due to the learning of bias features (\emph{i.e}., gender) that help
target task optimization, we explore the following research question: \emph{Can
we leverage shortcut features to replace the role of bias feature in target
task optimization for debiasing?} To this end, we propose \emph{Shortcut
Debiasing}, to first transfer the target task's learning of bias attributes
from bias features to shortcut features, and then employ causal intervention to
eliminate shortcut features during inference. The key idea of \emph{Shortcut
Debiasing} is to design controllable shortcut features to on one hand replace
bias features in contributing to the target task during the training stage, and
on the other hand be easily removed by intervention during the inference stage.
This guarantees the learning of the target task does not hinder the elimination
of bias features. We apply \emph{Shortcut Debiasing} to several benchmark
datasets, and achieve significant improvements over the state-of-the-art
debiasing methods in both accuracy and fairness.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08483" title="Abstract">arXiv:2308.08483</a> [<a href="/pdf/2308.08483" title="Download PDF">pdf</a>, <a href="/format/2308.08483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TBIN: Modeling Long Textual Behavior Data for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingxing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Click-through rate (CTR) prediction plays a pivotal role in the success of
recommendations. Inspired by the recent thriving of language models (LMs), a
surge of works improve prediction by organizing user behavior data in a
\textbf{textual} format and using LMs to understand user interest at a semantic
level. While promising, these works have to truncate the textual data to reduce
the quadratic computational overhead of self-attention in LMs. However, it has
been studied that long user behavior data can significantly benefit CTR
prediction. In addition, these works typically condense user diverse interests
into a single feature vector, which hinders the expressive capability of the
model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based
\textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above
limitations by combining an efficient locality-sensitive hashing algorithm and
a shifted chunk-based self-attention. The resulting user diverse interests are
dynamically activated, producing user interest representation towards the
target item. Finally, the results of both offline and online experiments on
real-world food recommendation platform demonstrate the effectiveness of TBIN.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08484" title="Abstract">arXiv:2308.08484</a> [<a href="/pdf/2308.08484" title="Download PDF">pdf</a>, <a href="/format/2308.08484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Horizontal Instability in Merge Trees: On the Computation of a  Comprehensive Deformation-based Edit Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wetzels%2C+F">Florian Wetzels</a>, 
<a href="/search/cs?searchtype=author&query=Anders%2C+M">Markus Anders</a>, 
<a href="/search/cs?searchtype=author&query=Garth%2C+C">Christoph Garth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Comparative analysis of scalar fields in scientific visualization often
involves distance functions on topological abstractions. This paper focuses on
the merge tree abstraction (representing the nesting of sub- or superlevel
sets) and proposes the application of the unconstrained deformation-based edit
distance. Previous approaches on merge trees often suffer from instability:
small perturbations in the data can lead to large distances of the
abstractions. While some existing methods can handle so-called vertical
instability, the unconstrained deformation-based edit distance addresses both
vertical and horizontal instabilities, also called saddle swaps. We establish
the computational complexity as NP-complete, and provide an integer linear
program formulation for computation. Experimental results on the TOSCA shape
matching ensemble provide evidence for the stability of the proposed distance.
We thereby showcase the potential of handling saddle swaps for comparison of
scalar fields through merge trees.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08487" title="Abstract">arXiv:2308.08487</a> [<a href="/pdf/2308.08487" title="Download PDF">pdf</a>, <a href="/format/2308.08487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Interest Network for Click-Through Rate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haolin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xihua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guihai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The history of user behaviors constitutes one of the most significant
characteristics in predicting the click-through rate (CTR), owing to their
strong semantic and temporal correlation with the target item. While the
literature has individually examined each of these correlations, research has
yet to analyze them in combination, that is, the quadruple correlation of
(behavior semantics, target semantics, behavior temporal, and target temporal).
The effect of this correlation on performance and the extent to which existing
methods learn it remain unknown. To address this gap, we empirically measure
the quadruple correlation and observe intuitive yet robust quadruple patterns.
We measure the learned correlation of several representative user behavior
methods, but to our surprise, none of them learn such a pattern, especially the
temporal one.
<br />In this paper, we propose the Temporal Interest Network (TIN) to capture the
quadruple semantic and temporal correlation between behaviors and the target.
We achieve this by incorporating target-aware temporal encoding, in addition to
semantic embedding, to represent behaviors and the target. Furthermore, we
deploy target-aware attention, along with target-aware representation, to
explicitly conduct the 4-way interaction. We performed comprehensive
evaluations on the Amazon and Alibaba datasets. Our proposed TIN outperforms
the best-performing baselines by 0.43\% and 0.29\% on two datasets,
respectively. Comprehensive analysis and visualization show that TIN is indeed
capable of learning the quadruple correlation effectively, while all existing
methods fail to do so. We provide our implementation of TIN in Tensorflow.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08488" title="Abstract">arXiv:2308.08488</a> [<a href="/pdf/2308.08488" title="Download PDF">pdf</a>, <a href="/format/2308.08488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Audio-Visual Speech Recognition by Lip-Subword Correlation  Based Visual Pre-training and Cross-Modal Fusion Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yusheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaofei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feijun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chin-Hui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, published in ICME2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent research, slight performance improvement is observed from automatic
speech recognition systems to audio-visual speech recognition systems in the
end-to-end framework with low-quality videos. Unmatching convergence rates and
specialized input representations between audio and visual modalities are
considered to cause the problem. In this paper, we propose two novel techniques
to improve audio-visual speech recognition (AVSR) under a pre-training and
fine-tuning training framework. First, we explore the correlation between lip
shapes and syllable-level subword units in Mandarin to establish good
frame-level syllable boundaries from lip shapes. This enables accurate
alignment of video and audio streams during visual model pre-training and
cross-modal fusion. Next, we propose an audio-guided cross-modal fusion encoder
(CMFE) neural network to utilize main training parameters for multiple
cross-modal attention layers to make full use of modality complementarity.
Experiments on the MISP2021-AVSR data set show the effectiveness of the two
proposed techniques. Together, using only a relatively small amount of training
data, the final system achieves better performances than state-of-the-art
systems with more complex front-ends and back-ends.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08493" title="Abstract">arXiv:2308.08493</a> [<a href="/pdf/2308.08493" title="Download PDF">pdf</a>, <a href="/ps/2308.08493" title="Download PostScript">ps</a>, <a href="/format/2308.08493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Travel in LLMs: Tracing Data Contamination in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golchin%2C+S">Shahriar Golchin</a>, 
<a href="/search/cs?searchtype=author&query=Surdeanu%2C+M">Mihai Surdeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1 preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Data contamination, i.e., the presence of test data from downstream tasks in
the training data of large language models (LLMs), is a potential major issue
in understanding LLMs' effectiveness on other tasks. We propose a
straightforward yet effective method for identifying data contamination within
LLMs. At its core, our approach starts by identifying potential contamination
in individual instances that are drawn from a small random sample; using this
information, our approach then assesses if an entire dataset partition is
contaminated. To estimate contamination of individual instances, we employ
"guided instruction:" a prompt consisting of the dataset name, partition type,
and the initial segment of a reference instance, asking the LLM to complete it.
An instance is flagged as contaminated if the LLM's output either exactly or
closely matches the latter segment of the reference. To understand if an entire
partition is contaminated, we propose two ideas. The first idea marks a dataset
partition as contaminated if the average overlap score with the reference
instances (as measured by ROUGE or BLEURT) is statistically significantly
better with the guided instruction vs. a general instruction that does not
include the dataset and partition name. The second idea marks a dataset as
contaminated if a classifier based on GPT-4 with in-context learning prompting
marks multiple instances as contaminated. Our best method achieves an accuracy
between 92% and 100% in detecting if an LLM is contaminated with seven
datasets, containing train and test/validation partitions, when contrasted with
manual evaluation by human expert. Further, our findings indicate that GPT-4 is
contaminated with AG News, WNLI, and XSum datasets.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08494" title="Abstract">arXiv:2308.08494</a> [<a href="/pdf/2308.08494" title="Download PDF">pdf</a>, <a href="/format/2308.08494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptualizing Machine Learning for Dynamic Information Retrieval of  Electronic Health Record Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sharon Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shannon Shen</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+M">Monica Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+B">Barbara Lam</a>, 
<a href="/search/cs?searchtype=author&query=Kurtzman%2C+N">Nicholas Kurtzman</a>, 
<a href="/search/cs?searchtype=author&query=Horng%2C+S">Steven Horng</a>, 
<a href="/search/cs?searchtype=author&query=Karger%2C+D">David Karger</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+D">David Sontag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of Machine Learning Research Volume 219; accepted to the Machine Learning for Healthcare 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The large amount of time clinicians spend sifting through patient notes and
documenting in electronic health records (EHRs) is a leading cause of clinician
burnout. By proactively and dynamically retrieving relevant notes during the
documentation process, we can reduce the effort required to find relevant
patient history. In this work, we conceptualize the use of EHR audit logs for
machine learning as a source of supervision of note relevance in a specific
clinical context, at a particular point in time. Our evaluation focuses on the
dynamic retrieval in the emergency department, a high acuity setting with
unique patterns of information retrieval and note writing. We show that our
methods can achieve an AUC of 0.963 for predicting which notes will be read in
an individual note writing session. We additionally conduct a user study with
several clinicians and find that our framework can help clinicians retrieve
relevant information more efficiently. Demonstrating that our framework and
methods can perform well in this demanding setting is a promising proof of
concept that they will translate to other clinical settings and data modalities
(e.g., labs, medications, imaging).
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08495" title="Abstract">arXiv:2308.08495</a> [<a href="/pdf/2308.08495" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Online Camera Calibration for Automated Driving and  Parking Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hogan%2C+C">Ciar&#xe1;n Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Sistu%2C+G">Ganesh Sistu</a>, 
<a href="/search/cs?searchtype=author&query=Eising%2C+C">Ciar&#xe1;n Eising</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Irish Machine Vision and Image Processing
  Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Camera-based perception systems play a central role in modern autonomous
vehicles. These camera based perception algorithms require an accurate
calibration to map the real world distances to image pixels. In practice,
calibration is a laborious procedure requiring specialised data collection and
careful tuning. This process must be repeated whenever the parameters of the
camera change, which can be a frequent occurrence in autonomous vehicles. Hence
there is a need to calibrate at regular intervals to ensure the camera is
accurate. Proposed is a deep learning framework to learn intrinsic and
extrinsic calibration of the camera in real time. The framework is
self-supervised and doesn't require any labelling or supervision to learn the
calibration parameters. The framework learns calibration without the need for
any physical targets or to drive the car on special planar surfaces.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08496" title="Abstract">arXiv:2308.08496</a> [<a href="/pdf/2308.08496" title="Download PDF">pdf</a>, <a href="/format/2308.08496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding User Intent Modeling for Conversational Recommender  Systems: A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farshidi%2C+S">Siamak Farshidi</a>, 
<a href="/search/cs?searchtype=author&query=Rezaee%2C+K">Kiyan Rezaee</a>, 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+S">Sara Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A+H">Amir Hossein Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Dadashzadeh%2C+A">Ali Dadashzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Ziabakhsh%2C+M">Morteza Ziabakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Eskandari%2C+S">Sadegh Eskandari</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+S">Slinger Jansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Context: User intent modeling is a crucial process in Natural Language
Processing that aims to identify the underlying purpose behind a user's
request, enabling personalized responses. With a vast array of approaches
introduced in the literature (over 13,000 papers in the last decade),
understanding the related concepts and commonly used models in AI-based systems
is essential. Method: We conducted a systematic literature review to gather
data on models typically employed in designing conversational recommender
systems. From the collected data, we developed a decision model to assist
researchers in selecting the most suitable models for their systems.
Additionally, we performed two case studies to evaluate the effectiveness of
our proposed decision model. Results: Our study analyzed 59 distinct models and
identified 74 commonly used features. We provided insights into potential model
combinations, trends in model selection, quality concerns, evaluation measures,
and frequently used datasets for training and evaluating these models.
Contribution: Our study contributes practical insights and a comprehensive
understanding of user intent modeling, empowering the development of more
effective and personalized conversational recommender systems. With the
Conversational Recommender System, researchers can perform a more systematic
and efficient assessment of fitting intent modeling frameworks.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08497" title="Abstract">arXiv:2308.08497</a> [<a href="/pdf/2308.08497" title="Download PDF">pdf</a>, <a href="/format/2308.08497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User  Preferences in Streaming Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chenglei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In real-world streaming recommender systems, user preferences often
dynamically change over time (e.g., a user may have different preferences
during weekdays and weekends). Existing bandit-based streaming recommendation
models only consider time as a timestamp, without explicitly modeling the
relationship between time variables and time-varying user preferences. This
leads to recommendation models that cannot quickly adapt to dynamic scenarios.
To address this issue, we propose a contextual bandit approach using
hypernetwork, called HyperBandit, which takes time features as input and
dynamically adjusts the recommendation model for time-varying user preferences.
Specifically, HyperBandit maintains a neural network capable of generating the
parameters for estimating time-varying rewards, taking into account the
correlation between time features and user preferences. Using the estimated
time-varying rewards, a bandit policy is employed to make online
recommendations by learning the latent item contexts. To meet the real-time
requirements in streaming recommendation scenarios, we have verified the
existence of a low-rank structure in the parameter matrix and utilize low-rank
factorization for efficient training. Theoretically, we demonstrate a sublinear
regret upper bound against the best policy. Extensive experiments on real-world
datasets show that the proposed HyperBandit consistently outperforms the
state-of-the-art baselines in terms of accumulated rewards.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08499" title="Abstract">arXiv:2308.08499</a> [<a href="/pdf/2308.08499" title="Download PDF">pdf</a>, <a href="/format/2308.08499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Service Recommendation System for the Social Internet of  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khelloufi%2C+A">Amar Khelloufi</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+H">Huansheng Ning</a>, 
<a href="/search/cs?searchtype=author&query=Sada%2C+A+B">Abdelkarim Ben Sada</a>, 
<a href="/search/cs?searchtype=author&query=Naouri%2C+A">Abdenacer Naouri</a>, 
<a href="/search/cs?searchtype=author&query=Dhelim%2C+S">Sahraoui Dhelim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The Social Internet of Things (SIoT) enables interconnected smart devices to
share data and services, opening up opportunities for personalized service
recommendations. However, existing research often overlooks crucial aspects
that can enhance the accuracy and relevance of recommendations in the SIoT
context. Specifically, existing techniques tend to consider the extraction of
social relationships between devices and neglect the contextual presentation of
service reviews. This study aims to address these gaps by exploring the
contextual representation of each device-service pair. Firstly, we propose a
latent features combination technique that can capture latent feature
interactions, by aggregating the device-device relationships within the SIoT.
Then, we leverage Factorization Machines to model higher-order feature
interactions specific to each SIoT device-service pair to accomplish accurate
rating prediction. Finally, we propose a service recommendation framework for
SIoT based on review aggregation and feature learning processes. The
experimental evaluation demonstrates the framework's effectiveness in improving
service recommendation accuracy and relevance.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08500" title="Abstract">arXiv:2308.08500</a> [<a href="/pdf/2308.08500" title="Download PDF">pdf</a>, <a href="/format/2308.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep  Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagrecha%2C+K">Kabir Nagrecha</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+P">Pablo Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+P">Prasanna Padmanabhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at RecSys 2023. 11 pages, 2 pages of references. 8 figures with 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Deep learning-based recommender models (DLRMs) have become an essential
component of many modern recommender systems. Several companies are now
building large compute clusters reserved only for DLRM training, driving new
interest in cost- and time- saving optimizations. The systems challenges faced
in this setting are unique; while typical deep learning training jobs are
dominated by model execution, the most important factor in DLRM training
performance is often online data ingestion.
<br />In this paper, we explore the unique characteristics of this data ingestion
problem and provide insights into DLRM training pipeline bottlenecks and
challenges. We study real-world DLRM data processing pipelines taken from our
compute cluster at Netflix to observe the performance impacts of online
ingestion and to identify shortfalls in existing pipeline optimizers. We find
that current tooling either yields sub-optimal performance, frequent crashes,
or else requires impractical cluster re-organization to adopt. Our studies lead
us to design and build a new solution for data pipeline optimization, InTune.
<br />InTune employs a reinforcement learning (RL) agent to learn how to distribute
the CPU resources of a trainer machine across a DLRM data pipeline to more
effectively parallelize data loading and improve throughput. Our experiments
show that InTune can build an optimized data pipeline configuration within only
a few minutes, and can easily be integrated into existing training workflows.
By exploiting the responsiveness and adaptability of RL, InTune achieves higher
online data ingestion rates than existing optimizers, thus reducing idle times
in model execution and increasing efficiency. We apply InTune to our real-world
cluster, and find that it increases data ingestion throughput by as much as
2.29X versus state-of-the-art data pipeline optimizers while also improving
both CPU &amp; GPU utilization.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08502" title="Abstract">arXiv:2308.08502</a> [<a href="/pdf/2308.08502" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Meta-learning based Stacked Regression Approach for Customer Lifetime  Value Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadgil%2C+K">Karan Gadgil</a>, 
<a href="/search/cs?searchtype=author&query=Gill%2C+S+S">Sukhpal Singh Gill</a>, 
<a href="/search/cs?searchtype=author&query=Abdelmoniem%2C+A+M">Ahmed M. Abdelmoniem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Companies across the globe are keen on targeting potential high-value
customers in an attempt to expand revenue and this could be achieved only by
understanding the customers more. Customer Lifetime Value (CLV) is the total
monetary value of transactions/purchases made by a customer with the business
over an intended period of time and is used as means to estimate future
customer interactions. CLV finds application in a number of distinct business
domains such as Banking, Insurance, Online-entertainment, Gaming, and
E-Commerce. The existing distribution-based and basic (recency, frequency &amp;
monetary) based models face a limitation in terms of handling a wide variety of
input features. Moreover, the more advanced Deep learning approaches could be
superfluous and add an undesirable element of complexity in certain application
areas. We, therefore, propose a system which is able to qualify both as
effective, and comprehensive yet simple and interpretable. With that in mind,
we develop a meta-learning-based stacked regression model which combines the
predictions from bagging and boosting models that each is found to perform well
individually. Empirical tests have been carried out on an openly available
Online Retail dataset to evaluate various models and show the efficacy of the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08504" title="Abstract">arXiv:2308.08504</a> [<a href="/pdf/2308.08504" title="Download PDF">pdf</a>, <a href="/format/2308.08504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResBuilder: Automated Learning of Depth with Residual Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burghoff%2C+J">Julian Burghoff</a>, 
<a href="/search/cs?searchtype=author&query=Rottmann%2C+M">Matthias Rottmann</a>, 
<a href="/search/cs?searchtype=author&query=von+Conta%2C+J">Jill von Conta</a>, 
<a href="/search/cs?searchtype=author&query=Schoenen%2C+S">Sebastian Schoenen</a>, 
<a href="/search/cs?searchtype=author&query=Witte%2C+A">Andreas Witte</a>, 
<a href="/search/cs?searchtype=author&query=Gottschalk%2C+H">Hanno Gottschalk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, we develop a neural architecture search algorithm, termed
Resbuilder, that develops ResNet architectures from scratch that achieve high
accuracy at moderate computational cost. It can also be used to modify existing
architectures and has the capability to remove and insert ResNet blocks, in
this way searching for suitable architectures in the space of ResNet
architectures. In our experiments on different image classification datasets,
Resbuilder achieves close to state-of-the-art performance while saving
computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune
the parameters on CIFAR10 which yields a suitable default choice for all other
datasets. We demonstrate that this property generalizes even to industrial
applications by applying our method with default parameters on a proprietary
fraud detection dataset.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08505" title="Abstract">arXiv:2308.08505</a> [<a href="/pdf/2308.08505" title="Download PDF">pdf</a>, <a href="/format/2308.08505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Poisoning Attacks Against Test-Time Adaptation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+T">Tianshuo Cong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinlei He</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 45th IEEE Symposium on Security and Privacy, May 20-23, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deploying machine learning (ML) models in the wild is challenging as it
suffers from distribution shifts, where the model trained on an original domain
cannot generalize well to unforeseen diverse transfer domains. To address this
challenge, several test-time adaptation (TTA) methods have been proposed to
improve the generalization ability of the target pre-trained models under test
data to cope with the shifted distribution. The success of TTA can be credited
to the continuous fine-tuning of the target model according to the
distributional hint from the test samples during test time. Despite being
powerful, it also opens a new attack surface, i.e., test-time poisoning
attacks, which are substantially different from previous poisoning attacks that
occur during the training time of ML models (i.e., adversaries cannot intervene
in the training process). In this paper, we perform the first test-time
poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT,
and RPL. Concretely, we generate poisoned samples based on the surrogate models
and feed them to the target TTA models. Experimental results show that the TTA
methods are generally vulnerable to test-time poisoning attacks. For instance,
the adversary can feed as few as 10 poisoned samples to degrade the performance
of the target model from 76.20% to 41.83%. Our results demonstrate that TTA
algorithms lacking a rigorous security assessment are unsuitable for deployment
in real-life scenarios. As such, we advocate for the integration of defenses
against test-time poisoning attacks into the design of TTA methods.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08510" title="Abstract">arXiv:2308.08510</a> [<a href="/pdf/2308.08510" title="Download PDF">pdf</a>, <a href="/format/2308.08510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+N">Ning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaobo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shuqiao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhiyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiansheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaoyang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 1 table, submitted to Advanced Intelligent Systems for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Robots play a critical role as the physical agent of human operators in
exploring the ocean. However, it remains challenging to grasp objects reliably
while fully submerging under a highly pressurized aquatic environment with
little visible light, mainly due to the fluidic interference on the tactile
mechanics between the finger and object surfaces. This study investigates the
transferability of grasping knowledge from on-land to underwater via a
vision-based soft robotic finger that learns 6D forces and torques (FT) using a
Supervised Variational Autoencoder (SVAE). A high-framerate camera captures the
whole-body deformations while a soft robotic finger interacts with physical
objects on-land and underwater. Results show that the trained SVAE model
learned a series of latent representations of the soft mechanics transferrable
from land to water, presenting a superior adaptation to the changing
environments against commercial FT sensors. Soft, delicate, and reactive
grasping enabled by tactile intelligence enhances the gripper's underwater
interaction with improved reliability and robustness at a much-reduced cost,
paving the path for learning-based intelligent grasping to support fundamental
scientific discoveries in environmental and ocean research.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08517" title="Abstract">arXiv:2308.08517</a> [<a href="/pdf/2308.08517" title="Download PDF">pdf</a>, <a href="/format/2308.08517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building RadiologyNET: Unsupervised annotation of a large-scale  multimodal medical database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Napravnik%2C+M">Mateja Napravnik</a>, 
<a href="/search/cs?searchtype=author&query=Hr%C5%BEi%C4%87%2C+F">Franko Hr&#x17e;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Tschauner%2C+S">Sebastian Tschauner</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0tajduhar%2C+I">Ivan &#x160;tajduhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Background and objective: The usage of machine learning in medical diagnosis
and treatment has witnessed significant growth in recent years through the
development of computer-aided diagnosis systems that are often relying on
annotated medical radiology images. However, the availability of large
annotated image datasets remains a major obstacle since the process of
annotation is time-consuming and costly. This paper explores how to
automatically annotate a database of medical radiology images with regard to
their semantic similarity.
<br />Material and methods: An automated, unsupervised approach is used to
construct a large annotated dataset of medical radiology images originating
from Clinical Hospital Centre Rijeka, Croatia, utilising multimodal sources,
including images, DICOM metadata, and narrative diagnoses. Several appropriate
feature extractors are tested for each of the data sources, and their utility
is evaluated using k-means and k-medoids clustering on a representative data
subset.
<br />Results: The optimal feature extractors are then integrated into a multimodal
representation, which is then clustered to create an automated pipeline for
labelling a precursor dataset of 1,337,926 medical images into 50 clusters of
visually similar images. The quality of the clusters is assessed by examining
their homogeneity and mutual information, taking into account the anatomical
region and modality representation.
<br />Conclusion: The results suggest that fusing the embeddings of all three data
sources together works best for the task of unsupervised clustering of
large-scale medical data, resulting in the most concise clusters. Hence, this
work is the first step towards building a much larger and more fine-grained
annotated dataset of medical radiology images.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08518" title="Abstract">arXiv:2308.08518</a> [<a href="/pdf/2308.08518" title="Download PDF">pdf</a>, <a href="/format/2308.08518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on  Bidirectional Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional geometric registration based estimation methods only exploit the
CAD model implicitly, which leads to their dependence on observation quality
and deficiency to occlusion.To address the problem,the paper proposes a
bidirectional correspondence prediction network with a point-wise
attention-aware mechanism. This network not only requires the model points to
predict the correspondence but also explicitly models the geometric
similarities between observations and the model prior.} Our key insight is that
the correlations between each model point and scene point provide essential
information for learning point-pair matches. To further tackle the correlation
noises brought by feature distribution divergence, we design a simple but
effective pseudo-siamese network to improve feature homogeneity.Experimental
results on the public datasets of LineMOD, YCB-Video, and Occ-LineMOD show that
the proposed method achieves better performance than other state-of-the-art
methods under the same evaluation criteria. Its robustness in estimating poses
is greatly improved, especially in an environment with severe occlusions.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08520" title="Abstract">arXiv:2308.08520</a> [<a href="/pdf/2308.08520" title="Download PDF">pdf</a>, <a href="/format/2308.08520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Painter: Teaching Auto-regressive Language Models to Draw Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourreza%2C+R">Reza Pourreza</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+A">Apratim Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Panchal%2C+S">Sunny Panchal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+P">Pulkit Madan</a>, 
<a href="/search/cs?searchtype=author&query=Memisevic%2C+R">Roland Memisevic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have made tremendous progress in natural
language understanding and they have also been successfully adopted in other
domains such as computer vision, robotics, reinforcement learning, etc. In this
work, we apply LLMs to image generation tasks by directly generating the
virtual brush strokes to paint an image. We present Painter, an LLM that can
convert user prompts in text description format to sketches by generating the
corresponding brush strokes in an auto-regressive way. We construct Painter
based on off-the-shelf LLM that is pre-trained on a large text corpus, by
fine-tuning it on the new task while preserving language understanding
capabilities. We create a dataset of diverse multi-object sketches paired with
textual prompts that covers several object types and tasks. Painter can
generate sketches from text descriptions, remove objects from canvas, and
detect and classify objects in sketches. Although this is an unprecedented
pioneering work in using LLMs for auto-regressive image generation, the results
are very encouraging.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08523" title="Abstract">arXiv:2308.08523</a> [<a href="/pdf/2308.08523" title="Download PDF">pdf</a>, <a href="/format/2308.08523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximations for Translational Packing of Convex Polygons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurpisz%2C+A">Adam Kurpisz</a>, 
<a href="/search/cs?searchtype=author&query=Suter%2C+S">Silvan Suter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the full version of the same-named paper which will be presented at ESA 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Optimal packing of objects in containers is a critical problem in various
real-life and industrial applications. This paper investigates the
two-dimensional packing of convex polygons without rotations, where only
translations are allowed. We study different settings depending on the type of
containers used, including minimizing the number of containers or the size of
the container based on an objective function.
<br />Building on prior research in the field, we develop polynomial-time
algorithms with improved approximation guarantees upon the best-known results
by Alt, de Berg and Knauer, as well as Aamand, Abrahamsen, Beretta and Kleist,
for problems such as Polygon Area Minimization, Polygon Perimeter Minimization,
Polygon Strip Packing, and Polygon Bin Packing. Our approach utilizes a
sequence of object transformations that allows sorting by height and
orientation, thus enhancing the effectiveness of shelf packing algorithms for
polygon packing problems. In addition, we present efficient approximation
algorithms for special cases of the Polygon Bin Packing problem, progressing
toward solving an open question concerning an O(1)-approximation algorithm for
arbitrary polygons.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08525" title="Abstract">arXiv:2308.08525</a> [<a href="/pdf/2308.08525" title="Download PDF">pdf</a>, <a href="/format/2308.08525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual  and Semantic Credit Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chaorui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixiong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image synthesis has made encouraging progress and attracted lots of
public attention recently. However, popular evaluation metrics in this area,
like the Inception Score and Fr'echet Inception Distance, incur several issues.
First of all, they cannot explicitly assess the perceptual quality of generated
images and poorly reflect the semantic alignment of each text-image pair. Also,
they are inefficient and need to sample thousands of images to stabilise their
evaluation results. In this paper, we propose to evaluate text-to-image
generation performance by directly estimating the likelihood of the generated
images using a pre-trained likelihood-based text-to-image generative model,
i.e., a higher likelihood indicates better perceptual quality and better
text-image alignment. To prevent the likelihood of being dominated by the
non-crucial part of the generated image, we propose several new designs to
develop a credit assignment strategy based on the semantic and perceptual
significance of the image patches. In the experiments, we evaluate the proposed
metric on multiple popular text-to-image generation models and datasets in
accessing both the perceptual quality and the text-image alignment. Moreover,
it can successfully assess the generation ability of these models with as few
as a hundred samples, making it very efficient in practice.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08527" title="Abstract">arXiv:2308.08527</a> [<a href="/pdf/2308.08527" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patterns and Pathways: Applying Social Network Analysis to Understand  User Behavior in the Tourism Industry Websites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maghsoudi%2C+M">Mehrdad Maghsoudi</a>, 
<a href="/search/cs?searchtype=author&query=Aliakbar%2C+S">Saeid Aliakbar</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+A">AmirMahdi Mohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The contemporary tourism landscape is undergoing rapid digitization,
necessitating a nuanced comprehension of online user behavior to guide
data-driven decision-making. This research bridges an existing gap by
investigating the tourism website ecosystem through social network analysis. It
focuses specifically on inter-website communication patterns based on user
navigation. Data mining facilitates the identification of 162 core Iranian
tourism websites, which are visualized as an interconnected network with
websites as nodes and user transitions as weighted directed edges. By
implementing community detection, eight key clusters are discerned,
encompassing domains like ticket/tour bookings, accommodations, location
services, and cuisine. Further analysis of inter-community relationships
reveals website groupings frequently accessed together by users, highlighting
complementary services sought during travel planning. The research derives
invaluable insights into user preferences and information propagation within
the tourism ecosystem. The methodology and findings contribute original
perspectives to academia while offering pragmatic strategic recommendations to
industry stakeholders like service providers, investors, and policymakers. This
pioneering exploration of latent user behavior patterns advances comprehension
of the evolving digital tourism landscape in Iran. It contributes pathways
toward a sustainable future vision of the ecosystem, guiding stakeholders in
targeted decision-making based on empirical evidence derived from social
network analysis of websites and consumption patterns. The innovative
methodology expands the toolkit for data-driven tourism research within
academia.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08529" title="Abstract">arXiv:2308.08529</a> [<a href="/pdf/2308.08529" title="Download PDF">pdf</a>, <a href="/format/2308.08529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosing Human-object Interaction Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangrui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although we have witnessed significant progress in human-object interaction
(HOI) detection with increasingly high mAP (mean Average Precision), a single
mAP score is too concise to obtain an informative summary of a model's
performance and to understand why one approach is better than another. In this
paper, we introduce a diagnosis toolbox for analyzing the error sources of the
existing HOI detection models. We first conduct holistic investigations in the
pipeline of HOI detection, consisting of human-object pair detection and then
interaction classification. We define a set of errors and the oracles to fix
each of them. By measuring the mAP improvement obtained from fixing an error
using its oracle, we can have a detailed analysis of the significance of
different errors. We then delve into the human-object detection and interaction
classification, respectively, and check the model's behavior. For the first
detection task, we investigate both recall and precision, measuring the
coverage of ground-truth human-object pairs as well as the noisiness level in
the detections. For the second classification task, we compute mAP for
interaction classification only, without considering the detection scores. We
also measure the performance of the models in differentiating human-object
pairs with and without actual interactions using the AP (Average Precision)
score. Our toolbox is applicable for different methods across different
datasets and available at https://github.com/neu-vi/Diag-HOI.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08530" title="Abstract">arXiv:2308.08530</a> [<a href="/pdf/2308.08530" title="Download PDF">pdf</a>, <a href="/format/2308.08530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an  Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstructio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kouros%2C+G">Georgios Kouros</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nagesh%2C+S">Sushruth Nagesh</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+S">Shubham Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarty%2C+P">Punarjay Chakravarty</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 3 tables, ICCV TRICKY 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have revolutionized the field of novel view
synthesis, demonstrating remarkable performance. However, the modeling and
rendering of reflective objects remain challenging problems. Recent methods
have shown significant improvements over the baselines in handling reflective
scenes, albeit at the expense of efficiency. In this work, we aim to strike a
balance between efficiency and quality. To this end, we investigate an
implicit-explicit approach based on conventional volume rendering to enhance
the reconstruction quality and accelerate the training and rendering processes.
We adopt an efficient density-based grid representation and reparameterize the
reflected radiance in our pipeline. Our proposed reflection-aware approach
achieves a competitive quality efficiency trade-off compared to competing
methods. Based on our experimental results, we propose and discuss hypotheses
regarding the factors influencing the results of density-based methods for
reconstructing reflective objects. The source code is available at:
https://github.com/gkouros/ref-dvgo
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08536" title="Abstract">arXiv:2308.08536</a> [<a href="/pdf/2308.08536" title="Download PDF">pdf</a>, <a href="/format/2308.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Transformers Learn Optimal Filtering for Unknown Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Balim%2C+H">Haldun Balim</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+Z">Zhe Du</a>, 
<a href="/search/eess?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/eess?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers have demonstrated remarkable success in natural language
processing; however, their potential remains mostly unexplored for problems
arising in dynamical systems. In this work, we investigate the optimal output
estimation problem using transformers, which generate output predictions using
all the past ones. We train the transformer using various systems drawn from a
prior distribution and then evaluate its performance on previously unseen
systems from the same distribution. As a result, the obtained transformer acts
like a prediction algorithm that learns in-context and quickly adapts to and
predicts well for different systems - thus we call it meta-output-predictor
(MOP). MOP matches the performance of the optimal output estimator, based on
Kalman filter, for most linear dynamical systems even though it does not have
access to a model. We observe via extensive numerical experiments that MOP also
performs well in challenging scenarios with non-i.i.d. noise, time-varying
dynamics, and nonlinear dynamics like a quadrotor system with unknown
parameters. To further support this observation, in the second part of the
paper, we provide statistical guarantees on the performance of MOP and quantify
the required amount of training to achieve a desired excess risk during
test-time. Finally, we point out some limitations of MOP by identifying two
classes of problems MOP fails to perform well, highlighting the need for
caution when using transformers for control and estimation.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08538" title="Abstract">arXiv:2308.08538</a> [<a href="/pdf/2308.08538" title="Download PDF">pdf</a>, <a href="/format/2308.08538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proprioceptive Learning with Soft Polyhedral Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaobo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+W">Wei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaoyang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures, 2 tables, submitted to the International Journal of Robotics Research for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Proprioception is the "sixth sense" that detects limb postures with motor
neurons. It requires a natural integration between the musculoskeletal systems
and sensory receptors, which is challenging among modern robots that aim for
lightweight, adaptive, and sensitive designs at a low cost. Here, we present
the Soft Polyhedral Network with an embedded vision for physical interactions,
capable of adaptive kinesthesia and viscoelastic proprioception by learning
kinetic features. This design enables passive adaptations to omni-directional
interactions, visually captured by a miniature high-speed motion tracking
system embedded inside for proprioceptive learning. The results show that the
soft network can infer real-time 6D forces and torques with accuracies of
0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also
incorporate viscoelasticity in proprioception during static adaptation by
adding a creep and relaxation modifier to refine the predicted results. The
proposed soft network combines simplicity in design, omni-adaptation, and
proprioceptive sensing with high accuracy, making it a versatile solution for
robotics at a low cost with more than 1 million use cycles for tasks such as
sensitive and competitive grasping, and touch-based geometry reconstruction.
This study offers new insights into vision-based proprioception for soft robots
in adaptive grasping, soft manipulation, and human-robot interaction.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08543" title="Abstract">arXiv:2308.08543</a> [<a href="/pdf/2308.08543" title="Download PDF">pdf</a>, <a href="/format/2308.08543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InsightMapper: A Closer Look at Inner-instance Information for  Vectorized High-Definition Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K+Y">Kenneth K.Y. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and demo will be available at <a href="https://tonyxuqaq.github.io/projects/InsightMapper">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Vectorized high-definition (HD) maps contain detailed information about
surrounding road elements, which are crucial for various downstream tasks in
modern autonomous driving vehicles, such as vehicle planning and control.
Recent works have attempted to directly detect the vectorized HD map as a point
set prediction task, resulting in significant improvements in detection
performance. However, these approaches fail to analyze and exploit the
inner-instance correlations between predicted points, impeding further
advancements. To address these challenges, we investigate the utilization of
inner-$\textbf{INS}$tance information for vectorized h$\textbf{IGH}$-definition
mapping through $\textbf{T}$ransformers and introduce InsightMapper. This paper
presents three novel designs within InsightMapper that leverage inner-instance
information in distinct ways, including hybrid query generation, inner-instance
query fusion, and inner-instance feature aggregation. Comparative experiments
are conducted on the NuScenes dataset, showcasing the superiority of our
proposed method. InsightMapper surpasses previous state-of-the-art (SOTA)
methods by 5.78 mAP and 5.12 TOPO, which assess topology correctness.
Simultaneously, InsightMapper maintains high efficiency during both training
and inference phases, resulting in remarkable comprehensive performance. The
project page for this work is available at
https://tonyxuqaq.github.io/projects/InsightMapper .
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08544" title="Abstract">arXiv:2308.08544</a> [<a href="/pdf/2308.08544" title="Download PDF">pdf</a>, <a href="/format/2308.08544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeViS: A Large-scale Benchmark for Video Segmentation with Motion  Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shuting He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project Page: <a href="https://henghuiding.github.io/MeViS/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper strives for motion expressions guided video segmentation, which
focuses on segmenting objects in video content based on a sentence describing
the motion of the objects. Existing referring video object datasets typically
focus on salient objects and use language expressions that contain excessive
static attributes that could potentially enable the target object to be
identified in a single frame. These datasets downplay the importance of motion
in video content for language-guided video object segmentation. To investigate
the feasibility of using motion expressions to ground and segment objects in
videos, we propose a large-scale dataset called MeViS, which contains numerous
motion expressions to indicate target objects in complex environments. We
benchmarked 5 existing referring video object segmentation (RVOS) methods and
conducted a comprehensive comparison on the MeViS dataset. The results show
that current RVOS methods cannot effectively address motion expression-guided
video segmentation. We further analyze the challenges and propose a baseline
approach for the proposed MeViS dataset. The goal of our benchmark is to
provide a platform that enables the development of effective language-guided
video segmentation algorithms that leverage motion expressions as a primary cue
for object segmentation in complex video scenes. The proposed MeViS dataset has
been released at https://henghuiding.github.io/MeViS.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08545" title="Abstract">arXiv:2308.08545</a> [<a href="/pdf/2308.08545" title="Download PDF">pdf</a>, <a href="/format/2308.08545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeCH: Text-guided Reconstruction of Lifelike Clothed Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yuliang Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tingting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project: <a href="https://huangyangyi.github.io/tech">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Despite recent research advancements in reconstructing clothed humans from a
single image, accurately restoring the "unseen regions" with high-level details
remains an unsolved challenge that lacks attention. Existing methods often
generate overly smooth back-side surfaces with a blurry texture. But how to
effectively capture all visual attributes of an individual from a single image,
which are sufficient to reconstruct unseen areas (e.g., the back view)?
Motivated by the power of foundation models, TeCH reconstructs the 3D human by
leveraging 1) descriptive text prompts (e.g., garments, colors, hairstyles)
which are automatically generated via a garment parsing model and Visual
Question Answering (VQA), 2) a personalized fine-tuned Text-to-Image diffusion
model (T2I) which learns the "indescribable" appearance. To represent
high-resolution 3D clothed humans at an affordable cost, we propose a hybrid 3D
representation based on DMTet, which consists of an explicit body shape grid
and an implicit distance field. Guided by the descriptive prompts +
personalized T2I diffusion model, the geometry and texture of the 3D humans are
optimized through multi-view Score Distillation Sampling (SDS) and
reconstruction losses based on the original observation. TeCH produces
high-fidelity 3D clothed humans with consistent &amp; delicate texture, and
detailed full-body geometry. Quantitative and qualitative experiments
demonstrate that TeCH outperforms the state-of-the-art methods in terms of
reconstruction accuracy and rendering quality. The code will be publicly
available for research purposes at https://huangyangyi.github.io/tech
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 17 Aug 23</h3>
<dl>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05659" title="Abstract">arXiv:2307.05659</a> (cross-list from math.LO) [<a href="/pdf/2307.05659" title="Download PDF">pdf</a>, <a href="/format/2307.05659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing the Quantitative-Qualitative Divide in Probabilistic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ibeling%2C+D">Duligur Ibeling</a>, 
<a href="/search/math?searchtype=author&query=Icard%2C+T">Thomas Icard</a>, 
<a href="/search/math?searchtype=author&query=Mierzewski%2C+K">Krzysztof Mierzewski</a>, 
<a href="/search/math?searchtype=author&query=Moss%C3%A9%2C+M">Milan Moss&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This paper explores the space of (propositional) probabilistic logical
languages, ranging from a purely `qualitative' comparative language to a highly
`quantitative' language involving arbitrary polynomials over probability terms.
While talk of qualitative vs. quantitative may be suggestive, we identify a
robust and meaningful boundary in the space by distinguishing systems that
encode (at most) additive reasoning from those that encode additive and
multiplicative reasoning. The latter includes not only languages with explicit
multiplication but also languages expressing notions of dependence and
conditionality. We show that the distinction tracks a divide in computational
complexity: additive systems remain complete for $\mathsf{NP}$, while
multiplicative systems are robustly complete for $\exists\mathbb{R}$. We also
address axiomatic questions, offering several new completeness results as well
as a proof of non-finite-axiomatizability for comparative probability.
Repercussions of our results for conceptual and empirical questions are
addressed, and open problems are discussed.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07944" title="Abstract">arXiv:2308.07944</a> (cross-list from q-fin.PM) [<a href="/pdf/2308.07944" title="Download PDF">pdf</a>, <a href="/format/2308.07944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portfolio Selection via Topological Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sokerin%2C+P">Petr Sokerin</a>, 
<a href="/search/q-fin?searchtype=author&query=Kuznetsov%2C+K">Kristian Kuznetsov</a>, 
<a href="/search/q-fin?searchtype=author&query=Makhneva%2C+E">Elizaveta Makhneva</a>, 
<a href="/search/q-fin?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Portfolio management is an essential part of investment decision-making.
However, traditional methods often fail to deliver reasonable performance. This
problem stems from the inability of these methods to account for the unique
characteristics of multivariate time series data from stock markets. We present
a two-stage method for constructing an investment portfolio of common stocks.
The method involves the generation of time series representations followed by
their subsequent clustering. Our approach utilizes features based on
Topological Data Analysis (TDA) for the generation of representations, allowing
us to elucidate the topological structure within the data. Experimental results
show that our proposed system outperforms other methods. This superior
performance is consistent over different time frames, suggesting the viability
of TDA as a powerful tool for portfolio selection.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07954" title="Abstract">arXiv:2308.07954</a> (cross-list from q-bio.BM) [<a href="/pdf/2308.07954" title="Download PDF">pdf</a>, <a href="/format/2308.07954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APACE: AlphaFold2 and advanced computing as a service for accelerated  discovery in biophysics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Park%2C+H">Hyun Park</a>, 
<a href="/search/q-bio?searchtype=author&query=Patel%2C+P">Parth Patel</a>, 
<a href="/search/q-bio?searchtype=author&query=Haas%2C+R">Roland Haas</a>, 
<a href="/search/q-bio?searchtype=author&query=Huerta%2C+E+A">E. A. Huerta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The prediction of protein 3D structure from amino acid sequence is a
computational grand challenge in biophysics, and plays a key role in robust
protein structure prediction algorithms, from drug discovery to genome
interpretation. The advent of AI models, such as AlphaFold, is revolutionizing
applications that depend on robust protein structure prediction algorithms. To
maximize the impact, and ease the usability, of these novel AI tools we
introduce APACE, AlphaFold2 and advanced computing as a service, a novel
computational framework that effectively handles this AI model and its TB-size
database to conduct accelerated protein structure prediction analyses in modern
supercomputing environments. We deployed APACE in the Delta supercomputer, and
quantified its performance for accurate protein structure predictions using
four exemplar proteins: 6AWO, 6OAN, 7MEZ, and 6D6U. Using up to 200 ensembles,
distributed across 50 nodes in Delta, equivalent to 200 A100 NVIDIA GPUs, we
found that APACE is up to two orders of magnitude faster than off-the-shelf
AlphaFold2 implementations, reducing time-to-solution from weeks to minutes.
This computational approach may be readily linked with robotics laboratories to
automate and accelerate scientific discovery.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07983" title="Abstract">arXiv:2308.07983</a> (cross-list from stat.ML) [<a href="/pdf/2308.07983" title="Download PDF">pdf</a>, <a href="/format/2308.07983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo guided Diffusion for Bayesian linear inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cardoso%2C+G">Gabriel Cardoso</a>, 
<a href="/search/stat?searchtype=author&query=Idrissi%2C+Y+J+E">Yazid Janati El Idrissi</a>, 
<a href="/search/stat?searchtype=author&query=Corff%2C+S+L">Sylvain Le Corff</a>, 
<a href="/search/stat?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Ill-posed linear inverse problems that combine knowledge of the forward
measurement model with prior models arise frequently in various applications,
from computational photography to medical imaging. Recent research has focused
on solving these problems with score-based generative models (SGMs) that
produce perceptually plausible images, especially in inpainting problems. In
this study, we exploit the particular structure of the prior defined in the SGM
to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted
from the forward diffusion model used to construct score-based diffusion. To
solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo
methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded
and we provide numerical simulations showing that it outperforms competing
baselines when dealing with ill-posed inverse problems.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07990" title="Abstract">arXiv:2308.07990</a> (cross-list from physics.soc-ph) [<a href="/pdf/2308.07990" title="Download PDF">pdf</a>, <a href="/format/2308.07990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Community detection based on structural balance in signed networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+X">Xianyu Xu</a>, 
<a href="/search/physics?searchtype=author&query=Xue%2C+L">Leyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In signed networks, some existing community detection methods treat negative
connections as intercommunity links and positive ones as intracommunity links.
However, it is important to recognize that negative links on real-world
networks also play a key role in maintaining community stability. In this work,
our aim is to identify communities that are not only densely connected but also
harmonious or balanced in terms of the nature of their relationships. Such
communities are more likely to be stable over time and less prone to conflicts.
Consequently, we propose a motif-based method to identify communities by
quantifying the importance of links in the local structural balance. The
results in synthetic and real-world networks show that the proposed method has
a higher performance in identifying the community. In addition, it demonstrates
strong robustness, i.e., remains insensitive to the balance of the network, and
accurately classifies communities in real-world networks.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07991" title="Abstract">arXiv:2308.07991</a> (cross-list from eess.SP) [<a href="/pdf/2308.07991" title="Download PDF">pdf</a>, <a href="/format/2308.07991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demo: Reconfigurable Distributed Antennas and Reflecting Surface  (RDARS)-aided Integrated Sensing and Communication System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jintao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+C">Chengwang Ji</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiajia Guo</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 3 figures. Accepted by IEEE/CIC International Conference on Communications in China, Dalian, China, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Integrated sensing and communication (ISAC) system has been envisioned as a
promising technology to be applied in future applications requiring both
communication and high-accuracy sensing. Different from most research focusing
on theoretical analysis and optimization in the area of ISAC, we implement a
reconfigurable distributed antennas and reflecting surfaces (RDARS)-aided ISAC
system prototype to achieve the dual-functionalities with the communication
signal. A RDARS, composed of programmable elements capable of switching between
reflection mode and connected mode, is introduced to assist in uplink signal
transmission and sensing. The developed RDARS-aided ISAC prototype achieves
reliable user localization without compromising the communication rate,
showcasing its potential for future 6G systems.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07999" title="Abstract">arXiv:2308.07999</a> (cross-list from physics.comp-ph) [<a href="/pdf/2308.07999" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IceCube experience using XRootD-based Origins with GPU workflows in PNRP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Schultz%2C+D">David Schultz</a>, 
<a href="/search/physics?searchtype=author&query=Sfiligoi%2C+I">Igor Sfiligoi</a>, 
<a href="/search/physics?searchtype=author&query=Riedel%2C+B">Benedikt Riedel</a>, 
<a href="/search/physics?searchtype=author&query=Andrijauskas%2C+F">Fabio Andrijauskas</a>, 
<a href="/search/physics?searchtype=author&query=Weitzel%2C+D">Derek Weitzel</a>, 
<a href="/search/physics?searchtype=author&query=W%C3%BCrthwein%2C+F">Frank W&#xfc;rthwein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 1 table, To be published in Proceedings of CHEP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Performance (cs.PF)

</div>
<p class="mathjax">The IceCube Neutrino Observatory is a cubic kilometer neutrino telescope
located at the geographic South Pole. Understanding detector systematic effects
is a continuous process. This requires the Monte Carlo simulation to be updated
periodically to quantify potential changes and improvements in science results
with more detailed modeling of the systematic effects. IceCube's largest
systematic effect comes from the optical properties of the ice the detector is
embedded in. Over the last few years there have been considerable improvements
in the understanding of the ice, which require a significant processing
campaign to update the simulation. IceCube normally stores the results in a
central storage system at the University of Wisconsin-Madison, but it ran out
of disk space in 2022. The Prototype National Research Platform (PNRP) project
thus offered to provide both GPU compute and storage capacity to IceCube in
support of this activity. The storage access was provided via XRootD-based OSDF
Origins, a first for IceCube computing. We report on the overall experience
using PNRP resources, with both successes and pain points.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08014" title="Abstract">arXiv:2308.08014</a> (cross-list from physics.soc-ph) [<a href="/pdf/2308.08014" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and implementation of grid-connected photovoltaic power plant  with the highest technical Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Dizaj%2C+M+H">Mehran Hosseinzadeh Dizaj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Energy is a necessity and the basis of human life. With the increase in the
need for energy supply in recent years, the use of fossil fuels has
intensified. Environment is a basic principle for human beings. In our dear
country Iran, with an average sundial of approximately 4.5 hours per day, there
is the highest potential for the use of photovoltaic systems. Connected to the
national power grid as a micro grid, in accordance with the standardization and
the highest efficiency with PVsyst software, the system losses were identified
and the necessary solutions were provided to solve them. In case of using 1 to
5 kW systems, which due to small It can be installed even on the roofs of
houses. In hot cities, where electricity consumption increases in the hot
seasons of the year, the pressure is removed from the national electricity
distribution network, and a significant amount of greenhouse gas emissions to
the environment is prevented. At the end by plotting the current value of the
project it was also proven to be economical.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08025" title="Abstract">arXiv:2308.08025</a> (cross-list from quant-ph) [<a href="/pdf/2308.08025" title="Download PDF">pdf</a>, <a href="/format/2308.08025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potential Energy Advantage of Quantum Economy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+H">Hansheng Jiang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shen%2C+Z+M">Zuo-Jun Max Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Energy cost is increasingly crucial in the modern computing industry with the
wide deployment of large-scale machine learning models and language models. For
the firms that provide computing services, low energy consumption is important
both from the perspective of their own market growth and the government's
regulations. In this paper, we study the energy benefits of quantum computing
vis-a-vis classical computing. Deviating from the conventional notion of
quantum advantage based solely on computational complexity, we redefine
advantage in an energy efficiency context. Through a Cournot competition model
constrained by energy usage, we demonstrate quantum computing firms can
outperform classical counterparts in both profitability and energy efficiency
at Nash equilibrium. Therefore quantum computing may represent a more
sustainable pathway for the computing industry. Moreover, we discover that the
energy benefits of quantum computing economies are contingent on large-scale
computation. Based on real physical parameters, we further illustrate the scale
of operation necessary for realizing this energy efficiency advantage.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08027" title="Abstract">arXiv:2308.08027</a> (cross-list from eess.AS) [<a href="/pdf/2308.08027" title="Download PDF">pdf</a>, <a href="/format/2308.08027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Open Vocabulary Keyword Search With Multilingual Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yusuf%2C+B">Bolaji Yusuf</a>, 
<a href="/search/eess?searchtype=author&query=Cernocky%2C+J">Jan Cernocky</a>, 
<a href="/search/eess?searchtype=author&query=Saraclar%2C+M">Murat Saraclar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE/ACM Transactions on Audio, Speech, and Language
  Processing, vol. 31, pp. 3070-3080, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Conventional keyword search systems operate on automatic speech recognition
(ASR) outputs, which causes them to have a complex indexing and search
pipeline. This has led to interest in ASR-free approaches to simplify the
search procedure. We recently proposed a neural ASR-free keyword search model
which achieves competitive performance while maintaining an efficient and
simplified pipeline, where queries and documents are encoded with a pair of
recurrent neural network encoders and the encodings are combined with a
dot-product. In this article, we extend this work with multilingual pretraining
and detailed analysis of the model. Our experiments show that the proposed
multilingual training significantly improves the model performance and that
despite not matching a strong ASR-based conventional keyword search system for
short queries and queries comprising in-vocabulary words, the proposed model
outperforms the ASR-based system for long queries and queries that do not
appear in the training data.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08030" title="Abstract">arXiv:2308.08030</a> (cross-list from stat.ML) [<a href="/pdf/2308.08030" title="Download PDF">pdf</a>, <a href="/format/2308.08030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Data Generated by Gaussian Mixture Models Using Deep  ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+T">Tian-Yi Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Huo%2C+X">Xiaoming Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">This paper studies the binary classification of unbounded data from ${\mathbb
R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural
networks. We obtain $\unicode{x2013}$ for the first time $\unicode{x2013}$
non-asymptotic upper bounds and convergence rates of the excess risk (excess
misclassification error) for the classification without restrictions on model
parameters. The convergence rates we derive do not depend on dimension $d$,
demonstrating that deep ReLU networks can overcome the curse of dimensionality
in classification. While the majority of existing generalization analysis of
classification algorithms relies on a bounded domain, we consider an unbounded
domain by leveraging the analyticity and fast decay of Gaussian distributions.
To facilitate our analysis, we give a novel approximation error bound for
general analytic functions using ReLU networks, which may be of independent
interest. Gaussian distributions can be adopted nicely to model data arising in
applications, e.g., speeches, images, and texts; our results provide a
theoretical verification of the observed efficiency of deep neural networks in
practical classification problems.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08038" title="Abstract">arXiv:2308.08038</a> (cross-list from eess.IV) [<a href="/pdf/2308.08038" title="Download PDF">pdf</a>, <a href="/format/2308.08038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Framework for Spleen Volume Estimation from 2D  Cross-sectional Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Z">Zhen Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Puyol-Anton%2C+E">Esther Puyol-Anton</a>, 
<a href="/search/eess?searchtype=author&query=Jogeesvaran%2C+H">Haran Jogeesvaran</a>, 
<a href="/search/eess?searchtype=author&query=Inusa%2C+B">Baba Inusa</a>, 
<a href="/search/eess?searchtype=author&query=King%2C+A+P">Andrew P. King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Abnormal spleen enlargement (splenomegaly) is regarded as a clinical
indicator for a range of conditions, including liver disease, cancer and blood
diseases. While spleen length measured from ultrasound images is a commonly
used surrogate for spleen size, spleen volume remains the gold standard metric
for assessing splenomegaly and the severity of related clinical conditions.
Computed tomography is the main imaging modality for measuring spleen volume,
but it is less accessible in areas where there is a high prevalence of
splenomegaly (e.g., the Global South). Our objective was to enable automated
spleen volume measurement from 2D cross-sectional segmentations, which can be
obtained from ultrasound imaging. In this study, we describe a variational
autoencoder-based framework to measure spleen volume from single- or dual-view
2D spleen segmentations. We propose and evaluate three volume estimation
methods within this framework. We also demonstrate how 95\% confidence
intervals of volume estimates can be produced to make our method more
clinically useful. Our best model achieved mean relative volume accuracies of
86.62\% and 92.58\% for single- and dual-view segmentations, respectively,
surpassing the performance of the clinical standard approach of linear
regression using manual measurements and a comparative deep learning-based
2D-3D reconstruction-based approach. The proposed spleen volume estimation
framework can be integrated into standard clinical workflows which currently
use 2D ultrasound images to measure spleen length. To the best of our
knowledge, this is the first work to achieve direct 3D spleen volume estimation
from 2D spleen segmentations.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08049" title="Abstract">arXiv:2308.08049</a> (cross-list from math.AG) [<a href="/pdf/2308.08049" title="Download PDF">pdf</a>, <a href="/format/2308.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of GIT quotients of semisimple groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gallardo%2C+P">Patricio Gallardo</a>, 
<a href="/search/math?searchtype=author&query=Martinez-Garcia%2C+J">Jesus Martinez-Garcia</a>, 
<a href="/search/math?searchtype=author&query=Moon%2C+H">Han-Bom Moon</a>, 
<a href="/search/math?searchtype=author&query=Swinarski%2C+D">David Swinarski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 figures. 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">We describe three algorithms to determine the stable, semistable, and
torus-polystable loci of the GIT quotient of a projective variety by a
reductive group. The algorithms are efficient when the group is semisimple. By
using an implementation of our algorithms for simple groups, we provide several
applications to the moduli theory of algebraic varieties, including the
K-moduli of algebraic varieties, the moduli of algebraic curves and the Mukai
models of the moduli space of curves for low genus. We also discuss a number of
potential improvements and some natural open problems arising from this work.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08054" title="Abstract">arXiv:2308.08054</a> (cross-list from math.OC) [<a href="/pdf/2308.08054" title="Download PDF">pdf</a>, <a href="/format/2308.08054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus on Lie groups for the Riemannian Center of Mass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kraisler%2C+S">Spencer Kraisler</a>, 
<a href="/search/math?searchtype=author&query=Talebi%2C+S">Shahriar Talebi</a>, 
<a href="/search/math?searchtype=author&query=Mesbahi%2C+M">Mehran Mesbahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we develop a consensus algorithm for distributed computation
of the Riemannian center of mass (RCM) on Lie Groups. The algorithm is built
upon a distributed optimization reformulation that allows developing an
intrinsic, distributed (without relying on a consensus subroutine), and a
computationally efficient protocol for the RCM computation. The novel idea for
developing this fast distributed algorithm is to utilize a Riemannian version
of distributed gradient flow combined with a gradient tracking technique. We
first guarantee that, under certain conditions, the limit point of our
algorithm is the RCM point of interest. We then provide a proof of global
convergence in the Euclidean setting, that can be viewed as a "geometric"
dynamic consensus that converges to the average from arbitrary initial points.
Finally, we proceed to showcase the superior convergence properties of the
proposed approach as compared with other classes of consensus
optimization-based algorithms for the RCM computation.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08060" title="Abstract">arXiv:2308.08060</a> (cross-list from stat.ML) [<a href="/pdf/2308.08060" title="Download PDF">pdf</a>, <a href="/format/2308.08060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model  and Consensus Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chafamo%2C+D">Daniel Chafamo</a>, 
<a href="/search/stat?searchtype=author&query=Shanmugam%2C+V">Vignesh Shanmugam</a>, 
<a href="/search/stat?searchtype=author&query=Tokcan%2C+N">Neriman Tokcan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Algebraic Geometry (math.AG); Genomics (q-bio.GN); Applications (stat.AP)

</div>
<p class="mathjax">Tensor factorizations (TF) are powerful tools for the efficient
representation and analysis of multidimensional data. However, classic TF
methods based on maximum likelihood estimation underperform when applied to
zero-inflated count data, such as single-cell RNA sequencing (scRNA-seq) data.
Additionally, the stochasticity inherent in TFs results in factors that vary
across repeated runs, making interpretation and reproducibility of the results
challenging. In this paper, we introduce Zero Inflated Poisson Tensor
Factorization (ZIPTF), a novel approach for the factorization of
high-dimensional count data with excess zeros. To address the challenge of
stochasticity, we introduce Consensus Zero Inflated Poisson Tensor
Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based
meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic
zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF
consistently outperforms baseline matrix and tensor factorization methods in
terms of reconstruction accuracy for zero-inflated data. When the probability
of excess zeros is high, ZIPTF achieves up to $2.4\times$ better accuracy.
Additionally, C-ZIPTF significantly improves the consistency and accuracy of
the factorization. When tested on both synthetic and real scRNA-seq data, ZIPTF
and C-ZIPTF consistently recover known and biologically meaningful gene
expression programs.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08070" title="Abstract">arXiv:2308.08070</a> (cross-list from stat.ML) [<a href="/pdf/2308.08070" title="Download PDF">pdf</a>, <a href="/ps/2308.08070" title="Download PostScript">ps</a>, <a href="/format/2308.08070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-affine regression via first-order methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+S">Seonho Kim</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+K">Kiryung Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider regression of a max-affine model that produces a piecewise linear
model by combining affine models via the max function. The max-affine model
ubiquitously arises in applications in signal processing and statistics
including multiclass classification, auction problems, and convex regression.
It also generalizes phase retrieval and learning rectifier linear unit
activation functions. We present a non-asymptotic convergence analysis of
gradient descent (GD) and mini-batch stochastic gradient descent (SGD) for
max-affine regression when the model is observed at random locations following
the sub-Gaussianity and an anti-concentration with additive sub-Gaussian noise.
Under these assumptions, a suitably initialized GD and SGD converge linearly to
a neighborhood of the ground truth specified by the corresponding error bound.
We provide numerical results that corroborate the theoretical finding.
Importantly, SGD not only converges faster in run time with fewer observations
than alternating minimization and GD in the noiseless scenario but also
outperforms them in low-sample scenarios with noise.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08075" title="Abstract">arXiv:2308.08075</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2308.08075" title="Download PDF">pdf</a>, <a href="/format/2308.08075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hydrodynamics of bubble flow through a porous medium with applications  to packed bed reactors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nagrani%2C+P+P">Pranay P. Nagrani</a>, 
<a href="/search/physics?searchtype=author&query=Marconnet%2C+A+M">Amy M. Marconnet</a>, 
<a href="/search/physics?searchtype=author&query=Christov%2C+I+C">Ivan C. Christov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Gas-liquid flows through packed bed reactors (PBRs) are challenging to
predict due to the tortuous flow paths that fluid interfaces must traverse.
Experiments at the International Space Station showed that bubble and pulse
flows are predominately observed under microgravity conditions, while trickle
and spray flows observed under terrestrial conditions, are not present in
microgravity. Toward understanding the physics behind the latter experiments,
we simulate bubble flow through a PBR for different
packing-particle-diameter-based Weber numbers and under different gravity
conditions. We demonstrate different pore-scale mechanisms such as capillary
entrapment, buoyancy entrapment, and inertia-induced bubble displacement. Then,
we perform a quantitative analysis by introducing a new dynamic length scale,
dependent upon the evolving gas-liquid interfacial area, to understand the
dynamic trade-offs between the inertia, capillary, and buoyancy forces on a
bubble passing through a PBR. This analysis leads us to define new
dimensionless Weber-like numbers that delineate bubble entrapment from bubble
displacement.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08094" title="Abstract">arXiv:2308.08094</a> (cross-list from eess.IV) [<a href="/pdf/2308.08094" title="Download PDF">pdf</a>, <a href="/format/2308.08094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snapshot High Dynamic Range Imaging with a Polarization Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+M">Mingyang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+M">Matthew Chan</a>, 
<a href="/search/eess?searchtype=author&query=Metzler%2C+C">Christopher Metzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High dynamic range (HDR) images are important for a range of tasks, from
navigation to consumer photography. Accordingly, a host of specialized HDR
sensors have been developed, the most successful of which are based on
capturing variable per-pixel exposures. In essence, these methods capture an
entire exposure bracket sequence at once in a single shot. This paper presents
a straightforward but highly effective approach for turning an off-the-shelf
polarization camera into a high-performance HDR camera. By placing a linear
polarizer in front of the polarization camera, we are able to simultaneously
capture four images with varied exposures, which are determined by the
orientation of the polarizer. We develop an outlier-robust and self-calibrating
algorithm to reconstruct an HDR image (at a single polarity) from these
measurements. Finally, we demonstrate the efficacy of our approach with
extensive real-world experiments.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08105" title="Abstract">arXiv:2308.08105</a> (cross-list from math.OC) [<a href="/pdf/2308.08105" title="Download PDF">pdf</a>, <a href="/format/2308.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Triggered Stabilization of Linear Time-Delay Systems via  Halanay-Type Inequality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+K">Kexue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the event-triggered control problem for time-delay
systems. A novel event-triggering scheme is proposed to exponentially stabilize
a class of linear time-delay systems. By employing a new Halanay-type
inequality and the Lyapunov function method, sufficient conditions on the
design of control gain and selection of parameters in the proposed
event-triggering scheme are derived to both ensure the exponential stability of
the closed-loop system and exclude Zeno behavior. Two examples are given to
demonstrate the effectiveness of the theoretical result.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08130" title="Abstract">arXiv:2308.08130</a> (cross-list from math.AP) [<a href="/pdf/2308.08130" title="Download PDF">pdf</a>, <a href="/ps/2308.08130" title="Download PostScript">ps</a>, <a href="/format/2308.08130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimates of a bi-fidelity method for a multi-phase  Navier-Stokes-Vlasov-Fokker-Planck system with random inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+Y">Yiwen Lin</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Uniform error estimates of a bi-fidelity method for a kinetic-fluid coupled
model with random initial inputs in the fine particle regime are proved in this
paper. Such a model is a system coupling the incompressible Navier-Stokes
equations to the Vlasov-Fokker-Planck equations for a mixture of the flows with
distinct particle sizes. The main analytic tool is the hypocoercivity analysis
for the multi-phase Navier-Stokes-Vlasov-Fokker-Planck system with
uncertainties, considering solutions in a perturbative setting near the global
equilibrium. This allows us to obtain the error estimates in both kinetic and
hydrodynamic regimes.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08133" title="Abstract">arXiv:2308.08133</a> (cross-list from math.AP) [<a href="/pdf/2308.08133" title="Download PDF">pdf</a>, <a href="/ps/2308.08133" title="Download PostScript">ps</a>, <a href="/format/2308.08133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating the probe and singular sources methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ikehata%2C+M">Masaru Ikehata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The probe and singular sources methods are well-known two classical direct
reconstruction methods in inverse obstacle problems governed by partial
differential equations. The common part of both methods is the notion of the
indicator functions which are defined outside an unknown obstacle and blow up
on the surface of the obstacle. However, their appearance is completely
different. In this paper, by considering an inverse obstacle problem governed
by the Laplace equation in a bounded domain as a prototype case, an integrated
version of the probe and singular sources methods which fills the gap between
their indicator functions is introduced. The main result is decomposed into
three parts. First, the singular sources method combined with the probe method
and notion of the Carleman function is formulated. Second, the indicator
functions of both methods can be obtained as a result of decomposing a third
indicator function into two ways. The third indicator function blows up on both
the outer and obstacle surfaces. Third, the probe and singular sources methods
are reformulated and it is shown that the indicator functions on which both
reformulated methods based, completely coincide with each other. As a
byproduct, it turns out that the reformulated singular sources method has also
the Side B of the probe method, which is a characterization of the unknown
obstacle by means of the blowing up property of an indicator sequence.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08135" title="Abstract">arXiv:2308.08135</a> (cross-list from q-fin.ST) [<a href="/pdf/2308.08135" title="Download PDF">pdf</a>, <a href="/format/2308.08135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microstructure-Empowered Stock Factor Extraction and Utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Jiao%2C+X">Xianfeng Jiao</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+Z">Zizhong Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Xu%2C+C">Chang Xu</a>, 
<a href="/search/q-fin?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/q-fin?searchtype=author&query=Liu%2C+W">Weiqing Liu</a>, 
<a href="/search/q-fin?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">High-frequency quantitative investment is a crucial aspect of stock
investment. Notably, order flow data plays a critical role as it provides the
most detailed level of information among high-frequency trading data, including
comprehensive data from the order book and transaction records at the tick
level. The order flow data is extremely valuable for market analysis as it
equips traders with essential insights for making informed decisions. However,
extracting and effectively utilizing order flow data present challenges due to
the large volume of data involved and the limitations of traditional factor
mining techniques, which are primarily designed for coarser-level stock data.
To address these challenges, we propose a novel framework that aims to
effectively extract essential factors from order flow data for diverse
downstream tasks across different granularities and scenarios. Our method
consists of a Context Encoder and an Factor Extractor. The Context Encoder
learns an embedding for the current order flow data segment's context by
considering both the expected and actual market state. In addition, the Factor
Extractor uses unsupervised learning methods to select such important signals
that are most distinct from the majority within the given context. The
extracted factors are then utilized for downstream tasks. In empirical studies,
our proposed framework efficiently handles an entire year of stock order flow
data across diverse scenarios, offering a broader range of applications
compared to existing tick-level approaches that are limited to only a few days
of stock data. We demonstrate that our method extracts superior factors from
order flow data, enabling significant improvement for stock trend prediction
and order execution tasks at the second and minute level.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08154" title="Abstract">arXiv:2308.08154</a> (cross-list from eess.IV) [<a href="/pdf/2308.08154" title="Download PDF">pdf</a>, <a href="/format/2308.08154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Perceptual Quality Preserving Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+T">Tongda Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yanghao Li</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+D">Dailan He</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuanyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+H">Hongwei Qin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose conditional perceptual quality, an extension of the perceptual
quality defined in \citet{blau2018perception}, by conditioning it on user
defined information. Specifically, we extend the original perceptual quality
$d(p_{X},p_{\hat{X}})$ to the conditional perceptual quality
$d(p_{X|Y},p_{\hat{X}|Y})$, where $X$ is the original image, $\hat{X}$ is the
reconstructed, $Y$ is side information defined by user and $d(.,.)$ is
divergence. We show that conditional perceptual quality has similar theoretical
properties as rate-distortion-perception trade-off \citep{blau2019rethinking}.
Based on these theoretical results, we propose an optimal framework for
conditional perceptual quality preserving compression. Experimental results
show that our codec successfully maintains high perceptual quality and semantic
quality at all bitrate. Besides, by providing a lowerbound of common randomness
required, we settle the previous arguments on whether randomness should be
incorporated into generator for (conditional) perceptual quality compression.
The source code is provided in supplementary material.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08166" title="Abstract">arXiv:2308.08166</a> (cross-list from math.CO) [<a href="/pdf/2308.08166" title="Download PDF">pdf</a>, <a href="/ps/2308.08166" title="Download PostScript">ps</a>, <a href="/format/2308.08166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On graphs with no induced $P_5$ or $K_5-e$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Char%2C+A">Arnab Char</a>, 
<a href="/search/math?searchtype=author&query=Karthick%2C+T">T. Karthick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is dedicated to the memory of Professor Frederic Maffray on his death anniversary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we are interested in some problems related to chromatic number
and clique number for the class of $(P_5,K_5-e)$-free graphs, and prove the
following. $(a)$ If $G$ is a connected ($P_5,K_5-e$)-free graph with
$\omega(G)\geq 7$, then either $G$ is the complement of a bipartite graph or
$G$ has a clique cut-set. Moreover, there is a connected ($P_5,K_5-e$)-free
imperfect graph $H$ with $\omega(H)=6$ and has no clique cut-set. This
strengthens a result of Malyshev and Lobanova [Disc. Appl. Math. 219 (2017)
158--166]. $(b)$ If $G$ is a ($P_5,K_5-e$)-free graph with $\omega(G)\geq 4$,
then $\chi(G)\leq \max\{7, \omega(G)\}$. Moreover, the bound is tight when
$\omega(G)\notin \{4,5,6\}$. This result together with known results partially
answers a question of Ju and Huang [<a href="/abs/2303.18003">arXiv:2303.18003</a> [math.CO] 2023], and also
improves a result of Xu [Manuscript 2022].
<br />While the "Chromatic Number Problem" is known to be $NP$-hard for the class
of $P_5$-free graphs, our results together with some known results imply that
the "Chromatic Number Problem" can be solved in polynomial time for the class
of ($P_5,K_5-e$)-free graphs which may be independent interest.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08167" title="Abstract">arXiv:2308.08167</a> (cross-list from quant-ph) [<a href="/pdf/2308.08167" title="Download PDF">pdf</a>, <a href="/ps/2308.08167" title="Download PostScript">ps</a>, <a href="/format/2308.08167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum Approximation Scheme for k-Means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jaiswal%2C+R">Ragesh Jaiswal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">We give a quantum approximation scheme (i.e., $(1 +
\varepsilon)$-approximation for every $\varepsilon &gt; 0$) for the classical
$k$-means clustering problem in the QRAM model with a running time that has
only polylogarithmic dependence on the number of data points. More
specifically, given a dataset $V$ with $N$ points in $\mathbb{R}^d$ stored in
QRAM data structure, our quantum algorithm runs in time $\tilde{O} \left(
2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ and with high probability
outputs a set $C$ of $k$ centers such that $cost(V, C) \leq (1+\varepsilon)
\cdot cost(V, C_{OPT})$. Here $C_{OPT}$ denotes the optimal $k$-centers,
$cost(.)$ denotes the standard $k$-means cost function (i.e., the sum of the
squared distance of points to the closest center), and $\eta$ is the aspect
ratio (i.e., the ratio of maximum distance to minimum distance). This is the
first quantum algorithm with a polylogarithmic running time that gives a
provable approximation guarantee of $(1+\varepsilon)$ for the $k$-means
problem. Also, unlike previous works on unsupervised learning, our quantum
algorithm does not require quantum linear algebra subroutines and has a running
time independent of parameters (e.g., condition number) that appear in such
procedures.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08170" title="Abstract">arXiv:2308.08170</a> (cross-list from quant-ph) [<a href="/pdf/2308.08170" title="Download PDF">pdf</a>, <a href="/ps/2308.08170" title="Download PostScript">ps</a>, <a href="/format/2308.08170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Centralities in Quantum Entanglement Distribution due to User  Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+D">Dibakar Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Malapaka%2C+S+K">Shiva Kumar Malapaka</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bapat%2C+J">Jyotsna Bapat</a>, 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+D">Debabrata Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Quantum networks are of great interest of late which apply quantum mechanics
to transfer information securely. One of the key properties which are exploited
is entanglement to transfer information from one network node to another.
Applications like quantum teleportation rely on the entanglement between the
concerned nodes. Thus, efficient entanglement distribution among network nodes
is of utmost importance. Several entanglement distribution methods have been
proposed in the literature which primarily rely on attributes, such as,
fidelities, link layer network topologies, proactive distribution, etc. This
paper studies the centralities of the network when the link layer topology of
entanglements (referred to as entangled graph) is driven by usage patterns of
peer-to-peer connections between remote nodes (referred to as connection graph)
with different characteristics. Three different distributions (uniform,
gaussian, and power law) are considered for the connection graph where the two
nodes are selected from the same distribution. For the entangled graph, both
reactive and proactive entanglements are employed to form a random graph.
Results show that the edge centralities (measured as usage frequencies of
individual edges during entanglement distribution) of the entangled graph
follow power law distributions whereas the growth in entanglements with
connections and node centralities (degrees of nodes) are monomolecularly
distributed for most of the scenarios. These findings will help in quantum
resource management, e.g., quantum technology with high reliability and lower
decoherence time may be allocated to edges with high centralities.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08172" title="Abstract">arXiv:2308.08172</a> (cross-list from eess.IV) [<a href="/pdf/2308.08172" title="Download PDF">pdf</a>, <a href="/format/2308.08172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AATCT-IDS: A Benchmark Abdominal Adipose Tissue CT Image Dataset for  Image Denoising, Semantic Segmentation, and Radiomics Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhiyu Ma</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+T">Tianming Du</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+D">Dechao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+D">Deguo Ma</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Shanchuan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yihao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhihao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Nie%2C+Q">Qianqing Nie</a>, 
<a href="/search/eess?searchtype=author&query=Grzegorzek%2C+M">Marcin Grzegorzek</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongzan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Methods: In this study, a benchmark \emph{Abdominal Adipose Tissue CT Image
Dataset} (AATTCT-IDS) containing 300 subjects is prepared and published.
AATTCT-IDS publics 13,732 raw CT slices, and the researchers individually
annotate the subcutaneous and visceral adipose tissue regions of 3,213 of those
slices that have the same slice distance to validate denoising methods, train
semantic segmentation models, and study radiomics. For different tasks, this
paper compares and analyzes the performance of various methods on AATTCT-IDS by
combining the visualization results and evaluation data. Thus, verify the
research potential of this data set in the above three types of tasks.
<br />Results: In the comparative study of image denoising, algorithms using a
smoothing strategy suppress mixed noise at the expense of image details and
obtain better evaluation data. Methods such as BM3D preserve the original image
structure better, although the evaluation data are slightly lower. The results
show significant differences among them. In the comparative study of semantic
segmentation of abdominal adipose tissue, the segmentation results of adipose
tissue by each model show different structural characteristics. Among them,
BiSeNet obtains segmentation results only slightly inferior to U-Net with the
shortest training time and effectively separates small and isolated adipose
tissue. In addition, the radiomics study based on AATTCT-IDS reveals three
adipose distributions in the subject population.
<br />Conclusion: AATTCT-IDS contains the ground truth of adipose tissue regions in
abdominal CT slices. This open-source dataset can attract researchers to
explore the multi-dimensional characteristics of abdominal adipose tissue and
thus help physicians and patients in clinical practice. AATCT-IDS is freely
published for non-commercial purpose at:
\url{https://figshare.com/articles/dataset/AATTCT-IDS/23807256}.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08197" title="Abstract">arXiv:2308.08197</a> (cross-list from eess.IV) [<a href="/pdf/2308.08197" title="Download PDF">pdf</a>, <a href="/format/2308.08197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Reference Deep Adaptive Curve Estimation for Low-Light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+J">Jianyu Wen</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chenhao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yixuan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Swierczynski%2C+P">Piotr Swierczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we propose a 2-stage low-light image enhancement method called
Self-Reference Deep Adaptive Curve Estimation (Self-DACE). In the first stage,
we present an intuitive, lightweight, fast, and unsupervised luminance
enhancement algorithm. The algorithm is based on a novel low-light enhancement
curve that can be used to locally boost image brightness. We also propose a new
loss function with a simplified physical model designed to preserve natural
images' color, structure, and fidelity. We use a vanilla CNN to map each pixel
through deep Adaptive Adjustment Curves (AAC) while preserving the local image
structure. Secondly, we introduce the corresponding denoising scheme to remove
the latent noise in the darkness. We approximately model the noise in the dark
and deploy a Denoising-Net to estimate and remove the noise after the first
stage. Exhaustive qualitative and quantitative analysis shows that our method
outperforms existing state-of-the-art algorithms on multiple real-world
datasets.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08208" title="Abstract">arXiv:2308.08208</a> (cross-list from quant-ph) [<a href="/pdf/2308.08208" title="Download PDF">pdf</a>, <a href="/format/2308.08208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quaternary Neural Belief Propagation Decoding of Quantum LDPC Codes with  Overcomplete Check Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Miao%2C+S">Sisi Miao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schnerring%2C+A">Alexander Schnerring</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+H">Haizheng Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.10245">arXiv:2212.10245</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantum low-density parity-check (QLDPC) codes are promising candidates for
error correction in quantum computers. One of the major challenges in
implementing QLDPC codes in quantum computers is the lack of a universal
decoder. In this work, we first propose to decode QLDPC codes with a belief
propagation (BP) decoder operating on overcomplete check matrices. Then, we
extend the neural BP (NBP) decoder, which was originally studied for suboptimal
binary BP decoding of QLPDC codes, to quaternary BP decoders. Numerical
simulation results demonstrate that both approaches as well as their
combination yield a low-latency, high-performance decoder for several short to
moderate length QLDPC codes.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08210" title="Abstract">arXiv:2308.08210</a> (cross-list from eess.IV) [<a href="/pdf/2308.08210" title="Download PDF">pdf</a>, <a href="/format/2308.08210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spherical Harmonics for structurally coherent continuous  representation of diffusion MRI signal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hendriks%2C+T">Tom Hendriks</a>, 
<a href="/search/eess?searchtype=author&query=Villanova%2C+A">Anna Villanova</a>, 
<a href="/search/eess?searchtype=author&query=Chamberland%2C+M">Maxime Chamberland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, accepted for cdMRI workshop at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a novel way to model diffusion magnetic resonance imaging (dMRI)
datasets, that benefits from the structural coherence of the human brain while
only using data from a single subject. Current methods model the dMRI signal in
individual voxels, disregarding the intervoxel coherence that is present. We
use a neural network to parameterize a spherical harmonics series (NeSH) to
represent the dMRI signal of a single subject from the Human Connectome Project
dataset, continuous in both the angular and spatial domain. The reconstructed
dMRI signal using this method shows a more structurally coherent representation
of the data. Noise in gradient images is removed and the fiber orientation
distribution functions show a smooth change in direction along a fiber tract.
We showcase how the reconstruction can be used to calculate mean diffusivity,
fractional anisotropy, and total apparent fiber density. These results can be
achieved with a single model architecture, tuning only one hyperparameter. In
this paper we also demonstrate how upsampling in both the angular and spatial
domain yields reconstructions that are on par or better than existing methods.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08232" title="Abstract">arXiv:2308.08232</a> (cross-list from math.OC) [<a href="/pdf/2308.08232" title="Download PDF">pdf</a>, <a href="/format/2308.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCQPTH: an efficient differentiable splitting method for convex  quadratic programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Butler%2C+A">Andrew Butler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present SCQPTH: a differentiable first-order splitting method for convex
quadratic programs. The SCQPTH framework is based on the alternating direction
method of multipliers (ADMM) and the software implementation is motivated by
the state-of-the art solver OSQP: an operating splitting solver for convex
quadratic programs (QPs). The SCQPTH software is made available as an
open-source python package and contains many similar features including
efficient reuse of matrix factorizations, infeasibility detection, automatic
scaling and parameter selection. The forward pass algorithm performs operator
splitting in the dimension of the original problem space and is therefore
suitable for large scale QPs with $100-1000$ decision variables and thousands
of constraints. Backpropagation is performed by implicit differentiation of the
ADMM fixed-point mapping. Experiments demonstrate that for large scale QPs,
SCQPTH can provide a $1\times - 10\times$ improvement in computational
efficiency in comparison to existing differentiable QP solvers.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08237" title="Abstract">arXiv:2308.08237</a> (cross-list from math.CO) [<a href="/pdf/2308.08237" title="Download PDF">pdf</a>, <a href="/format/2308.08237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The maximum four point condition matrix of a tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Azimi%2C+A">Ali Azimi</a>, 
<a href="/search/math?searchtype=author&query=Jana%2C+R">Rakesh Jana</a>, 
<a href="/search/math?searchtype=author&query=Nagar%2C+M+K">Mukesh Kumar Nagar</a>, 
<a href="/search/math?searchtype=author&query=Sivasubramanian%2C+S">Sivaramakrishnan Sivasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">$\newcommand{\Max}{\mathrm{Max4PC}}$ The Four point condition (4PC
henceforth) is a well known condition characterising distances in trees $T$.
Let $w,x,y,z$ be four vertices in $T$ and let $d_{x,y}$ denote the distance
between vertices $x,y$ in $T$. The 4PC condition says that among the three
terms $d_{w,x} + d_{y,z}$, $d_{w,y} + d_{x,z}$ and $d_{w,z} + d_{x,y}$ the
maximum value equals the second maximum value.
<br />We define an $\binom{n}{2} \times \binom{n}{2}$ sized matrix $\Max_T$ from a
tree $T$ where the rows and columns are indexed by size-2 subsets. The entry of
$\Max_T$ corresponding to the row indexed by $\{w,x\}$ and column $\{y,z\}$ is
the maximum value among the three terms $d_{w,x} + d_{y,z}$, $d_{w,y} +
d_{x,z}$ and $d_{w,z} + d_{x,y}$. In this work, we determine basic properties
of this matrix like rank, give an algorithm that outputs a family of bases, and
find the determinant of $\Max_T$ when restricted to our basis. We further
determine the inertia and the Smith Normal Form (SNF) of $\Max_T$.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08247" title="Abstract">arXiv:2308.08247</a> (cross-list from stat.ML) [<a href="/pdf/2308.08247" title="Download PDF">pdf</a>, <a href="/format/2308.08247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Phases of Scaling Laws for Nearest Neighbor Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yang%2C+P">Pengkun Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+J">Jingzhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">A scaling law refers to the observation that the test performance of a model
improves as the number of training data increases. A fast scaling law implies
that one can solve machine learning problems by simply boosting the data and
the model sizes. Yet, in many cases, the benefit of adding more data can be
negligible. In this work, we study the rate of scaling laws of nearest neighbor
classifiers. We show that a scaling law can have two phases: in the first
phase, the generalization error depends polynomially on the data dimension and
decreases fast; whereas in the second phase, the error depends exponentially on
the data dimension and decreases slowly. Our analysis highlights the complexity
of the data distribution in determining the generalization error. When the data
distributes benignly, our result suggests that nearest neighbor classifier can
achieve a generalization error that depends polynomially, instead of
exponentially, on the data dimension.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08269" title="Abstract">arXiv:2308.08269</a> (cross-list from eess.IV) [<a href="/pdf/2308.08269" title="Download PDF">pdf</a>, <a href="/format/2308.08269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OnUVS: Online Feature Decoupling Framework for High-Fidelity Ultrasound  Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+A">Ao Chang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xinrui Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Rusi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yanlin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Lian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+J">Jiamin Liang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuhao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+T">Tong Han</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Ultrasound (US) imaging is indispensable in clinical practice. To diagnose
certain diseases, sonographers must observe corresponding dynamic anatomic
structures to gather comprehensive information. However, the limited
availability of specific US video cases causes teaching difficulties in
identifying corresponding diseases, which potentially impacts the detection
rate of such cases. The synthesis of US videos may represent a promising
solution to this issue. Nevertheless, it is challenging to accurately animate
the intricate motion of dynamic anatomic structures while preserving image
fidelity. To address this, we present a novel online feature-decoupling
framework called OnUVS for high-fidelity US video synthesis. Our highlights can
be summarized by four aspects. First, we introduced anatomic information into
keypoint learning through a weakly-supervised training strategy, resulting in
improved preservation of anatomical integrity and motion while minimizing the
labeling burden. Second, to better preserve the integrity and textural
information of US images, we implemented a dual-decoder that decouples the
content and textural features in the generator. Third, we adopted a
multiple-feature discriminator to extract a comprehensive range of visual cues,
thereby enhancing the sharpness and fine details of the generated videos.
Fourth, we constrained the motion trajectories of keypoints during online
learning to enhance the fluidity of generated videos. Our validation and user
studies on in-house echocardiographic and pelvic floor US videos showed that
OnUVS synthesizes US videos with high fidelity.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08283" title="Abstract">arXiv:2308.08283</a> (cross-list from eess.IV) [<a href="/pdf/2308.08283" title="Download PDF">pdf</a>, <a href="/format/2308.08283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARE: A Large Scale CT Image Dataset and Clinical Applicable Benchmark  Model for Rectal Cancer Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hantao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+W">Weidong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+C">Chenyang Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+S">Shouhong Wan</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+B">Bingbing Zou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wanqin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+P">Peiquan Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Rectal cancer segmentation of CT image plays a crucial role in timely
clinical diagnosis, radiotherapy treatment, and follow-up. Although current
segmentation methods have shown promise in delineating cancerous tissues, they
still encounter challenges in achieving high segmentation precision. These
obstacles arise from the intricate anatomical structures of the rectum and the
difficulties in performing differential diagnosis of rectal cancer.
Additionally, a major obstacle is the lack of a large-scale, finely annotated
CT image dataset for rectal cancer segmentation. To address these issues, this
work introduces a novel large scale rectal cancer CT image dataset CARE with
pixel-level annotations for both normal and cancerous rectum, which serves as a
valuable resource for algorithm research and clinical application development.
Moreover, we propose a novel medical cancer lesion segmentation benchmark model
named U-SAM. The model is specifically designed to tackle the challenges posed
by the intricate anatomical structures of abdominal organs by incorporating
prompt information. U-SAM contains three key components: promptable information
(e.g., points) to aid in target area localization, a convolution module for
capturing low-level lesion details, and skip-connections to preserve and
recover spatial information during the encoding-decoding process. To evaluate
the effectiveness of U-SAM, we systematically compare its performance with
several popular segmentation methods on the CARE dataset. The generalization of
the model is further verified on the WORD dataset. Extensive experiments
demonstrate that the proposed U-SAM outperforms state-of-the-art methods on
these two datasets. These experiments can serve as the baseline for future
research and clinical application development.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08305" title="Abstract">arXiv:2308.08305</a> (cross-list from stat.ML) [<a href="/pdf/2308.08305" title="Download PDF">pdf</a>, <a href="/format/2308.08305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Warped geometric information on the optimisation of Euclidean functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hartmann%2C+M">Marcelo Hartmann</a>, 
<a href="/search/stat?searchtype=author&query=Williams%2C+B">Bernardo Williams</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+H">Hanlin Yu</a>, 
<a href="/search/stat?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>, 
<a href="/search/stat?searchtype=author&query=Barp%2C+A">Alessandro Barp</a>, 
<a href="/search/stat?searchtype=author&query=Klami%2C+A">Arto Klami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the fundamental task of optimizing a real-valued function defined
in a potentially high-dimensional Euclidean space, such as the loss function in
many machine-learning tasks or the logarithm of the probability distribution in
statistical inference. We use the warped Riemannian geometry notions to
redefine the optimisation problem of a function on Euclidean space to a
Riemannian manifold with a warped metric, and then find the function's optimum
along this manifold. The warped metric chosen for the search domain induces a
computational friendly metric-tensor for which optimal search directions
associate with geodesic curves on the manifold becomes easier to compute.
Performing optimization along geodesics is known to be generally infeasible,
yet we show that in this specific manifold we can analytically derive Taylor
approximations up to third-order. In general these approximations to the
geodesic curve will not lie on the manifold, however we construct suitable
retraction maps to pull them back onto the manifold. Therefore, we can
efficiently optimize along the approximate geodesic curves. We cover the
related theory, describe a practical optimization algorithm and empirically
evaluate it on a collection of challenging optimisation benchmarks. Our
proposed algorithm, using third-order approximation of geodesics, outperforms
standard Euclidean gradient-based counterparts in term of number of iterations
until convergence and an alternative method for Hessian-based optimisation
routines.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08306" title="Abstract">arXiv:2308.08306</a> (cross-list from eess.AS) [<a href="/pdf/2308.08306" title="Download PDF">pdf</a>, <a href="/format/2308.08306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying Dementia in the Presence of Depression: A Cross-Corpus Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Braun%2C+F">Franziska Braun</a>, 
<a href="/search/eess?searchtype=author&query=Bayerl%2C+S+P">Sebastian P. Bayerl</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%A9rez-Toro%2C+P+A">Paula A. P&#xe9;rez-Toro</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%B6nig%2C+F">Florian H&#xf6;nig</a>, 
<a href="/search/eess?searchtype=author&query=Lehfeld%2C+H">Hartmut Lehfeld</a>, 
<a href="/search/eess?searchtype=author&query=Hillemacher%2C+T">Thomas Hillemacher</a>, 
<a href="/search/eess?searchtype=author&query=N%C3%B6th%2C+E">Elmar N&#xf6;th</a>, 
<a href="/search/eess?searchtype=author&query=Bocklet%2C+T">Tobias Bocklet</a>, 
<a href="/search/eess?searchtype=author&query=Riedhammer%2C+K">Korbinian Riedhammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Automated dementia screening enables early detection and intervention,
reducing costs to healthcare systems and increasing quality of life for those
affected. Depression has shared symptoms with dementia, adding complexity to
diagnoses. The research focus so far has been on binary classification of
dementia (DEM) and healthy controls (HC) using speech from picture description
tests from a single dataset. In this work, we apply established baseline
systems to discriminate cognitive impairment in speech from the semantic Verbal
Fluency Test and the Boston Naming Test using text, audio and emotion
embeddings in a 3-class classification problem (HC vs. MCI vs. DEM). We perform
cross-corpus and mixed-corpus experiments on two independently recorded German
datasets to investigate generalization to larger populations and different
recording conditions. In a detailed error analysis, we look at depression as a
secondary diagnosis to understand what our classifiers actually learn.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08309" title="Abstract">arXiv:2308.08309</a> (cross-list from math.OC) [<a href="/pdf/2308.08309" title="Download PDF">pdf</a>, <a href="/format/2308.08309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Data-Driven Explainability in Mathematical Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aigner%2C+K">Kevin-Martin Aigner</a>, 
<a href="/search/math?searchtype=author&query=Goerigk%2C+M">Marc Goerigk</a>, 
<a href="/search/math?searchtype=author&query=Hartisch%2C+M">Michael Hartisch</a>, 
<a href="/search/math?searchtype=author&query=Liers%2C+F">Frauke Liers</a>, 
<a href="/search/math?searchtype=author&query=Miehlich%2C+A">Arthur Miehlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Advancements in mathematical programming have made it possible to efficiently
tackle large-scale real-world problems that were deemed intractable just a few
decades ago. However, provably optimal solutions may not be accepted due to the
perception of optimization software as a black box. Although well understood by
scientists, this lacks easy accessibility for practitioners. Hence, we advocate
for introducing the explainability of a solution as another evaluation
criterion, next to its objective value, which enables us to find trade-off
solutions between these two criteria. Explainability is attained by comparing
against (not necessarily optimal) solutions that were implemented in similar
situations in the past. Thus, solutions are preferred that exhibit similar
features. Although we prove that already in simple cases the explainable model
is NP-hard, we characterize relevant polynomially solvable cases such as the
explainable shortest-path problem. Our numerical experiments on both artificial
as well as real-world road networks show the resulting Pareto front. It turns
out that the cost of enforcing explainability can be very small.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08313" title="Abstract">arXiv:2308.08313</a> (cross-list from eess.IV) [<a href="/pdf/2308.08313" title="Download PDF">pdf</a>, <a href="/format/2308.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECPC-IDS:A benchmark endometrail cancer PET/CT image dataset for  evaluation of semantic segmentation and detection of hypermetabolic regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+D">Dechao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xuanyi Li</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+T">Tianming Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+D">Deguo Ma</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhiyu Ma</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongzan Sun</a>, 
<a href="/search/eess?searchtype=author&query=Grzegorzek%2C+M">Marcin Grzegorzek</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Huiyan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Endometrial cancer is one of the most common tumors in the female
reproductive system and is the third most common gynecological malignancy that
causes death after ovarian and cervical cancer. Early diagnosis can
significantly improve the 5-year survival rate of patients. With the
development of artificial intelligence, computer-assisted diagnosis plays an
increasingly important role in improving the accuracy and objectivity of
diagnosis, as well as reducing the workload of doctors. However, the absence of
publicly available endometrial cancer image datasets restricts the application
of computer-assisted diagnostic techniques.In this paper, a publicly available
Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation
and Detection of Hypermetabolic Regions (ECPC-IDS) are published. Specifically,
the segmentation section includes PET and CT images, with a total of 7159
images in multiple formats. In order to prove the effectiveness of segmentation
methods on ECPC-IDS, five classical deep learning semantic segmentation methods
are selected to test the image segmentation task. The object detection section
also includes PET and CT images, with a total of 3579 images and XML files with
annotation information. Six deep learning methods are selected for experiments
on the detection task.This study conduct extensive experiments using deep
learning-based semantic segmentation and object detection methods to
demonstrate the differences between various methods on ECPC-IDS. As far as we
know, this is the first publicly available dataset of endometrial cancer with a
large number of multiple images, including a large amount of information
required for image and target detection. ECPC-IDS can aid researchers in
exploring new algorithms to enhance computer-assisted technology, benefiting
both clinical doctors and patients greatly.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08339" title="Abstract">arXiv:2308.08339</a> (cross-list from eess.IV) [<a href="/pdf/2308.08339" title="Download PDF">pdf</a>, <a href="/format/2308.08339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Probabilistic Model for Retinal Image Generation and  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alimanov%2C+A">Alnur Alimanov</a>, 
<a href="/search/eess?searchtype=author&query=Islam%2C+M+B">Md Baharul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computational Photography 2023 (ICCP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Experts use retinal images and vessel trees to detect and diagnose various
eye, blood circulation, and brain-related diseases. However, manual
segmentation of retinal images is a time-consuming process that requires high
expertise and is difficult due to privacy issues. Many methods have been
proposed to segment images, but the need for large retinal image datasets
limits the performance of these methods. Several methods synthesize deep
learning models based on Generative Adversarial Networks (GAN) to generate
limited sample varieties. This paper proposes a novel Denoising Diffusion
Probabilistic Model (DDPM) that outperformed GANs in image synthesis. We
developed a Retinal Trees (ReTree) dataset consisting of retinal images,
corresponding vessel trees, and a segmentation network based on DDPM trained
with images from the ReTree dataset. In the first stage, we develop a two-stage
DDPM that generates vessel trees from random numbers belonging to a standard
normal distribution. Later, the model is guided to generate fundus images from
given vessel trees and random distribution. The proposed dataset has been
evaluated quantitatively and qualitatively. Quantitative evaluation metrics
include Frechet Inception Distance (FID) score, Jaccard similarity coefficient,
Cohen's kappa, Matthew's Correlation Coefficient (MCC), precision, recall,
F1-score, and accuracy. We trained the vessel segmentation model with synthetic
data to validate our dataset's efficiency and tested it on authentic data. Our
developed dataset and source code is available at
https://github.com/AAleka/retree.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08345" title="Abstract">arXiv:2308.08345</a> (cross-list from eess.IV) [<a href="/pdf/2308.08345" title="Download PDF">pdf</a>, <a href="/format/2308.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+R">Ruiqiang Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+Z">Zhuoyue Wan</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BIBM 2023 Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vessel image segmentation plays a pivotal role in medical diagnostics, aiding
in the early detection and treatment of vascular diseases. While segmentation
based on deep learning has shown promising results, effectively segmenting
small structures and maintaining connectivity between them remains challenging.
To address these limitations, we propose GAEI-UNet, a novel model that combines
global attention and elastic interaction-based techniques. GAEI-UNet leverages
global spatial and channel context information to enhance high-level semantic
understanding within the U-Net architecture, enabling precise segmentation of
small vessels. Additionally, we adopt an elastic interaction-based loss
function to improve connectivity among these fine structures. By capturing the
forces generated by misalignment between target and predicted shapes, our model
effectively learns to preserve the correct topology of vessel networks.
Evaluation on retinal vessel dataset -- DRIVE demonstrates the superior
performance of GAEI-UNet in terms of SE and connectivity of small structures,
without significantly increasing computational complexity. This research aims
to advance the field of vessel image segmentation, providing more accurate and
reliable diagnostic tools for the medical community. The implementation code is
available on Code.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08365" title="Abstract">arXiv:2308.08365</a> (cross-list from eess.IV) [<a href="/pdf/2308.08365" title="Download PDF">pdf</a>, <a href="/format/2308.08365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data  Degradations and OOD Model Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martins%2C+N+P">Nuno Pimp&#xe3;o Martins</a>, 
<a href="/search/eess?searchtype=author&query=Kalaidzidis%2C+Y">Yannis Kalaidzidis</a>, 
<a href="/search/eess?searchtype=author&query=Zerial%2C+M">Marino Zerial</a>, 
<a href="/search/eess?searchtype=author&query=Jug%2C+F">Florian Jug</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Microscopy images are crucial for life science research, allowing detailed
inspection and characterization of cellular and tissue-level structures and
functions. However, microscopy data are unavoidably affected by image
degradations, such as noise, blur, or others. Many such degradations also
contribute to a loss of image contrast, which becomes especially pronounced in
deeper regions of thick samples. Today, best performing methods to increase the
quality of images are based on Deep Learning approaches, which typically
require ground truth (GT) data during training. Our inability to counteract
blurring and contrast loss when imaging deep into samples prevents the
acquisition of such clean GT data. The fact that the forward process of
blurring and contrast loss deep into tissue can be modeled, allowed us to
propose a new method that can circumvent the problem of unobtainable GT data.
To this end, we first synthetically degraded the quality of microscopy images
even further by using an approximate forward model for deep tissue image
degradations. Then we trained a neural network that learned the inverse of this
degradation function from our generated pairs of raw and degraded images. We
demonstrated that networks trained in this way can be used out-of-distribution
(OOD) to improve the quality of less severely degraded images, e.g. the raw
data imaged in a microscope. Since the absolute level of degradation in such
microscopy images can be stronger than the additional degradation introduced by
our forward model, we also explored the effect of iterative predictions. Here,
we observed that in each iteration the measured image contrast kept improving
while detailed structures in the images got increasingly removed. Therefore,
dependent on the desired downstream analysis, a balance between contrast
improvement and retention of image details has to be found.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08387" title="Abstract">arXiv:2308.08387</a> (cross-list from stat.ML) [<a href="/pdf/2308.08387" title="Download PDF">pdf</a>, <a href="/format/2308.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Sweep: an improved, binary quantifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kloos%2C+K">Kevin Kloos</a>, 
<a href="/search/stat?searchtype=author&query=Karch%2C+J+D">Julian D. Karch</a>, 
<a href="/search/stat?searchtype=author&query=Meertens%2C+Q+A">Quinten A. Meertens</a>, 
<a href="/search/stat?searchtype=author&query=de+Rooij%2C+M">Mark de Rooij</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantification is a supervised machine learning task, focused on estimating
the class prevalence of a dataset rather than labeling its individual
observations. We introduce Continuous Sweep, a new parametric binary quantifier
inspired by the well-performing Median Sweep. Median Sweep is currently one of
the best binary quantifiers, but we have changed this quantifier on three
points, namely 1) using parametric class distributions instead of empirical
distributions, 2) optimizing decision boundaries instead of applying discrete
decision rules, and 3) calculating the mean instead of the median. We derive
analytic expressions for the bias and variance of Continuous Sweep under
general model assumptions. This is one of the first theoretical contributions
in the field of quantification learning. Moreover, these derivations enable us
to find the optimal decision boundaries. Finally, our simulation study shows
that Continuous Sweep outperforms Median Sweep in a wide range of situations.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08396" title="Abstract">arXiv:2308.08396</a> (cross-list from eess.IV) [<a href="/pdf/2308.08396" title="Download PDF">pdf</a>, <a href="/format/2308.08396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of post-radiotherapy recurrence volumes in head and neck  squamous cell carcinoma using 3D U-Net segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kutn%C3%A1r%2C+D">Denis Kutn&#xe1;r</a>, 
<a href="/search/eess?searchtype=author&query=Vogelius%2C+I+R">Ivan R Vogelius</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%A5kansson%2C+K+E">Katrin Elisabet H&#xe5;kansson</a>, 
<a href="/search/eess?searchtype=author&query=Petersen%2C+J">Jens Petersen</a>, 
<a href="/search/eess?searchtype=author&query=Friborg%2C+J">Jeppe Friborg</a>, 
<a href="/search/eess?searchtype=author&query=Specht%2C+L">Lena Specht</a>, 
<a href="/search/eess?searchtype=author&query=Bernsdorf%2C+M">Mogens Bernsdorf</a>, 
<a href="/search/eess?searchtype=author&query=Gothelf%2C+A">Anita Gothelf</a>, 
<a href="/search/eess?searchtype=author&query=Kristensen%2C+C">Claus Kristensen</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+A+G">Abraham George Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Locoregional recurrences (LRR) are still a frequent site of treatment failure
for head and neck squamous cell carcinoma (HNSCC) patients.
<br />Identification of high risk subvolumes based on pretreatment imaging is key
to biologically targeted radiation therapy. We investigated the extent to which
a Convolutional neural network (CNN) is able to predict LRR volumes based on
pre-treatment 18F-fluorodeoxyglucose positron emission tomography
(FDG-PET)/computed tomography (CT) scans in HNSCC patients and thus the
potential to identify biological high risk volumes using CNNs.
<br />For 37 patients who had undergone primary radiotherapy for oropharyngeal
squamous cell carcinoma, five oncologists contoured the relapse volumes on
recurrence CT scans. Datasets of pre-treatment FDG-PET/CT, gross tumour volume
(GTV) and contoured relapse for each of the patients were randomly divided into
training (n=23), validation (n=7) and test (n=7) datasets. We compared a CNN
trained from scratch, a pre-trained CNN, a SUVmax threshold approach, and using
the GTV directly.
<br />The SUVmax threshold method included 5 out of the 7 relapse origin points
within a volume of median 4.6 cubic centimetres (cc). Both the GTV contour and
best CNN segmentations included the relapse origin 6 out of 7 times with median
volumes of 28 and 18 cc respectively.
<br />The CNN included the same or greater number of relapse volume POs, with
significantly smaller relapse volumes. Our novel findings indicate that CNNs
may predict LRR, yet further work on dataset development is required to attain
clinically useful prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08410" title="Abstract">arXiv:2308.08410</a> (cross-list from math.OC) [<a href="/pdf/2308.08410" title="Download PDF">pdf</a>, <a href="/format/2308.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital twinning of cardiac electrophysiology models from the surface  ECG: a geodesic backpropagation approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grandits%2C+T">Thomas Grandits</a>, 
<a href="/search/math?searchtype=author&query=Verh%C3%BClsdonk%2C+J">Jan Verh&#xfc;lsdonk</a>, 
<a href="/search/math?searchtype=author&query=Haase%2C+G">Gundolf Haase</a>, 
<a href="/search/math?searchtype=author&query=Effland%2C+A">Alexander Effland</a>, 
<a href="/search/math?searchtype=author&query=Pezzuto%2C+S">Simone Pezzuto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">The eikonal equation has become an indispensable tool for modeling cardiac
electrical activation accurately and efficiently. In principle, by matching
clinically recorded and eikonal-based electrocardiograms (ECGs), it is possible
to build patient-specific models of cardiac electrophysiology in a purely
non-invasive manner. Nonetheless, the fitting procedure remains a challenging
task. The present study introduces a novel method, Geodesic-BP, to solve the
inverse eikonal problem. Geodesic-BP is well-suited for GPU-accelerated machine
learning frameworks, allowing us to optimize the parameters of the eikonal
equation to reproduce a given ECG. We show that Geodesic-BP can reconstruct a
simulated cardiac activation with high accuracy in a synthetic test case, even
in the presence of modeling inaccuracies. Furthermore, we apply our algorithm
to a publicly available dataset of a rabbit model, with very positive results.
Given the future shift towards personalized medicine, Geodesic-BP has the
potential to help in future functionalizations of cardiac models meeting
clinical time constraints while maintaining the physiological accuracy of
state-of-the-art cardiac models.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08425" title="Abstract">arXiv:2308.08425</a> (cross-list from cond-mat.soft) [<a href="/pdf/2308.08425" title="Download PDF">pdf</a>, <a href="/format/2308.08425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On fusogenicity of positively charged phased-separated lipid vesicles:  experiments and computational simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Palzhanov%2C+Y">Yerbol Palzhanov</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dang%2C+D+T">Dang Thien Dang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Quaini%2C+A">Annalisa Quaini</a>, 
<a href="/search/cond-mat?searchtype=author&query=Olshanskii%2C+M">Maxim Olshanskii</a>, 
<a href="/search/cond-mat?searchtype=author&query=Majd%2C+S">Sheereen Majd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This paper studies the fusogenicity of cationic liposomes in relation to
their surface distribution of cationic lipids and utilizes membrane phase
separation to control this surface distribution. It is found that concentrating
the cationic lipids into small surface patches on liposomes, through
phase-separation, can enhance liposome's fusogenicity. Further concentrating
these lipids into smaller patches on the surface of liposomes led to an
increased level of fusogenicity. These experimental findings are supported by
numerical simulations using a mathematical model for phase-separated charged
liposomes. Findings of this study may be used for design and development of
highly fusogenic liposomes with minimal level of toxicity.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08426" title="Abstract">arXiv:2308.08426</a> (cross-list from math.OC) [<a href="/pdf/2308.08426" title="Download PDF">pdf</a>, <a href="/format/2308.08426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Robust Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oshin%2C+A">Alex Oshin</a>, 
<a href="/search/math?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Deterministic model predictive control (MPC), while powerful, is often
insufficient for effectively controlling autonomous systems in the real-world.
Factors such as environmental noise and model error can cause deviations from
the expected nominal performance. Robust MPC algorithms aim to bridge this gap
between deterministic and uncertain control. However, these methods are often
excessively difficult to tune for robustness due to the nonlinear and
non-intuitive effects that controller parameters have on performance. To
address this challenge, a unifying perspective on differentiable optimization
for control is presented, which enables derivation of a general, differentiable
tube-based MPC algorithm. The proposed approach facilitates the automatic and
real-time tuning of robust controllers in the presence of large uncertainties
and disturbances.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08427" title="Abstract">arXiv:2308.08427</a> (cross-list from stat.ML) [<a href="/pdf/2308.08427" title="Download PDF">pdf</a>, <a href="/format/2308.08427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Risk Aversion with Inverse Reinforcement Learning via  Interactive Questioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cheng%2C+Z">Ziteng Cheng</a>, 
<a href="/search/stat?searchtype=author&query=Coache%2C+A">Anthony Coache</a>, 
<a href="/search/stat?searchtype=author&query=Jaimungal%2C+S">Sebastian Jaimungal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a novel framework for identifying an agent's risk
aversion using interactive questioning. Our study is conducted in two
scenarios: a one-period case and an infinite horizon case. In the one-period
case, we assume that the agent's risk aversion is characterized by a cost
function of the state and a distortion risk measure. In the infinite horizon
case, we model risk aversion with an additional component, a discount factor.
Assuming the access to a finite set of candidates containing the agent's true
risk aversion, we show that asking the agent to demonstrate her optimal
policies in various environment, which may depend on their previous answers, is
an effective means of identifying the agent's risk aversion. Specifically, we
prove that the agent's risk aversion can be identified as the number of
questions tends to infinity, and the questions are randomly designed. We also
develop an algorithm for designing optimal questions and provide empirical
evidence that our method learns risk aversion significantly faster than
randomly designed questions in simulations. Our framework has important
applications in robo-advising and provides a new approach for identifying an
agent's risk preferences.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08448" title="Abstract">arXiv:2308.08448</a> (cross-list from quant-ph) [<a href="/pdf/2308.08448" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing Quantum Generative Adversarial Network (qGAN) and QCBM in  Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ganguly%2C+S">Santanu Ganguly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI Summit, London
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum machine learning (QML) is a cross-disciplinary subject made up of two
of the most exciting research areas: quantum computing and classical machine
learning (ML), with ML and artificial intelligence (AI) being projected as the
first fields that will be impacted by the rise of quantum machines. Quantum
computers are being used today in drug discovery, material &amp; molecular
modelling and finance. In this work, we discuss some upcoming active new
research areas in application of quantum machine learning (QML) in finance. We
discuss certain QML models that has become areas of active interest in the
financial world for various applications. We use real world financial dataset
and compare models such as qGAN (quantum generative adversarial networks) and
QCBM (quantum circuit Born machine) among others, using simulated environments.
For the qGAN, we define quantum circuits for discriminators and generators and
show promises of future quantum advantage via QML in finance.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08457" title="Abstract">arXiv:2308.08457</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2308.08457" title="Download PDF">pdf</a>, <a href="/format/2308.08457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Magneto-Micropolar Boundary Layer Model for Liquid Flows -- Effect  of Micromagnetorotation (MMR)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Khan%2C+M+S">Muhammad Sabeel Khan</a>, 
<a href="/search/physics?searchtype=author&query=Hameed%2C+I">Isma Hameed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we present a micropolar continuum model based on the theory of
magnetohydrodynamics. In particular, the effect of micromagnetorotation (MMR)
is taken into account in the derivation of an initial-boundary value problem
(i-bvp) within magneto-micorpolar flows. MMR is a phenomenon that is related to
the micromotions of the magnetic liquid particles in the presence of externally
applied magnetic field. In all previous investigations magnetization was
supposed to be parallel to applied magnetic field therefore its effect in the
lateral direction is neglected. This assumption is not correct in
magnetic-micropolar flows. Since, magnetic-micropolar flows are anisotropic in
nature. Here, we present a model accounting for this MMR effect. The
constitutive equation for the MMR is described and the governing system of flow
dynamics is described in the form of PDEs. Boundary layer flow assumptions are
used to derive an initial-boundary value problem in ODEs. As a consequence, two
newly defined parameters arises that are related to the MMR. The effects of
these parameters on the flow characteristics are investigated. The developed
i-bvp is solved through the shooting method using MATLAB routines. Effects of
MMR are analyzed on the miro-rotational and hydrodynamic velocities profiles.
Some interesting features of the flow are observed. Results are presented
through graphs and discussed in detail. It is worth mentioning that the model
presented is first of its kind in the literature and has a great potential in
investigating boundary layer flows within micropolar continuum with other
physical aspects of the flow pertinent to engineering and biomedical
applications.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08463" title="Abstract">arXiv:2308.08463</a> (cross-list from eess.IV) [<a href="/pdf/2308.08463" title="Download PDF">pdf</a>, <a href="/format/2308.08463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Distill Global Representation for Sparse-View CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zilong Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+C">Chenglong Ma</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=shan%2C+H">Hongming shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Sparse-view computed tomography (CT) -- using a small number of projections
for tomographic reconstruction -- enables much lower radiation dose to patients
and accelerated data acquisition. The reconstructed images, however, suffer
from strong artifacts, greatly limiting their diagnostic value. Current trends
for sparse-view CT turn to the raw data for better information recovery. The
resultant dual-domain methods, nonetheless, suffer from secondary artifacts,
especially in ultra-sparse view scenarios, and their generalization to other
scanners/protocols is greatly limited. A crucial question arises: have the
image post-processing methods reached the limit? Our answer is not yet. In this
paper, we stick to image post-processing methods due to great flexibility and
propose global representation (GloRe) distillation framework for sparse-view
CT, termed GloReDi. First, we propose to learn GloRe with Fourier convolution,
so each element in GloRe has an image-wide receptive field. Second, unlike
methods that only use the full-view images for supervision, we propose to
distill GloRe from intermediate-view reconstructed images that are readily
available but not explored in previous literature. The success of GloRe
distillation is attributed to two key components: representation directional
distillation to align the GloRe directions, and band-pass-specific contrastive
distillation to gain clinically important details. Extensive experiments
demonstrate the superiority of the proposed GloReDi over the state-of-the-art
methods, including dual-domain ones. The source code is available at
https://github.com/longzilicart/GloReDi.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08465" title="Abstract">arXiv:2308.08465</a> (cross-list from eess.IV) [<a href="/pdf/2308.08465" title="Download PDF">pdf</a>, <a href="/format/2308.08465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Uncertainty Estimation for Medical Image Segmentation  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+X">Xinyu Bai</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning a medical image segmentation model is an inherently ambiguous task,
as uncertainties exist in both images (noise) and manual annotations (human
errors and bias) used for model training. To build a trustworthy image
segmentation model, it is important to not just evaluate its performance but
also estimate the uncertainty of the model prediction. Most state-of-the-art
image segmentation networks adopt a hierarchical encoder architecture,
extracting image features at multiple resolution levels from fine to coarse. In
this work, we leverage this hierarchical image representation and propose a
simple yet effective method for estimating uncertainties at multiple levels.
The multi-level uncertainties are modelled via the skip-connection module and
then sampled to generate an uncertainty map for the predicted image
segmentation. We demonstrate that a deep learning segmentation network such as
U-net, when implemented with such hierarchical uncertainty estimation module,
can achieve a high segmentation performance, while at the same time provide
meaningful uncertainty maps that can be used for out-of-distribution detection.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08467" title="Abstract">arXiv:2308.08467</a> (cross-list from quant-ph) [<a href="/pdf/2308.08467" title="Download PDF">pdf</a>, <a href="/ps/2308.08467" title="Download PostScript">ps</a>, <a href="/format/2308.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Neural Quantum Support Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Simon%2C+L">Lars Simon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Radons%2C+M">Manuel Radons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 0 figures. arXiv admin note: substantial text overlap with <a href="/abs/2308.07204">arXiv:2308.07204</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In \cite{simon2023algorithms} we introduced four algorithms for the training
of neural support vector machines (NSVMs) and demonstrated their feasibility.
In this note we introduce neural quantum support vector machines, that is,
NSVMs with a quantum kernel, and extend our results to this setting.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08511" title="Abstract">arXiv:2308.08511</a> (cross-list from eess.IV) [<a href="/pdf/2308.08511" title="Download PDF">pdf</a>, <a href="/format/2308.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zirong Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yanyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianjia Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Weiwen Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hengyong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial
technologies in the field of medical imaging. Score-based models have proven to
be effective in addressing different inverse problems encountered in CT and
MRI, such as sparse-view CT and fast MRI reconstruction. However, these models
face challenges in achieving accurate three dimensional (3D) volumetric
reconstruction. The existing score-based models primarily focus on
reconstructing two dimensional (2D) data distribution, leading to
inconsistencies between adjacent slices in the reconstructed 3D volumetric
images. To overcome this limitation, we propose a novel two-and-a-half order
score-based model (TOSM). During the training phase, our TOSM learns data
distributions in 2D space, which reduces the complexity of training compared to
directly working on 3D volumes. However, in the reconstruction phase, the TOSM
updates the data distribution in 3D space, utilizing complementary scores along
three directions (sagittal, coronal, and transaxial) to achieve a more precise
reconstruction. The development of TOSM is built on robust theoretical
principles, ensuring its reliability and efficacy. Through extensive
experimentation on large-scale sparse-view CT and fast MRI datasets, our method
demonstrates remarkable advancements and attains state-of-the-art results in
solving 3D ill-posed inverse problems. Notably, the proposed TOSM effectively
addresses the inter-slice inconsistency issue, resulting in high-quality 3D
volumetric reconstruction.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08539" title="Abstract">arXiv:2308.08539</a> (cross-list from quant-ph) [<a href="/pdf/2308.08539" title="Download PDF">pdf</a>, <a href="/format/2308.08539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant-depth circuits for Uniformly Controlled Gates and Boolean  functions with application to quantum memory circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Allcock%2C+J">Jonathan Allcock</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bao%2C+J">Jinge Bao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Doriguello%2C+J+F">Jo&#xe3;o F. Doriguello</a>, 
<a href="/search/quant-ph?searchtype=author&query=Luongo%2C+A">Alessandro Luongo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Santha%2C+M">Miklos Santha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 10 figures. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We explore the power of the unbounded Fan-Out gate and the Global Tunable
gates generated by Ising-type Hamiltonians in constructing constant-depth
quantum circuits, with particular attention to quantum memory devices. We
propose two types of constant-depth constructions for implementing Uniformly
Controlled Gates. These gates include the Fan-In gates defined by
$|x\rangle|b\rangle\mapsto |x\rangle|b\oplus f(x)\rangle$ for $x\in\{0,1\}^n$
and $b\in\{0,1\}$, where $f$ is a Boolean function. The first of our
constructions is based on computing the one-hot encoding of the control
register $|x\rangle$, while the second is based on Boolean analysis and
exploits different representations of $f$ such as its Fourier expansion. Via
these constructions, we obtain constant-depth circuits for the quantum
counterparts of read-only and read-write memory devices -- Quantum Random
Access Memory (QRAM) and Quantum Random Access Gate (QRAG) -- of memory size
$n$. The implementation based on one-hot encoding requires either
$O(n\log{n}\log\log{n})$ ancillae and $O(n\log{n})$ Fan-Out gates or
$O(n\log{n})$ ancillae and $6$ Global Tunable gates. On the other hand, the
implementation based on Boolean analysis requires only $2$ Global Tunable gates
at the expense of $O(n^2)$ ancillae.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 17 Aug 23</h3>
<dl>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.07140" title="Abstract">arXiv:2009.07140</a> (replaced) [<a href="/pdf/2009.07140" title="Download PDF">pdf</a>, <a href="/format/2009.07140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint  Sampling for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Congcong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B+E">Bertram E. Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted by IROS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.06880" title="Abstract">arXiv:2102.06880</a> (replaced) [<a href="/pdf/2102.06880" title="Download PDF">pdf</a>, <a href="/format/2102.06880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twin-width and permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+%C3%89">&#xc9;douard Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Ne%C5%A1et%C5%99il%2C+J">Jaroslav Ne&#x161;et&#x159;il</a>, 
<a href="/search/cs?searchtype=author&query=de+Mendez%2C+P+O">Patrice Ossona de Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Siebertz%2C+S">Sebastian Siebertz</a>, 
<a href="/search/cs?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08091" title="Abstract">arXiv:2111.08091</a> (replaced) [<a href="/pdf/2111.08091" title="Download PDF">pdf</a>, <a href="/format/2111.08091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint State and Input Estimation of Agent Based on Recursive Kalman  Filter Given Prior Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zida Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhaoliang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Ankur Mehta</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 2022 International Conference on Robotics and Automation (ICRA)
  (pp. 1675-1681). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08637" title="Abstract">arXiv:2112.08637</a> (replaced) [<a href="/pdf/2112.08637" title="Download PDF">pdf</a>, <a href="/format/2112.08637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Limits of Self-Supervision in Handling Bias in Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+L">Lisa Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Karthik Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Gella%2C+S">Spandana Gella</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Hakkani-Tur%2C+D">Dilek Hakkani-Tur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.02602" title="Abstract">arXiv:2201.02602</a> (replaced) [<a href="/pdf/2201.02602" title="Download PDF">pdf</a>, <a href="/format/2201.02602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavenumber-explicit hp-FEM analysis for Maxwell&#x27;s equations with  impedance boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Melenk%2C+J+M">Jens M. Melenk</a>, 
<a href="/search/math?searchtype=author&query=Sauter%2C+S+A">Stefan A. Sauter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 91 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12670" title="Abstract">arXiv:2201.12670</a> (replaced) [<a href="/pdf/2201.12670" title="Download PDF">pdf</a>, <a href="/format/2201.12670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMGRL: Scalable Multi-resolution Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namazi%2C+R">Reza Namazi</a>, 
<a href="/search/cs?searchtype=author&query=Ghalebi%2C+E">Elahe Ghalebi</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+S">Sinead Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Mahyar%2C+H">Hamidreza Mahyar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06727" title="Abstract">arXiv:2202.06727</a> (replaced) [<a href="/e-print/2202.06727" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STG-GAN: A spatiotemporal graph generative adversarial networks for  short-term passenger flow prediction in urban rail transit systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lixing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guangyin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianguo Qi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziyou Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some errors that might mislead readers for this version. There is no new version right now
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00007" title="Abstract">arXiv:2203.00007</a> (replaced) [<a href="/e-print/2203.00007" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Attention Fusion Network for short-term passenger flow  prediction on holidays in urban rail transit systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lixing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jiateng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziyou Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some errors that might mislead readers for this version. There is no new version right now
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11434" title="Abstract">arXiv:2203.11434</a> (replaced) [<a href="/pdf/2203.11434" title="Download PDF">pdf</a>, <a href="/format/2203.11434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-linear Embeddings in Hilbert Simplex Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+F">Frank Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2nd Annual Workshop on Topology, Algebra, and Geometry in Machine
  Learning (TAG-ML, ICML23 workshop), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.12275" title="Abstract">arXiv:2203.12275</a> (replaced) [<a href="/pdf/2203.12275" title="Download PDF">pdf</a>, <a href="/format/2203.12275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certified Symmetry and Dominance Breaking for Combinatorial Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Gocht%2C+S">Stephan Gocht</a>, 
<a href="/search/cs?searchtype=author&query=McCreesh%2C+C">Ciaran McCreesh</a>, 
<a href="/search/cs?searchtype=author&query=Nordstr%C3%B6m%2C+J">Jakob Nordstr&#xf6;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was published in the Journal of Artificial Intelligence Research <a href="https://doi.org/10.1613/jair.1.14296">this https URL</a> It is an extended version of our (equally-named) paper to appear in the proceedings of AAAI 2022 <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20283">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research, volume 77: pages
  1539-1589, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.12196" title="Abstract">arXiv:2204.12196</a> (replaced) [<a href="/pdf/2204.12196" title="Download PDF">pdf</a>, <a href="/format/2204.12196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Split-Fusion Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zixuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Lei Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+C">Chong-Wah Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03354" title="Abstract">arXiv:2205.03354</a> (replaced) [<a href="/pdf/2205.03354" title="Download PDF">pdf</a>, <a href="/format/2205.03354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the order of accuracy for finite difference approximations of partial  differential equations using stencil composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mishra%2C+A">Abhishek Mishra</a>, 
<a href="/search/math?searchtype=author&query=Salac%2C+D">David Salac</a>, 
<a href="/search/math?searchtype=author&query=Knepley%2C+M+G">Matthew G. Knepley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14585" title="Abstract">arXiv:2205.14585</a> (replaced) [<a href="/pdf/2205.14585" title="Download PDF">pdf</a>, <a href="/format/2205.14585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unsupervised, open-source workflow for 2D and 3D building mapping  from airborne LiDAR data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hunsoo Song</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jinha Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07414" title="Abstract">arXiv:2207.07414</a> (replaced) [<a href="/pdf/2207.07414" title="Download PDF">pdf</a>, <a href="/format/2207.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-based gravitational wave signal detection and extraction with deep  neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/gr-qc?searchtype=author&query=Lyu%2C+R">Ruoxi Lyu</a>, 
<a href="/search/gr-qc?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/gr-qc?searchtype=author&query=Cao%2C+Z">Zhoujian Cao</a>, 
<a href="/search/gr-qc?searchtype=author&query=Ren%2C+Z">Zhixiang Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Commun Phys 6, 212 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06783" title="Abstract">arXiv:2208.06783</a> (replaced) [<a href="/pdf/2208.06783" title="Download PDF">pdf</a>, <a href="/format/2208.06783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Unstable Periodic Orbit of Unknown Fractional-Order Systems  via Adaptive Delayed Feedback Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yaghooti%2C+B">Bahram Yaghooti</a>, 
<a href="/search/eess?searchtype=author&query=Safavigerdini%2C+K">Kaveh Safavigerdini</a>, 
<a href="/search/eess?searchtype=author&query=Hajiloo%2C+R">Reza Hajiloo</a>, 
<a href="/search/eess?searchtype=author&query=Salarieh%2C+H">Hassan Salarieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11061" title="Abstract">arXiv:2208.11061</a> (replaced) [<a href="/pdf/2208.11061" title="Download PDF">pdf</a>, <a href="/format/2208.11061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Traffic Congestion Prediction based on Multimodal Fusion and  Representation Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bodong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Songyi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yaping Zhao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Data Science and Advanced
  Analytics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12288" title="Abstract">arXiv:2208.12288</a> (replaced) [<a href="/e-print/2208.12288" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Dynamic State Estimation for Networked Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+F">Fei Feng</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper needs to be withdrawn by the author. In Section II, Part C, there is lack of procedure to achieve parameter estimation using the proposed model. In Section V, Part E, experiment parameter setting is missed. Noise for estimating inertia case needs to be reset for simulation. Additional tests need to be added. These two parts need to be rewritten
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04744" title="Abstract">arXiv:2209.04744</a> (replaced) [<a href="/pdf/2209.04744" title="Download PDF">pdf</a>, <a href="/format/2209.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for Optimal Intervention Design in Causal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cammarata%2C+L">Louis Cammarata</a>, 
<a href="/search/cs?searchtype=author&query=Squires%2C+C">Chandler Squires</a>, 
<a href="/search/cs?searchtype=author&query=Sapsis%2C+T+P">Themistoklis P. Sapsis</a>, 
<a href="/search/cs?searchtype=author&query=Uhler%2C+C">Caroline Uhler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10021" title="Abstract">arXiv:2209.10021</a> (replaced) [<a href="/pdf/2209.10021" title="Download PDF">pdf</a>, <a href="/ps/2209.10021" title="Download PostScript">ps</a>, <a href="/format/2209.10021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffTune: Auto-Tuning through Auto-Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yiquan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minkyung Kim and Lin Song contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00563" title="Abstract">arXiv:2210.00563</a> (replaced) [<a href="/pdf/2210.00563" title="Download PDF">pdf</a>, <a href="/format/2210.00563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Assisted Discovery of Quantitative and Formal Models in Social  Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balla%2C+J">Julia Balla</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dugan%2C+O">Owen Dugan</a>, 
<a href="/search/cs?searchtype=author&query=Dangovski%2C+R">Rumen Dangovski</a>, 
<a href="/search/cs?searchtype=author&query=Soljacic%2C+M">Marin Soljacic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01549" title="Abstract">arXiv:2210.01549</a> (replaced) [<a href="/pdf/2210.01549" title="Download PDF">pdf</a>, <a href="/format/2210.01549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Graphs Benefit From Discrete State Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haefeli%2C+K+K">Kilian Konstantin Haefeli</a>, 
<a href="/search/cs?searchtype=author&query=Martinkus%2C+K">Karolis Martinkus</a>, 
<a href="/search/cs?searchtype=author&query=Perraudin%2C+N">Nathana&#xeb;l Perraudin</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the First Learning on Graphs Conference (LoG 2022) and the NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02614" title="Abstract">arXiv:2210.02614</a> (replaced) [<a href="/pdf/2210.02614" title="Download PDF">pdf</a>, <a href="/format/2210.02614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Server Learning: Enhancing Performance for  Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+V+S">Van Sy Mai</a>, 
<a href="/search/cs?searchtype=author&query=La%2C+R+J">Richard J. La</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03021" title="Abstract">arXiv:2210.03021</a> (replaced) [<a href="/pdf/2210.03021" title="Download PDF">pdf</a>, <a href="/ps/2210.03021" title="Download PostScript">ps</a>, <a href="/format/2210.03021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explanations as Programs in Probabilistic Logic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vidal%2C+G">Germ&#xe1;n Vidal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as: Vidal, G. (2022). Explanations as Programs in Probabilistic Logic Programming. In: Hanus, M., Igarashi, A. (eds) Functional and Logic Programming. FLOPS 2022. Lecture Notes in Computer Science, vol 13215. Springer, Cham. The final authenticated publication is available online at <a href="https://doi.org/10.1007/978-3-030-99461-7_12">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03921" title="Abstract">arXiv:2210.03921</a> (replaced) [<a href="/pdf/2210.03921" title="Download PDF">pdf</a>, <a href="/format/2210.03921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Selection: A Surprisingly Effective and General Principle for  Building Small Interpretable Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghose%2C+A">Abhishek Ghose</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04214" title="Abstract">arXiv:2210.04214</a> (replaced) [<a href="/pdf/2210.04214" title="Download PDF">pdf</a>, <a href="/format/2210.04214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VM-NeRF: Tackling Sparsity in NeRF with View Morphing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bortolon%2C+M">Matteo Bortolon</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bue%2C+A">Alessio Del Bue</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICIAP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05020" title="Abstract">arXiv:2210.05020</a> (replaced) [<a href="/pdf/2210.05020" title="Download PDF">pdf</a>, <a href="/format/2210.05020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Sparsification for Communication-Efficient Collaborative  Rotation and Translation Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yulun Tian</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised extended technical report (37 pages, 15 figures, 6 tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05740" title="Abstract">arXiv:2210.05740</a> (replaced) [<a href="/pdf/2210.05740" title="Download PDF">pdf</a>, <a href="/format/2210.05740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Constrained DRO with a Complexity Independent of Sample Size
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiameng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+s">Kung sik Chan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+E+W">Er Wei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09043" title="Abstract">arXiv:2210.09043</a> (replaced) [<a href="/e-print/2210.09043" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ST-former for short-term passenger flow prediction during COVID-19 in  urban rail transit system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lixing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziyou Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some errors that might mislead readers for this version. There is no new version right now
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10592" title="Abstract">arXiv:2210.10592</a> (replaced) [<a href="/pdf/2210.10592" title="Download PDF">pdf</a>, <a href="/format/2210.10592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyTed: Disentangled Representation Learning for Discrete-time Dynamic  Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gaolin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bingbing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Hongjian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12150" title="Abstract">arXiv:2210.12150</a> (replaced) [<a href="/pdf/2210.12150" title="Download PDF">pdf</a>, <a href="/format/2210.12150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing Chemical Physics using the Lean Theorem Prover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobbin%2C+M+P">Maxwell P. Bobbin</a>, 
<a href="/search/cs?searchtype=author&query=Sharlin%2C+S">Samiha Sharlin</a>, 
<a href="/search/cs?searchtype=author&query=Feyzishendi%2C+P">Parivash Feyzishendi</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+A+H">An Hong Dang</a>, 
<a href="/search/cs?searchtype=author&query=Wraback%2C+C+M">Catherine M. Wraback</a>, 
<a href="/search/cs?searchtype=author&query=Josephson%2C+T+R">Tyler R. Josephson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14184" title="Abstract">arXiv:2210.14184</a> (replaced) [<a href="/pdf/2210.14184" title="Download PDF">pdf</a>, <a href="/format/2210.14184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Ability of Interpolating Deep Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+T">Tian-Yi Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Huo%2C+X">Xiaoming Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15654" title="Abstract">arXiv:2210.15654</a> (replaced) [<a href="/pdf/2210.15654" title="Download PDF">pdf</a>, <a href="/ps/2210.15654" title="Download PostScript">ps</a>, <a href="/format/2210.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reductions in Higher-Order Rewriting and Their Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barenbaum%2C+P">Pablo Barenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Bonelli%2C+E">Eduardo Bonelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00225" title="Abstract">arXiv:2211.00225</a> (replaced) [<a href="/pdf/2211.00225" title="Download PDF">pdf</a>, <a href="/ps/2211.00225" title="Download PostScript">ps</a>, <a href="/format/2211.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative algorithms for partitioned neural network approximation to  partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+H+J">Hee Jun Yang</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+H+H">Hyea Hyun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02690" title="Abstract">arXiv:2211.02690</a> (replaced) [<a href="/pdf/2211.02690" title="Download PDF">pdf</a>, <a href="/format/2211.02690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech enhancement using ego-noise references with a microphone array  embedded in an unmanned aerial vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tengan%2C+E">Elisa Tengan</a>, 
<a href="/search/eess?searchtype=author&query=Dietzen%2C+T">Thomas Dietzen</a>, 
<a href="/search/eess?searchtype=author&query=Ruiz%2C+S">Santiago Ruiz</a>, 
<a href="/search/eess?searchtype=author&query=Alkmim%2C+M">Mansour Alkmim</a>, 
<a href="/search/eess?searchtype=author&query=Cardenuto%2C+J">Jo&#xe3;o Cardenuto</a>, 
<a href="/search/eess?searchtype=author&query=van+Waterschoot%2C+T">Toon van Waterschoot</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 24th International Congress on Acoustics (ICA),
  Gyeongju, South Korea, 24 Oct 2022-28 Oct 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02982" title="Abstract">arXiv:2211.02982</a> (replaced) [<a href="/pdf/2211.02982" title="Download PDF">pdf</a>, <a href="/format/2211.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event and Entity Extraction from Generated Video Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scherer%2C+J">Johannes Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Scherp%2C+A">Ansgar Scherp</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+D">Deepayan Bhowmik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at CD-MAKE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05457" title="Abstract">arXiv:2211.05457</a> (replaced) [<a href="/e-print/2211.05457" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax-Guided Domain Adaptation for Aspect-based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+A">Anguo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I want to withdraw this article due to personal reason
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09703" title="Abstract">arXiv:2211.09703</a> (replaced) [<a href="/pdf/2211.09703" title="Download PDF">pdf</a>, <a href="/format/2211.09703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EfficientTrain: Exploring Generalized Curriculum Learning for Training  Visual Backbones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yulin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianjiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10605" title="Abstract">arXiv:2211.10605</a> (replaced) [<a href="/pdf/2211.10605" title="Download PDF">pdf</a>, <a href="/format/2211.10605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISAC Meets SWIPT: Multi-functional Wireless Systems Integrating Sensing,  Communication, and Powering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+H">Haocheng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.16716">arXiv:2210.16716</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10946" title="Abstract">arXiv:2211.10946</a> (replaced) [<a href="/pdf/2211.10946" title="Download PDF">pdf</a>, <a href="/format/2211.10946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalizing Flows for Human Pose Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirschorn%2C+O">Or Hirschorn</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11695" title="Abstract">arXiv:2211.11695</a> (replaced) [<a href="/pdf/2211.11695" title="Download PDF">pdf</a>, <a href="/format/2211.11695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Si&#x27;ao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12791" title="Abstract">arXiv:2211.12791</a> (replaced) [<a href="/pdf/2211.12791" title="Download PDF">pdf</a>, <a href="/format/2211.12791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An ensemble of VisNet, Transformer-M, and pretraining models for  molecular property prediction in OGB Large-Scale Challenge @ NeurIPS 2022
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaoning Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zun Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinheng He</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+B">Bin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01103" title="Abstract">arXiv:2212.01103</a> (replaced) [<a href="/pdf/2212.01103" title="Download PDF">pdf</a>, <a href="/format/2212.01103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zutao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guansong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01729" title="Abstract">arXiv:2212.01729</a> (replaced) [<a href="/pdf/2212.01729" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Synchronized Full System State Estimation Considering Practical  Implementation Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Varghese%2C+A+C">Antos Cheeramban Varghese</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+H">Hritik Shah</a>, 
<a href="/search/eess?searchtype=author&query=Azimian%2C+B">Behrouz Azimian</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>, 
<a href="/search/eess?searchtype=author&query=Farantatos%2C+E">Evangelos Farantatos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03141" title="Abstract">arXiv:2212.03141</a> (replaced) [<a href="/pdf/2212.03141" title="Download PDF">pdf</a>, <a href="/format/2212.03141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis-aware defeaturing of complex geometries with Neumann features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antolin%2C+P">Pablo Antolin</a>, 
<a href="/search/math?searchtype=author&query=Chanon%2C+O">Ondine Chanon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05370" title="Abstract">arXiv:2212.05370</a> (replaced) [<a href="/pdf/2212.05370" title="Download PDF">pdf</a>, <a href="/format/2212.05370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-free Depth for Object Pop-out
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09095" title="Abstract">arXiv:2212.09095</a> (replaced) [<a href="/pdf/2212.09095" title="Download PDF">pdf</a>, <a href="/format/2212.09095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Role of Scale for In-Context Learning: An  Interpretability-based Case Study at 66 Billion Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Karthik Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Dingliwal%2C+S">Saket Dingliwal</a>, 
<a href="/search/cs?searchtype=author&query=Bodapati%2C+S">Sravan Bodapati</a>, 
<a href="/search/cs?searchtype=author&query=Kirchhoff%2C+K">Katrin Kirchhoff</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+D">Dan Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Annual Meeting of the Association for Computational Linguistics (ACL) 2023, Main Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01690" title="Abstract">arXiv:2301.01690</a> (replaced) [<a href="/pdf/2301.01690" title="Download PDF">pdf</a>, <a href="/ps/2301.01690" title="Download PostScript">ps</a>, <a href="/format/2301.01690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proofs as stateful programs: A first-order logic with abstract Hoare  triples, and an interpretation into an imperative language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Powell%2C+T">Thomas Powell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06567" title="Abstract">arXiv:2301.06567</a> (replaced) [<a href="/pdf/2301.06567" title="Download PDF">pdf</a>, <a href="/format/2301.06567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Surface Water Mapping up to Fine-scale using Geometric Features  of Water from Topographic Airborne LiDAR Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hunsoo Song</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jinha Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10405" title="Abstract">arXiv:2301.10405</a> (replaced) [<a href="/pdf/2301.10405" title="Download PDF">pdf</a>, <a href="/format/2301.10405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Language Model-based Knowledge Graph Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress and the project website is <a href="https://zjunlp.github.io/project/KGE_Editing/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11118" title="Abstract">arXiv:2301.11118</a> (replaced) [<a href="/pdf/2301.11118" title="Download PDF">pdf</a>, <a href="/format/2301.11118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Box$^2$EL: Concept and Role Box Embeddings for the Description Logic  EL++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackermeier%2C+M">Mathias Jackermeier</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11562" title="Abstract">arXiv:2301.11562</a> (replaced) [<a href="/pdf/2301.11562" title="Download PDF">pdf</a>, <a href="/format/2301.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is My Prediction Arbitrary? The Confounding Effects of Variance in Fair  Classification Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choksi%2C+M+Z">Madiha Zahrah Choksi</a>, 
<a href="/search/cs?searchtype=author&query=Barocas%2C+S">Solon Barocas</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Siddhartha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baobao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13109" title="Abstract">arXiv:2301.13109</a> (replaced) [<a href="/pdf/2301.13109" title="Download PDF">pdf</a>, <a href="/format/2301.13109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A symmetric low-regularity integrator for the nonlinear Schr&#xf6;dinger  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bronsard%2C+Y+A">Yvonne Alama Bronsard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02509" title="Abstract">arXiv:2302.02509</a> (replaced) [<a href="/pdf/2302.02509" title="Download PDF">pdf</a>, <a href="/format/2302.02509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate reconstructability of quantum states and noisy quantum  secret sharing schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ouyang%2C+Y">Yingkai Ouyang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goswami%2C+K">Kaumudibikash Goswami</a>, 
<a href="/search/quant-ph?searchtype=author&query=Romero%2C+J">Jacquiline Romero</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sanders%2C+B+C">Barry C. Sanders</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hsieh%2C+M">Min-Hsiu Hsieh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tomamichel%2C+M">Marco Tomamichel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. A 108, 012425, Published 21 July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06608" title="Abstract">arXiv:2302.06608</a> (replaced) [<a href="/pdf/2302.06608" title="Download PDF">pdf</a>, <a href="/format/2302.06608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-aware Blending with Generative NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gayoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yunjey Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin-Hwa Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun-Yan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://blandocs.github.io/blendnerf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07558" title="Abstract">arXiv:2302.07558</a> (replaced) [<a href="/pdf/2302.07558" title="Download PDF">pdf</a>, <a href="/format/2302.07558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initialisation from lattice Boltzmann to multi-step Finite Difference  methods: modified equations and discrete observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bellotti%2C+T">Thomas Bellotti</a> (CMAP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07786" title="Abstract">arXiv:2302.07786</a> (replaced) [<a href="/pdf/2302.07786" title="Download PDF">pdf</a>, <a href="/format/2302.07786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation of the Deformation for Cycling Chemo-Mechanically Coupled  Battery Active Particles with Mechanical Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schoof%2C+R">R. Schoof</a>, 
<a href="/search/math?searchtype=author&query=Castelli%2C+G+F">G. F. Castelli</a>, 
<a href="/search/math?searchtype=author&query=D%C3%B6rfler%2C+W">W. D&#xf6;rfler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13036" title="Abstract">arXiv:2302.13036</a> (replaced) [<a href="/pdf/2302.13036" title="Download PDF">pdf</a>, <a href="/format/2302.13036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limited Query Graph Connectivity Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+A">Aneta Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hung Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13555" title="Abstract">arXiv:2302.13555</a> (replaced) [<a href="/pdf/2302.13555" title="Download PDF">pdf</a>, <a href="/format/2302.13555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing any Linear Combination of Unitaries on Intermediate-term  Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chakraborty%2C+S">Shantanav Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 72+16 pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14036" title="Abstract">arXiv:2302.14036</a> (replaced) [<a href="/pdf/2302.14036" title="Download PDF">pdf</a>, <a href="/format/2302.14036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-only domain adaptation for end-to-end ASR using integrated  text-to-mel-spectrogram generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bataev%2C+V">Vladimir Bataev</a>, 
<a href="/search/eess?searchtype=author&query=Korostik%2C+R">Roman Korostik</a>, 
<a href="/search/eess?searchtype=author&query=Shabalin%2C+E">Evgeny Shabalin</a>, 
<a href="/search/eess?searchtype=author&query=Lavrukhin%2C+V">Vitaly Lavrukhin</a>, 
<a href="/search/eess?searchtype=author&query=Ginsburg%2C+B">Boris Ginsburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00557" title="Abstract">arXiv:2303.00557</a> (replaced) [<a href="/pdf/2303.00557" title="Download PDF">pdf</a>, <a href="/ps/2303.00557" title="Download PostScript">ps</a>, <a href="/format/2303.00557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding codes on infinite grids automatically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Salo%2C+V">Ville Salo</a>, 
<a href="/search/math?searchtype=author&query=T%C3%B6rm%C3%A4%2C+I">Ilkka T&#xf6;rm&#xe4;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03207" title="Abstract">arXiv:2303.03207</a> (replaced) [<a href="/pdf/2303.03207" title="Download PDF">pdf</a>, <a href="/format/2303.03207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Reinforcement Learning and Formal Verification for Safe  Colonoscopy Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corsi%2C+D">Davide Corsi</a>, 
<a href="/search/cs?searchtype=author&query=Marzari%2C+L">Luca Marzari</a>, 
<a href="/search/cs?searchtype=author&query=Pore%2C+A">Ameya Pore</a>, 
<a href="/search/cs?searchtype=author&query=Farinelli%2C+A">Alessandro Farinelli</a>, 
<a href="/search/cs?searchtype=author&query=Casals%2C+A">Alicia Casals</a>, 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+P">Paolo Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Alba%2C+D">Diego Dall&#x27;Alba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the IEEE International Conference on Intelligent Robots and Systems (IROS), 2023. [Corsi, Marzari and Pore contributed equally]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05408" title="Abstract">arXiv:2303.05408</a> (replaced) [<a href="/pdf/2303.05408" title="Download PDF">pdf</a>, <a href="/format/2303.05408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast algorithms for Vizing&#x27;s theorem on bounded degree graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernshteyn%2C+A">Anton Bernshteyn</a>, 
<a href="/search/cs?searchtype=author&query=Dhawan%2C+A">Abhishek Dhawan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07928" title="Abstract">arXiv:2303.07928</a> (replaced) [<a href="/pdf/2303.07928" title="Download PDF">pdf</a>, <a href="/format/2303.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of the Exponential and Cayley Map on SE(3) as relevant for Lie  Group Integration of the Generalized Poisson Equation and Flexible Multibody  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mueller%2C+A">Andreas Mueller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. Royal Soc. A, Vol. 477, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Differential Geometry (math.DG)</span>; Robotics (cs.RO); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08646" title="Abstract">arXiv:2303.08646</a> (replaced) [<a href="/pdf/2303.08646" title="Download PDF">pdf</a>, <a href="/format/2303.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HFGD: High-level Feature Guided Decoder for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Ye Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Di Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lixin Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version, refactored presentation and added more experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09219" title="Abstract">arXiv:2303.09219</a> (replaced) [<a href="/pdf/2303.09219" title="Download PDF">pdf</a>, <a href="/format/2303.09219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixCycle: Mixup Assisted Semi-Supervised 3D Single Object Tracking with  Cycle Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chu&#x27;ai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Salzmann%2C+M">Mathieu Salzmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09375" title="Abstract">arXiv:2303.09375</a> (replaced) [<a href="/pdf/2303.09375" title="Download PDF">pdf</a>, <a href="/format/2303.09375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svitov%2C+D">David Svitov</a>, 
<a href="/search/cs?searchtype=author&query=Gudkov%2C+D">Dmitrii Gudkov</a>, 
<a href="/search/cs?searchtype=author&query=Bashirov%2C+R">Renat Bashirov</a>, 
<a href="/search/cs?searchtype=author&query=Lempitsky%2C+V">Victor Lempitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09472" title="Abstract">arXiv:2303.09472</a> (replaced) [<a href="/pdf/2303.09472" title="Download PDF">pdf</a>, <a href="/format/2303.09472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffIR: Efficient Diffusion Model for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinglong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ICCV2023. Codes and models are available at <a href="https://github.com/Zj-BinXia/DiffIR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09713" title="Abstract">arXiv:2303.09713</a> (replaced) [<a href="/pdf/2303.09713" title="Download PDF">pdf</a>, <a href="/format/2303.09713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHAMPAGNE: Learning Real-world Conversation from Large-Scale Web Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seungju Han</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://seungjuhan.me/champagne">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10310" title="Abstract">arXiv:2303.10310</a> (replaced) [<a href="/pdf/2303.10310" title="Download PDF">pdf</a>, <a href="/format/2303.10310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo Supervised Metrics: Evaluating Unsupervised Image to Image  Translation Models In Unsupervised Cross-Domain Classification Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Hindawi%2C+F">Firas Al-Hindawi</a>, 
<a href="/search/cs?searchtype=author&query=Siddiquee%2C+M+M+R">Md Mahfuzur Rahman Siddiquee</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Teresa Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.09107">arXiv:2212.09107</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10385" title="Abstract">arXiv:2303.10385</a> (replaced) [<a href="/pdf/2303.10385" title="Download PDF">pdf</a>, <a href="/format/2303.10385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Occlusion Inference with Vectorized Representation for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bochao Huang</a>, Pin
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11888" title="Abstract">arXiv:2303.11888</a> (replaced) [<a href="/pdf/2303.11888" title="Download PDF">pdf</a>, <a href="/format/2303.11888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalty-Based Imitation Learning With Cross Semantics Generation Sensor  Fusion for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongkuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+A">Aifen Sui</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Letian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinxian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12791" title="Abstract">arXiv:2303.12791</a> (replaced) [<a href="/pdf/2303.12791" title="Download PDF">pdf</a>, <a href="/format/2303.12791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHERF: Generalizable Human NeRF from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shoukang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Fangzhou Hong</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haiyi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023. Project webpage: <a href="https://skhu101.github.io/SHERF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13516" title="Abstract">arXiv:2303.13516</a> (replaced) [<a href="/pdf/2303.13516" title="Download PDF">pdf</a>, <a href="/format/2303.13516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ablating Concepts in Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+N">Nupur Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bingliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng-Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun-Yan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project website: <a href="https://www.cs.cmu.edu/~concept-ablation/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13538" title="Abstract">arXiv:2303.13538</a> (replaced) [<a href="/pdf/2303.13538" title="Download PDF">pdf</a>, <a href="/format/2303.13538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bluetooth and WiFi Dataset for Real World RF Fingerprinting of  Commercial Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jagannath%2C+A">Anu Jagannath</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+Z">Zackary Kane</a>, 
<a href="/search/cs?searchtype=author&query=Jagannath%2C+J">Jithin Jagannath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16166" title="Abstract">arXiv:2303.16166</a> (replaced) [<a href="/pdf/2303.16166" title="Download PDF">pdf</a>, <a href="/format/2303.16166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Good and Reproducible Results are a Giant with Feet of Clay: The  Importance of Software Quality in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papi%2C+S">Sara Papi</a>, 
<a href="/search/cs?searchtype=author&query=Gaido%2C+M">Marco Gaido</a>, 
<a href="/search/cs?searchtype=author&query=Pilzer%2C+A">Andrea Pilzer</a>, 
<a href="/search/cs?searchtype=author&query=Negri%2C+M">Matteo Negri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17761" title="Abstract">arXiv:2303.17761</a> (replaced) [<a href="/pdf/2303.17761" title="Download PDF">pdf</a>, <a href="/ps/2303.17761" title="Download PostScript">ps</a>, <a href="/format/2303.17761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Flatness by Pure Prolongation: Necessary and Sufficient  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=L%C3%A9vine%2C+J">Jean L&#xe9;vine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01622" title="Abstract">arXiv:2304.01622</a> (replaced) [<a href="/pdf/2304.01622" title="Download PDF">pdf</a>, <a href="/format/2304.01622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An interpretability framework for Similar case matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Nankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiajun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">Aimin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01752" title="Abstract">arXiv:2304.01752</a> (replaced) [<a href="/pdf/2304.01752" title="Download PDF">pdf</a>, <a href="/format/2304.01752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black Box Few-Shot Adaptation for Vision-Language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouali%2C+Y">Yassine Ouali</a>, 
<a href="/search/cs?searchtype=author&query=Bulat%2C+A">Adrian Bulat</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+B">Brais Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01973" title="Abstract">arXiv:2304.01973</a> (replaced) [<a href="/pdf/2304.01973" title="Download PDF">pdf</a>, <a href="/format/2304.01973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ERM++: An Improved Baseline for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teterwak%2C+P">Piotr Teterwak</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+K">Kuniaki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Tsiligkaridis%2C+T">Theodoros Tsiligkaridis</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An improved baseline for Domain Generalization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03496" title="Abstract">arXiv:2304.03496</a> (replaced) [<a href="/pdf/2304.03496" title="Download PDF">pdf</a>, <a href="/format/2304.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecture-Preserving Provable Repair of Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhe Tao</a>, 
<a href="/search/cs?searchtype=author&query=Nawas%2C+S">Stephanie Nawas</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J">Jacqueline Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A+V">Aditya V. Thakur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper at PLDI 2023. Tool is available at <a href="https://github.com/95616ARG/APRNN/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04137" title="Abstract">arXiv:2304.04137</a> (replaced) [<a href="/pdf/2304.04137" title="Download PDF">pdf</a>, <a href="/format/2304.04137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RD-DPP: Rate-Distortion Theory Meets Determinantal Point Process to  Diversify Learning Data Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+R">Rahul Amin</a>, 
<a href="/search/cs?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06783" title="Abstract">arXiv:2304.06783</a> (replaced) [<a href="/pdf/2304.06783" title="Download PDF">pdf</a>, <a href="/format/2304.06783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributionally Robust Approach to Regret Optimal Control using the  Wasserstein Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taha%2C+F+A">Feras Al Taha</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+S">Shuhao Yan</a>, 
<a href="/search/math?searchtype=author&query=Bitar%2C+E">Eilyan Bitar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, to appear in the proceedings of the 2023 IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06906" title="Abstract">arXiv:2304.06906</a> (replaced) [<a href="/pdf/2304.06906" title="Download PDF">pdf</a>, <a href="/format/2304.06906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu-Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu-Xiao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jian-Yu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng-Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yukichiii.github.io/project/swin3D/swin3D.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08503" title="Abstract">arXiv:2304.08503</a> (replaced) [<a href="/pdf/2304.08503" title="Download PDF">pdf</a>, <a href="/format/2304.08503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scalable Test Problem Generator for Sequential Transfer Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiaoming Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cuie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Liang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08862" title="Abstract">arXiv:2304.08862</a> (replaced) [<a href="/pdf/2304.08862" title="Download PDF">pdf</a>, <a href="/format/2304.08862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Nearest Neighbour Phrase Mining for Contextual Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bleeker%2C+M">Maurits Bleeker</a>, 
<a href="/search/cs?searchtype=author&query=Swietojanski%2C+P">Pawel Swietojanski</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+S">Stefan Braun</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xiaodan Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Interspeech 2023. 5 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09114" title="Abstract">arXiv:2304.09114</a> (replaced) [<a href="/pdf/2304.09114" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Standard Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coiera%2C+E">Enrico Coiera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: information standard, interoperability, machine learning, technology evaluation 25 Pages Main text word Count: 5108 Abstract word count: 206 Tables: 1 Figures: 7 Boxes: 1. JAMIA Post-print version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13017" title="Abstract">arXiv:2304.13017</a> (replaced) [<a href="/pdf/2304.13017" title="Download PDF">pdf</a>, <a href="/format/2304.13017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DuETT: Dual Event Time Transformer for Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labach%2C+A">Alex Labach</a>, 
<a href="/search/cs?searchtype=author&query=Pokhrel%2C+A">Aslesha Pokhrel</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X+S">Xiao Shi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zuberi%2C+S">Saba Zuberi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S+E">Seung Eun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Volkovs%2C+M">Maksims Volkovs</a>, 
<a href="/search/cs?searchtype=author&query=Poutanen%2C+T">Tomi Poutanen</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+R+G">Rahul G. Krishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MLHC 2023, camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14012" title="Abstract">arXiv:2304.14012</a> (replaced) [<a href="/pdf/2304.14012" title="Download PDF">pdf</a>, <a href="/format/2304.14012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Visual Servoing Based on Discrete Orthogonal Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00086" title="Abstract">arXiv:2305.00086</a> (replaced) [<a href="/pdf/2305.00086" title="Download PDF">pdf</a>, <a href="/format/2305.00086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integrated System Dynamics and Discrete Event Supply Chain Simulation  Framework for Supply Chain Resilience with Non-Stationary Pandemic Demand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camur%2C+M+C">Mustafa Can Camur</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+C">Chin-Yuan Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Thanos%2C+A+E">Aristotelis E. Thanos</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+C+C">Chelsea C. White</a>, 
<a href="/search/cs?searchtype=author&query=Yund%2C+W">Walter Yund</a>, 
<a href="/search/cs?searchtype=author&query=Iakovou%2C+E">Eleftherios Iakovou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00137" title="Abstract">arXiv:2305.00137</a> (replaced) [<a href="/pdf/2305.00137" title="Download PDF">pdf</a>, <a href="/ps/2305.00137" title="Download PostScript">ps</a>, <a href="/format/2305.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially-Coupled QDLPC Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+S">Siyi Yang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Calderbank%2C+R">Robert Calderbank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01397" title="Abstract">arXiv:2305.01397</a> (replaced) [<a href="/pdf/2305.01397" title="Download PDF">pdf</a>, <a href="/format/2305.01397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are demographically invariant models and representations in medical  imaging fair?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petersen%2C+E">Eike Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Ferrante%2C+E">Enzo Ferrante</a>, 
<a href="/search/cs?searchtype=author&query=Ganz%2C+M">Melanie Ganz</a>, 
<a href="/search/cs?searchtype=author&query=Feragen%2C+A">Aasa Feragen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02801" title="Abstract">arXiv:2305.02801</a> (replaced) [<a href="/pdf/2305.02801" title="Download PDF">pdf</a>, <a href="/ps/2305.02801" title="Download PostScript">ps</a>, <a href="/format/2305.02801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A numerically efficient output-only system-identification framework for  stochastically forced self-sustained oscillators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+M">Minwoo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+K+T">Kyu Tae Kim</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jongho Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03453" title="Abstract">arXiv:2305.03453</a> (replaced) [<a href="/pdf/2305.03453" title="Download PDF">pdf</a>, <a href="/format/2305.03453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large  Language Model Signals for Science Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabang He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04043" title="Abstract">arXiv:2305.04043</a> (replaced) [<a href="/pdf/2305.04043" title="Download PDF">pdf</a>, <a href="/format/2305.04043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echoes: Unsupervised Debiasing via Pseudo-bias Labeling in an Echo  Chamber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yahan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04170" title="Abstract">arXiv:2305.04170</a> (replaced) [<a href="/pdf/2305.04170" title="Download PDF">pdf</a>, <a href="/format/2305.04170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLOCS: Object Detection based on Dense Channel Compression for Feature  Spatial Solidification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haojie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xue Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Suihan Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05890" title="Abstract">arXiv:2305.05890</a> (replaced) [<a href="/pdf/2305.05890" title="Download PDF">pdf</a>, <a href="/format/2305.05890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUTS+: High-dimensional Causal Discovery from Irregular Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lianglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tingxiong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongren Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+J">Jinli Suo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kunlun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09634" title="Abstract">arXiv:2305.09634</a> (replaced) [<a href="/pdf/2305.09634" title="Download PDF">pdf</a>, <a href="/format/2305.09634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-Objective Lexicographic Optimization in Markov Decision Processes  with Related Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busatto-Gaston%2C+D">Damien Busatto-Gaston</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Debraj Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirban Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sayan Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+A">Guillermo A. P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+J">Jean-Fran&#xe7;ois Raskin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09781" title="Abstract">arXiv:2305.09781</a> (replaced) [<a href="/pdf/2305.09781" title="Download PDF">pdf</a>, <a href="/format/2305.09781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecInfer: Accelerating Generative Large Language Model Serving with  Speculative Inference and Token Tree Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Oliaro%2C+G">Gabriele Oliaro</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+R+Y+Y">Rae Ying Yee Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Alan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lijie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chunan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Arfeen%2C+D">Daiyaan Arfeen</a>, 
<a href="/search/cs?searchtype=author&query=Abhyankar%2C+R">Reyna Abhyankar</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10732" title="Abstract">arXiv:2305.10732</a> (replaced) [<a href="/pdf/2305.10732" title="Download PDF">pdf</a>, <a href="/ps/2305.10732" title="Download PostScript">ps</a>, <a href="/format/2305.10732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlindHarmony: &quot;Blind&quot; Harmonization for MR Images via Flow model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jeong%2C+H">Hwihun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Byun%2C+H">Heejoon Byun</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+D+U">Dong Un Kang</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jongho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 accepted. 9 pages and 5 Figures for manuscipt, supplementary included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11011" title="Abstract">arXiv:2305.11011</a> (replaced) [<a href="/pdf/2305.11011" title="Download PDF">pdf</a>, <a href="/format/2305.11011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case VCG Redistribution Mechanism Design Based on the Lottery  Ticket Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11095" title="Abstract">arXiv:2305.11095</a> (replaced) [<a href="/pdf/2305.11095" title="Download PDF">pdf</a>, <a href="/format/2305.11095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot  Task Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+P">Puyuan Peng</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/eess?searchtype=author&query=Harwath%2C+D">David Harwath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12550" title="Abstract">arXiv:2305.12550</a> (replaced) [<a href="/pdf/2305.12550" title="Download PDF">pdf</a>, <a href="/format/2305.12550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing for Intermittently-Powered Sensing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaosheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13483" title="Abstract">arXiv:2305.13483</a> (replaced) [<a href="/pdf/2305.13483" title="Download PDF">pdf</a>, <a href="/format/2305.13483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Protocol Format as State Machine via Controlled Static Loop  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qingkai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13855" title="Abstract">arXiv:2305.13855</a> (replaced) [<a href="/pdf/2305.13855" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Step Deep Learning Method for 3DCT-2DUS Kidney Registration During  Breathing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yanling%2C+C">Chi Yanling</a>, 
<a href="/search/eess?searchtype=author&query=Yuyu%2C+X">Xu Yuyu</a>, 
<a href="/search/eess?searchtype=author&query=Huiying%2C+L">Liu Huiying</a>, 
<a href="/search/eess?searchtype=author&query=Xiaoxiang%2C+W">Wu Xiaoxiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhiqiang%2C+L">Liu Zhiqiang</a>, 
<a href="/search/eess?searchtype=author&query=Jiawei%2C+M">Mao Jiawei</a>, 
<a href="/search/eess?searchtype=author&query=Guibin%2C+X">Xu Guibin</a>, 
<a href="/search/eess?searchtype=author&query=Weimin%2C+H">Huang Weimin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13873" title="Abstract">arXiv:2305.13873</a> (replaced) [<a href="/pdf/2305.13873" title="Download PDF">pdf</a>, <a href="/format/2305.13873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes  From Text-To-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yiting Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xinyue Shen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinlei He</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zannettou%2C+S">Savvas Zannettou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the ACM Conference on Computer and Communications Security, November 26, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15121" title="Abstract">arXiv:2305.15121</a> (replaced) [<a href="/pdf/2305.15121" title="Download PDF">pdf</a>, <a href="/format/2305.15121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Individual Input for Deep Anomaly Detection on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="/search/cs?searchtype=author&query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="/search/cs?searchtype=author&query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+B">Bich-Li&#xea;n Doan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18437" title="Abstract">arXiv:2305.18437</a> (replaced) [<a href="/pdf/2305.18437" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Machine Learning for Categorical and Mixed Data with  Lossless Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kovalerchuk%2C+B">Boris Kovalerchuk</a>, 
<a href="/search/cs?searchtype=author&query=McCoy%2C+E">Elijah McCoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 32 figures, 29 tables. arXiv admin note: substantial text overlap with <a href="/abs/2206.06476">arXiv:2206.06476</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18477" title="Abstract">arXiv:2305.18477</a> (replaced) [<a href="/pdf/2305.18477" title="Download PDF">pdf</a>, <a href="/ps/2305.18477" title="Download PostScript">ps</a>, <a href="/format/2305.18477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Meta: Leveraging Game Design Parameters for Patch-Agnostic  Esport Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chitayat%2C+A+P">Alan Pedrassoli Chitayat</a>, 
<a href="/search/cs?searchtype=author&query=Block%2C+F">Florian Block</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+J">James Walker</a>, 
<a href="/search/cs?searchtype=author&query=Drachen%2C+A">Anders Drachen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00461" title="Abstract">arXiv:2306.00461</a> (replaced) [<a href="/pdf/2306.00461" title="Download PDF">pdf</a>, <a href="/format/2306.00461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating Disjoint Partial Models without Blocking Clauses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spallitta%2C+G">Giuseppe Spallitta</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+R">Roberto Sebastiani</a>, 
<a href="/search/cs?searchtype=author&query=Biere%2C+A">Armin Biere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01102" title="Abstract">arXiv:2306.01102</a> (replaced) [<a href="/pdf/2306.01102" title="Download PDF">pdf</a>, <a href="/format/2306.01102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMatic: Neural Architecture Search via Large Language Models and  Quality-Diversity Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasir%2C+M+U">Muhammad U. Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Earle%2C+S">Sam Earle</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Steven James</a>, 
<a href="/search/cs?searchtype=author&query=Cleghorn%2C+C">Christopher Cleghorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01631" title="Abstract">arXiv:2306.01631</a> (replaced) [<a href="/pdf/2306.01631" title="Download PDF">pdf</a>, <a href="/format/2306.01631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-level Contrastive Learning for Knowledge-Enhanced Molecule  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Pengcheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Cao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianfan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02179" title="Abstract">arXiv:2306.02179</a> (replaced) [<a href="/pdf/2306.02179" title="Download PDF">pdf</a>, <a href="/format/2306.02179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Buying Time: Latency Racing vs. Bidding in Transaction Ordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamageishvili%2C+A">Akaki Mamageishvili</a>, 
<a href="/search/cs?searchtype=author&query=Kelkar%2C+M">Mahimna Kelkar</a>, 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+J+C">Jan Christoph Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Felten%2C+E+W">Edward W. Felten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02502" title="Abstract">arXiv:2306.02502</a> (replaced) [<a href="/pdf/2306.02502" title="Download PDF">pdf</a>, <a href="/format/2306.02502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the Role of Power Grids in Internet Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03589" title="Abstract">arXiv:2306.03589</a> (replaced) [<a href="/pdf/2306.03589" title="Download PDF">pdf</a>, <a href="/format/2306.03589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does over-squashing affect the power of GNNs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Giovanni%2C+F">Francesco Di Giovanni</a>, 
<a href="/search/cs?searchtype=author&query=Rusch%2C+T+K">T. Konstantin Rusch</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M+M">Michael M. Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Deac%2C+A">Andreea Deac</a>, 
<a href="/search/cs?searchtype=author&query=Lackenby%2C+M">Marc Lackenby</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veli&#x10d;kovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04306" title="Abstract">arXiv:2306.04306</a> (replaced) [<a href="/pdf/2306.04306" title="Download PDF">pdf</a>, <a href="/format/2306.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Allophant: Cross-lingual Phoneme Recognition with Articulatory  Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glocker%2C+K">Kevin Glocker</a> (1), 
<a href="/search/cs?searchtype=author&query=Herygers%2C+A">Aaricia Herygers</a> (1), 
<a href="/search/cs?searchtype=author&query=Georges%2C+M">Munir Georges</a> (1 and 2) ((1) AImotion Bavaria Technische Hochschule Ingolstadt, (2) Intel Labs Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 2 tables, accepted to INTERSPEECH 2023; published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. INTERSPEECH 2023, 2258-2262
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04928" title="Abstract">arXiv:2306.04928</a> (replaced) [<a href="/pdf/2306.04928" title="Download PDF">pdf</a>, <a href="/format/2306.04928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater Intention Recognition using Head Motion and Throat Vibration  for Supernumerary Robotic Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuqin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Wanghongjie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Asada%2C+H">Harry Asada</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaoyang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, 3 tables, accepted to IEEE CASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05989" title="Abstract">arXiv:2306.05989</a> (replaced) [<a href="/pdf/2306.05989" title="Download PDF">pdf</a>, <a href="/format/2306.05989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QBSD: Quartile-Based Seasonality Decomposition for Cost-Effective Time  Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isaac%2C+E+R">Ebenezer RHP Isaac</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+B">Bulbul Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07077" title="Abstract">arXiv:2306.07077</a> (replaced) [<a href="/e-print/2306.07077" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Dynamical Implicit Diffusion Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M+R">Mohammad R. Rezaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I request a withdrawal because there are no experiments with real-world datasets and also the method section requires major changes to look mathematically sounds
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07384" title="Abstract">arXiv:2306.07384</a> (replaced) [<a href="/pdf/2306.07384" title="Download PDF">pdf</a>, <a href="/format/2306.07384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Quantifier Comprehension in Large Language Models: Another  Example of Inverse Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshat Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10698" title="Abstract">arXiv:2306.10698</a> (replaced) [<a href="/pdf/2306.10698" title="Download PDF">pdf</a>, <a href="/format/2306.10698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning with Multitask Episodic Memory Based on  Task-Conditioned Hypernetwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liuyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10813" title="Abstract">arXiv:2306.10813</a> (replaced) [<a href="/pdf/2306.10813" title="Download PDF">pdf</a>, <a href="/format/2306.10813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12343" title="Abstract">arXiv:2306.12343</a> (replaced) [<a href="/pdf/2306.12343" title="Download PDF">pdf</a>, <a href="/format/2306.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum R&#xe9;nyi and $f$-divergences from integral representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hirche%2C+C">Christoph Hirche</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tomamichel%2C+M">Marco Tomamichel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages. v2: improved results on reverse Pinsker inequalities + minor clarifications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14337" title="Abstract">arXiv:2306.14337</a> (replaced) [<a href="/pdf/2306.14337" title="Download PDF">pdf</a>, <a href="/format/2306.14337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPU-Resident Sparse Direct Linear Solvers for Alternating Current  Optimal Power Flow Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Awirydowicz%2C+K">Kasia &#x15a;wirydowicz</a>, 
<a href="/search/cs?searchtype=author&query=Koukpaizan%2C+N">Nicholson Koukpaizan</a>, 
<a href="/search/cs?searchtype=author&query=Ribizel%2C+T">Tobias Ribizel</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6bel%2C+F">Fritz G&#xf6;bel</a>, 
<a href="/search/cs?searchtype=author&query=Abhyankar%2C+S">Shrirang Abhyankar</a>, 
<a href="/search/cs?searchtype=author&query=Anzt%2C+H">Hartwig Anzt</a>, 
<a href="/search/cs?searchtype=author&query=Pele%C5%A1%2C+S">Slaven Pele&#x161;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15891" title="Abstract">arXiv:2306.15891</a> (replaced) [<a href="/pdf/2306.15891" title="Download PDF">pdf</a>, <a href="/format/2306.15891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing the Diffusive Behavior of the Multiscale Linear Transport  Equations by Asymptotic-Preserving Convolutional DeepONets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Keke Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiong-bin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16296" title="Abstract">arXiv:2306.16296</a> (replaced) [<a href="/pdf/2306.16296" title="Download PDF">pdf</a>, <a href="/format/2306.16296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot  Analogical Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jarnac%2C+L">Lucas Jarnac</a>, 
<a href="/search/cs?searchtype=author&query=Couceiro%2C+M">Miguel Couceiro</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17436" title="Abstract">arXiv:2306.17436</a> (replaced) [<a href="/pdf/2306.17436" title="Download PDF">pdf</a>, <a href="/format/2306.17436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIO-GVM: an Accurate, Tightly-Coupled Lidar-Inertial Odometry with  Gaussian Voxel Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xingyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shenghai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17558" title="Abstract">arXiv:2306.17558</a> (replaced) [<a href="/pdf/2306.17558" title="Download PDF">pdf</a>, <a href="/format/2306.17558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the extraction of robust sign embeddings for low resource sign  language recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Coster%2C+M">Mathieu De Coster</a>, 
<a href="/search/cs?searchtype=author&query=Rushe%2C+E">Ellen Rushe</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+R">Ruth Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Ventresque%2C+A">Anthony Ventresque</a>, 
<a href="/search/cs?searchtype=author&query=Dambre%2C+J">Joni Dambre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04246" title="Abstract">arXiv:2307.04246</a> (replaced) [<a href="/pdf/2307.04246" title="Download PDF">pdf</a>, <a href="/format/2307.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Decomposition of Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vavilala%2C+V">Vaibhav Vavilala</a>, 
<a href="/search/cs?searchtype=author&query=Forsyth%2C+D">David Forsyth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07399" title="Abstract">arXiv:2307.07399</a> (replaced) [<a href="/pdf/2307.07399" title="Download PDF">pdf</a>, <a href="/format/2307.07399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle-to-grid plug-in forecasting for participation in ancillary  services markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Graham%2C+J">Jemima Graham</a>, 
<a href="/search/eess?searchtype=author&query=Teng%2C+F">Fei Teng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Belgrade PowerTech
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07889" title="Abstract">arXiv:2307.07889</a> (replaced) [<a href="/pdf/2307.07889" title="Download PDF">pdf</a>, <a href="/format/2307.07889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise  Comparisons using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Manakul%2C+P">Potsawee Manakul</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J. F. Gales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08693" title="Abstract">arXiv:2307.08693</a> (replaced) [<a href="/pdf/2307.08693" title="Download PDF">pdf</a>, <a href="/format/2307.08693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEMI-DiffusionInst: A Diffusion Model Based Approach for Semiconductor  Defect Classification and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Ridder%2C+V">Vic De Ridder</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+B">Bappaditya Dey</a>, 
<a href="/search/cs?searchtype=author&query=Halder%2C+S">Sandip Halder</a>, 
<a href="/search/cs?searchtype=author&query=Van+Waeyenberge%2C+B">Bartel Van Waeyenberge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, To be published by IEEE in the proceedings of the 2023 ELMAR conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09879" title="Abstract">arXiv:2307.09879</a> (replaced) [<a href="/pdf/2307.09879" title="Download PDF">pdf</a>, <a href="/format/2307.09879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAMG($&#x3b8;$): An Auto-tuned AMG Method Based on Deep Learning for  Strong Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zou%2C+H">Haifeng Zou</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiaowen Xu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Chen-Song Zhang</a>, 
<a href="/search/math?searchtype=author&query=Mo%2C+Z">Zeyao Mo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10162" title="Abstract">arXiv:2307.10162</a> (replaced) [<a href="/pdf/2307.10162" title="Download PDF">pdf</a>, <a href="/format/2307.10162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTVis: Research Trend Visualization Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xingyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhixian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE VIS 2023 (Poster). 2 pages, 1 figure. For our demo page, visit <a href="https://www.rtvis.design/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11252" title="Abstract">arXiv:2307.11252</a> (replaced) [<a href="/pdf/2307.11252" title="Download PDF">pdf</a>, <a href="/format/2307.11252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Delays in Multi-Agent Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kottinger%2C+J">Justin Kottinger</a>, 
<a href="/search/cs?searchtype=author&query=Almagor%2C+S">Shaull Almagor</a>, 
<a href="/search/cs?searchtype=author&query=Salzman%2C+O">Oren Salzman</a>, 
<a href="/search/cs?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11787" title="Abstract">arXiv:2307.11787</a> (replaced) [<a href="/pdf/2307.11787" title="Download PDF">pdf</a>, <a href="/ps/2307.11787" title="Download PostScript">ps</a>, <a href="/format/2307.11787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Cognitive Judgements Differ From Human
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamprinidis%2C+S">Sotiris Lamprinidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure. License changed to CC BY-NC-SA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12027" title="Abstract">arXiv:2307.12027</a> (replaced) [<a href="/pdf/2307.12027" title="Download PDF">pdf</a>, <a href="/format/2307.12027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Spectral Discriminators for Perceptual Quality  Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yunan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shunxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Code and Models are publicly available at <a href="https://github.com/Luciennnnnnn/DualFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12267" title="Abstract">arXiv:2307.12267</a> (replaced) [<a href="/pdf/2307.12267" title="Download PDF">pdf</a>, <a href="/format/2307.12267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid  Essay in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zijie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lele Sha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanliang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages including references, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12502" title="Abstract">arXiv:2307.12502</a> (replaced) [<a href="/pdf/2307.12502" title="Download PDF">pdf</a>, <a href="/format/2307.12502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Contrasting Feature Perturbation for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenjian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12761" title="Abstract">arXiv:2307.12761</a> (replaced) [<a href="/pdf/2307.12761" title="Download PDF">pdf</a>, <a href="/format/2307.12761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR Meta Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boettcher%2C+W">Wolfgang Boettcher</a>, 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Unal%2C+O">Ozan Unal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023, v2 has updated author list and fixed a figure caption
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12833" title="Abstract">arXiv:2307.12833</a> (replaced) [<a href="/pdf/2307.12833" title="Download PDF">pdf</a>, <a href="/format/2307.12833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring social networks from observed groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neal%2C+Z+P">Zachary P. Neal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13565" title="Abstract">arXiv:2307.13565</a> (replaced) [<a href="/pdf/2307.13565" title="Download PDF">pdf</a>, <a href="/format/2307.13565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-Focused Learning: Foundations, State of the Art, Benchmark and  Future Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandi%2C+J">Jayanta Mandi</a>, 
<a href="/search/cs?searchtype=author&query=Kotary%2C+J">James Kotary</a>, 
<a href="/search/cs?searchtype=author&query=Berden%2C+S">Senne Berden</a>, 
<a href="/search/cs?searchtype=author&query=Mulamba%2C+M">Maxime Mulamba</a>, 
<a href="/search/cs?searchtype=author&query=Bucarey%2C+V">Victor Bucarey</a>, 
<a href="/search/cs?searchtype=author&query=Guns%2C+T">Tias Guns</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Experimental Survey and Benchmarking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14051" title="Abstract">arXiv:2307.14051</a> (replaced) [<a href="/pdf/2307.14051" title="Download PDF">pdf</a>, <a href="/format/2307.14051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Semantic Subspace Traverser: Empowering 3D Generative Model with  Shape Editing Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Pei Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qijun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023. Code: <a href="https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14385" title="Abstract">arXiv:2307.14385</a> (replaced) [<a href="/pdf/2307.14385" title="Download PDF">pdf</a>, <a href="/format/2307.14385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mental-LLM: Leveraging Large Language Models for Mental Health  Prediction via Online Text Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bingshen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuanzhe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+S">Saadia Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hendler%2C+J">James Hendler</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A+K">Anind K. Dey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15029" title="Abstract">arXiv:2307.15029</a> (replaced) [<a href="/pdf/2307.15029" title="Download PDF">pdf</a>, <a href="/format/2307.15029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Segmentation Network for Scene Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guiqin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15128" title="Abstract">arXiv:2307.15128</a> (replaced) [<a href="/pdf/2307.15128" title="Download PDF">pdf</a>, <a href="/format/2307.15128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Remote Sensing Change Detection of Unregistered Bi-temporal  Images for Natural Disasters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guiqin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+L">Lianlei Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15780" title="Abstract">arXiv:2307.15780</a> (replaced) [<a href="/pdf/2307.15780" title="Download PDF">pdf</a>, <a href="/format/2307.15780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Rec: Personalized Recommendation via Prompting Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hanjia Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Song Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Hanqing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Si Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ren Chen</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+C">Chris Leung</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiajie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yinglong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16082" title="Abstract">arXiv:2307.16082</a> (replaced) [<a href="/pdf/2307.16082" title="Download PDF">pdf</a>, <a href="/format/2307.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnrichEvent: Enriching Social Data with Contextual Information for  Emerging Event Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfahani%2C+M+S">Mohammadali Sefidi Esfahani</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+M">Mohammad Akbari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16120" title="Abstract">arXiv:2307.16120</a> (replaced) [<a href="/pdf/2307.16120" title="Download PDF">pdf</a>, <a href="/format/2307.16120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unrolling Networks with Recurrent Momentum Acceleration for  Nonlinear Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qingping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiayu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Junqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinglai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16436" title="Abstract">arXiv:2307.16436</a> (replaced) [<a href="/pdf/2307.16436" title="Download PDF">pdf</a>, <a href="/format/2307.16436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-regulated biological transportation structures with general entropy  dissipations, part I: the 1D case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Astuto%2C+C">Clarissa Astuto</a>, 
<a href="/search/math?searchtype=author&query=Haskovec%2C+J">Jan Haskovec</a>, 
<a href="/search/math?searchtype=author&query=Markowich%2C+P">Peter Markowich</a>, 
<a href="/search/math?searchtype=author&query=Portaro%2C+S">Simone Portaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16586" title="Abstract">arXiv:2307.16586</a> (replaced) [<a href="/pdf/2307.16586" title="Download PDF">pdf</a>, <a href="/format/2307.16586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment  Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16706" title="Abstract">arXiv:2307.16706</a> (replaced) [<a href="/pdf/2307.16706" title="Download PDF">pdf</a>, <a href="/ps/2307.16706" title="Download PostScript">ps</a>, <a href="/format/2307.16706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An O.D.E. Framework of Distributed TD-Learning for Networked Multi-Agent  Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Donghwan Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+D+W">Do Wan Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16751" title="Abstract">arXiv:2307.16751</a> (replaced) [<a href="/pdf/2307.16751" title="Download PDF">pdf</a>, <a href="/format/2307.16751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Performance Fine Defect Detection in Artificial Leather Using Dual  Feature Pool Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xue Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Suihan Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00864" title="Abstract">arXiv:2308.00864</a> (replaced) [<a href="/pdf/2308.00864" title="Download PDF">pdf</a>, <a href="/format/2308.00864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeRP: Personalized Residual Policies For Congestion Mitigation Through  Co-operative Advisory Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Aamir Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+N">Neeloy Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jung-Hoon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cathy Wu</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ITSC 2023. Additional material and code is available at the project webpage: <a href="https://sites.google.com/illinois.edu/perp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01790" title="Abstract">arXiv:2308.01790</a> (replaced) [<a href="/pdf/2308.01790" title="Download PDF">pdf</a>, <a href="/ps/2308.01790" title="Download PostScript">ps</a>, <a href="/format/2308.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact structures for persistence modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blanchette%2C+B">Benjamin Blanchette</a>, 
<a href="/search/math?searchtype=author&query=Br%C3%BCstle%2C+T">Thomas Br&#xfc;stle</a>, 
<a href="/search/math?searchtype=author&query=Hanson%2C+E+J">Eric J. Hanson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: corrected typos and minor erros, 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Representation Theory (math.RT)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01990" title="Abstract">arXiv:2308.01990</a> (replaced) [<a href="/pdf/2308.01990" title="Download PDF">pdf</a>, <a href="/format/2308.01990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Prompt Injections to SQL Injection Attacks: How Protected is Your  LLM-Integrated Web Application?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedro%2C+R">Rodrigo Pedro</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D">Daniel Castro</a>, 
<a href="/search/cs?searchtype=author&query=Carreira%2C+P">Paulo Carreira</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+N">Nuno Santos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 3 tables, 5 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02510" title="Abstract">arXiv:2308.02510</a> (replaced) [<a href="/pdf/2308.02510" title="Download PDF">pdf</a>, <a href="/format/2308.02510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing through the Brain: Image Reconstruction of Visual Perception from  Human Brain Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lan%2C+Y">Yu-Ting Lan</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+K">Kan Ren</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yansen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+W">Wei-Long Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+B">Bao-Liang Lu</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+L">Lili Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preprint version of an ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02716" title="Abstract">arXiv:2308.02716</a> (replaced) [<a href="/pdf/2308.02716" title="Download PDF">pdf</a>, <a href="/format/2308.02716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EndoDepthL: Lightweight Endoscopic Monocular Depth Estimation with  CNN-Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02835" title="Abstract">arXiv:2308.02835</a> (replaced) [<a href="/pdf/2308.02835" title="Download PDF">pdf</a>, <a href="/format/2308.02835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Based Task Generation through Causal Sequence of Physical  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamage%2C+C">Chathura Gamage</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+V">Vimukthini Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Stephenson%2C+M">Matthew Stephenson</a>, 
<a href="/search/cs?searchtype=author&query=Renz%2C+J">Jochen Renz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE-23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03223" title="Abstract">arXiv:2308.03223</a> (replaced) [<a href="/pdf/2308.03223" title="Download PDF">pdf</a>, <a href="/format/2308.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete weak duality of hybrid high-order methods for convex  minimization problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tran%2C+N+T">Ngoc Tien Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03266" title="Abstract">arXiv:2308.03266</a> (replaced) [<a href="/pdf/2308.03266" title="Download PDF">pdf</a>, <a href="/format/2308.03266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and  Effective Hotword Customization Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yexin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zerui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04673" title="Abstract">arXiv:2308.04673</a> (replaced) [<a href="/pdf/2308.04673" title="Download PDF">pdf</a>, <a href="/format/2308.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-Auth: An Authentication Framework by Fragile Watermarking for  Pre-trained Encoders in Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Changchun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Liming Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Run Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenhao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI2024. 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05342" title="Abstract">arXiv:2308.05342</a> (replaced) [<a href="/pdf/2308.05342" title="Download PDF">pdf</a>, <a href="/format/2308.05342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metacognitive Prompting Improves Understanding in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05379" title="Abstract">arXiv:2308.05379</a> (replaced) [<a href="/pdf/2308.05379" title="Download PDF">pdf</a>, <a href="/format/2308.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Semantics: Learning a Behavior Augmented Relevance Model with  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Partial content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06422" title="Abstract">arXiv:2308.06422</a> (replaced) [<a href="/pdf/2308.06422" title="Download PDF">pdf</a>, <a href="/format/2308.06422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of  Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizi%2C+S">Seyedarmin Azizi</a>, 
<a href="/search/cs?searchtype=author&query=Nazemi%2C+M">Mahdi Nazemi</a>, 
<a href="/search/cs?searchtype=author&query=Fayyazi%2C+A">Arash Fayyazi</a>, 
<a href="/search/cs?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07009" title="Abstract">arXiv:2308.07009</a> (replaced) [<a href="/pdf/2308.07009" title="Download PDF">pdf</a>, <a href="/format/2308.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal  and Robust Vehicle Evasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suryanto%2C+N">Naufal Suryanto</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Larasati%2C+H+T">Harashta Tatimma Larasati</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyoeun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thi-Thu-Huong Le</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yoonyoung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hunmin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Se-Yoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Howon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICCV 2023. Main Paper with Supplementary Material. Project Page: <a href="https://islab-ai.github.io/active-iccv2023/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07056" title="Abstract">arXiv:2308.07056</a> (replaced) [<a href="/pdf/2308.07056" title="Download PDF">pdf</a>, <a href="/format/2308.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxBlink: X-Large Speaker Verification Dataset on Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuke Lin</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoyi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to ICASSP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07118" title="Abstract">arXiv:2308.07118</a> (replaced) [<a href="/pdf/2308.07118" title="Download PDF">pdf</a>, <a href="/format/2308.07118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural radiance fields in the industrial and robotics domain:  applications, research opportunities and use cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A0lapak%2C+E">Eugen &#x160;lapak</a>, 
<a href="/search/cs?searchtype=author&query=Pardo%2C+E">Enric Pardo</a>, 
<a href="/search/cs?searchtype=author&query=Dopiriak%2C+M">Mat&#xfa;&#x161; Dopiriak</a>, 
<a href="/search/cs?searchtype=author&query=Maksymyuk%2C+T">Taras Maksymyuk</a>, 
<a href="/search/cs?searchtype=author&query=Gazda%2C+J">Juraj Gazda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07163" title="Abstract">arXiv:2308.07163</a> (replaced) [<a href="/pdf/2308.07163" title="Download PDF">pdf</a>, <a href="/format/2308.07163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperSparse Neural Networks: Shifting Exploration to Exploitation  through Adaptive Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glandorf%2C+P">Patrick Glandorf</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+T">Timo Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Rosenhahn%2C+B">Bodo Rosenhahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV'23 Workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07250" title="Abstract">arXiv:2308.07250</a> (replaced) [<a href="/pdf/2308.07250" title="Download PDF">pdf</a>, <a href="/format/2308.07250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCE: An Augmented Combination of Bagging and Boosting in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fauvel%2C+K">Kevin Fauvel</a>, 
<a href="/search/cs?searchtype=author&query=Fromont%2C+%C3%89">&#xc9;lisa Fromont</a>, 
<a href="/search/cs?searchtype=author&query=Masson%2C+V">V&#xe9;ronique Masson</a>, 
<a href="/search/cs?searchtype=author&query=Faverdin%2C+P">Philippe Faverdin</a>, 
<a href="/search/cs?searchtype=author&query=Termier%2C+A">Alexandre Termier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07298" title="Abstract">arXiv:2308.07298</a> (replaced) [<a href="/pdf/2308.07298" title="Download PDF">pdf</a>, <a href="/format/2308.07298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Eye Tracking from Dense 3D Surface Reconstructions using  Single-Shot Deflectometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiazhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bingjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cossairt%2C+O">Oliver Cossairt</a>, 
<a href="/search/cs?searchtype=author&query=Willomitzer%2C+F">Florian Willomitzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07414" title="Abstract">arXiv:2308.07414</a> (replaced) [<a href="/pdf/2308.07414" title="Download PDF">pdf</a>, <a href="/format/2308.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Votemandering: Strategies and Fairness in Political Redistricting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+S">Sanyukta Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Ludden%2C+I+G">Ian G Ludden</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+S+H">Sheldon H Jacobson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07426" title="Abstract">arXiv:2308.07426</a> (replaced) [<a href="/pdf/2308.07426" title="Download PDF">pdf</a>, <a href="/format/2308.07426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehui Wang</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6pken%2C+W">Wolfram H&#xf6;pken</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07439" title="Abstract">arXiv:2308.07439</a> (replaced) [<a href="/pdf/2308.07439" title="Download PDF">pdf</a>, <a href="/format/2308.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction-Aware Personalized Vehicle Trajectory Prediction Using  Temporal Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelraouf%2C+A">Amr Abdelraouf</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rohit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kyungtae Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07578" title="Abstract">arXiv:2308.07578</a> (replaced) [<a href="/pdf/2308.07578" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding User Behavior in Volumetric Video Watching: Dataset,  Analysis and Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaiyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haowen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yili Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07687" title="Abstract">arXiv:2308.07687</a> (replaced) [<a href="/pdf/2308.07687" title="Download PDF">pdf</a>, <a href="/format/2308.07687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using  Pre-trained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023, with supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07711" title="Abstract">arXiv:2308.07711</a> (replaced) [<a href="/pdf/2308.07711" title="Download PDF">pdf</a>, <a href="/format/2308.07711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPM: Structured Pretraining and Matching Architectures for Relevance  Modeling in Meituan Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zan%2C+W">Wen Zan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yaopeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaotian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dayao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07873" title="Abstract">arXiv:2308.07873</a> (replaced) [<a href="/e-print/2308.07873" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Last-iterate Convergence of Policy Optimization in Zero-sum  Polymatrix Markov games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zailin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiansheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihua Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proof of Lemma 3.4 is wrong, \bar{L}_{h+1}^{t-k} should be replaced by \sqrt{\bar{L}_{h+1}^{t-k}}. In this case the proof of the main theorem should be substantially modified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07896" title="Abstract">arXiv:2308.07896</a> (replaced) [<a href="/pdf/2308.07896" title="Download PDF">pdf</a>, <a href="/format/2308.07896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by  Score-integrand Solver with Recursive Derivative Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+S">Shigui Li</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/stat?searchtype=author&query=Zeng%2C+D">Delu Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Computation (stat.CO)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item249">Cross-lists</a></li>
<li><a href="#item304">Replacements</a></li>
</ul>
<small>[ total of 481 entries:  <b>1-481</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2308">2308</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
