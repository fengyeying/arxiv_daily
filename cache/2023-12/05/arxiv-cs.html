<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  1 Dec 23  to  Mon  4 Dec 23, announced Tue,  5 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item584">Cross-lists</a></li>
<li><a href="#item663">Replacements</a></li>
</ul>
<small>[ total of 1070 entries:  <b>1-1070</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue,  5 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00789" title="Abstract">arXiv:2312.00789</a> [<a href="/pdf/2312.00789" title="Download PDF">pdf</a>, <a href="/ps/2312.00789" title="Download PostScript">ps</a>, <a href="/format/2312.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do androids dream of fictional references? A bibliographic dialogue with  ChatGPT3.5
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vergnas%2C+O+L">Olivier Las Vergnas</a> (AFA, CIREL)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Alliage : Culture - Science - Technique, 2023, 2023 (83)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This article focuses on bibliographic references generated by the ChatGPT3.5
tool. Using this tool based on the trained GPT generation model ChatGPT3.5,
developed by the company OpenAI, we explored six different themes and analyzed
a sample of references generated by the model, in French and English. The
results revealed high percentages of fictitious references in several fields,
underlining the importance of carefully checking these references before using
them in research work. An improvement in results was nevertheless noted between
May and July with regard to English references for themes on which ChatGPR3.5
has been particularly trained, but the situation remains unsatisfactory in
French, for example. It should also be pointed out that much of the text in
this article was generated by ChatGPT in a joint effort with the human author.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00793" title="Abstract">arXiv:2312.00793</a> [<a href="/pdf/2312.00793" title="Download PDF">pdf</a>, <a href="/format/2312.00793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variants of Tagged Sentential Decision Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+D">Deyuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Q">Quanlong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Liangda Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhaorong Lai</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yong Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">A recently proposed canonical form of Boolean functions, namely tagged
sentential decision diagrams (TSDDs), exploits both the standard and
zero-suppressed trimming rules. The standard ones minimize the size of
sentential decision diagrams (SDDs) while the zero-suppressed trimming rules
have the same objective as the standard ones but for zero-suppressed sentential
decision diagrams (ZSDDs). The original TSDDs, which we call zero-suppressed
TSDDs (ZTSDDs), firstly fully utilize the zero-suppressed trimming rules, and
then the standard ones. In this paper, we present a variant of TSDDs which we
call standard TSDDs (STSDDs) by reversing the order of trimming rules. We then
prove the canonicity of STSDDs and present the algorithms for binary operations
on TSDDs. In addition, we offer two kinds of implementations of STSDDs and
ZTSDDs and acquire three variations of the original TSDDs. Experimental
evaluations demonstrate that the four versions of TSDDs have the size advantage
over SDDs and ZSDDs.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00794" title="Abstract">arXiv:2312.00794</a> [<a href="/pdf/2312.00794" title="Download PDF">pdf</a>, <a href="/format/2312.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informative Priors Improve the Reliability of Multimodal Clinical Data  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopez%2C+L+J+L">L. Julian Lechuga Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=Shamout%2C+F+E">Farah E. Shamout</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ML4H 2023 Findings Track Collection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Machine learning-aided clinical decision support has the potential to
significantly improve patient care. However, existing efforts in this domain
for principled quantification of uncertainty have largely been limited to
applications of ad-hoc solutions that do not consistently improve reliability.
In this work, we consider stochastic neural networks and design a tailor-made
multimodal data-driven (M2D2) prior distribution over network parameters. We
use simple and scalable Gaussian mean-field variational inference to train a
Bayesian neural network using the M2D2 prior. We train and evaluate the
proposed approach using clinical time-series data in MIMIC-IV and corresponding
chest X-ray images in MIMIC-CXR for the classification of acute care
conditions. Our empirical results show that the proposed method produces a more
reliable predictive model compared to deterministic and Bayesian neural network
baselines.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00795" title="Abstract">arXiv:2312.00795</a> [<a href="/pdf/2312.00795" title="Download PDF">pdf</a>, <a href="/format/2312.00795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talent-Interview: Web-Client Cheating Detection for Online Exams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ege%2C+M">Mert Ege</a>, 
<a href="/search/cs?searchtype=author&query=Ceyhan%2C+M">Mustafa Ceyhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper explains the workflow of Talent Interview project that is web-client cheating detection application
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Online exams are more attractive after the Covid-19 pandemic. Furthermore,
during recruitment, online exams are used. However, there are more cheating
possibilities for online exams. Assigning a proctor for each exam increases
cost. At this point, automatic proctor systems detect possible cheating status.
This article proposes an end-to-end system and submodules to get better results
for online proctoring. Object detection, face recognition, human voice
detection, and segmentation are used in our system. Furthermore, our proposed
model works on the PCs of users, meaning a client-based system. So, server cost
is eliminated. As far as we know, it is the first time the client-based online
proctoring system has been used for recruitment. Online exams are more
attractive after the Covid-19 pandemic. Furthermore, during recruitment, online
exams are used. However, there are more cheating possibilities for online
exams. Assigning a proctor for each exam increases cost. At this point,
automatic proctor systems detect possible cheating status. This article
proposes an end-to-end system and submodules to get better results for online
proctoring. Object detection, face recognition, human voice detection, and
segmentation are used in our system. Furthermore, our proposed model works on
the PCs of users, meaning a client-based system. So, server cost is eliminated.
As far as we know, it is the first time the client-based online proctoring
system has been used for recruitment. Furthermore, this cheating system works
at https://www.talent-interview.com/tr/.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00797" title="Abstract">arXiv:2312.00797</a> [<a href="/pdf/2312.00797" title="Download PDF">pdf</a>, <a href="/format/2312.00797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-mode OAM Convergent Transmission with Co-divergent Angle Tailored  by Airy Wavefront
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yufei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yilong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y+L">Yong Liang Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Airy beam, line-of-sight channel, orbital angular momentum, OAM multi-mode, wireless communication
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Antennas and Propagation (Volume: 71, Issue:
  6, June 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Wireless backhaul offers a more cost-effective, time-efficient, and
reconfigurable solution than wired backhaul to connect the edge-computing cells
to the core network. As the amount of transmitted data increases, the low-rank
characteristic of Line-of-Sight (LoS) channel severely limits the growth of
channel capacity in the point-to-point backhaul transmission scenario. Orbital
Angular Momentum (OAM), also known as vortex beam, is considered a potentially
effective solution for high-capacity LoS wireless transmission. However, due to
the shortcomings of its energy divergence and the specificity of multi-mode
divergence angles, OAM beams have been difficult to apply in practical
communication systems for a long time. In this work, a novel multi-mode
convergent transmission with co-scale reception scheme is proposed. OAM beams
of different modes can be transmitted with the same beam divergent angle, while
the wavefronts are tailored by the ring-shaped Airy compensation lens during
propagation, so that the energy will converge to the same spatial area for
receiving. Based on this scheme, not only is the Signal-to-Noise Ratio (SNR)
greatly improved, but it is also possible to simultaneously receive and
demodulate OAM channels multiplexed with different modes in a limited space
area. Through prototype experiments, we demonstrated that 3 kinds of OAM modes
are tunable, and different channels can be separated simultaneously with
receiving power increasing. The measurement isolations between channels are
over 11 dB, which ensures a reliable 16-QAM multiplexing wireless transmission
demo system. This work may explore the potential applications of OAM-based
multi-mode convergent transmission in LoS wireless communications.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00798" title="Abstract">arXiv:2312.00798</a> [<a href="/pdf/2312.00798" title="Download PDF">pdf</a>, <a href="/format/2312.00798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Walter Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+M+O">Matthew O. Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in
a suite of classic behavioral games that are designed to elicit characteristics
such as trust, fairness, risk-aversion, cooperation, \textit{etc.}; as well as
a traditional Big-5 psychological survey that measures personality traits.
ChatGPT-4 passes the Turing Test in that it consistently exhibits human-like
behavioral and personality traits based on a comparison to the behavior of
hundreds of thousands of humans from more than 50 countries. Chatbots also
modify their behavior based on previous experience and contexts ``as if'' they
were learning from the interactions, and change their behavior in response to
different framings of the same strategic situation. Their behaviors are often
distinct from average and modal human behaviors, in which case they tend to
behave on the more altruistic and cooperative end of the distribution. We
estimate that they act as if they are maximizing an average of their own and
partner's payoff.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00803" title="Abstract">arXiv:2312.00803</a> [<a href="/pdf/2312.00803" title="Download PDF">pdf</a>, <a href="/ps/2312.00803" title="Download PostScript">ps</a>, <a href="/format/2312.00803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InceptionCaps: A Performant Glaucoma Classification Model for  Data-scarce Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manohar%2C+G">Gyanendar Manohar</a>, 
<a href="/search/cs?searchtype=author&query=O%27Reilly%2C+R">Ruairi O&#x27;Reilly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Glaucoma is an irreversible ocular disease and is the second leading cause of
visual disability worldwide. Slow vision loss and the asymptomatic nature of
the disease make its diagnosis challenging. Early detection is crucial for
preventing irreversible blindness. Ophthalmologists primarily use retinal
fundus images as a non-invasive screening method. Convolutional neural networks
(CNN) have demonstrated high accuracy in the classification of medical images.
Nevertheless, CNN's translation-invariant nature and inability to handle the
part-whole relationship between objects make its direct application unsuitable
for glaucomatous fundus image classification, as it requires a large number of
labelled images for training. This work reviews existing state of the art
models and proposes InceptionCaps, a novel capsule network (CapsNet) based deep
learning model having pre-trained InceptionV3 as its convolution base, for
automatic glaucoma classification. InceptionCaps achieved an accuracy of 0.956,
specificity of 0.96, and AUC of 0.9556, which surpasses several
state-of-the-art deep learning model performances on the RIM-ONE v2 dataset.
The obtained result demonstrates the robustness of the proposed deep learning
model.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00804" title="Abstract">arXiv:2312.00804</a> [<a href="/pdf/2312.00804" title="Download PDF">pdf</a>, <a href="/format/2312.00804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic detection of problem-gambling signs from online texts using  large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+E">Elke Smith</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+N">Nils Reiter</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Problem gambling is a major public health concern and is associated with
profound psychological distress and economic problems. There are numerous
gambling communities on the internet where users exchange information about
games, gambling tactics, as well as gambling-related problems. Individuals
exhibiting higher levels of problem gambling engage more in such communities.
Online gambling communities may provide insights into problem-gambling
behaviour. Using data scraped from a major German gambling discussion board, we
fine-tuned a large language model, specifically a Bidirectional Encoder
Representations from Transformers (BERT) model, to predict signs of
problem-gambling from forum posts. Training data were generated by manual
annotation and by taking into account diagnostic criteria and gambling-related
cognitive distortions. Using k-fold cross-validation, our models achieved a
precision of 0.95 and F1 score of 0.71, demonstrating that satisfactory
classification performance can be achieved by generating high-quality training
material through manual annotation based on diagnostic criteria. The current
study confirms that a BERT-based model can be reliably used on small data sets
and to detect signatures of problem gambling in online communication data. Such
computational approaches may have potential for the detection of changes in
problem-gambling prevalence among online users.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00805" title="Abstract">arXiv:2312.00805</a> [<a href="/pdf/2312.00805" title="Download PDF">pdf</a>, <a href="/format/2312.00805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender inference: can chatGPT outperform common commercial tools?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alexopoulos%2C+M">Michelle Alexopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+K">Kelly Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Mahetaji%2C+K">Kaushar Mahetaji</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M+E">Marcus Emmanuel Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Gutwillinger%2C+R">Rogan Gutwillinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of CASCON 2023, ACM, New York, NY, USA, 161-166
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An increasing number of studies use gender information to understand
phenomena such as gender bias, inequity in access and participation, or the
impact of the Covid pandemic response. Unfortunately, most datasets do not
include self-reported gender information, making it necessary for researchers
to infer gender from other information, such as names or names and country
information. An important limitation of these tools is that they fail to
appropriately capture the fact that gender exists on a non-binary scale,
however, it remains important to evaluate and compare how well these tools
perform in a variety of contexts. In this paper, we compare the performance of
a generative Artificial Intelligence (AI) tool ChatGPT with three commercially
available list-based and machine learning-based gender inference tools (Namsor,
Gender-API, and genderize.io) on a unique dataset. Specifically, we use a large
Olympic athlete dataset and report how variations in the input (e.g., first
name and first and last name, with and without country information) impact the
accuracy of their predictions. We report results for the full set, as well as
for the subsets: medal versus non-medal winners, athletes from the largest
English-speaking countries, and athletes from East Asia. On these sets, we find
that Namsor is the best traditional commercially available tool. However,
ChatGPT performs at least as well as Namsor and often outperforms it,
especially for the female sample when country and/or last name information is
available. All tools perform better on medalists versus non-medalists and on
names from English-speaking countries. Although not designed for this purpose,
ChatGPT may be a cost-effective tool for gender prediction. In the future, it
might even be possible for ChatGPT or other large scale language models to
better identify self-reported gender rather than report gender on a binary
scale.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00808" title="Abstract">arXiv:2312.00808</a> [<a href="/pdf/2312.00808" title="Download PDF">pdf</a>, <a href="/format/2312.00808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming organic chemistry research paradigms: moving from manual  efforts to the intersection of automation and artificial intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengchun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+F">Fanyang Mo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Organic chemistry is undergoing a major paradigm shift, moving from a
labor-intensive approach to a new era dominated by automation and artificial
intelligence (AI). This transformative shift is being driven by technological
advances, the ever-increasing demand for greater research efficiency and
accuracy, and the burgeoning growth of interdisciplinary research. AI models,
supported by computational power and algorithms, are drastically reshaping
synthetic planning and introducing groundbreaking ways to tackle complex
molecular synthesis. In addition, autonomous robotic systems are rapidly
accelerating the pace of discovery by performing tedious tasks with
unprecedented speed and precision. This article examines the multiple
opportunities and challenges presented by this paradigm shift and explores its
far-reaching implications. It provides valuable insights into the future
trajectory of organic chemistry research, which is increasingly defined by the
synergistic interaction of automation and AI.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00812" title="Abstract">arXiv:2312.00812</a> [<a href="/pdf/2312.00812" title="Download PDF">pdf</a>, <a href="/format/2312.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Autonomous Driving with Large Language Models: A Safety  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Ruochen Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Chengtian Lang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+S+S">Sinong Simon Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably
in the form of diminished public trust and safety concerns from long-tail
unforeseen driving scenarios. This predicament is due to the limitation of deep
neural networks in AD software, which struggle with interpretability and
exhibit poor generalization capabilities in out-of-distribution and uncertain
scenarios. To this end, this paper advocates for the integration of Large
Language Models (LLMs) into the AD system, leveraging their robust common-sense
knowledge, reasoning abilities, and human-interaction capabilities. The
proposed approach deploys the LLM as an intelligent decision-maker in planning,
incorporating safety verifiers for contextual safety learning to enhance
overall AD performance and safety. We present results from two case studies
that affirm the efficacy of our approach. We further discuss the potential
integration of LLM for other AD software components including perception,
prediction, and simulation. Despite the observed challenges in the case
studies, the integration of LLMs is promising and beneficial for reinforcing
both safety and performance in AD.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00817" title="Abstract">arXiv:2312.00817</a> [<a href="/pdf/2312.00817" title="Download PDF">pdf</a>, <a href="/format/2312.00817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimelyGPT: Recurrent Convolutional Transformer for Long Time-series  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qincheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained models (PTMs) have gained prominence in Natural Language
Processing and Computer Vision domains. When it comes to time-series PTMs,
their development has been limited. Previous research on time-series
transformers has mainly been devoted to small-scale tasks, yet these models
have not consistently outperformed traditional models. Additionally, the
performance of these transformers on large-scale data remains unexplored. These
findings raise doubts about Transformer's capabilities to scale up and capture
temporal dependencies. In this study, we re-examine time-series transformers
and identify the shortcomings of prior studies. Drawing from these insights, we
then introduce a pioneering architecture called Timely Generative Pre-trained
Transformer (\model). This architecture integrates recurrent attention and
temporal convolution modules to effectively capture global-local temporal
dependencies in long sequences. The relative position embedding with time decay
can effectively deal with trend and periodic patterns from time-series. Our
experiments show that \model~excels in modeling continuously monitored
biosignal as well as irregularly-sampled time-series data commonly observed in
longitudinal electronic health records. This breakthrough suggests a priority
shift in time-series deep learning research, moving from small-scale modeling
from scratch to large-scale pre-training.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00818" title="Abstract">arXiv:2312.00818</a> [<a href="/pdf/2312.00818" title="Download PDF">pdf</a>, <a href="/ps/2312.00818" title="Download PostScript">ps</a>, <a href="/format/2312.00818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The perpetual motion machine of AI-generated data and the distraction of  ChatGPT-as-scientist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Listgarten%2C+J">Jennifer Listgarten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since ChatGPT works so well, are we on the cusp of solving science with AI?
Is not AlphaFold2 suggestive that the potential of LLMs in biology and the
sciences more broadly is limitless? Can we use AI itself to bridge the lack of
data in the sciences in order to then train an AI? Herein we present a
discussion of these topics.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00819" title="Abstract">arXiv:2312.00819</a> [<a href="/pdf/2312.00819" title="Download PDF">pdf</a>, <a href="/format/2312.00819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Travel Behavior Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+B">Baichuan Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanyong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruoyun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaotong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinhua Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Travel behavior prediction is a fundamental task in transportation demand
management. The conventional methods for travel behavior prediction rely on
numerical data to construct mathematical models and calibrate model parameters
to represent human preferences. Recent advancement in large language models
(LLMs) has shown great reasoning abilities to solve complex problems. In this
study, we propose to use LLMs to predict travel behavior with prompt
engineering without data-based parameter learning. Specifically, we carefully
design our prompts that include 1) task description, 2) travel characteristics,
3) individual attributes, and 4) guides of thinking with domain knowledge, and
ask the LLMs to predict an individual's travel behavior and explain the
results. We select the travel mode choice task as a case study. Results show
that, though no training samples are provided, LLM-based predictions have
competitive accuracy and F1-score as canonical supervised learning methods such
as multinomial logit, random forest, and neural networks. LLMs can also output
reasons that support their prediction. However, though in most of the cases,
the output explanations are reasonable, we still observe cases that violate
logic or with hallucinations.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00820" title="Abstract">arXiv:2312.00820</a> [<a href="/pdf/2312.00820" title="Download PDF">pdf</a>, <a href="/format/2312.00820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Cross Diffusion for Semantic Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Ziyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In diffusion models, deviations from a straight generative flow are a common
issue, resulting in semantic inconsistencies and suboptimal generations. To
address this challenge, we introduce `Non-Cross Diffusion', an innovative
approach in generative modeling for learning ordinary differential equation
(ODE) models. Our methodology strategically incorporates an ascending dimension
of input to effectively connect points sampled from two distributions with
uncrossed paths. This design is pivotal in ensuring enhanced semantic
consistency throughout the inference process, which is especially critical for
applications reliant on consistent generative flows, including various
distillation methods and deterministic sampling, which are fundamental in image
editing and interpolation tasks. Our empirical results demonstrate the
effectiveness of Non-Cross Diffusion, showing a substantial reduction in
semantic inconsistencies at different inference steps and a notable enhancement
in the overall performance of diffusion models.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00823" title="Abstract">arXiv:2312.00823</a> [<a href="/pdf/2312.00823" title="Download PDF">pdf</a>, <a href="/format/2312.00823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Multi-Modality Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+M">Mengmeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jialie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Ping Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Although current prompt learning methods have successfully been designed to
effectively reuse the large pre-trained models without fine-tuning their large
number of parameters, they still have limitations to be addressed, i.e.,
without considering the adverse impact of meaningless patches in every image
and without simultaneously considering in-sample generalization and
out-of-sample generalization. In this paper, we propose an adaptive
multi-modality prompt learning to address the above issues. To do this, we
employ previous text prompt learning and propose a new image prompt learning.
The image prompt learning achieves in-sample and out-of-sample generalization,
by first masking meaningless patches and then padding them with the learnable
parameters and the information from texts. Moreover, each of the prompts
provides auxiliary information to each other, further strengthening these two
kinds of generalization. Experimental results on real datasets demonstrate that
our method outperforms SOTA methods, in terms of different downstream tasks.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00824" title="Abstract">arXiv:2312.00824</a> [<a href="/pdf/2312.00824" title="Download PDF">pdf</a>, <a href="/format/2312.00824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Self-Supervised Contrastive Learning Using Beta Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+M+C">Mehmet Can Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Yanikoglu%2C+B">Berrin Yanikoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning a discriminative semantic space using unlabelled and noisy data
remains unaddressed in a multi-label setting. We present a contrastive
self-supervised learning method which is robust to data noise, grounded in the
domain of variational methods. The method (VCL) utilizes variational
contrastive learning with beta-divergence to learn robustly from unlabelled
datasets, including uncurated and noisy datasets. We demonstrate the
effectiveness of the proposed method through rigorous experiments including
linear evaluation and fine-tuning scenarios with multi-label datasets in the
face understanding domain. In almost all tested scenarios, VCL surpasses the
performance of state-of-the-art self-supervised methods, achieving a noteworthy
increase in accuracy.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00825" title="Abstract">arXiv:2312.00825</a> [<a href="/pdf/2312.00825" title="Download PDF">pdf</a>, <a href="/format/2312.00825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing and Mitigating Intersectional Social Biases in Vision-Language  Models with Counterfactual Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Howard%2C+P">Phillip Howard</a>, 
<a href="/search/cs?searchtype=author&query=Madasu%2C+A">Avinash Madasu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tiep Le</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+G+L">Gustavo Lujan Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Bhiwandiwalla%2C+A">Anahita Bhiwandiwalla</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+V">Vasudev Lal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.02988">arXiv:2310.02988</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While vision-language models (VLMs) have achieved remarkable performance
improvements recently, there is growing evidence that these models also posses
harmful biases with respect to social attributes such as gender and race. Prior
studies have primarily focused on probing such bias attributes individually
while ignoring biases associated with intersections between social attributes.
This could be due to the difficulty of collecting an exhaustive set of
image-text pairs for various combinations of social attributes. To address this
challenge, we employ text-to-image diffusion models to produce counterfactual
examples for probing intserctional social biases at scale. Our approach
utilizes Stable Diffusion with cross attention control to produce sets of
counterfactual image-text pairs that are highly similar in their depiction of a
subject (e.g., a given occupation) while differing only in their depiction of
intersectional social attributes (e.g., race &amp; gender). Through our
over-generate-then-filter methodology, we produce SocialCounterfactuals, a
high-quality dataset containing over 171k image-text pairs for probing
intersectional biases related to gender, race, and physical characteristics. We
conduct extensive experiments to demonstrate the usefulness of our generated
dataset for probing and mitigating intersectional social biases in
state-of-the-art VLMs.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00826" title="Abstract">arXiv:2312.00826</a> [<a href="/pdf/2312.00826" title="Download PDF">pdf</a>, <a href="/format/2312.00826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEVIAS: Learning Disentangled Video Representations of Action and Scene  for Holistic Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Kyungho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+G">Geo Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngrae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinwoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, 17 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When watching a video, humans can naturally extract human actions from the
surrounding scene context, even when action-scene combinations are unusual.
However, unlike humans, video action recognition models often learn
scene-biased action representations from the spurious correlation in training
data, leading to poor performance in out-of-context scenarios. While
scene-debiased models achieve improved performance in out-of-context scenarios,
they often overlook valuable scene information in the data. Addressing this
challenge, we propose Disentangled VIdeo representations of Action and Scene
(DEVIAS), which aims to achieve holistic video understanding. Disentangled
action and scene representations with our method could provide flexibility to
adjust the emphasis on action or scene information depending on downstream task
and dataset characteristics. Disentangled action and scene representations
could be beneficial for both in-context and out-of-context video understanding.
To this end, we employ slot attention to learn disentangled action and scene
representations with a single model, along with auxiliary tasks that further
guide slot attention. We validate the proposed method on both in-context
datasets: UCF-101 and Kinetics-400, and out-of-context datasets: SCUBA and HAT.
Our proposed method shows favorable performance across different datasets
compared to the baselines, demonstrating its effectiveness in diverse video
understanding scenarios.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00827" title="Abstract">arXiv:2312.00827</a> [<a href="/pdf/2312.00827" title="Download PDF">pdf</a>, <a href="/format/2312.00827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Connecting Noise Modeling to Boost Noise  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Chau Pham</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Noisy labels can impair model performance, making the study of learning with
noisy labels an important topic. Two conventional approaches are noise modeling
and noise detection. However, these two methods are typically studied
independently, and there has been limited work on their collaboration. In this
work, we explore the integration of these two approaches, proposing an
interconnected structure with three crucial blocks: noise modeling, source
knowledge identification, and enhanced noise detection using noise
source-knowledge-integration methods. This collaboration structure offers
advantages such as discriminating hard negatives and preserving genuinely clean
labels that might be suspiciously noisy. Our experiments on four datasets,
featuring three types of noise and different combinations of each block,
demonstrate the efficacy of these components' collaboration. Our collaborative
structure methods achieve up to a 10% increase in top-1 classification accuracy
in synthesized noise datasets and 3-5% in real-world noisy datasets. The
results also suggest that these components make distinct contributions to
overall performance across various noise scenarios. These findings provide
valuable insights for designing noisy label learning methods customized for
specific noise scenarios in the future. Our code is accessible to the public.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00833" title="Abstract">arXiv:2312.00833</a> [<a href="/pdf/2312.00833" title="Download PDF">pdf</a>, <a href="/format/2312.00833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lasagna: Layered Score Distillation for Disentangled Object Relighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bashkirova%2C+D">Dina Bashkirova</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Arijit Ray</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+R">Rupayan Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Bargal%2C+S+A">Sarah Adel Bargal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Professional artists, photographers, and other visual content creators use
object relighting to establish their photo's desired effect. Unfortunately,
manual tools that allow relighting have a steep learning curve and are
difficult to master. Although generative editing methods now enable some forms
of image editing, relighting is still beyond today's capabilities; existing
methods struggle to keep other aspects of the image -- colors, shapes, and
textures -- consistent after the edit. We propose Lasagna, a method that
enables intuitive text-guided relighting control. Lasagna learns a lighting
prior by using score distillation sampling to distill the prior of a diffusion
model, which has been finetuned on synthetic relighting data. To train Lasagna,
we curate a new synthetic dataset ReLiT, which contains 3D object assets re-lit
from multiple light source locations. Despite training on synthetic images,
quantitative results show that Lasagna relights real-world images while
preserving other aspects of the input image, outperforming state-of-the-art
text-guided image editing methods. Lasagna enables realistic and controlled
results on natural images and digital art pieces and is preferred by humans
over other methods in over 91% of cases. Finally, we demonstrate the
versatility of our learning objective by extending it to allow colorization,
another form of image editing.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00834" title="Abstract">arXiv:2312.00834</a> [<a href="/pdf/2312.00834" title="Download PDF">pdf</a>, <a href="/format/2312.00834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV-RIR: Audio-Visual Room Impulse Response Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratnarajah%2C+A">Anton Ratnarajah</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sonal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chiniya%2C+P">Purva Chiniya</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate estimation of Room Impulse Response (RIR), which captures an
environment's acoustic properties, is important for speech processing and AR/VR
applications. We propose AV-RIR, a novel multi-modal multi-task learning
approach to accurately estimate the RIR from a given reverberant speech signal
and the visual cues of its corresponding environment. AV-RIR builds on a novel
neural codec-based architecture that effectively captures environment geometry
and materials properties and solves speech dereverberation as an auxiliary task
by using multi-task learning. We also propose Geo-Mat features that augment
material information into visual cues and CRIP that improves late reverberation
components in the estimated RIR via image-to-RIR retrieval by 86%. Empirical
results show that AV-RIR quantitatively outperforms previous audio-only and
visual-only approaches by achieving 36% - 63% improvement across various
acoustic metrics in RIR estimation. Additionally, it also achieves higher
preference scores in human evaluation. As an auxiliary benefit, dereverbed
speech from AV-RIR shows competitive performance with the state-of-the-art in
various spoken language processing tasks and outperforms reverberation time
error score in the real-world AVSpeech dataset. Qualitative examples of both
synthesized reverberant speech and enhanced speech can be found at
https://www.youtube.com/watch?v=tTsKhviukAE.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00839" title="Abstract">arXiv:2312.00839</a> [<a href="/pdf/2312.00839" title="Download PDF">pdf</a>, <a href="/format/2312.00839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent  Weight Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Lei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiye Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xicheng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Asynchronous pipeline model parallelism with a "1F1B" (one forward, one
backward) schedule generates little bubble overhead and always provides quite a
high throughput. However, the "1F1B" schedule inevitably leads to weight
inconsistency and weight staleness issues due to the cross-training of
different mini-batches across GPUs. To simultaneously address these two
problems, in this paper, we propose an optimizer-dependent weight prediction
strategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight
of our proposal is that we employ a weight prediction strategy in the forward
pass to ensure that each mini-batch uses consistent and staleness-free weights
to compute the forward pass. To be concrete, we first construct the weight
prediction scheme based on the update rule of the used optimizer when training
the deep neural network models. Then throughout the "1F1B" pipelined training,
each mini-batch is mandated to execute weight prediction ahead of the forward
pass, subsequently employing the predicted weights to perform the forward pass.
As a result, PipeOptim 1) inherits the advantage of the "1F1B" schedule and
generates pretty high throughput, and 2) can ensure effective parameter
learning regardless of the type of the used optimizer. To verify the
effectiveness of our proposal, we conducted extensive experimental evaluations
using eight different deep-learning models spanning three machine-learning
tasks including image classification, sentiment analysis, and machine
translation. The experiment results demonstrate that PipeOptim outperforms the
popular pipelined approaches including GPipe, PipeDream, PipeDream-2BW, and
SpecTrain. The code of PipeOptim will be accessible at
https://github.com/guanleics/PipeOptim.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00840" title="Abstract">arXiv:2312.00840</a> [<a href="/pdf/2312.00840" title="Download PDF">pdf</a>, <a href="/format/2312.00840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Redundancy-Free Sub-networks in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">LianLi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Catastrophic Forgetting (CF) is a prominent issue in continual learning.
Parameter isolation addresses this challenge by masking a sub-network for each
task to mitigate interference with old tasks. However, these sub-networks are
constructed relying on weight magnitude, which does not necessarily correspond
to the importance of weights, resulting in maintaining unimportant weights and
constructing redundant sub-networks. To overcome this limitation, inspired by
information bottleneck, which removes redundancy between adjacent network
layers, we propose \textbf{\underline{I}nformation \underline{B}ottleneck
\underline{M}asked sub-network (IBM)} to eliminate redundancy within
sub-networks. Specifically, IBM accumulates valuable information into essential
weights to construct redundancy-free sub-networks, not only effectively
mitigating CF by freezing the sub-networks but also facilitating new tasks
training through the transfer of valuable knowledge. Additionally, IBM
decomposes hidden representations to automate the construction process and make
it flexible. Extensive experiments demonstrate that IBM consistently
outperforms state-of-the-art methods. Notably, IBM surpasses the
state-of-the-art parameter isolation method with a 70\% reduction in the number
of parameters within sub-networks and an 80\% decrease in training time.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00843" title="Abstract">arXiv:2312.00843</a> [<a href="/pdf/2312.00843" title="Download PDF">pdf</a>, <a href="/format/2312.00843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Robustness of Decentralized Training for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+C">Chenxi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wangcheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Binhang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Decentralized training of large language models has emerged as an effective
way to democratize this technology. However, the potential threats associated
with this approach have not been carefully discussed, which would hinder the
development of decentralized training infrastructures. This paper aims to
initiate discussion towards this end by exploring the robustness of
decentralized training from three main perspectives. First, we demonstrate the
vulnerabilities inherent in decentralized training frameworks in terms of
hardware, data, and models. Second, we highlight the fundamental difference
between decentralized foundation model training and vanilla federated learning,
where the security techniques employed in federated learning cannot be applied
directly. Third, we discuss the essential components required for a robust and
efficient decentralized training framework and present a case study by modeling
a concrete threat model. Our objective in this vision paper is to emphasize the
importance of addressing security concerns in the context of decentralized
training for large language models.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00844" title="Abstract">arXiv:2312.00844</a> [<a href="/pdf/2312.00844" title="Download PDF">pdf</a>, <a href="/format/2312.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huadong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Minhao Jing</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Renhe Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It is widely believed that the dense supervision is better than the sparse
supervision in the field of depth completion, but the underlying reasons for
this are rarely discussed. In this paper, we find that the challenge of using
sparse supervision for training Radar-Camera depth prediction models is the
Projection Transformation Collapse (PTC). The PTC implies that sparse
supervision leads the model to learn unexpected collapsed projection
transformations between Image/Radar/LiDAR spaces. Building on this insight, we
propose a novel ``Disruption-Compensation" framework to handle the PTC, thereby
relighting the use of sparse supervision in depth completion tasks. The
disruption part deliberately discards position correspondences among
Image/Radar/LiDAR, while the compensation part leverages 3D spatial and 2D
semantic information to compensate for the discarded beneficial position
correspondence. Extensive experimental results demonstrate that our framework
(sparse supervision) outperforms the state-of-the-art (dense supervision) with
11.6$\%$ improvement in mean absolute error and $1.6 \times$ speedup. The code
is available at ...
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00845" title="Abstract">arXiv:2312.00845</a> [<a href="/pdf/2312.00845" title="Download PDF">pdf</a>, <a href="/format/2312.00845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VMC: Video Motion Customization using Temporal Attention Adaption for  Text-to-Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyeonho Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G+Y">Geon Yeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://video-motion-customization.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-video diffusion models have advanced video generation significantly.
However, customizing these models to generate videos with tailored motions
presents a substantial challenge. In specific, they encounter hurdles in (a)
accurately reproducing motion from a target video, and (b) creating diverse
visual variations. For example, straightforward extensions of static image
customization methods to video often lead to intricate entanglements of
appearance and motion data. To tackle this, here we present the Video Motion
Customization (VMC) framework, a novel one-shot tuning approach crafted to
adapt temporal attention layers within video diffusion models. Our approach
introduces a novel motion distillation objective using residual vectors between
consecutive frames as a motion reference. The diffusion process then preserves
low-frequency motion trajectories while mitigating high-frequency
motion-unrelated noise in image space. We validate our method against
state-of-the-art video generative models across diverse real-world motions and
contexts. Our codes, data and the project demo can be found at
https://video-motion-customization.github.io
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00846" title="Abstract">arXiv:2312.00846</a> [<a href="/pdf/2312.00846" title="Download PDF">pdf</a>, <a href="/format/2312.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuSG: Neural Implicit Surface Reconstruction with 3D Gaussian Splatting  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing neural implicit surface reconstruction methods have achieved
impressive performance in multi-view 3D reconstruction by leveraging explicit
geometry priors such as depth maps or point clouds as regularization. However,
the reconstruction results still lack fine details because of the over-smoothed
depth map or sparse point cloud. In this work, we propose a neural implicit
surface reconstruction pipeline with guidance from 3D Gaussian Splatting to
recover highly detailed surfaces. The advantage of 3D Gaussian Splatting is
that it can generate dense point clouds with detailed structure. Nonetheless, a
naive adoption of 3D Gaussian Splatting can fail since the generated points are
the centers of 3D Gaussians that do not necessarily lie on the surface. We thus
introduce a scale regularizer to pull the centers close to the surface by
enforcing the 3D Gaussians to be extremely thin. Moreover, we propose to refine
the point cloud from 3D Gaussians Splatting with the normal priors from the
surface predicted by neural implicit models instead of using a fixed set of
points as guidance. Consequently, the quality of surface reconstruction
improves from the guidance of the more accurate 3D Gaussian splatting. By
jointly optimizing the 3D Gaussian Splatting and the neural implicit model, our
approach benefits from both representations and generates complete surfaces
with intricate details. Experiments on Tanks and Temples verify the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00849" title="Abstract">arXiv:2312.00849</a> [<a href="/pdf/2312.00849" title="Download PDF">pdf</a>, <a href="/format/2312.00849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from  Fine-grained Correctional Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Taiwen He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Ganqu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have recently demonstrated
impressive capabilities in multimodal understanding, reasoning, and
interaction. However, existing MLLMs prevalently suffer from serious
hallucination problems, generating text that is not factually grounded in
associated images. The problem makes existing MLLMs untrustworthy and thus
impractical in real-world (especially high-stakes) applications. To address the
challenge, we present RLHF-V, which enhances MLLM trustworthiness via behavior
alignment from fine-grained correctional human feedback. Specifically, RLHF-V
collects human preference in the form of segment-level corrections on
hallucinations, and performs dense direct preference optimization over the
human feedback. Comprehensive experiments on five benchmarks in both automatic
and human evaluation show that, RLHF-V can enable substantially more
trustworthy MLLM behaviors with promising data and computation efficiency.
Remarkably, using 1.4k annotated data samples, RLHF-V significantly reduces the
hallucination rate of the base MLLM by 34.8%, outperforming the concurrent
LLaVA-RLHF trained on 10k annotated data. The final model achieves
state-of-the-art performance in trustworthiness among open-source MLLMs, and
shows better robustness than GPT-4V in preventing hallucinations aroused from
over-generalization. We open-source our code, model, and data at
https://github.com/RLHF-V/RLHF-V.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00851" title="Abstract">arXiv:2312.00851</a> [<a href="/pdf/2312.00851" title="Download PDF">pdf</a>, <a href="/format/2312.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Inspired Criterion for Pruning-Quantization Joint Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jie Lei</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Leyuan Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pruning-quantization joint learning always facilitates the deployment of deep
neural networks (DNNs) on resource-constrained edge devices. However, most
existing methods do not jointly learn a global criterion for pruning and
quantization in an interpretable way. In this paper, we propose a novel physics
inspired criterion for pruning-quantization joint learning (PIC-PQ), which is
explored from an analogy we first draw between elasticity dynamics (ED) and
model compression (MC). Specifically, derived from Hooke's law in ED, we
establish a linear relationship between the filters' importance distribution
and the filter property (FP) by a learnable deformation scale in the physics
inspired criterion (PIC). Furthermore, we extend PIC with a relative shift
variable for a global view. To ensure feasibility and flexibility, available
maximum bitwidth and penalty factor are introduced in quantization bitwidth
assignment. Experiments on benchmarks of image classification demonstrate that
PIC-PQ yields a good trade-off between accuracy and bit-operations (BOPs)
compression ratio e.g., 54.96X BOPs compression ratio in ResNet56 on CIFAR10
with 0.10% accuracy drop and 53.24X in ResNet18 on ImageNet with 0.61% accuracy
drop). The code will be available at https://github.com/fanxxxxyi/PIC-PQ.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00852" title="Abstract">arXiv:2312.00852</a> [<a href="/pdf/2312.00852" title="Download PDF">pdf</a>, <a href="/format/2312.00852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond First-Order Tweedie: Solving Inverse Problems using Latent  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rout%2C+L">Litu Rout</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yujia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Caramanis%2C+C">Constantine Caramanis</a>, 
<a href="/search/cs?searchtype=author&query=Shakkottai%2C+S">Sanjay Shakkottai</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wen-Sheng Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Sampling from the posterior distribution poses a major computational
challenge in solving inverse problems using latent diffusion models. Common
methods rely on Tweedie's first-order moments, which are known to induce a
quality-limiting bias. Existing second-order approximations are impractical due
to prohibitive computational costs, making standard reverse diffusion processes
intractable for posterior sampling. This paper introduces Second-order Tweedie
sampler from Surrogate Loss (STSL), a novel sampler that offers efficiency
comparable to first-order Tweedie with a tractable reverse process using
second-order approximation. Our theoretical results reveal that the
second-order approximation is lower bounded by our surrogate loss that only
requires $O(1)$ compute using the trace of the Hessian, and by the lower bound
we derive a new drift term to make the reverse process tractable. Our method
surpasses SoTA solvers PSLD and P2L, achieving 4X and 8X reduction in neural
function evaluations, respectively, while notably enhancing sampling quality on
FFHQ, ImageNet, and COCO benchmarks. In addition, we show STSL extends to
text-guided image editing and addresses residual distortions present from
corrupted images in leading text-guided image editing methods. To our best
knowledge, this is the first work to offer an efficient second-order
approximation in solving inverse problems using latent diffusion and editing
real-world images with corruptions.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00853" title="Abstract">arXiv:2312.00853</a> [<a href="/pdf/2312.00853" title="Download PDF">pdf</a>, <a href="/format/2312.00853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Guided Latent Diffusion for Temporally Consistent Real-world  Video Super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chenhang He</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-world low-resolution (LR) videos have diverse and complex degradations,
imposing great challenges on video super-resolution (VSR) algorithms to
reproduce their high-resolution (HR) counterparts with high quality. Recently,
the diffusion models have shown compelling performance in generating realistic
details for image restoration tasks. However, the diffusion process has
randomness, making it hard to control the contents of restored images. This
issue becomes more serious when applying diffusion models to VSR tasks because
temporal consistency is crucial to the perceptual quality of videos. In this
paper, we propose an effective real-world VSR algorithm by leveraging the
strength of pre-trained latent diffusion models. To ensure the content
consistency among adjacent frames, we exploit the temporal dynamics in LR
videos to guide the diffusion process by optimizing the latent sampling path
with a motion-guided loss, ensuring that the generated HR video maintains a
coherent and continuous visual flow. To further mitigate the discontinuity of
generated details, we insert temporal module to the decoder and fine-tune it
with an innovative sequence-oriented loss. The proposed motion-guided latent
diffusion (MGLD) based VSR algorithm achieves significantly better perceptual
quality than state-of-the-arts on real-world VSR benchmark datasets, validating
the effectiveness of the proposed model design and training strategies.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00855" title="Abstract">arXiv:2312.00855</a> [<a href="/pdf/2312.00855" title="Download PDF">pdf</a>, <a href="/format/2312.00855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refine, Discriminate and Align: Stealing Encoders via Sample-Wise  Prototypes and Multi-Relational Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuchi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuwen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper introduces RDA, a pioneering approach designed to address two
primary deficiencies prevalent in previous endeavors aiming at stealing
pre-trained encoders: (1) suboptimal performances attributed to biased
optimization objectives, and (2) elevated query costs stemming from the
end-to-end paradigm that necessitates querying the target encoder every epoch.
Specifically, we initially Refine the representations of the target encoder for
each training sample, thereby establishing a less biased optimization objective
before the steal-training phase. This is accomplished via a sample-wise
prototype, which consolidates the target encoder's representations for a given
sample's various perspectives. Demanding exponentially fewer queries compared
to the end-to-end approach, prototypes can be instantiated to guide subsequent
query-free training. For more potent efficacy, we develop a multi-relational
extraction loss that trains the surrogate encoder to Discriminate mismatched
embedding-prototype pairs while Aligning those matched ones in terms of both
amplitude and angle. In this way, the trained surrogate encoder achieves
state-of-the-art results across the board in various downstream datasets with
limited queries. Moreover, RDA is shown to be robust to multiple widely-used
defenses.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00856" title="Abstract">arXiv:2312.00856</a> [<a href="/pdf/2312.00856" title="Download PDF">pdf</a>, <a href="/format/2312.00856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAFE-Net: Quality Assessment of Facial Expressions with Landmark  Heatmaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shuchao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Dadashzadeh%2C+A">Amirhossein Dadashzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Whone%2C+A">Alan Whone</a>, 
<a href="/search/cs?searchtype=author&query=Mirmehdi%2C+M">Majid Mirmehdi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial expression recognition (FER) methods have made great inroads in
categorising moods and feelings in humans. Beyond FER, pain estimation methods
assess levels of intensity in pain expressions, however assessing the quality
of all facial expressions is of critical value in health-related applications.
In this work, we address the quality of five different facial expressions in
patients affected by Parkinson's disease. We propose a novel landmark-guided
approach, QAFE-Net, that combines temporal landmark heatmaps with RGB data to
capture small facial muscle movements that are encoded and mapped to severity
scores. The proposed approach is evaluated on a new Parkinson's Disease Facial
Expression dataset (PFED5), as well as on the pain estimation benchmark, the
UNBC-McMaster Shoulder Pain Expression Archive Database. Our comparative
experiments demonstrate that the proposed method outperforms SOTA action
quality assessment works on PFED5 and achieves lower mean absolute error than
the SOTA pain estimation methods on UNBC-McMaster. Our code and the new PFED5
dataset are available at https://github.com/shuchaoduan/QAFE-Net.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00857" title="Abstract">arXiv:2312.00857</a> [<a href="/pdf/2312.00857" title="Download PDF">pdf</a>, <a href="/format/2312.00857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Space Explorer: Visual Analytics for Multimodal Latent Space  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B+C">Bum Chul Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+S">Samuel Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lubitz%2C+S+A">Steven A Lubitz</a>, 
<a href="/search/cs?searchtype=author&query=Philippakis%2C+A">Anthony Philippakis</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+P">Puneet Batra</a>, 
<a href="/search/cs?searchtype=author&query=Ellinor%2C+P+T">Patrick T Ellinor</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K">Kenney Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Machine learning models built on training data with multiple modalities can
reveal new insights that are not accessible through unimodal datasets. For
example, cardiac magnetic resonance images (MRIs) and electrocardiograms (ECGs)
are both known to capture useful information about subjects' cardiovascular
health status. A multimodal machine learning model trained from large datasets
can potentially predict the onset of heart-related diseases and provide novel
medical insights about the cardiovascular system. Despite the potential
benefits, it is difficult for medical experts to explore multimodal
representation models without visual aids and to test the predictive
performance of the models on various subpopulations. To address the challenges,
we developed a visual analytics system called Latent Space Explorer. Latent
Space Explorer provides interactive visualizations that enable users to explore
the multimodal representation of subjects, define subgroups of interest,
interactively decode data with different modalities with the selected subjects,
and inspect the accuracy of the embedding in downstream prediction tasks. A
user study was conducted with medical experts and their feedback provided
useful insights into how Latent Space Explorer can help their analysis and
possible new direction for further development in the medical domain.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00858" title="Abstract">arXiv:2312.00858</a> [<a href="/pdf/2312.00858" title="Download PDF">pdf</a>, <a href="/format/2312.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCache: Accelerating Diffusion Models for Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Project Page: <a href="https://horseee.github.io/Diffusion_DeepCache/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have recently gained unprecedented attention in the field of
image synthesis due to their remarkable generative capabilities.
Notwithstanding their prowess, these models often incur substantial
computational costs, primarily attributed to the sequential denoising process
and cumbersome model size. Traditional methods for compressing diffusion models
typically involve extensive retraining, presenting cost and feasibility
challenges. In this paper, we introduce DeepCache, a novel training-free
paradigm that accelerates diffusion models from the perspective of model
architecture. DeepCache capitalizes on the inherent temporal redundancy
observed in the sequential denoising steps of diffusion models, which caches
and retrieves features across adjacent denoising stages, thereby curtailing
redundant computations. Utilizing the property of the U-Net, we reuse the
high-level features while updating the low-level features in a very cheap way.
This innovative strategy, in turn, enables a speedup factor of 2.3$\times$ for
Stable Diffusion v1.5 with only a 0.05 decline in CLIP Score, and 4.1$\times$
for LDM-4-G with a slight decrease of 0.22 in FID on ImageNet. Our experiments
also demonstrate DeepCache's superiority over existing pruning and distillation
methods that necessitate retraining and its compatibility with current sampling
techniques. Furthermore, we find that under the same throughput, DeepCache
effectively achieves comparable or even marginally improved results with DDIM
or PLMS. The code is available at https://github.com/horseee/DeepCache
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00860" title="Abstract">arXiv:2312.00860</a> [<a href="/pdf/2312.00860" title="Download PDF">pdf</a>, <a href="/format/2312.00860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Any 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cen%2C+J">Jiazhong Cen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Project page: <a href="https://jumpat.github.io/SAGA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Interactive 3D segmentation in radiance fields is an appealing task since its
importance in 3D scene understanding and manipulation. However, existing
methods face challenges in either achieving fine-grained, multi-granularity
segmentation or contending with substantial computational overhead, inhibiting
real-time interaction. In this paper, we introduce Segment Any 3D GAussians
(SAGA), a novel 3D interactive segmentation approach that seamlessly blends a
2D segmentation foundation model with 3D Gaussian Splatting (3DGS), a recent
breakthrough of radiance fields. SAGA efficiently embeds multi-granularity 2D
segmentation results generated by the segmentation foundation model into 3D
Gaussian point features through well-designed contrastive training. Evaluation
on existing benchmarks demonstrates that SAGA can achieve competitive
performance with state-of-the-art methods. Moreover, SAGA achieves
multi-granularity segmentation and accommodates various prompts, including
points, scribbles, and 2D masks. Notably, SAGA can finish the 3D segmentation
within milliseconds, achieving nearly 1000x acceleration compared to previous
SOTA. The project page is at https://jumpat.github.io/SAGA.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00863" title="Abstract">arXiv:2312.00863</a> [<a href="/pdf/2312.00863" title="Download PDF">pdf</a>, <a href="/format/2312.00863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment  Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+B">Bala Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lemeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fanyi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F">Forrest Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segment Anything Model (SAM) has emerged as a powerful tool for numerous
vision applications. A key component that drives the impressive performance for
zero-shot transfer and high versatility is a super large Transformer model
trained on the extensive high-quality SA-1B dataset. While beneficial, the huge
computation cost of SAM model has limited its applications to wider real-world
applications. To address this limitation, we propose EfficientSAMs,
light-weight SAM models that exhibits decent performance with largely reduced
complexity. Our idea is based on leveraging masked image pretraining, SAMI,
which learns to reconstruct features from SAM image encoder for effective
visual representation learning. Further, we take SAMI-pretrained light-weight
image encoders and mask decoder to build EfficientSAMs, and finetune the models
on SA-1B for segment anything task. We perform evaluations on multiple vision
tasks including image classification, object detection, instance segmentation,
and semantic object detection, and find that our proposed pretraining method,
SAMI, consistently outperforms other masked image pretraining methods. On
segment anything task such as zero-shot instance segmentation, our
EfficientSAMs with SAMI-pretrained lightweight image encoders perform favorably
with a significant gain (e.g., ~4 AP on COCO/LVIS) over other fast SAM models.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00869" title="Abstract">arXiv:2312.00869</a> [<a href="/pdf/2312.00869" title="Download PDF">pdf</a>, <a href="/format/2312.00869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment and Caption Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page, along with the associated code, can be accessed via the following <a href="https://xk-huang.github.io/segment-caption-anything/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a method to efficiently equip the Segment Anything Model (SAM)
with the ability to generate regional captions. SAM presents strong
generalizability to segment anything while is short for semantic understanding.
By introducing a lightweight query-based feature mixer, we align the
region-specific features with the embedding space of language models for later
caption generation. As the number of trainable parameters is small (typically
in the order of tens of millions), it costs less computation, less memory
usage, and less communication bandwidth, resulting in both fast and scalable
training. To address the scarcity problem of regional caption data, we propose
to first pre-train our model on objection detection and segmentation tasks. We
call this step weak supervision pretraining since the pre-training data only
contains category names instead of full-sentence descriptions. The weak
supervision pretraining allows us to leverage many publicly available object
detection and segmentation datasets. We conduct extensive experiments to
demonstrate the superiority of our method and validate each design choice. This
work serves as a stepping stone towards scaling up regional captioning data and
sheds light on exploring efficient ways to augment SAM with regional semantics.
The project page, along with the associated code, can be accessed via the
following https://xk-huang.github.io/segment-caption-anything/.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00870" title="Abstract">arXiv:2312.00870</a> [<a href="/pdf/2312.00870" title="Download PDF">pdf</a>, <a href="/format/2312.00870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thambiraja%2C+B">Balamurugan Thambiraja</a>, 
<a href="/search/cs?searchtype=author&query=Aliakbarian%2C+S">Sadegh Aliakbarian</a>, 
<a href="/search/cs?searchtype=author&query=Cosker%2C+D">Darren Cosker</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://balamuruganthambiraja.github.io/3DiFACE/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present 3DiFACE, a novel method for personalized speech-driven 3D facial
animation and editing. While existing methods deterministically predict facial
animations from speech, they overlook the inherent one-to-many relationship
between speech and facial expressions, i.e., there are multiple reasonable
facial expression animations matching an audio input. It is especially
important in content creation to be able to modify generated motion or to
specify keyframes. To enable stochasticity as well as motion editing, we
propose a lightweight audio-conditioned diffusion model for 3D facial motion.
This diffusion model can be trained on a small 3D motion dataset, maintaining
expressive lip motion output. In addition, it can be finetuned for specific
subjects, requiring only a short video of the person. Through quantitative and
qualitative evaluations, we show that our method outperforms existing
state-of-the-art techniques and yields speech-driven animations with greater
fidelity and diversity.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00874" title="Abstract">arXiv:2312.00874</a> [<a href="/pdf/2312.00874" title="Download PDF">pdf</a>, <a href="/format/2312.00874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs  in Language Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jingcong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Meng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Ruofei Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The knowledge graph is a structure to store and represent knowledge, and
recent studies have discussed its capability to assist language models for
various applications. Some variations of knowledge graphs aim to record
arguments and their relations for computational argumentation tasks. However,
many must simplify semantic types to fit specific schemas, thus losing
flexibility and expression ability. In this paper, we propose the Hierarchical
Argumentation Graph (Hi-ArG), a new structure to organize arguments. We also
introduce two approaches to exploit Hi-ArG, including a text-graph multi-modal
model GreaseArG and a new pre-training framework augmented with graph
information. Experiments on two argumentation tasks have shown that after
further pre-training and fine-tuning, GreaseArG supersedes same-scale language
models on these tasks, while incorporating graph information during further
pre-training can also improve the performance of vanilla language models. Code
for this paper is available at https://github.com/ljcleo/Hi-ArG .
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00878" title="Abstract">arXiv:2312.00878</a> [<a href="/pdf/2312.00878" title="Download PDF">pdf</a>, <a href="/format/2312.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Everything: Emerging Localization Properties in  Vision-Language Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousselham%2C+W">Walid Bousselham</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+F">Felix Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Vittorio Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/WalBouss/GEM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision-language foundation models have shown remarkable performance in
various zero-shot settings such as image retrieval, classification, or
captioning. But so far, those models seem to fall behind when it comes to
zero-shot localization of referential expressions and objects in images. As a
result, they need to be fine-tuned for this task. In this paper, we show that
pretrained vision-language (VL) models allow for zero-shot open-vocabulary
object localization without any fine-tuning. To leverage those capabilities, we
propose a Grounding Everything Module (GEM) that generalizes the idea of
value-value attention introduced by CLIPSurgery to a self-self attention path.
We show that the concept of self-self attention corresponds to clustering, thus
enforcing groups of tokens arising from the same object to be similar while
preserving the alignment with the language space. To further guide the group
formation, we propose a set of regularizations that allows the model to finally
generalize across datasets and backbones. We evaluate the proposed GEM
framework on various benchmark tasks and datasets for semantic segmentation. It
shows that GEM not only outperforms other training-free open-vocabulary
localization methods, but also achieves state-of-the-art results on the
recently proposed OpenImagesV7 large-scale segmentation benchmark.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00890" title="Abstract">arXiv:2312.00890</a> [<a href="/pdf/2312.00890" title="Download PDF">pdf</a>, <a href="/ps/2312.00890" title="Download PostScript">ps</a>, <a href="/format/2312.00890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Stability and Controller Design Criteria for Two-dimensional  Differential-Algebraic-Equation Systems via LMI Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=RoshanaeeDeh%2C+A">Abdolah RoshanaeeDeh</a> (1), 
<a href="/search/eess?searchtype=author&query=Atrianfar%2C+H">Hajar Atrianfar</a> (1), 
<a href="/search/eess?searchtype=author&query=Shafiee%2C+M">Masoud Shafiee</a> (1) ((1) Amirkabir Universuty of technology (Tehran Polytechnic))
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses issues concerning asymptotic stability testing and
controller design for the two-dimensional Rosser model in
Differential-Algebraic-Equations systems (DAEs). We present sufficient
stability criteria based on the Lyapunov approach, utilizing a set of
Linear-Matrix-Inequalities (LMIs) tailored for two-dimensional DAEs.
Furthermore, we establish a set of sufficient conditions for determining the
feasibility of both state- and output-feedback controllers. Our methods
eliminate the need for decomposing the two-dimensional DAEs into separate
algebraic and differential components.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00894" title="Abstract">arXiv:2312.00894</a> [<a href="/pdf/2312.00894" title="Download PDF">pdf</a>, <a href="/format/2312.00894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models to Improve REST API Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Myeongsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Stennett%2C+T">Tyler Stennett</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Saurabh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 46th IEEE/ACM International Conference on Software Engineering - New Ideas and Emerging Results Track (ICSE-NIER 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The widespread adoption of REST APIs, coupled with their growing complexity
and size, has led to the need for automated REST API testing tools. Current
testing tools focus on the structured data in REST API specifications but often
neglect valuable insights available in unstructured natural-language
descriptions in the specifications, which leads to suboptimal test coverage.
Recently, to address this gap, researchers have developed techniques that
extract rules from these human-readable descriptions and query knowledge bases
to derive meaningful input values. However, these techniques are limited in the
types of rules they can extract and can produce inaccurate results. This paper
presents RESTGPT, an innovative approach that leverages the power and intrinsic
context-awareness of Large Language Models (LLMs) to improve REST API testing.
RESTGPT takes as input an API specification, extracts machine-interpretable
rules, and generates example parameter values from natural-language
descriptions in the specification. It then augments the original specification
with these rules and values. Our preliminary evaluation suggests that RESTGPT
outperforms existing techniques in both rule extraction and value generation.
Given these encouraging results, we outline future research directions for
leveraging LLMs more broadly for improving REST API testing.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00902" title="Abstract">arXiv:2312.00902</a> [<a href="/pdf/2312.00902" title="Download PDF">pdf</a>, <a href="/ps/2312.00902" title="Download PostScript">ps</a>, <a href="/format/2312.00902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lennard Jones Token: a blockchain solution to scientific data curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+H">Brian H. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Strachan%2C+A">Alejandro Strachan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Data science and artificial intelligence have become an indispensable part of
scientific research. While such methods rely on high-quality and large
quantities of machine-readable scientific data, the current scientific data
infrastructure faces significant challenges that limit effective data curation
and sharing. These challenges include insufficient return on investment for
researchers to share quality data, logistical difficulties in maintaining
long-term data repositories, and the absence of standardized methods for
evaluating the relative importance of various datasets. To address these
issues, this paper presents the Lennard Jones Token, a blockchain-based
proof-of-concept solution implemented on the Ethereum network. The token system
incentivizes users to submit optimized structures of Lennard Jones particles by
offering token rewards, while also charging for access to these valuable
structures. Utilizing smart contracts, the system automates the evaluation of
submitted data, ensuring that only structures with energies lower than those in
the existing database for a given cluster size are rewarded. The paper explores
the details of the Lennard Jones Token as a proof of concept and proposes
future blockchain-based tokens aimed at enhancing the curation and sharing of
scientific data.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00907" title="Abstract">arXiv:2312.00907</a> [<a href="/pdf/2312.00907" title="Download PDF">pdf</a>, <a href="/format/2312.00907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme Event Prediction with Multi-agent Reinforcement Learning-based  Parametrization of Atmospheric and Oceanic Turbulence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mojgani%2C+R">Rambod Mojgani</a>, 
<a href="/search/cs?searchtype=author&query=Waelchli%2C+D">Daniel Waelchli</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yifei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Koumoutsakos%2C+P">Petros Koumoutsakos</a>, 
<a href="/search/cs?searchtype=author&query=Hassanzadeh%2C+P">Pedram Hassanzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Atmospheric and Oceanic Physics (physics.ao-ph); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Global climate models (GCMs) are the main tools for understanding and
predicting climate change. However, due to limited numerical resolutions, these
models suffer from major structural uncertainties; e.g., they cannot resolve
critical processes such as small-scale eddies in atmospheric and oceanic
turbulence. Thus, such small-scale processes have to be represented as a
function of the resolved scales via closures (parametrization). The accuracy of
these closures is particularly important for capturing climate extremes.
Traditionally, such closures are based on heuristics and simplifying
assumptions about the unresolved physics. Recently, supervised-learned
closures, trained offline on high-fidelity data, have been shown to outperform
the classical physics-based closures. However, this approach requires a
significant amount of high-fidelity training data and can also lead to
instabilities. Reinforcement learning is emerging as a potent alternative for
developing such closures as it requires only low-order statistics and leads to
stable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL)
computational elements serve a dual role of discretization points and learning
agents. We leverage SMARL and fundamentals of turbulence physics to learn
closures for prototypes of atmospheric and oceanic turbulence. The policy is
trained using only the enstrophy spectrum, which is nearly invariant and can be
estimated from a few high-fidelity samples (these few samples are far from
enough for supervised/offline learning). We show that these closures lead to
stable low-resolution simulations that, at a fraction of the cost, can
reproduce the high-fidelity simulations' statistics, including the tails of the
probability density functions. The results demonstrate the high potential of
SMARL for closure modeling for GCMs, especially in the regime of scarce data
and indirect observations.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00909" title="Abstract">arXiv:2312.00909</a> [<a href="/pdf/2312.00909" title="Download PDF">pdf</a>, <a href="/format/2312.00909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-TAKE: Theme Aware Keyword Extraction Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maragheh%2C+R+Y">Reza Yousefi Maragheh</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chenhao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Irugu%2C+C+C">Charan Chand Irugu</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+P">Parth Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jason Cho</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianpeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sukumar%2C+S">Saranyan Sukumar</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Malay Patel</a>, 
<a href="/search/cs?searchtype=author&query=Korpeoglu%2C+E">Evren Korpeoglu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sushant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Achan%2C+K">Kannan Achan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Keyword extraction is one of the core tasks in natural language processing.
Classic extraction models are notorious for having a short attention span which
make it hard for them to conclude relational connections among the words and
sentences that are far from each other. This, in turn, makes their usage
prohibitive for generating keywords that are inferred from the context of the
whole text. In this paper, we explore using Large Language Models (LLMs) in
generating keywords for items that are inferred from the items textual
metadata. Our modeling framework includes several stages to fine grain the
results by avoiding outputting keywords that are non informative or sensitive
and reduce hallucinations common in LLM. We call our LLM-based framework
Theme-Aware Keyword Extraction (LLM TAKE). We propose two variations of
framework for generating extractive and abstractive themes for products in an E
commerce setting. We perform an extensive set of experiments on three real data
sets and show that our modeling framework can enhance accuracy based and
diversity based metrics when compared with benchmark models.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00912" title="Abstract">arXiv:2312.00912</a> [<a href="/pdf/2312.00912" title="Download PDF">pdf</a>, <a href="/format/2312.00912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quick Back-Translation for Unsupervised Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brimacombe%2C+B">Benjamin Brimacombe</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiawei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in EMNLP 2023 Findings. Source code can be found at the following link: <a href="https://github.com/bbrimacombe/Quick-Back-Translation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">The field of unsupervised machine translation has seen significant
advancement from the marriage of the Transformer and the back-translation
algorithm. The Transformer is a powerful generative model, and back-translation
leverages Transformer's high-quality translations for iterative
self-improvement. However, the Transformer is encumbered by the run-time of
autoregressive inference during back-translation, and back-translation is
limited by a lack of synthetic data efficiency. We propose a two-for-one
improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT
re-purposes the encoder as a generative model, and uses encoder-generated
sequences to train the decoder in conjunction with the original autoregressive
back-translation step, improving data throughput and utilization. Experiments
on various WMT benchmarks demonstrate that a relatively small number of
refining steps of QBT improve current unsupervised machine translation models,
and that QBT dramatically outperforms standard back-translation only method in
terms of training efficiency for comparable translation qualities.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00914" title="Abstract">arXiv:2312.00914</a> [<a href="/pdf/2312.00914" title="Download PDF">pdf</a>, <a href="/format/2312.00914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Information Freshness over a Channel that Wears Out
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stamatakis%2C+G+J">George J. Stamatakis</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Asilomar 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">A sensor samples and transmits status updates to a destination through a
wireless channel that wears out over time and with every use. At each time
slot, the sensor can decide to sample and transmit a fresh status update,
restore the initial quality of the channel, or remain silent. The actions
impose different costs on the operation of the system, and we study the problem
of optimally selecting the actions at the transmitter so as to maximize the
freshness of the information at the receiver, while minimizing the
communication cost. Freshness is measured by the age of information (AoI). The
problem is addressed using dynamic programming, and numerical results are
presented to provide insights into the optimal transmission policy.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00918" title="Abstract">arXiv:2312.00918</a> [<a href="/pdf/2312.00918" title="Download PDF">pdf</a>, <a href="/format/2312.00918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACE: A Program Analysis Framework for Continuous Performance Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biringa%2C+C">Chidera Biringa</a>, 
<a href="/search/cs?searchtype=author&query=Kul%2C+G">Gokhan Kul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ACM Transactions on Software Engineering and Methodology (TOSEM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Software development teams establish elaborate continuous integration
pipelines containing automated test cases to accelerate the development process
of software. Automated tests help to verify the correctness of code
modifications decreasing the response time to changing requirements. However,
when the software teams do not track the performance impact of pending
modifications, they may need to spend considerable time refactoring existing
code. This paper presents PACE, a program analysis framework that provides
continuous feedback on the performance impact of pending code updates. We
design performance microbenchmarks by mapping the execution time of functional
test cases given a code update. We map microbenchmarks to code stylometry
features and feed them to predictors for performance predictions. Our
experiments achieved significant performance in predicting code performance,
outperforming current state-of-the-art by 75% on neural-represented code
stylometry features.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00923" title="Abstract">arXiv:2312.00923</a> [<a href="/pdf/2312.00923" title="Download PDF">pdf</a>, <a href="/format/2312.00923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Delay in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csaba%2C+B">Botos Csaba</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Matthias M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Bibi%2C+A">Adel Bibi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Online continual learning, the process of training models on streaming data,
has gained increasing attention in recent years. However, a critical aspect
often overlooked is the label delay, where new data may not be labeled due to
slow and costly annotation processes. We introduce a new continual learning
framework with explicit modeling of the label delay between data and label
streams over time steps. In each step, the framework reveals both unlabeled
data from the current time step $t$ and labels delayed with $d$ steps, from the
time step $t-d$. In our extensive experiments amounting to 1060 GPU days, we
show that merely augmenting the computational resources is insufficient to
tackle this challenge. Our findings underline a notable performance decline
when solely relying on labeled data when the label delay becomes significant.
More surprisingly, when using state-of-the-art SSL and TTA techniques to
utilize the newer, unlabeled data, they fail to surpass the performance of a
na\"ive method that simply trains on the delayed supervised stream. To this
end, we introduce a simple, efficient baseline that rehearses from the labeled
memory samples that are most similar to the new unlabeled samples. This method
bridges the accuracy gap caused by label delay without significantly increasing
computational complexity. We show experimentally that our method is the least
affected by the label delay factor and in some cases successfully recovers the
accuracy of the non-delayed counterpart. We conduct various ablations and
sensitivity experiments, demonstrating the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00925" title="Abstract">arXiv:2312.00925</a> [<a href="/pdf/2312.00925" title="Download PDF">pdf</a>, <a href="/format/2312.00925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Describing Globally Distributed Software Architectures for Tax  Compliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorner%2C+M">Michael Dorner</a>, 
<a href="/search/cs?searchtype=author&query=Treidler%2C+O">Oliver Treidler</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+T">Tom-Eric Kunz</a>, 
<a href="/search/cs?searchtype=author&query=Zabardast%2C+E">Ehsan Zabardast</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0mite%2C+D">Darja &#x160;mite</a>, 
<a href="/search/cs?searchtype=author&query=Capraro%2C+M">Maximilian Capraro</a>, 
<a href="/search/cs?searchtype=author&query=Wnuk%2C+K">Krzysztof Wnuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICSA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: The company-internal reuse of software components owned by
organizational units in different countries is taxable. To comply with
international taxation standards, multinational enterprises need to consider a
geographical perspective on their software architecture. However, there is no
viewpoint that frames the concerns of tax authorities as stakeholders towards a
globally distributed software architecture.
<br />Objective: In this article, we introduce the reader to the concerns of tax
authorities as stakeholders and we investigate how software companies can
describe their globally distributed software architectures to tax authorities.
<br />Method: In an in-virtuo experiment, we (1) develop a viewpoint that frames
the concerns of tax authorities, (2) create a view of a large-scale, globally
distributed microservice architecture from a multinational enterprise, and (3)
evaluate the resulting software architecture description with a panel of four
tax experts.
<br />Results: The panel of tax experts found that our proposed architectural
viewpoint properly and sufficiently frames the concerns of taxation
stakeholders. However, the resulting view falls short: Although the
architecture description reveals that almost 70% of all reuse relationships
between the 2560 microservices in our case are cross-border and, therefore,
taxable, unclear jurisdictions of owners and a potentially insufficient
definition of ownership introduce significant noise to the view that limits its
usefulness and explanatory power of our software architecture description.
<br />Conclusion: Although our software architecture description provides a solid
foundation for the subsequent step, namely valuing software components, we
stumbled over several theoretical and practical problems when identifying and
defining ownership in distributed teams, which requires further
interdisciplinary research.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00933" title="Abstract">arXiv:2312.00933</a> [<a href="/pdf/2312.00933" title="Download PDF">pdf</a>, <a href="/format/2312.00933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preserving Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T+F">Tan F. Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures, submitted to IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper presents a privacy-preserving event detection scheme based on
measurements made by a network of sensors. A diameter-like decision statistic
made up of the marginal types of the measurements observed by the sensors is
employed. The proposed detection scheme can achieve the best type-I error
exponent as the type-II error rate is required to be negligible. Detection
performance with finite-length observations is also demonstrated through a
simulation example of spectrum sensing. Privacy protection is achieved by
obfuscating the type data with random zero-modulo-sum numbers that are
generated and distributed via the exchange of encrypted messages among the
sensors. The privacy-preserving performance against ``honest but curious''
adversaries, including colluding sensors, the fusion center, and external
eavesdroppers, is analyzed through a series of cryptographic games. It is shown
that the probability that any probabilistic polynomial time adversary
successfully estimates the sensors' measured types can not be much better than
independent guessing, when there are at least two non-colluding sensors.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00934" title="Abstract">arXiv:2312.00934</a> [<a href="/pdf/2312.00934" title="Download PDF">pdf</a>, <a href="/format/2312.00934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimPLoID: Harnessing probabilistic logic programming for infectious  disease epidemiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weitk%C3%A4mper%2C+F">Felix Weitk&#xe4;mper</a>, 
<a href="/search/cs?searchtype=author&query=Almiftah%2C+A">Ameen Almiftah</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kailin Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">High quality epidemiological modelling is essential in order to combat the
spread of infectious diseases. In this contribution, we present SimPLoID, an
epidemiological modelling framework based on the probabilistic logic
programming language ProbLog. SimPLoiI combines concepts from compartmental
modelling, such as the classic Susceptible-Infected-Recovered (SIR) model, with
network-based modelling. As a proof of concept, SimPLoID showcases the
potential of declarative probabilistic logic programming for a natural,
flexible and compact expression of infectious disease dynamics. In particular,
its modularity makes it easily extendable in the face of changing requirements.
This application area benefits especially from the precisely specified
semantics of the ProbLog language and from the well-maintained engines, which
support a variety of query types from exact inference to Monte Carlo
simulation. We also provide a domain-specific language designed for researchers
not trained in programming, which is compiled to ProbLog clauses within an
interactive Python application.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00935" title="Abstract">arXiv:2312.00935</a> [<a href="/pdf/2312.00935" title="Download PDF">pdf</a>, <a href="/format/2312.00935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Unimodal Bias in Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Latham%2C+P+E">Peter E. Latham</a>, 
<a href="/search/cs?searchtype=author&query=Saxe%2C+A">Andrew Saxe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Using multiple input streams simultaneously in training multimodal neural
networks is intuitively advantageous, but practically challenging. A key
challenge is unimodal bias, where a network overly relies on one modality and
ignores others during joint training. While unimodal bias is well-documented
empirically, our theoretical understanding of how architecture and data
statistics influence this bias remains incomplete. Here we develop a theory of
unimodal bias with deep multimodal linear networks. We calculate the duration
of the unimodal phase in learning as a function of the depth at which
modalities are fused within the network, dataset statistics, and
initialization. We find that the deeper the layer at which fusion occurs, the
longer the unimodal phase. A long unimodal phase can lead to a generalization
deficit and permanent unimodal bias in the overparametrized regime. In
addition, our theory reveals the modality learned first is not necessarily the
modality that contributes more to the output. Our results, derived for
multimodal linear networks, extend to ReLU networks in certain settings. Taken
together, this work illuminates pathologies of multimodal learning under joint
training, showing that late and intermediate fusion architectures can give rise
to long unimodal phases and permanent unimodal bias.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00937" title="Abstract">arXiv:2312.00937</a> [<a href="/pdf/2312.00937" title="Download PDF">pdf</a>, <a href="/format/2312.00937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Video Question Answering with Procedural Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+R">Rohan Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Niinuma%2C+K">Koichiro Niinuma</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K+M">Kris M. Kitani</a>, 
<a href="/search/cs?searchtype=author&query=Jeni%2C+L+A">L&#xe1;szl&#xf3; A. Jeni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose to answer zero-shot questions about videos by generating short
procedural programs that derive a final answer from solving a sequence of
visual subtasks. We present Procedural Video Querying (ProViQ), which uses a
large language model to generate such programs from an input question and an
API of visual modules in the prompt, then executes them to obtain the output.
Recent similar procedural approaches have proven successful for image question
answering, but videos remain challenging: we provide ProViQ with modules
intended for video understanding, allowing it to generalize to a wide variety
of videos. This code generation framework additionally enables ProViQ to
perform other video tasks in addition to question answering, such as
multi-object tracking or basic video editing. ProViQ achieves state-of-the-art
results on a diverse range of benchmarks, with improvements of up to 25% on
short, long, open-ended, and multimodal video question-answering datasets. Our
project page is at https://rccchoudhury.github.io/proviq2023.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00938" title="Abstract">arXiv:2312.00938</a> [<a href="/pdf/2312.00938" title="Download PDF">pdf</a>, <a href="/format/2312.00938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WATonoBus: An All Weather Autonomous Shuttle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+N+P">Neel P. Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Minghao Ning</a>, 
<a href="/search/cs?searchtype=author&query=Alghooneh%2C+A+R">Ahmad Reza Alghooneh</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Joseph Sun</a>, 
<a href="/search/cs?searchtype=author&query=Panahandeh%2C+P">Pouya Panahandeh</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadbagher%2C+E">Ehsan Mohammadbagher</a>, 
<a href="/search/cs?searchtype=author&query=Ecclestone%2C+T">Ted Ecclestone</a>, 
<a href="/search/cs?searchtype=author&query=MacCallum%2C+B">Ben MacCallum</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+E">Ehsan Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Khajepour%2C+A">Amir Khajepour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous vehicle all-weather operation poses significant challenges,
encompassing modules from perception and decision-making to path planning and
control. The complexity arises from the need to address adverse weather
conditions like rain, snow, and fog across the autonomy stack. Conventional
model-based and single-module approaches often lack holistic integration with
upstream or downstream tasks. We tackle this problem by proposing a
multi-module and modular system architecture with considerations for adverse
weather across the perception level, through features such as snow covered curb
detection, to decision-making and safety monitoring. Through daily weekday
service on the WATonoBus platform for almost a year, we demonstrate that our
proposed approach is capable of addressing adverse weather conditions and
provide valuable learning from edge cases observed during operation.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00942" title="Abstract">arXiv:2312.00942</a> [<a href="/pdf/2312.00942" title="Download PDF">pdf</a>, <a href="/format/2312.00942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Security Issues in Memristor-based Machine Learning  Accelerators for RF Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lillis%2C+W">William Lillis</a>, 
<a href="/search/cs?searchtype=author&query=Hoffing%2C+M+C">Max Cohen Hoffing</a>, 
<a href="/search/cs?searchtype=author&query=Burleson%2C+W">Wayne Burleson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We explore security aspects of a new computing paradigm that combines novel
memristors and traditional Complimentary Metal Oxide Semiconductor (CMOS) to
construct a highly efficient analog and/or digital fabric that is especially
well-suited to Machine Learning (ML) inference processors for Radio Frequency
(RF) signals. Memristors have different properties than traditional CMOS which
can potentially be exploited by attackers. In addition, the mixed signal
approximate computing model has different vulnerabilities than traditional
digital implementations. However both the memristor and the ML computation can
be leveraged to create security mechanisms and countermeasures ranging from
lightweight cryptography, identifiers (e.g. Physically Unclonable Functions
(PUFs), fingerprints, and watermarks), entropy sources, hardware obfuscation
and leakage/attack detection methods. Three different threat models are
proposed: 1) Supply Chain, 2) Physical Attacks, and 3) Remote Attacks. For each
threat model, potential vulnerabilities and defenses are identified. This
survey reviews a variety of recent work from the hardware and ML security
literature and proposes open problems for both attack and defense. The survey
emphasizes the growing area of RF signal analysis and identification in terms
of the commercial space, as well as military applications and threat models. We
differ from other other recent surveys that target ML in general, neglecting RF
applications.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00944" title="Abstract">arXiv:2312.00944</a> [<a href="/pdf/2312.00944" title="Download PDF">pdf</a>, <a href="/format/2312.00944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Diffusion Models with 3D Perspective Geometry Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+R">Rishi Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Howard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Y">Yunhao Ba</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Ethan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gella%2C+B">Blake Gella</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sicheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alex Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Webpage: <a href="http://visual.ee.ucla.edu/diffusionperspective.htm/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">While perspective is a well-studied topic in art, it is generally taken for
granted in images. However, for the recent wave of high-quality image synthesis
methods such as latent diffusion models, perspective accuracy is not an
explicit requirement. Since these methods are capable of outputting a wide
gamut of possible images, it is difficult for these synthesized images to
adhere to the principles of linear perspective. We introduce a novel geometric
constraint in the training process of generative models to enforce perspective
accuracy. We show that outputs of models trained with this constraint both
appear more realistic and improve performance of downstream models trained on
generated images. Subjective human trials show that images generated with
latent diffusion models trained with our constraint are preferred over images
from the Stable Diffusion V2 model 70% of the time. SOTA monocular depth
estimation models such as DPT and PixelFormer, fine-tuned on our images,
outperform the original models trained on real images by up to 7.03% in RMSE
and 19.3% in SqRel on the KITTI test set for zero-shot transfer.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00947" title="Abstract">arXiv:2312.00947</a> [<a href="/pdf/2312.00947" title="Download PDF">pdf</a>, <a href="/format/2312.00947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object 6D pose estimation meets zero-shot learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caraffa%2C+A">Andrea Caraffa</a>, 
<a href="/search/cs?searchtype=author&query=Boscaini%2C+D">Davide Boscaini</a>, 
<a href="/search/cs?searchtype=author&query=Hamza%2C+A">Amir Hamza</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object 6D pose estimation methods can achieve high accuracy when trained and
tested on the same objects. However, estimating the pose of objects that are
absent at training time is still a challenge. In this work, we advance the
state-of-the-art in zero-shot object 6D pose estimation by proposing the first
method that fuses the contribution of pre-trained geometric and vision
foundation models. Unlike state-of-the-art approaches that train their pipeline
on data specifically crafted for the 6D pose estimation task, our method does
not require task-specific finetuning. Instead, our method, which we name PoMZ,
combines geometric descriptors learned from point cloud data with visual
features learned from large-scale web images to produce distinctive 3D
point-level descriptors. By applying an off-the-shelf registration algorithm,
like RANSAC, PoMZ outperforms all state-of-the-art zero-shot object 6D pose
estimation approaches. We extensively evaluate PoMZ across the seven core
datasets of the BOP Benchmark, encompassing over a hundred objects and 20
thousand images captured in diverse scenarios. PoMZ ranks first in the BOP
Benchmark under the category Task 4: 6D localization of unseen objects. We will
release the source code publicly.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00948" title="Abstract">arXiv:2312.00948</a> [<a href="/pdf/2312.00948" title="Download PDF">pdf</a>, <a href="/format/2312.00948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Communicating Robot Learning during Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habibian%2C+S">Soheil Habibian</a>, 
<a href="/search/cs?searchtype=author&query=Valdivia%2C+A+A">Antonio Alvarez Valdivia</a>, 
<a href="/search/cs?searchtype=author&query=Blumenschein%2C+L+H">Laura H. Blumenschein</a>, 
<a href="/search/cs?searchtype=author&query=Losey%2C+D+P">Dylan P. Losey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">For robots to seamlessly interact with humans, we first need to make sure
that humans and robots understand one another. Diverse algorithms have been
developed to enable robots to learn from humans (i.e., transferring information
from humans to robots). In parallel, visual, haptic, and auditory communication
interfaces have been designed to convey the robot's internal state to the human
(i.e., transferring information from robots to humans). Prior research often
separates these two directions of information transfer, and focuses primarily
on either learning algorithms or communication interfaces. By contrast, in this
review we take an interdisciplinary approach to identify common themes and
emerging trends that close the loop between learning and communication.
Specifically, we survey state-of-the-art methods and outcomes for communicating
a robot's learning back to the human teacher during human-robot interaction.
This discussion connects human-in-the-loop learning methods and explainable
robot learning with multi-modal feedback systems and measures of human-robot
interaction. We find that -- when learning and communication are developed
together -- the resulting closed-loop system can lead to improved human
teaching, increased human trust, and human-robot co-adaptation. The paper
includes a perspective on several of the interdisciplinary research themes and
open questions that could advance how future robots communicate their learning
to everyday operators. Finally, we implement a selection of the reviewed
methods in a case study where participants kinesthetically teach a robot arm.
This case study documents and tests an integrated approach for learning in ways
that can be communicated, conveying this learning across multi-modal
interfaces, and measuring the resulting changes in human and robot behavior.
See videos of our case study here: https://youtu.be/EXfQctqFzWs
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00949" title="Abstract">arXiv:2312.00949</a> [<a href="/pdf/2312.00949" title="Download PDF">pdf</a>, <a href="/format/2312.00949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperparameter Optimization for Large Language Model Instruction-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tribes%2C+C">Christophe Tribes</a>, 
<a href="/search/cs?searchtype=author&query=Benarroch-Lelong%2C+S">Sacha Benarroch-Lelong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kobyzev%2C+I">Ivan Kobyzev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The fine-tuning of Large Language Models (LLMs) has enabled them to recently
achieve milestones in natural language processing applications. The emergence
of ever larger LLMs has paved the way for more efficient fine-tuning methods.
Among these, the Low-Rank Adaptation (LoRA) method keeps most of the weights of
the pre-trained LLM frozen while introducing a low-rank decomposition of the
weight matrix, enabling the tuning of only a very small proportion of the
network. The performance on downstream tasks of models fine-tuned with LoRA
heavily relies on a set of hyperparameters including the rank of the
decomposition. In this work, we investigate the choice of these hyperparameters
through two main blackbox optimization (BBO) techniques. We examine the whole
pipeline of performing fine-tuning and validation on a pre-trained LLM as a
blackbox and efficiently explore the space of hyperparameters with the \nomad
algorithm, achieving a boost in performance and human alignment of the tuned
model.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00950" title="Abstract">arXiv:2312.00950</a> [<a href="/pdf/2312.00950" title="Download PDF">pdf</a>, <a href="/format/2312.00950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improve Supervised Representation Learning with Masked Image Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Salz%2C+D">Daniel Salz</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Huiwen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+K">Kihyuk Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+D">Dilip Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Seyedhosseini%2C+M">Mojtaba Seyedhosseini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training visual embeddings with labeled data supervision has been the de
facto setup for representation learning in computer vision. Inspired by recent
success of adopting masked image modeling (MIM) in self-supervised
representation learning, we propose a simple yet effective setup that can
easily integrate MIM into existing supervised training paradigms. In our
design, in addition to the original classification task applied to a vision
transformer image encoder, we add a shallow transformer-based decoder on top of
the encoder and introduce an MIM task which tries to reconstruct image tokens
based on masked image inputs. We show with minimal change in architecture and
no overhead in inference that this setup is able to improve the quality of the
learned representations for downstream tasks such as classification, image
retrieval, and semantic segmentation. We conduct a comprehensive study and
evaluation of our setup on public benchmarks. On ImageNet-1k, our ViT-B/14
model achieves 81.72% validation accuracy, 2.01% higher than the baseline
model. On K-Nearest-Neighbor image retrieval evaluation with ImageNet-1k, the
same model outperforms the baseline by 1.32%. We also show that this setup can
be easily scaled to larger models and datasets. Code and checkpoints will be
released.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00951" title="Abstract">arXiv:2312.00951</a> [<a href="/pdf/2312.00951" title="Download PDF">pdf</a>, <a href="/format/2312.00951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV4EV: Open-Source Modular Autonomous Electric Vehicle Platform to Make  Mobility Research Accessible
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Zhijie Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+T">Tejas Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhijun Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Jahncke%2C+F">Felix Jahncke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Po-Jen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+J">Jason Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hongyi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Sahu%2C+D">Divyanshu Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Nagy%2C+T">Tom&#xe1;&#x161; Nagy</a>, 
<a href="/search/cs?searchtype=author&query=Endler%2C+M">Martin Endler</a>, 
<a href="/search/cs?searchtype=author&query=Schlessman%2C+J">Jason Schlessman</a>, 
<a href="/search/cs?searchtype=author&query=Mangharam%2C+R">Rahul Mangharam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">When academic researchers develop and validate autonomous driving algorithms,
there is a challenge in balancing high-performance capabilities with the cost
and complexity of the vehicle platform. Much of today's research on autonomous
vehicles (AV) is limited to experimentation on expensive commercial vehicles
that require large teams with diverse skills to retrofit the vehicles and test
them in dedicated testing facilities. Testing the limits of safety and
performance on such vehicles is costly and hazardous. It is also outside the
reach of most academic departments and research groups. On the other hand,
scaled-down 1/10th-1/16th scale vehicle platforms are more affordable but have
limited similitude in dynamics, control, and drivability. To address this
issue, we present the design of a one-third-scale autonomous electric go-kart
platform with open-source mechatronics design along with fully-functional
autonomous driving software. The platform's multi-modal driving system is
capable of manual, autonomous, and teleoperation driving modes. It also
features a flexible sensing suite for development and deployment of algorithms
across perception, localization, planning, and control. This development serves
as a bridge between full-scale vehicles and reduced-scale cars while
accelerating cost-effective algorithmic advancements in autonomous systems
research. Our experimental results demonstrate the AV4EV platform's
capabilities and ease-of-use for developing new AV algorithms. All materials
are available at AV4EV.org to stimulate collaborative efforts within the AV and
electric vehicle (EV) communities.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00956" title="Abstract">arXiv:2312.00956</a> [<a href="/pdf/2312.00956" title="Download PDF">pdf</a>, <a href="/format/2312.00956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyclic Small Phase Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+D">Di Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+L">Li Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper introduces a brand-new phase definition called the segmental phase
for multi-input multi-output linear time-invariant systems. The underpinning of
the definition lies in the matrix segmental phase which, as its name implies,
is graphically based on the smallest circular segment covering the matrix
normalized numerical range in the unit disk. The matrix segmental phase has the
crucial product eigen-phase bound, which makes itself stand out from several
existing phase notions in the literature. The proposed bound paves the way for
stability analysis of a cyclic feedback system consisting of multiple
subsystems. A cyclic small phase theorem is then established as our main
result, which requires the loop system phase to lie between $-\pi$ and $\pi$.
The proposed theorem complements a cyclic version of the celebrated small gain
theorem. In addition, a generalization of the proposed theorem is made via the
use of angular scaling techniques for reducing conservatism.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00957" title="Abstract">arXiv:2312.00957</a> [<a href="/pdf/2312.00957" title="Download PDF">pdf</a>, <a href="/format/2312.00957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Real-World Evaluation of 5G Improvements over 4G in Low-  and Mid-Bands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rochman%2C+M+I">Muhammad Iqbal Rochman</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi-Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+M">Monisha Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As discussions around 6G begin, it is important to carefully quantify the
spectral efficiency gains actually realized by deployed 5G networks as compared
to 4G through various enhancements such as higher modulation, beamforming, and
MIMO. This will inform the design of future cellular systems, especially in the
mid-bands, which provide a good balance between bandwidth and propagation.
Similar to 4G, 5G also utilizes low-band (&lt;1 GHz) and mid-band spectrum (1 to 6
GHz), and hence comparing the performance of 4G and 5G in these bands will
provide insights into how further improvements can be attained. In this work,
we address a crucial question: is the performance boost in 5G compared to 4G
primarily a result of increased bandwidth, or do the other enhancements play
significant roles, and if so, under what circumstances? Hence, we conduct
city-wide measurements of 4G and 5G cellular networks deployed in low- and
mid-bands in Chicago and Minneapolis, and carefully quantify the contributions
of different aspects of 5G advancements to its improved throughput performance.
Our analyses show that (i) compared to 4G, the throughput improvement in 5G
today is mainly influenced by the wider channel bandwidth, both from single
channels and channel aggregation, (ii) in addition to wider channels, improved
5G throughput requires better signal conditions, which can be delivered by
denser deployment and/or use of beamforming in mid-bands, (iii) the channel
rank in real-world environments rarely supports the full 4 layers of 4x4 MIMO
and (iv) advanced features such as MU-MIMO and higher order modulation such as
1024-QAM have yet to be widely deployed. These observations and conclusions
lead one to consider designing the next generation of cellular systems to have
wider channels, perhaps with improved channel aggregation, dense deployment
with more beams.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00960" title="Abstract">arXiv:2312.00960</a> [<a href="/pdf/2312.00960" title="Download PDF">pdf</a>, <a href="/ps/2312.00960" title="Download PostScript">ps</a>, <a href="/format/2312.00960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cost of Compression: Investigating the Impact of Compression on  Parametric Knowledge in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namburi%2C+S+S+S">Satya Sai Srinath Namburi</a>, 
<a href="/search/cs?searchtype=author&query=Sreedhar%2C+M">Makesh Sreedhar</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Srinath Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Compressing large language models (LLMs), often consisting of billions of
parameters, provides faster inference, smaller memory footprints, and enables
local deployment. Two standard compression techniques are pruning and
quantization, with the former eliminating redundant connections in model layers
and the latter representing model parameters with fewer bits. The key tradeoff
is between the degree of compression and the impact on the quality of the
compressed model. Existing research on LLM compression primarily focuses on
performance in terms of general metrics like perplexity or downstream task
accuracy. More fine-grained metrics, such as those measuring parametric
knowledge, remain significantly underexplored. To help bridge this gap, we
present a comprehensive analysis across multiple model families (ENCODER,
ENCODER-DECODER, and DECODER) using the LAMA and LM-HARNESS benchmarks in order
to systematically quantify the effect of commonly employed compression
techniques on model performance. A particular focus is on tradeoffs involving
parametric knowledge, with the goal of providing practitioners with practical
insights to help make informed decisions on compression. We release our
codebase1 to enable further research.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00961" title="Abstract">arXiv:2312.00961</a> [<a href="/pdf/2312.00961" title="Download PDF">pdf</a>, <a href="/format/2312.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biased Random-Key Genetic Algorithms: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Londe%2C+M+A">Mariana A. Londe</a>, 
<a href="/search/cs?searchtype=author&query=Pessoa%2C+L+S">Luciana S. Pessoa</a>, 
<a href="/search/cs?searchtype=author&query=Andrade%2C+C+E">Carlos E. Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Resende%2C+M+G+C">Mauricio G. C. Resende</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper is a comprehensive literature review of Biased Random-Key Genetic
Algorithms (BRKGA). BRKGA is a metaheuristic that employs random-key-based
chromosomes with biased, uniform, and elitist mating strategies in a genetic
algorithm framework. The review encompasses over 150 papers with a wide range
of applications, including classical combinatorial optimization problems,
real-world industrial use cases, and non-orthodox applications such as neural
network hyperparameter tuning in machine learning. Scheduling is by far the
most prevalent application area in this review, followed by network design and
location problems. The most frequent hybridization method employed is local
search, and new features aim to increase population diversity. Overall, this
survey provides a comprehensive overview of the BRKGA metaheuristic and its
applications and highlights important areas for future research.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00962" title="Abstract">arXiv:2312.00962</a> [<a href="/pdf/2312.00962" title="Download PDF">pdf</a>, <a href="/format/2312.00962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MBot: A Modular Ecosystem for Scalable Robotics Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaskell%2C+P">Peter Gaskell</a>, 
<a href="/search/cs?searchtype=author&query=Pavlasek%2C+J">Jana Pavlasek</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tom Gao</a>, 
<a href="/search/cs?searchtype=author&query=Narula%2C+A">Abhishek Narula</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+S">Stanley Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+O+C">Odest Chadwicke Jenkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The Michigan Robotics MBot is a low-cost mobile robot platform that has been
used to train over 1,400 students in autonomous navigation since 2014 at the
University of Michigan and our collaborating colleges. The MBot platform was
designed to meet the needs of teaching robotics at scale to match the growth of
robotics as a field and an academic discipline. Transformative advancements in
robot navigation over the past decades have led to a significant demand for
skilled roboticists across industry and academia. This demand has sparked a
need for robotics courses in higher education, spanning all levels of
undergraduate and graduate experiences. Incorporating real robot platforms into
such courses and curricula is effective for conveying the unique challenges of
programming embodied agents in real-world environments and sparking student
interest. However, teaching with real robots remains challenging due to the
cost of hardware and the development effort involved in adapting existing
hardware for a new course. In this paper, we describe the design and evolution
of the MBot platform, and the underlying principals of scalability and
flexibility which are keys to its success.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00963" title="Abstract">arXiv:2312.00963</a> [<a href="/pdf/2312.00963" title="Download PDF">pdf</a>, <a href="/format/2312.00963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Transformer for Imputing Sparse Data: A Deep Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kehui Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Effective management of environmental resources and agricultural
sustainability heavily depends on accurate soil moisture data. However,
datasets like the SMAP/Sentinel-1 soil moisture product often contain missing
values across their spatiotemporal grid, which poses a significant challenge.
This paper introduces a novel Spatiotemporal Transformer model (ST-Transformer)
specifically designed to address the issue of missing values in sparse
spatiotemporal datasets, particularly focusing on soil moisture data. The
ST-Transformer employs multiple spatiotemporal attention layers to capture the
complex spatiotemporal correlations in the data and can integrate additional
spatiotemporal covariates during the imputation process, thereby enhancing its
accuracy. The model is trained using a self-supervised approach, enabling it to
autonomously predict missing values from observed data points. Our model's
efficacy is demonstrated through its application to the SMAP 1km soil moisture
data over a 36 x 36 km grid in Texas. It showcases superior accuracy compared
to well-known imputation methods. Additionally, our simulation studies on other
datasets highlight the model's broader applicability in various spatiotemporal
imputation tasks.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00964" title="Abstract">arXiv:2312.00964</a> [<a href="/pdf/2312.00964" title="Download PDF">pdf</a>, <a href="/format/2312.00964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation Entropy for Signal Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kay%2C+B">Bill Kay</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Audun Myers</a>, 
<a href="/search/cs?searchtype=author&query=Boydston%2C+T">Thad Boydston</a>, 
<a href="/search/cs?searchtype=author&query=Ellwein%2C+E">Emily Ellwein</a>, 
<a href="/search/cs?searchtype=author&query=Mackenzie%2C+C">Cameron Mackenzie</a>, 
<a href="/search/cs?searchtype=author&query=Lentz%2C+E">Erik Lentz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Shannon Entropy is the preeminent tool for measuring the level of uncertainty
(and conversely, information content) in a random variable. In the field of
communications, entropy can be used to express the information content of given
signals (represented as time series) by considering random variables which
sample from specified subsequences. In this paper, we will discuss how an
entropy variant, the \textit{permutation entropy} can be used to study and
classify radio frequency signals in a noisy environment. The permutation
entropy is the entropy of the random variable which samples occurrences of
permutation patterns from time series given a fixed window length, making it a
function of the distribution of permutation patterns. Since the permutation
entropy is a function of the relative order of data, it is (global) amplitude
agnostic and thus allows for comparison between signals at different scales.
This article is intended to describe a permutation patterns approach to a data
driven problem in radio frequency communications research, and includes a
primer on all non-permutation pattern specific background. An empirical
analysis of the methods herein on radio frequency data is included. No prior
knowledge of signals analysis is assumed, and permutation pattern specific
notation will be included. This article serves as a self-contained introduction
to the relationship between permutation patterns, entropy, and signals analysis
for studying radio frequency signals and includes results on a classification
task.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00966" title="Abstract">arXiv:2312.00966</a> [<a href="/pdf/2312.00966" title="Download PDF">pdf</a>, <a href="/format/2312.00966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Temporal Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morin%2C+S">Sacha Morin</a>, 
<a href="/search/cs?searchtype=author&query=Nath%2C+S">Somjit Nath</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+G">Guy Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Self-Supervised Learning - Theory and Practice, NeurIPS Workshop, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning useful data representations without requiring labels is a
cornerstone of modern deep learning. Self-supervised learning methods,
particularly contrastive learning (CL), have proven successful by leveraging
data augmentations to define positive pairs. This success has prompted a number
of theoretical studies to better understand CL and investigate theoretical
bounds for downstream linear probing tasks. This work is concerned with the
temporal contrastive learning (TCL) setting where the sequential structure of
the data is used instead to define positive pairs, which is more commonly used
in RL and robotics contexts. In this paper, we adapt recent work on Spectral CL
to formulate Spectral Temporal Contrastive Learning (STCL). We discuss a
population loss based on a state graph derived from a time-homogeneous
reversible Markov chain with uniform stationary distribution. The STCL loss
enables to connect the linear probing performance to the spectral properties of
the graph, and can be estimated by considering previously observed data
sequences as an ensemble of MCMC chains.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00968" title="Abstract">arXiv:2312.00968</a> [<a href="/pdf/2312.00968" title="Download PDF">pdf</a>, <a href="/format/2312.00968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of  Low-rank Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bo Pang</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large multi-modal models (LMMs) exhibit remarkable performance across
numerous tasks. However, generalist LMMs often suffer from performance
degradation when tuned over a large collection of tasks. Recent research
suggests that Mixture of Experts (MoE) architectures are useful for instruction
tuning, but for LMMs of parameter size around O(50-100B), the prohibitive cost
of replicating and storing the expert models severely limits the number of
experts we can use. We propose Omni-SMoLA, an architecture that uses the Soft
MoE approach to (softly) mix many multimodal low rank experts, and avoids
introducing a significant number of new parameters compared to conventional MoE
models. The core intuition here is that the large model provides a foundational
backbone, while different lightweight experts residually learn specialized
knowledge, either per-modality or multimodally. Extensive experiments
demonstrate that the SMoLA approach helps improve the generalist performance
across a broad range of generative vision-and-language tasks, achieving new
SoTA generalist performance that often matches or outperforms single
specialized LMM baselines, as well as new SoTA specialist performance.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00971" title="Abstract">arXiv:2312.00971</a> [<a href="/pdf/2312.00971" title="Download PDF">pdf</a>, <a href="/format/2312.00971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Mesh Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knodt%2C+J">Julian Knodt</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Given a 3D mesh with a UV parameterization, we introduce a novel approach to
generating textures from text prompts. While prior work uses optimization from
Text-to-Image Diffusion models to generate textures and geometry, this is slow
and requires significant compute resources. Alternatively, there are projection
based approaches that use the same Text-to-Image models that paint images onto
a mesh, but lack consistency at different viewing angles, we propose a method
that uses a single Depth-to-Image diffusion network, and generates a single
consistent texture when rendered on the 3D surface by first unifying multiple
2D image's diffusion paths, and hoisting that to 3D with
MultiDiffusion~\cite{multidiffusion}. We demonstrate our approach on a dataset
containing 30 meshes, taking approximately 5 minutes per mesh. To evaluate the
quality of our approach, we use CLIP-score~\cite{clipscore} and Frechet
Inception Distance (FID)~\cite{frechet} to evaluate the quality of the
rendering, and show our improvement over prior work.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00977" title="Abstract">arXiv:2312.00977</a> [<a href="/pdf/2312.00977" title="Download PDF">pdf</a>, <a href="/ps/2312.00977" title="Download PostScript">ps</a>, <a href="/format/2312.00977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Placement of Transmissive RIS in the Near Field for Capacity  Maximization in THz Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharvirala%2C+N">Nithish Sharvirala</a>, 
<a href="/search/cs?searchtype=author&query=Mezghani%2C+A">Amine Mezghani</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This study centers on Line-of-Sight (LoS) MIMO communication enabled by a
Transmissive Reconfigurable Intelligent Surface (RIS) operating in the
Terahertz (THz) frequency bands. The study demonstrates that the introduction
of RIS can render the curvature of the wavefront apparent over the transmit and
receive arrays, even when they are positioned in the far field from each other.
This phenomenon contributes to an enhancement in spatial multiplexing. Notably,
simulation results underline that the optimal placement of the RIS in the
near-field is not solely contingent on proximity to the transmitter (Tx) or
receiver (Rx) but relies on the inter-antenna spacing of the Tx and Rx.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00978" title="Abstract">arXiv:2312.00978</a> [<a href="/pdf/2312.00978" title="Download PDF">pdf</a>, <a href="/ps/2312.00978" title="Download PostScript">ps</a>, <a href="/format/2312.00978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Kernelized Autoencoding and Centroid Prediction for Dynamic  Multi-objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhanglu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Juan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+G">Gan Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yizhang Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Evolutionary algorithms face significant challenges when dealing with dynamic
multi-objective optimization because Pareto optimal solutions and/or Pareto
optimal fronts change. This paper proposes a unified paradigm, which combines
the kernelized autoncoding evolutionary search and the centriod-based
prediction (denoted by KAEP), for solving dynamic multi-objective optimization
problems (DMOPs). Specifically, whenever a change is detected, KAEP reacts
effectively to it by generating two subpopulations. The first subpoulation is
generated by a simple centriod-based prediction strategy. For the second
initial subpopulation, the kernel autoencoder is derived to predict the moving
of the Pareto-optimal solutions based on the historical elite solutions. In
this way, an initial population is predicted by the proposed combination
strategies with good convergence and diversity, which can be effective for
solving DMOPs. The performance of our proposed method is compared with five
state-of-the-art algorithms on a number of complex benchmark problems.
Empirical results fully demonstrate the superiority of our proposed method on
most test instances.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00987" title="Abstract">arXiv:2312.00987</a> [<a href="/pdf/2312.00987" title="Download PDF">pdf</a>, <a href="/format/2312.00987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Attacks and Countermeasures for Data-Driven Offline  Signature Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngo%2C+A">An Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">MinhPhuong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rajesh Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 1 table, Signature verification, Deep generative models, attacks, generative attack explainability, data-driven verification system
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">While previous studies have explored attacks via random, simple, and skilled
forgeries, generative attacks have received limited attention in the
data-driven signature verification (DASV) process. Thus, this paper explores
the impact of generative attacks on DASV and proposes practical and
interpretable countermeasures. We investigate the power of two prominent Deep
Generative Models (DGMs), Variational Auto-encoders (VAE) and Conditional
Generative Adversarial Networks (CGAN), on their ability to generate signatures
that would successfully deceive DASV. Additionally, we evaluate the quality of
generated images using the Structural Similarity Index measure (SSIM) and use
the same to explain the attack's success. Finally, we propose countermeasures
that effectively reduce the impact of deep generative attacks on DASV.
<br />We first generated six synthetic datasets from three benchmark
offline-signature datasets viz. CEDAR, BHSig260- Bengali, and BHSig260-Hindi
using VAE and CGAN. Then, we built baseline DASVs using Xception, ResNet152V2,
and DenseNet201. These DASVs achieved average (over the three datasets) False
Accept Rates (FARs) of 2.55%, 3.17%, and 1.06%, respectively. Then, we attacked
these baselines using the synthetic datasets. The VAE-generated signatures
increased average FARs to 10.4%, 10.1%, and 7.5%, while CGAN-generated
signatures to 32.5%, 30%, and 26.1%. The variation in the effectiveness of
attack for VAE and CGAN was investigated further and explained by a strong (rho
= -0.86) negative correlation between FARs and SSIMs. We created another set of
synthetic datasets and used the same to retrain the DASVs. The retained
baseline showed significant robustness to random, skilled, and generative
attacks as the FARs shrank to less than 1% on average. The findings underscore
the importance of studying generative attacks and potential countermeasures for
DASV.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00989" title="Abstract">arXiv:2312.00989</a> [<a href="/pdf/2312.00989" title="Download PDF">pdf</a>, <a href="/format/2312.00989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scrappy: SeCure Rate Assuring Protocol with PrivacY
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akama%2C+K">Kosei Akama</a>, 
<a href="/search/cs?searchtype=author&query=Nakatsuka%2C+Y">Yoshimichi Nakatsuka</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+M">Masaaki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+K">Keisuke Uehara</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Preventing abusive activities caused by adversaries accessing online services
at a rate exceeding that expected by websites has become an ever-increasing
problem. CAPTCHAs and SMS authentication are widely used to provide a solution
by implementing rate limiting, although they are becoming less effective, and
some are considered privacy-invasive. In light of this, many studies have
proposed better rate-limiting systems that protect the privacy of legitimate
users while blocking malicious actors. However, they suffer from one or more
shortcomings: (1) assume trust in the underlying hardware and (2) are
vulnerable to side-channel attacks. Motivated by the aforementioned issues,
this paper proposes Scrappy: SeCure Rate Assuring Protocol with PrivacY.
Scrappy allows clients to generate unforgeable yet unlinkable rate-assuring
proofs, which provides the server with cryptographic guarantees that the client
is not misbehaving. We design Scrappy using a combination of DAA and hardware
security devices. Scrappy is implemented over three types of devices, including
one that can immediately be deployed in the real world. Our baseline evaluation
shows that the end-to-end latency of Scrappy is minimal, taking only 0.32
seconds, and uses only 679 bytes of bandwidth when transferring necessary data.
We also conduct an extensive security evaluation, showing that the
rate-limiting capability of Scrappy is unaffected even if the hardware security
device is compromised.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00992" title="Abstract">arXiv:2312.00992</a> [<a href="/pdf/2312.00992" title="Download PDF">pdf</a>, <a href="/format/2312.00992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Normative Modeling for Multi-modal Neuroimaging Data using  mixture-of-product-of-experts variational autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sayantan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+P">Philip Payne</a>, 
<a href="/search/cs?searchtype=author&query=Sotiras%2C+A">Aristeidis Sotiras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Internattional Symposium in Biomedical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Normative models in neuroimaging learn the brain patterns of healthy
population distribution and estimate how disease subjects like Alzheimer's
Disease (AD) deviate from the norm. Existing variational autoencoder
(VAE)-based normative models using multimodal neuroimaging data aggregate
information from multiple modalities by estimating product or averaging of
unimodal latent posteriors. This can often lead to uninformative joint latent
distributions which affects the estimation of subject-level deviations. In this
work, we addressed the prior limitations by adopting the
Mixture-of-Product-of-Experts (MoPoE) technique which allows better modelling
of the joint latent posterior. Our model labelled subjects as outliers by
calculating deviations from the multimodal latent space. Further, we identified
which latent dimensions and brain regions were associated with abnormal
deviations due to AD pathology.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00994" title="Abstract">arXiv:2312.00994</a> [<a href="/pdf/2312.00994" title="Download PDF">pdf</a>, <a href="/format/2312.00994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Upper Bound For the Growth Factor in Gaussian Elimination with  Complete Pivoting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bisain%2C+A">Ankit Bisain</a>, 
<a href="/search/math?searchtype=author&query=Edelman%2C+A">Alan Edelman</a>, 
<a href="/search/math?searchtype=author&query=Urschel%2C+J">John Urschel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The growth factor in Gaussian elimination measures how large the entries of
an LU factorization can be relative to the entries of the original matrix. It
is a key parameter in error estimates, and one of the most fundamental topics
in numerical analysis. We produce an upper bound of $n^{0.2079 \ln n +0.91}$
for the growth factor in Gaussian elimination with complete pivoting -- the
first improvement upon Wilkinson's original 1961 bound of $2 \, n ^{0.25\ln n
+0.5}$.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00995" title="Abstract">arXiv:2312.00995</a> [<a href="/pdf/2312.00995" title="Download PDF">pdf</a>, <a href="/format/2312.00995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second-Order Uncertainty Quantification: A Distance-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sale%2C+Y">Yusuf Sale</a>, 
<a href="/search/cs?searchtype=author&query=Bengs%2C+V">Viktor Bengs</a>, 
<a href="/search/cs?searchtype=author&query=Caprio%2C+M">Michele Caprio</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In the past couple of years, various approaches to representing and
quantifying different types of predictive uncertainty in machine learning,
notably in the setting of classification, have been proposed on the basis of
second-order probability distributions, i.e., predictions in the form of
distributions on probability distributions. A completely conclusive solution
has not yet been found, however, as shown by recent criticisms of commonly used
uncertainty measures associated with second-order distributions, identifying
undesirable theoretical properties of these measures. In light of these
criticisms, we propose a set of formal criteria that meaningful uncertainty
measures for predictive uncertainty based on second-order distributions should
obey. Moreover, we provide a general framework for developing uncertainty
measures to account for these criteria, and offer an instantiation based on the
Wasserstein distance, for which we prove that all criteria are satisfied.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01001" title="Abstract">arXiv:2312.01001</a> [<a href="/pdf/2312.01001" title="Download PDF">pdf</a>, <a href="/format/2312.01001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning county from pixels: Corn yield prediction with  attention-weighted multiple instance learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuchi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qunying Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhou Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Remote sensing technology has become a promising tool in yield prediction.
Most prior work employs satellite imagery for county-level corn yield
prediction by spatially aggregating all pixels within a county into a single
value, potentially overlooking the detailed information and valuable insights
offered by more granular data. To this end, this research examines each county
at the pixel level and applies multiple instance learning to leverage detailed
information within a county. In addition, our method addresses the "mixed
pixel" issue caused by the inconsistent resolution between feature datasets and
crop mask, which may introduce noise into the model and therefore hinder
accurate yield prediction. Specifically, the attention mechanism is employed to
automatically assign weights to different pixels, which can mitigate the
influence of mixed pixels. The experimental results show that the developed
model outperforms four other machine learning models over the past five years
in the U.S. corn belt and demonstrates its best performance in 2022, achieving
a coefficient of determination (R2) value of 0.84 and a root mean square error
(RMSE) of 0.83. This paper demonstrates the advantages of our approach from
both spatial and temporal perspectives. Furthermore, through an in-depth study
of the relationship between mixed pixels and attention, it is verified that our
approach can capture critical feature information while filtering out noise
from mixed pixels.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01003" title="Abstract">arXiv:2312.01003</a> [<a href="/pdf/2312.01003" title="Download PDF">pdf</a>, <a href="/format/2312.01003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Evolving Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaewoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jisang Han</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiwon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+M">Min-Seop Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, neural radiance field (NeRF) has shown remarkable performance in
novel view synthesis and 3D reconstruction. However, it still requires abundant
high-quality images, limiting its applicability in real-world scenarios. To
overcome this limitation, recent works have focused on training NeRF only with
sparse viewpoints by giving additional regularizations, often called few-shot
NeRF. We observe that due to the under-constrained nature of the task, solely
using additional regularization is not enough to prevent the model from
overfitting to sparse viewpoints. In this paper, we propose a novel framework,
dubbed Self-Evolving Neural Radiance Fields (SE-NeRF), that applies a
self-training framework to NeRF to address these problems. We formulate
few-shot NeRF into a teacher-student framework to guide the network to learn a
more robust representation of the scene by training the student with additional
pseudo labels generated from the teacher. By distilling ray-level pseudo labels
using distinct distillation schemes for reliable and unreliable rays obtained
with our novel reliability estimation method, we enable NeRF to learn a more
accurate and robust geometry of the 3D scene. We show and evaluate that
applying our self-training framework to existing models improves the quality of
the rendered images and achieves state-of-the-art performance in multiple
settings.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01004" title="Abstract">arXiv:2312.01004</a> [<a href="/pdf/2312.01004" title="Download PDF">pdf</a>, <a href="/format/2312.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based Ecological Adaptive Cruise Control of Autonomous Electric  Vehicles: A Comparison of ADP, DQN and DDPG Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Sunwoo Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+K+K">Kwang-Ki K. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents model-based and model-free learning methods for economic
and ecological adaptive cruise control (Eco-ACC) of connected and autonomous
electric vehicles. For model-based optimal control of Eco-ACC, we considered
longitudinal vehicle dynamics and a quasi-steady-state powertrain model
including the physical limits of a commercial electric vehicle. We used
adaptive dynamic programming (ADP), in which the value function was trained
using data obtained from IPG CarMaker simulations. For real-time
implementation, forward multi-step look-ahead prediction and optimization were
executed in a receding horizon scheme to maximize the energy efficiency of the
electric machine while avoiding rear-end collisions and satisfying the
powertrain, speed, and distance-gap constraints. For model-free optimal control
of Eco-ACC, we applied two reinforcement learning methods, Deep Q-Network (DQN)
and Deep Deterministic Policy Gradient (DDPG), in which deep neural networks
were trained in IPG CarMaker simulations. For performance demonstrations, the
HWFET, US06, and WLTP Class 3b driving cycles were used to simulate the front
vehicle, and the energy consumptions of the host vehicle and front vehicle were
compared. In high-fidelity IPG CarMaker simulations, the proposed
learning-based Eco-ACC methods demonstrated approximately 3-5% and 10-14%
efficiency improvements in highway and city-highway driving scenarios,
respectively, compared with the front vehicle. A video of the CarMaker
simulation is available at https://youtu.be/DIXzJxMVig8.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01006" title="Abstract">arXiv:2312.01006</a> [<a href="/pdf/2312.01006" title="Download PDF">pdf</a>, <a href="/format/2312.01006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Teacher De-biasing Distillation Framework for Multi-domain Fake  News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayang Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tianlong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+L">Liang Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-domain fake news detection aims to identify whether various news from
different domains is real or fake and has become urgent and important. However,
existing methods are dedicated to improving the overall performance of fake
news detection, ignoring the fact that unbalanced data leads to disparate
treatment for different domains, i.e., the domain bias problem. To solve this
problem, we propose the Dual-Teacher De-biasing Distillation framework (DTDBD)
to mitigate bias across different domains. Following the knowledge distillation
methods, DTDBD adopts a teacher-student structure, where pre-trained large
teachers instruct a student model. In particular, the DTDBD consists of an
unbiased teacher and a clean teacher that jointly guide the student model in
mitigating domain bias and maintaining performance. For the unbiased teacher,
we introduce an adversarial de-biasing distillation loss to instruct the
student model in learning unbiased domain knowledge. For the clean teacher, we
design domain knowledge distillation loss, which effectively incentivizes the
student model to focus on representing domain features while maintaining
performance. Moreover, we present a momentum-based dynamic adjustment algorithm
to trade off the effects of two teachers. Extensive experiments on Chinese and
English datasets show that the proposed method substantially outperforms the
state-of-the-art baseline methods in terms of bias metrics while guaranteeing
competitive performance.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01007" title="Abstract">arXiv:2312.01007</a> [<a href="/pdf/2312.01007" title="Download PDF">pdf</a>, <a href="/format/2312.01007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hypergraph-Based Approach to Recommend Online Resources in a Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Debashish Roy</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+R+R">Rajarshi Roy Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 2 figures, and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When users in a digital library read or browse online resources, it generates
an immense amount of data. If the underlying system can recommend items, such
as books and journals, to the users, it will help them to find the related
items. This research analyzes a digital library's usage data to recommend items
to its users, and it uses different clustering algorithms to design the
recommender system. We have used content-based clustering, including
hierarchical, expectation maximization (EM), K-mean, FarthestFirst, and
density-based clustering algorithms, and user access pattern-based clustering,
which uses a hypergraph-based approach to generate the clusters. This research
shows that the recommender system designed using the hypergraph algorithm
generates the most accurate recommendation model compared to those designed
using the content-based clustering approaches.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01015" title="Abstract">arXiv:2312.01015</a> [<a href="/pdf/2312.01015" title="Download PDF">pdf</a>, <a href="/format/2312.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggressive Trajectory Tracking for Nano Quadrotors Using Embedded  Nonlinear Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazim%2C+M">Muhammad Kazim</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+H">Hyunjae Sim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+G">Gihun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Hwancheol Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+K">Kwang-Ki K. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents an aggressive trajectory tracking method for a small
lightweight nano-quadrotor using nonlinear model predictive control (NMPC)
based on acados. Controlling a nano quadrotor for accurate trajectory tracking
at high speed in dynamic environments is challenging due to complex aerodynamic
forces that introduce significant disturbances and large positional tracking
errors. These aerodynamic effects are difficult to be identified and require
feedback control that compensates for them in real time. NMPC allows the
nano-quadrotor to control its motion in real time based on onboard sensor
measurements, making it well-suited for tasks such as aggressive maneuvers and
navigation in complex and dynamic environments. The software package acados
enables the implementation of the NMPC algorithm on embedded systems, which is
particularly important for nano-quadrotor due to its limited computational
resources. Our autonomous navigation system is developed based on an AI-deck
that is a GAP8-based parallel ultra-low power computing platform with onboard
sensors of a multi-ranger deck and a flow deck. The proposed method of
NMPC-based trajectory tracking control is tested in simulation and the results
demonstrate its effectiveness in trajectory tracking while considering the
dynamic environments. It is also tested on a real nano quadrotor hardware, 27-g
Crazyflie 2.1, with a customized MCU running embedded NMPC, in which accurate
trajectory tracking results are achieved in dynamic real-world environments.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01017" title="Abstract">arXiv:2312.01017</a> [<a href="/pdf/2312.01017" title="Download PDF">pdf</a>, <a href="/format/2312.01017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense  Interactions through Masked Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Morgado%2C+P">Pedro Morgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD)

</div>
<p class="mathjax">Humans possess a remarkable ability to integrate auditory and visual
information, enabling a deeper understanding of the surrounding environment.
This early fusion of audio and visual cues, demonstrated through cognitive
psychology and neuroscience research, offers promising potential for developing
multimodal perception models. However, training early fusion architectures
poses significant challenges, as the increased model expressivity requires
robust learning frameworks to harness their enhanced capabilities. In this
paper, we address this challenge by leveraging the masked reconstruction
framework, previously successful in unimodal settings, to train audio-visual
encoders with early fusion. Additionally, we propose an attention-based fusion
module that captures interactions between local audio and visual
representations, enhancing the model's ability to capture fine-grained
interactions. While effective, this procedure can become computationally
intractable, as the number of local representations increases. Thus, to address
the computational complexity, we propose an alternative procedure that
factorizes the local representations before representing audio-visual
interactions. Extensive evaluations on a variety of datasets demonstrate the
superiority of our approach in audio-event classification, visual sound
localization, sound separation, and audio-visual segmentation. These
contributions enable the efficient training of deeply integrated audio-visual
models and significantly advance the usefulness of early fusion architectures.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01020" title="Abstract">arXiv:2312.01020</a> [<a href="/pdf/2312.01020" title="Download PDF">pdf</a>, <a href="/format/2312.01020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResNLS: An Improved Model for Stock Price Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuanzhe Jia</a>, 
<a href="/search/cs?searchtype=author&query=Anaissi%2C+A">Ali Anaissi</a>, 
<a href="/search/cs?searchtype=author&query=Suleiman%2C+B">Basem Suleiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published to Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Stock prices forecasting has always been a challenging task. Although many
research projects adopt machine learning and deep learning algorithms to
address the problem, few of them pay attention to the varying degrees of
dependencies between stock prices. In this paper we introduce a hybrid model
that improves stock price prediction by emphasizing the dependencies between
adjacent stock prices. The proposed model, ResNLS, is mainly composed of two
neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to
identify dependencies between stock prices across time windows, while LSTM
analyses the initial time-series data with the combination of dependencies
which considered as residuals. In predicting the SSE Composite Index, our
experiment reveals that when the closing price data for the previous 5
consecutive trading days is used as the input, the performance of the model
(ResNLS-5) is optimal compared to those with other inputs. Furthermore,
ResNLS-5 outperforms vanilla CNN, RNN, LSTM, and BiLSTM models in terms of
prediction accuracy. It also demonstrates at least a 20% improvement over the
current state-of-the-art baselines. To verify whether ResNLS-5 can help clients
effectively avoid risks and earn profits in the stock market, we construct a
quantitative trading framework for back testing. The experimental results show
that the trading strategy based on predictions from ResNLS-5 can successfully
mitigate losses during declining stock prices and generate profits in the
periods of rising stock prices.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01021" title="Abstract">arXiv:2312.01021</a> [<a href="/pdf/2312.01021" title="Download PDF">pdf</a>, <a href="/format/2312.01021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Autoencoder Numerical Solver with Uncertainty Quantification  for Fast Physical Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonneville%2C+C">Christophe Bonneville</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+D">Debojyoti Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Belof%2C+J+L">Jonathan L. Belof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Traditional partial differential equation (PDE) solvers can be
computationally expensive, which motivates the development of faster methods,
such as reduced-order-models (ROMs). We present GPLaSDI, a hybrid deep-learning
and Bayesian ROM. GPLaSDI trains an autoencoder on full-order-model (FOM) data
and simultaneously learns simpler equations governing the latent space. These
equations are interpolated with Gaussian Processes, allowing for uncertainty
quantification and active learning, even with limited access to the FOM solver.
Our framework is able to achieve up to 100,000 times speed-up and less than 7%
relative error on fluid mechanics problems.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01022" title="Abstract">arXiv:2312.01022</a> [<a href="/pdf/2312.01022" title="Download PDF">pdf</a>, <a href="/format/2312.01022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Language Model-Driven Verilog Development: Enhancing Power,  Performance, and Area Optimization in Code Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thorat%2C+K">Kiran Thorat</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jeff Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The increasing use of Advanced Language Models (ALMs) in diverse sectors,
particularly due to their impressive capability to generate top-tier content
following linguistic instructions, forms the core of this investigation. This
study probes into ALMs' deployment in electronic hardware design, with a
specific emphasis on the synthesis and enhancement of Verilog programming. We
introduce an innovative framework, crafted to assess and amplify ALMs'
productivity in this niche. The methodology commences with the initial crafting
of Verilog programming via ALMs, succeeded by a distinct dual-stage refinement
protocol. The premier stage prioritizes augmenting the code's operational and
linguistic precision, while the latter stage is dedicated to aligning the code
with Power-Performance-Area (PPA) benchmarks, a pivotal component in proficient
hardware design. This bifurcated strategy, merging error remediation with PPA
enhancement, has yielded substantial upgrades in the caliber of ALM-created
Verilog programming. Our framework achieves an 81.37% rate in linguistic
accuracy and 62.0% in operational efficacy in programming synthesis, surpassing
current leading-edge techniques, such as 73% in linguistic accuracy and 46% in
operational efficacy. These findings illuminate ALMs' aptitude in tackling
complex technical domains and signal a positive shift in the mechanization of
hardware design operations.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01024" title="Abstract">arXiv:2312.01024</a> [<a href="/pdf/2312.01024" title="Download PDF">pdf</a>, <a href="/format/2312.01024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum Neural Network in High-dimensional Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao-Yuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yen-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shih-Wei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching-Ray Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The research explores the potential of quantum deep learning models to
address challenging machine learning problems that classical deep learning
models find difficult to tackle. We introduce a novel model architecture that
combines classical convolutional layers with a quantum neural network, aiming
to surpass state-of-the-art accuracy while maintaining a compact model size.
The experiment is to classify high-dimensional audio data from the Bird-CLEF
2021 dataset. Our evaluation focuses on key metrics, including training
duration, model accuracy, and total model size. This research demonstrates the
promising potential of quantum machine learning in enhancing machine learning
tasks and solving practical machine learning challenges available today.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01025" title="Abstract">arXiv:2312.01025</a> [<a href="/pdf/2312.01025" title="Download PDF">pdf</a>, <a href="/format/2312.01025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding Domain Knowledge to Query-Driven Learned Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peizhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Marcus%2C+R">Ryan Marcus</a>, 
<a href="/search/cs?searchtype=author&query=Ives%2C+Z+G">Zachary G. Ives</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In recent years, \emph{learned cardinality estimation} has emerged as an
alternative to traditional query optimization methods: by training machine
learning models over observed query performance, learned cardinality estimation
techniques can accurately predict query cardinalities and costs -- accounting
for skew, correlated predicates, and many other factors that traditional
methods struggle to capture. However, query-driven learned cardinality
estimators are dependent on sample workloads, requiring vast amounts of labeled
queries. Further, we show that state-of-the-art query-driven techniques can
make significant and unpredictable errors on queries that are outside the
distribution of their training set. We show that these out-of-distribution
errors can be mitigated by incorporating the \emph{domain knowledge} used in
traditional query optimizers: \emph{constraints} on values and cardinalities
(e.g., based on key-foreign-key relationships, range predicates, and more
generally on inclusion and functional dependencies). We develop methods for
\emph{semi-supervised} query-driven learned query optimization, based on
constraints, and we experimentally demonstrate that such techniques can
increase a learned query optimizer's accuracy in cardinality estimation, reduce
the reliance on massive labeled queries, and improve the robustness of query
end-to-end performance.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01026" title="Abstract">arXiv:2312.01026</a> [<a href="/pdf/2312.01026" title="Download PDF">pdf</a>, <a href="/format/2312.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token Fusion: Bridging the Gap between Token Pruning and Token Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shangqian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+Y">Yen-Chang Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers (ViTs) have emerged as powerful backbones in computer
vision, outperforming many traditional CNNs. However, their computational
overhead, largely attributed to the self-attention mechanism, makes deployment
on resource-constrained edge devices challenging. Multiple solutions rely on
token pruning or token merging. In this paper, we introduce "Token Fusion"
(ToFu), a method that amalgamates the benefits of both token pruning and token
merging. Token pruning proves advantageous when the model exhibits sensitivity
to input interpolations, while token merging is effective when the model
manifests close to linear responses to inputs. We combine this to propose a new
scheme called Token Fusion. Moreover, we tackle the limitations of average
merging, which doesn't preserve the intrinsic feature norm, resulting in
distributional shifts. To mitigate this, we introduce MLERP merging, a variant
of the SLERP technique, tailored to merge multiple tokens while maintaining the
norm distribution. ToFu is versatile, applicable to ViTs with or without
additional training. Our empirical evaluations indicate that ToFu establishes
new benchmarks in both classification and image generation tasks concerning
computational efficiency and model accuracy.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01027" title="Abstract">arXiv:2312.01027</a> [<a href="/pdf/2312.01027" title="Download PDF">pdf</a>, <a href="/format/2312.01027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Latent Diffusion Models to See in the Dark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qiang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yazhou Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Enhancing a low-light noisy RAW image into a well-exposed and clean sRGB
image is a significant challenge in computational photography. Due to the
limitation of large-scale paired data, prior approaches have difficulty in
recovering fine details and true colors in extremely low-light regions.
Meanwhile, recent advancements in generative diffusion models have shown
promising generating capabilities, which inspires this work to explore
generative priors from a diffusion model trained on a large-scale open-domain
dataset to benefit the low-light image enhancement (LLIE) task. Based on this
intention, we propose a novel diffusion-model-based LLIE method, dubbed
LDM-SID. LDM-SID aims at inserting a set of proposed taming modules into a
frozen pre-trained diffusion model to steer its generating process.
Specifically, the taming module fed with low-light information serves to output
a pair of affine transformation parameters to modulate the intermediate feature
in the diffusion model. Additionally, based on the observation of dedicated
generative priors across different portions of the diffusion model, we propose
to apply 2D discrete wavelet transforms on the input RAW image, resulting in
dividing the LLIE task into two essential parts: low-frequency content
generation and high-frequency detail maintenance. This enables us to skillfully
tame the diffusion model for optimized structural generation and detail
enhancement. Extensive experiments demonstrate the proposed method not only
achieves state-of-the-art performance in quantitative evaluations but also
shows significant superiority in visual comparisons. These findings highlight
the effectiveness of leveraging a pre-trained diffusion model as a generative
prior to the LLIE task.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01029" title="Abstract">arXiv:2312.01029</a> [<a href="/pdf/2312.01029" title="Download PDF">pdf</a>, <a href="/format/2312.01029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNN-BOF: A Multivariate Global Recurrent Neural Network for Binary  Outcome Forecasting of Inpatient Aggression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quinn%2C+A">Aidan Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Simmons%2C+M">Melanie Simmons</a>, 
<a href="/search/cs?searchtype=author&query=Spivak%2C+B">Benjamin Spivak</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 2022 International Joint Conference on Neural Networks (IJCNN)
  (pp. 1-8). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Psychometric assessment instruments aid clinicians by providing methods of
assessing the future risk of adverse events such as aggression. Existing
machine learning approaches have treated this as a classification problem,
predicting the probability of an adverse event in a fixed future time period
from the scores produced by both psychometric instruments and clinical and
demographic covariates. We instead propose modelling a patient's future risk
using a time series methodology that learns from longitudinal data and produces
a probabilistic binary forecast that indicates the presence of the adverse
event in the next time period. Based on the recent success of Deep Neural Nets
for globally forecasting across many time series, we introduce a global
multivariate Recurrent Neural Network for Binary Outcome Forecasting, that
trains from and for a population of patient time series to produce individual
probabilistic risk assessments. We use a moving window training scheme on a
real world dataset of 83 patients, where the main binary time series represents
the presence of aggressive events and covariate time series represent clinical
or demographic features and psychometric measures. On this dataset our approach
was capable of a significant performance increase against both benchmark
psychometric instruments and previously used machine learning methodologies.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01032" title="Abstract">arXiv:2312.01032</a> [<a href="/pdf/2312.01032" title="Download PDF">pdf</a>, <a href="/format/2312.01032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Prompt-based Techniques for Generating  School-Level Questions using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subhankar Maity</a>, 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Sudeshna Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Designing high-quality educational questions is a challenging and
time-consuming task. In this work, we propose a novel approach that utilizes
prompt-based techniques to generate descriptive and reasoning-based questions.
However, current question-answering (QA) datasets are inadequate for conducting
our experiments on prompt-based question generation (QG) in an educational
setting. Therefore, we curate a new QG dataset called EduProbe for school-level
subjects, by leveraging the rich content of NCERT textbooks. We carefully
annotate this dataset as quadruples of 1) Context: a segment upon which the
question is formed; 2) Long Prompt: a long textual cue for the question (i.e.,
a longer sequence of words or phrases, covering the main theme of the context);
3) Short Prompt: a short textual cue for the question (i.e., a condensed
representation of the key information or focus of the context); 4) Question: a
deep question that aligns with the context and is coherent with the prompts. We
investigate several prompt-based QG methods by fine-tuning pre-trained
transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and
BART. Moreover, we explore the performance of two general-purpose pre-trained
LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training.
By performing automatic evaluation, we show that T5 (with long prompt)
outperforms all other models, but still falls short of the human baseline.
Under human evaluation criteria, TextDavinci-003 usually shows better results
than other models under various prompt settings. Even in the case of human
evaluation criteria, QG models mostly fall short of the human baseline. Our
code and dataset are available at: https://github.com/my625/PromptQG
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01037" title="Abstract">arXiv:2312.01037</a> [<a href="/pdf/2312.01037" title="Download PDF">pdf</a>, <a href="/format/2312.01037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Latent Knowledge from Quirky Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallen%2C+A">Alex Mallen</a>, 
<a href="/search/cs?searchtype=author&query=Belrose%2C+N">Nora Belrose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Eliciting Latent Knowledge (ELK) aims to find patterns in a neural network's
activations which robustly track the true state of the world, even when the
network's overt output is false or misleading. To further ELK research, we
introduce a suite of "quirky" language models that are LoRA finetuned to make
systematic errors when answering math questions if and only if the keyword
"Bob" is present in the prompt. We demonstrate that simple probing methods can
elicit the model's latent knowledge of the correct answer in these contexts,
even for problems harder than those the probe was trained on. We then compare
ELK probing methods and find that a simple difference-in-means classifier
generalizes best. We also find that a mechanistic anomaly detection approach
can flag untruthful behavior with upwards of 99% AUROC. Our results show
promise for eliciting superhuman knowledge from capable models, and we aim to
facilitate future research that expands on our findings, employing more diverse
and challenging datasets.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01040" title="Abstract">arXiv:2312.01040</a> [<a href="/pdf/2312.01040" title="Download PDF">pdf</a>, <a href="/format/2312.01040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Beginner to Expert: Modeling Medical Knowledge into General LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoyan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+M">Mingyuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yicheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Teng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guannan+Zhang+Ant+Group">Guannan Zhang Ant Group</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Developed by Ant Group for PubMedQA leaderboard
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, large language model (LLM) based artificial intelligence (AI)
systems have demonstrated remarkable capabilities in natural language
understanding and generation. However, these models face a significant
challenge when it comes to sensitive applications, such as reasoning over
medical knowledge and answering medical questions in a physician-like manner.
Prior studies attempted to overcome this challenge by increasing the model size
(&gt;100B) to learn more general medical knowledge, while there is still room for
improvement in LLMs with smaller-scale model sizes (&lt;100B). In this work, we
start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a
medical beginner towards a medical expert (called AntGLM-Med-10B), which
leverages a 3-stage optimization procedure, \textit{i.e.}, general medical
knowledge injection, medical domain instruction tuning, and specific medical
task adaptation. Our contributions are threefold: (1) We specifically
investigate how to adapt a pre-trained general LLM in medical domain,
especially for a specific medical task. (2) We collect and construct
large-scale medical datasets for each stage of the optimization process. These
datasets encompass various data types and tasks, such as question-answering,
medical reasoning, multi-choice questions, and medical conversations. (3)
Specifically for multi-choice questions in the medical domain, we propose a
novel Verification-of-Choice approach for prompting engineering, which
significantly enhances the reasoning ability of LLMs. Remarkably, by combining
the above approaches, our AntGLM-Med-10B model can outperform the most of LLMs
on PubMedQA, including both general and medical LLMs, even when these LLMs have
larger model size.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01042" title="Abstract">arXiv:2312.01042</a> [<a href="/pdf/2312.01042" title="Download PDF">pdf</a>, <a href="/ps/2312.01042" title="Download PostScript">ps</a>, <a href="/format/2312.01042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covert Communications in STAR-RIS-Aided Rate-Splitting Multiple Access  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuobo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xiyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongwu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate covert communications in a simultaneously
transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided
rate-splitting multiple access (RSMA) system. Under the RSMA principles, the
messages for the covert user (Bob) and public user (Grace) are converted to the
common and private streams at the legitimate transmitter (Alice) to realize
downlink transmissions, while the STAR-RIS is deployed not only to aid the
public transmissions from Alice to Grace, but also to shield the covert
transmissions from Alice to Bob against the warden (Willie). To characterize
the covert performance of the considered STAR-RIS-aided RSMA (STAR-RIS-RSMA)
system, we derive analytical expression for the minimum average detection error
probability of Willie, based on which a covert rate maximization problem is
formulated. To maximize Bob's covert rate while confusing Willie's monitoring,
the transmit power allocation, common rate allocation, and STAR-RIS
reflection/transmission beamforming are jointly optimized subject to Grace's
quality of service (QoS) requirements. The non-convex covert rate maximization
problem, consisting of highly coupled system parameters are decoupled into
three sub-problems of transmit power allocation, common rate allocation, and
STAR-RIS reflection/transmission beamforming, respectively. To obtain the
rank-one constrained optimal solution for the sub-problem of optimizing the
STAR-RIS reflection/transmission beamforming, a penalty-based successive convex
approximation scheme is developed. Moreover, an alternative optimization (AO)
algorithm is designed to determine the optimal solution for the sub-problem of
optimizing the transmit power allocation, while the original problem is overall
solved by a new AO algorithm.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01044" title="Abstract">arXiv:2312.01044</a> [<a href="/pdf/2312.01044" title="Download PDF">pdf</a>, <a href="/format/2312.01044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Zero-Shot Text Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yiran Pang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yanbin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrained large language models (LLMs) have become extensively used across
various sub-disciplines of natural language processing (NLP). In NLP, text
classification problems have garnered considerable focus, but still faced with
some limitations related to expensive computational cost, time consumption, and
robust performance to unseen classes. With the proposal of chain of thought
prompting (CoT), LLMs can be implemented using zero-shot learning (ZSL) with
the step by step reasoning prompts, instead of conventional question and answer
formats. The zero-shot LLMs in the text classification problems can alleviate
these limitations by directly utilizing pretrained models to predict both seen
and unseen classes. Our research primarily validates the capability of GPT
models in text classification. We focus on effectively utilizing prompt
strategies to various text classification scenarios. Besides, we compare the
performance of zero shot LLMs with other state of the art text classification
methods, including traditional machine learning methods, deep learning methods,
and ZSL methods. Experimental results demonstrate that the performance of LLMs
underscores their effectiveness as zero-shot text classifiers in three of the
four datasets analyzed. The proficiency is especially advantageous for small
businesses or teams that may not have extensive knowledge in text
classification.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01045" title="Abstract">arXiv:2312.01045</a> [<a href="/pdf/2312.01045" title="Download PDF">pdf</a>, <a href="/format/2312.01045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROFL: A Privacy-Preserving Federated Learning Method with Stringent  Defense Against Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yisheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li-Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) faces two major issues: privacy leakage and poisoning
attacks, which may seriously undermine the reliability and security of the
system. Overcoming them simultaneously poses a great challenge. This is because
privacy protection policies prohibit access to users' local gradients to avoid
privacy leakage, while Byzantine-robust methods necessitate access to these
gradients to defend against poisoning attacks. To address these problems, we
propose a novel privacy-preserving Byzantine-robust FL framework PROFL. PROFL
is based on the two-trapdoor additional homomorphic encryption algorithm and
blinding techniques to ensure the data privacy of the entire FL process. During
the defense process, PROFL first utilize secure Multi-Krum algorithm to remove
malicious gradients at the user level. Then, according to the Pauta criterion,
we innovatively propose a statistic-based privacy-preserving defense algorithm
to eliminate outlier interference at the feature level and resist impersonation
poisoning attacks with stronger concealment. Detailed theoretical analysis
proves the security and efficiency of the proposed method. We conducted
extensive experiments on two benchmark datasets, and PROFL improved accuracy by
39% to 75% across different attack settings compared to similar
privacy-preserving robust methods, demonstrating its significant advantage in
robustness.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01049" title="Abstract">arXiv:2312.01049</a> [<a href="/pdf/2312.01049" title="Download PDF">pdf</a>, <a href="/format/2312.01049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint User Association and Resource Allocation for Multi-Cell Networks  with Adaptive Semantic Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingqiu He</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chaoqun You</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Semantic communication is a promising communication paradigm that utilizes
Deep Neural Networks (DNNs) to extract the information relevant to downstream
tasks, hence significantly reducing the amount of transmitted data. In current
practice, the semantic communication transmitter for a specific task is
typically pre-trained and shared by all users. However, due to user
heterogeneity, it is desirable to use different transmitters according to the
available computational and communication resources of users. In this paper, we
first show that it is possible to dynamically adjust the computational and
communication overhead of DNN-based transmitters, thereby achieving adaptive
semantic communication. After that, we investigate the user association and
resource allocation problem in a multi-cell network where users are equipped
with adaptive semantic communication transmitters. To solve this problem, we
decompose it into three subproblems involving the scheduling of each user, the
resource allocation of each base station (BS), and the user association between
users and BSs. Then we solve each problem progressively based on the solution
of the previous subproblem. The final algorithm can obtain near-optimal
solutions in polynomial time. Numerical results show that our algorithm
outperforms benchmarks under various situations.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01050" title="Abstract">arXiv:2312.01050</a> [<a href="/pdf/2312.01050" title="Download PDF">pdf</a>, <a href="/format/2312.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Analysis of Stress-Related Posts in Reddit Acamedic  Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oryngozha%2C+N">Nazzere Oryngozha</a>, 
<a href="/search/cs?searchtype=author&query=Shamoi%2C+P">Pakizar Shamoi</a>, 
<a href="/search/cs?searchtype=author&query=Igali%2C+A">Ayan Igali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Nowadays, the significance of monitoring stress levels and recognizing early
signs of mental illness cannot be overstated. Automatic stress detection in
text can proactively help manage stress and protect mental well-being. In
today's digital era, social media platforms reflect the psychological
well-being and stress levels within various communities. This study focuses on
detecting and analyzing stress-related posts in Reddit academic communities.
Due to online education and remote work, these communities have become central
for academic discussions and support. We classify text as stressed or not using
natural language processing and machine learning classifiers, with Dreaddit as
our training dataset, which contains labeled data from Reddit. Next, we collect
and analyze posts from various academic subreddits. We identified that the most
effective individual feature for stress detection is the Bag of Words, paired
with the Logistic Regression classifier, achieving a 77.78% accuracy rate and
an F1 score of 0.79 on the DReaddit dataset. This combination also performs
best in stress detection on human-annotated datasets, with a 72% accuracy rate.
Our key findings reveal that posts and comments in professors Reddit
communities are the most stressful, compared to other academic levels,
including bachelor, graduate, and Ph.D. students. This research contributes to
our understanding of the stress levels within academic communities. It can help
academic institutions and online communities develop measures and interventions
to address this issue effectively.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01052" title="Abstract">arXiv:2312.01052</a> [<a href="/pdf/2312.01052" title="Download PDF">pdf</a>, <a href="/format/2312.01052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured, Complex and Time-complete Temporal Event Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chenchen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zijian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Temporal event forecasting aims to predict what will happen next given the
observed events in history. Previous formulations of temporal event are
unstructured, atomic, or lacking full temporal information, thus largely
restricting the representation quality and forecasting ability of temporal
events. To address these limitations, we introduce a novel formulation for
Structured, Complex, and Time-complete Temporal Event (SCTc-TE). Based on this
new formulation, we develop a simple and fully automated pipeline for
constructing such SCTc-TEs from a large amount of news articles. Furthermore,
we propose a novel model that leverages both Local and Global contexts for
SCTc-TE forecasting, named LoGo. To evaluate our model, we construct two
large-scale datasets named MidEast-TE and GDELT-TE. Extensive evaluations
demonstrate the advantages of our datasets in multiple aspects, while
experimental results justify the effectiveness of our forecasting model LoGo.
We release the code and dataset via
https://github.com/yecchen/GDELT-ComplexEvent.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01053" title="Abstract">arXiv:2312.01053</a> [<a href="/pdf/2312.01053" title="Download PDF">pdf</a>, <a href="/format/2312.01053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Speech-to-Text Translation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sethiya%2C+N">Nivedita Sethiya</a>, 
<a href="/search/cs?searchtype=author&query=Maurya%2C+C+K">Chandresh Kumar Maurya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech-to-text translation pertains to the task of converting speech signals
in a language to text in another language. It finds its application in various
domains, such as hands-free communication, dictation, video lecture
transcription, and translation, to name a few. Automatic Speech Recognition
(ASR), as well as Machine Translation(MT) models, play crucial roles in
traditional ST translation, enabling the conversion of spoken language in its
original form to written text and facilitating seamless cross-lingual
communication. ASR recognizes spoken words, while MT translates the transcribed
text into the target language. Such disintegrated models suffer from cascaded
error propagation and high resource and training costs. As a result,
researchers have been exploring end-to-end (E2E) models for ST translation.
However, to our knowledge, there is no comprehensive review of existing works
on E2E ST. The present survey, therefore, discusses the work in this direction.
Our attempt has been to provide a comprehensive review of models employed,
metrics, and datasets used for ST tasks, providing challenges and future
research direction with new insights. We believe this review will be helpful to
researchers working on various applications of ST models.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01054" title="Abstract">arXiv:2312.01054</a> [<a href="/pdf/2312.01054" title="Download PDF">pdf</a>, <a href="/format/2312.01054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring and Improving the Spatial Reasoning Abilities of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Manasi Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) represent formidable tools for sequence
modeling, boasting an innate capacity for general pattern recognition.
Nevertheless, their broader spatial reasoning capabilities, especially applied
to numerical trajectory data, remain insufficiently explored. In this paper, we
investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama
2 7B models when confronted with 3D robotic trajectory data from the CALVIN
baseline and associated tasks, including 2D directional and shape labeling.
Additionally, we introduce a novel prefix-based prompting mechanism, which
yields a 33% improvement on the 3D trajectory data and an increase of up to 10%
on SpartQA tasks over zero-shot prompting (with gains for other prompting types
as well). The experimentation with 3D trajectory data offers an intriguing
glimpse into the manner in which LLMs engage with numerical and spatial
information, thus laying a solid foundation for the identification of target
areas for future enhancements.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01056" title="Abstract">arXiv:2312.01056</a> [<a href="/pdf/2312.01056" title="Download PDF">pdf</a>, <a href="/format/2312.01056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Surrogate Modeling Capabilities of Continuous Time  Echo State Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+S">Saakaar Bhatnagar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Continuous Time Echo State Networks (CTESN) are a promising yet
under-explored surrogate modeling technique for dynamical systems, particularly
those governed by stiff Ordinary Differential Equations (ODEs). This paper
critically investigates the effects of important hyper-parameters and
algorithmic choices on the generalization capability of CTESN surrogates on two
benchmark problems governed by Robertson's equations. The method is also used
to parametrize the initial conditions of a system of ODEs that realistically
model automobile collisions, solving them accurately up to 200 times faster
than numerical ODE solvers. The results of this paper demonstrate the ability
of CTESN surrogates to accurately predict sharp transients and highly nonlinear
system responses, and their utility in speeding up the solution of stiff ODE
systems, allowing for their use in diverse applications from accelerated design
optimization to digital twins.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01057" title="Abstract">arXiv:2312.01057</a> [<a href="/pdf/2312.01057" title="Download PDF">pdf</a>, <a href="/format/2312.01057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLHF and IIA: Perverse Incentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanqiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiuyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+G">Grace Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Existing algorithms for reinforcement learning from human feedback (RLHF) can
incentivize responses at odds with preferences because they are based on models
that assume independence of irrelevant alternatives (IIA). The perverse
incentives induced by IIA give rise to egregious behavior when innovating on
query formats or learning algorithms.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01058" title="Abstract">arXiv:2312.01058</a> [<a href="/pdf/2312.01058" title="Download PDF">pdf</a>, <a href="/format/2312.01058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Progress on Cooperative Multi-agent Reinforcement Learning  in Open Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lihe Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+C">Cong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Multi-agent Reinforcement Learning (MARL) has gained wide attention in recent
years and has made progress in various fields. Specifically, cooperative MARL
focuses on training a team of agents to cooperatively achieve tasks that are
difficult for a single agent to handle. It has shown great potential in
applications such as path planning, autonomous driving, active voltage control,
and dynamic algorithm configuration. One of the research focuses in the field
of cooperative MARL is how to improve the coordination efficiency of the
system, while research work has mainly been conducted in simple, static, and
closed environment settings. To promote the application of artificial
intelligence in real-world, some research has begun to explore multi-agent
coordination in open environments. These works have made progress in exploring
and researching the environments where important factors might change. However,
the mainstream work still lacks a comprehensive review of the research
direction. In this paper, starting from the concept of reinforcement learning,
we subsequently introduce multi-agent systems (MAS), cooperative MARL, typical
methods, and test environments. Then, we summarize the research work of
cooperative MARL from closed to open environments, extract multiple research
directions, and introduce typical works. Finally, we summarize the strengths
and weaknesses of the current research, and look forward to the future
development direction and research problems in cooperative MARL in open
environments.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01059" title="Abstract">arXiv:2312.01059</a> [<a href="/pdf/2312.01059" title="Download PDF">pdf</a>, <a href="/format/2312.01059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm-GPT: Combining Large Language Models with Safe Motion Planning for  Robot Choreography Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+A">Aoran Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+T+P">Tanmay P. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+S">Sanjmi Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Korol%2C+A">Anna-Mariya Korol</a>, 
<a href="/search/cs?searchtype=author&query=Brunke%2C+L">Lukas Brunke</a>, 
<a href="/search/cs?searchtype=author&query=Adajania%2C+V+K">Vivek K. Adajania</a>, 
<a href="/search/cs?searchtype=author&query=Culha%2C+U">Utku Culha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents Swarm-GPT, a system that integrates large language models
(LLMs) with safe swarm motion planning - offering an automated and novel
approach to deployable drone swarm choreography. Swarm-GPT enables users to
automatically generate synchronized drone performances through natural language
instructions. With an emphasis on safety and creativity, Swarm-GPT addresses a
critical gap in the field of drone choreography by integrating the creative
power of generative models with the effectiveness and safety of model-based
planning algorithms. This goal is achieved by prompting the LLM to generate a
unique set of waypoints based on extracted audio data. A trajectory planner
processes these waypoints to guarantee collision-free and feasible motion.
Results can be viewed in simulation prior to execution and modified through
dynamic re-prompting. Sim-to-real transfer experiments demonstrate Swarm-GPT's
ability to accurately replicate simulated drone trajectories, with a mean
sim-to-real root mean square error (RMSE) of 28.7 mm. To date, Swarm-GPT has
been successfully showcased at three live events, exemplifying safe real-world
deployment of pre-trained models.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01060" title="Abstract">arXiv:2312.01060</a> [<a href="/pdf/2312.01060" title="Download PDF">pdf</a>, <a href="/format/2312.01060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum-driven Mixed-frequency Network for Hyperspectral Salient Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peifu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shiyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haolin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Multimedia, to be published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hyperspectral salient object detection (HSOD) aims to detect spectrally
salient objects in hyperspectral images (HSIs). However, existing methods
inadequately utilize spectral information by either converting HSIs into
false-color images or converging neural networks with clustering. We propose a
novel approach that fully leverages the spectral characteristics by extracting
two distinct frequency components from the spectrum: low-frequency Spectral
Saliency and high-frequency Spectral Edge. The Spectral Saliency approximates
the region of salient objects, while the Spectral Edge captures edge
information of salient objects. These two complementary components, crucial for
HSOD, are derived by computing from the inter-layer spectral angular distance
of the Gaussian pyramid and the intra-neighborhood spectral angular gradients,
respectively. To effectively utilize this dual-frequency information, we
introduce a novel lightweight Spectrum-driven Mixed-frequency Network (SMN).
SMN incorporates two parameter-free plug-and-play operators, namely Spectral
Saliency Generator and Spectral Edge Operator, to extract the Spectral Saliency
and Spectral Edge components from the input HSI independently. Subsequently,
the Mixed-frequency Attention module, comprised of two frequency-dependent
heads, intelligently combines the embedded features of edge and saliency
information, resulting in a mixed-frequency feature representation.
Furthermore, a saliency-edge-aware decoder progressively scales up the
mixed-frequency feature while preserving rich detail and saliency information
for accurate salient object prediction. Extensive experiments conducted on the
HS-SOD benchmark and our custom dataset HSOD-BIT demonstrate that our SMN
outperforms state-of-the-art methods regarding HSOD performance. Code and
dataset will be available at https://github.com/laprf/SMN.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01062" title="Abstract">arXiv:2312.01062</a> [<a href="/pdf/2312.01062" title="Download PDF">pdf</a>, <a href="/ps/2312.01062" title="Download PostScript">ps</a>, <a href="/format/2312.01062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic Signal Analysis with Deep Neural Network for Detecting Fault  Diagnosis in Industrial Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yurdakul%2C+M">Mustafa Yurdakul</a>, 
<a href="/search/cs?searchtype=author&query=Tasdemir%2C+S">Sakir Tasdemir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting machine malfunctions at an early stage is crucial for reducing
interruptions in operational processes within industrial settings. Recently,
the deep learning approach has started to be preferred for the detection of
failures in machines. Deep learning provides an effective solution in fault
detection processes thanks to automatic feature extraction. In this study, a
deep learning-based system was designed to analyze the sound signals produced
by industrial machines. Acoustic sound signals were converted into Mel
spectrograms. For the purpose of classifying spectrogram images, the
DenseNet-169 model, a deep learning architecture recognized for its
effectiveness in image classification tasks, was used. The model was trained
using the transfer learning method on the MIMII dataset including sounds from
four types of industrial machines. The results showed that the proposed method
reached an accuracy rate varying between 97.17% and 99.87% at different Sound
Noise Rate levels.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01065" title="Abstract">arXiv:2312.01065</a> [<a href="/pdf/2312.01065" title="Download PDF">pdf</a>, <a href="/format/2312.01065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scholarly Knowledge Graph Construction from Published Software Packages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haris%2C+M">Muhammad Haris</a>, 
<a href="/search/cs?searchtype=author&query=Auer%2C+S">S&#xf6;ren Auer</a>, 
<a href="/search/cs?searchtype=author&query=Stocker%2C+M">Markus Stocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The value of structured scholarly knowledge for research and society at large
is well understood, but producing scholarly knowledge (i.e., knowledge
traditionally published in articles) in structured form remains a challenge. We
propose an approach for automatically extracting scholarly knowledge from
published software packages by static analysis of their metadata and contents
(scripts and data) and populating a scholarly knowledge graph with the
extracted knowledge. Our approach is based on mining scientific software
packages linked to article publications by extracting metadata and analyzing
the Abstract Syntax Tree (AST) of the source code to obtain information about
the used and produced data as well as operations performed on data. The
resulting knowledge graph includes articles, software packages metadata, and
computational techniques applied to input data utilized as materials in
research work. The knowledge graph also includes the results reported as
scholarly knowledge in articles.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01066" title="Abstract">arXiv:2312.01066</a> [<a href="/pdf/2312.01066" title="Download PDF">pdf</a>, <a href="/format/2312.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Database System for State Management in Stateful Network Service  Function Chains [Vision]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhonghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Network Function Virtualization (NFV) heralds a transformative era in network
function deployment, enabling the orchestration of Service Function Chains
(SFCs) for delivering complex and dynamic network services. Yet, the
development and sustenance of stateful SFCs remain challenging, with intricate
demands for usability in SFC development, performance, and execution
correctness. In this paper, we present DB4NFV, a database system designed to
address these challenges. Central to DB4NFV is the integration of transactional
semantics into the entire lifecycle of stateful SFC, a core idea that enhances
all aspects of the system. This integration provides an intuitive and
well-structured API, which greatly simplifies the development of stateful SFCs.
Concurrently, transactional semantics facilitate the optimization of runtime
performance by efficiently leveraging modern multicore architectures. Moreover,
by encapsulating state operations as transactions, DB4NFV achieves robustness,
even at the entire chain level, ensuring reliable operation across varying
network conditions. Consequently, DB4NFV marks a substantial forward leap in
NFV state management, leveraging transactional semantics to achieve a
harmonious blend of usability, efficiency, and robustness, thus facilitating
the effective deployment of stateful SFCs in contemporary network
infrastructures.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01067" title="Abstract">arXiv:2312.01067</a> [<a href="/pdf/2312.01067" title="Download PDF">pdf</a>, <a href="/format/2312.01067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Painterly Reality: Enhancing Audience Experience with Paintings through  Interactive Art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A+L">Aven Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+D">David Yip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Perceiving paintings entails more than merely engaging the audience's eyes
and brains; their perceptions and experiences of a painting can be intricately
connected with body movement. This paper proposes an interactive art approach
entitled "Painterly Reality" that facilitates the perception and interaction
with paintings in a three-dimensional manner. Its objective is to promote
bodily engagement with the painting (i.e., embedded body embodiment and its
movement and interaction) to enhance the audience's experience, while
maintaining its essence. Unlike two-dimensional interactions, this approach
constructs the Painterly Reality by capturing the audience's body embodiment in
real-time and embedding into a three-dimensional painterly world derived from a
given painting input. Through their body embodiment, the audience can navigate
the painterly world and play with the magical realism (i.e., interactive
painterly objects), fostering meaningful experiences via interactions. The
Painterly Reality is subsequently projected through an Augmented Reality Mirror
as a live painting and displayed in front of the audience. Hence, the audience
can gain enhanced experiences through bodily engagement while simultaneously
viewing and appreciating the live painting. The paper implements the proposed
approach as an interactive artwork, entitled "Everyday Conjunctive," with Fong
Tse Ka's painting and installs in a local museum, which successfully enhances
audience experience through bodily engagement.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01068" title="Abstract">arXiv:2312.01068</a> [<a href="/pdf/2312.01068" title="Download PDF">pdf</a>, <a href="/format/2312.01068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPHMs: Diffusion Parametric Head Models for Depth-based Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiapeng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yinyu Nie</a>, 
<a href="/search/cs?searchtype=author&query=Markhasin%2C+L">Lev Markhasin</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>, 
<a href="/search/cs?searchtype=author&query=Niessner%2C+M">Matthias Niessner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Diffusion Parametric Head Models (DPHMs), a generative model
that enables robust volumetric head reconstruction and tracking from monocular
depth sequences. While recent volumetric head models, such as NPHMs, can now
excel in representing high-fidelity head geometries, tracking and
reconstruction heads from real-world single-view depth sequences remains very
challenging, as the fitting to partial and noisy observations is
underconstrained. To tackle these challenges, we propose a latent
diffusion-based prior to regularize volumetric head reconstruction and
tracking. This prior-based regularizer effectively constrains the identity and
expression codes to lie on the underlying latent manifold which represents
plausible head shapes. To evaluate the effectiveness of the diffusion-based
prior, we collect a dataset of monocular Kinect sequences consisting of various
complex facial expression motions and rapid transitions. We compare our method
to state-of-the-art tracking methods, and demonstrate improved head identity
reconstruction as well as robust expression tracking.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01071" title="Abstract">arXiv:2312.01071</a> [<a href="/pdf/2312.01071" title="Download PDF">pdf</a>, <a href="/format/2312.01071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Hierarchical DRL Enabled Resource Allocation for Secure  Transmission in Multi-IRS-Assisted Sensing-Enhanced Spectrum Sharing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fuhui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qihui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Secure communications are of paramount importance in spectrum sharing
networks due to the allocation and sharing characteristics of spectrum
resources. To further explore the potential of intelligent reflective surfaces
(IRSs) in enhancing spectrum sharing and secure transmission performance, a
multiple intelligent reflection surface (multi-IRS)-assisted sensing-enhanced
wideband spectrum sharing network is investigated by considering physical layer
security techniques. An intelligent resource allocation scheme based on double
deep Q networks (D3QN) algorithm and soft Actor-Critic (SAC) algorithm is
proposed to maximize the secure transmission rate of the secondary network by
jointly optimizing IRS pairings, subchannel assignment, transmit beamforming of
the secondary base station, reflection coefficients of IRSs and the sensing
time. To tackle the sparse reward problem caused by a significant amount of
reflection elements of multiple IRSs, the method of hierarchical reinforcement
learning is exploited. An alternative optimization (AO)-based conventional
mathematical scheme is introduced to verify the computational complexity
advantage of our proposed intelligent scheme. Simulation results demonstrate
the efficiency of our proposed intelligent scheme as well as the superiority of
multi-IRS design in enhancing secrecy rate and spectrum utilization. It is
shown that inappropriate deployment of IRSs can reduce the security performance
with the presence of multiple eavesdroppers (Eves), and the arrangement of IRSs
deserves further consideration.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01072" title="Abstract">arXiv:2312.01072</a> [<a href="/pdf/2312.01072" title="Download PDF">pdf</a>, <a href="/format/2312.01072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Temporal Credit Assignment in Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pignatelli%2C+E">Eduardo Pignatelli</a>, 
<a href="/search/cs?searchtype=author&query=Ferret%2C+J">Johan Ferret</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/cs?searchtype=author&query=Mesnard%2C+T">Thomas Mesnard</a>, 
<a href="/search/cs?searchtype=author&query=van+Hasselt%2C+H">Hado van Hasselt</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+L">Laura Toni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Credit Assignment Problem (CAP) refers to the longstanding challenge of
Reinforcement Learning (RL) agents to associate actions with their long-term
consequences. Solving the CAP is a crucial step towards the successful
deployment of RL in the real world since most decision problems provide
feedback that is noisy, delayed, and with little or no information about the
causes. These conditions make it hard to distinguish serendipitous outcomes
from those caused by informed decision-making. However, the mathematical nature
of credit and the CAP remains poorly understood and defined. In this survey, we
review the state of the art of Temporal Credit Assignment (CA) in deep RL. We
propose a unifying formalism for credit that enables equitable comparisons of
state of the art algorithms and improves our understanding of the trade-offs
between the various methods. We cast the CAP as the problem of learning the
influence of an action over an outcome from a finite amount of experience. We
discuss the challenges posed by delayed effects, transpositions, and a lack of
action influence, and analyse how existing methods aim to address them.
Finally, we survey the protocols to evaluate a credit assignment method, and
suggest ways to diagnoses the sources of struggle for different credit
assignment methods. Overall, this survey provides an overview of the field for
new-entry practitioners and researchers, it offers a coherent perspective for
scholars looking to expedite the starting stages of a new study on the CAP, and
it suggests potential directions for future research
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01080" title="Abstract">arXiv:2312.01080</a> [<a href="/pdf/2312.01080" title="Download PDF">pdf</a>, <a href="/format/2312.01080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Residual-guided Learning Method for Image Steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Miaoxin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dongxia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kangkang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weiqi Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Traditional steganographic techniques have often relied on manually crafted
attributes related to image residuals. These methods demand a significant level
of expertise and face challenges in integrating diverse image residual
characteristics. In this paper, we introduce an innovative deep learning-based
methodology that seamlessly integrates image residuals, residual distances, and
image local variance to autonomously learn embedding probabilities. Our
framework includes an embedding probability generator and three pivotal guiding
components: Residual guidance strives to facilitate embedding in
complex-textured areas. Residual distance guidance aims to minimize the
residual differences between cover and stego images. Local variance guidance
effectively safeguards against modifications in regions characterized by
uncomplicated or uniform textures. The three components collectively guide the
learning process, enhancing the security performance. Comprehensive
experimental findings underscore the superiority of our approach when compared
to traditional steganographic methods and randomly initialized ReLOAD in the
spatial domain.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01081" title="Abstract">arXiv:2312.01081</a> [<a href="/pdf/2312.01081" title="Download PDF">pdf</a>, <a href="/format/2312.01081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Resource Allocation for Semantic Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fuhui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhijin Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic communication, recognized as a promising technology for future
intelligent applications, has received widespread research attention. Despite
the potential of semantic communication to enhance transmission reliability,
especially in low signal-to-noise (SNR) environments, the critical issue of
resource allocation and compatibility in the dynamic wireless environment
remains largely unexplored. In this paper, we propose an adaptive semantic
resource allocation paradigm with semantic-bit quantization (SBQ) compatibly
for existing wireless communications, where the inaccurate environment
perception introduced by the additional mapping relationship between semantic
metrics and transmission metrics is solved. In order to investigate the
performance of semantic communication networks, the quality of service for
semantic communication (SC-QoS), including the semantic quantization efficiency
(SQE) and transmission latency, is proposed for the first time. A problem of
maximizing the overall effective SC-QoS is formulated by jointly optimizing the
transmit beamforming of the base station, the bits for semantic representation,
the subchannel assignment, and the bandwidth resource allocation. To address
the non-convex formulated problem, an intelligent resource allocation scheme is
proposed based on a hybrid deep reinforcement learning (DRL) algorithm, where
the intelligent agent can perceive both semantic tasks and dynamic wireless
environments. Simulation results demonstrate that our design can effectively
combat semantic noise and achieve superior performance in wireless
communications compared to several benchmark schemes. Furthermore, compared to
mapping-guided paradigm based resource allocation schemes, our proposed
adaptive scheme can achieve up to 13% performance improvement in terms of
SC-QoS.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01082" title="Abstract">arXiv:2312.01082</a> [<a href="/pdf/2312.01082" title="Download PDF">pdf</a>, <a href="/format/2312.01082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effects of Randomness on Stability of Learning with Limited  Labelled Data: A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pecher%2C+B">Branislav Pecher</a>, 
<a href="/search/cs?searchtype=author&query=Srba%2C+I">Ivan Srba</a>, 
<a href="/search/cs?searchtype=author&query=Bielikova%2C+M">Maria Bielikova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Learning with limited labelled data, such as few-shot learning, meta-learning
or transfer learning, aims to effectively train a model using only small amount
of labelled samples. However, these approaches were observed to be excessively
sensitive to the effects of uncontrolled randomness caused by non-determinism
in the training process. The randomness negatively affects the stability of the
models, leading to large variance in results across training runs. When such
instability is disregarded, it can unintentionally, but unfortunately also
intentionally, create an imaginary perception of research progress. Recently,
this area started to attract a research attention and the number of relevant
studies is continuously growing. In this survey, we provide a comprehensive
overview of 134 papers addressing the effects of randomness on the stability of
learning with limited labelled data. We distinguish between four main tasks
addressed in the papers (investigate/evaluate; determine; mitigate;
benchmark/compare/report randomness effects), providing findings for each one.
Furthermore, we identify and discuss seven challenges and open problems
together with possible directions to facilitate further research. The ultimate
goal of this survey is to emphasise the importance of this growing research
area, which so far has not received appropriate level of attention.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01083" title="Abstract">arXiv:2312.01083</a> [<a href="/pdf/2312.01083" title="Download PDF">pdf</a>, <a href="/format/2312.01083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Prototype Module and Motion Compensation for Few-Shot Action  Recognition (CLIP-CP$\mathbf{M^2}$C)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Li Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">YiKang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Han Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, few-shot action recognition has significantly progressed by
learning the feature discriminability and designing suitable comparison
methods. Still, there are the following restrictions. (a) Previous works are
mainly based on visual mono-modal. Although some multi-modal works use labels
as supplementary to construct prototypes of support videos, they can not use
this information for query videos. The labels are not used efficiently. (b)
Most of the works ignore the motion feature of video, although the motion
features are essential for distinguishing. We proposed a Consistency Prototype
and Motion Compensation Network(CLIP-CP$M^2$C) to address these issues.
Firstly, we use the CLIP for multi-modal few-shot action recognition with the
text-image comparison for domain adaption. Secondly, in order to make the
amount of information between the prototype and the query more similar, we
propose a novel method to compensate for the text(prompt) information of query
videos when text(prompt) does not exist, which depends on a Consistency Loss.
Thirdly, we use the differential features of the adjacent frames in two
directions as the motion features, which explicitly embeds the network with
motion dynamics. We also apply the Consistency Loss to the motion features.
Extensive experiments on standard benchmark datasets demonstrate that the
proposed method can compete with state-of-the-art results. Our code is
available at the URL: https://github.com/xxx/xxx.git.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01085" title="Abstract">arXiv:2312.01085</a> [<a href="/pdf/2312.01085" title="Download PDF">pdf</a>, <a href="/format/2312.01085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jizhou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current traditional methods for LiDAR-camera extrinsics estimation depend on
offline targets and human efforts, while learning-based approaches resort to
iterative refinement for calibration results, posing constraints on their
generalization and application in on-board systems. In this paper, we propose a
novel approach to address the extrinsic calibration problem in a robust,
automatic, and single-shot manner. Instead of directly optimizing extrinsics,
we leverage the consistency learning between LiDAR and camera to implement
implicit re-calibartion. Specially, we introduce an appearance-consistency loss
and a geometric-consistency loss to minimizing the inconsitency between the
attrbutes (e.g., intensity and depth) of projected LiDAR points and the
predicted ones. This design not only enhances adaptability to various scenarios
but also enables a simple and efficient formulation during inference. We
conduct comprehensive experiments on different datasets, and the results
demonstrate that our method achieves accurate and robust performance. To
promote further research and development in this area, we will release our
model and code.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01087" title="Abstract">arXiv:2312.01087</a> [<a href="/pdf/2312.01087" title="Download PDF">pdf</a>, <a href="/format/2312.01087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompted Zero-Shot Multi-label Classification of Factual Incorrectness  in Machine-Generated Summaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subhankar Maity</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Saptarshi Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study addresses the critical issue of factual inaccuracies in
machine-generated text summaries, an increasingly prevalent issue in
information dissemination. Recognizing the potential of such errors to
compromise information reliability, we investigate the nature of factual
inconsistencies across machine-summarized content. We introduce a prompt-based
classification system that categorizes errors into four distinct types:
misrepresentation, inaccurate quantities or measurements, false attribution,
and fabrication. The participants are tasked with evaluating a corpus of
machine-generated summaries against their original articles. Our methodology
employs qualitative judgements to identify the occurrence of factual
distortions. The results show that our prompt-based approaches are able to
detect the type of errors in the summaries to some extent, although there is
scope for improvement in our classification systems.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01090" title="Abstract">arXiv:2312.01090</a> [<a href="/pdf/2312.01090" title="Download PDF">pdf</a>, <a href="/format/2312.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self Generated Wargame AI: Double Layer Agent Task Planning Based on  Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Y.Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">C.Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">J.Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">W.Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">X.Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The big language model represented by ChatGPT has had a disruptive impact on
the field of artificial intelligence. But it mainly focuses on Natural language
processing, speech recognition, machine learning and natural-language
understanding. This paper innovatively applies the big language model to the
field of intelligent decision-making, places the big language model in the
decision-making center, and constructs an agent architecture with the big
language model as the core. Based on this, it further proposes a two-layer
agent task planning, issues and executes decision commands through the
interaction of natural language, and carries out simulation verification
through the wargame simulation environment. Through the game confrontation
simulation experiment, it is found that the intelligent decision-making ability
of the big language model is significantly stronger than the commonly used
reinforcement learning AI and rule AI, and the intelligence, understandability
and generalization are all better. And through experiments, it was found that
the intelligence of the large language model is closely related to prompt. This
work also extends the large language model from previous human-computer
interaction to the field of intelligent decision-making, which has important
reference value and significance for the development of intelligent
decision-making.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01091" title="Abstract">arXiv:2312.01091</a> [<a href="/pdf/2312.01091" title="Download PDF">pdf</a>, <a href="/format/2312.01091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying DeFi MEV Activities in Flashbots Bundle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zheyuan He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xiaoze Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This submission serves as our full paper version with the appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Decentralized Finance, mushrooming in permissionless blockchains, has
attracted a recent surge in popularity. Due to the transparency of
permissionless blockchains, opportunistic traders can compete to earn revenue
by extracting Miner Extractable Value (MEV), which undermines both the
consensus security and efficiency of blockchain systems. The Flashbots bundle
mechanism further aggravates the MEV competition because it empowers
opportunistic traders with the capability of designing more sophisticated MEV
extraction. In this paper, we conduct the first systematic study on DeFi MEV
activities in Flashbots bundle by developing ActLifter, a novel automated tool
for accurately identifying DeFi actions in transactions of each bundle, and
ActCluster, a new approach that leverages iterative clustering to facilitate us
to discover known/unknown DeFi MEV activities. Extensive experimental results
show that ActLifter can achieve nearly 100% precision and recall in DeFi action
identification, significantly outperforming state-of-the-art techniques.
Moreover, with the help of ActCluster, we obtain many new observations and
discover 17 new kinds of DeFi MEV activities, which occur in 53.12% of bundles
but have not been reported in existing studies
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01092" title="Abstract">arXiv:2312.01092</a> [<a href="/pdf/2312.01092" title="Download PDF">pdf</a>, <a href="/format/2312.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semi-Supervised Deep Learning Approach to Dataset Collection for  Query-By-Humming Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amatov%2C+A">Amantur Amatov</a>, 
<a href="/search/cs?searchtype=author&query=Lamanov%2C+D">Dmitry Lamanov</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+M">Maksim Titov</a>, 
<a href="/search/cs?searchtype=author&query=Vovk%2C+I">Ivan Vovk</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+I">Ilya Makarov</a>, 
<a href="/search/cs?searchtype=author&query=Kudinov%2C+M">Mikhail Kudinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Query-by-Humming (QbH) is a task that involves finding the most relevant song
based on a hummed or sung fragment. Despite recent successful commercial
solutions, implementing QbH systems remains challenging due to the lack of
high-quality datasets for training machine learning models. In this paper, we
propose a deep learning data collection technique and introduce Covers and
Hummings Aligned Dataset (CHAD), a novel dataset that contains 18 hours of
short music fragments, paired with time-aligned hummed versions. To expand our
dataset, we employ a semi-supervised model training pipeline that leverages the
QbH task as a specialized case of cover song identification (CSI) task.
Starting with a model trained on the initial dataset, we iteratively collect
groups of fragments of cover versions of the same song and retrain the model on
the extended data. Using this pipeline, we collect over 308 hours of additional
music fragments, paired with time-aligned cover versions. The final model is
successfully applied to the QbH task and achieves competitive results on
benchmark datasets. Our study shows that the proposed dataset and training
pipeline can effectively facilitate the implementation of QbH systems.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01093" title="Abstract">arXiv:2312.01093</a> [<a href="/pdf/2312.01093" title="Download PDF">pdf</a>, <a href="/format/2312.01093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Postoperative Nausea And Vomiting Using Machine Learning: A  Model Development and Validation Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glebov%2C+M">Maxim Glebov</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Orkin%2C+B">Boris Orkin</a>, 
<a href="/search/cs?searchtype=author&query=Berkenstadt%2C+H">Haim Berkenstadt</a>, 
<a href="/search/cs?searchtype=author&query=Bunimovich-Mendrazitsky%2C+S">Svetlana Bunimovich-Mendrazitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Background: Postoperative nausea and vomiting (PONV) is a frequently observed
complication in patients undergoing surgery under general anesthesia. Moreover,
it is a frequent cause of distress and dissatisfaction during the early
postoperative period. The tools used for predicting PONV at present have not
yielded satisfactory results. Therefore, prognostic tools for the prediction of
early and delayed PONV were developed in this study with the aim of achieving
satisfactory predictive performance.
<br />Methods: The retrospective data of adult patients admitted to the
post-anesthesia care unit after undergoing surgical procedures under general
anesthesia at the Sheba Medical Center, Israel, between September 1, 2018, and
September 1, 2023, were used in this study. An ensemble model of machine
learning algorithms trained on the data of 54848 patients was developed. The
k-fold cross-validation method was used followed by splitting the data to train
and test sets that optimally preserve the sociodemographic features of the
patients, such as age, sex, and smoking habits, using the Bee Colony algorithm.
<br />Findings: Among the 54848 patients, early and delayed PONV were observed in
2706 (4.93%) and 8218 (14.98%) patients, respectively. The proposed PONV
prediction tools could correctly predict early and delayed PONV in 84.0% and
77.3% of cases, respectively, outperforming the second-best PONV prediction
tool (Koivuranta score) by 13.4% and 12.9%, respectively. Feature importance
analysis revealed that the performance of the proposed prediction tools aligned
with previous clinical knowledge, indicating their utility.
<br />Interpretation: The machine learning-based tools developed in this study
enabled improved PONV prediction, thereby facilitating personalized care and
improved patient outcomes.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01097" title="Abstract">arXiv:2312.01097</a> [<a href="/pdf/2312.01097" title="Download PDF">pdf</a>, <a href="/format/2312.01097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning as In-Painting: A Diffusion-Based Embodied Task Planning  Framework for Environments under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Fu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Te-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Task planning for embodied AI has been one of the most challenging problems
where the community does not meet a consensus in terms of formulation. In this
paper, we aim to tackle this problem with a unified framework consisting of an
end-to-end trainable method and a planning algorithm. Particularly, we propose
a task-agnostic method named 'planning as in-painting'. In this method, we use
a Denoising Diffusion Model (DDM) for plan generation, conditioned on both
language instructions and perceptual inputs under partially observable
environments. Partial observation often leads to the model hallucinating the
planning. Therefore, our diffusion-based method jointly models both state
trajectory and goal estimation to improve the reliability of the generated
plan, given the limited available information at each step. To better leverage
newly discovered information along the plan execution for a higher success
rate, we propose an on-the-fly planning algorithm to collaborate with the
diffusion-based planner. The proposed framework achieves promising performances
in various embodied AI tasks, including vision-language navigation, object
manipulation, and task planning in a photorealistic virtual environment. The
code is available at: https://github.com/joeyy5588/planning-as-inpainting.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01099" title="Abstract">arXiv:2312.01099</a> [<a href="/pdf/2312.01099" title="Download PDF">pdf</a>, <a href="/format/2312.01099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Multiple Instance Learning for Whole Slide Image  Classification: A Bag-Level Classifier is a Good Instance-Level Teacher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+R">Ruofeng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lanfen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multiple Instance Learning (MIL) has demonstrated promise in Whole Slide
Image (WSI) classification. However, a major challenge persists due to the high
computational cost associated with processing these gigapixel images. Existing
methods generally adopt a two-stage approach, comprising a non-learnable
feature embedding stage and a classifier training stage. Though it can greatly
reduce the memory consumption by using a fixed feature embedder pre-trained on
other domains, such scheme also results in a disparity between the two stages,
leading to suboptimal classification accuracy. To address this issue, we
propose that a bag-level classifier can be a good instance-level teacher. Based
on this idea, we design Iteratively Coupled Multiple Instance Learning (ICMIL)
to couple the embedder and the bag classifier at a low cost. ICMIL initially
fix the patch embedder to train the bag classifier, followed by fixing the bag
classifier to fine-tune the patch embedder. The refined embedder can then
generate better representations in return, leading to a more accurate
classifier for the next iteration. To realize more flexible and more effective
embedder fine-tuning, we also introduce a teacher-student framework to
efficiently distill the category knowledge in the bag classifier to help the
instance-level embedder fine-tuning. Thorough experiments were conducted on
four distinct datasets to validate the effectiveness of ICMIL. The experimental
results consistently demonstrate that our method significantly improves the
performance of existing MIL backbones, achieving state-of-the-art results. The
code is available at: https://github.com/Dootmaan/ICMIL/tree/confidence_based
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01100" title="Abstract">arXiv:2312.01100</a> [<a href="/pdf/2312.01100" title="Download PDF">pdf</a>, <a href="/ps/2312.01100" title="Download PostScript">ps</a>, <a href="/format/2312.01100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prior-Aware Robust Beam Alignment for Low-SNR Millimeter-Wave  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jihun Park</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Yongjeong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Jaewon Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seonjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yo-Seb Jeon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents a robust beam alignment technique for millimeter-wave
communications in low signal-to-noise ratio (SNR) environments. The core
strategy of our technique is to repeatedly transmit the most probable beam
candidates to reduce beam misalignment probability induced by noise.
Specifically, for a given beam training overhead, both the selection of
candidates and the number of repetitions for each beam candidate are optimized
based on channel prior information. To achieve this, a deep neural network is
employed to learn the prior probability of the optimal beam at each location.
The beam misalignment probability is then analyzed based on the channel prior,
forming the basis for an optimization problem aimed at minimizing the analyzed
beam misalignment probability. A closed-form solution is derived for a special
case with two beam candidates, and an efficient algorithm is developed for
general cases with multiple beam candidates. Simulation results using the
DeepMIMO dataset demonstrate the superior performance of our technique in
dynamic low-SNR communication environments when compared to existing beam
alignment techniques.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01101" title="Abstract">arXiv:2312.01101</a> [<a href="/pdf/2312.01101" title="Download PDF">pdf</a>, <a href="/ps/2312.01101" title="Download PostScript">ps</a>, <a href="/format/2312.01101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization of trace norms in two and three dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertoluzza%2C+S">Silvia Bertoluzza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We extend a localization result for the $H^{1/2}$ norm by B. Faermann to a
wider class of subspaces of $H^{1/2}(\Gamma)$, and we prove an analogous result
for the $H^{-1/2}(\Gamma)$ norm, $\Gamma$ being the boundary of a bounded
polytopal domain $\Omega$ in $\mathbb{R}^n$, $n=2,3$. As a corollary, we obtain
equivalent, better localized, norms for both $H^{1/2}(\Gamma)$ and
$H^{-1/2}(\Gamma)$, which can be exploited, for instance, in the design of
preconditioners or of stabilized methods.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01103" title="Abstract">arXiv:2312.01103</a> [<a href="/pdf/2312.01103" title="Download PDF">pdf</a>, <a href="/format/2312.01103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code-Mixed Text to Speech Synthesis under Low-Resource Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Garera%2C+N">Nikesh Garera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SPECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Text-to-speech (TTS) systems are an important component in voice-based
e-commerce applications. These applications include end-to-end voice assistant
and customer experience (CX) voice bot. Code-mixed TTS is also relevant in
these applications since the product names are commonly described in English
while the surrounding text is in a regional language. In this work, we describe
our approaches for production quality code-mixed Hindi-English TTS systems
built for e-commerce applications. We propose a data-oriented approach by
utilizing monolingual data sets in individual languages. We leverage a
transliteration model to convert the Roman text into a common Devanagari script
and then combine both datasets for training. We show that such single script
bi-lingual training without any code-mixing works well for pure code-mixed test
sets. We further present an exhaustive evaluation of single-speaker adaptation
and multi-speaker training with Tacotron2 + Waveglow setup to show that the
former approach works better. These approaches are also coupled with transfer
learning and decoder-only fine-tuning to improve performance. We compare these
approaches with the Google TTS and report a positive CMOS score of 0.02 with
the proposed transfer learning approach. We also perform low-resource voice
adaptation experiments to show that a new voice can be onboarded with just 3
hrs of data. This highlights the importance of our pre-trained models in
resource-constrained settings. This subjective evaluation is performed on a
large number of out-of-domain pure code-mixed sentences to demonstrate the high
quality of the systems.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01104" title="Abstract">arXiv:2312.01104</a> [<a href="/pdf/2312.01104" title="Download PDF">pdf</a>, <a href="/format/2312.01104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QPoser: Quantized Explicit Pose Prior Modeling for Controllable Pose  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yumeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yaoxiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Explicit pose prior models compress human poses into latent representations
for using in pose-related downstream tasks. A desirable explicit pose prior
model should satisfy three desirable abilities: 1) correctness, i.e. ensuring
to generate physically possible poses; 2) expressiveness, i.e. ensuring to
preserve details in generation; 3) controllability, meaning that generation
from reference poses and explicit instructions should be convenient. Existing
explicit pose prior models fail to achieve all of three properties, in special
controllability. To break this situation, we propose QPoser, a highly
controllable explicit pose prior model which guarantees correctness and
expressiveness. In QPoser, a multi-head vector quantized autoencoder (MS-VQVAE)
is proposed for obtaining expressive and distributed pose representations.
Furthermore, a global-local feature integration mechanism (GLIF-AE) is utilized
to disentangle the latent representation and integrate full-body information
into local-joint features. Experimental results show that QPoser significantly
outperforms state-of-the-art approaches in representing expressive and correct
poses, meanwhile is easily to be used for detailed conditional generation from
reference poses and prompting instructions.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01105" title="Abstract">arXiv:2312.01105</a> [<a href="/pdf/2312.01105" title="Download PDF">pdf</a>, <a href="/format/2312.01105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S2P3: Self-Supervised Polarimetric Pose Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruhkamp%2C+P">Patrick Ruhkamp</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daoyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes the first self-supervised 6D object pose prediction from
multimodal RGB+polarimetric images. The novel training paradigm comprises 1) a
physical model to extract geometric information of polarized light, 2) a
teacher-student knowledge distillation scheme and 3) a self-supervised loss
formulation through differentiable rendering and an invertible physical
constraint. Both networks leverage the physical properties of polarized light
to learn robust geometric representations by encoding shape priors and
polarization characteristics derived from our physical model. Geometric
pseudo-labels from the teacher support the student network without the need for
annotated real data. Dense appearance and geometric information of objects are
obtained through a differentiable renderer with the predicted pose for
self-supervised direct coupling. The student network additionally features our
proposed invertible formulation of the physical shape priors that enables
end-to-end self-supervised training through physical constraints of derived
polarization characteristics compared against polarimetric input images. We
specifically focus on photometrically challenging objects with texture-less or
reflective surfaces and transparent materials for which the most prominent
performance gain is reported.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01107" title="Abstract">arXiv:2312.01107</a> [<a href="/pdf/2312.01107" title="Download PDF">pdf</a>, <a href="/format/2312.01107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Speaker Adaptation in Low Resource Text to Speech Systems using  Synthetic Data and Transfer learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Garera%2C+N">Nikesh Garera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PACLIC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Text-to-speech (TTS) systems are being built using end-to-end deep learning
approaches. However, these systems require huge amounts of training data. We
present our approach to built production quality TTS and perform speaker
adaptation in extremely low resource settings. We propose a transfer learning
approach using high-resource language data and synthetically generated data. We
transfer the learnings from the out-domain high-resource English language.
Further, we make use of out-of-the-box single-speaker TTS in the target
language to generate in-domain synthetic data. We employ a three-step approach
to train a high-quality single-speaker TTS system in a low-resource Indian
language Hindi. We use a Tacotron2 like setup with a spectrogram prediction
network and a waveglow vocoder. The Tacotron2 acoustic model is trained on
English data, followed by synthetic Hindi data from the existing TTS system.
Finally, the decoder of this model is fine-tuned on only 3 hours of target
Hindi speaker data to enable rapid speaker adaptation. We show the importance
of this dual pre-training and decoder-only fine-tuning using subjective MOS
evaluation. Using transfer learning from high-resource language and synthetic
corpus we present a low-cost solution to train a custom TTS model.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01109" title="Abstract">arXiv:2312.01109</a> [<a href="/pdf/2312.01109" title="Download PDF">pdf</a>, <a href="/format/2312.01109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in  the Age of Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunder%2C+N">Nora Dunder</a>, 
<a href="/search/cs?searchtype=author&query=Lundborg%2C+S">Saga Lundborg</a>, 
<a href="/search/cs?searchtype=author&query=Viberg%2C+O">Olga Viberg</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+J">Jacqueline Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 3 tables. (Pre-print). Final version to be submitted to ACM Journals. LAK2024, March,18-22, 2024, Kyoto, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
<p class="mathjax">AI-powered education technologies can support students and teachers in
computer science education. However, with the recent developments in generative
AI, and especially the increasingly emerging popularity of ChatGPT, the
effectiveness of using large language models for solving programming tasks has
been underexplored. The present study examines ChatGPT's ability to generate
code solutions at different difficulty levels for introductory programming
courses. We conducted an experiment where ChatGPT was tested on 127 randomly
selected programming problems provided by Kattis, an automatic software grading
tool for computer science programs, often used in higher education. The results
showed that ChatGPT independently could solve 19 out of 127 programming tasks
generated and assessed by Kattis. Further, ChatGPT was found to be able to
generate accurate code solutions for simple problems but encountered
difficulties with more complex programming tasks. The results contribute to the
ongoing debate on the utility of AI-powered tools in programming education.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01110" title="Abstract">arXiv:2312.01110</a> [<a href="/pdf/2312.01110" title="Download PDF">pdf</a>, <a href="/ps/2312.01110" title="Download PostScript">ps</a>, <a href="/format/2312.01110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong Duality Relations in Nonconvex Risk-Constrained Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalogerias%2C+D">Dionysis Kalogerias</a>, 
<a href="/search/cs?searchtype=author&query=Pougkakiotis%2C+S">Spyridon Pougkakiotis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We establish strong duality relations for functional two-step compositional
risk-constrained learning problems with multiple nonconvex loss functions
and/or learning constraints, regardless of nonconvexity and under a minimal set
of technical assumptions. Our results in particular imply zero duality gaps
within the class of problems under study, both extending and improving on the
state of the art in (risk-neutral) constrained learning. More specifically, we
consider risk objectives/constraints which involve real-valued convex and
positively homogeneous risk measures admitting dual representations with
bounded risk envelopes, generalizing expectations and including popular
examples, such as the conditional value-at-risk (CVaR), the mean-absolute
deviation (MAD), and more generally all real-valued coherent risk measures on
integrable losses as special cases. Our results are based on recent advances in
risk-constrained nonconvex programming in infinite dimensions, which rely on a
remarkable new application of J. J. Uhl's convexity theorem, which is an
extension of A. A. Lyapunov's convexity theorem for general, infinite
dimensional Banach spaces. By specializing to the risk-neutral setting, we
demonstrate, for the first time, that constrained classification and regression
can be treated under a unifying lens, while dispensing certain restrictive
assumptions enforced in the current literature, yielding a new state-of-the-art
strong duality framework for nonconvex constrained learning.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01113" title="Abstract">arXiv:2312.01113</a> [<a href="/pdf/2312.01113" title="Download PDF">pdf</a>, <a href="/ps/2312.01113" title="Download PostScript">ps</a>, <a href="/format/2312.01113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malicious code detection in android: the role of sequence  characteristics and disassembling methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balikcioglu%2C+P+G">Pinar G. Balikcioglu</a>, 
<a href="/search/cs?searchtype=author&query=Sirlanci%2C+M">Melih Sirlanci</a>, 
<a href="/search/cs?searchtype=author&query=Kucuk%2C+O+A">Ozge A. Kucuk</a>, 
<a href="/search/cs?searchtype=author&query=Ulukapi%2C+B">Bulut Ulukapi</a>, 
<a href="/search/cs?searchtype=author&query=Turkmen%2C+R+K">Ramazan K. Turkmen</a>, 
<a href="/search/cs?searchtype=author&query=Acarturk%2C+C">Cengiz Acarturk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure, 8 tables, journal article
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Information Security, 22, 107-118 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The acceptance and widespread use of the Android operating system drew the
attention of both legitimate developers and malware authors, which resulted in
a significant number of benign and malicious applications available on various
online markets. Since the signature-based methods fall short for detecting
malicious software effectively considering the vast number of applications,
machine learning techniques in this field have also become widespread. In this
context, stating the acquired accuracy values in the contingency tables in
malware detection studies has become a popular and efficient method and enabled
researchers to evaluate their methodologies comparatively. In this study, we
wanted to investigate and emphasize the factors that may affect the accuracy
values of the models managed by researchers, particularly the disassembly
method and the input data characteristics. Firstly, we developed a model that
tackles the malware detection problem from a Natural Language Processing (NLP)
perspective using Long Short-Term Memory (LSTM). Then, we experimented with
different base units (instruction, basic block, method, and class) and
representations of source code obtained from three commonly used disassembling
tools (JEB, IDA, and Apktool) and examined the results. Our findings exhibit
that the disassembly method and different input representations affect the
model results. More specifically, the datasets collected by the Apktool
achieved better results compared to the other two disassemblers.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01114" title="Abstract">arXiv:2312.01114</a> [<a href="/pdf/2312.01114" title="Download PDF">pdf</a>, <a href="/format/2312.01114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TURead: An eye movement dataset of Turkish reading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acarturk%2C+C">Cengiz Acarturk</a>, 
<a href="/search/cs?searchtype=author&query=Ozkan%2C+A">Aysegul Ozkan</a>, 
<a href="/search/cs?searchtype=author&query=Pekcetin%2C+T+N">Tugce Nur Pekcetin</a>, 
<a href="/search/cs?searchtype=author&query=Ormanoglu%2C+Z">Zuhal Ormanoglu</a>, 
<a href="/search/cs?searchtype=author&query=Kirkici%2C+B">Bilal Kirkici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures, 23 tables, Behavior Research Methods (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this study, we present TURead, an eye movement dataset of silent and oral
sentence reading in Turkish, an agglutinative language with a shallow
orthography understudied in reading research. TURead provides empirical data to
investigate the relationship between morphology and oculomotor control. We
employ a target-word approach in which target words are manipulated by word
length and by the addition of two commonly used suffixes in Turkish. The
dataset contains well-established eye movement variables; prelexical
characteristics such as vowel harmony and bigram-trigram frequencies and word
features, such as word length, predictability, frequency, eye voice span
measures, Cloze test scores of the root word and suffix predictabilities, as
well as the scores obtained from two working memory tests. Our findings on
fixation parameters and word characteristics are in line with the patterns
reported in the relevant literature.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01116" title="Abstract">arXiv:2312.01116</a> [<a href="/pdf/2312.01116" title="Download PDF">pdf</a>, <a href="/format/2312.01116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Deterministic and Nondeterministic Decision Trees for  Decision Tables with Many-valued Decisions from Closed Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostonov%2C+A">Azimkhon Ostonov</a>, 
<a href="/search/cs?searchtype=author&query=Moshkov%2C+M">Mikhail Moshkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper, we consider classes of decision tables with many-valued
decisions closed relative to removal of attributes (columns) and changing sets
of decisions assigned to rows. For tables from an arbitrary closed class, we
study a function $\mathcal{H}^{\infty}_{\psi ,A}(n)$ that characterizes the
dependence in the worst case of the minimum complexity of deterministic
decision trees on the minimum complexity of nondeterministic decision trees.
Note that nondeterministic decision trees for a decision table can be
interpreted as a way to represent an arbitrary system of true decision rules
for this table that cover all rows. We indicate the condition for the function
$\mathcal{H}^{\infty}_{\psi ,A}(n)$ to be defined everywhere. If this function
is everywhere defined, then it is either bounded from above by a constant or is
greater than or equal to $n$ for infinitely many $n$. In particular, for any
nondecreasing function $\varphi$ such that $\varphi (n)\geq n$ and $\varphi
(0)=0$, the function $\mathcal{H}^{\infty}_{\psi ,A}(n)$ can grow between
$\varphi (n)$ and $\varphi (n)+n$. We indicate also conditions for the function
$\mathcal{H}^{\infty}_{\psi,A}(n)$ to be bounded from above by a polynomial on
$n$.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01117" title="Abstract">arXiv:2312.01117</a> [<a href="/pdf/2312.01117" title="Download PDF">pdf</a>, <a href="/format/2312.01117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paved2Paradise: Cost-Effective and Scalable LiDAR Simulation by  Factoring the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcorn%2C+M+A">Michael A. Alcorn</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+N">Noah Schwartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">To achieve strong real world performance, neural networks must be trained on
large, diverse datasets; however, obtaining and annotating such datasets is
costly and time-consuming, particularly for 3D point clouds. In this paper, we
describe Paved2Paradise, a simple, cost-effective approach for generating fully
labeled, diverse, and realistic lidar datasets from scratch, all while
requiring minimal human annotation. Our key insight is that, by deliberately
collecting separate "background" and "object" datasets (i.e., "factoring the
real world"), we can intelligently combine them to produce a combinatorially
large and diverse training set. The Paved2Paradise pipeline thus consists of
four steps: (1) collecting copious background data, (2) recording individuals
from the desired object class(es) performing different behaviors in an isolated
environment (like a parking lot), (3) bootstrapping labels for the object
dataset, and (4) generating samples by placing objects at arbitrary locations
in backgrounds. To demonstrate the utility of Paved2Paradise, we generated
synthetic datasets for two tasks: (1) human detection in orchards (a task for
which no public data exists) and (2) pedestrian detection in urban
environments. Qualitatively, we find that a model trained exclusively on
Paved2Paradise synthetic data is highly effective at detecting humans in
orchards, including when individuals are heavily occluded by tree branches.
Quantitatively, a model trained on Paved2Paradise data that sources backgrounds
from KITTI performs comparably to a model trained on the actual dataset. These
results suggest the Paved2Paradise synthetic data pipeline can help accelerate
point cloud model development in sectors where acquiring lidar datasets has
previously been cost-prohibitive.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01118" title="Abstract">arXiv:2312.01118</a> [<a href="/pdf/2312.01118" title="Download PDF">pdf</a>, <a href="/format/2312.01118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Accuracy: Statistical Measures and Benchmark for Evaluation of  Representation from Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiantao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Atito%2C+S">Sara Atito</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhenhua Feng</a>, 
<a href="/search/cs?searchtype=author&query=Awais%2C+M">Muhammad Awais</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, self-supervised metric learning has raised attention for the
potential to learn a generic distance function. It overcomes the limitations of
conventional supervised one, e.g., scalability and label biases. Despite
progress in this domain, current benchmarks, incorporating a narrow scope of
classes, stop the nuanced evaluation of semantic representations. To bridge
this gap, we introduce a large-scale benchmark with diversity and granularity
of classes, Statistical Metric Learning Benchmark (SMLB) built upon
ImageNet-21K and WordNet. SMLB is designed to rigorously evaluate the
discriminative discernment and generalizability across more than 14M images,
20K classes, and 16K taxonomic nodes. Alongside, we propose novel evaluation
metrics -- `overlap' for separability and `aSTD' for consistency -- to measure
distance statistical information, which are efficient and robust to the change
of class number. Our benchmark offers a novel perspective of evaluating the
quality of representations beyond accuracy. Our findings reveal the limitations
of supervised learning and the class bias inherent in SSL models, offering
insights into potential areas for future model enhancement.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01121" title="Abstract">arXiv:2312.01121</a> [<a href="/pdf/2312.01121" title="Download PDF">pdf</a>, <a href="/format/2312.01121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual reservoir acceleration for CPU and GPU: Case study for coupled  spin-torque oscillator reservoir
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Jong%2C+T+G">Thomas Geert de Jong</a>, 
<a href="/search/cs?searchtype=author&query=Akashi%2C+N">Nozomi Akashi</a>, 
<a href="/search/cs?searchtype=author&query=Taniguchi%2C+T">Tomohiro Taniguchi</a>, 
<a href="/search/cs?searchtype=author&query=Notsu%2C+H">Hirofumi Notsu</a>, 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+K">Kohei Nakajima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We provide high-speed implementations for simulating reservoirs described by
$N$-coupled spin-torque oscillators. Here $N$ also corresponds to the number of
reservoir nodes. We benchmark a variety of implementations based on CPU and
GPU. Our new methods are at least 2.6 times quicker than the baseline for $N$
in range $1$ to $10^4$. More specifically, over all implementations the best
factor is 78.9 for $N=1$ which decreases to 2.6 for $N=10^3$ and finally
increases to 23.8 for $N=10^4$. GPU outperforms CPU significantly at $N=2500$.
Our results show that GPU implementations should be tested for reservoir
simulations. The implementations considered here can be used for any reservoir
with evolution that can be approximated using an explicit method.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01125" title="Abstract">arXiv:2312.01125</a> [<a href="/pdf/2312.01125" title="Download PDF">pdf</a>, <a href="/format/2312.01125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Performance Analysis of Index Modulation Empowered AFDM  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lixia Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this letter, we incorporate index modulation (IM) into affine frequency
division multiplexing (AFDM), called AFDM-IM, to enhance the bit error rate
(BER) and energy efficiency (EE) performance. In this scheme, the information
bits are conveyed not only by $M$-ary constellation symbols, but also by the
activation of the chirp subcarriers (SCs) indices, which are determined based
on the incoming bit streams. Then, two power allocation strategies, namely
power reallocation (PR) strategy and power saving (PS) strategy, are proposed
to enhance BER and EE performance, respectively. Furthermore, the average bit
error probability (ABEP) is theoretically analyzed. Simulation results
demonstrate that the proposed AFDM-IM scheme achieves better BER performance
than the conventional AFDM scheme.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01126" title="Abstract">arXiv:2312.01126</a> [<a href="/pdf/2312.01126" title="Download PDF">pdf</a>, <a href="/format/2312.01126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BER Analysis of SCMA-OFDM Systems in the Presence of Carrier Frequency  Offset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Rongping Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sparse code multiple access (SCMA) building upon orthogonal frequency
division multiplexing (OFDM) is a promising wireless technology for supporting
massive connectivity in future machine-type communication networks. However,
the sensitivity of OFDM to carrier frequency offset (CFO) poses a major
challenge because it leads to orthogonality loss and incurs intercarrier
interference (ICI). In this paper, we investigate the bit error rate (BER)
performance of SCMA-OFDM systems in the presence of CFO over both Gaussian and
multipath Rayleigh fading channels. We first model the ICI in SCMA-OFDM as
Gaussian variables conditioned on a single channel realization for fading
channels. The BER is then evaluated by averaging over all codeword pairs
considering the fading statistics. Through simulations, we validate the
accuracy of our BER analysis and reveal that there is a significant BER
degradation for SCMA-OFDM systems when the normalized CFO exceeds 0.02.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01129" title="Abstract">arXiv:2312.01129</a> [<a href="/pdf/2312.01129" title="Download PDF">pdf</a>, <a href="/format/2312.01129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlDreamer: Stylized 3D Generation with Multi-View ControlNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Yeongtak Oh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jooyoung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+C">Chaehun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungroh Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in text-to-3D generation have significantly contributed
to the automation and democratization of 3D content creation. Building upon
these developments, we aim to address the limitations of current methods in
generating 3D models with creative geometry and styles. We introduce multi-view
ControlNet, a novel depth-aware multi-view diffusion model trained on generated
datasets from a carefully curated 100K text corpus. Our multi-view ControlNet
is then integrated into our two-stage pipeline, ControlDreamer, enabling
text-guided generation of stylized 3D models. Additionally, we present a
comprehensive benchmark for 3D style editing, encompassing a broad range of
subjects, including objects, animals, and characters, to further facilitate
diverse 3D generation. Our comparative analysis reveals that this new pipeline
outperforms existing text-to-3D methods as evidenced by qualitative comparisons
and CLIP score metrics.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01130" title="Abstract">arXiv:2312.01130</a> [<a href="/pdf/2312.01130" title="Download PDF">pdf</a>, <a href="/format/2312.01130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STREAM: Software Tool for Routing Efficiently Advanced Macrofluidics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lehong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kendre%2C+S+V">Savita V. Kendre</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nemitz%2C+M+P">Markus P. Nemitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The current fabrication and assembly of fluidic circuits for soft robots
relies heavily on manual processes; as the complexity of fluidic circuits
increases, manual assembly becomes increasingly arduous, error-prone, and
timeconsuming. We introduce a software tool that generates printable fluidic
networks automatically. We provide a library of fluidic logic elements that are
easily 3D printed from thermoplastic polyurethanes using Fused Deposition
Modeling only. Our software tool and component library allow the development of
arbitrary soft digital circuits. We demonstrate a variable frequency ring
oscillator and a full adder. The simplicity of our approach using FDM printers
only, democratizes fluidic circuit implementation beyond specialized
laboratories. Our software is available on GitHub
(https://github.com/roboticmaterialsgroup/FluidLogic).
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01131" title="Abstract">arXiv:2312.01131</a> [<a href="/pdf/2312.01131" title="Download PDF">pdf</a>, <a href="/format/2312.01131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FDM Printing: a Fabrication Method for Fluidic Soft Circuits?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kendre%2C+S+V">Savita V. Kendre</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lehong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wilke%2C+E">Ethan Wilke</a>, 
<a href="/search/cs?searchtype=author&query=Pacheco%2C+N">Nicholas Pacheco</a>, 
<a href="/search/cs?searchtype=author&query=Fichera%2C+L">Loris Fichera</a>, 
<a href="/search/cs?searchtype=author&query=Nemitz%2C+M+P">Markus P. Nemitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, IEEE RoboSoft 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Existing fluidic soft logic gates for the control of soft robots either rely
on extensive manual fabrication processes or expensive printing techniques. In
our work, we explore Fused Deposition Modeling for creating fully 3D printed
fluidic logic gates. We print a soft bistable valve from thermoplastic
polyurethane using a desktop FDM printer. We introduce a new printing nozzle
for extruding tubing. Our fabrication strategy reduces the production time of
soft bistable valves from 27 hours with replica molding to 3 hours with a FDM
printer. Our rapid and cost-effective fabrication process for fluidic logic
gates seeks to democratize fluidic circuitry for the control of soft robots.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01135" title="Abstract">arXiv:2312.01135</a> [<a href="/pdf/2312.01135" title="Download PDF">pdf</a>, <a href="/format/2312.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-based FDM Printing for Fabricating Airtight Soft Actuators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zilin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lehong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nemitz%2C+M+P">Markus P. Nemitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, IEEE RoboSoft conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Pneumatic soft robots are typically fabricated by molding, a manual
fabrication process that requires skilled labor. Additive manufacturing has the
potential to break this limitation and speed up the fabrication process but
struggles with consistently producing high-quality prints. We propose a
low-cost approach to improve the print quality of desktop fused deposition
modeling by adding a webcam to the printer to monitor the printing process and
detect and correct defects such as holes or gaps. We demonstrate that our
approach improves the air-tightness of printed pneumatic actuators without
fine-tuning printing parameters. Our approach presents a new option for
robustly fabricating airtight, soft robotic actuators.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01137" title="Abstract">arXiv:2312.01137</a> [<a href="/pdf/2312.01137" title="Download PDF">pdf</a>, <a href="/format/2312.01137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Robust Sparsity-Aware Block Diagonal Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tastan%2C+A">Aylin Tastan</a>, 
<a href="/search/cs?searchtype=author&query=Muma%2C+M">Michael Muma</a>, 
<a href="/search/cs?searchtype=author&query=Zoubir%2C+A+M">Abdelhak M.Zoubir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages article, 4 pages supplementary, 51 pages accompanying material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The block diagonal structure of an affinity matrix is a commonly desired
property in cluster analysis because it represents clusters of feature vectors
by non-zero coefficients that are concentrated in blocks. However, recovering a
block diagonal affinity matrix is challenging in real-world applications, in
which the data may be subject to outliers and heavy-tailed noise that obscure
the hidden cluster structure. To address this issue, we first analyze the
effect of different fundamental outlier types in graph-based cluster analysis.
A key idea that simplifies the analysis is to introduce a vector that
represents a block diagonal matrix as a piece-wise linear function of the
similarity coefficients that form the affinity matrix. We reformulate the
problem as a robust piece-wise linear fitting problem and propose a Fast and
Robust Sparsity-Aware Block Diagonal Representation (FRS-BDR) method, which
jointly estimates cluster memberships and the number of blocks. Comprehensive
experiments on a variety of real-world applications demonstrate the
effectiveness of FRS-BDR in terms of clustering accuracy, robustness against
corrupted features, computation time and cluster enumeration performance.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01143" title="Abstract">arXiv:2312.01143</a> [<a href="/pdf/2312.01143" title="Download PDF">pdf</a>, <a href="/format/2312.01143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards leveraging LLMs for Conditional QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+S">Syed-Amad Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Dakle%2C+P+P">Parag Pravin Dakle</a>, 
<a href="/search/cs?searchtype=author&query=Rallabandi%2C+S">SaiKrishna Rallabandi</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+P">Preethi Raghavan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study delves into the capabilities and limitations of Large Language
Models (LLMs) in the challenging domain of conditional question-answering.
Utilizing the Conditional Question Answering (CQA) dataset and focusing on
generative models like T5 and UL2, we assess the performance of LLMs across
diverse question types. Our findings reveal that fine-tuned LLMs can surpass
the state-of-the-art (SOTA) performance in some cases, even without fully
encoding all input context, with an increase of 7-8 points in Exact Match (EM)
and F1 scores for Yes/No questions. However, these models encounter challenges
in extractive question answering, where they lag behind the SOTA by over 10
points, and in mitigating the risk of injecting false information. A study with
oracle-retrievers emphasizes the critical role of effective evidence retrieval,
underscoring the necessity for advanced solutions in this area. Furthermore, we
highlight the significant influence of evaluation metrics on performance
assessments and advocate for a more comprehensive evaluation framework. The
complexity of the task, the observed performance discrepancies, and the need
for effective evidence retrieval underline the ongoing challenges in this field
and underscore the need for future work focusing on refining training tasks and
exploring prompt-based techniques to enhance LLM performance in conditional
question-answering tasks.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01148" title="Abstract">arXiv:2312.01148</a> [<a href="/pdf/2312.01148" title="Download PDF">pdf</a>, <a href="/format/2312.01148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Has Anything Changed? 3D Change Detection by 2D Segmentation Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adam%2C+A">Aikaterini Adam</a>, 
<a href="/search/cs?searchtype=author&query=Karantzalos%2C+K">Konstantinos Karantzalos</a>, 
<a href="/search/cs?searchtype=author&query=Grammatikopoulos%2C+L">Lazaros Grammatikopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+T">Torsten Sattler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As capturing devices become common, 3D scans of interior spaces are acquired
on a daily basis. Through scene comparison over time, information about objects
in the scene and their changes is inferred. This information is important for
robots and AR and VR devices, in order to operate in an immersive virtual
experience. We thus propose an unsupervised object discovery method that
identifies added, moved, or removed objects without any prior knowledge of what
objects exist in the scene. We model this problem as a combination of a 3D
change detection and a 2D segmentation task. Our algorithm leverages generic 2D
segmentation masks to refine an initial but incomplete set of 3D change
detections. The initial changes, acquired through render-and-compare likely
correspond to movable objects. The incomplete detections are refined through
graph optimization, distilling the information of the 2D segmentation masks in
the 3D space. Experiments on the 3Rscan dataset prove that our method
outperforms competitive baselines, with SoTA results.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01149" title="Abstract">arXiv:2312.01149</a> [<a href="/pdf/2312.01149" title="Download PDF">pdf</a>, <a href="/format/2312.01149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disjoint Dominating and 2-Dominating Sets in Graphs: Hardness and  Approximation results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rana%2C+S">Soumyashree Rana</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Sounaka Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+B+S">Bhawani Sankar Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, submitted to discrete optimisation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A set $D \subseteq V$ of a graph $G=(V, E)$ is a dominating set of $G$ if
each vertex $v\in V\setminus D$ is adjacent to at least one vertex in $D,$
whereas a set $D_2\subseteq V$ is a $2$-dominating (double dominating) set of
$G$ if each vertex $v\in V \setminus D_2$ is adjacent to at least two vertices
in $D_2.$ A graph $G$ is a $DD_2$-graph if there exists a pair ($D, D_2$) of
dominating set and $2$-dominating set of $G$ which are disjoint. In this paper,
we solve some open problems posed by M.Miotk, J.~Topp and P.{\.Z}yli{\'n}ski
(Disjoint dominating and 2-dominating sets in graphs, Discrete Optimization,
35:100553, 2020) by giving approximation algorithms for the problem of
determining a minimal spanning $DD_2$-graph of minimum size (Min-$DD_2$) with
an approximation ratio of $3$; a minimal spanning $DD_2$-graph of maximum size
(Max-$DD_2$) with an approximation ratio of $3$; and for the problem of adding
minimum number of edges to a graph $G$ to make it a $DD_2$-graph
(Min-to-$DD_2$) with an $O(\log n)$ approximation ratio. Furthermore, we prove
that Min-$DD_2$ and Max-$DD_2$ are APX-complete for graphs with maximum degree
$4$. We also show that Min-$DD_2$ and Max-$DD_2$ are approximable within a
factor of $1.8$ and $1.5$ respectively, for any $3$-regular graph. Finally, we
show the inapproximability result of Max-Min-to-$DD_2$ for bipartite graphs,
that this problem can not be approximated within $n^{\frac{1}{6}-\varepsilon}$
for any $\varepsilon &gt;0,$ unless P=NP.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01150" title="Abstract">arXiv:2312.01150</a> [<a href="/pdf/2312.01150" title="Download PDF">pdf</a>, <a href="/format/2312.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointer Networks Trained Better via Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Muyao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Tand%2C+K">Ke Tand</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> None
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Pointer Network (PtrNet) is a specific neural network for solving
Combinatorial Optimization Problems (COPs). While PtrNets offer real-time
feed-forward inference for complex COPs instances, its quality of the results
tends to be less satisfactory. One possible reason is that such issue suffers
from the lack of global search ability of the gradient descent, which is
frequently employed in traditional PtrNet training methods including both
supervised learning and reinforcement learning. To improve the performance of
PtrNet, this paper delves deeply into the advantages of training PtrNet with
Evolutionary Algorithms (EAs), which have been widely acknowledged for not
easily getting trapped by local optima. Extensive empirical studies based on
the Travelling Salesman Problem (TSP) have been conducted. Results demonstrate
that PtrNet trained with EA can consistently perform much better inference
results than eight state-of-the-art methods on various problem scales. Compared
with gradient descent based PtrNet training methods, EA achieves up to 30.21\%
improvement in quality of the solution with the same computational time. With
this advantage, this paper is able to at the first time report the results of
solving 1000-dimensional TSPs by training a PtrNet on the same dimensionality,
which strongly suggests that scaling up the training instances is in need to
improve the performance of PtrNet on solving higher-dimensional COPs.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01151" title="Abstract">arXiv:2312.01151</a> [<a href="/pdf/2312.01151" title="Download PDF">pdf</a>, <a href="/ps/2312.01151" title="Download PostScript">ps</a>, <a href="/format/2312.01151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Here Is Not There: Measuring Entailment-Based Trajectory Similarity for  Location-Privacy Protection and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Janowicz%2C+K">Krzysztof Janowicz</a>, 
<a href="/search/cs?searchtype=author&query=Currier%2C+K">Kitty Currier</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Meilin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinmeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Ling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Graser%2C+A">Anita Graser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">While the paths humans take play out in social as well as physical space,
measures to describe and compare their trajectories are carried out in
abstract, typically Euclidean, space. When these measures are applied to
trajectories of actual individuals in an application area, alterations that are
inconsequential in abstract space may suddenly become problematic once overlaid
with geographic reality. In this work, we present a different view on
trajectory similarity by introducing a measure that utilizes logical
entailment. This is an inferential perspective that considers facts as triple
statements deduced from the social and environmental context in which the
travel takes place, and their practical implications. We suggest a
formalization of entailment-based trajectory similarity, measured as the
overlapping proportion of facts, which are spatial relation statements in our
case study. With the proposed measure, we evaluate LSTM-TrajGAN, a
privacy-preserving trajectory-generation model. The entailment-based model
evaluation reveals potential consequences of disregarding the rich structure of
geographic space (e.g., miscalculated insurance risk due to regional shifts in
our toy example). Our work highlights the advantage of applying logical
entailment to trajectory-similarity reasoning for location-privacy protection
and beyond.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01163" title="Abstract">arXiv:2312.01163</a> [<a href="/pdf/2312.01163" title="Download PDF">pdf</a>, <a href="/format/2312.01163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Learning Paradigm for Foundation Model-based Remote Sensing Change  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kaiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiangyong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Change detection (CD) is a critical task to observe and analyze dynamic
processes of land cover. Although numerous deep learning-based CD models have
performed excellently, their further performance improvements are constrained
by the limited knowledge extracted from the given labelled data. On the other
hand, the foundation models that emerged recently contain a huge amount of
knowledge by scaling up across data modalities and proxy tasks. In this paper,
we propose a Bi-Temporal Adapter Network (BAN), which is a universal foundation
model-based CD adaptation framework aiming to extract the knowledge of
foundation models for CD. The proposed BAN contains three parts, i.e. frozen
foundation model (e.g., CLIP), bitemporal adapter branch (Bi-TAB), and bridging
modules between them. Specifically, the Bi-TAB can be either an existing
arbitrary CD model or some hand-crafted stacked blocks. The bridging modules
are designed to align the general features with the task/domain-specific
features and inject the selected general knowledge into the Bi-TAB. To our
knowledge, this is the first universal framework to adapt the foundation model
to the CD task. Extensive experiments show the effectiveness of our BAN in
improving the performance of existing CD methods (e.g., up to 4.08\% IoU
improvement) with only a few additional learnable parameters. More importantly,
these successful practices show us the potential of foundation models for
remote sensing CD. The code is available at \url{https://github.com/likyoo/BAN}
and will be supported in our Open-CD \url{https://github.com/likyoo/open-cd}.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01164" title="Abstract">arXiv:2312.01164</a> [<a href="/pdf/2312.01164" title="Download PDF">pdf</a>, <a href="/format/2312.01164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telling stories with data -- A systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+K">Kay Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Eberhardt%2C+W">Wiebke Eberhardt</a>, 
<a href="/search/cs?searchtype=author&query=Belavadi%2C+P">Poornima Belavadi</a>, 
<a href="/search/cs?searchtype=author&query=Ajdadilish%2C+B">Batoul Ajdadilish</a>, 
<a href="/search/cs?searchtype=author&query=van+Haften%2C+N">Nanette van Haften</a>, 
<a href="/search/cs?searchtype=author&query=Overes%2C+E">Ed Overes</a>, 
<a href="/search/cs?searchtype=author&query=Brouns%2C+T">Taryn Brouns</a>, 
<a href="/search/cs?searchtype=author&query=Valdez%2C+A+C">Andr&#xe9; Calero Valdez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The exponential growth of data has outpaced human ability to process
information, necessitating innovative approaches for effective human-data
interaction. To transform raw data into meaningful insights, storytelling, and
visualization have emerged as powerful techniques for communicating complex
information to decision-makers. This article offers a comprehensive, systematic
review of the utilization of storytelling in visualizations. It organizes the
existing literature into distinct categories, encompassing frameworks, data and
visualization types, application domains, narrative structures, outcome
measurements, and design principles. By providing a well-structured overview of
this rapidly evolving field, the article serves as a valuable guide for
educators, researchers, and practitioners seeking to harness the power of
storytelling in data visualization.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01167" title="Abstract">arXiv:2312.01167</a> [<a href="/pdf/2312.01167" title="Download PDF">pdf</a>, <a href="/format/2312.01167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learned Attribute Self-Interaction Network for Continual and  Generalized Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+V+K">Vinay K Verma</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N">Nikhil Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K+J">Kevin J Liang</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aakansha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Carin%2C+L">Lawrence Carin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Zero-shot learning (ZSL) is a promising approach to generalizing a model to
categories unseen during training by leveraging class attributes, but
challenges remain. Recently, methods using generative models to combat bias
towards classes seen during training have pushed state of the art, but these
generative models can be slow or computationally expensive to train. Also,
these generative models assume that the attribute vector of each unseen class
is available a priori at training, which is not always practical. Additionally,
while many previous ZSL methods assume a one-time adaptation to unseen classes,
in reality, the world is always changing, necessitating a constant adjustment
of deployed models. Models unprepared to handle a sequential stream of data are
likely to experience catastrophic forgetting. We propose a Meta-learned
Attribute self-Interaction Network (MAIN) for continual ZSL. By pairing
attribute self-interaction trained using meta-learning with inverse
regularization of the attribute encoder, we are able to outperform
state-of-the-art results without leveraging the unseen class attributes while
also being able to train our models substantially faster (&gt;100x) than expensive
generative-based approaches. We demonstrate this with experiments on five
standard ZSL datasets (CUB, aPY, AWA1, AWA2, and SUN) in the generalized
zero-shot learning and continual (fixed/dynamic) zero-shot learning settings.
Extensive ablations and analyses demonstrate the efficacy of various components
proposed.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01169" title="Abstract">arXiv:2312.01169</a> [<a href="/pdf/2312.01169" title="Download PDF">pdf</a>, <a href="/format/2312.01169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Category Learning: A Semi-Supervised Learning Method for Dense  Prediction with Extremely Limited Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Debattista%2C+K">Kurt Debattista</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> T-PAMI under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the costliness of labelled data in real-world applications,
semi-supervised learning, underpinned by pseudo labelling, is an appealing
solution. However, handling confusing samples is nontrivial: discarding
valuable confusing samples would compromise the model generalisation while
using them for training would exacerbate the issue of confirmation bias caused
by the resulting inevitable mislabelling. To solve this problem, this paper
proposes to use confusing samples proactively without label correction.
Specifically, a Virtual Category (VC) is assigned to each confusing sample in
such a way that it can safely contribute to the model optimisation even without
a concrete label. This provides an upper bound for inter-class information
sharing capacity, which eventually leads to a better embedding space. Extensive
experiments on two mainstream dense prediction tasks -- semantic segmentation
and object detection, demonstrate that the proposed VC learning significantly
surpasses the state-of-the-art, especially when only very few labels are
available. Our intriguing findings highlight the usage of VC learning in dense
vision tasks.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01170" title="Abstract">arXiv:2312.01170</a> [<a href="/pdf/2312.01170" title="Download PDF">pdf</a>, <a href="/format/2312.01170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power-balanced Memristive Cryptographic Implementation Against Side  Channel Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xianyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+H">Heidemarie Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Polian%2C+I">Ilia Polian</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Memristors, as emerging nano-devices, offer promising performance and exhibit
rich electrical dynamic behavior. Having already found success in applications
such as neuromorphic and in-memory computing, researchers are now exploring
their potential for cryptographic implementations. In this study, we present a
novel power-balanced hiding strategy utilizing memristor groups to conceal
power consumption in cryptographic logic circuits. Our approach ensures
consistent power costs of all 16 logic gates in
Complementary-Resistive-Switching-with-Reading (CRS-R) logic family during
writing and reading cycles regardless of Logic Input Variable (LIV) values. By
constructing hiding groups, we enable an effective power balance in each gate
hiding group. Furthermore, experimental validation of our strategy includes the
implementation of a cryptographic construction, xor4SBox, using NOR gates. The
circuit construction without the hiding strategy and with the hiding strategy
undergo T-test analysis, confirming the significant improvement achieved with
our approach. Our work presents a substantial advancement in power-balanced
hiding methods, offering enhanced security and efficiency in logic circuits.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01172" title="Abstract">arXiv:2312.01172</a> [<a href="/pdf/2312.01172" title="Download PDF">pdf</a>, <a href="/format/2312.01172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-sensor Printed Machine Learning Classification via Bespoke ADC and  Decision Tree Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Armeniakos%2C+G">Giorgos Armeniakos</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+P+L">Paula L. Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+P">Priyanjana Pal</a>, 
<a href="/search/cs?searchtype=author&query=Zervakis%2C+G">Georgios Zervakis</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B. Tahoori</a>, 
<a href="/search/cs?searchtype=author&query=Soudris%2C+D">Dimitrios Soudris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 27th Design, Automation and Test in Europe Conference (DATE'24), Mar 25-27 2024, Valencia, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Printed electronics (PE) technology provides cost-effective hardware with
unmet customization, due to their low non-recurring engineering and fabrication
costs. PE exhibit features such as flexibility, stretchability, porosity, and
conformality, which make them a prominent candidate for enabling ubiquitous
computing. Still, the large feature sizes in PE limit the realization of
complex printed circuits, such as machine learning classifiers, especially when
processing sensor inputs is necessary, mainly due to the costly
analog-to-digital converters (ADCs). To this end, we propose the design of
fully customized ADCs and present, for the first time, a co-design framework
for generating bespoke Decision Tree classifiers. Our comprehensive evaluation
shows that our co-design enables self-powered operation of on-sensor printed
classifiers in all benchmark cases.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01177" title="Abstract">arXiv:2312.01177</a> [<a href="/pdf/2312.01177" title="Download PDF">pdf</a>, <a href="/ps/2312.01177" title="Download PostScript">ps</a>, <a href="/format/2312.01177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDPL-PFOD2: A New Large-Scale Dataset for Printed Farsi Optical  Character Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asadi-zeydabadi%2C+F">Fatemeh Asadi-zeydabadi</a>, 
<a href="/search/cs?searchtype=author&query=Afkari-Fahandari%2C+A">Ali Afkari-Fahandari</a>, 
<a href="/search/cs?searchtype=author&query=Faraji%2C+A">Amin Faraji</a>, 
<a href="/search/cs?searchtype=author&query=Shabaninia%2C+E">Elham Shabaninia</a>, 
<a href="/search/cs?searchtype=author&query=Nezamabadi-pour%2C+H">Hossein Nezamabadi-pour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Optical Character Recognition is a technique that converts document images
into searchable and editable text, making it a valuable tool for processing
scanned documents. While the Farsi language stands as a prominent and official
language in Asia, efforts to develop efficient methods for recognizing Farsi
printed text have been relatively limited. This is primarily attributed to the
languages distinctive features, such as cursive form, the resemblance between
certain alphabet characters, and the presence of numerous diacritics and dot
placement. On the other hand, given the substantial training sample
requirements of deep-based architectures for effective performance, the
development of such datasets holds paramount significance. In light of these
concerns, this paper aims to present a novel large-scale dataset, IDPL-PFOD2,
tailored for Farsi printed text recognition. The dataset comprises 2003541
images featuring a wide variety of fonts, styles, and sizes. This dataset is an
extension of the previously introduced IDPL-PFOD dataset, offering a
substantial increase in both volume and diversity. Furthermore, the datasets
effectiveness is assessed through the utilization of both CRNN-based and Vision
Transformer architectures. The CRNN-based model achieves a baseline accuracy
rate of 78.49% and a normalized edit distance of 97.72%, while the Vision
Transformer architecture attains an accuracy of 81.32% and a normalized edit
distance of 98.74%.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01178" title="Abstract">arXiv:2312.01178</a> [<a href="/pdf/2312.01178" title="Download PDF">pdf</a>, <a href="/format/2312.01178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring a Hybrid Deep Learning Framework to Automatically Discover  Topic and Sentiment in COVID-19 Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+K+T">Khandaker Tayef Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+I+H">Iqbal H. Sarker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">COVID-19 has created a major public health problem worldwide and other
problems such as economic crisis, unemployment, mental distress, etc. The
pandemic is deadly in the world and involves many people not only with
infection but also with problems, stress, wonder, fear, resentment, and hatred.
Twitter is a highly influential social media platform and a significant source
of health-related information, news, opinion and public sentiment where
information is shared by both citizens and government sources. Therefore an
effective analysis of COVID-19 tweets is essential for policymakers to make
wise decisions. However, it is challenging to identify interesting and useful
content from major streams of text to understand people's feelings about the
important topics of the COVID-19 tweets. In this paper, we propose a new
\textit{framework} for analyzing topic-based sentiments by extracting key
topics with significant labels and classifying positive, negative, or neutral
tweets on each topic to quickly find common topics of public opinion and
COVID-19-related attitudes. While building our model, we take into account
hybridization of BiLSTM and GRU structures for sentiment analysis to achieve
our goal. The experimental results show that our topic identification method
extracts better topic labels and the sentiment analysis approach using our
proposed hybrid deep learning model achieves the highest accuracy compared to
traditional models.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01179" title="Abstract">arXiv:2312.01179</a> [<a href="/pdf/2312.01179" title="Download PDF">pdf</a>, <a href="/format/2312.01179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The time dimensional reduction method to determine the initial  conditions for nonlinear and nonlocal hyperbolic equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dang%2C+T+D">Trong D. Dang</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+L+H">Loc H. Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Vu%2C+H+T+T">Huong T. T. Vu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The objective of this paper is to compute initial conditions for quasi-linear
hyperbolic equations. Our proposed approach involves approximating the solution
of the hyperbolic equation by truncating its Fourier expansion in the time
domain using the polynomial-exponential basis. This truncation enables the
elimination of the time variable, resulting in a system of quasi-linear
elliptic equations. Thus, we refer to our approach as the "time dimensional
reduction method." To solve this system globally without requesting a good
initial guess, we employ the Carleman contraction principle. To demonstrate the
effectiveness of our method, we provide several numerical examples. The time
dimensional reduction method not only provides accurate solutions but also
exhibits exceptional computational speed.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01180" title="Abstract">arXiv:2312.01180</a> [<a href="/pdf/2312.01180" title="Download PDF">pdf</a>, <a href="/format/2312.01180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Text-to-Image Generative AI Models in  Scientific Contexts: A Case Study on Nuclear Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joynt%2C+V">Veda Joynt</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+J">Jacob Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+N">Naman Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+K">Katie Vu</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+O+H">O Hwang Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+T+R">Todd R. Allen</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Aditi Verma</a>, 
<a href="/search/cs?searchtype=author&query=Radaideh%2C+M+I">Majdi I. Radaideh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures, 9 tables, submitted to review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In this work, we propose and assess the potential of generative artificial
intelligence (AI) to generate public engagement around potential clean energy
sources. Such an application could increase energy literacy -- an awareness of
low-carbon energy sources among the public therefore leading to increased
participation in decision-making about the future of energy systems. We explore
the use of generative AI to communicate technical information about low-carbon
energy sources to the general public, specifically in the realm of nuclear
energy. We explored 20 AI-powered text-to-image generators and compared their
individual performances on general and scientific nuclear-related prompts. Of
these models, DALL-E, DreamStudio, and Craiyon demonstrated promising
performance in generating relevant images from general-level text related to
nuclear topics. However, these models fall short in three crucial ways: (1)
they fail to accurately represent technical details of energy systems; (2) they
reproduce existing biases surrounding gender and work in the energy sector; and
(3) they fail to accurately represent indigenous landscapes -- which have
historically been sites of resource extraction and waste deposition for energy
industries. This work is performed to motivate the development of specialized
generative tools and their captions to improve energy literacy and effectively
engage the public with low-carbon energy sources.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01183" title="Abstract">arXiv:2312.01183</a> [<a href="/pdf/2312.01183" title="Download PDF">pdf</a>, <a href="/format/2312.01183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Robotic Cholecystectomy Dataset (CRCD): Integrating  Kinematics, Pedal Signals, and Endoscopic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+K">Ki-Hwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Borgioli%2C+L">Leonardo Borgioli</a>, 
<a href="/search/cs?searchtype=author&query=Mangano%2C+A">Alberto Mangano</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+V">Valentina Valle</a>, 
<a href="/search/cs?searchtype=author&query=Di+Pangrazio%2C+M">Marco Di Pangrazio</a>, 
<a href="/search/cs?searchtype=author&query=Toti%2C+F">Francesco Toti</a>, 
<a href="/search/cs?searchtype=author&query=Pozza%2C+G">Gioia Pozza</a>, 
<a href="/search/cs?searchtype=author&query=Ambrosini%2C+L">Luciano Ambrosini</a>, 
<a href="/search/cs?searchtype=author&query=Ducas%2C+A">Alvaro Ducas</a>, 
<a href="/search/cs?searchtype=author&query=Zefran%2C+M">Milos Zefran</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liaohai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Giulianotti%2C+P+C">Pier Cristoforo Giulianotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, 4 tables, submitted to 2024 International Symposium on Medical Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, the potential applications of machine learning to Minimally
Invasive Surgery (MIS) have spurred interest in data sets that can be used to
develop data-driven tools. This paper introduces a novel dataset recorded
during ex vivo pseudo-cholecystectomy procedures on pig livers, utilizing the
da Vinci Research Kit (dVRK). Unlike current datasets, ours bridges a critical
gap by offering not only full kinematic data but also capturing all pedal
inputs used during the procedure and providing a time-stamped record of the
endoscope's movements. Contributed by seven surgeons, this data set introduces
a new dimension to surgical robotics research, allowing the creation of
advanced models for automating console functionalities. Our work addresses the
existing limitation of incomplete recordings and imprecise kinematic data,
common in other datasets. By introducing two models, dedicated to predicting
clutch usage and camera activation, we highlight the dataset's potential for
advancing automation in surgical robotics. The comparison of methodologies and
time windows provides insights into the models' boundaries and limitations.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01185" title="Abstract">arXiv:2312.01185</a> [<a href="/pdf/2312.01185" title="Download PDF">pdf</a>, <a href="/format/2312.01185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A ripple in time: a discontinuity in American history
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rivin%2C+I">Igor Rivin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures; GitHub repository <a href="https://github.com/sashakolpakov/ripple_in_time">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this note we use the State of the Union Address dataset from Kaggle to
make some surprising (and some not so surprising) observations pertaining to
the general timeline of American history, and the character and nature of the
addresses themselves. Our main approach is using vector embeddings, such as
BERT (DistilBERT) and GPT-2. While it is widely believed that BERT (and its
variations) is most suitable for NLP classification tasks, we find out that
GPT-2 in conjunction with nonlinear dimension reduction methods such as UMAP
provide better separation and stronger clustering. This makes GPT-2 + UMAP an
interesting alternative. In our case, no model fine-tuning is required, and the
pre-trained out-of-the-box GPT-2 model is enough. We also used a fine-tuned
DistilBERT model for classification (detecting which president delivered which
address), with very good results (accuracy 93% - 95% depending on the run). All
computations can be replicated by using the accompanying code on GitHub.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01187" title="Abstract">arXiv:2312.01187</a> [<a href="/pdf/2312.01187" title="Download PDF">pdf</a>, <a href="/format/2312.01187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojas-Gomez%2C+R+A">Renan A. Rojas-Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>, 
<a href="/search/cs?searchtype=author&query=Bijamov%2C+A">Alex Bijamov</a>, 
<a href="/search/cs?searchtype=author&query=Morningstar%2C+W+R">Warren R. Morningstar</a>, 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+P+A">Philip Andrew Mansfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Self-supervised learning relies heavily on data augmentation to extract
meaningful representations from unlabeled images. While existing
state-of-the-art augmentation pipelines incorporate a wide range of primitive
transformations, these often disregard natural image structure. Thus, augmented
samples can exhibit degraded semantic information and low stylistic diversity,
affecting downstream performance of self-supervised representations. To
overcome this, we propose SASSL: Style Augmentations for Self Supervised
Learning, a novel augmentation technique based on Neural Style Transfer. The
method decouples semantic and stylistic attributes in images and applies
transformations exclusively to the style while preserving content, generating
diverse augmented samples that better retain their semantic properties.
Experimental results show our technique achieves a top-1 classification
performance improvement of more than 2% on ImageNet compared to the
well-established MoCo v2. We also measure transfer learning performance across
five diverse datasets, observing significant improvements of up to 3.75%. Our
experiments indicate that decoupling style from content information and
transferring style across datasets to diversify augmentations can significantly
improve downstream performance of self-supervised representations.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01188" title="Abstract">arXiv:2312.01188</a> [<a href="/pdf/2312.01188" title="Download PDF">pdf</a>, <a href="/format/2312.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Expansion and Gradient Based Task Inference for Replay Free  Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Soumya Roy</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+V+K">Vinay K Verma</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepak Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be Appeared in WACV, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper proposes a simple but highly efficient expansion-based model for
continual learning. The recent feature transformation, masking and
factorization-based methods are efficient, but they grow the model only over
the global or shared parameter. Therefore, these approaches do not fully
utilize the previously learned information because the same task-specific
parameter forgets the earlier knowledge. Thus, these approaches show limited
transfer learning ability. Moreover, most of these models have constant
parameter growth for all tasks, irrespective of the task complexity. Our work
proposes a simple filter and channel expansion based method that grows the
model over the previous task parameters and not just over the global parameter.
Therefore, it fully utilizes all the previously learned information without
forgetting, which results in better knowledge transfer. The growth rate in our
proposed model is a function of task complexity; therefore for a simple task,
the model has a smaller parameter growth while for complex tasks, the model
requires more parameters to adapt to the current task. Recent expansion based
models show promising results for task incremental learning (TIL). However, for
class incremental learning (CIL), prediction of task id is a crucial challenge;
hence, their results degrade rapidly as the number of tasks increase. In this
work, we propose a robust task prediction method that leverages entropy
weighted data augmentations and the models gradient using pseudo labels. We
evaluate our model on various datasets and architectures in the TIL, CIL and
generative continual learning settings. The proposed approach shows
state-of-the-art results in all these settings. Our extensive ablation studies
show the efficacy of the proposed components.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01191" title="Abstract">arXiv:2312.01191</a> [<a href="/pdf/2312.01191" title="Download PDF">pdf</a>, <a href="/format/2312.01191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Interactive Image-Text Alignment for Remote Sensing Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, remote sensing image captioning has gained significant attention in
the remote sensing community. Due to the significant differences in spatial
resolution of remote sensing images, existing methods in this field have
predominantly concentrated on the fine-grained extraction of remote sensing
image features, but they cannot effectively handle the semantic consistency
between visual features and textual features. To efficiently align the
image-text, we propose a novel two-stage vision-language pre-training-based
approach to bootstrap interactive image-text alignment for remote sensing image
captioning, called BITA, which relies on the design of a lightweight
interactive Fourier Transformer to better align remote sensing image-text
features. The Fourier layer in the interactive Fourier Transformer is capable
of extracting multi-scale features of remote sensing images in the frequency
domain, thereby reducing the redundancy of remote sensing visual features.
Specifically, the first stage involves preliminary alignment through image-text
contrastive learning, which aligns the learned multi-scale remote sensing
features from the interactive Fourier Transformer with textual features. In the
second stage, the interactive Fourier Transformer connects the frozen image
encoder with a large language model. Then, prefix causal language modeling is
utilized to guide the text generation process using visual features.
Ultimately, across the UCM-caption, RSICD, and NWPU-caption datasets, the
experimental results clearly demonstrate that BITA outperforms other advanced
comparative approaches. The code is available at
https://github.com/yangcong356/BITA.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01193" title="Abstract">arXiv:2312.01193</a> [<a href="/pdf/2312.01193" title="Download PDF">pdf</a>, <a href="/ps/2312.01193" title="Download PostScript">ps</a>, <a href="/format/2312.01193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle path and traffic flow optimization via lane changing of  automated or semi-automated vehicles on motorways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Georgantas%2C+A">Antonios Georgantas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Diploma Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Emerging vehicle automation and communication systems (VACS) may contribute
to the improvement of vehicle travel time and the mitigation of motorway
traffic congestion on the basis of appropriate control strategies. This work
considers the possibility that automated, or semi-automated, vehicles are
equipped with devices that perform (or recommend) lane-changing tasks. The
lane-changing strategy MOBIL (minimizing overall braking induced by lane
changing) has been chosen for its simplicity and ductility, as well as for the
reduced number of parameters that need to be specified (namely, politeness
factor and threshold). A wide set of simulations, where MOBIL has been
implemented within the microscopic traffic simulator Aimsun for a calibrated
motorway network (representing a stretch of motorway A12 in the Netherlands),
has been performed. Simulations revealed the impact that the choice of
different parameters have on the travel time of different vehicles, allowing
also to analyse their behaviour with respect to different traffic conditions
(without or with traffic congestion).
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01195" title="Abstract">arXiv:2312.01195</a> [<a href="/pdf/2312.01195" title="Download PDF">pdf</a>, <a href="/format/2312.01195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIM: Automatic Interrupt Modeling for Dynamic Firmware Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+B">Bo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Meng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Long Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kirda%2C+E">Engin Kirda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted to IEEE Transactions on Dependable and Secure Computing at Oct 12, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The security of microcontrollers, which drive modern IoT and embedded
devices, continues to raise major concerns. Within a microcontroller (MCU), the
firmware is a monolithic piece of software that contains the whole software
stack, whereas a variety of peripherals represent the hardware. As MCU firmware
contains vulnerabilities, it is ideal to test firmware with off-the-shelf
software testing techniques, such as dynamic symbolic execution and fuzzing.
Nevertheless, no emulator can emulate the diverse MCU peripherals or
execute/test the firmware. Specifically, the interrupt interface, among all I/O
interfaces used by MCU peripherals, is extremely challenging to emulate.
<br />In this paper, we present AIM -- a generic, scalable, and
hardware-independent dynamic firmware analysis framework that supports
unemulated MCU peripherals by a novel interrupt modeling mechanism. AIM
effectively and efficiently covers interrupt-dependent code in firmware by a
novel, firmware-guided, Just-in-Time Interrupt Firing technique. We implemented
our framework in angr and performed dynamic symbolic execution for eight
real-world MCU firmware. According to testing results, our framework covered up
to 11.2 times more interrupt-dependent code than state-of-the-art approaches
while accomplishing several challenging goals not feasible previously. Finally,
a comparison with a state-of-the-art firmware fuzzer demonstrates dynamic
symbolic execution and fuzzing together can achieve better firmware testing
coverage.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01196" title="Abstract">arXiv:2312.01196</a> [<a href="/pdf/2312.01196" title="Download PDF">pdf</a>, <a href="/format/2312.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Parametric Gaussians for Monocular Non-Rigid Object  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Devikalyan Das</a>, 
<a href="/search/cs?searchtype=author&query=Wewer%2C+C">Christopher Wewer</a>, 
<a href="/search/cs?searchtype=author&query=Yunus%2C+R">Raza Yunus</a>, 
<a href="/search/cs?searchtype=author&query=Ilg%2C+E">Eddy Ilg</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing dynamic objects from monocular videos is a severely
underconstrained and challenging problem, and recent work has approached it in
various directions. However, owing to the ill-posed nature of this problem,
there has been no solution that can provide consistent, high-quality novel
views from camera positions that are significantly different from the training
views. In this work, we introduce Neural Parametric Gaussians (NPGs) to take on
this challenge by imposing a two-stage approach: first, we fit a low-rank
neural deformation model, which then is used as regularization for non-rigid
reconstruction in the second stage. The first stage learns the object's
deformations such that it preserves consistency in novel views. The second
stage obtains high reconstruction quality by optimizing 3D Gaussians that are
driven by the coarse model. To this end, we introduce a local 3D Gaussian
representation, where temporally shared Gaussians are anchored in and deformed
by local oriented volumes. The resulting combined model can be rendered as
radiance fields, resulting in high-quality photo-realistic reconstructions of
the non-rigidly deforming objects, maintaining 3D consistency across novel
views. We demonstrate that NPGs achieve superior results compared to previous
works, especially in challenging scenarios with few multi-view cues.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01197" title="Abstract">arXiv:2312.01197</a> [<a href="/pdf/2312.01197" title="Download PDF">pdf</a>, <a href="/format/2312.01197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short-term Precipitation Forecasting in The Netherlands: An Application  of Convolutional LSTM neural networks to weather radar data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demetrakopoulos%2C+P">Petros Demetrakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This work addresses the challenge of short-term precipitation forecasting by
applying Convolutional Long Short-Term Memory (ConvLSTM) neural networks to
weather radar data from the Royal Netherlands Meteorological Institute (KNMI).
The research exploits the combination of Convolutional Neural Networks (CNNs)
layers for spatial pattern recognition and LSTM network layers for modelling
temporal sequences, integrating these strengths into a ConvLSTM architecture.
The model was trained and validated on weather radar data from the Netherlands.
The model is an autoencoder consisting of nine layers, uniquely combining
convolutional operations with LSTMs temporal processing, enabling it to capture
the movement and intensity of precipitation systems. The training set comprised
of sequences of radar images, with the model being tasked to predict
precipitation patterns 1.5 hours ahead using the preceding data. Results
indicate high accuracy in predicting the direction and intensity of
precipitation movements. The findings of this study underscore the significant
potential of ConvLSTM networks in meteorological forecasting, particularly in
regions with complex weather patterns. It contributes to the field by offering
a more accurate, data-driven approach to weather prediction, highlighting the
broader applicability of ConvLSTM networks in meteorological tasks.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01200" title="Abstract">arXiv:2312.01200</a> [<a href="/pdf/2312.01200" title="Download PDF">pdf</a>, <a href="/format/2312.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAUDability: Estimating Users&#x27; Susceptibility to Financial Fraud Using  Adversarial Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doytshman%2C+C">Chen Doytshman</a>, 
<a href="/search/cs?searchtype=author&query=Momiyama%2C+S">Satoru Momiyama</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Inderjeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In recent years, financial fraud detection systems have become very efficient
at detecting fraud, which is a major threat faced by e-commerce platforms. Such
systems often include machine learning-based algorithms aimed at detecting and
reporting fraudulent activity. In this paper, we examine the application of
adversarial learning based ranking techniques in the fraud detection domain and
propose FRAUDability, a method for the estimation of a financial fraud
detection system's performance for every user. We are motivated by the
assumption that "not all users are created equal" -- while some users are well
protected by fraud detection algorithms, others tend to pose a challenge to
such systems. The proposed method produces scores, namely "fraudability
scores," which are numerical estimations of a fraud detection system's ability
to detect financial fraud for a specific user, given his/her unique activity in
the financial system. Our fraudability scores enable those tasked with
defending users in a financial platform to focus their attention and resources
on users with high fraudability scores to better protect them. We validate our
method using a real e-commerce platform's dataset and demonstrate the
application of fraudability scores from the attacker's perspective, on the
platform, and more specifically, on the fraud detection systems used by the
e-commerce enterprise. We show that the scores can also help attackers increase
their financial profit by 54%, by engaging solely with users with high
fraudability scores, avoiding those users whose spending habits enable more
accurate fraud detection.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01201" title="Abstract">arXiv:2312.01201</a> [<a href="/pdf/2312.01201" title="Download PDF">pdf</a>, <a href="/format/2312.01201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC Privacy Preserving Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qipan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Youlong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data privacy protection is garnering increased attention among researchers.
Diffusion models (DMs), particularly with strict differential privacy, can
potentially produce images with both high privacy and visual quality. However,
challenges arise in ensuring robust protection in privatizing specific data
attributes, areas where current models often fall short. To address these
challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model
leverages diffusion principles and ensure Probably Approximately Correct (PAC)
privacy. We enhance privacy protection by integrating a private classifier
guidance into the Langevin Sampling Process. Additionally, recognizing the gap
in measuring the privacy of models, we have developed a novel metric to gauge
privacy levels. Our model, assessed with this new metric and supported by
Gaussian matrix computations for the PAC bound, has shown superior performance
in privacy protection over existing leading private generative models according
to benchmark tests.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01202" title="Abstract">arXiv:2312.01202</a> [<a href="/pdf/2312.01202" title="Download PDF">pdf</a>, <a href="/format/2312.01202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Voices to Validity: Leveraging Large Language Models (LLMs) for  Textual Analysis of Policy Stakeholder Interviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alex Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Obtaining stakeholders' diverse experiences and opinions about current policy
in a timely manner is crucial for policymakers to identify strengths and gaps
in resource allocation, thereby supporting effective policy design and
implementation. However, manually coding even moderately sized interview texts
or open-ended survey responses from stakeholders can often be labor-intensive
and time-consuming. This study explores the integration of Large Language
Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of
stakeholder interviews regarding K-12 education policy within one U.S. state.
Employing a mixed-methods approach, human experts developed a codebook and
coding processes as informed by domain knowledge and unsupervised topic
modeling results. They then designed prompts to guide GPT-4 analysis and
iteratively evaluate different prompts' performances. This combined
human-computer method enabled nuanced thematic and sentiment analysis. Results
reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at
specific themes, expanding to broader themes increased congruence to 96.02%,
surpassing traditional Natural Language Processing (NLP) methods by over 25%.
Additionally, GPT-4 is more closely matched to expert sentiment analysis than
lexicon-based methods. Findings from quantitative measures and qualitative
reviews underscore the complementary roles of human domain expertise and
automated analysis as LLMs offer new perspectives and coding consistency. The
human-computer interactive approach enhances efficiency, validity, and
interpretability of educational policy research.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01203" title="Abstract">arXiv:2312.01203</a> [<a href="/pdf/2312.01203" title="Download PDF">pdf</a>, <a href="/format/2312.01203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Discrete Representations For Continual Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+E">Edan Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+M+C">Marlos C. Machado</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A">Adam White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures, submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning (RL) agents make decisions using nothing but
observations from the environment, and consequently, heavily rely on the
representations of those observations. Though some recent breakthroughs have
used vector-based categorical representations of observations, often referred
to as discrete representations, there is little work explicitly assessing the
significance of such a choice. In this work, we provide a thorough empirical
investigation of the advantages of representing observations as vectors of
categorical values within the context of reinforcement learning. We perform
evaluations on world-model learning, model-free RL, and ultimately continual RL
problems, where the benefits best align with the needs of the problem setting.
We find that, when compared to traditional continuous representations, world
models learned over discrete representations accurately model more of the world
with less capacity, and that agents trained with discrete representations learn
better policies with less data. In the context of continual RL, these benefits
translate into faster adapting agents. Additionally, our analysis suggests that
the observed performance improvements can be attributed to the information
contained within the latent vectors and potentially the encoding of the
discrete representation itself.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01204" title="Abstract">arXiv:2312.01204</a> [<a href="/pdf/2312.01204" title="Download PDF">pdf</a>, <a href="/format/2312.01204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Wireless Time-Sensitive Networking (TSN):  Architecture, Technologies, Applications, and Open Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zanbouri%2C+K">Kouros Zanbouri</a>, 
<a href="/search/cs?searchtype=author&query=Noor-A-Rahim%2C+M">Md. Noor-A-Rahim</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+J">Jobish John</a>, 
<a href="/search/cs?searchtype=author&query=Sreenan%2C+C+J">Cormac J. Sreenan</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Pesch%2C+D">Dirk Pesch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Time-Sensitive Networking (TSN) is expected to be a critical component of
critical machine type communication networks in areas such as Industry 4.0 and
beyond. With rising mobility requirements in industrial applications and the
prevalence of wireless networks, wireless network integration into TSN is
becoming increasingly important. This survey article presents a comprehensive
review of wireless TSN, including an overview of the architecture of a wireless
TSN network and an examination of the various wireless technologies and
protocols that can be used in such networks. In addition, the article discusses
industrial applications of wireless TSN, among them automation, robotics, and
autonomous vehicles. The article concludes by summarizing the challenges and
open issues related to the integration of TSN into wireless networks, and by
offering recommendations for future research directions.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01213" title="Abstract">arXiv:2312.01213</a> [<a href="/pdf/2312.01213" title="Download PDF">pdf</a>, <a href="/format/2312.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking  Neural networks: from Algorithms to Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Souvik Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui-Jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A">Akhilesh Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neuromorphic computing and, in particular, spiking neural networks (SNNs)
have become an attractive alternative to deep neural networks for a broad range
of signal processing applications, processing static and/or temporal inputs
from different sensory modalities, including audio and vision sensors. In this
paper, we start with a description of recent advances in algorithmic and
optimization innovations to efficiently train and scale low-latency, and
energy-efficient spiking neural networks (SNNs) for complex machine learning
applications. We then discuss the recent efforts in algorithm-architecture
co-design that explores the inherent trade-offs between achieving high
energy-efficiency and low latency while still providing high accuracy and
trustworthiness. We then describe the underlying hardware that has been
developed to leverage such algorithmic innovations in an efficient way. In
particular, we describe a hybrid method to integrate significant portions of
the model's computation within both memory components as well as the sensor
itself. Finally, we discuss the potential path forward for research in building
deployable SNN systems identifying key challenges in the
algorithm-hardware-application co-design space with an emphasis on
trustworthiness.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01214" title="Abstract">arXiv:2312.01214</a> [<a href="/pdf/2312.01214" title="Download PDF">pdf</a>, <a href="/ps/2312.01214" title="Download PostScript">ps</a>, <a href="/format/2312.01214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Sensor Diagnostics for Robotic Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kukreja%2C+A">Astha Kukreja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Ensuring the safe and reliable operation of collaborative robots demands
robust sensor diagnostics. This paper introduces a methodology for formulating
model-based constraints tailored for sensor diagnostics, featuring analytical
relationships extending across mechanical and electrical domains. While
applicable to various robotic systems, the study specifically centers on a
robotic joint employing a series elastic actuator. Three distinct constraints
are imposed on the series elastic actuator: the Torsional Spring Constraint,
Joint Dynamics Constraint, and Electrical Motor Constraint. Through a
simulation example, we demonstrate the efficacy of the proposed model-based
sensor diagnostics methodology. The study addresses two distinct types of
sensor faults that may arise in the torque sensor of a robot joint, and delves
into their respective detection methods. This insightful sensor diagnostic
methodology is customizable and applicable across various components of robots,
offering fault diagnostic and isolation capabilities. This research contributes
valuable insights aimed at enhancing the diagnostic capabilities essential for
the optimal performance of robotic manipulators in collaborative environments.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01215" title="Abstract">arXiv:2312.01215</a> [<a href="/pdf/2312.01215" title="Download PDF">pdf</a>, <a href="/format/2312.01215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNb-NeuS: Reflectance and Normal-based Multi-View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brument%2C+B">Baptiste Brument</a>, 
<a href="/search/cs?searchtype=author&query=Bruneau%2C+R">Robin Bruneau</a>, 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9au%2C+Y">Yvain Qu&#xe9;au</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9lou%2C+J">Jean M&#xe9;lou</a>, 
<a href="/search/cs?searchtype=author&query=Lauze%2C+F+B">Fran&#xe7;ois Bernard Lauze</a>, 
<a href="/search/cs?searchtype=author&query=Jean-Denis">Jean-Denis</a>, 
<a href="/search/cs?searchtype=author&query=Durou%2C+J">Jean-Denis Durou</a>, 
<a href="/search/cs?searchtype=author&query=Calvet%2C+L">Lilian Calvet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures, 6 tables. The source code will be available at <a href="https://github.com/bbrument/RNb-NeuS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a versatile paradigm for integrating multi-view
reflectance and normal maps acquired through photometric stereo. Our approach
employs a pixel-wise joint re-parameterization of reflectance and normal,
considering them as a vector of radiances rendered under simulated, varying
illumination. This re-parameterization enables the seamless integration of
reflectance and normal maps as input data in neural volume rendering-based 3D
reconstruction while preserving a single optimization objective. In contrast,
recent multi-view photometric stereo (MVPS) methods depend on multiple,
potentially conflicting objectives. Despite its apparent simplicity, our
proposed approach outperforms state-of-the-art approaches in MVPS benchmarks
across F-score, Chamfer distance, and mean angular error metrics. Notably, it
significantly improves the detailed 3D reconstruction of areas with high
curvature or low visibility.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01216" title="Abstract">arXiv:2312.01216</a> [<a href="/pdf/2312.01216" title="Download PDF">pdf</a>, <a href="/format/2312.01216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individual Behavioral Insights in Schizophrenia: A Network Analysis and  Mobile Sensing Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+A">Andy Davies</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+E">Eiko Fried</a>, 
<a href="/search/cs?searchtype=author&query=Aung%2C+H">Hane Aung</a>, 
<a href="/search/cs?searchtype=author&query=Costilla-Reyes%2C+O">Omar Costilla-Reyes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on proceedings of EAI PervasiveHealth 2023 - 17th EAI International Conference on Pervasive Computing Technologies for Healthcare
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Digital phenotyping in mental health often consists of collecting behavioral
and experience-based information through sensory and self-reported data from
devices such as smartphones. Such rich and comprehensive data could be used to
develop insights into the relationships between daily behavior and a range of
mental health conditions. However, current analytical approaches have shown
limited application due to these datasets being both high dimensional and
multimodal in nature. This study demonstrates the first use of a principled
method which consolidates the complexities of subjective self-reported data
(Ecological Momentary Assessments - EMAs) with concurrent sensor-based data. In
this study the CrossCheck dataset is used to analyse data from 50 participants
diagnosed with schizophrenia. Network Analysis is applied to EMAs at an
individual (n-of-1) level while sensor data is used to identify periods of
various behavioral context. Networks generated during periods of certain
behavioral contexts, such as variations in the daily number of locations
visited, were found to significantly differ from baseline networks and networks
generated from randomly sampled periods of time. The framework presented here
lays a foundation to reveal behavioural contexts and the concurrent impact of
self-reporting at an n-of-1 level. These insights are valuable in the
management of serious mental illnesses such as schizophrenia.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01217" title="Abstract">arXiv:2312.01217</a> [<a href="/pdf/2312.01217" title="Download PDF">pdf</a>, <a href="/format/2312.01217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Opinions Towards Climate Change on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pupneja%2C+Y">Yashaswi Pupneja</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Joseph Zou</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A9vy%2C+S">Sacha L&#xe9;vy</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shenyang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Social media platforms such as Twitter (now known as X) have revolutionized
how the public engage with important societal and political topics. Recently,
climate change discussions on social media became a catalyst for political
polarization and the spreading of misinformation. In this work, we aim to
understand how real world events influence the opinions of individuals towards
climate change related topics on social media. To this end, we extracted and
analyzed a dataset of 13.6 millions tweets sent by 3.6 million users from 2006
to 2019. Then, we construct a temporal graph from the user-user mentions
network and utilize the Louvain community detection algorithm to analyze the
changes in community structure around Conference of the Parties on Climate
Change~(COP) events. Next, we also apply tools from the Natural Language
Processing literature to perform sentiment analysis and topic modeling on the
tweets. Our work acts as a first step towards understanding the evolution of
pro-climate change communities around COP events. Answering these questions
helps us understand how to raise people's awareness towards climate change thus
hopefully calling on more individuals to join the collaborative effort in
slowing down climate change.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01219" title="Abstract">arXiv:2312.01219</a> [<a href="/pdf/2312.01219" title="Download PDF">pdf</a>, <a href="/ps/2312.01219" title="Download PostScript">ps</a>, <a href="/format/2312.01219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hierarchical event correlation model for real time threat detection  and response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maosa%2C+H">Herbert Maosa</a>, 
<a href="/search/cs?searchtype=author&query=Ouazzane%2C+K">Karim Ouazzane</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed Chahine Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Information Security
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Under Review 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Intrusion detection systems perform post-compromise detection of security
breaches whenever preventive measures such as firewalls do not avert an attack.
However, these systems raise a vast number of alerts that must be analysed and
triaged by security analysts. This process is largely manual, tedious and
time-consuming. Alert correlation is a technique that tries to reduce the
number of intrusion alerts by aggregating those that are related in some way.
However, the correlation is performed outside the IDS through third-party
systems and tools, after the high volume of alerts has already been raised.
These other third-party systems add to the complexity of security operations.
In this paper, we build on the very researched area of correlation techniques
by developing a novel hierarchical event correlation model that promises to
reduce the number of alerts issued by an Intrusion Detection System. This is
achieved by correlating the events before the IDS classifies them. The proposed
model takes the best of features from similarity and graph-based correlation
techniques to deliver an ensemble capability not possible by either approach
separately. Further, we propose a correlation process for correlation of events
rather than alerts as is the case in current art. We further develop our own
correlation and clustering algorithm which is tailor-made to the correlation
and clustering of network event data. The model is implemented as a proof of
concept with experiments run on the DARPA 99 Intrusion detection set. The
correlation achieved 87 percent data reduction through aggregation, producing
nearly 21000 clusters in about 30 seconds.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01220" title="Abstract">arXiv:2312.01220</a> [<a href="/pdf/2312.01220" title="Download PDF">pdf</a>, <a href="/format/2312.01220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhipeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting objects in low-light scenarios presents a persistent challenge, as
detectors trained on well-lit data exhibit significant performance degradation
on low-light data due to the low visibility. Previous methods mitigate this
issue by investigating image enhancement or object detection techniques using
low-light image datasets. However, the progress is impeded by the inherent
difficulties associated with collecting and annotating low-light images. To
address this challenge, we propose to boost low-light object detection with
zero-shot day-night domain adaptation, which aims to generalize a detector from
well-lit scenarios to low-light ones without requiring real low-light data. We
first design a reflectance representation learning module to learn
Retinex-based illumination invariance in images with a carefully designed
illumination invariance reinforcement strategy. Next, an
interchange-redecomposition-coherence procedure is introduced to improve over
the vanilla Retinex image decomposition process by performing two sequential
image decompositions and introducing a redecomposition cohering loss. Extensive
experiments on ExDark, DARK FACE and CODaN datasets show strong low-light
generalizability of our method.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01221" title="Abstract">arXiv:2312.01221</a> [<a href="/pdf/2312.01221" title="Download PDF">pdf</a>, <a href="/format/2312.01221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Quantum Natural Language Processing for Hindi Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+N">Naman Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Belekar%2C+G">Gaurang Belekar</a>, 
<a href="/search/cs?searchtype=author&query=Saumya%2C+S">Sunil Saumya</a>, 
<a href="/search/cs?searchtype=author&query=H%2C+A+B">Aswath Babu H</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Quantum Natural Language Processing (QNLP) is taking huge leaps in solving
the shortcomings of classical Natural Language Processing (NLP) techniques and
moving towards a more "Explainable" NLP system. The current literature around
QNLP focuses primarily on implementing QNLP techniques in sentences in the
English language. In this paper, we propose to enable the QNLP approach to
HINDI, which is the third most spoken language in South Asia. We present the
process of building the parameterized quantum circuits required to undertake
QNLP on Hindi sentences. We use the pregroup representation of Hindi and the
DisCoCat framework to draw sentence diagrams. Later, we translate these
diagrams to Parameterised Quantum Circuits based on Instantaneous Quantum
Polynomial (IQP) style ansatz. Using these parameterized quantum circuits
allows one to train grammar and topic-aware sentence classifiers for the Hindi
Language.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01225" title="Abstract">arXiv:2312.01225</a> [<a href="/pdf/2312.01225" title="Download PDF">pdf</a>, <a href="/format/2312.01225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCE-FID: Using Large Unlabeled, Medium Crowdsourced-Labeled, and Small  Expert-Labeled Tweets for Foodborne Illness Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruofan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dandan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Rundensteiner%2C+E">Elke Rundensteiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Foodborne illnesses significantly impact public health. Deep learning
surveillance applications using social media data aim to detect early warning
signals. However, labeling foodborne illness-related tweets for model training
requires extensive human resources, making it challenging to collect a
sufficient number of high-quality labels for tweets within a limited budget.
The severe class imbalance resulting from the scarcity of foodborne
illness-related tweets among the vast volume of social media further
exacerbates the problem. Classifiers trained on a class-imbalanced dataset are
biased towards the majority class, making accurate detection difficult. To
overcome these challenges, we propose EGAL, a deep learning framework for
foodborne illness detection that uses small expert-labeled tweets augmented by
crowdsourced-labeled and massive unlabeled data. Specifically, by leveraging
tweets labeled by experts as a reward set, EGAL learns to assign a weight of
zero to incorrectly labeled tweets to mitigate their negative influence. Other
tweets receive proportionate weights to counter-balance the unbalanced class
distribution. Extensive experiments on real-world \textit{TWEET-FID} data show
that EGAL outperforms strong baseline models across different settings,
including varying expert-labeled set sizes and class imbalance ratios. A case
study on a multistate outbreak of Salmonella Typhimurium infection linked to
packaged salad greens demonstrates how the trained model captures relevant
tweets offering valuable outbreak insights. EGAL, funded by the U.S. Department
of Agriculture (USDA), has the potential to be deployed for real-time analysis
of tweet streaming, contributing to foodborne illness outbreak surveillance
efforts.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01227" title="Abstract">arXiv:2312.01227</a> [<a href="/pdf/2312.01227" title="Download PDF">pdf</a>, <a href="/format/2312.01227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Bayesian Estimation in Sensor Networks: Consensus on  Marginal Densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paritosh%2C+P">Parth Paritosh</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+S">Sonia Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we aim to design and analyze distributed Bayesian estimation
algorithms for sensor networks. The challenges we address are to (i) derive a
distributed provably-correct algorithm in the functional space of probability
distributions over continuous variables, and (ii) leverage these results to
obtain new distributed estimators restricted to subsets of variables observed
by individual agents. This relates to applications such as cooperative
localization and federated learning, where the data collected at any agent
depends on a subset of all variables of interest. We present Bayesian density
estimation algorithms using data from non-linear likelihoods at agents in
centralized, distributed, and marginal distributed settings. After setting up a
distributed estimation objective, we prove almost-sure convergence to the
optimal set of pdfs at each agent. Then, we prove the same for a storage-aware
algorithm estimating densities only over relevant variables at each agent.
Finally, we present a Gaussian version of these algorithms and implement it in
a mapping problem using variational inference to handle non-linear likelihood
models associated with LiDAR sensing.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01229" title="Abstract">arXiv:2312.01229</a> [<a href="/pdf/2312.01229" title="Download PDF">pdf</a>, <a href="/format/2312.01229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Commitment for Geo-Distributed Transactions via Decentralized  Co-coordinators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Huiqi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yaofeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weining Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aoying Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In a geo-distributed database, data shards and their respective replicas are
deployed in distinct datacenters across multiple regions, enabling
regional-level disaster recovery and the ability to serve global users locally.
However, transaction processing in geo-distributed databases requires multiple
cross-region communications, especially during the commit phase, which can
significantly impact system performance.
<br />To optimize the performance of geo-distributed transactions, we propose
Decentralized Two-phase Commit (D2PC), a new transaction commit protocol aiming
to minimize the negative impact of cross-region communication. In D2PC, we
employ multiple co-coordinators that perform commit coordination in parallel.
Each co-coordinator is responsible for collecting 2PC votes and making a
PreCommit decision in its local region. This approach allows for the concurrent
invocation of multiple cross-region network round trips, and each region can
conclude its concurrency control locally before replication is complete, thus
significantly reducing the chances of blocking and enhancing system
concurrency. Moreover, we propose the bypass leader replication reply method,
leveraging decentralized co-coordinators to bypass the leader for message
transmission, thereby reducing the commit latency. Experimental results have
demonstrated that D2PC can reduce commit latency by 43% and improve throughput
by up to 2.43 times compared to the existing alternative geo-distributed
transaction processing methods.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01232" title="Abstract">arXiv:2312.01232</a> [<a href="/pdf/2312.01232" title="Download PDF">pdf</a>, <a href="/format/2312.01232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Vision Transformers in Image Classification  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mahmoud Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+A">Ahmad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Ngom%2C+A">Alioune Ngom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image Classification is a fundamental task in the field of computer vision
that frequently serves as a benchmark for gauging advancements in Computer
Vision. Over the past few years, significant progress has been made in image
classification due to the emergence of deep learning. However, challenges still
exist, such as modeling fine-grained visual information, high computation
costs, the parallelism of the model, and inconsistent evaluation protocols
across datasets. In this paper, we conduct a comprehensive survey of existing
papers on Vision Transformers for image classification. We first introduce the
popular image classification datasets that influenced the design of models.
Then, we present Vision Transformers models in chronological order, starting
with early attempts at adapting attention mechanism to vision tasks followed by
the adoption of vision transformers, as they have demonstrated success in
capturing intricate patterns and long-range dependencies within images.
Finally, we discuss open problems and shed light on opportunities for image
classification to facilitate new research ideas.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01235" title="Abstract">arXiv:2312.01235</a> [<a href="/pdf/2312.01235" title="Download PDF">pdf</a>, <a href="/ps/2312.01235" title="Download PostScript">ps</a>, <a href="/format/2312.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Data Revocation in Federated Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ningning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+E">Ermin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+R">Randall Berry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">By allowing users to erase their data's impact on federated learning models,
federated unlearning protects users' right to be forgotten and data privacy.
Despite a burgeoning body of research on federated unlearning's technical
feasibility, there is a paucity of literature investigating the considerations
behind users' requests for data revocation. This paper proposes a
non-cooperative game framework to study users' data revocation strategies in
federated unlearning. We prove the existence of a Nash equilibrium. However,
users' best response strategies are coupled via model performance and
unlearning costs, which makes the equilibrium computation challenging. We
obtain the Nash equilibrium by establishing its equivalence with a much simpler
auxiliary optimization problem. We also summarize users' multi-dimensional
attributes into a single-dimensional metric and derive the closed-form
characterization of an equilibrium, when users' unlearning costs are
negligible. Moreover, we compare the cases of allowing and forbidding partial
data revocation in federated unlearning. Interestingly, the results reveal that
allowing partial revocation does not necessarily increase users' data
contributions or payoffs due to the game structure. Additionally, we
demonstrate that positive externalities may exist between users' data
revocation decisions when users incur unlearning costs, while this is not the
case when their unlearning costs are negligible.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01236" title="Abstract">arXiv:2312.01236</a> [<a href="/pdf/2312.01236" title="Download PDF">pdf</a>, <a href="/format/2312.01236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evetac: An Event-based Optical Tactile Sensor for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Funk%2C+N">Niklas Funk</a>, 
<a href="/search/cs?searchtype=author&query=Helmut%2C+E">Erik Helmut</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>, 
<a href="/search/cs?searchtype=author&query=Calandra%2C+R">Roberto Calandra</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optical tactile sensors have recently become popular. They provide high
spatial resolution, but struggle to offer fine temporal resolutions. To
overcome this shortcoming, we study the idea of replacing the RGB camera with
an event-based camera and introduce a new event-based optical tactile sensor
called Evetac. Along with hardware design, we develop touch processing
algorithms to process its measurements online at 1000 Hz. We devise an
efficient algorithm to track the elastomer's deformation through the imprinted
markers despite the sensor's sparse output. Benchmarking experiments
demonstrate Evetac's capabilities of sensing vibrations up to 498 Hz,
reconstructing shear forces, and significantly reducing data rates compared to
RGB optical tactile sensors. Moreover, Evetac's output and the marker tracking
provide meaningful features for learning data-driven slip detection and
prediction models. The learned models form the basis for a robust and adaptive
closed-loop grasp controller capable of handling a wide range of objects. We
believe that fast and efficient event-based tactile sensors like Evetac will be
essential for bringing human-like manipulation capabilities to robotics. The
sensor design is open-sourced at https://sites.google.com/view/evetac .
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01237" title="Abstract">arXiv:2312.01237</a> [<a href="/pdf/2312.01237" title="Download PDF">pdf</a>, <a href="/format/2312.01237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPAD-membership for Problems with Exact Rational Solutions: A General  Approach via Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filos-Ratsikas%2C+A">Aris Filos-Ratsikas</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+K+A">Kristoffer Arnsfelt Hansen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B8gh%2C+K">Kasper H&#xf8;gh</a>, 
<a href="/search/cs?searchtype=author&query=Hollender%2C+A">Alexandros Hollender</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We introduce a general technique for proving membership of search problems
with exact rational solutions in PPAD, one of the most well-known classes
containing total search problems with polynomial-time verifiable solutions. In
particular, we construct a "pseudogate", coined the linear-OPT-gate, which can
be used as a "plug-and-play" component in a piecewise-linear (PL) arithmetic
circuit, as an integral component of the "Linear-FIXP" equivalent definition of
the class. The linear-OPT-gate can solve several convex optimization programs,
including quadratic programs, which often appear organically in the simplest
existence proofs for these problems. This effectively transforms existence
proofs to PPAD-membership proofs, and consequently establishes the existence of
solutions described by rational numbers.
<br />Using the linear-OPT-gate, we are able to significantly simplify and
generalize almost all known PPAD-membership proofs for finding exact solutions
in the application domains of game theory, competitive markets, auto-bidding
auctions, and fair division, as well as to obtain new PPAD-membership results
for problems in these domains.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01238" title="Abstract">arXiv:2312.01238</a> [<a href="/pdf/2312.01238" title="Download PDF">pdf</a>, <a href="/format/2312.01238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep learning pipeline for cross-sectional and longitudinal multiview  data integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sarthak Jain</a>, 
<a href="/search/cs?searchtype=author&query=Safo%2C+S+E">Sandra E. Safo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Biomedical research now commonly integrates diverse data types or views from
the same individuals to better understand the pathobiology of complex diseases,
but the challenge lies in meaningfully integrating these diverse views.
Existing methods often require the same type of data from all views
(cross-sectional data only or longitudinal data only) or do not consider any
class outcome in the integration method, presenting limitations. To overcome
these limitations, we have developed a pipeline that harnesses the power of
statistical and deep learning methods to integrate cross-sectional and
longitudinal data from multiple sources. Additionally, it identifies key
variables contributing to the association between views and the separation
among classes, providing deeper biological insights. This pipeline includes
variable selection/ranking using linear and nonlinear methods, feature
extraction using functional principal component analysis and Euler
characteristics, and joint integration and classification using dense
feed-forward networks and recurrent neural networks. We applied this pipeline
to cross-sectional and longitudinal multi-omics data (metagenomics,
transcriptomics, and metabolomics) from an inflammatory bowel disease (IBD)
study and we identified microbial pathways, metabolites, and genes that
discriminate by IBD status, providing information on the etiology of IBD. We
conducted simulations to compare the two feature extraction methods. The
proposed pipeline is available from the following GitHub repository:
https://github.com/lasandrall/DeepIDA-GRU.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01241" title="Abstract">arXiv:2312.01241</a> [<a href="/pdf/2312.01241" title="Download PDF">pdf</a>, <a href="/format/2312.01241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just-in-Time Security Patch Detection -- LLM At the Rescue for Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kisub Kim</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Haoye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ezzini%2C+S">Saad Ezzini</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the face of growing vulnerabilities found in open-source software, the
need to identify {discreet} security patches has become paramount. The lack of
consistency in how software providers handle maintenance often leads to the
release of security patches without comprehensive advisories, leaving users
vulnerable to unaddressed security risks. To address this pressing issue, we
introduce a novel security patch detection system, LLMDA, which capitalizes on
Large Language Models (LLMs) and code-text alignment methodologies for patch
review, data enhancement, and feature combination. Within LLMDA, we initially
utilize LLMs for examining patches and expanding data of PatchDB and SPI-DB,
two security patch datasets from recent literature. We then use labeled
instructions to direct our LLMDA, differentiating patches based on security
relevance. Following this, we apply a PTFormer to merge patches with code,
formulating hybrid attributes that encompass both the innate details and the
interconnections between the patches and the code. This distinctive combination
method allows our system to capture more insights from the combined context of
patches and code, hence improving detection precision. Finally, we devise a
probabilistic batch contrastive learning mechanism within batches to augment
the capability of the our LLMDA in discerning security patches. The results
reveal that LLMDA significantly surpasses the start of the art techniques in
detecting security patches, underscoring its promise in fortifying software
maintenance.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01242" title="Abstract">arXiv:2312.01242</a> [<a href="/pdf/2312.01242" title="Download PDF">pdf</a>, <a href="/format/2312.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDxT: Deep Generative Transformer Models for Differential Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+M">Mohammad Mahmudul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Raff%2C+E">Edward Raff</a>, 
<a href="/search/cs?searchtype=author&query=Oates%2C+T">Tim Oates</a>, 
<a href="/search/cs?searchtype=author&query=Matuszek%2C+C">Cynthia Matuszek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 1st Workshop on Deep Generative Models for Health at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Differential Diagnosis (DDx) is the process of identifying the most likely
medical condition among the possible pathologies through the process of
elimination based on evidence. An automated process that narrows a large set of
pathologies down to the most likely pathologies will be of great importance.
The primary prior works have relied on the Reinforcement Learning (RL) paradigm
under the intuition that it aligns better with how physicians perform DDx. In
this paper, we show that a generative approach trained with simpler supervised
and self-supervised learning signals can achieve superior results on the
current benchmark. The proposed Transformer-based generative network, named
DDxT, autoregressively produces a set of possible pathologies, i.e., DDx, and
predicts the actual pathology using a neural network. Experiments are performed
using the DDXPlus dataset. In the case of DDx, the proposed network has
achieved a mean accuracy of 99.82% and a mean F1 score of 0.9472. Additionally,
mean accuracy reaches 99.98% with a mean F1 score of 0.9949 while predicting
ground truth pathology. The proposed DDxT outperformed the previous RL-based
approaches by a big margin. Overall, the automated Transformer-based DDx
generative model has the potential to become a useful tool for a physician in
times of urgency.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01244" title="Abstract">arXiv:2312.01244</a> [<a href="/pdf/2312.01244" title="Download PDF">pdf</a>, <a href="/ps/2312.01244" title="Download PostScript">ps</a>, <a href="/format/2312.01244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Applications of Automated Extraction of Socio-political  Events from Text (CASE 2023): Workshop and Shared Task Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%BCrriyeto%C4%9Flu%2C+A">Ali H&#xfc;rriyeto&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Tanev%2C+H">Hristo Tanev</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Osman Mutlu</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+S">Surendrabikram Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F+A">Fiona Anting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Y%C3%B6r%C3%BCk%2C+E">Erdem Y&#xf6;r&#xfc;k</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://aclanthology.org/2023.case-1.22">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We provide a summary of the sixth edition of the CASE workshop that is held
in the scope of RANLP 2023. The workshop consists of regular papers, three
keynotes, working papers of shared task participants, and shared task overview
papers. This workshop series has been bringing together all aspects of event
information collection across technical and social science fields. In addition
to contributing to the progress in text based event extraction, the workshop
provides a space for the organization of a multimodal event information
collection task.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01249" title="Abstract">arXiv:2312.01249</a> [<a href="/pdf/2312.01249" title="Download PDF">pdf</a>, <a href="/format/2312.01249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neary%2C+C">Cyrus Neary</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+C">Christian Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Samyal%2C+A+S">Aryaman Singh Samyal</a>, 
<a href="/search/cs?searchtype=author&query=Lennon%2C+C">Craig Lennon</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">We propose and demonstrate a compositional framework for training and
verifying reinforcement learning (RL) systems within a multifidelity
sim-to-real pipeline, in order to deploy reliable and adaptable RL policies on
physical hardware. By decomposing complex robotic tasks into component subtasks
and defining mathematical interfaces between them, the framework allows for the
independent training and testing of the corresponding subtask policies, while
simultaneously providing guarantees on the overall behavior that results from
their composition. By verifying the performance of these subtask policies using
a multifidelity simulation pipeline, the framework not only allows for
efficient RL training, but also for a refinement of the subtasks and their
interfaces in response to challenges arising from discrepancies between
simulation and reality. In an experimental case study we apply the framework to
train and deploy a compositional RL system that successfully pilots a Warthog
unmanned ground robot.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01253" title="Abstract">arXiv:2312.01253</a> [<a href="/pdf/2312.01253" title="Download PDF">pdf</a>, <a href="/ps/2312.01253" title="Download PostScript">ps</a>, <a href="/format/2312.01253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Merits of Faster-than-Nyquist Signaling in the Finite Blocklength  Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+J+D">Yong Jin Daniel Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We identify potential merits of faster-than-Nyquist (FTN) signaling in the
finite blocklength (FBL) regime. A unique aspect of FTN signaling is that it
can increase the blocklength by packing more data symbols within the same time
and frequency to yield strictly higher number of independent signaling
dimensions than that of Nyquist rate signaling. Using the finite-blocklength
information theory, we provide tight bounds on the maximum channel coding rate
(MCCR) of FTN signaling for any finite time-bandwidth product. The merits are
categorized into two operating regions of FTN, i.e., when the time-acceleration
factor of FTN, $\tau$, is above or below a certain threshold $\tau_{0}$. When
$\tau &gt; \tau_{0}$, FTN has both higher channel capacity and MCCR than that of
Nyquist rate signaling, when the utilized pulse shape is non-sinc. Since the
issues associated with the ideal sinc pulse only get exacerbated when packets
are short, the benefit of FTN becomes more significant in the FBL regime. On
the other hand, when $\tau &lt; \tau_{0}$, the channel capacity is fixed but MCCR
of FTN can continue to increase to a certain degree, thereby reducing the gap
between the capacity and MCCR. This benefit is present regardless of the
utilized pulse shape, including the ideal sinc-pulse, and is unique to the FBL
regime. Instead of increasing MCCR for fixed block error rates, FTN can
alternatively lower the block error rates for fixed channel coding rates. These
results imply that FTN can lower the penalty from limited channel coding over
short blocklength and can improve the performance and reliability of short
packet communications.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01255" title="Abstract">arXiv:2312.01255</a> [<a href="/pdf/2312.01255" title="Download PDF">pdf</a>, <a href="/format/2312.01255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta ControlNet: Enhancing Task Adaptation via Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinze Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingbin Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion-based image synthesis has attracted extensive attention recently.
In particular, ControlNet that uses image-based prompts exhibits powerful
capability in image tasks such as canny edge detection and generates images
well aligned with these prompts. However, vanilla ControlNet generally requires
extensive training of around 5000 steps to achieve a desirable control for a
single task. Recent context-learning approaches have improved its adaptability,
but mainly for edge-based tasks, and rely on paired examples. Thus, two
important open issues are yet to be addressed to reach the full potential of
ControlNet: (i) zero-shot control for certain tasks and (ii) faster adaptation
for non-edge-based tasks. In this paper, we introduce a novel Meta ControlNet
method, which adopts the task-agnostic meta learning technique and features a
new layer freezing design. Meta ControlNet significantly reduces learning steps
to attain control ability from 5000 to 1000. Further, Meta ControlNet exhibits
direct zero-shot adaptability in edge-based tasks without any finetuning, and
achieves control within only 100 finetuning steps in more complex non-edge
tasks such as Human Pose, outperforming all existing methods. The codes is
available in https://github.com/JunjieYang97/Meta-ControlNet.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01256" title="Abstract">arXiv:2312.01256</a> [<a href="/pdf/2312.01256" title="Download PDF">pdf</a>, <a href="/format/2312.01256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking XOR Arbiter PUFs without Reliability Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayadi%2C+N">Niloufar Sayadi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P+H">Phuong Ha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+M">Marten van Dijk</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chenglu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Unreliable XOR Arbiter PUFs were broken by a machine learning attack, which
targets the underlying Arbiter PUFs individually. However, reliability
information from the PUF was required for this attack.
<br />We show that, for the first time, a perfectly reliable XOR Arbiter PUF, where
no reliability information is accessible, can be efficiently attacked in the
same divide-and-conquer manner. Our key insight is that the responses of
correlated challenges also reveal their distance to the decision boundary. This
leads to a chosen challenge attack on XOR Arbiter PUFs. The effectiveness of
our attack is confirmed through PUF simulation and FPGA implementation.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01260" title="Abstract">arXiv:2312.01260</a> [<a href="/pdf/2312.01260" title="Download PDF">pdf</a>, <a href="/format/2312.01260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking PGD Attack: Is Sign Function Necessary?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingbin Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural networks have demonstrated success in various domains, yet their
performance can be significantly degraded by even a small input perturbation.
Consequently, the construction of such perturbations, known as adversarial
attacks, has gained significant attention, many of which fall within
"white-box" scenarios where we have full access to the neural network. Existing
attack algorithms, such as the projected gradient descent (PGD), commonly take
the sign function on the raw gradient before updating adversarial inputs,
thereby neglecting gradient magnitude information. In this paper, we present a
theoretical analysis of how such sign-based update algorithm influences
step-wise attack performance, as well as its caveat. We also interpret why
previous attempts of directly using raw gradients failed. Based on that, we
further propose a new raw gradient descent (RGD) algorithm that eliminates the
use of sign. Specifically, we convert the constrained optimization problem into
an unconstrained one, by introducing a new hidden variable of non-clipped
perturbation that can move beyond the constraint. The effectiveness of the
proposed RGD algorithm has been demonstrated extensively in experiments,
outperforming PGD and other competitors in various settings, without incurring
any additional computational overhead. The codes is available in
https://github.com/JunjieYang97/RGD.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01261" title="Abstract">arXiv:2312.01261</a> [<a href="/pdf/2312.01261" title="Download PDF">pdf</a>, <a href="/format/2312.01261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIBET: Identifying and Evaluating Biases in Text-to-Image Generative  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chinchure%2C+A">Aditya Chinchure</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+P">Pushkar Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gaurav Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Salij%2C+K">Kiri Salij</a>, 
<a href="/search/cs?searchtype=author&query=Hosanagar%2C+K">Kartik Hosanagar</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Turk%2C+M">Matthew Turk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Text-to-Image (TTI) generative models have shown great progress in the past
few years in terms of their ability to generate complex and high-quality
imagery. At the same time, these models have been shown to suffer from harmful
biases, including exaggerated societal biases (e.g., gender, ethnicity), as
well as incidental correlations that limit such model's ability to generate
more diverse imagery. In this paper, we propose a general approach to study and
quantify a broad spectrum of biases, for any TTI model and for any prompt,
using counterfactual reasoning. Unlike other works that evaluate generated
images on a predefined set of bias axes, our approach automatically identifies
potential biases that might be relevant to the given prompt, and measures those
biases. In addition, our paper extends quantitative scores with post-hoc
explanations in terms of semantic concepts in the images generated. We show
that our method is uniquely capable of explaining complex multi-dimensional
biases through semantic concepts, as well as the intersectionality between
different biases for any given prompt. We perform extensive user studies to
illustrate that the results of our method and analysis are consistent with
human judgements.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01262" title="Abstract">arXiv:2312.01262</a> [<a href="/pdf/2312.01262" title="Download PDF">pdf</a>, <a href="/format/2312.01262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review and A Robust Framework of Data-Efficient 3D Scene Parsing with  Traditional/Learned 3D Descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangcheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Computer Vision (IJCV), 2022. 10 Figures, 13 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Existing state-of-the-art 3D point cloud understanding methods merely perform
well in a fully supervised manner. To the best of our knowledge, there exists
no unified framework that simultaneously solves the downstream high-level
understanding tasks including both segmentation and detection, especially when
labels are extremely limited. This work presents a general and simple framework
to tackle point cloud understanding when labels are limited. The first
contribution is that we have done extensive methodology comparisons of
traditional and learned 3D descriptors for the task of weakly supervised 3D
scene understanding, and validated that our adapted traditional PFH-based 3D
descriptors show excellent generalization ability across different domains. The
second contribution is that we proposed a learning-based region merging
strategy based on the affinity provided by both the traditional/learned 3D
descriptors and learned semantics. The merging process takes both low-level
geometric and high-level semantic feature correlations into consideration.
Experimental results demonstrate that our framework has the best performance
among the three most important weakly supervised point clouds understanding
tasks including semantic segmentation, instance segmentation, and object
detection even when very limited number of points are labeled. Our method,
termed Region Merging 3D (RM3D), has superior performance on ScanNet
data-efficient learning online benchmarks and other four large-scale 3D
understanding benchmarks under various experimental settings, outperforming
current arts by a margin for various 3D understanding tasks without complicated
learning strategies such as active learning.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01267" title="Abstract">arXiv:2312.01267</a> [<a href="/pdf/2312.01267" title="Download PDF">pdf</a>, <a href="/format/2312.01267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Reinforcement Learning for Molecular Design: Antioxidant  case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huanyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Akhiyarov%2C+D">Denis Akhiyarov</a>, 
<a href="/search/cs?searchtype=author&query=Loehle%2C+S">Sophie Loehle</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+K">Kenneth Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Araya-Polo%2C+M">Mauricio Araya-Polo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Deep reinforcement learning has successfully been applied for molecular
discovery as shown by the Molecule Deep Q-network (MolDQN) algorithm. This
algorithm has challenges when applied to optimizing new molecules: training
such a model is limited in terms of scalability to larger datasets and the
trained model cannot be generalized to different molecules in the same dataset.
In this paper, a distributed reinforcement learning algorithm for antioxidants,
called DA-MolDQN is proposed to address these problems. State-of-the-art bond
dissociation energy (BDE) and ionization potential (IP) predictors are
integrated into DA-MolDQN, which are critical chemical properties while
optimizing antioxidants. Training time is reduced by algorithmic improvements
for molecular modifications. The algorithm is distributed, scalable for up to
512 molecules, and generalizes the model to a diverse set of molecules. The
proposed models are trained with a proprietary antioxidant dataset. The results
have been reproduced with both proprietary and public datasets. The proposed
molecules have been validated with DFT simulations and a subset of them
confirmed in public "unseen" datasets. In summary, DA-MolDQN is up to 100x
faster than previous algorithms and can discover new optimized molecules from
proprietary and public antioxidants.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01274" title="Abstract">arXiv:2312.01274</a> [<a href="/pdf/2312.01274" title="Download PDF">pdf</a>, <a href="/format/2312.01274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Compose SuperWeights for Neural Parameter Allocation Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teterwak%2C+P">Piotr Teterwak</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+S">Soren Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Dryden%2C+N">Nikoli Dryden</a>, 
<a href="/search/cs?searchtype=author&query=Bashkirova%2C+D">Dina Bashkirova</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural parameter allocation search (NPAS) automates parameter sharing by
obtaining weights for a network given an arbitrary, fixed parameter budget.
Prior work has two major drawbacks we aim to address. First, there is a
disconnect in the sharing pattern between the search and training steps, where
weights are warped for layers of different sizes during the search to measure
similarity, but not during training, resulting in reduced performance. To
address this, we generate layer weights by learning to compose sets of
SuperWeights, which represent a group of trainable parameters. These
SuperWeights are created to be large enough so they can be used to represent
any layer in the network, but small enough that they are computationally
efficient. The second drawback we address is the method of measuring similarity
between shared parameters. Whereas prior work compared the weights themselves,
we argue this does not take into account the amount of conflict between the
shared weights. Instead, we use gradient information to identify layers with
shared weights that wish to diverge from each other. We demonstrate that our
SuperWeight Networks consistently boost performance over the state-of-the-art
on the ImageNet and CIFAR datasets in the NPAS setting. We further show that
our approach can generate parameters for many network architectures using the
same set of weights. This enables us to support tasks like efficient ensembling
and anytime prediction, outperforming fully-parameterized ensembles with 17%
fewer parameters.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01276" title="Abstract">arXiv:2312.01276</a> [<a href="/pdf/2312.01276" title="Download PDF">pdf</a>, <a href="/ps/2312.01276" title="Download PostScript">ps</a>, <a href="/format/2312.01276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Running cognitive evaluations on large language models: The do&#x27;s and the  don&#x27;ts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivanova%2C+A+A">Anna A. Ivanova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, I describe methodological considerations for studies that aim
to evaluate the cognitive capacities of large language models (LLMs) using
language-based behavioral assessments. Drawing on three case studies from the
literature (a commonsense knowledge benchmark, a theory of mind evaluation, and
a test of syntactic agreement), I describe common pitfalls that might arise
when applying a cognitive test to an LLM. I then list 10 do's and don'ts that
should help design high-quality cognitive evaluations for AI systems. I
conclude by discussing four areas where the do's and don'ts are currently under
active discussion -- prompt sensitivity, cultural and linguistic diversity,
using LLMs as research assistants, and running evaluations on open vs. closed
LLMs. Overall, the goal of the paper is to contribute to the broader discussion
of best practices in the rapidly growing field of AI Psychology.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01279" title="Abstract">arXiv:2312.01279</a> [<a href="/pdf/2312.01279" title="Download PDF">pdf</a>, <a href="/format/2312.01279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enouen%2C+J">James Enouen</a>, 
<a href="/search/cs?searchtype=author&query=Nakhost%2C+H">Hootan Nakhost</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+S">Sayna Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S+O">Sercan O Arik</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have attracted huge interest in practical
applications given their increasingly accurate responses and coherent reasoning
abilities. Given their nature as black-boxes using complex reasoning processes
on their inputs, it is inevitable that the demand for scalable and faithful
explanations for LLMs' generated content will continue to grow. There have been
major developments in the explainability of neural network models over the past
decade. Among them, post-hoc explainability methods, especially Shapley values,
have proven effective for interpreting deep learning models. However, there are
major challenges in scaling up Shapley values for LLMs, particularly when
dealing with long input contexts containing thousands of tokens and
autoregressively generated output sequences. Furthermore, it is often unclear
how to effectively utilize generated explanations to improve the performance of
LLMs. In this paper, we introduce TextGenSHAP, an efficient post-hoc
explanation method incorporating LM-specific techniques. We demonstrate that
this leads to significant increases in speed compared to conventional Shapley
value computations, reducing processing times from hours to minutes for
token-level explanations, and to just seconds for document-level explanations.
In addition, we demonstrate how real-time Shapley values can be utilized in two
important scenarios, providing better understanding of long-document question
answering by localizing important words and sentences; and improving existing
document retrieval systems through enhancing the accuracy of selected passages
and ultimately the final responses.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01280" title="Abstract">arXiv:2312.01280</a> [<a href="/pdf/2312.01280" title="Download PDF">pdf</a>, <a href="/format/2312.01280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Decodes Deep Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huzheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gee%2C+J">James Gee</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianbo Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: see <a href="https://huzeyann.github.io/brain-decodes-deep-nets">this https URL</a> . Code: see <a href="https://github.com/huzeyann/BrainDecodesDeepNets">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We developed a tool for visualizing and analyzing large pre-trained vision
models by mapping them onto the brain, thus exposing their hidden inside. Our
innovation arises from a surprising usage of brain encoding: predicting brain
fMRI measurements in response to images. We report two findings. First,
explicit mapping between the brain and deep-network features across dimensions
of space, layers, scales, and channels is crucial. This mapping method,
FactorTopy, is plug-and-play for any deep-network; with it, one can paint a
picture of the network onto the brain (literally!). Second, our visualization
shows how different training methods matter: they lead to remarkable
differences in hierarchical organization and scaling behavior, growing with
more data or network capacity. It also provides insight into finetuning: how
pre-trained models change when adapting to small datasets. Our method is
practical: only 3K images are enough to learn a network-to-brain mapping.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01281" title="Abstract">arXiv:2312.01281</a> [<a href="/pdf/2312.01281" title="Download PDF">pdf</a>, <a href="/format/2312.01281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mendata: A Framework to Purify Manipulated Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zonghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N">Neil Gong</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+M+K">Michael K. Reiter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Untrusted data used to train a model might have been manipulated to endow the
learned model with hidden properties that the data contributor might later
exploit. Data purification aims to remove such manipulations prior to training
the model. We propose Mendata, a novel framework to purify manipulated training
data. Starting from a small reference dataset in which a large majority of the
inputs are clean, Mendata perturbs the training inputs so that they retain
their utility but are distributed similarly (as measured by Wasserstein
distance) to the reference data, thereby eliminating hidden properties from the
learned model. A key challenge is how to find such perturbations, which we
address by formulating a min-max optimization problem and developing a two-step
method to iteratively solve it. We demonstrate the effectiveness of Mendata by
applying it to defeat state-of-the-art data poisoning and data tracing
techniques.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01283" title="Abstract">arXiv:2312.01283</a> [<a href="/pdf/2312.01283" title="Download PDF">pdf</a>, <a href="/format/2312.01283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeper into Self-Supervised Monocular Indoor Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feiqing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation using Convolutional Neural Networks (CNNs) has
shown impressive performance in outdoor driving scenes. However,
self-supervised learning of indoor depth from monocular sequences is quite
challenging for researchers because of the following two main reasons. One is
the large areas of low-texture regions and the other is the complex ego-motion
on indoor training datasets. In this work, our proposed method, named
IndoorDepth, consists of two innovations. In particular, we first propose a
novel photometric loss with improved structural similarity (SSIM) function to
tackle the challenge from low-texture regions. Moreover, in order to further
mitigate the issue of inaccurate ego-motion prediction, multiple photometric
losses at different stages are used to train a deeper pose network with two
residual pose blocks. Subsequent ablation study can validate the effectiveness
of each new idea. Experiments on the NYUv2 benchmark demonstrate that our
IndoorDepth outperforms the previous state-of-the-art methods by a large
margin. In addition, we also validate the generalization ability of our method
on ScanNet dataset. Code is availabe at https://github.com/fcntes/IndoorDepth.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01284" title="Abstract">arXiv:2312.01284</a> [<a href="/pdf/2312.01284" title="Download PDF">pdf</a>, <a href="/format/2312.01284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Messenger: Steganography for Message-Concealed Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Truong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the ever-expanding digital landscape, safeguarding sensitive information
remains paramount. This paper delves deep into digital protection, specifically
focusing on steganography. While prior research predominantly fixated on
individual bit decoding, we address this limitation by introducing ``message
accuracy'', a novel metric evaluating the entirety of decoded messages for a
more holistic evaluation. In addition, we propose an adaptive universal loss
tailored to enhance message accuracy, named Log-Sum-Exponential (LSE) loss,
thereby significantly improving the message accuracy of recent approaches.
Furthermore, we also introduce a new latent-aware encoding technique in our
framework named \Approach, harnessing pretrained Stable Diffusion for advanced
steganographic image generation, giving rise to a better trade-off between
image quality and message recovery. Throughout experimental results, we have
demonstrated the superior performance of the new LSE loss and latent-aware
encoding technique. This comprehensive approach marks a significant step in
evolving evaluation metrics, refining loss functions, and innovating image
concealment techniques, aiming for more robust and dependable information
protection.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01285" title="Abstract">arXiv:2312.01285</a> [<a href="/pdf/2312.01285" title="Download PDF">pdf</a>, <a href="/format/2312.01285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Literature Review on the Smart Wheelchair Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+Y">Yane Kim</a>, 
<a href="/search/eess?searchtype=author&query=Velamala%2C+B">Bharath Velamala</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+Y">Youngseo Choi</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+Y">Yujin Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+H">Hyunkin Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kulkarni%2C+N">Nishad Kulkarni</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+E">Eung-Joo Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study offers an in-depth analysis of smart wheelchair (SW) systems,
charting their progression from early developments to future innovations. It
delves into various Brain-Computer Interface (BCI) systems, including mu
rhythm, event-related potential, and steady-state visual evoked potential. The
paper addresses challenges in signal categorization, proposing the sparse
Bayesian extreme learning machine as an innovative solution. Additionally, it
explores the integration of emotional states in BCI systems, the application of
alternative control methods such as EMG-based systems, and the deployment of
intelligent adaptive interfaces utilizing recurrent quantum neural networks.
The study also covers advancements in autonomous navigation, assistance, and
mapping, emphasizing their importance in SW systems. The human aspect of SW
interaction receives considerable attention, specifically in terms of privacy,
physiological factors, and the refinement of control mechanisms. The paper
acknowledges the commercial challenges faced, like the limitations of indoor
usage and the necessity for user training. For future applications, the
research explores the potential of autonomous systems adept at adapting to
changing environments and user needs. This exploration includes reinforcement
learning and various control methods, such as eye and voice control, to improve
adaptability and interaction. The potential integration with smart home
technologies, including advanced features such as robotic arms, is also
considered, aiming to further enhance user accessibility and independence.
Ultimately, this study seeks to provide a thorough overview of SW systems,
presenting extensive research to detail their historical evolution, current
state, and future prospects.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01286" title="Abstract">arXiv:2312.01286</a> [<a href="/pdf/2312.01286" title="Download PDF">pdf</a>, <a href="/format/2312.01286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Convolutional Neural Networks for Disruption Prediction in  Nuclear Fusion Plasmas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnold%2C+W+F">William F Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Spangher%2C+L">Lucas Spangher</a>, 
<a href="/search/cs?searchtype=author&query=Rea%2C+C">Christina Rea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CCAI NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">Grid decarbonization for climate change requires dispatchable carbon-free
energy like nuclear fusion. The tokamak concept offers a promising path for
fusion, but one of the foremost challenges in implementation is the occurrence
of energetic plasma disruptions. In this study, we delve into Machine Learning
approaches to predict plasma state outcomes. Our contributions are twofold: (1)
We present a novel application of Continuous Convolutional Neural Networks for
disruption prediction and (2) We examine the advantages and disadvantages of
continuous models over discrete models for disruption prediction by comparing
our model with the previous, discrete state of the art, and show that
continuous models offer significantly better performance (Area Under the
Receiver Operating Characteristic Curve = 0.974 v.s. 0.799) with fewer
parameters
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01288" title="Abstract">arXiv:2312.01288</a> [<a href="/pdf/2312.01288" title="Download PDF">pdf</a>, <a href="/format/2312.01288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Edge Networks: Decentralized Learning Over Wireless  Fronthaul
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seung-Wook Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies task-oriented edge networks where multiple edge
internet-of-things nodes execute machine learning tasks with the help of
powerful deep neural networks (DNNs) at a network cloud. Separate edge nodes
(ENs) result in a partially observable system where they can only get
partitioned features of the global network states. These local observations
need to be forwarded to the cloud via resource-constrained wireless fronthual
links. Individual ENs compress their local observations into uplink fronthaul
messages using task-oriented encoder DNNs. Then, the cloud carries out a remote
inference task by leveraging received signals. Such a distributed topology
requests a decentralized training and decentralized execution (DTDE) learning
framework for designing edge-cloud cooperative inference rules and their
decentralized training strategies. First, we develop fronthaul-cooperative DNN
architecture along with proper uplink coordination protocols suitable for
wireless fronthaul interconnection. Inspired by the nomographic function, an
efficient cloud inference model becomes an integration of a number of shallow
DNNs. This modulized architecture brings versatile calculations that are
independent of the number of ENs. Next, we present a decentralized training
algorithm of separate edge-cloud DNNs over downlink wireless fronthaul
channels. An appropriate downlink coordination protocol is proposed, which
backpropagates gradient vectors wirelessly from the cloud to the ENs.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01291" title="Abstract">arXiv:2312.01291</a> [<a href="/pdf/2312.01291" title="Download PDF">pdf</a>, <a href="/ps/2312.01291" title="Download PostScript">ps</a>, <a href="/format/2312.01291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunities for Retrieval and Tool Augmented Large Language Models in  Scientific Facilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prince%2C+M+H">Michael H. Prince</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+H">Henry Chan</a>, 
<a href="/search/cs?searchtype=author&query=Vriza%2C+A">Aikaterini Vriza</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+V+K">Varuni K. Sastry</a>, 
<a href="/search/cs?searchtype=author&query=Dearing%2C+M+T">Matthew T. Dearing</a>, 
<a href="/search/cs?searchtype=author&query=Harder%2C+R+J">Ross J. Harder</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+R+K">Rama K. Vasudevan</a>, 
<a href="/search/cs?searchtype=author&query=Cherukara%2C+M+J">Mathew J. Cherukara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci); Accelerator Physics (physics.acc-ph); Applied Physics (physics.app-ph); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">Upgrades to advanced scientific user facilities such as next-generation x-ray
light sources, nanoscience centers, and neutron facilities are revolutionizing
our understanding of materials across the spectrum of the physical sciences,
from life sciences to microelectronics. However, these facility and instrument
upgrades come with a significant increase in complexity. Driven by more
exacting scientific needs, instruments and experiments become more intricate
each year. This increased operational complexity makes it ever more challenging
for domain scientists to design experiments that effectively leverage the
capabilities of and operate on these advanced instruments. Large language
models (LLMs) can perform complex information retrieval, assist in
knowledge-intensive tasks across applications, and provide guidance on tool
usage. Using x-ray light sources, leadership computing, and nanoscience centers
as representative examples, we describe preliminary experiments with a
Context-Aware Language Model for Science (CALMS) to assist scientists with
instrument operations and complex experimentation. With the ability to retrieve
relevant information from facility documentation, CALMS can answer simple
questions on scientific capabilities and other operational procedures. With the
ability to interface with software tools and experimental hardware, CALMS can
conversationally operate scientific instruments. By making information more
accessible and acting on user needs, LLMs could expand and diversify scientific
facilities' users and accelerate scientific output.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01292" title="Abstract">arXiv:2312.01292</a> [<a href="/pdf/2312.01292" title="Download PDF">pdf</a>, <a href="/ps/2312.01292" title="Download PostScript">ps</a>, <a href="/format/2312.01292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Beam Scheduling and Power Optimization for Beam Hopping LEO  Satellite Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenbo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Low earth orbit (LEO) satellite communications can provide ubiquitous and
reliable services, making it an essential part of the Internet of Everything
network. Beam hopping (BH) is an emerging technology for effectively addressing
the issue of low resource utilization caused by the non-uniform spatio-temporal
distribution of traffic demands. However, how to allocate multi-dimensional
resources in a timely and efficient way for the highly dynamic LEO satellite
systems remains a challenge. This paper proposes a joint beam scheduling and
power optimization beam hopping (JBSPO-BH) algorithm considering the
differences in the geographic distribution of sink nodes. The JBSPO-BH
algorithm decouples the original problem into two sub-problems. The beam
scheduling problem is modelled as a potential game, and the Nash equilibrium
(NE) point is obtained as the beam scheduling strategy. Moreover, the penalty
function interior point method is applied to optimize the power allocation.
Simulation results show that the JBSPO-BH algorithm has low time complexity and
fast convergence and achieves better performance both in throughput and
fairness. Compared with greedy-based BH, greedy-based BH with the power
optimization, round-robin BH, Max-SINR BH and satellite resource allocation
algorithm, the throughput of the proposed algorithm is improved by 44.99%,
20.79%, 156.06%, 15.39% and 8.17%, respectively.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01294" title="Abstract">arXiv:2312.01294</a> [<a href="/pdf/2312.01294" title="Download PDF">pdf</a>, <a href="/format/2312.01294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Ensembles Meets Quantile Regression: Uncertainty-aware Imputation  for Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Multivariate time series are everywhere. Nevertheless, real-world time series
data often exhibit numerous missing values, which is the time series imputation
task. Although previous deep learning methods have been shown to be effective
for time series imputation, they are shown to produce overconfident
imputations, which might be a potentially overlooked threat to the reliability
of the intelligence system. Score-based diffusion method(i.e., CSDI) is
effective for the time series imputation task but computationally expensive due
to the nature of the generative diffusion model framework. In this paper, we
propose a non-generative time series imputation method that produces accurate
imputations with inherent uncertainty and meanwhile is computationally
efficient. Specifically, we incorporate deep ensembles into quantile regression
with a shared model backbone and a series of quantile discrimination
functions.This framework combines the merits of accurate uncertainty estimation
of deep ensembles and quantile regression and above all, the shared model
backbone tremendously reduces most of the computation overhead of the multiple
ensembles. We examine the performance of the proposed method on two real-world
datasets: air quality and health-care datasets and conduct extensive
experiments to show that our method excels at making deterministic and
probabilistic predictions. Compared with the score-based diffusion method:
CSDI, we can obtain comparable forecasting results and is better when more data
is missing. Furthermore, as a non-generative model compared with CSDI, the
proposed method consumes a much smaller computation overhead, yielding much
faster training speed and fewer model parameters.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01295" title="Abstract">arXiv:2312.01295</a> [<a href="/pdf/2312.01295" title="Download PDF">pdf</a>, <a href="/format/2312.01295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-stage dynamic creative optimization under sparse ambiguous samples  for e-commerce advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guandong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Ad creative is one of the main mediums for e-commerce advertising. In our
approach we decouple this dynamic creative optimization into two stages, a
cascaded structure that can trade off between effectiveness and efficiency. In
the first stage, we train an automatic creative optimization architecture based
on autoco to simulate complex interactions between creative elements. Although
we obtained the ranking of different creatives under a sku, because we bucketed
and merged historical data according to periods, this confuses the ctr
diversity of the same ad creatives on different days and weakens the ability to
separate ambiguous samples. Therefore, we propose a transformer-based rerank
model. With the help of the rank model, we propose a distillation method to
learn the relative order of ideas and extract the ranking knowledge to guide
the rerank learning. The creative order soft labels under each sku are
generated by the rank model to alleviate the dilemma that a large number of
under-represented creatives cannot obtain real labels. Through the knowledge
diffusion of rerank, the ambiguous samples are associated with the positive and
negative samples. Cascade rerank and autoco to output the estimated value of
the synthetic ad image. In the second stage, we designed a bandit model, and
the bandit selected one of the output ad of the first stage for timely
delivery. Experimental results show that our method can outperform competing
baselines in terms of sctr. Online A/B testing shows that our method improves
ctr by 10% compared to the baseline.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01297" title="Abstract">arXiv:2312.01297</a> [<a href="/pdf/2312.01297" title="Download PDF">pdf</a>, <a href="/format/2312.01297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlatProxy: A DPU-centric Service Mesh Architecture for Hyperscale  Cloud-native Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenyan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hanyue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingya Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guihai Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Service mesh is a fundamental technology for building cloud-native
applications, which ensures the stable running of a large number of services by
an intermediate layer that governs communication between services. However,
service mesh is not well suited for high-performance scenarios. The root cause
is that the current service mesh is not suitable for the evolution of
cloud-native applications. On the one hand, the service mesh built on CPU
cannot listen to communication bypassing the CPU. On the other hand, service
mesh includes many I/O-intensive and computationally-intensive tasks that can
overload CPU cores as traffic grows beyond CPU performance.
<br />Therefore, we propose a data-centric service mesh that migrates the proxy of
the service mesh to the entrance of the network. Moreover, we also design the
DPU-centric FlatProxy, a data-centric service mesh based on DPU. There are
three advantages to the DPU-centric service mesh. Firstly, it takes over all
traffic flow in and out of the node, which expands the sense scale of the
service mesh from container to node. Secondly, it improves communication
performance and reduces host resource usage by offloading some functions and
optimizing communication. Thirdly, it minimizes performance and security issues
through the physical isolation of business services and cloud infrastructure.
<br />Compared with Envoy, the current mainstream service mesh implementation,
FlatProxy reduces latency by 90\% and improves throughput by 4x in Gbps and 8x
in qps, and it only occupies a small amount of CPU resources.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01299" title="Abstract">arXiv:2312.01299</a> [<a href="/pdf/2312.01299" title="Download PDF">pdf</a>, <a href="/format/2312.01299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Non-parametric Knowledge-based Diffusion Least Mean Squares over  Adaptive Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashkezari-Toussi%2C+S">Soheil Ashkezari-Toussi</a>, 
<a href="/search/cs?searchtype=author&query=sadoghi-Yazdi%2C+H">Hadi sadoghi-Yazdi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The present study proposes incorporating non-parametric knowledge into the
diffusion least-mean-squares algorithm in the framework of a maximum a
posteriori (MAP) estimation. The proposed algorithm leads to a robust
estimation of an unknown parameter vector in a group of cooperative estimators.
Utilizing kernel density estimation and buffering some intermediate
estimations, the prior distribution and conditional likelihood of the
parameters vector in each node are calculated. Pseudo Huber loss function is
used for designing the likelihood function. Also, an error thresholding
function is defined to reduce the computational overhead as well as more
relaxation against noise, which stops the update every time an error is less
than a predefined threshold. The performance of the proposed algorithm is
examined in the stationary and non-stationary scenarios in the presence of
Gaussian and non-Gaussian noise. Results show the robustness of the proposed
algorithm in the presence of different noise types.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01301" title="Abstract">arXiv:2312.01301</a> [<a href="/pdf/2312.01301" title="Download PDF">pdf</a>, <a href="/format/2312.01301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Churn Prediction via Multimodal Fusion Learning:Integrating Customer  Financial Literacy, Voice, and Behavioral Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudd%2C+D+H">David Hason Rudd</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+H">Huan Huo</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+R">Md Rafiqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In todays competitive landscape, businesses grapple with customer retention.
Churn prediction models, although beneficial, often lack accuracy due to the
reliance on a single data source. The intricate nature of human behavior and
high dimensional customer data further complicate these efforts. To address
these concerns, this paper proposes a multimodal fusion learning model for
identifying customer churn risk levels in financial service providers. Our
multimodal approach integrates customer sentiments financial literacy (FL)
level, and financial behavioral data, enabling more accurate and bias-free
churn prediction models. The proposed FL model utilizes a SMOGN COREG
supervised model to gauge customer FL levels from their financial data. The
baseline churn model applies an ensemble artificial neural network and
oversampling techniques to predict churn propensity in high-dimensional
financial data. We also incorporate a speech emotion recognition model
employing a pre-trained CNN-VGG16 to recognize customer emotions based on
pitch, energy, and tone. To integrate these diverse features while retaining
unique insights, we introduced late and hybrid fusion techniques that
complementary boost coordinated multimodal co learning. Robust metrics were
utilized to evaluate the proposed multimodal fusion model and hence the
approach validity, including mean average precision and macro-averaged F1
score. Our novel approach demonstrates a marked improvement in churn
prediction, achieving a test accuracy of 91.2%, a Mean Average Precision (MAP)
score of 66, and a Macro-Averaged F1 score of 54 through the proposed hybrid
fusion learning technique compared with late fusion and baseline models.
Furthermore, the analysis demonstrates a positive correlation between negative
emotions, low FL scores, and high-risk customers.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01302" title="Abstract">arXiv:2312.01302</a> [<a href="/pdf/2312.01302" title="Download PDF">pdf</a>, <a href="/ps/2312.01302" title="Download PostScript">ps</a>, <a href="/format/2312.01302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart safety watch for elderly people and pregnant women
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+B+D">Balachandra D S</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+M+M">Maithreyee M S</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+S+B">Saipavan B M</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+S">Shashank S</a>, 
<a href="/search/cs?searchtype=author&query=Devaki%2C+D+P">Dr. P Devaki</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+M+A">Ms. Ashwini M</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Robotics (cs.RO)

</div>
<p class="mathjax">Falls represent one of the most detrimental occurrences for the elderly.
Given the continually increasing ageing demographic, there is a pressing demand
for advancing fall detection systems. The swift progress in sensor networks and
the Internet of Things (IoT) has made human-computer interaction through sensor
fusion an acknowledged and potent approach for tackling the issue of fall
detection. Even IoT-enabled systems can deliver economical health monitoring
solutions tailored to pregnant women within their daily environments. Recent
research indicates that these remote health monitoring setups have the
potential to enhance the well-being of both the mother and the infant
throughout the pregnancy and postpartum phases. One more emerging advancement
is the integration of 'panic buttons,' which are gaining popularity due to the
escalating emphasis on safety. These buttons instantly transmit the user's
real-time location to pre-designated emergency contacts when activated. Our
solution focuses on the above three challenges we see every day. Fall detection
for the elderly helps the elderly in case they fall and have nobody around for
help. Sleep pattern sensing is helpful for pregnant women based on the SPO2
sensors integrated within our device. It is also bundled with heart rate
monitoring. Our third solution focuses on a panic situation; upon pressing the
determined buttons, a panic alert would be sent to the emergency contacts
listed. The device also comes with a mobile app developed using Flutter that
takes care of all the heavy processing rather than the device itself.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01304" title="Abstract">arXiv:2312.01304</a> [<a href="/pdf/2312.01304" title="Download PDF">pdf</a>, <a href="/format/2312.01304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jut: A Framework for Just-in-Time Data Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Silvery Fu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Siyuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Mistri%2C+J">Jamsheed Mistri</a>, 
<a href="/search/cs?searchtype=author&query=McCanne%2C+S">Steve McCanne</a>, 
<a href="/search/cs?searchtype=author&query=Ousterhout%2C+A">Amy Ousterhout</a>, 
<a href="/search/cs?searchtype=author&query=Ratnasamy%2C+S">Sylvia Ratnasamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">With the proliferation of sensor and personal devices, our physical spaces
are now awash in potential data sources. In principle this data could serve a
wide range of applications and services. However, leveraging these data sources
is challenging with today's systems because they are not typically designed to
consume data opportunistically, from a new device that happens to arrive in the
vicinity.
<br />In this paper, we present the design and implementation of Jut, a system
designed for "Just-in-Time" data access - in which an application is able to
discover and consume data from any available source, even ones not known at
development or installation time. Jut combines two novel design choices:
modularizing data processing systems to better reflect the physical world, and
a new form of application-data integration that equips data processing
pipelines with the information they need to process new and evolving data
formats and schemas. We show that these choices greatly simplify the
development and use of smart-space and IoT applications. For a representative
set of devices and application scenarios, we show that Jut can implement
use-cases not easily supported today, or can do so with 3.2-14.8x less
development effort and 3-12x lower query complexity than current systems.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01305" title="Abstract">arXiv:2312.01305</a> [<a href="/pdf/2312.01305" title="Download PDF">pdf</a>, <a href="/format/2312.01305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+J">Jeong-gi Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+E">Erqun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuhe Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+H">Hanseok Ko</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+S">Shweta Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jgkwak95.github.io/ViVid-1-to-3/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Generating novel views of an object from a single image is a challenging
task. It requires an understanding of the underlying 3D structure of the object
from an image and rendering high-quality, spatially consistent new views. While
recent methods for view synthesis based on diffusion have shown great progress,
achieving consistency among various view estimates and at the same time abiding
by the desired camera pose remains a critical problem yet to be solved. In this
work, we demonstrate a strikingly simple method, where we utilize a pre-trained
video diffusion model to solve this problem. Our key idea is that synthesizing
a novel view could be reformulated as synthesizing a video of a camera going
around the object of interest -- a scanning video -- which then allows us to
leverage the powerful priors that a video diffusion model would have learned.
Thus, to perform novel-view synthesis, we create a smooth camera trajectory to
the target view that we wish to render, and denoise using both a
view-conditioned diffusion model and a video diffusion model. By doing so, we
obtain a highly consistent novel view synthesis, outperforming the state of the
art.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01306" title="Abstract">arXiv:2312.01306</a> [<a href="/pdf/2312.01306" title="Download PDF">pdf</a>, <a href="/format/2312.01306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Significance of Subword tokenization for Low Resource and Efficient  Named Entity Recognition: A case study in Marathi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+H">Harsh Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Anuja Patil</a>, 
<a href="/search/cs?searchtype=author&query=Lavekar%2C+D">Dhanashree Lavekar</a>, 
<a href="/search/cs?searchtype=author&query=Khairnar%2C+P">Pranav Khairnar</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Pande%2C+S">Sachin Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICDAM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Named Entity Recognition (NER) systems play a vital role in NLP applications
such as machine translation, summarization, and question-answering. These
systems identify named entities, which encompass real-world concepts like
locations, persons, and organizations. Despite extensive research on NER
systems for the English language, they have not received adequate attention in
the context of low resource languages. In this work, we focus on NER for
low-resource language and present our case study in the context of the Indian
language Marathi. The advancement of NLP research revolves around the
utilization of pre-trained transformer models such as BERT for the development
of NER models. However, we focus on improving the performance of shallow models
based on CNN, and LSTM by combining the best of both worlds. In the era of
transformers, these traditional deep learning models are still relevant because
of their high computational efficiency. We propose a hybrid approach for
efficient NER by integrating a BERT-based subword tokenizer into vanilla
CNN/LSTM models. We show that this simple approach of replacing a traditional
word-based tokenizer with a BERT-tokenizer brings the accuracy of vanilla
single-layer models closer to that of deep pre-trained models like BERT. We
show the importance of using sub-word tokenization for NER and present our
study toward building efficient NLP systems. The evaluation is performed on
L3Cube-MahaNER dataset using tokenizers from MahaBERT, MahaGPT, IndicBERT, and
mBERT.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01307" title="Abstract">arXiv:2312.01307</a> [<a href="/pdf/2312.01307" title="Download PDF">pdf</a>, <a href="/format/2312.01307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGE: Bridging Semantic and Actionable Parts for GEneralizable  Articulated-Object Manipulation under Language Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Songlin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Congyue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bokui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generalizable manipulation of articulated objects remains a challenging
problem in many real-world scenarios, given the diverse object structures,
functionalities, and goals. In these tasks, both semantic interpretations and
physical plausibilities are crucial for a policy to succeed. To address this
problem, we propose SAGE, a novel framework that bridges the understanding of
semantic and actionable parts of articulated objects to achieve generalizable
manipulation under language instructions. Given a manipulation goal specified
by natural language, an instruction interpreter with Large Language Models
(LLMs) first translates them into programmatic actions on the object's semantic
parts. This process also involves a scene context parser for understanding the
visual inputs, which is designed to generate scene descriptions with both rich
information and accurate interaction-related facts by joining the forces of
generalist Visual-Language Models (VLMs) and domain-specialist part perception
models. To further convert the action programs into executable policies, a part
grounding module then maps the object semantic parts suggested by the
instruction interpreter into so-called Generalizable Actionable Parts
(GAParts). Finally, an interactive feedback module is incorporated to respond
to failures, which greatly increases the robustness of the overall framework.
Experiments both in simulation environments and on real robots show that our
framework can handle a large variety of articulated objects with diverse
language-instructed goals. We also provide a new benchmark for language-guided
articulated-object manipulation in realistic scenarios.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01308" title="Abstract">arXiv:2312.01308</a> [<a href="/pdf/2312.01308" title="Download PDF">pdf</a>, <a href="/format/2312.01308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Background Knowledge Gaps in Translation with Automatic  Explicitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+H">HyoJung Han</a>, 
<a href="/search/cs?searchtype=author&query=Boyd-Graber%2C+J+L">Jordan Lee Boyd-Graber</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Translations help people understand content written in another language.
However, even correct literal translations do not fulfill that goal when people
lack the necessary background to understand them. Professional translators
incorporate explicitations to explain the missing context by considering
cultural differences between source and target audiences. Despite its potential
to help users, NLP research on explicitation is limited because of the dearth
of adequate evaluation methods. This work introduces techniques for
automatically generating explicitations, motivated by WikiExpl: a dataset that
we collect from Wikipedia and annotate with human translators. The resulting
explicitations are useful as they help answer questions more accurately in a
multilingual question answering framework.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01314" title="Abstract">arXiv:2312.01314</a> [<a href="/pdf/2312.01314" title="Download PDF">pdf</a>, <a href="/format/2312.01314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark  Dataset for Generative Language Models in Norwegian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lemei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Farup%2C+T+N">Terje Nissen Farup</a>, 
<a href="/search/cs?searchtype=author&query=Lauvrak%2C+E+W">Even W. Lauvrak</a>, 
<a href="/search/cs?searchtype=author&query=Ingvaldsen%2C+J+E">Jon Espen Ingvaldsen</a>, 
<a href="/search/cs?searchtype=author&query=Eide%2C+S">Simen Eide</a>, 
<a href="/search/cs?searchtype=author&query=Gulla%2C+J+A">Jon Atle Gulla</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhirong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in Generative Language Models (GLMs) have transformed
Natural Language Processing (NLP) by showcasing the effectiveness of the
"pre-train, prompt, and predict" paradigm in utilizing pre-trained GLM
knowledge for diverse applications. Despite their potential, these capabilities
lack adequate quantitative characterization due to the absence of comprehensive
benchmarks, particularly for low-resource languages. Existing low-resource
benchmarks focus on discriminative language models like BERT, neglecting the
evaluation of generative language models. Moreover, current benchmarks often
overlook measuring generalization performance across multiple tasks, a crucial
metric for GLMs.
<br />To bridge these gaps, we introduce NLEBench, a comprehensive benchmark
tailored for evaluating natural language generation capabilities in Norwegian,
a low-resource language. We use Norwegian as a case study to explore whether
current GLMs and benchmarks in mainstream languages like English can reveal the
unique characteristics of underrepresented languages. NLEBench encompasses a
suite of real-world NLP tasks ranging from news storytelling, summarization,
open-domain conversation, natural language understanding, instruction
fine-tuning, toxicity and bias evaluation, to self-curated Chain-of-Thought
investigation. It features two high-quality, human-annotated datasets: an
instruction dataset covering traditional Norwegian cultures, idioms, slang, and
special expressions, and a document-grounded multi-label dataset for topic
classification, question answering, and summarization. This paper also
introduces foundational Norwegian Generative Language Models (NorGLMs)
developed with diverse parameter scales and Transformer-based architectures.
Systematic evaluations on the proposed benchmark suite provide insights into
the capabilities and scalability of NorGLMs across various downstream tasks.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01315" title="Abstract">arXiv:2312.01315</a> [<a href="/pdf/2312.01315" title="Download PDF">pdf</a>, <a href="/format/2312.01315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Shape Recognition by Learning Deep Shape-aware Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenlong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Changsheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Ming Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Siyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Koniusz%2C+P">Piotr Koniusz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024; 8 pages for main paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional shape descriptors have been gradually replaced by convolutional
neural networks due to their superior performance in feature extraction and
classification. The state-of-the-art methods recognize object shapes via image
reconstruction or pixel classification. However , these methods are biased
toward texture information and overlook the essential shape descriptions, thus,
they fail to generalize to unseen shapes. We are the first to propose a fewshot
shape descriptor (FSSD) to recognize object shapes given only one or a few
samples. We employ an embedding module for FSSD to extract
transformation-invariant shape features. Secondly, we develop a dual attention
mechanism to decompose and reconstruct the shape features via learnable shape
primitives. In this way, any shape can be formed through a finite set basis,
and the learned representation model is highly interpretable and extendable to
unseen shapes. Thirdly, we propose a decoding module to include the supervision
of shape masks and edges and align the original and reconstructed shape
features, enforcing the learned features to be more shape-aware. Lastly, all
the proposed modules are assembled into a few-shot shape recognition scheme.
Experiments on five datasets show that our FSSD significantly improves the
shape classification compared to the state-of-the-art under the few-shot
setting.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01324" title="Abstract">arXiv:2312.01324</a> [<a href="/pdf/2312.01324" title="Download PDF">pdf</a>, <a href="/format/2312.01324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MABViT -- Modified Attention Block Enhances Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+M">Mahesh Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+A">Aswinkumar Ramkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have demonstrated the effectiveness of Gated Linear Units
(GLU) in enhancing transformer models, particularly in Large Language Models
(LLMs). Additionally, utilizing a parallel configuration within each
Transformer block rather than the conventional serialized method has been
revealed to accelerate the training of LLMs without significantly impacting
performance. However, when the MLP and attention block were run in parallel for
the image classification task, we observed a noticeable decline in performance.
We propose a novel transformer variant that integrates non-linearity within the
attention block to tackle this problem. We implemented the GLU-based activation
function on the Value tensor, and this new technique surpasses the current
state-of-the-art S/16 variant of Vision Transformers by 0.6% on the ImageNet-1K
dataset while utilizing fewer parameters. It also supersedes the B/16 variant
while using only half the parameters. Furthermore, we provide results with the
GELU activation function variant to confirm our assertions. Lastly, we showcase
that the MABViT variants exhibit greater potential when utilized in deep
transformers compared to the standard architecture.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01326" title="Abstract">arXiv:2312.01326</a> [<a href="/pdf/2312.01326" title="Download PDF">pdf</a>, <a href="/format/2312.01326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OA-ECBVC: A Cooperative Collision-free Encirclement and Capture Approach  in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yulong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yizhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Ruihua Han</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+L">Lele Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B+M">Ben M. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This article investigates the practical scenarios of chasing an adversarial
evader in an unbounded environment with cluttered obstacles. We propose a
Voronoi-based decentralized algorithm for multiple pursuers to encircle and
capture the evader by reacting to collisions. An efficient approach is
presented for constructing an obstacle-aware evader-centered bounded Voronoi
cell (OA-ECBVC), which strictly ensures collision avoidance in various obstacle
scenarios when pursuing the evader. The evader can be efficiently enclosed in a
convex hull given random initial configurations. Furthermore, to cooperatively
capture the evader, each pursuer continually compresses the boundary of its
OA-ECBVC to quickly reduce the movement space of the evader while maintaining
encirclement. Our OA-ECBVC algorithm is validated in various simulated
environments with different dynamic systems of robots. Real-time performance of
resisting uncertainties shows the superior reliability of our method for
deployment on multiple robot platforms.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01330" title="Abstract">arXiv:2312.01330</a> [<a href="/pdf/2312.01330" title="Download PDF">pdf</a>, <a href="/format/2312.01330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Security of Satellite Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peled%2C+R">Roy Peled</a>, 
<a href="/search/cs?searchtype=author&query=Aizikovich%2C+E">Eran Aizikovich</a>, 
<a href="/search/cs?searchtype=author&query=Habler%2C+E">Edan Habler</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Satellite systems are facing an ever-increasing amount of cybersecurity
threats as their role in communications, navigation, and other services
expands. Recent papers have examined attacks targeting satellites and space
systems; however, they did not comprehensively analyze the threats to
satellites and systematically identify adversarial techniques across the attack
lifecycle. This paper presents a comprehensive taxonomy of adversarial tactics,
techniques, and procedures explicitly targeting LEO satellites. First, we
analyze the space ecosystem including the ground, space, Communication, and
user segments, highlighting their architectures, functions, and
vulnerabilities. Then, we examine the threat landscape, including adversary
types, and capabilities, and survey historical and recent attacks such as
jamming, spoofing, and supply chain. Finally, we propose a novel extension of
the MITRE ATT&amp;CK framework to categorize satellite attack techniques across the
adversary lifecycle from reconnaissance to impact. The taxonomy is demonstrated
by modeling high-profile incidents, including the Viasat attack that disrupted
Ukraine's communications. The taxonomy provides the foundation for the
development of defenses against emerging cyber risks to space assets. The
proposed threat model will advance research in the space domain and contribute
to the security of the space domain against sophisticated attacks.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01335" title="Abstract">arXiv:2312.01335</a> [<a href="/pdf/2312.01335" title="Download PDF">pdf</a>, <a href="/ps/2312.01335" title="Download PostScript">ps</a>, <a href="/format/2312.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Emotion Recognition Under Mask Coverage Using a Data Augmentation  Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhadipour%2C+A">Aref Farhadipour</a>, 
<a href="/search/cs?searchtype=author&query=Taghipour%2C+P">Pouya Taghipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Identifying human emotions using AI-based computer vision systems, when
individuals wear face masks, presents a new challenge in the current Covid-19
pandemic. In this study, we propose a facial emotion recognition system capable
of recognizing emotions from individuals wearing different face masks. A novel
data augmentation technique was utilized to improve the performance of our
model using four mask types for each face image. We evaluated the effectiveness
of four convolutional neural networks, Alexnet, Squeezenet, Resnet50 and
VGGFace2 that were trained using transfer learning. The experimental findings
revealed that our model works effectively in multi-mask mode compared to
single-mask mode. The VGGFace2 network achieved the highest accuracy rate, with
97.82% for the person-dependent mode and 74.21% for the person-independent mode
using the JAFFE dataset. However, we evaluated our proposed model using the
UIBVFED dataset. The Resnet50 has demonstrated superior performance, with
accuracies of 73.68% for the person-dependent mode and 59.57% for the
person-independent mode. Moreover, we employed metrics such as precision,
sensitivity, specificity, AUC, F1 score, and confusion matrix to measure our
system's efficiency in detail. Additionally, the LIME algorithm was used to
visualize CNN's decision-making strategy.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01339" title="Abstract">arXiv:2312.01339</a> [<a href="/pdf/2312.01339" title="Download PDF">pdf</a>, <a href="/format/2312.01339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Powered Arabic Crossword Puzzle Generation for Educational  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+Z">Mohamed Zaky Saad</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for ArabicNLP 2023 - The First Arabic Natural Language Processing Conference - Co-located with EMNLP 2023 in Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents the first Arabic crossword puzzle generator driven by
advanced AI technology. Leveraging cutting-edge large language models including
GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system
generates distinctive and challenging clues. Based on a dataset comprising over
50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot
learning strategies, and rigorous quality-checking protocols to enforce the
generation of high-quality clue-answer pairs. Importantly, educational
crosswords contribute to enhancing memory, expanding vocabulary, and promoting
problem-solving skills, thereby augmenting the learning experience through a
fun and engaging approach, reshaping the landscape of traditional learning
methods. The overall system can be exploited as a powerful educational tool
that amalgamates AI and innovative learning techniques, heralding a
transformative era for Arabic crossword puzzles and the intersection of
technology and education.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01342" title="Abstract">arXiv:2312.01342</a> [<a href="/pdf/2312.01342" title="Download PDF">pdf</a>, <a href="/format/2312.01342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Coordinates and Conventional Neural Networks -- An Alternative for  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zheyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Paffenroth%2C+R">Randy Paffenroth</a>, 
<a href="/search/cs?searchtype=author&query=Jayasumana%2C+A+P">Anura P. Jayasumana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is submitted and will be published on Big Data Conference 2023, Data-driven Science for Graphs: Algorithms, Architectures, and Application workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph-based data present unique challenges and opportunities for machine
learning. Graph Neural Networks (GNNs), and especially those algorithms that
capture graph topology through message passing for neighborhood aggregation,
have been a leading solution. However, these networks often require substantial
computational resources and may not optimally leverage the information
contained in the graph's topology, particularly for large-scale or complex
graphs. We propose Topology Coordinate Neural Network (TCNN) and Directional
Virtual Coordinate Neural Network (DVCNN) as novel and efficient alternatives
to message passing GNNs, that directly leverage the graph's topology,
sidestepping the computational challenges presented by competing algorithms.
Our proposed methods can be viewed as a reprise of classic techniques for graph
embedding for neural network feature engineering, but they are novel in that
our embedding techniques leverage ideas in Graph Coordinates (GC) that are
lacking in current practice. Experimental results, benchmarked against the Open
Graph Benchmark Leaderboard, demonstrate that TCNN and DVCNN achieve
competitive or superior performance to message passing GNNs. For similar levels
of accuracy and ROC-AUC, TCNN and DVCNN need far fewer trainable parameters
than contenders of the OGBN Leaderboard. The proposed TCNN architecture
requires fewer parameters than any neural network method currently listed in
the OGBN Leaderboard for both OGBN-Proteins and OGBN-Products datasets.
Conversely, our methods achieve higher performance for a similar number of
trainable parameters. By providing an efficient and effective alternative to
message passing GNNs, our work expands the toolbox of techniques for
graph-based machine learning.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01344" title="Abstract">arXiv:2312.01344</a> [<a href="/pdf/2312.01344" title="Download PDF">pdf</a>, <a href="/format/2312.01344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> tsMorph: generation of semi-synthetic time series to understand  algorithm performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+M">Mois&#xe9;s Santos</a>, 
<a href="/search/cs?searchtype=author&query=de+Carvalho%2C+A">Andr&#xe9; de Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+C">Carlos Soares</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series forecasting is a subject of significant scientific and industrial
importance. Despite the widespread utilization of forecasting methods, there is
a dearth of research aimed at comprehending the conditions under which these
methods yield favorable or unfavorable performances. Empirical studies,
although common, encounter challenges due to the limited availability of
datasets, impeding the extraction of reliable insights. To address this, we
present tsMorph, a straightforward approach for generating semi-synthetic time
series through dataset morphing. tsMorph operates by creating a sequence of
datasets derived from two original datasets. These newly generated datasets
exhibit a progressive departure from the characteristics of one dataset and a
convergence toward the attributes of the other. This method provides a valuable
alternative for obtaining substantial datasets. In this paper, we demonstrate
the utility of tsMorph by assessing the performance of the Long Short-Term
Memory Network forecasting algorithm. The time series under examination are
sourced from the NN5 Competition. The findings reveal compelling insights.
Notably, the performance of the Long Short-Term Memory Network improves
proportionally with the frequency of the time series. These experiments affirm
that tsMorph serves as an effective tool for gaining an understanding of
forecasting algorithm behaviors, offering a pathway to overcome the limitations
posed by empirical studies and enabling more extensive and reliable
experimentation.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01345" title="Abstract">arXiv:2312.01345</a> [<a href="/pdf/2312.01345" title="Download PDF">pdf</a>, <a href="/ps/2312.01345" title="Download PostScript">ps</a>, <a href="/format/2312.01345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Modelling, Analysis and Control of Three-Phase Electrical  Systems Using Geometric Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Velasco%2C+M">Manel Velasco</a>, 
<a href="/search/eess?searchtype=author&query=Zaplana%2C+I">Isiah Zaplana</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B2ria-Cerezo%2C+A">Arnau D&#xf2;ria-Cerezo</a>, 
<a href="/search/eess?searchtype=author&query=Duarte%2C+J">Josu&#xe9; Duarte</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%AD%2C+P">Pau Mart&#xed;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State-of-the-art techniques for modeling, analysis and control of three-phase
electrical systems belong to the real-valued multi-input/multi-output (MIMO)
domain, or to the complex-valued nonlinear single-input/single-output (SISO)
domain. In order to complement both domains while simplifying complexity and
offering new analysis and design perspectives, this paper introduces the
application of geometric algebra (GA) principles to the modeling, analysis and
control of three-phase electrical systems. The key contribution for the
modeling part is the identification of the transformation that allows
transferring real-valued linear MIMO systems into GA-valued linear SISO
representations (with independence of having a balanced or unbalanced system).
Closed-loop stability analysis in the new space is addressed by using intrinsic
properties of GA. In addition, a recipe for designing stabilizing and
decoupling GA-valued controllers is provided. Numerical examples illustrate key
developments and experiments corroborate the main findings.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01350" title="Abstract">arXiv:2312.01350</a> [<a href="/pdf/2312.01350" title="Download PDF">pdf</a>, <a href="/format/2312.01350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Honesty Is the Best Policy: Defining and Mitigating AI Deception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ward%2C+F+R">Francis Rhys Ward</a>, 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+F">Francesco Belardinelli</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>, 
<a href="/search/cs?searchtype=author&query=Everitt%2C+T">Tom Everitt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a spotlight at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deceptive agents are a challenge for the safety, trustworthiness, and
cooperation of AI systems. We focus on the problem that agents might deceive in
order to achieve their goals (for instance, in our experiments with language
models, the goal of being evaluated as truthful). There are a number of
existing definitions of deception in the literature on game theory and symbolic
AI, but there is no overarching theory of deception for learning agents in
games. We introduce a formal definition of deception in structural causal
games, grounded in the philosophy literature, and applicable to real-world
machine learning systems. Several examples and results illustrate that our
formal definition aligns with the philosophical and commonsense meaning of
deception. Our main technical result is to provide graphical criteria for
deception. We show, experimentally, that these results can be used to mitigate
deception in reinforcement learning agents and language models.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01354" title="Abstract">arXiv:2312.01354</a> [<a href="/pdf/2312.01354" title="Download PDF">pdf</a>, <a href="/format/2312.01354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protecting Sensitive Tabular Data in Hybrid Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+M">Maya Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Gershinsky%2C+G">Gidon Gershinsky</a>, 
<a href="/search/cs?searchtype=author&query=Salant%2C+E">Eliot Salant</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+S">Salvador Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Regulated industries, such as Healthcare and Finance, are starting to move
parts of their data and workloads to the public cloud. However, they are still
reluctant to trust the public cloud with their most sensitive records, and
hence leave them in their premises, leveraging the hybrid cloud architecture.
We address the security and performance challenges of big data analytics using
a hybrid cloud in a real-life use case from a hospital. In this use case, the
hospital collects sensitive patient data and wants to run analytics on it in
order to lower antibiotics resistance, a significant challenge in healthcare.
We show that it is possible to run large-scale analytics on data that is
securely stored in the public cloud encrypted using Apache Parquet Modular
Encryption (PME), without significant performance losses even if the secret
encryption keys are stored on-premises. PME is a standard mechanism for data
encryption and key management, not specific to any public cloud, and therefore
helps prevent vendor lock-in. It also provides privacy and integrity
guarantees, and enables granular access control to the data. We also present an
innovation in PME for lowering the performance hit incurred by calls to the Key
Management Service. Our solution therefore enables protecting large amounts of
sensitive data in hybrid clouds and still allows to efficiently gain valuable
insights from it.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01356" title="Abstract">arXiv:2312.01356</a> [<a href="/pdf/2312.01356" title="Download PDF">pdf</a>, <a href="/ps/2312.01356" title="Download PostScript">ps</a>, <a href="/format/2312.01356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CEScore: Simple and Efficient Confidence Estimation Model for Evaluating  Split and Rephrase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajlouni%2C+A+B+A">AlMotasem Bellah Al Ajlouni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinlong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The split and rephrase (SR) task aims to divide a long, complex sentence into
a set of shorter, simpler sentences that convey the same meaning. This
challenging problem in NLP has gained increased attention recently because of
its benefits as a pre-processing step in other NLP tasks. Evaluating quality of
SR is challenging, as there no automatic metric fit to evaluate this task. In
this work, we introduce CEScore, as novel statistical model to automatically
evaluate SR task. By mimicking the way humans evaluate SR, CEScore provides 4
metrics (Sscore, Gscore, Mscore, and CEscore) to assess simplicity,
grammaticality, meaning preservation, and overall quality, respectively. In
experiments with 26 models, CEScore correlates strongly with human evaluations,
achieving 0.98 in Spearman correlations at model-level. This underscores the
potential of CEScore as a simple and effective metric for assessing the overall
quality of SR models.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01357" title="Abstract">arXiv:2312.01357</a> [<a href="/pdf/2312.01357" title="Download PDF">pdf</a>, <a href="/ps/2312.01357" title="Download PostScript">ps</a>, <a href="/format/2312.01357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyze the robustness of three NMF algorithms (Robust NMF with L1 norm,  L2-1 norm NMF, L2 NMF)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+C">Cheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiaqi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yixuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Non-negative matrix factorization (NMF) and its variants have been widely
employed in clustering and classification tasks (Long, &amp; Jian , 2021). However,
noises can seriously affect the results of our experiments. Our research is
dedicated to investigating the noise robustness of non-negative matrix
factorization (NMF) in the face of different types of noise. Specifically, we
adopt three different NMF algorithms, namely L1 NMF, L2 NMF, and L21 NMF, and
use the ORL and YaleB data sets to simulate a series of experiments with
salt-and-pepper noise and Block-occlusion noise separately. In the experiment,
we use a variety of evaluation indicators, including root mean square error
(RMSE), accuracy (ACC), and normalized mutual information (NMI), to evaluate
the performance of different NMF algorithms in noisy environments. Through
these indicators, we quantify the resistance of NMF algorithms to noise and
gain insights into their feasibility in practical applications.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01358" title="Abstract">arXiv:2312.01358</a> [<a href="/pdf/2312.01358" title="Download PDF">pdf</a>, <a href="/ps/2312.01358" title="Download PostScript">ps</a>, <a href="/format/2312.01358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formations organization in robotic swarm using the thermal motion  equivalent method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heiss%2C+E">Eduard Heiss</a>, 
<a href="/search/cs?searchtype=author&query=Kozyr%2C+A">Andrey Kozyr</a>, 
<a href="/search/cs?searchtype=author&query=Morozov%2C+O">Oleg Morozov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages with 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Due to its decentralised, distributed and scalable nature, swarm robotics has
great potential for applications ranging from agriculture to environmental
monitoring and logistics. Various swarm control methods and algorithms are
currently known, such as virtual leader, vector and potential field, and
others. Such methods often show good results in specific conditions and tasks.
The variety of tasks solved by the swarm requires the development of a
universal control algorithm. In this paper, we propose an evolution of a
thermal motion equivalent method (TMEM) inspired by the behavioural similarity
of thermodynamic interactions between molecules. Previous research has shown
the high efficiency of such a method for terrain monitoring tasks. This work
addresses the problem of swarm formation of geometric structures, as required
for logistics and formation movement tasks. It is shown that the formation of
swarm geometric structures using the TMEM is possible with a special nonlinear
interaction function of the agents. A piecewise linear interaction function is
proposed that allows the formation of a stable group of agents. The results of
the paper are validated by numerical modelling of the swarm dynamics. A linear
quadrocopter model is considered as an agent. The fairness of the choice of the
interaction function is shown.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01359" title="Abstract">arXiv:2312.01359</a> [<a href="/pdf/2312.01359" title="Download PDF">pdf</a>, <a href="/ps/2312.01359" title="Download PostScript">ps</a>, <a href="/format/2312.01359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> r-indexing without backward searching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+O">Omar Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Bal%C3%A1%C5%BE%2C+A">Andrej Bal&#xe1;&#x17e;</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+N+K">Nathaniel K. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Depuydt%2C+L">Lore Depuydt</a>, 
<a href="/search/cs?searchtype=author&query=Goga%2C+A">Adri&#xe1;n Goga</a>, 
<a href="/search/cs?searchtype=author&query=Petescia%2C+A">Alessia Petescia</a>, 
<a href="/search/cs?searchtype=author&query=Zakeri%2C+M">Mohsen Zakeri</a>, 
<a href="/search/cs?searchtype=author&query=Fostier%2C+J">Jan Fostier</a>, 
<a href="/search/cs?searchtype=author&query=Gagie%2C+T">Travis Gagie</a>, 
<a href="/search/cs?searchtype=author&query=Langmead%2C+B">Ben Langmead</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Prezza%2C+N">Nicola Prezza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Suppose we are given a text $T$ of length $n$ and a straight-line program for
$T$ with $g$ rules. Let $\bar{r}$ be the number of runs in the Burrows-Wheeler
Transform of the reverse of $T$. We can index $T$ in $O (\bar{r} + g)$ space
such that, given a pattern $P$ and constant-time access to the Karp-Rabin
hashes of the substrings of $P$ and the reverse of $P$, we can find the maximal
exact matches of $P$ with respect to $T$ correctly with high probability and
using $O (\log n)$ time for each edge we would descend in the suffix tree of
$T$ while finding those matches.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01361" title="Abstract">arXiv:2312.01361</a> [<a href="/pdf/2312.01361" title="Download PDF">pdf</a>, <a href="/format/2312.01361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoEC: Mixture of Experts Implicit Neural Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+C">Cheng-Ching Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+R">Ruichuan An</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaobao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">He Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Emerging Implicit Neural Representation (INR) is a promising data compression
technique, which represents the data using the parameters of a Deep Neural
Network (DNN). Existing methods manually partition a complex scene into local
regions and overfit the INRs into those regions. However, manually designing
the partition scheme for a complex scene is very challenging and fails to
jointly learn the partition and INRs. To solve the problem, we propose MoEC, a
novel implicit neural compression method based on the theory of mixture of
experts. Specifically, we use a gating network to automatically assign a
specific INR to a 3D point in the scene. The gating network is trained jointly
with the INRs of different local regions. Compared with block-wise and
tree-structured partitions, our learnable partition can adaptively find the
optimal partition in an end-to-end manner. We conduct detailed experiments on
massive and diverse biomedical data to demonstrate the advantages of MoEC
against existing approaches. In most of experiment settings, we have achieved
state-of-the-art results. Especially in cases of extreme compression ratios,
such as 6000x, we are able to uphold the PSNR of 48.16.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01364" title="Abstract">arXiv:2312.01364</a> [<a href="/pdf/2312.01364" title="Download PDF">pdf</a>, <a href="/format/2312.01364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tradeoff of age-of-information and power under reliability constraint  for short-packet communication with block-length adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K.%2C+S+A">Sudarsanan A. K.</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+V+B">Vineeth B. S.</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+C+R">Chandra R. Murthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In applications such as remote estimation and monitoring, update packets are
transmitted by power-constrained devices using short-packet codes over wireless
networks. Therefore, networks need to be end-to-end optimized using information
freshness metrics such as age of information under transmit power and
reliability constraints to ensure support for such applications. For
short-packet coding, modelling and understanding the effect of block codeword
length on transmit power and other performance metrics is important. To
understand the above optimization for short-packet coding, we consider the
optimal tradeoff problem between age of information and transmit power under
reliability constraints for short packet point-to-point communication model
with an exogenous packet generation process. In contrast to prior work, we
consider scheduling policies that can possibly adapt the block-length or
transmission time of short packet codes in order to achieve the optimal
tradeoff. We characterize the tradeoff using a semi-Markov decision process
formulation. We also obtain analytical upper bounds as well as numerical,
analytical, and asymptotic lower bounds on the optimal tradeoff. We show that
in certain regimes, such as high reliability and high packet generation rate,
non-adaptive scheduling policies (fixed transmission time policies) are
close-to-optimal. Furthermore, in a high-power or in a low-power regime,
non-adaptive as well as state-independent randomized scheduling policies are
order-optimal. These results are corroborated by numerical and simulation
experiments. The tradeoff is then characterized for a wireless point-to-point
channel with block fading as well as for other packet generation models
(including an age-dependent packet generation model).
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01367" title="Abstract">arXiv:2312.01367</a> [<a href="/pdf/2312.01367" title="Download PDF">pdf</a>, <a href="/format/2312.01367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiFace: Cross-Modal Face Recognition through Controlled Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bowen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shibao Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion probabilistic models (DPMs) have exhibited exceptional proficiency
in generating visual media of outstanding quality and realism. Nonetheless,
their potential in non-generative domains, such as face recognition, has yet to
be thoroughly investigated. Meanwhile, despite the extensive development of
multi-modal face recognition methods, their emphasis has predominantly centered
on visual modalities. In this context, face recognition through textual
description presents a unique and promising solution that not only transcends
the limitations from application scenarios but also expands the potential for
research in the field of cross-modal face recognition. It is regrettable that
this avenue remains unexplored and underutilized, a consequence from the
challenges mainly associated with three aspects: 1) the intrinsic imprecision
of verbal descriptions; 2) the significant gaps between texts and images; and
3) the immense hurdle posed by insufficient databases.To tackle this problem,
we present DiFace, a solution that effectively achieves face recognition via
text through a controllable diffusion process, by establishing its theoretical
connection with probability transport. Our approach not only unleashes the
potential of DPMs across a broader spectrum of tasks but also achieves, to the
best of our knowledge, a significant accuracy in text-to-image face recognition
for the first time, as demonstrated by our experiments on verification and
identification.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01370" title="Abstract">arXiv:2312.01370</a> [<a href="/pdf/2312.01370" title="Download PDF">pdf</a>, <a href="/ps/2312.01370" title="Download PostScript">ps</a>, <a href="/format/2312.01370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A $W$-weighted generalization of $\{1,2,3,1^{k}\}$-inverse for  rectangular matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chowdhry%2C+G">Geeta Chowdhry</a>, 
<a href="/search/math?searchtype=author&query=Roy%2C+F">Falguni Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a novel extension of the $\{1,2,3,1^{k}\}$-inverse
concept to complex rectangular matrices, denoted as a $W$-weighted
$\{1,2,3,1^{k}\}$-inverse (or $\{1',2',3',{1^{k}}'\}$-inverse), where the
weight $W \in \mathbb{C}^{n \times m}$. The study begins by introducing a
weighted $\{1,2,3\}$-inverse (or $\{1',2',3'\}$-inverse) along with its
representations and characterizations. The paper establishes criteria for the
existence of $\{1',2',3'\}$-inverses and extends the criteria to
$\{1'\}$-inverses. It is further demonstrated that $A\in \mathbb{C}^{m \times
n}$ admits a $\{1',2',3',{1^{k}}'\}$-inverse if and only if $r(WAW)=r(A)$,
where $r(\cdot)$ is the rank of a matrix. The work additionally establishes
various representations for the set $A\{ 1',2',3',{1^{k}}'\}$, including
canonical representations derived through singular value and core-nilpotent
decompositions. This, in turn, yields distinctive canonical representations for
the set $A\{ 1,2,3,{1^{k}}\}$. $\{ 1',2',3',{1^{k}}'\}$-inverse is shown to be
unique if and only if it has index $0$ or $1$, reducing it to the weighted core
inverse. Moreover, the paper investigates properties and characterizations of
$\{1',2',3',{1^{k}}'\}$-inverses, which then results in new insights into the
characterizations of the set $A\{ 1,2,3,{1^{k}}\}$.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01381" title="Abstract">arXiv:2312.01381</a> [<a href="/pdf/2312.01381" title="Download PDF">pdf</a>, <a href="/format/2312.01381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-driven All-in-one Adverse Weather Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wei Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">All-in-one (AiO) frameworks restore various adverse weather degradations with
a single set of networks jointly. To handle various weather conditions, an AiO
framework is expected to adaptively learn weather-specific knowledge for
different degradations and shared knowledge for common patterns. However,
existing methods: 1) rely on extra supervision signals, which are usually
unknown in real-world applications; 2) employ fixed network structures, which
restrict the diversity of weather-specific knowledge. In this paper, we propose
a Language-driven Restoration framework (LDR) to alleviate the aforementioned
issues. First, we leverage the power of pre-trained vision-language (PVL)
models to enrich the diversity of weather-specific knowledge by reasoning about
the occurrence, type, and severity of degradation, generating description-based
degradation priors. Then, with the guidance of degradation prior, we sparsely
select restoration experts from a candidate list dynamically based on a
Mixture-of-Experts (MoE) structure. This enables us to adaptively learn the
weather-specific and shared knowledge to handle various weather conditions
(e.g., unknown or mixed weather). Experiments on extensive restoration
scenarios show our superior performance (see Fig. 1). The source code will be
made available.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01384" title="Abstract">arXiv:2312.01384</a> [<a href="/pdf/2312.01384" title="Download PDF">pdf</a>, <a href="/format/2312.01384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tight Lower Bound for 3-Coloring Grids in the Online-LOCAL Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi-Jun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+G">Gopinath Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thuan Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yu-Cheng Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recently, Akbari, Eslami, Lievonen, Melnyk, S\"{a}rkij\"{a}rvi, and Suomela
(ICALP 2023) studied the locality of graph problems in distributed, sequential,
dynamic, and online settings from a unified point of view. They designed a
novel $O(\log n)$-locality algorithm for proper 3-coloring bipartite graphs in
the $\mathsf{Online}$-$\mathsf{LOCAL}$ model. In this work, we show the
optimality of the algorithm by demonstrating a tight $\Omega(\log n)$ locality
lower bound which holds even on grids. Moreover, we show a higher
$\Omega(\sqrt{n})$ lower bound for 3-coloring toroidal and cylindrical grids.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01386" title="Abstract">arXiv:2312.01386</a> [<a href="/pdf/2312.01386" title="Download PDF">pdf</a>, <a href="/ps/2312.01386" title="Download PostScript">ps</a>, <a href="/format/2312.01386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Optimality of GP-UCB
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Lu Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Gaussian Process Upper Confidence Bound (GP-UCB) is one of the most popular
methods for optimizing black-box functions with noisy observations, due to its
simple structure and superior performance. Its empirical successes lead to a
natural, yet unresolved question: Is GP-UCB regret optimal? In this paper, we
offer the first generally affirmative answer to this important open question in
the Bayesian optimization literature. We establish new upper bounds on both the
simple and cumulative regret of GP-UCB when the objective function to optimize
admits certain smoothness property. These upper bounds match the known minimax
lower bounds (up to logarithmic factors independent of the feasible region's
dimensionality) for optimizing functions with the same smoothness.
Intriguingly, our findings indicate that, with the same level of exploration,
GP-UCB can simultaneously achieve optimality in both simple and cumulative
regret. The crux of our analysis hinges on a refined uniform error bound for
online estimation of functions in reproducing kernel Hilbert spaces. This error
bound, which we derive from empirical process theory, is of independent
interest, and its potential applications may reach beyond the scope of this
study.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01391" title="Abstract">arXiv:2312.01391</a> [<a href="/pdf/2312.01391" title="Download PDF">pdf</a>, <a href="/ps/2312.01391" title="Download PostScript">ps</a>, <a href="/format/2312.01391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moderate Dimension Reduction for $k$-Center Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S+H+-">Shaofeng H.-C. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Krauthgamer%2C+R">Robert Krauthgamer</a>, 
<a href="/search/cs?searchtype=author&query=Sapir%2C+S">Shay Sapir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The Johnson-Lindenstrauss (JL) Lemma introduced the concept of dimension
reduction via a random linear map, which has become a fundamental technique in
many computational settings. For a set of $n$ points in $\mathbb{R}^d$ and any
fixed $\epsilon&gt;0$, it reduces the dimension $d$ to $O(\log n)$ while
preserving, with high probability, all the pairwise Euclidean distances within
factor $1+\epsilon$. Perhaps surprisingly, the target dimension can be lower if
one only wishes to preserve the optimal value of a certain problem, e.g.,
max-cut or $k$-means. However, for some notorious problems, like diameter (aka
furthest pair), dimension reduction via the JL map to below $O(\log n)$ does
not preserve the optimal value within factor $1+\epsilon$.
<br />We propose to focus on another regime, of \emph{moderate dimension
reduction}, where a problem's value is preserved within factor $\alpha=O(1)$
(or even larger) using target dimension $\log n / \mathrm{poly}(\alpha)$. We
establish the viability of this approach and show that the famous $k$-center
problem is $\alpha$-approximated when reducing to dimension $O(\tfrac{\log
n}{\alpha^2}+\log k)$. Along the way, we address the diameter problem via the
special case $k=1$. Our result extends to several important variants of
$k$-center (with outliers, capacities, or fairness constraints), and the bound
improves further with the input's doubling dimension.
<br />While our $poly(\alpha)$-factor improvement in the dimension may seem small,
it actually has significant implications for streaming algorithms, and easily
yields an algorithm for $k$-center in dynamic geometric streams, that achieves
$O(\alpha)$-approximation using space $\mathrm{poly}(kdn^{1/\alpha^2})$. This
is the first algorithm to beat $O(n)$ space in high dimension $d$, as all
previous algorithms require space at least $\exp(d)$. Furthermore, it extends
to the $k$-center variants mentioned above.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01392" title="Abstract">arXiv:2312.01392</a> [<a href="/pdf/2312.01392" title="Download PDF">pdf</a>, <a href="/ps/2312.01392" title="Download PostScript">ps</a>, <a href="/format/2312.01392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Characterization and Entropy Regulated Data Balancing  through Principal Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yevick%2C+D">David Yevick</a>, 
<a href="/search/cs?searchtype=author&query=Hutchison%2C+K">Karolina Hutchison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper examines the relationship between the behavior of a neural network
and the distribution formed from the projections of the data records into the
space spanned by the low-order principal components of the training data. For
example, in a benchmark calculation involving rotated and unrotated MNIST
digits, classes (digits) that are mapped far from the origin in a
low-dimensional principal component space and that overlap minimally with other
digits converge rapidly and exhibit high degrees of accuracy in neural network
calculations that employ the associated components of each data record as
inputs. Further, if the space spanned by these low-order principal components
is divided into bins and the input data records that are mapped into a given
bin averaged, the resulting pattern can be distinguished by its geometric
features which interpolate between those of adjacent bins in an analogous
manner to variational autoencoders. Based on this observation, a simply
realized data balancing procedure can be realized by evaluating the entropy
associated with each histogram bin and subsequently repeating the original
image data associated with the bin by a number of times that is determined from
this entropy.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01394" title="Abstract">arXiv:2312.01394</a> [<a href="/pdf/2312.01394" title="Download PDF">pdf</a>, <a href="/ps/2312.01394" title="Download PostScript">ps</a>, <a href="/format/2312.01394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiders&#x27; Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+G">Gleb Polevoy</a>, 
<a href="/search/cs?searchtype=author&query=Michalak%2C+T">Tomasz Michalak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Consider spies infiltrating a network or dissidents secretly organising under
a dictatorship. Such scenarios can be cast as adversarial social network
analysis problems involving nodes connecting while evading network analysis
tools, e.g., centrality measures or community detection algorithms. While most
works consider unilateral actions of an evader, we define a network formation
game. Here, several newcomers attempt to rewire the existing social network, to
become directly tied with the high centrality players, while keeping their own
centrality small. This extends the network formation literature, including the
Jackson and Wolinsky model, by considering additional strategies and new
utility functions. We algorithmically demonstrate that the pairwise Nash stable
networks (\PANS) constitute a lattice, where the stronger \PANS{} lattice is
nested in the weaker \PANS. We also prove that inclusion in \PANS{} implies
less utility for everyone. Furthermore, we bound the social efficiency of
\PANS{} and directly connect efficiency to the strength of \PANS. Finally, we
characterise the \PANS{} in practically important settings, deriving tight
efficiency bounds. Our results suggest the hiders how to interconnect stably
and efficiently. Additionally, the results let us detect infiltrated networks,
enhancing the social network analysis tools. Besides the theoretical
development, this is applicable to fighting terrorism and espionage.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01397" title="Abstract">arXiv:2312.01397</a> [<a href="/pdf/2312.01397" title="Download PDF">pdf</a>, <a href="/format/2312.01397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Prompting Upgrades Neural Network Sparsification: A Data-Model  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Can Jin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under conference review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid development of large-scale deep learning models questions the
affordability of hardware platforms, which necessitates the pruning to reduce
their computational and memory footprints. Sparse neural networks as the
product, have demonstrated numerous favorable benefits like low complexity,
undamaged generalization, etc. Most of the prominent pruning strategies are
invented from a model-centric perspective, focusing on searching and preserving
crucial weights by analyzing network topologies. However, the role of data and
its interplay with model-centric pruning has remained relatively unexplored. In
this research, we introduce a novel data-model co-design perspective: to
promote superior weight sparsity by learning important model topology and
adequate input data in a synergetic manner. Specifically, customized Visual
Prompts are mounted to upgrade neural Network sparsification in our proposed
VPNs framework. As a pioneering effort, this paper conducts systematic
investigations about the impact of different visual prompts on model pruning
and suggests an effective joint optimization approach. Extensive experiments
with 3 network architectures and 8 datasets evidence the substantial
performance improvements from VPNs over existing start-of-the-art pruning
algorithms. Furthermore, we find that subnetworks discovered by VPNs from
pre-trained models enjoy better transferability across diverse downstream
scenarios. These insights shed light on new promising possibilities of
data-model co-designs for vision model sparsification.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01398" title="Abstract">arXiv:2312.01398</a> [<a href="/pdf/2312.01398" title="Download PDF">pdf</a>, <a href="/format/2312.01398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal  Stakeholder&#x27;s Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+A">Anmol Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Anish%2C+P+R">Preethu Rose Anish</a>, 
<a href="/search/cs?searchtype=author&query=Karande%2C+S">Shirish Karande</a>, 
<a href="/search/cs?searchtype=author&query=Ghaisas%2C+S">Smita Ghaisas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, to be published in Natural Legal Language Processing Workshop at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Commercial contracts are known to be a valuable source for deriving
project-specific requirements. However, contract negotiations mainly occur
among the legal counsel of the parties involved. The participation of non-legal
stakeholders, including requirement analysts, engineers, and solution
architects, whose primary responsibility lies in ensuring the seamless
implementation of contractual terms, is often indirect and inadequate.
Consequently, a significant number of sentences in contractual clauses, though
legally accurate, can appear unfair from an implementation perspective to
non-legal stakeholders. This perception poses a problem since requirements
indicated in the clauses are obligatory and can involve punitive measures and
penalties if not implemented as committed in the contract. Therefore, the
identification of potentially unfair clauses in contracts becomes crucial. In
this work, we conduct an empirical study to analyze the perspectives of
different stakeholders regarding contractual fairness. We then investigate the
ability of Pre-trained Language Models (PLMs) to identify unfairness in
contractual sentences by comparing chain of thought prompting and
semi-supervised fine-tuning approaches. Using BERT-based fine-tuning, we
achieved an accuracy of 84% on a dataset consisting of proprietary contracts.
It outperformed chain of thought prompting using Vicuna-13B by a margin of 9%.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01403" title="Abstract">arXiv:2312.01403</a> [<a href="/pdf/2312.01403" title="Download PDF">pdf</a>, <a href="/format/2312.01403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OplixNet: Towards Area-Efficient Optical Split-Complex Networks with  Real-to-Complex Data Assignment and Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiu%2C+R">Ruidi Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Eldebiky%2C+A">Amro Eldebiky</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>, 
<a href="/search/eess?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/eess?searchtype=author&query=Schlichtmann%2C+U">Ulf Schlichtmann</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Having the potential for high speed, high throughput, and low energy cost,
optical neural networks (ONNs) have emerged as a promising candidate for
accelerating deep learning tasks. In conventional ONNs, light amplitudes are
modulated at the input and detected at the output. However, the light phases
are still ignored in conventional structures, although they can also carry
information for computing. To address this issue, in this paper, we propose a
framework called OplixNet to compress the areas of ONNs by modulating input
image data into the amplitudes and phase parts of light signals. The input and
output parts of the ONNs are redesigned to make full use of both amplitude and
phase information. Moreover, mutual learning across different ONN structures is
introduced to maintain the accuracy. Experimental results demonstrate that the
proposed framework significantly reduces the areas of ONNs with the accuracy
within an acceptable range. For instance, 75.03% area is reduced with a 0.33%
accuracy decrease on fully connected neural network (FCNN) and 74.88% area is
reduced with a 2.38% accuracy decrease on ResNet-32.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01407" title="Abstract">arXiv:2312.01407</a> [<a href="/pdf/2312.01407" title="Download PDF">pdf</a>, <a href="/format/2312.01407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoRF: Rendering Dynamic Radiance Fields as 2D Feature Video Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kaixin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chengcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minye Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page, see <a href="https://aoliao12138.github.io/VideoRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) excel in photorealistically rendering static
scenes. However, rendering dynamic, long-duration radiance fields on ubiquitous
devices remains challenging, due to data storage and computational constraints.
In this paper, we introduce VideoRF, the first approach to enable real-time
streaming and rendering of dynamic radiance fields on mobile platforms. At the
core is a serialized 2D feature image stream representing the 4D radiance field
all in one. We introduce a tailored training scheme directly applied to this 2D
domain to impose the temporal and spatial redundancy of the feature image
stream. By leveraging the redundancy, we show that the feature image stream can
be efficiently compressed by 2D video codecs, which allows us to exploit video
hardware accelerators to achieve real-time decoding. On the other hand, based
on the feature image stream, we propose a novel rendering pipeline for VideoRF,
which has specialized space mappings to query radiance properties efficiently.
Paired with a deferred shading model, VideoRF has the capability of real-time
rendering on mobile devices thanks to its efficiency. We have developed a
real-time interactive player that enables online streaming and rendering of
dynamic scenes, offering a seamless and immersive free-viewpoint experience
across a range of devices, from desktops to mobile phones.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01408" title="Abstract">arXiv:2312.01408</a> [<a href="/pdf/2312.01408" title="Download PDF">pdf</a>, <a href="/format/2312.01408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving In-Context Learning in Diffusion Models with Visual  Context-Modulated Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhendong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In light of the remarkable success of in-context learning in large language
models, its potential extension to the vision domain, particularly with visual
foundation models like Stable Diffusion, has sparked considerable interest.
Existing approaches in visual in-context learning frequently face hurdles such
as expensive pretraining, limiting frameworks, inadequate visual comprehension,
and limited adaptability to new tasks. In response to these challenges, we
introduce improved Prompt Diffusion (iPromptDiff) in this study. iPromptDiff
integrates an end-to-end trained vision encoder that converts visual context
into an embedding vector. This vector is subsequently used to modulate the
token embeddings of text prompts. We show that a diffusion-based vision
foundation model, when equipped with this visual context-modulated text
guidance and a standard ControlNet structure, exhibits versatility and
robustness across a variety of training tasks and excels in in-context learning
for novel vision tasks, such as normal-to-image or image-to-line
transformations. The effectiveness of these capabilities relies heavily on a
deep visual understanding, which is achieved through relevant visual
demonstrations processed by our proposed in-context learning architecture.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01409" title="Abstract">arXiv:2312.01409</a> [<a href="/pdf/2312.01409" title="Download PDF">pdf</a>, <a href="/format/2312.01409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Rendering: Controllable 4D-Guided Video Generation with 2D  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shengqu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ceylan%2C+D">Duygu Ceylan</a>, 
<a href="/search/cs?searchtype=author&query=Gadelha%2C+M">Matheus Gadelha</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C+P">Chun-Hao Paul Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+Y">Tuanfeng Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://primecai.github.io/generative_rendering/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Traditional 3D content creation tools empower users to bring their
imagination to life by giving them direct control over a scene's geometry,
appearance, motion, and camera path. Creating computer-generated videos,
however, is a tedious manual process, which can be automated by emerging
text-to-video diffusion models. Despite great promise, video diffusion models
are difficult to control, hindering a user to apply their own creativity rather
than amplifying it. To address this challenge, we present a novel approach that
combines the controllability of dynamic 3D meshes with the expressivity and
editability of emerging diffusion models. For this purpose, our approach takes
an animated, low-fidelity rendered mesh as input and injects the ground truth
correspondence information obtained from the dynamic mesh into various stages
of a pre-trained text-to-image generation model to output high-quality and
temporally consistent frames. We demonstrate our approach on various examples
where motion can be obtained by animating rigged assets or changing the camera
path.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01419" title="Abstract">arXiv:2312.01419</a> [<a href="/pdf/2312.01419" title="Download PDF">pdf</a>, <a href="/format/2312.01419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding and counting small tournaments in large tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuster%2C+R">Raphael Yuster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We present new algorithms for counting and detecting small tournaments in a
given tournament. In particular, it is proved that every tournament on four
vertices (there are four) can be detected in $O(n^2)$ time and counted in
$O(n^\omega)$ time where $\omega &lt; 2.373$ is the matrix multiplication
exponent. It is also proved that any tournament on five vertices (there are
$12$) can be counted in $O(n^{\omega+1})$ time. As for lower-bounds, we prove
that for almost all $k$-vertex tournaments, the complexity of the detection
problem is not easier than the complexity of the corresponding well-studied
counting problem for {\em undirected cliques} of order $k-O(\log k)$.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01421" title="Abstract">arXiv:2312.01421</a> [<a href="/pdf/2312.01421" title="Download PDF">pdf</a>, <a href="/format/2312.01421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobotGPT: Robot Manipulation Learning from ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yixiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dingzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=A%2C+Y">Yong A</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+P">Peng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bin Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present RobotGPT, an innovative decision framework for robotic
manipulation that prioritizes stability and safety. The execution code
generated by ChatGPT cannot guarantee the stability and safety of the system.
ChatGPT may provide different answers for the same task, leading to
unpredictability. This instability prevents the direct integration of ChatGPT
into the robot manipulation loop. Although setting the temperature to 0 can
generate more consistent outputs, it may cause ChatGPT to lose diversity and
creativity. Our objective is to leverage ChatGPT's problem-solving capabilities
in robot manipulation and train a reliable agent. The framework includes an
effective prompt structure and a robust learning model. Additionally, we
introduce a metric for measuring task difficulty to evaluate ChatGPT's
performance in robot manipulation. Furthermore, we evaluate RobotGPT in both
simulation and real-world environments. Compared to directly using ChatGPT to
generate code, our framework significantly improves task success rates, with an
average increase from 38.5% to 91.5%. Therefore, training a RobotGPT by
utilizing ChatGPT as an expert is a more stable approach compared to directly
using ChatGPT as a task planner.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01424" title="Abstract">arXiv:2312.01424</a> [<a href="/pdf/2312.01424" title="Download PDF">pdf</a>, <a href="/format/2312.01424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+K">Kongzhang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Long Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Hop-constrained s-t simple path (HC-s-t path) enumeration is a fundamental
problem in graph analysis. Existing solutions for this problem focus on
optimizing the processing performance of a single query. However, in practice,
it is more often that multiple HC-s-t path queries are issued simultaneously
and processed as a batch. Therefore, we study the problem of batch HC-s-t path
query processing in this paper and aim to compute the results of all queries
concurrently and efficiently as a batch. To achieve this goal, we first propose
the concept of HC-s path query which can precisely characterize the common
computation among different queries.We then devise a two-phase HC-s path query
detection algorithm to identify the common HC-s path queries for the given
HC-s-t path queries. Based on the detected HC-s path queries, we further devise
an efficient HC-s-t path enumeration algorithm in which the common computation
represented by HC-s path queries are effectively shared. We conduct extensive
experiments on real-world graphs and the experimental results demonstrate that
our proposed algorithm is efficient and scalable regarding processing multiple
HC-s-t path queries in large graphs at billion-scale.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01429" title="Abstract">arXiv:2312.01429</a> [<a href="/pdf/2312.01429" title="Download PDF">pdf</a>, <a href="/format/2312.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers are uninterpretable with myopic methods: a case study with  bounded Dyck grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kaiyue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Risteski%2C+A">Andrej Risteski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Interpretability methods aim to understand the algorithm implemented by a
trained model (e.g., a Transofmer) by examining various aspects of the model,
such as the weight matrices or the attention patterns. In this work, through a
combination of theoretical results and carefully controlled experiments on
synthetic data, we take a critical view of methods that exclusively focus on
individual parts of the model, rather than consider the network as a whole. We
consider a simple synthetic setup of learning a (bounded) Dyck language.
Theoretically, we show that the set of models that (exactly or approximately)
solve this task satisfy a structural characterization derived from ideas in
formal languages (the pumping lemma). We use this characterization to show that
the set of optima is qualitatively rich; in particular, the attention pattern
of a single layer can be ``nearly randomized'', while preserving the
functionality of the network. We also show via extensive experiments that these
constructions are not merely a theoretical artifact: even after severely
constraining the architecture of the model, vastly different solutions can be
reached via standard training. Thus, interpretability claims based on
inspecting individual heads or weight matrices in the Transformer can be
misleading.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01431" title="Abstract">arXiv:2312.01431</a> [<a href="/pdf/2312.01431" title="Download PDF">pdf</a>, <a href="/format/2312.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for  Few-shot Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+W">Wenjie Pei</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qizhong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiandong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adapting large pre-trained image models to few-shot action recognition has
proven to be an effective and efficient strategy for learning robust feature
extractors, which is essential for few-shot learning. Typical fine-tuning based
adaptation paradigm is prone to overfitting in the few-shot learning scenarios
and offers little modeling flexibility for learning temporal features in video
data. In this work we present the Disentangled-and-Deformable Spatio-Temporal
Adapter (D$^2$ST-Adapter), a novel adapter tuning framework for few-shot action
recognition, which is designed in a dual-pathway architecture to encode spatial
and temporal features in a disentangled manner. Furthermore, we devise the
Deformable Spatio-Temporal Attention module as the core component of
D$^2$ST-Adapter, which can be tailored to model both spatial and temporal
features in corresponding pathways, allowing our D$^2$ST-Adapter to encode
features in a global view in 3D spatio-temporal space while maintaining a
lightweight design. Extensive experiments with instantiations of our method on
both pre-trained ResNet and ViT demonstrate the superiority of our method over
state-of-the-art methods for few-shot action recognition. Our method is
particularly well-suited to challenging scenarios where temporal dynamics are
critical for action recognition.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01432" title="Abstract">arXiv:2312.01432</a> [<a href="/pdf/2312.01432" title="Download PDF">pdf</a>, <a href="/format/2312.01432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Dual Subgradient Optimization of the Integrated Transportation  Distance Between Stochastic Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhengqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ruszczynski%2C+A">Andrzej Ruszczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">A generalization of the Wasserstein metric, the integrated transportation
distance, establishes a novel distance between probability kernels of Markov
systems. This metric serves as the foundation for an efficient approximation
technique, enabling the replacement of the original system's kernel with a
kernel with a discrete support of limited cardinality. To facilitate practical
implementation, we present a specialized dual algorithm capable of constructing
these approximate kernels quickly and efficiently, without requiring
computationally expensive matrix operations. Finally, we demonstrate the
efficacy of our method through several illustrative examples, showcasing its
utility in practical scenarios. This advancement offers new possibilities for
the streamlined analysis and manipulation of stochastic systems represented by
kernels.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01434" title="Abstract">arXiv:2312.01434</a> [<a href="/pdf/2312.01434" title="Download PDF">pdf</a>, <a href="/ps/2312.01434" title="Download PostScript">ps</a>, <a href="/format/2312.01434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A connection between the boomerang uniformity and the extended  differential in odd characteristic and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+M">Mohit Pal</a>, 
<a href="/search/cs?searchtype=author&query=Stanica%2C+P">Pantelimon Stanica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Number Theory (math.NT)

</div>
<p class="mathjax">This paper makes the first bridge between the classical
differential/boomerang uniformity and the newly introduced $c$-differential
uniformity. We show that the boomerang uniformity of an odd APN function is
given by the maximum of the entries (except for the first row/column) of the
function's $(-1)$-Difference Distribution Table. In fact, the boomerang
uniformity of an odd permutation APN function equals its $(-1)$-differential
uniformity. We next apply this result to easily compute the boomerang
uniformity of several odd APN functions. In the second part we give two classes
of differentially low-uniform functions obtained by modifying the inverse
function. The first class of permutations (CCZ-inequivalent to the inverse)
over a finite field $\mathbb{F}_{p^n}$ ($p$, an odd prime) is obtained from the
composition of the inverse function with an order-$3$ cycle permutation, with
differential uniformity $3$ if $p=3$ and $n$ is odd; $5$ if $p=13$ and $n$ is
even; and $4$ otherwise. The second class is a family of binomials and we show
that their differential uniformity equals~$4$. We next complete the open case
of $p=3$ in the investigation started by G\" olo\u glu and McGuire (2014), for
$p\geq 5$, and continued by K\"olsch (2021), for $p=2$, $n\geq 5$, on the
characterization of $L_1(X^{p^n-2})+L_2(X)$ (with linearized $L_1,L_2$) being a
permutation polynomial. Finally, we extend to odd characteristic a result of
Charpin and Kyureghyan (2010) providing an upper bound for the differential
uniformity of the function and its switched version via a trace function.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01435" title="Abstract">arXiv:2312.01435</a> [<a href="/pdf/2312.01435" title="Download PDF">pdf</a>, <a href="/format/2312.01435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Report Generation for Histopathology images using pre-trained  Vision Transformers and BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Saurav Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D+E">Donald E. Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning for histopathology has been successfully used for disease
classification, image segmentation and more. However, combining image and text
modalities using current state-of-the-art methods has been a challenge due to
the high resolution of histopathology images. Automatic report generation for
histopathology images is one such challenge. In this work, we show that using
an existing pre-trained Vision Transformer in a two-step process of first using
it to encode 4096x4096 sized patches of the Whole Slide Image (WSI) and then
using it as the encoder and a pre-trained Bidirectional Encoder Representations
from Transformers (BERT) model for language modeling-based decoder for report
generation, we can build a fairly performant and portable report generation
mechanism that takes into account the whole of the high resolution image,
instead of just the patches. Our method allows us to not only generate and
evaluate captions that describe the image, but also helps us classify the image
into tissue types and the gender of the patient as well. Our best performing
model achieves a 79.98% accuracy in Tissue Type classification and 66.36%
accuracy in classifying the sex of the patient the tissue came from, with a
BLEU-4 score of 0.5818 in our caption generation task.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01436" title="Abstract">arXiv:2312.01436</a> [<a href="/pdf/2312.01436" title="Download PDF">pdf</a>, <a href="/format/2312.01436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Resource Partitioning Approach for ARINC 653 RTOS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheptsov%2C+V">Vitaly Cheptsov</a>, 
<a href="/search/cs?searchtype=author&query=Khoroshilov%2C+A">Alexey Khoroshilov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, submitted to Ivannikov ISP RAS Open Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">Modern airborne operating systems implement the concept of robust time and
resource partitioning imposed by the standards for aerospace and
airborne-embedded software systems, such as ARINC 653. While these standards do
provide a considerable amount of design choices in regards to resource
partitioning on the architectural and API levels, such as isolated memory
spaces between the application partitions, predefined resource configuration,
and unidirectional ports with limited queue and message sizes for
inter-partition communication, they do not specify how an operating system
should implement them in software. Furthermore, they often tend to set the
minimal level of the required guarantees, for example, in terms of memory
permissions, and disregard the hardware state of the art, which presently can
provide considerably stronger guarantees at no extra cost. In the paper we
present an architecture of robust resource partitioning for ARINC 653 real-time
operating systems based on completely static MMU configuration. The
architecture was implemented on different types of airborne hardware, including
platforms with TLB-based and page table-based MMU. Key benefits of the proposed
approach include minimised run-time overhead and simpler verification of the
memory subsystem.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01441" title="Abstract">arXiv:2312.01441</a> [<a href="/pdf/2312.01441" title="Download PDF">pdf</a>, <a href="/format/2312.01441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopman-based feedback design with stability guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Str%C3%A4sser%2C+R">Robin Str&#xe4;sser</a>, 
<a href="/search/eess?searchtype=author&query=Schaller%2C+M">Manuel Schaller</a>, 
<a href="/search/eess?searchtype=author&query=Worthmann%2C+K">Karl Worthmann</a>, 
<a href="/search/eess?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/eess?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present a method to design a state-feedback controller ensuring
exponential stability for nonlinear systems using only measurement data. Our
approach relies on Koopman operator theory and uses robust control to
explicitly account for approximation errors due to finitely many data samples.
To simplify practical usage across various applications, we provide a
tutorial-style exposition of the feedback design and its stability guarantees
for single-input systems. Moreover, we extend this controller design to
multi-input systems and more flexible nonlinear state-feedback controllers
using gain-scheduling techniques to increase the guaranteed region of
attraction. As the proposed controller design is framed as a semidefinite
program, it allows for an efficient solution. Finally, we validate the proposed
feedback design procedure by means of numerical examples.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01444" title="Abstract">arXiv:2312.01444</a> [<a href="/pdf/2312.01444" title="Download PDF">pdf</a>, <a href="/format/2312.01444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looking Inside Out: Anticipating Driver Intent From Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kung%2C+Y">Yung-chi Kung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Arthur Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junmin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Anticipating driver intention is an important task when vehicles of mixed and
varying levels of human/machine autonomy share roadways. Driver intention can
be leveraged to improve road safety, such as warning surrounding vehicles in
the event the driver is attempting a dangerous maneuver. In this work, we
propose a novel method of utilizing in-cabin and external camera data to
improve state-of-the-art (SOTA) performance in predicting future driver
actions. Compared to existing methods, our approach explicitly extracts object
and road-level features from external camera data, which we demonstrate are
important features for predicting driver intention. Using our handcrafted
features as inputs for both a transformer and an LSTM-based architecture, we
empirically show that jointly utilizing in-cabin and external features improves
performance compared to using in-cabin features alone. Furthermore, our models
predict driver maneuvers more accurately and earlier than existing approaches,
with an accuracy of 87.5% and an average prediction time of 4.35 seconds before
the maneuver takes place. We release our model configurations and training
scripts on https://github.com/ykung83/Driver-Intent-Prediction
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01445" title="Abstract">arXiv:2312.01445</a> [<a href="/pdf/2312.01445" title="Download PDF">pdf</a>, <a href="/format/2312.01445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Home Network Problems with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%B6tterl%2C+J">Jeremias D&#xf6;tterl</a>, 
<a href="/search/cs?searchtype=author&query=Fard%2C+Z+H">Zahra Hemmati Fard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been partially funded by the German Federal Ministry of Education and Research (BMBF) in the FRONT-RUNNER project (Grant 16KISR005K)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a classifier that can identify ten common home network problems
based on the raw textual output of networking tools such as ping, dig, and ip.
Our deep learning model uses an encoder-only transformer architecture with a
particular pre-tokenizer that we propose for splitting the tool output into
token sequences. The use of transformers distinguishes our approach from
related work on network problem classification, which still primarily relies on
non-deep-learning methods. Our model achieves high accuracy in our experiments,
demonstrating the high potential of transformer-based problem classification
for the home network.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01450" title="Abstract">arXiv:2312.01450</a> [<a href="/pdf/2312.01450" title="Download PDF">pdf</a>, <a href="/format/2312.01450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foveation in the Era of Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Killick%2C+G">George Killick</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+P">Paul Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Siebert%2C+P">Paul Siebert</a>, 
<a href="/search/cs?searchtype=author&query=Aragon-Camarasa%2C+G">Gerardo Aragon-Camarasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we tackle the challenge of actively attending to visual scenes
using a foveated sensor. We introduce an end-to-end differentiable foveated
active vision architecture that leverages a graph convolutional network to
process foveated images, and a simple yet effective formulation for foveated
image sampling. Our model learns to iteratively attend to regions of the image
relevant for classification. We conduct detailed experiments on a variety of
image datasets, comparing the performance of our method with previous
approaches to foveated vision while measuring how the impact of different
choices, such as the degree of foveation, and the number of fixations the
network performs, affect object recognition performance. We find that our model
outperforms a state-of-the-art CNN and foveated vision architectures of
comparable parameters and a given pixel or computation budget
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01454" title="Abstract">arXiv:2312.01454</a> [<a href="/pdf/2312.01454" title="Download PDF">pdf</a>, <a href="/format/2312.01454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-Bot: Database Diagnosis System using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuanhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiesi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruohang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guoyang Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Database administrators (DBAs) play an important role in managing,
maintaining and optimizing database systems. However, it is hard and tedious
for DBAs to manage a large number of databases and give timely response
(waiting for hours is intolerable in many online cases). In addition, existing
empirical methods only support limited diagnosis scenarios, which are also
labor-intensive to update the diagnosis rules for database version updates.
Recently large language models (LLMs) have shown great potential in various
fields. Thus, we propose D-Bot, an LLM-based database diagnosis system that can
automatically acquire knowledge from diagnosis documents, and generate
reasonable and well-founded diagnosis report (i.e., identifying the root causes
and solutions) within acceptable time (e.g., under 10 minutes compared to hours
by a DBA). The techniques in D-Bot include (i) offline knowledge extraction
from documents, (ii) automatic prompt generation (e.g., knowledge matching,
tool retrieval), (iii) root cause analysis using tree search algorithm, and
(iv) collaborative mechanism for complex anomalies with multiple root causes.
We verify D-Bot on real benchmarks (including 539 anomalies of six typical
applications), and the results show that D-Bot can effectively analyze the root
causes of unseen anomalies and significantly outperforms traditional methods
and vanilla models like GPT-4.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01455" title="Abstract">arXiv:2312.01455</a> [<a href="/pdf/2312.01455" title="Download PDF">pdf</a>, <a href="/format/2312.01455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 32-Bit RISC-V CPU Core on Logisim
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+S+D">Siddesh D. Patil</a>, 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+P+V">Premraj V. Jadhav</a>, 
<a href="/search/cs?searchtype=author&query=Sankhe%2C+S">Siddharth Sankhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">This project focuses on making a RISC-V CPU Core using the Logisim software.
RISC-V is significant because it will allow smaller device manufacturers to
build hardware without paying royalties and allow developers and researchers to
design and experiment with a proven and freely available instruction set
architecture. RISC-V is ideal for a variety of applications from IOTs to
Embedded systems such as disks, CPUs, Calculators, SOCs, etc. RISC-V(Reduced
Instruction Set Architecture) is an open standard instruction set architecture
(ISA) based on established reduced instruction set computer (RISC) principles.
Unlike most other ISA designs, the RISC-V ISA is provided under open source
licenses that do not require fees to use.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01456" title="Abstract">arXiv:2312.01456</a> [<a href="/pdf/2312.01456" title="Download PDF">pdf</a>, <a href="/format/2312.01456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Policy Learning in Stochastic Control Systems with Formal  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%BDikeli%C4%87%2C+%C4%90">&#x110;or&#x111;e &#x17d;ikeli&#x107;</a> (1), 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a> (2), 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Abhinav Verma</a> (3), 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+K">Krishnendu Chatterjee</a> (1), 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+T+A">Thomas A. Henzinger</a> (1) ((1) Institute of Science and Technology Austria, (2) Massachusetts Institute of Technology, (3) The Pennsylvania State University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning has shown promising results in learning neural network
policies for complicated control tasks. However, the lack of formal guarantees
about the behavior of such policies remains an impediment to their deployment.
We propose a novel method for learning a composition of neural network policies
in stochastic environments, along with a formal certificate which guarantees
that a specification over the policy's behavior is satisfied with the desired
probability. Unlike prior work on verifiable RL, our approach leverages the
compositional nature of logical specifications provided in SpectRL, to learn
over graphs of probabilistic reach-avoid specifications. The formal guarantees
are provided by learning neural network policies together with reach-avoid
supermartingales (RASM) for the graph's sub-tasks and then composing them into
a global policy. We also derive a tighter lower bound compared to previous work
on the probability of reach-avoidance implied by a RASM, which is required to
find a compositional policy with an acceptable probabilistic threshold for
complex tasks with multiple edge policies. We implement a prototype of our
approach and evaluate it on a Stochastic Nine Rooms environment.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01467" title="Abstract">arXiv:2312.01467</a> [<a href="/pdf/2312.01467" title="Download PDF">pdf</a>, <a href="/format/2312.01467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Dominating Set and Coloring for Geometric Intersection Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%2C+M">Minati De</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+S">Sambhav Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Satyam Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We present online deterministic algorithms for minimum coloring and minimum
dominating set problems in the context of geometric intersection graphs. We
consider a graph parameter: the independent kissing number $\zeta$, which is a
number equal to `the size of the largest induced star in the graph $-1$'. For a
graph with an independent kissing number at most $\zeta$, we show that the
famous greedy algorithm achieves an optimal competitive ratio of $\zeta$ for
the minimum dominating set and the minimum independent dominating set problems.
However, for the minimum connected dominating set problem, we obtain a
competitive ratio of at most $2\zeta$. To complement this, we prove that for
the minimum connected dominating set problem, any deterministic online
algorithm has a competitive ratio of at least $2(\zeta-1)$ for the geometric
intersection graph of translates of a convex object in $\mathbb{R}^2$. Next,
for the minimum coloring problem, we obtain algorithms having a competitive
ratio of $O\left({\zeta'}{\log m}\right)$ for geometric intersection graphs of
bounded scaled $\alpha$-fat objects in $\mathbb{R}^d$ having widths in the
interval $[1,m]$, where $\zeta'$ is the independent kissing number of the
geometric intersection graph of bounded scaled $\alpha$-fat objects having
widths in the interval $[1,2]$. Finally, we investigate the value of $\zeta$
for geometric intersection graphs of various families of geometric objects.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01468" title="Abstract">arXiv:2312.01468</a> [<a href="/pdf/2312.01468" title="Download PDF">pdf</a>, <a href="/format/2312.01468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Our study assesses the adversarial robustness of LiDAR-camera fusion models
in 3D object detection. We introduce an attack technique that, by simply adding
a limited number of physically constrained adversarial points above a car, can
make the car undetectable by the fusion model. Experimental results reveal that
even without changes to the image data channel, the fusion model can be
deceived solely by manipulating the LiDAR data channel. This finding raises
safety concerns in the field of autonomous driving. Further, we explore how the
quantity of adversarial points, the distance between the front-near car and the
LiDAR-equipped car, and various angular factors affect the attack success rate.
We believe our research can contribute to the understanding of multi-sensor
robustness, offering insights and guidance to enhance the safety of autonomous
driving.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01471" title="Abstract">arXiv:2312.01471</a> [<a href="/pdf/2312.01471" title="Download PDF">pdf</a>, <a href="/ps/2312.01471" title="Download PostScript">ps</a>, <a href="/format/2312.01471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonstandard finite difference methods preserving general quadratic  Lyapunov functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hoang%2C+M+T">Manh Tuan Hoang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this work, we consider a class of dynamical systems described by ordinary
differential equations under the assumption that the global asymptotic
stability (GAS) of equilibrium points is established based on the Lyapunov
stability theory with the help of quadratic Lyapunov functions. We employ the
Micken's methodology to construct a family of explicit nonstandard finite
difference (NSFD) methods preserving any given quadratic Lyapunov function $V$,
i.e. they admit $V$ as a discrete Lyapunov function. Here, the proposed NSFD
methods are derived from a novel non-local approximation for the zero vector
function.
<br />Through rigorous mathematical analysis, we show that the constructed NSFD
methods have the ability to preserve any given quadratic Lyapunov functions
regardless of the values of the step size. As an important consequence, they
are dynamically consistent with respect to the GAS of continuous-time dynamical
systems. On the other hand, the positivity of the proposed NSFD methods is
investigated. It is proved that they can also preserve the positivity of
solutions of continuous-time dynamical systems.
<br />Finally, the theoretical findings are supported by a series of illustrative
numerical experiments, in which advantages of the NSFD methods are
demonstrated.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01472" title="Abstract">arXiv:2312.01472</a> [<a href="/pdf/2312.01472" title="Download PDF">pdf</a>, <a href="/format/2312.01472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenchMARL: Benchmarking Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bettini%2C+M">Matteo Bettini</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+V">Vincent Moens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The field of Multi-Agent Reinforcement Learning (MARL) is currently facing a
reproducibility crisis. While solutions for standardized reporting have been
proposed to address the issue, we still lack a benchmarking tool that enables
standardization and reproducibility, while leveraging cutting-edge
Reinforcement Learning (RL) implementations. In this paper, we introduce
BenchMARL, the first MARL training library created to enable standardized
benchmarking across different algorithms, models, and environments. BenchMARL
uses TorchRL as its backend, granting it high performance and maintained
state-of-the-art implementations while addressing the broad community of MARL
PyTorch users. Its design enables systematic configuration and reporting, thus
allowing users to create and run complex benchmarks from simple one-line
inputs. BenchMARL is open-sourced on GitHub:
https://github.com/facebookresearch/BenchMARL
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01473" title="Abstract">arXiv:2312.01473</a> [<a href="/pdf/2312.01473" title="Download PDF">pdf</a>, <a href="/format/2312.01473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularity as Intrinsic Reward for Free Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sancaktar%2C+C">Cansu Sancaktar</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready version. Project webpage at <a href="http://sites.google.com/view/rair-project">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose regularity as a novel reward signal for intrinsically-motivated
reinforcement learning. Taking inspiration from child development, we postulate
that striving for structure and order helps guide exploration towards a
subspace of tasks that are not favored by naive uncertainty-based intrinsic
rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR)
allows us to operationalize it within model-based reinforcement learning. In a
synthetic environment, we showcase the plethora of structured patterns that can
emerge from pursuing this regularity objective. We also demonstrate the
strength of our method in a multi-object robotic manipulation environment. We
incorporate RaIR into free play and use it to complement the model's epistemic
uncertainty as an intrinsic reward. Doing so, we witness the autonomous
construction of towers and other regular structures during free play, which
leads to a substantial improvement in zero-shot downstream task performance on
assembly tasks.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01474" title="Abstract">arXiv:2312.01474</a> [<a href="/pdf/2312.01474" title="Download PDF">pdf</a>, <a href="/format/2312.01474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Functional Rearrangement Priors from Large Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yiming Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Long Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Object rearrangement, a fundamental challenge in robotics, demands versatile
strategies to handle diverse objects, configurations, and functional needs. To
achieve this, the AI robot needs to learn functional rearrangement priors in
order to specify precise goals that meet the functional requirements. Previous
methods typically learn such priors from either laborious human annotations or
manually designed heuristics, which limits scalability and generalization. In
this work, we propose a novel approach that leverages large models to distill
functional rearrangement priors. Specifically, our approach collects diverse
arrangement examples using both LLMs and VLMs and then distills the examples
into a diffusion model. During test time, the learned diffusion model is
conditioned on the initial configuration and guides the positioning of objects
to meet functional requirements. In this manner, we create a handshaking point
that combines the strengths of conditional generative models and large models.
Extensive experiments on multiple domains, including real-world scenarios,
demonstrate the effectiveness of our approach in generating compatible goals
for object rearrangement tasks, significantly outperforming baseline methods.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01476" title="Abstract">arXiv:2312.01476</a> [<a href="/pdf/2312.01476" title="Download PDF">pdf</a>, <a href="/format/2312.01476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Enhanced Relational Operators with Vector Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanca%2C+V">Viktor Sanca</a>, 
<a href="/search/cs?searchtype=author&query=Chatzakis%2C+M">Manos Chatzakis</a>, 
<a href="/search/cs?searchtype=author&query=Ailamaki%2C+A">Anastasia Ailamaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Collecting data, extracting value, and combining insights from relational and
context-rich multi-modal sources in data processing pipelines presents a
challenge for traditional relational DBMS. While relational operators allow
declarative and optimizable query specification, they are limited to data
transformations unsuitable for capturing or analyzing context. On the other
hand, representation learning models can map context-rich data into embeddings,
allowing machine-automated context processing but requiring imperative data
transformation integration with the analytical query.
<br />To bridge this dichotomy, we present a context-enhanced relational join and
introduce an embedding operator composable with relational operators. This
enables hybrid relational and context-rich vector data processing, with
algebraic equivalences compatible with relational algebra and corresponding
logical and physical optimizations. We investigate model-operator interaction
with vector data processing and study the characteristics of the E-join
operator. Using an example of string embeddings, we demonstrate enabling hybrid
context-enhanced processing on relational join operators with vector
embeddings. The importance of holistic optimization, from logical to physical,
is demonstrated in an order of magnitude execution time improvement.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01479" title="Abstract">arXiv:2312.01479</a> [<a href="/pdf/2312.01479" title="Download PDF">pdf</a>, <a href="/format/2312.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenVoice: Versatile Instant Voice Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zengyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xumin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce OpenVoice, a versatile voice cloning approach that requires only
a short audio clip from the reference speaker to replicate their voice and
generate speech in multiple languages. OpenVoice represents a significant
advancement in addressing the following open challenges in the field: 1)
Flexible Voice Style Control. OpenVoice enables granular control over voice
styles, including emotion, accent, rhythm, pauses, and intonation, in addition
to replicating the tone color of the reference speaker. The voice styles are
not directly copied from and constrained by the style of the reference speaker.
Previous approaches lacked the ability to flexibly manipulate voice styles
after cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves
zero-shot cross-lingual voice cloning for languages not included in the
massive-speaker training set. Unlike previous approaches, which typically
require extensive massive-speaker multi-lingual (MSML) dataset for all
languages, OpenVoice can clone voices into a new language without any
massive-speaker training data for that language. OpenVoice is also
computationally efficient, costing tens of times less than commercially
available APIs that offer even inferior performance. To foster further research
in the field, we have made the source code and trained model publicly
accessible. We also provide qualitative results in our demo website. Prior to
its public release, our internal version of OpenVoice was used tens of millions
of times by users worldwide between May and October 2023, serving as the
backend of MyShell.ai.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01482" title="Abstract">arXiv:2312.01482</a> [<a href="/pdf/2312.01482" title="Download PDF">pdf</a>, <a href="/format/2312.01482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeltingReel: Density Varying Soft Fabrication with Reeling and Felting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping-Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lung-Pan Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages in The 9th Annual Conference of Taiwan Association of Computer-Human Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">FeltingReel is a soft fabrication system that allows users to create a 3D
non-woven textile with various structural strengths. Our system coils wool yarn
onto a central reel to form a basic shape and uses actuated barbed needles to
refine it. By controlling the coiling tension and the felting times, our system
varies the density of the workpiece in a target area to achieve various
structural strengths. Specifically, our system controls the tilt of coiling and
felting using a Stewart platform around a motorized rotating reel. Our system
also allows different basic shapes with hollow internal structures to be formed
by changing the detachable reel core. We investigate the effects of different
felting needles, frequencies, and coiling directions that influence the
density, structural strength, and fabrication time of a workpiece. We propose
three methods to combine felting and reeling. We evaluate their performances
and final products by producing two example workpieces using our system. We
demonstrate several objects made by our working system and discuss its
capabilities and limitations.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01487" title="Abstract">arXiv:2312.01487</a> [<a href="/pdf/2312.01487" title="Download PDF">pdf</a>, <a href="/format/2312.01487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BetterMinton Service: Analyzing the Badminton Service using Open Kinetic  Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+E+C">Eden Cong-He Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lung-Pan Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, The 9th Annual Conference of Taiwanese Association of Computer-Human Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We present a badminton training system that focuses on the backhand short
service. Unlike the prior motor skill training systems which focus on the
trainee's posture, our system analyzes the process of moving joints with the
open kinetic chain (OKC), which helps align movement and minimize muscle use
for better joint control. We process the users' mocap data to visually show
their last service process comparing to 4 ideal OKC characteristics that we
collected from a 6-sub-elite formative study as well as recommended contact
posture. We validate our system through a 12-user study that measures serving
accuracy, qualitative feedback, and skeletal data with users at various skill
levels and open source our skeletal analysis model for future use. While the
participants' overall service accuracy was not significantly improved, our
results show that our system helps participants in the short term to fine-tune
their service motion closer to our ideal 4 OKC characteristics.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01488" title="Abstract">arXiv:2312.01488</a> [<a href="/pdf/2312.01488" title="Download PDF">pdf</a>, <a href="/format/2312.01488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADT: Agent-based Dynamic Thresholding for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Howley%2C+E">Enda Howley</a>, 
<a href="/search/cs?searchtype=author&query=Schukat%2C+M">Micheal Schukat</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Adaptive Learning Agents Workshop @ International Conference on
  Autonomous Agents and Multiagent Systems (AAMAS) 2023, London, UK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The complexity and scale of IT systems are increasing dramatically, posing
many challenges to real-world anomaly detection. Deep learning anomaly
detection has emerged, aiming at feature learning and anomaly scoring, which
has gained tremendous success. However, little work has been done on the
thresholding problem despite it being a critical factor for the effectiveness
of anomaly detection. In this paper, we model thresholding in anomaly detection
as a Markov Decision Process and propose an agent-based dynamic thresholding
(ADT) framework based on a deep Q-network. The proposed method can be
integrated into many systems that require dynamic thresholding. An auto-encoder
is utilized in this study to obtain feature representations and produce anomaly
scores for complex input data. ADT can adjust thresholds adaptively by
utilizing the anomaly scores from the auto-encoder and significantly improve
anomaly detection performance. The properties of ADT are studied through
experiments on three real-world datasets and compared with benchmarks, hence
demonstrating its thresholding capability, data-efficient learning, stability,
and robustness. Our study validates the effectiveness of reinforcement learning
in optimal thresholding control in anomaly detection.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01490" title="Abstract">arXiv:2312.01490</a> [<a href="/pdf/2312.01490" title="Download PDF">pdf</a>, <a href="/format/2312.01490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment  Draping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruochen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Parashar%2C+S">Shaifali Parashar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent neural, physics-based modeling of garment deformations allows faster
and visually aesthetic results as opposed to the existing methods.
Material-specific parameters are used by the formulation to control the garment
inextensibility. This delivers unrealistic results with physically implausible
stretching. Oftentimes, the draped garment is pushed inside the body which is
either corrected by an expensive post-processing, thus adding to further
inconsistent stretching; or by deploying a separate training regime for each
body type, restricting its scalability. Additionally, the flawed skinning
process deployed by existing methods produces incorrect results on loose
garments.
<br />In this paper, we introduce a geometrical constraint to the existing
formulation that is collision-aware and imposes garment inextensibility
wherever possible. Thus, we obtain realistic results where draped clothes
stretch only while covering bigger body regions. Furthermore, we propose a
geometry-aware garment skinning method by defining a body-garment closeness
measure which works for all garment types, especially the loose ones.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01498" title="Abstract">arXiv:2312.01498</a> [<a href="/pdf/2312.01498" title="Download PDF">pdf</a>, <a href="/format/2312.01498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Neural Traffic Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zherong Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for IEEE Robotic and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Extensive research has been devoted to the field of multi-agent navigation.
Recently, there has been remarkable progress attributed to the emergence of
learning-based techniques with substantially elevated intelligence and realism.
Nonetheless, prevailing learned models face limitations in terms of scalability
and effectiveness, primarily due to their agent-centric nature, i.e., the
learned neural policy is individually deployed on each agent. Inspired by the
efficiency observed in real-world traffic networks, we present an
environment-centric navigation policy. Our method learns a set of traffic rules
to coordinate a vast group of unintelligent agents that possess only basic
collision-avoidance capabilities. Our method segments the environment into
distinct blocks and parameterizes the traffic rule using a Graph Recurrent
Neural Network (GRNN) over the block network. Each GRNN node is trained to
modulate the velocities of agents as they traverse through. Using either
Imitation Learning (IL) or Reinforcement Learning (RL) schemes, we demonstrate
the efficacy of our neural traffic rules in resolving agent congestion, closely
resembling real-world traffic regulations. Our method handles up to $240$
agents at real-time and generalizes across diverse agent and environment
configurations.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01499" title="Abstract">arXiv:2312.01499</a> [<a href="/pdf/2312.01499" title="Download PDF">pdf</a>, <a href="/format/2312.01499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Decentralized Task Offloading and Resource Allocation in  User-Centric Mobile Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qin%2C+L">Langtian Qin</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Hancheng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chong%2C+B">Baolin Chong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+F">Feng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP)

</div>
<p class="mathjax">In the traditional cellular-based mobile edge computing (MEC), users at the
edge of the cell are prone to suffer severe inter-cell interference and signal
attenuation, leading to low throughput even transmission interruptions. Such
edge effect severely obstructs offloading of tasks to MEC servers. To address
this issue, we propose user-centric mobile edge computing (UCMEC), a novel MEC
architecture integrating user-centric transmission, which can ensure high
throughput and reliable communication for task offloading. Then, we formulate
an optimization problem with joint consideration of task offloading, power
control, and computing resource allocation in UCMEC, aiming at obtaining the
optimal performance in terms of long-term average total delay. To solve the
intractable problem, we propose two decentralized joint optimization schemes
based on multi-agent deep reinforcement learning (MADRL) and convex
optimization, which consider both cooperation and non-cooperation among network
nodes. Simulation results demonstrate that the proposed schemes in UCMEC can
significantly improve the uplink transmission rate by at most 343.56% and
reduce the long-term average total delay by at most 45.57% compared to
traditional cellular-based MEC.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01500" title="Abstract">arXiv:2312.01500</a> [<a href="/pdf/2312.01500" title="Download PDF">pdf</a>, <a href="/format/2312.01500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Approach to Evaluate Sentence-Level Fluency: Do We Really  Need Reference?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanumolu%2C+G">Gopichand Kanumolu</a>, 
<a href="/search/cs?searchtype=author&query=Madasu%2C+L">Lokesh Madasu</a>, 
<a href="/search/cs?searchtype=author&query=Baswani%2C+P">Pavan Baswani</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Ananya Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+M">Manish Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNLP-AACL SEALP Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Fluency is a crucial goal of all Natural Language Generation (NLG) systems.
Widely used automatic evaluation metrics fall short in capturing the fluency of
machine-generated text. Assessing the fluency of NLG systems poses a challenge
since these models are not limited to simply reusing words from the input but
may also generate abstractions. Existing reference-based fluency evaluations,
such as word overlap measures, often exhibit weak correlations with human
judgments. This paper adapts an existing unsupervised technique for measuring
text fluency without the need for any reference. Our approach leverages various
word embeddings and trains language models using Recurrent Neural Network (RNN)
architectures. We also experiment with other available multilingual Language
Models (LMs). To assess the performance of the models, we conduct a comparative
analysis across 10 Indic languages, correlating the obtained fluency scores
with human judgments. Our code and human-annotated benchmark test-set for
fluency is available at
https://github.com/AnanyaCoder/TextFluencyForIndicLanaguges.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01502" title="Abstract">arXiv:2312.01502</a> [<a href="/pdf/2312.01502" title="Download PDF">pdf</a>, <a href="/format/2312.01502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normed Spaces for Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taha%2C+D">Diaaeldin Taha</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Riestenberg%2C+J+M">J. Maxwell Riestenberg</a>, 
<a href="/search/cs?searchtype=author&query=Strube%2C+M">Michael Strube</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages,7 figures,9 tables | The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Theoretical results from discrete geometry suggest that normed spaces can
abstractly embed finite metric spaces with surprisingly low theoretical bounds
on distortion in low dimensions. In this paper, inspired by this theoretical
insight, we highlight normed spaces as a more flexible and computationally
efficient alternative to several popular Riemannian manifolds for learning
graph embeddings. Normed space embeddings significantly outperform several
popular manifolds on a large range of synthetic and real-world graph
reconstruction benchmark datasets while requiring significantly fewer
computational resources. We also empirically verify the superiority of normed
space embeddings on growing families of graphs associated with negative, zero,
and positive curvature, further reinforcing the flexibility of normed spaces in
capturing diverse graph structures as graph sizes increase. Lastly, we
demonstrate the utility of normed space embeddings on two applied graph
embedding tasks, namely, link prediction and recommender systems. Our work
highlights the potential of normed spaces for geometric graph representation
learning, raises new research questions, and offers a valuable tool for
experimental mathematics in the field of finite metric space embeddings. We
make our code and data publically available.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01504" title="Abstract">arXiv:2312.01504</a> [<a href="/pdf/2312.01504" title="Download PDF">pdf</a>, <a href="/format/2312.01504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectively Fine-tune to Improve Large Multimodal Models for Radiology  Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuzhe Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sungmin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+Y">Yash Shah</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Panpan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Deep Generative Models for Health Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Writing radiology reports from medical images requires a high level of domain
expertise. It is time-consuming even for trained radiologists and can be
error-prone for inexperienced radiologists. It would be appealing to automate
this task by leveraging generative AI, which has shown drastic progress in
vision and language understanding. In particular, Large Language Models (LLM)
have demonstrated impressive capabilities recently and continued to set new
state-of-the-art performance on almost all natural language tasks. While many
have proposed architectures to combine vision models with LLMs for multimodal
tasks, few have explored practical fine-tuning strategies. In this work, we
proposed a simple yet effective two-stage fine-tuning protocol to align visual
features to LLM's text embedding space as soft visual prompts. Our framework
with OpenLLaMA-7B achieved state-of-the-art level performance without
domain-specific pretraining. Moreover, we provide detailed analyses of soft
visual prompts and attention mechanisms, shedding light on future research
directions.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01507" title="Abstract">arXiv:2312.01507</a> [<a href="/pdf/2312.01507" title="Download PDF">pdf</a>, <a href="/format/2312.01507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn2Extend: Extending sequences by retaining their statistical  properties with mixture models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vartziotis%2C+D">Dimitris Vartziotis</a>, 
<a href="/search/cs?searchtype=author&query=Dasoulas%2C+G">George Dasoulas</a>, 
<a href="/search/cs?searchtype=author&query=Pausinger%2C+F">Florian Pausinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper addresses the challenge of extending general finite sequences of
real numbers within a subinterval of the real line, maintaining their inherent
statistical properties by employing machine learning. Our focus lies on
preserving the gap distribution and pair correlation function of these point
sets. Leveraging advancements in deep learning applied to point processes, this
paper explores the use of an auto-regressive \textit{Sequence Extension Mixture
Model} (SEMM) for extending finite sequences, by estimating directly the
conditional density, instead of the intensity function. We perform comparative
experiments on multiple types of point processes, including Poisson, locally
attractive, and locally repelling sequences, and we perform a case study on the
prediction of Riemann $\zeta$ function zeroes. The results indicate that the
proposed mixture model outperforms traditional neural network architectures in
sequence extension with the retention of statistical properties. Given this
motivation, we showcase the capabilities of a mixture model to extend
sequences, maintaining specific statistical properties, i.e. the gap
distribution, and pair correlation indicators.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01508" title="Abstract">arXiv:2312.01508</a> [<a href="/pdf/2312.01508" title="Download PDF">pdf</a>, <a href="/format/2312.01508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CityGen: Infinite and Controllable 3D City Layout Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianshu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">City layout generation has recently gained significant attention. The goal of
this task is to automatically generate the layout of a city scene, including
elements such as roads, buildings, vegetation, as well as other urban
infrastructures. Previous methods using VAEs or GANs for 3D city layout
generation offer limited diversity and constrained interactivity, only allowing
users to selectively regenerate parts of the layout, which greatly limits
customization. In this paper, we propose CityGen, a novel end-to-end framework
for infinite, diverse and controllable 3D city layout generation.First, we
propose an outpainting pipeline to extend the local layout to an infinite city
layout. Then, we utilize a multi-scale diffusion model to generate diverse and
controllable local semantic layout patches. The extensive experiments show that
CityGen achieves state-of-the-art (SOTA) performance under FID and KID in
generating an infinite and controllable 3D city layout. CityGen demonstrates
promising applicability in fields like smart cities, urban planning, and
digital simulation.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01509" title="Abstract">arXiv:2312.01509</a> [<a href="/pdf/2312.01509" title="Download PDF">pdf</a>, <a href="/format/2312.01509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Bias in Pre-trained Language Models: Current Trends and  Under-represented Societies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yogarajan%2C+V">Vithya Yogarajan</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>, 
<a href="/search/cs?searchtype=author&query=Keegan%2C+T+T">Te Taka Keegan</a>, 
<a href="/search/cs?searchtype=author&query=Neuwirth%2C+R+J">Rostam J. Neuwirth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 5 figures, 11 tables. arXiv admin note: text overlap with <a href="/abs/2309.00770">arXiv:2309.00770</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The benefits and capabilities of pre-trained language models (LLMs) in
current and future innovations are vital to any society. However, introducing
and using LLMs comes with biases and discrimination, resulting in concerns
about equality, diversity and fairness, and must be addressed. While
understanding and acknowledging bias in LLMs and developing mitigation
strategies are crucial, the generalised assumptions towards societal needs can
result in disadvantages towards under-represented societies and indigenous
populations. Furthermore, the ongoing changes to actual and proposed amendments
to regulations and laws worldwide also impact research capabilities in tackling
the bias problem. This research presents a comprehensive survey synthesising
the current trends and limitations in techniques used for identifying and
mitigating bias in LLMs, where the overview of methods for tackling bias are
grouped into metrics, benchmark datasets, and mitigation strategies. The
importance and novelty of this survey are that it explores the perspective of
under-represented societies. We argue that current practices tackling the bias
problem cannot simply be 'plugged in' to address the needs of under-represented
societies. We use examples from New Zealand to present requirements for
adopting existing techniques to under-represented societies.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01511" title="Abstract">arXiv:2312.01511</a> [<a href="/pdf/2312.01511" title="Download PDF">pdf</a>, <a href="/format/2312.01511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: The Gap Between Data Rights Ideals and Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yujin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Corren%2C+E">Ella Corren</a>, 
<a href="/search/cs?searchtype=author&query=Garrido%2C+G+M">Gonzalo Munilla Garrido</a>, 
<a href="/search/cs?searchtype=author&query=Hoofnagle%2C+C">Chris Hoofnagle</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Databases (cs.DB)

</div>
<p class="mathjax">As information economies burgeon, they unlock innovation and economic wealth
while posing novel threats to civil liberties and altering power dynamics
between individuals, companies, and governments. Legislatures have reacted with
privacy laws designed to empower individuals over their data. These laws
typically create rights for "data subjects" (individuals) to make requests of
data collectors (companies and governments). The European Union General Data
Protection Regulation (GDPR) exemplifies this, granting extensive data rights
to data subjects, a model embraced globally. However, the question remains: do
these rights-based privacy laws effectively empower individuals over their
data? This paper scrutinizes these approaches by reviewing 201
interdisciplinary empirical studies, news articles, and blog posts. We pinpoint
15 key questions concerning the efficacy of rights allocations. The literature
often presents conflicting results regarding the effectiveness of rights-based
frameworks, but it generally emphasizes their limitations. We offer
recommendations to policymakers and Computer Science (CS) groups committed to
these frameworks, and suggest alternative privacy regulation approaches.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01513" title="Abstract">arXiv:2312.01513</a> [<a href="/pdf/2312.01513" title="Download PDF">pdf</a>, <a href="/ps/2312.01513" title="Download PostScript">ps</a>, <a href="/format/2312.01513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Effort May Fail: Equilibria of Shared Effort with a Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+G">Gleb Polevoy</a>, 
<a href="/search/cs?searchtype=author&query=Trajanovski%2C+S">Stojan Trajanovski</a>, 
<a href="/search/cs?searchtype=author&query=de+Weerdt%2C+M">Mathijs de Weerdt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Shared effort games model people investing resources in public projects,
where the share of the generated values is predefined. In linear $\theta$
sharing (effort) games, a project's value is linear in the total contribution,
while the threshold $\theta$ for effort defines which contributors win and
receive their (equal) share. Thresholds between 0 and 1 model games such as
paper co-authorship and shared assignments, where a minimum positive
contribution is required for sharing in the value. We constructively
characterise the conditions for the existence of a pure equilibrium for
$\theta\in\{0,1\}$, and for two-player games with a general threshold,% and
find the prices of anarchy and stability. For more players, we also provide
existence and efficiency results, and use generalised fictitious play
simulations to show when a pure equilibrium exists and what its efficiency is.
We also prove mixed equilibria always exist and bound their efficiency. This
facilitates reaching socially efficient equilibria.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01515" title="Abstract">arXiv:2312.01515</a> [<a href="/pdf/2312.01515" title="Download PDF">pdf</a>, <a href="/format/2312.01515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bigger is not Always Better: The Effect of Context Size on Speech  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robertson%2C+S">Sean Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Dunbar%2C+E">Ewan Dunbar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Repository at <a href="https://github.com/sdrobert/scpc.">this https URL</a> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">It has been generally assumed in the automatic speech recognition (ASR)
literature that it is better for models to have access to wider context
windows. Yet, many of the potential reasons this might be true in the
supervised setting do not necessarily transfer over to the case of unsupervised
learning. We investigate how much context is necessary to achieve high-quality
pre-trained acoustic models using self-supervised learning. We principally
investigate contrastive predictive coding (CPC), which we adapt to be able to
precisely control the amount of context visible to the model during training
and inference. We find that phone discriminability in the resulting model
representations peaks at around 40~ms of preceding context, and that having too
much context (beyond around 320 ms) substantially degrades the quality of the
representations. Surprisingly, we find that this pattern also transfers to
supervised ASR when the pre-trained representations are used as frozen input
features. Our results point to potential changes in the design of current
upstream architectures to better facilitate a variety of downstream tasks.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01520" title="Abstract">arXiv:2312.01520</a> [<a href="/pdf/2312.01520" title="Download PDF">pdf</a>, <a href="/format/2312.01520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy and the Kullback-Leibler Divergence for Bayesian Networks:  Computational Complexity and Efficient Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Bayesian networks (BNs) are a foundational model in machine learning and
causal inference. Their graphical structure can handle high-dimensional
problems, divide-and-conquering them into a sparse collection of smaller ones;
underlies Judea Pearl's causality; and determines their explainability and
interpretability. Despite their popularity, there are few resources in the
literature on how to compute Shannon's entropy and the Kullback-Leibler (KL)
divergence for BNs under their most common distributional assumptions. In this
paper, we provide computationally efficient algorithms for both by leveraging
BNs' graphical structure, and we illustrate them with a complete set of
numerical examples. In the process, we show it is possible to reduce the
computational complexity of KL from cubic to quadratic for Gaussian BNs.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01521" title="Abstract">arXiv:2312.01521</a> [<a href="/pdf/2312.01521" title="Download PDF">pdf</a>, <a href="/format/2312.01521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Markov Prolog
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomson%2C+A">Alexander Thomson</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+D">David Page</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">The recent rapid advance of AI has been driven largely by innovations in
neural network architectures. A concomitant concern is how to understand these
resulting systems. In this paper, we propose a tool to assist in both the
design of further innovative architectures and the simple yet precise
communication of their structure. We propose the language Neural Markov Prolog
(NMP), based on both Markov logic and Prolog, as a means to both bridge first
order logic and neural network design and to allow for the easy generation and
presentation of architectures for images, text, relational databases, or other
target data types or their mixtures.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01522" title="Abstract">arXiv:2312.01522</a> [<a href="/pdf/2312.01522" title="Download PDF">pdf</a>, <a href="/format/2312.01522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G2D: From Global to Dense Radiography Representation Learning via  Vision-Language Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Cheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sibo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anand Shah</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, medical vision-language pre-training (VLP) has reached substantial
progress to learn global visual representation from medical images and their
paired radiology reports. However, medical imaging tasks in real world usually
require finer granularity in visual features. These tasks include visual
localization tasks (e.g., semantic segmentation, object detection) and visual
grounding task. Yet, current medical VLP methods face challenges in learning
these fine-grained features, as they primarily focus on brute-force alignment
between image patches and individual text tokens for local visual feature
learning, which is suboptimal for downstream dense prediction tasks. In this
work, we propose a new VLP framework, named \textbf{G}lobal to \textbf{D}ense
level representation learning (G2D) that achieves significantly improved
granularity and more accurate grounding for the learned features, compared to
existing medical VLP approaches. In particular, G2D learns dense and
semantically-grounded image representations via a pseudo segmentation task
parallel with the global vision-language alignment. Notably, generating pseudo
segmentation targets does not incur extra trainable parameters: they are
obtained on the fly during VLP with a parameter-free processor. G2D achieves
superior performance across 6 medical imaging tasks and 25 diseases,
particularly in semantic segmentation, which necessitates fine-grained,
semantically-grounded image features. In this task, G2D surpasses peer models
even when fine-tuned with just 1\% of the training data, compared to the 100\%
used by these models. The code will be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01523" title="Abstract">arXiv:2312.01523</a> [<a href="/pdf/2312.01523" title="Download PDF">pdf</a>, <a href="/format/2312.01523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Arjun Singh</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A+K">Abhay Kumar Yadav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we introduce a novel fine-tuning technique for language
models, which involves incorporating symmetric noise into the embedding
process. This method aims to enhance the model's function by more stringently
regulating its local curvature, demonstrating superior performance over the
current method, NEFTune. When fine-tuning the LLaMA-2-7B model using Alpaca,
standard techniques yield a 29.79% score on AlpacaEval. However, our approach,
SymNoise, increases this score significantly to 69.04%, using symmetric noisy
embeddings. This is a 6.7% improvement over the state-of-the-art method,
NEFTune~(64.69%). Furthermore, when tested on various models and stronger
baseline instruction datasets, such as Evol-Instruct, ShareGPT, OpenPlatypus,
SymNoise consistently outperforms NEFTune. The current literature, including
NEFTune, has underscored the importance of more in-depth research into the
application of noise-based strategies in the fine-tuning of language models.
Our approach, SymNoise, is another significant step towards this direction,
showing notable improvement over the existing state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01524" title="Abstract">arXiv:2312.01524</a> [<a href="/pdf/2312.01524" title="Download PDF">pdf</a>, <a href="/ps/2312.01524" title="Download PostScript">ps</a>, <a href="/format/2312.01524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Swarm: A Code Generation Tool Based on the Automatic Derivation of  Transformation Rule Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+H">Hina Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Jilani%2C+A+A">Atif Aftab Jilani</a>, 
<a href="/search/cs?searchtype=author&query=Rauf%2C+A">Abdul Rauf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol. 14, No. 6, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automatic generation of software code from system design models remains an
actively explored research area for the past several years. A number of tools
are currently available to facilitate and automate the task of generating code
from software models. To the best of our knowledge, existing software tools
rely on an explicitly defined transformation rule set to perform the
model-to-code transformation process. In this paper, we introduce a novel tool
named Code Swarm, abbreviated as CodS, that automatically generates
implementation code from system design models by utilizing a swarm-based
approach. Specifically, CodS is capable of generating Java code from the class
and state models of the software system by making use of the previously solved
model-to-code transformation examples. Our tool enables the designers to
specify behavioural actions in the input models using the Action Specification
Language (ASL). We use an industrial case study of the Elevator Control System
(ECS) to perform the experimental validation of our tool. Our results indicate
that the code generated by CodS is correct and consistent with the input design
models. CodS performs the process of automatic code generation without taking
the explicit transformation rule set or languages metamodels information as
input, which distinguishes it from all the existing automatic code generation
tools.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01529" title="Abstract">arXiv:2312.01529</a> [<a href="/pdf/2312.01529" title="Download PDF">pdf</a>, <a href="/format/2312.01529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T3D: Towards 3D Medical Image Understanding through Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Cheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quilodr%C3%A1n-Casas%2C+C+C">Cesar C&#xe9;sar Quilodr&#xe1;n-Casas</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anand Shah</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Expert annotation of 3D medical image for downstream analysis is
resource-intensive, posing challenges in clinical applications. Visual
self-supervised learning (vSSL), though effective for learning visual
invariance, neglects the incorporation of domain knowledge from medicine. To
incorporate medical knowledge into visual representation learning,
vision-language pre-training (VLP) has shown promising results in 2D image.
However, existing VLP approaches become generally impractical when applied to
high-resolution 3D medical images due to GPU hardware constraints and the
potential loss of critical details caused by downsampling, which is the
intuitive solution to hardware constraints. To address the above limitations,
we introduce T3D, the first VLP framework designed for high-resolution 3D
medical images. T3D incorporates two text-informed pretext tasks:
(\lowerromannumeral{1}) text-informed contrastive learning;
(\lowerromannumeral{2}) text-informed image restoration. These tasks focus on
learning 3D visual representations from high-resolution 3D medical images and
integrating clinical knowledge from radiology reports, without distorting
information through forced alignment of downsampled volumes with detailed
anatomical text. Trained on a newly curated large-scale dataset of 3D medical
images and radiology reports, T3D significantly outperforms current vSSL
methods in tasks like organ and tumor segmentation, as well as disease
classification. This underlines T3D's potential in representation learning for
3D medical image analysis. All data and code will be available upon acceptance.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01531" title="Abstract">arXiv:2312.01531</a> [<a href="/pdf/2312.01531" title="Download PDF">pdf</a>, <a href="/format/2312.01531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SANeRF-HQ: Segment Anything for NeRF in High Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Benran Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the Segment Anything Model (SAM) has showcased remarkable
capabilities of zero-shot segmentation, while NeRF (Neural Radiance Fields) has
gained popularity as a method for various 3D problems beyond novel view
synthesis. Though there exist initial attempts to incorporate these two methods
into 3D segmentation, they face the challenge of accurately and consistently
segmenting objects in complex scenarios. In this paper, we introduce the
Segment Anything for NeRF in High Quality (SANeRF-HQ) to achieve high quality
3D segmentation of any object in a given scene. SANeRF-HQ utilizes SAM for
open-world object segmentation guided by user-supplied prompts, while
leveraging NeRF to aggregate information from different viewpoints. To overcome
the aforementioned challenges, we employ density field and RGB similarity to
enhance the accuracy of segmentation boundary during the aggregation.
Emphasizing on segmentation accuracy, we evaluate our method quantitatively on
multiple NeRF datasets where high-quality ground-truths are available or
manually annotated. SANeRF-HQ shows a significant quality improvement over
previous state-of-the-art methods in NeRF object segmentation, provides higher
flexibility for object localization, and enables more consistent object
segmentation across multiple views. Additional information can be found at
https://lyclyc52.github.io/SANeRF-HQ/.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01532" title="Abstract">arXiv:2312.01532</a> [<a href="/pdf/2312.01532" title="Download PDF">pdf</a>, <a href="/format/2312.01532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models to Accelerate Communication for Users with  Severe Motor Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shanqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Venugopalan%2C+S">Subhashini Venugopalan</a>, 
<a href="/search/cs?searchtype=author&query=Seaver%2C+K">Katie Seaver</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tomanek%2C+K">Katrin Tomanek</a>, 
<a href="/search/cs?searchtype=author&query=Jalasutram%2C+S">Sri Jalasutram</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+M+R">Meredith Ringel Morris</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+S">Shaun Kane</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Ajit Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+R+L">Robert L. MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Kornman%2C+E">Emily Kornman</a>, 
<a href="/search/cs?searchtype=author&query=Vance%2C+D">Daniel Vance</a>, 
<a href="/search/cs?searchtype=author&query=Casey%2C+B">Blair Casey</a>, 
<a href="/search/cs?searchtype=author&query=Gleason%2C+S+M">Steve M. Gleason</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+P+Q">Philip Q. Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Brenner%2C+M+P">Michael P. Brenner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Finding ways to accelerate text input for individuals with profound motor
impairments has been a long-standing area of research. Closing the speed gap
for augmentative and alternative communication (AAC) devices such as
eye-tracking keyboards is important for improving the quality of life for such
individuals. Recent advances in neural networks of natural language pose new
opportunities for re-thinking strategies and user interfaces for enhanced
text-entry for AAC users. In this paper, we present SpeakFaster, consisting of
large language models (LLMs) and a co-designed user interface for text entry in
a highly-abbreviated form, allowing saving 57% more motor actions than
traditional predictive keyboards in offline simulation. A pilot study with 19
non-AAC participants typing on a mobile device by hand demonstrated gains in
motor savings in line with the offline simulation, while introducing relatively
small effects on overall typing speed. Lab and field testing on two eye-gaze
typing users with amyotrophic lateral sclerosis (ALS) demonstrated text-entry
rates 29-60% faster than traditional baselines, due to significant saving of
expensive keystrokes achieved through phrase and word predictions from
context-aware LLMs. These findings provide a strong foundation for further
exploration of substantially-accelerated text communication for motor-impaired
users and demonstrate a direction for applying LLMs to text-based user
interfaces.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01534" title="Abstract">arXiv:2312.01534</a> [<a href="/pdf/2312.01534" title="Download PDF">pdf</a>, <a href="/format/2312.01534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeletal Cut Loci on Convex Polyhedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Rourke%2C+J">Joseph O&#x27;Rourke</a>, 
<a href="/search/cs?searchtype=author&query=Vilcu%2C+C">Costin Vilcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures, 8 refeences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Metric Geometry (math.MG)

</div>
<p class="mathjax">The cut locus C(x) on a convex polyhedron P with respect to a point x is a
tree of geodesic segments (shortest paths) on P that includes every vertex. In
general, edges of C(x) are not edges of P, i.e., not part of the 1-skeleton
Sk(P) of P. We say that P has a *skeletal cut locus* if there is some x in P
such that C(x) is a subset of Sk(P). In this paper we study skeletal cut loci,
obtaining three main results.
<br />First, given any combinatorial tree T , there exists a convex polyhedron P
and a point x with a skeletal cut locus that matches the combinatorics of T.
Second, any (non-degenerate) polyhedron P has at most a finite number of points
x for which C(x) is a subset of Sk(P). Third, we show that almost all polyhedra
have no skeletal cut locus.
<br />Because the source unfolding of P with respect to x is always a
non-overlapping net for P, and because the boundary of the source unfolding is
the (unfolded) cut locus, source unfoldings of polyhedra with skeletal cut loci
are edge-unfoldings, and moreover "blooming," avoiding self-intersection during
an unfolding process.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01536" title="Abstract">arXiv:2312.01536</a> [<a href="/pdf/2312.01536" title="Download PDF">pdf</a>, <a href="/format/2312.01536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CalliPaint: Chinese Calligraphy Inpainting with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qisheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhinuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gus Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a Machine Learning for Creativity and Design(ML4CD) workshop paper at NeruaIPS 2023. <a href="https://neurips.cc/virtual/2023/workshop/66545#wse-detail-75063">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chinese calligraphy can be viewed as a unique form of visual art. Recent
advancements in computer vision hold significant potential for the future
development of generative models in the realm of Chinese calligraphy.
Nevertheless, methods of Chinese calligraphy inpainting, which can be
effectively used in the art and education fields, remain relatively unexplored.
In this paper, we introduce a new model that harnesses recent advancements in
both Chinese calligraphy generation and image inpainting. We demonstrate that
our proposed model CalliPaint can produce convincing Chinese calligraphy.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01537" title="Abstract">arXiv:2312.01537</a> [<a href="/pdf/2312.01537" title="Download PDF">pdf</a>, <a href="/ps/2312.01537" title="Download PostScript">ps</a>, <a href="/format/2312.01537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Potential of Federated Learning: The Symphony of Dataset  Distillation via Deep Generative Latents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuqi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Vahidian%2C+S">Saeed Vahidian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data heterogeneity presents significant challenges for federated learning
(FL). Recently, dataset distillation techniques have been introduced, and
performed at the client level, to attempt to mitigate some of these challenges.
In this paper, we propose a highly efficient FL dataset distillation framework
on the server side, significantly reducing both the computational and
communication demands on local devices while enhancing the clients' privacy.
Unlike previous strategies that perform dataset distillation on local devices
and upload synthetic data to the server, our technique enables the server to
leverage prior knowledge from pre-trained deep generative models to synthesize
essential data representations from a heterogeneous model architecture. This
process allows local devices to train smaller surrogate models while enabling
the training of a larger global model on the server, effectively minimizing
resource utilization. We substantiate our claim with a theoretical analysis,
demonstrating the asymptotic resemblance of the process to the hypothetical
ideal of completely centralized training on a heterogeneous dataset. Empirical
evidence from our comprehensive experiments indicates our method's superiority,
delivering an accuracy enhancement of up to 40% over non-dataset-distillation
techniques in highly heterogeneous FL contexts, and surpassing existing
dataset-distillation methods by 18%. In addition to the high accuracy, our
framework converges faster than the baselines because rather than the server
trains on several sets of heterogeneous data distributions, it trains on a
multi-modal distribution. Our code is available at
https://github.com/FedDG23/FedDG-main.git
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01538" title="Abstract">arXiv:2312.01538</a> [<a href="/pdf/2312.01538" title="Download PDF">pdf</a>, <a href="/format/2312.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Distance-Encoding Neural Networks for Graph Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuhui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Orvieto%2C+A">Antonio Orvieto</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bobby He</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Graph neural networks based on iterative one-hop message passing have been
shown to struggle in harnessing information from distant nodes effectively.
Conversely, graph transformers allow each node to attend to all other nodes
directly, but suffer from high computational complexity and have to rely on
ad-hoc positional encoding to bake in the graph inductive bias. In this paper,
we propose a new architecture to reconcile these challenges. Our approach stems
from the recent breakthroughs in long-range modeling provided by deep
state-space models on sequential data: for a given target node, our model
aggregates other nodes by their shortest distances to the target and uses a
parallelizable linear recurrent network over the chain of distances to provide
a natural encoding of its neighborhood structure. With no need for positional
encoding, we empirically show that the performance of our model is highly
competitive compared with that of state-of-the-art graph transformers on
various benchmarks, at a drastically reduced computational complexity. In
addition, we show that our model is theoretically more expressive than one-hop
message passing neural networks.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01540" title="Abstract">arXiv:2312.01540</a> [<a href="/pdf/2312.01540" title="Download PDF">pdf</a>, <a href="/format/2312.01540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Computer Vision in an Ever-Changing World: A Survey of Techniques  for Tackling Distribution Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adhikarla%2C+E">Eashan Adhikarla</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Nicholson%2C+J">John Nicholson</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+B+D">Brian D. Davison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">AI applications are becoming increasingly visible to the general public.
There is a notable gap between the theoretical assumptions researchers make
about computer vision models and the reality those models face when deployed in
the real world. One of the critical reasons for this gap is a challenging
problem known as distribution shift. Distribution shifts tend to vary with
complexity of the data, dataset size, and application type. In our paper, we
discuss the identification of such a prominent gap, exploring the concept of
distribution shift and its critical significance. We provide an in-depth
overview of various types of distribution shifts, elucidate their distinctions,
and explore techniques within the realm of the data-centric domain employed to
address them. Distribution shifts can occur during every phase of the machine
learning pipeline, from the data collection stage to the stage of training a
machine learning model to the stage of final model deployment. As a result, it
raises concerns about the overall robustness of the machine learning techniques
for computer vision applications that are deployed publicly for consumers.
Different deep learning models each tailored for specific type of data and
tasks, architectural pipelines; highlighting how variations in data
preprocessing and feature extraction can impact robustness., data augmentation
strategies (e.g. geometric, synthetic and learning-based); demonstrating their
role in enhancing model generalization, and training mechanisms (e.g. transfer
learning, zero-shot) fall under the umbrella of data-centric methods. Each of
these components form an integral part of the neural-network we analyze
contributing uniquely to strengthening model robustness against distribution
shifts. We compare and contrast numerous AI models that are built for
mitigating shifts in hidden stratification and spurious correlations, ...
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01541" title="Abstract">arXiv:2312.01541</a> [<a href="/pdf/2312.01541" title="Download PDF">pdf</a>, <a href="/format/2312.01541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Non-separable Binary Classification and its Applications in  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lau%2C+M">Matthew Lau</a>, 
<a href="/search/cs?searchtype=author&query=Seck%2C+I">Ismaila Seck</a>, 
<a href="/search/cs?searchtype=author&query=Meliopoulos%2C+A+P">Athanasios P Meliopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wenke Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ndiaye%2C+E">Eugene Ndiaye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/mattlaued/XOR-is-Linearly-Classifiable">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The inability to linearly classify XOR has motivated much of deep learning.
We revisit this age-old problem and show that linear classification of XOR is
indeed possible. Instead of separating data between halfspaces, we propose a
slightly different paradigm, equality separation, that adapts the SVM objective
to distinguish data within or outside the margin. Our classifier can then be
integrated into neural network pipelines with a smooth approximation. From its
properties, we intuit that equality separation is suitable for anomaly
detection. To formalize this notion, we introduce closing numbers, a
quantitative measure on the capacity for classifiers to form closed decision
regions for anomaly detection. Springboarding from this theoretical connection
between binary classification and anomaly detection, we test our hypothesis on
supervised anomaly detection experiments, showing that equality separation can
detect both seen and unseen anomalies.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01543" title="Abstract">arXiv:2312.01543</a> [<a href="/pdf/2312.01543" title="Download PDF">pdf</a>, <a href="/format/2312.01543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Torso-Based Control Interface for Standing Mobility-Assistive Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Paez-Granados%2C+D">Diego Paez-Granados</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+M">Modar Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Kenji Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ASME Transactions on Mechatronics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Wheelchairs and mobility devices have transformed our bodies into cybernic
systems, extending our well-being by enabling individuals with reduced mobility
to regain freedom. Notwithstanding, current interfaces of control require to
use the hands, therefore constraining the user from performing functional
activities of daily living. In this work, we present a unique design of
torso-based control interface with compliant coupling support for standing
mobility assistive devices. We take the coupling between the human and robot
into consideration in the interface design. The design includes a compliant
support mechanism and a mapping between the body movement space and the
velocity space. We present experiments including multiple conditions, with a
joystick for comparison with the proposed torso control interface. The results
of a path-following experiment showed that users were able to control the
device naturally using the hands-free interface, and the performance was
comparable with the joystick, with 10% more consumed time, an average cross
error of 0.116 m and 4.9% less average acceleration. The result of an
object-transferring experiment showed the advantage of using the proposed
interface in case users needed to manipulate objects while locomotion. The
torso control scored 15% less in the System Usability Scale than the joystick
in the path following task but 3.3% more in the object transferring task.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01544" title="Abstract">arXiv:2312.01544</a> [<a href="/pdf/2312.01544" title="Download PDF">pdf</a>, <a href="/format/2312.01544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KEEC: Embed to Control on An Equivariant Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiaoyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yukun Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper investigates how representation learning can enable optimal
control in unknown and complex dynamics, such as chaotic and non-linear
systems, without relying on prior domain knowledge of the dynamics. The core
idea is to establish an equivariant geometry that is diffeomorphic to the
manifold defined by a dynamical system and to perform optimal control within
this corresponding geometry, which is a non-trivial task. To address this
challenge, Koopman Embed to Equivariant Control (KEEC) is introduced for model
learning and control. Inspired by Lie theory, KEEC begins by learning a
non-linear dynamical system defined on a manifold and embedding trajectories
into a Lie group. Subsequently, KEEC formulates an equivariant value function
equation in reinforcement learning on the equivariant geometry, ensuring an
invariant effect as the value function on the original manifold. By deriving
analytical-form optimal actions on the equivariant value function, KEEC
theoretically achieves quadratic convergence for the optimal equivariant value
function by leveraging the differential information on the equivariant
geometry. The effectiveness of KEEC is demonstrated in challenging dynamical
systems, including chaotic ones like Lorenz-63. Notably, our findings indicate
that isometric and isomorphic loss functions, ensuring the compactness and
smoothness of geometry, outperform loss functions without these properties.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01546" title="Abstract">arXiv:2312.01546</a> [<a href="/pdf/2312.01546" title="Download PDF">pdf</a>, <a href="/format/2312.01546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Channel Capacity with Neural Mutual Information Estimator Based  on Message Importance Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhefan Li</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenghui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Channel capacity estimation plays a crucial role in beyond 5G intelligent
communications. Despite its significance, this task is challenging for a
majority of channels, especially for the complex channels not modeled as the
well-known typical ones. Recently, neural networks have been used in mutual
information estimation and optimization. They are particularly considered as
efficient tools for learning channel capacity. In this paper, we propose a
cooperative framework to simultaneously estimate channel capacity and design
the optimal codebook. First, we will leverage MIM-based GAN, a novel form of
generative adversarial network (GAN) using message importance measure (MIM) as
the information distance, into mutual information estimation, and develop a
novel method, named MIM-based mutual information estimator (MMIE). Then, we
design a generalized cooperative framework for channel capacity learning, in
which a generator is regarded as an encoder producing the channel input, while
a discriminator is the mutual information estimator that assesses the
performance of the generator. Through the adversarial training, the generator
automatically learns the optimal codebook and the discriminator estimates the
channel capacity. Numerical experiments will demonstrate that compared with
several conventional estimators, the MMIE achieves state-of-the-art performance
in terms of accuracy and stability.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01547" title="Abstract">arXiv:2312.01547</a> [<a href="/pdf/2312.01547" title="Download PDF">pdf</a>, <a href="/ps/2312.01547" title="Download PostScript">ps</a>, <a href="/format/2312.01547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Algorithms for Gaussians with Huber Contamination: Mean  Estimation and Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D+M">Daniel M. Kane</a>, 
<a href="/search/cs?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>, 
<a href="/search/cs?searchtype=author&query=Pittas%2C+T">Thanasis Pittas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the fundamental problems of Gaussian mean estimation and linear
regression with Gaussian covariates in the presence of Huber contamination. Our
main contribution is the design of the first sample near-optimal and almost
linear-time algorithms with optimal error guarantees for both of these
problems. Specifically, for Gaussian robust mean estimation on $\mathbb{R}^d$
with contamination parameter $\epsilon \in (0, \epsilon_0)$ for a small
absolute constant $\epsilon_0$, we give an algorithm with sample complexity $n
= \tilde{O}(d/\epsilon^2)$ and almost linear runtime that approximates the
target mean within $\ell_2$-error $O(\epsilon)$. This improves on prior work
that achieved this error guarantee with polynomially suboptimal sample and time
complexity. For robust linear regression, we give the first algorithm with
sample complexity $n = \tilde{O}(d/\epsilon^2)$ and almost linear runtime that
approximates the target regressor within $\ell_2$-error $O(\epsilon)$. This is
the first polynomial sample and time algorithm achieving the optimal error
guarantee, answering an open question in the literature. At the technical
level, we develop a methodology that yields almost-linear time algorithms for
multi-directional filtering that may be of broader interest.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01549" title="Abstract">arXiv:2312.01549</a> [<a href="/pdf/2312.01549" title="Download PDF">pdf</a>, <a href="/ps/2312.01549" title="Download PostScript">ps</a>, <a href="/format/2312.01549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Non-Compatibility of Optimistic Rollups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Landis%2C+D">Daji Landis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Optimistic rollups are a popular and promising method of increasing the
throughput capacity of their underlying chain. These methods rely on economic
incentives to guarantee their security. We present a model of optimistic
rollups that suggests that the incentives are not necessarily aligned with the
expected behavior of the players, thus potentially undermining the security of
existing optimistic rollups.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01550" title="Abstract">arXiv:2312.01550</a> [<a href="/pdf/2312.01550" title="Download PDF">pdf</a>, <a href="/format/2312.01550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using human and robot synthetic data for training smart hand tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bendana%2C+J">Jose Bendana</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+S+S+V">Sundar Sripada V. S.</a>, 
<a href="/search/cs?searchtype=author&query=Salazar%2C+C+D">Carlos D. Salazar</a>, 
<a href="/search/cs?searchtype=author&query=Chinchali%2C+S">Sandeep Chinchali</a>, 
<a href="/search/cs?searchtype=author&query=Longoria%2C+R+G">Raul G. Longoria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The future of work does not require a choice between human and robot. Aside
from explicit human-robot collaboration, robotics can play an increasingly
important role in helping train workers as well as the tools they may use,
especially in complex tasks that may be difficult to automate or effectively
roboticize. This paper introduces a form of smart tool for use by human workers
and shows how training the tool for task recognition, one of the key
requirements, can be accomplished. Machine learning (ML) with purely
human-based data can be extremely laborious and time-consuming. First, we show
how data synthetically-generated by a robot can be leveraged in the ML training
process. Later, we demonstrate how fine-tuning ML models for individual
physical tasks and workers can significantly scale up the benefits of using ML
to provide this feedback. Experimental results show the effectiveness and
scalability of our approach, as we test data size versus accuracy. Smart hand
tools of the type introduced here can provide insights and real-time analytics
on efficient and safe tool usage and operation, thereby enhancing human
participation and skill in a wide range of work environments. Using robotic
platforms to help train smart tools will be essential, particularly given the
diverse types of applications for which smart hand tools are envisioned for
human use.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01552" title="Abstract">arXiv:2312.01552</a> [<a href="/pdf/2312.01552" title="Download PDF">pdf</a>, <a href="/format/2312.01552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="/search/cs?searchtype=author&query=Sclar%2C+M">Melanie Sclar</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K">Khyathi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures. Project website: <a href="https://allenai.github.io/re-align/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The alignment tuning process of large language models (LLMs) typically
involves instruction learning through supervised fine-tuning (SFT) and
preference tuning via reinforcement learning from human feedback (RLHF). A
recent study, LIMA (Zhou et al. 2023), shows that using merely 1K examples for
SFT can achieve significant alignment performance as well, suggesting that the
effect of alignment tuning might be "superficial." This raises questions about
how exactly the alignment tuning transforms a base LLM.
<br />We analyze the effect of alignment tuning by examining the token distribution
shift between base LLMs and their aligned counterpart. Our findings reveal that
base LLMs and their alignment-tuned versions perform nearly identically in
decoding on the majority of token positions. Most distribution shifts occur
with stylistic tokens. These direct evidence strongly supports the Superficial
Alignment Hypothesis suggested by LIMA.
<br />Based on these findings, we rethink the alignment of LLMs by posing the
research question: how effectively can we align base LLMs without SFT or RLHF?
To address this, we introduce a simple, tuning-free alignment method, URIAL.
URIAL achieves effective alignment purely through in-context learning (ICL)
with base LLMs, requiring as few as three constant stylistic examples and a
system prompt. We conduct a fine-grained and interpretable evaluation on a
diverse set of examples, named JUST-EVAL-INSTRUCT. Results demonstrate that
base LLMs with URIAL can match or even surpass the performance of LLMs aligned
with SFT or SFT+RLHF. We show that the gap between tuning-free and tuning-based
alignment methods can be significantly reduced through strategic prompting and
ICL. Our findings on the superficial nature of alignment tuning and results
with URIAL suggest that deeper analysis and theoretical understanding of
alignment is crucial to future LLM research.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01554" title="Abstract">arXiv:2312.01554</a> [<a href="/pdf/2312.01554" title="Download PDF">pdf</a>, <a href="/format/2312.01554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Ears for Robots: Machine Hearing in the Age of Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xuan Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures The materials covered in this article were presented and discussed at the Hearing Seminar at Stanford University organized by Malcolm Slaney in October, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Robotics (cs.RO); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Robot hearing system is becoming an important topic due to the increasing
number of field robots in uncertain environments. This study discusses what a
hearing system means to a robot and why it is important. In particular, the
hardware design principles are introduced with the example of robotaxi, on
which exterior microphone arrays are used for detection of siren and other
abnormal sound events. After that, a preliminary robot hearing software design
framework is developed based on the taxonomy of modern probabilistic robotics
as a part of decision processes.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01555" title="Abstract">arXiv:2312.01555</a> [<a href="/pdf/2312.01555" title="Download PDF">pdf</a>, <a href="/format/2312.01555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI is Responsible AI: How Explainability Creates Trustworthy  and Socially Responsible Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baker%2C+S">Stephanie Baker</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wei Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 7 figures (figures 3-6 include subfigures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial intelligence (AI) has been clearly established as a technology
with the potential to revolutionize fields from healthcare to finance - if
developed and deployed responsibly. This is the topic of responsible AI, which
emphasizes the need to develop trustworthy AI systems that minimize bias,
protect privacy, support security, and enhance transparency and accountability.
Explainable AI (XAI) has been broadly considered as a building block for
responsible AI (RAI), with most of the literature considering it as a solution
for improved transparency. This work proposes that XAI and responsible AI are
significantly more deeply entwined. In this work, we explore state-of-the-art
literature on RAI and XAI technologies. Based on our findings, we demonstrate
that XAI can be utilized to ensure fairness, robustness, privacy, security, and
transparency in a wide range of contexts. Our findings lead us to conclude that
XAI is an essential foundation for every pillar of RAI.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01556" title="Abstract">arXiv:2312.01556</a> [<a href="/pdf/2312.01556" title="Download PDF">pdf</a>, <a href="/format/2312.01556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching Dense Representations with Inverted Indexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Teofili%2C+T">Tommaso Teofili</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Nearly all implementations of top-$k$ retrieval with dense vector
representations today take advantage of hierarchical navigable small-world
network (HNSW) indexes. However, the generation of vector representations and
efficiently searching large collections of vectors are distinct challenges that
can be decoupled. In this work, we explore the contrarian approach of
performing top-$k$ retrieval on dense vector representations using inverted
indexes. We present experiments on the MS MARCO passage ranking dataset,
evaluating three dimensions of interest: output quality, speed, and index size.
Results show that searching dense representations using inverted indexes is
possible. Our approach exhibits reasonable effectiveness with compact indexes,
but is impractically slow. Thus, while workable, our solution does not provide
a compelling tradeoff and is perhaps best characterized today as a "technical
curiosity".
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01558" title="Abstract">arXiv:2312.01558</a> [<a href="/pdf/2312.01558" title="Download PDF">pdf</a>, <a href="/format/2312.01558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Compression Using Sampling and Implicit Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezasoltani%2C+S">Shima Rezasoltani</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+F+Z">Faisal Z. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Hyperspectral images, which record the electromagnetic spectrum for a pixel
in the image of a scene, often store hundreds of channels per pixel and contain
an order of magnitude more information than a similarly-sized RBG color image.
Consequently, concomitant with the decreasing cost of capturing these images,
there is a need to develop efficient techniques for storing, transmitting, and
analyzing hyperspectral images. This paper develops a method for hyperspectral
image compression using implicit neural representations where a multilayer
perceptron network F with sinusoidal activation functions "learns" to map pixel
locations to pixel intensities for a given hyperspectral image I. F thus acts
as a compressed encoding of this image, and the original image is reconstructed
by evaluating F at each pixel location. We use a sampling method with two
factors: window size and sampling rate to reduce the compression time. We have
evaluated our method on four benchmarks -- Indian Pines, Jasper Ridge, Pavia
University, and Cuprite using PSNR and SSIM -- and we show that the proposed
method achieves better compression than JPEG, JPEG2000, and PCA-DCT at low
bitrates. Besides, we compare our results with the learning-based methods like
PCA+JPEG2000, FPCA+JPEG2000, 3D DCT, 3D DWT+SVR, and WSRC and show the
corresponding results in the "Compression Results" section. We also show that
our methods with sampling achieve better speed and performance than our method
without sampling.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01559" title="Abstract">arXiv:2312.01559</a> [<a href="/pdf/2312.01559" title="Download PDF">pdf</a>, <a href="/ps/2312.01559" title="Download PostScript">ps</a>, <a href="/format/2312.01559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axisymmetric Virtual Elements For Problems of Elasticity and Plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yaw%2C+L+L">Louie L. Yaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 36 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The virtual element method (VEM) allows discretization of elasticity and
plasticity problems with polygons in 2D and polyhedrals in 3D. The polygons
(and polyhedrals) can have an arbitrary number of sides and can be concave or
convex. These features, among others, are attractive for meshing complex
geometries. However, to the author's knowledge axisymmetric virtual elements
have not appeared before in the literature. Hence, in this work a novel first
order consistent axisymmetric virtual element method is applied to problems of
elasticity and plasticity. The VEM specific implementation details and
adjustments needed to solve axisymmetric simulations are presented.
Representative benchmark problems including pressure vessels and circular
plates are illustrated. Examples also show that problems of near
incompressibility are solved successfully. Consequently, this research
demonstrates that the axisymmetric VEM formulation successfully solves certain
classes of solid mechanics problems. The work concludes with a discussion of
results for the current formulation and future research directions.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01560" title="Abstract">arXiv:2312.01560</a> [<a href="/pdf/2312.01560" title="Download PDF">pdf</a>, <a href="/ps/2312.01560" title="Download PostScript">ps</a>, <a href="/format/2312.01560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaftGP: Random Fast Graph Partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Meng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yibin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Li Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaorui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rongqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bo Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides the node set of a graph into densely-connected blocks. Following
prior work on the IEEE HPEC Graph Challenge benchmark and recent advances in
graph machine learning, we propose a novel RAndom FasT Graph Partitioning
(RaftGP) method based on an efficient graph embedding scheme. It uses the
Gaussian random projection to extract community-preserving features from
classic GP objectives. These features are fed into a graph neural network (GNN)
to derive low-dimensional node embeddings. Surprisingly, our experiments
demonstrate that a randomly initialized GNN even without training is enough for
RaftGP to derive informative community-preserving embeddings and support
high-quality GP. To enable the derived embeddings to tackle GP, we introduce a
hierarchical model selection algorithm that simultaneously determines the
number of blocks and the corresponding GP result. We evaluate RaftGP on the
Graph Challenge benchmark and compare the performance with five baselines,
where our method can achieve a better trade-off between quality and efficiency.
In particular, compared to the baseline algorithm of the IEEE HPEC Graph
Challenge, our method is 6.68x -- 23.9x faster on graphs with 1E3 -- 5E4 nodes
and at least 64.5x faster on larger (1E5 node) graphs on which the baseline
takes more than 1E4 seconds. Our method achieves better accuracy on all test
cases. We also develop a new graph generator to address some limitations of the
original generator in the benchmark.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01561" title="Abstract">arXiv:2312.01561</a> [<a href="/pdf/2312.01561" title="Download PDF">pdf</a>, <a href="/format/2312.01561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Person Matching and 3D Pose Estimation with Arbitrary  Uncalibrated Camera Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-view person matching and 3D human pose estimation in multi-camera
networks are particularly difficult when the cameras are extrinsically
uncalibrated. Existing efforts generally require large amounts of 3D data for
training neural networks or known camera poses for geometric constraints to
solve the problem. However, camera poses and 3D data annotation are usually
expensive and not always available. We present a method, PME, that solves the
two tasks without requiring either information. Our idea is to address
cross-view person matching as a clustering problem using each person as a
cluster center, then obtain correspondences from person matches, and estimate
3D human poses through multi-view triangulation and bundle adjustment. We solve
the clustering problem by introducing a "size constraint" using the number of
cameras and a "source constraint" using the fact that two people from the same
camera view should not match, to narrow the solution space to a small feasible
region. The 2D human poses used in clustering are obtained through a
pre-trained 2D pose detector, so our method does not require expensive 3D
training data for each new scene. We extensively evaluate our method on three
open datasets and two indoor and outdoor datasets collected using arbitrarily
set cameras. Our method outperforms other methods by a large margin on
cross-view person matching, reaches SOTA performance on 3D human pose
estimation without using either camera poses or 3D training data, and shows
good generalization ability across five datasets of various environment
settings.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01564" title="Abstract">arXiv:2312.01564</a> [<a href="/pdf/2312.01564" title="Download PDF">pdf</a>, <a href="/format/2312.01564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APoLLo: Unified Adapter and Prompt Learning for Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S">Sanjoy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+S">Sayan Nag</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 (Main track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The choice of input text prompt plays a critical role in the performance of
Vision-Language Pretrained (VLP) models such as CLIP. We present APoLLo, a
unified multi-modal approach that combines Adapter and Prompt learning for
Vision-Language models. Our method is designed to substantially improve the
generalization capabilities of VLP models when they are fine-tuned in a
few-shot setting. We introduce trainable cross-attention-based adapter layers
in conjunction with vision and language encoders to strengthen the alignment
between the two modalities. We enforce consistency between the respective
encoder branches (receiving augmented inputs) to prevent overfitting in
downstream tasks. Our method is evaluated on three representative tasks:
generalization to novel classes, cross-dataset evaluation, and unseen domain
shifts. In practice, APoLLo achieves a relative gain up to 6.03% over MaPLe
(SOTA) on novel classes for 10 diverse image recognition datasets.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01565" title="Abstract">arXiv:2312.01565</a> [<a href="/pdf/2312.01565" title="Download PDF">pdf</a>, <a href="/ps/2312.01565" title="Download PostScript">ps</a>, <a href="/format/2312.01565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding mixed memberships in categorical data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+H">Huan Qing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Latent class analysis is a fundamental problem in categorical data analysis,
which often encounters overlapping latent classes that further challenge the
problem. This paper addresses the problem of finding latent mixed memberships
of subjects in categorical data with polytomous responses under the Grade of
Membership (GoM) model, which allows each subject to be associated with a
membership score in each latent class. We propose two efficient spectral
algorithms for estimating latent mixed memberships and other GoM parameters.
Our algorithms are developed by using the singular value decomposition of a
regularized Laplacian matrix. We establish their convergence rates under a mild
condition on data sparsity. We also provide a measure to evaluate the quality
of estimated mixed memberships for real-world categorical data and determine
the number of latent classes based on this measure. Finally, we demonstrate the
performances of our methods in both computer-generated and real-world
categorical data.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01567" title="Abstract">arXiv:2312.01567</a> [<a href="/pdf/2312.01567" title="Download PDF">pdf</a>, <a href="/format/2312.01567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Automated Quantum Variational Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subasi%2C+O">Omer Subasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this work, we address the problem of automating quantum variational
machine learning. We develop a multi-locality parallelizable search algorithm,
called MUSE, to find the initial points and the sets of parameters that achieve
the best performance for quantum variational circuit learning. Simulations with
five real-world classification datasets indicate that on average, MUSE improves
the detection accuracy of quantum variational classifiers 2.3 times with
respect to the observed lowest scores. Moreover, when applied to two real-world
regression datasets, MUSE improves the quality of the predictions from negative
coefficients of determination to positive ones. Furthermore, the classification
and regression scores of the quantum variational models trained with MUSE are
on par with the classical counterparts.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01568" title="Abstract">arXiv:2312.01568</a> [<a href="/pdf/2312.01568" title="Download PDF">pdf</a>, <a href="/format/2312.01568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Speech Emotion Recognition Using Modality-specific  Self-Supervised Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patamia%2C+R+A">Rutherford Agbeshi Patamia</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P+E">Paulo E. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Acheampong%2C+K+N">Kingsley Nketia Acheampong</a>, 
<a href="/search/cs?searchtype=author&query=Ekong%2C+F">Favour Ekong</a>, 
<a href="/search/cs?searchtype=author&query=Sarpong%2C+K">Kwabena Sarpong</a>, 
<a href="/search/cs?searchtype=author&query=Kun%2C+S">She Kun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Emotion recognition is a topic of significant interest in assistive robotics
due to the need to equip robots with the ability to comprehend human behavior,
facilitating their effective interaction in our society. Consequently,
efficient and dependable emotion recognition systems supporting optimal
human-machine communication are required. Multi-modality (including speech,
audio, text, images, and videos) is typically exploited in emotion recognition
tasks. Much relevant research is based on merging multiple data modalities and
training deep learning models utilizing low-level data representations.
However, most existing emotion databases are not large (or complex) enough to
allow machine learning approaches to learn detailed representations. This paper
explores modalityspecific pre-trained transformer frameworks for
self-supervised learning of speech and text representations for data-efficient
emotion recognition while achieving state-of-the-art performance in recognizing
emotions. This model applies feature-level fusion using nonverbal cue data
points from motion capture to provide multimodal speech emotion recognition.
The model was trained using the publicly available IEMOCAP dataset, achieving
an overall accuracy of 77.58% for four emotions, outperforming state-of-the-art
approaches
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01571" title="Abstract">arXiv:2312.01571</a> [<a href="/pdf/2312.01571" title="Download PDF">pdf</a>, <a href="/format/2312.01571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Configure Good In-Context Sequence for Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiawei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Inspired by the success of Large Language Models in dealing with new tasks
via In-Context Learning (ICL) in NLP, researchers have also developed Large
Vision-Language Models (LVLMs) with ICL capabilities. However, when
implementing ICL using these LVLMs, researchers usually resort to the simplest
way like random sampling to configure the in-context sequence, thus leading to
sub-optimal results. To enhance the ICL performance, in this study, we use
Visual Question Answering (VQA) as case study to explore diverse in-context
configurations to find the powerful ones. Additionally, through observing the
changes of the LVLM outputs by altering the in-context sequence, we gain
insights into the inner properties of LVLMs, improving our understanding of
them. Specifically, to explore in-context configurations, we design diverse
retrieval methods and employ different strategies to manipulate the retrieved
demonstrations. Through exhaustive experiments on three VQA datasets: VQAv2,
VizWiz, and OK-VQA, we uncover three important inner properties of the applied
LVLM and demonstrate which strategies can consistently improve the ICL VQA
performance. Our code is provided in:
https://github.com/GaryJiajia/OFv2_ICL_VQA.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01575" title="Abstract">arXiv:2312.01575</a> [<a href="/pdf/2312.01575" title="Download PDF">pdf</a>, <a href="/format/2312.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Challenging Multimodal Video Summary: Simultaneously Extracting and  Generating Keyframe-Caption Pairs from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudo%2C+K">Keito Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Nagasawa%2C+H">Haruki Nagasawa</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+J">Jun Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Shimizu%2C+N">Nobuyuki Shimizu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper proposes a practical multimodal video summarization task setting
and a dataset to train and evaluate the task. The target task involves
summarizing a given video into a predefined number of keyframe-caption pairs
and displaying them in a listable format to grasp the video content quickly.
This task aims to extract crucial scenes from the video in the form of images
(keyframes) and generate corresponding captions explaining each keyframe's
situation. This task is useful as a practical application and presents a highly
challenging problem worthy of study. Specifically, achieving simultaneous
optimization of the keyframe selection performance and caption quality
necessitates careful consideration of the mutual dependence on both preceding
and subsequent keyframes and captions. To facilitate subsequent research in
this field, we also construct a dataset by expanding upon existing datasets and
propose an evaluation framework. Furthermore, we develop two baseline systems
and report their respective performance.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01576" title="Abstract">arXiv:2312.01576</a> [<a href="/pdf/2312.01576" title="Download PDF">pdf</a>, <a href="/format/2312.01576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Efficient Unsupervised Satellite Image-based Building Damage  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yadan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Existing Building Damage Detection (BDD) methods always require
labour-intensive pixel-level annotations of buildings and their conditions,
hence largely limiting their applications. In this paper, we investigate a
challenging yet practical scenario of BDD, Unsupervised Building Damage
Detection (U-BDD), where only unlabelled pre- and post-disaster satellite image
pairs are provided. As a pilot study, we have first proposed an advanced U-BDD
baseline that leverages pre-trained vision-language foundation models (i.e.,
Grounding DINO, SAM and CLIP) to address the U-BDD task. However, the apparent
domain gap between satellite and generic images causes low confidence in the
foundation models used to identify buildings and their damages. In response, we
further present a novel self-supervised framework, U-BDD++, which improves upon
the U-BDD baseline by addressing domain-specific issues associated with
satellite imagery. Furthermore, the new Building Proposal Generation (BPG)
module and the CLIP-enabled noisy Building Proposal Selection (CLIP-BPS) module
in U-BDD++ ensure high-quality self-training. Extensive experiments on the
widely used building damage assessment benchmark demonstrate the effectiveness
of the proposed method for unsupervised building damage detection. The
presented annotation-free and foundation model-based paradigm ensures an
efficient learning phase. This study opens a new direction for real-world BDD
and sets a strong baseline for future research.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01577" title="Abstract">arXiv:2312.01577</a> [<a href="/pdf/2312.01577" title="Download PDF">pdf</a>, <a href="/format/2312.01577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RJHMC-Tree for Exploration of the Bayesian Decision Tree Posterior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cochrane%2C+J+A">Jodie A. Cochrane</a>, 
<a href="/search/cs?searchtype=author&query=Wills%2C+A+G">Adrian G. Wills</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+S+J">Sarah J. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Decision trees have found widespread application within the machine learning
community due to their flexibility and interpretability. This paper is directed
towards learning decision trees from data using a Bayesian approach, which is
challenging due to the potentially enormous parameter space required to span
all tree models. Several approaches have been proposed to combat this
challenge, with one of the more successful being Markov chain Monte Carlo
(MCMC) methods. The efficacy and efficiency of MCMC methods fundamentally rely
on the quality of the so-called proposals, which is the focus of this paper. In
particular, this paper investigates using a Hamiltonian Monte Carlo (HMC)
approach to explore the posterior of Bayesian decision trees more efficiently
by exploiting the geometry of the likelihood within a global update scheme. Two
implementations of the novel algorithm are developed and compared to existing
methods by testing against standard datasets in the machine learning and
Bayesian decision tree literature. HMC-based methods are shown to perform
favourably with respect to predictive test accuracy, acceptance rate, and tree
complexity.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01581" title="Abstract">arXiv:2312.01581</a> [<a href="/pdf/2312.01581" title="Download PDF">pdf</a>, <a href="/format/2312.01581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signed Binarization: Unlocking Efficiency Through Repetition-Sparsity  Trade-Off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuhar%2C+S">Sachit Kuhar</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+Y">Yash Jain</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Efficient inference of Deep Neural Networks (DNNs) on resource-constrained
edge devices is essential. Quantization and sparsity are key algorithmic
techniques that translate to repetition and sparsity within tensors at the
hardware-software interface. This paper introduces the concept of
repetition-sparsity trade-off that helps explain computational efficiency
during inference. We propose Signed Binarization, a unified co-design framework
that synergistically integrates hardware-software systems, quantization
functions, and representation learning techniques to address this trade-off.
Our results demonstrate that Signed Binarization is more accurate than
binarization with the same number of non-zero weights. Detailed analysis
indicates that signed binarization generates a smaller distribution of
effectual (non-zero) parameters nested within a larger distribution of total
parameters, both of the same type, for a DNN block. Finally, our approach
achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces
density by 2.8x compared to binary methods for ResNet 18, presenting an
alternative solution for deploying efficient models in resource-limited
environments.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01582" title="Abstract">arXiv:2312.01582</a> [<a href="/pdf/2312.01582" title="Download PDF">pdf</a>, <a href="/format/2312.01582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining with Contrastive Phrasal Highlighting: A Case Study in  Assisting Humans to Detect Translation Differences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briakou%2C+E">Eleftheria Briakou</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+N">Navita Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Explainable NLP techniques primarily explain by answering "Which tokens in
the input are responsible for this prediction?''. We argue that for NLP models
that make predictions by comparing two input texts, it is more useful to
explain by answering "What differences between the two inputs explain this
prediction?''. We introduce a technique to generate contrastive highlights that
explain the predictions of a semantic divergence model via
phrase-alignment-guided erasure. We show that the resulting highlights match
human rationales of cross-lingual semantic differences better than popular
post-hoc saliency techniques and that they successfully help people detect
fine-grained meaning differences in human translations and critical machine
translation errors.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01583" title="Abstract">arXiv:2312.01583</a> [<a href="/pdf/2312.01583" title="Download PDF">pdf</a>, <a href="/format/2312.01583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Collision Detection Oriented Motion Primitives for Path  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DallaLibera%2C+F">Fabio DallaLibera</a>, 
<a href="/search/cs?searchtype=author&query=Shinya%2C+A">Abe Shinya</a>, 
<a href="/search/cs?searchtype=author&query=Takeshi%2C+A">Ando Takeshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Mobile robots in dynamic environments require fast planning, especially when
onboard computational resources are limited. While classic potential field
based algorithms may suffice in simple scenarios, in most cases algorithms able
to escape local minima are necessary. Configuration-space search algorithms
have proven to provide a good trade-off between quality of the solutions and
search time. Literature presents a wide variety of approaches that speed up
this search by reducing the number of edges that need to be inspected. Much
less attention was instead given to reducing the time necessary to evaluate the
cost of a single edge. This paper addresses this point by associating edges to
motion primitives that prioritize fast collision detection. We show how biarcs
can be used as motion primitives that enable fast collision detection, while
still providing smooth, tangent continuous paths. The proposed approach does
not assume a disc shaped hitbox, making it appealing for all robots with very
different width and length or for differential drive robots with active wheels
located far from the robot's center.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01585" title="Abstract">arXiv:2312.01585</a> [<a href="/pdf/2312.01585" title="Download PDF">pdf</a>, <a href="/format/2312.01585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCGEC: One-class Graph Embedding Classification for DNN Backdoor  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+P">Ping Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks (DNNs) have been found vulnerable to backdoor attacks,
raising security concerns about their deployment in mission-critical
applications. There are various approaches to detect backdoor attacks, however
they all make certain assumptions about the target attack to be detected and
require equal and huge numbers of clean and backdoor samples for training,
which renders these detection methods quite limiting in real-world
circumstances.
<br />This study proposes a novel one-class classification framework called
One-class Graph Embedding Classification (OCGEC) that uses GNNs for model-level
backdoor detection with only a little amount of clean data. First, we train
thousands of tiny models as raw datasets from a small number of clean datasets.
Following that, we design a ingenious model-to-graph method for converting the
model's structural details and weight features into graph data. We then
pre-train a generative self-supervised graph autoencoder (GAE) to better learn
the features of benign models in order to detect backdoor models without
knowing the attack strategy. After that, we dynamically combine the GAE and
one-class classifier optimization goals to form classification boundaries that
distinguish backdoor models from benign models.
<br />Our OCGEC combines the powerful representation capabilities of graph neural
networks with the utility of one-class classification techniques in the field
of anomaly detection. In comparison to other baselines, it achieves AUC scores
of more than 98% on a number of tasks, which far exceeds existing methods for
detection even when they rely on a huge number of positive and negative
samples. Our pioneering application of graphic scenarios for generic backdoor
detection can provide new insights that can be used to improve other backdoor
defense tasks. Code is available at https://github.com/jhy549/OCGEC.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01587" title="Abstract">arXiv:2312.01587</a> [<a href="/pdf/2312.01587" title="Download PDF">pdf</a>, <a href="/format/2312.01587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Independent Learning of Nash Equilibrium Policies in  $n$-Player Stochastic Games with Unknown Independent Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tiancheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Etesami%2C+S+R">S. Rasoul Etesami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study a subclass of $n$-player stochastic games, namely, stochastic games
with independent chains and unknown transition matrices. In this class of
games, players control their own internal Markov chains whose transitions do
not depend on the states/actions of other players. However, players' decisions
are coupled through their payoff functions. We assume players can receive only
realizations of their payoffs, and that the players can not observe the states
and actions of other players, nor do they know the transition probability
matrices of their own Markov chain. Relying on a compact dual formulation of
the game based on occupancy measures and the technique of confidence set to
maintain high-probability estimates of the unknown transition matrices, we
propose a fully decentralized mirror descent algorithm to learn an
$\epsilon$-NE for this class of games. The proposed algorithm has the desired
properties of independence, scalability, and convergence. Specifically, under
no assumptions on the reward functions, we show the proposed algorithm
converges in polynomial time in a weaker distance (namely, the averaged
Nikaido-Isoda gap) to the set of $\epsilon$-NE policies with arbitrarily high
probability. Moreover, assuming the existence of a variationally stable Nash
equilibrium policy, we show that the proposed algorithm converges
asymptotically to the stable $\epsilon$-NE policy with arbitrarily high
probability. In addition to Markov potential games and linear-quadratic
stochastic games, this work provides another subclass of $n$-player stochastic
games that, under some mild assumptions, admit polynomial-time learning
algorithms for finding their stationary $\epsilon$-NE policies.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01588" title="Abstract">arXiv:2312.01588</a> [<a href="/pdf/2312.01588" title="Download PDF">pdf</a>, <a href="/format/2312.01588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ActiveClean: Generating Line-Level Vulnerability Data via Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshy%2C+A+K">Ashwin Kallingal Joshy</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+S">Mirza Sanjida Alam</a>, 
<a href="/search/cs?searchtype=author&query=Sharmin%2C+S">Shaila Sharmin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+W">Wei Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning vulnerability detection tools are increasing in popularity and
have been shown to be effective. These tools rely on large volume of high
quality training data, which are very hard to get. Most of the currently
available datasets provide function-level labels, reporting whether a function
is vulnerable or not vulnerable. However, for a vulnerability detection to be
useful, we need to also know the lines that are relevant to the vulnerability.
This paper makes efforts towards developing systematic tools and proposes.
ActiveClean to generate the large volume of line-level vulnerability data from
commits. That is, in addition to function-level labels, it also reports which
lines in the function are likely responsible for vulnerability detection. In
the past, static analysis has been applied to clean commits to generate
line-level data. Our approach based on active learning, which is easy to use
and scalable, provide a complementary approach to static analysis. We designed
semantic and syntactic properties from commit lines and use them to train the
model. We evaluated our approach on both Java and C datasets processing more
than 4.3K commits and 119K commit lines. AcitveClean achieved an F1 score
between 70-74. Further, we also show that active learning is effective by using
just 400 training data to reach F1 score of 70.23. Using ActiveClean, we
generate the line-level labels for the entire FFMpeg project in the Devign
dataset, including 5K functions, and also detected incorrect function-level
labels. We demonstrated that using our cleaned data, LineVul, a SOTA line-level
vulnerability detection tool, detected 70 more vulnerable lines and 18 more
vulnerable functions, and improved Top 10 accuracy from 66% to 73%.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01589" title="Abstract">arXiv:2312.01589</a> [<a href="/pdf/2312.01589" title="Download PDF">pdf</a>, <a href="/format/2312.01589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Euclidean Bottleneck Steiner Tree is Fixed-Parameter Tractable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandyapadhyay%2C+S">Sayan Bandyapadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Lochet%2C+W">William Lochet</a>, 
<a href="/search/cs?searchtype=author&query=Lokshtanov%2C+D">Daniel Lokshtanov</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jie Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SODA'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In the Euclidean Bottleneck Steiner Tree problem, the input consists of a set
of $n$ points in $\mathbb{R}^2$ called terminals and a parameter $k$, and the
goal is to compute a Steiner tree that spans all the terminals and contains at
most $k$ points of $\mathbb{R}^2$ as Steiner points such that the maximum
edge-length of the Steiner tree is minimized, where the length of a tree edge
is the Euclidean distance between its two endpoints. The problem is
well-studied and is known to be NP-hard. In this paper, we give a $k^{O(k)}
n^{O(1)}$-time algorithm for Euclidean Bottleneck Steiner Tree, which implies
that the problem is fixed-parameter tractable (FPT). This settles an open
question explicitly asked by Bae et al. [Algorithmica, 2011], who showed that
the $\ell_1$ and $\ell_{\infty}$ variants of the problem are FPT. Our approach
can be generalized to the problem with $\ell_p$ metric for any rational $1 \le
p \le \infty$, or even other metrics on $\mathbb{R}^2$.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01592" title="Abstract">arXiv:2312.01592</a> [<a href="/pdf/2312.01592" title="Download PDF">pdf</a>, <a href="/format/2312.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu-Le%2C+T">The-Anh Vu-Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+T">Tho Quan</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models have been supervised with both language-only objective and
visual grounding in existing studies of visual-grounded language learning.
However, due to differences in the distribution and scale of visual-grounded
datasets and language corpora, the language model tends to mix up the context
of the tokens that occurred in the grounded data with those that do not. As a
result, during representation learning, there is a mismatch between the visual
information and the contextual meaning of the sentence. To overcome this
limitation, we propose GroundedBERT - a grounded language learning method that
enhances the BERT representation with visually grounded information.
GroundedBERT comprises two components: (i) the original BERT which captures the
contextual representation of words learned from the language corpora, and (ii)
a visual grounding module which captures visual information learned from
visual-grounded datasets. Moreover, we employ Optimal Transport (OT),
specifically its partial variant, to solve the fractional alignment problem
between the two modalities. Our proposed method significantly outperforms the
baseline language models on various language tasks of the GLUE and SQuAD
datasets.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01597" title="Abstract">arXiv:2312.01597</a> [<a href="/pdf/2312.01597" title="Download PDF">pdf</a>, <a href="/format/2312.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in contrastive language-image pretraining (CLIP) have
demonstrated strong capabilities in zero-shot classification by aligning visual
representations with target text embeddings in an image level. However, in
dense prediction tasks, CLIP often struggles to localize visual features within
an image and fails to give accurate pixel-level predictions, which prevents it
from functioning as a generalized visual foundation model. In this work, we aim
to enhance CLIP's potential for semantic segmentation with minimal
modifications to its pretrained models. By rethinking self-attention, we
surprisingly find that CLIP can adapt to dense prediction tasks by simply
introducing a novel Correlative Self-Attention (CSA) mechanism. Specifically,
we replace the traditional self-attention block of CLIP vision encoder's last
layer by our CSA module and reuse its pretrained projection matrices of query,
key, and value, leading to a training-free adaptation approach for CLIP's
zero-shot semantic segmentation. Extensive experiments show the advantage of
CSA: we obtain a 38.2% average zero-shot mIoU across eight semantic
segmentation benchmarks highlighted in this paper, significantly outperforming
the existing SoTA's 33.9% and the vanilla CLIP's 14.1%.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01598" title="Abstract">arXiv:2312.01598</a> [<a href="/pdf/2312.01598" title="Download PDF">pdf</a>, <a href="/format/2312.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Good Questions Help Zero-Shot Image Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaiwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xinmei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiubo Geng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aligning the recent large language models (LLMs) with computer vision models
leads to large vision-language models (LVLMs), which have paved the way for
zero-shot image reasoning tasks. However, LVLMs are usually trained on short
high-level captions only referring to sparse focus regions in images. Such a
``tunnel vision'' limits LVLMs to exploring other relevant contexts in complex
scenes. To address this challenge, we introduce Question-Driven Visual
Exploration (QVix), a novel prompting strategy that enhances the exploratory
capabilities of LVLMs in zero-shot reasoning tasks. QVix leverages LLMs' strong
language prior to generate input-exploratory questions with more details than
the original query, guiding LVLMs to explore visual content more
comprehensively and uncover subtle or peripheral details. QVix enables a wider
exploration of visual scenes, improving the LVLMs' reasoning accuracy and depth
in tasks such as visual question answering and visual entailment. Our
evaluations on various challenging zero-shot vision-language benchmarks,
including ScienceQA and fine-grained visual classification, demonstrate that
QVix significantly outperforms existing methods, highlighting its effectiveness
in bridging the gap between complex visual data and LVLMs' exploratory
abilities.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01601" title="Abstract">arXiv:2312.01601</a> [<a href="/pdf/2312.01601" title="Download PDF">pdf</a>, <a href="/format/2312.01601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local-Global History-aware Contrastive Learning for Temporal Knowledge  Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Huaiyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuting Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiayaqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, Accept ICDE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Temporal knowledge graphs (TKGs) have been identified as a promising approach
to represent the dynamics of facts along the timeline. The extrapolation of TKG
is to predict unknowable facts happening in the future, holding significant
practical value across diverse fields. Most extrapolation studies in TKGs focus
on modeling global historical fact repeating and cyclic patterns, as well as
local historical adjacent fact evolution patterns, showing promising
performance in predicting future unknown facts. Yet, existing methods still
face two major challenges: (1) They usually neglect the importance of
historical information in KG snapshots related to the queries when encoding the
local and global historical information; (2) They exhibit weak anti-noise
capabilities, which hinders their performance when the inputs are contaminated
with noise.To this end, we propose a novel \blue{Lo}cal-\blue{g}lobal
history-aware \blue{C}ontrastive \blue{L}earning model (\blue{LogCL}) for TKG
reasoning, which adopts contrastive learning to better guide the fusion of
local and global historical information and enhance the ability to resist
interference. Specifically, for the first challenge, LogCL proposes an
entity-aware attention mechanism applied to the local and global historical
facts encoder, which captures the key historical information related to
queries. For the latter issue, LogCL designs four historical query contrast
patterns, effectively improving the robustness of the model. The experimental
results on four benchmark datasets demonstrate that LogCL delivers better and
more robust performance than the state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01605" title="Abstract">arXiv:2312.01605</a> [<a href="/pdf/2312.01605" title="Download PDF">pdf</a>, <a href="/format/2312.01605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextAug: Test time Text Augmentation for Multimodal Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fawakherji%2C+M">Mulham Fawakherji</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+E">Eduard Vazquez</a>, 
<a href="/search/cs?searchtype=author&query=Giampa%2C+P">Pasquale Giampa</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+B">Binod Bhattarai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal Person Reidentification is gaining popularity in the research
community due to its effectiveness compared to counter-part unimodal
frameworks. However, the bottleneck for multimodal deep learning is the need
for a large volume of multimodal training examples. Data augmentation
techniques such as cropping, flipping, rotation, etc. are often employed in the
image domain to improve the generalization of deep learning models. Augmenting
in other modalities than images, such as text, is challenging and requires
significant computational resources and external data sources. In this study,
we investigate the effectiveness of two computer vision data augmentation
techniques: cutout and cutmix, for text augmentation in multi-modal person
re-identification. Our approach merges these two augmentation strategies into
one strategy called CutMixOut which involves randomly removing words or
sub-phrases from a sentence (Cutout) and blending parts of two or more
sentences to create diverse examples (CutMix) with a certain probability
assigned to each operation. This augmentation was implemented at inference time
without any prior training. Our results demonstrate that the proposed technique
is simple and effective in improving the performance on multiple multimodal
person re-identification benchmarks.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01606" title="Abstract">arXiv:2312.01606</a> [<a href="/pdf/2312.01606" title="Download PDF">pdf</a>, <a href="/ps/2312.01606" title="Download PostScript">ps</a>, <a href="/format/2312.01606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Driven Enhancement of Welding Quality Control: Predicting  Welding Depth and Pore Volume in Hairpin Welding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darwish%2C+A">Amena Darwish</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+S">Stefan Ericson</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+R">Rohollah Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Andersson%2C+T">Tobias Andersson</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6nn%2C+D">Dan L&#xf6;nn</a>, 
<a href="/search/cs?searchtype=author&query=Lassila%2C+A+A">Andreas Andersson Lassila</a>, 
<a href="/search/cs?searchtype=author&query=Salomonsson%2C+K">Kent Salomonsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">To advance quality assurance in the welding process, this study presents a
robust deep learning model that enables the prediction of two critical welds
Key Performance Characteristics (KPCs): welding depth and average pore volume.
In the proposed approach, a comprehensive range of laser welding Key Input
Characteristics (KICs) is utilized, including welding beam geometries, welding
feed rates, path repetitions for weld beam geometries, and bright light weld
ratios for all paths, all of which were obtained from hairpin welding
experiments. Two deep learning networks are employed with multiple hidden dense
layers and linear activation functions to showcase the capabilities of deep
neural networks in capturing the intricate nonlinear connections inherent
within welding KPCs and KICs. Applying deep learning networks to the small
numerical experimental hairpin welding dataset has shown promising results,
achieving Mean Absolute Error (MAE) values as low as 0.1079 for predicting
welding depth and 0.0641 for average pore volume. Additionally, the validity
verification demonstrates the reliability of the proposed method. This, in
turn, promises significant advantages in controlling welding outcomes, moving
beyond the current trend of relying merely on monitoring for defect
classification.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01607" title="Abstract">arXiv:2312.01607</a> [<a href="/pdf/2312.01607" title="Download PDF">pdf</a>, <a href="/format/2312.01607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo Experiments of Network Effects in Randomized Controlled  Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trencs%C3%A9ni%2C+M">M&#xe1;rton Trencs&#xe9;ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">I run Monte Carlo simulations of content production over random
Watts-Strogatz graphs to show various effects relevant to modeling and
understanding Randomized Controlled Trials on social networks: the network
effect, spillover effect, experiment dampening effect, intrinsic dampening
effect, clustering effect, degree distribution effect and the experiment size
effect. I will also define some simple metrics to measure their strength. When
running experiments these potentially unexpected effects must be understood and
controlled for in some manner, such as modeling the underlying graph structure
to establish a baseline.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01612" title="Abstract">arXiv:2312.01612</a> [<a href="/pdf/2312.01612" title="Download PDF">pdf</a>, <a href="/format/2312.01612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xNeuSM: Explainable Neural Subgraph Matching with Graph Learnable  Multi-hop Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Duc Q. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Thanh Toan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=quan%2C+T">Tho quan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Subgraph matching is a challenging problem with a wide range of applications
in database systems, biochemistry, and cognitive science. It involves
determining whether a given query graph is present within a larger target
graph. Traditional graph-matching algorithms provide precise results but face
challenges in large graph instances due to the NP-complete problem, limiting
their practical applicability. In contrast, recent neural network-based
approximations offer more scalable solutions, but often lack interpretable node
correspondences. To address these limitations, this article presents xNeuSM:
Explainable Neural Subgraph Matching which introduces Graph Learnable Multi-hop
Attention Networks (GLeMA) that adaptively learns the parameters governing the
attention factor decay for each node across hops rather than relying on fixed
hyperparameters. We provide a theoretical analysis establishing error bounds
for GLeMA's approximation of multi-hop attention as a function of the number of
hops. Additionally, we prove that learning distinct attention decay factors for
each node leads to a correct approximation of multi-hop attention. Empirical
evaluation on real-world datasets shows that xNeuSM achieves substantial
improvements in prediction accuracy of up to 34% compared to approximate
baselines and, notably, at least a seven-fold faster query time than exact
algorithms. The source code of our implementation is available at
https://github.com/martinakaduc/xNeuSM.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01616" title="Abstract">arXiv:2312.01616</a> [<a href="/pdf/2312.01616" title="Download PDF">pdf</a>, <a href="/format/2312.01616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yunfei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guidong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accuracy and computational efficiency are the most important metrics to
Visual Inertial Navigation System (VINS). The existing VINS algorithms with
either high accuracy or low computational complexity, are difficult to provide
the high precision localization in resource-constrained devices. To this end,
we propose a novel filter-based VINS framework named SchurVINS, which could
guarantee both high accuracy by building a complete residual model and low
computational complexity with Schur complement. Technically, we first formulate
the full residual model where Gradient, Hessian and observation covariance are
explicitly modeled. Then Schur complement is employed to decompose the full
model into ego-motion residual model and landmark residual model. Finally,
Extended Kalman Filter (EKF) update is implemented in these two models with
high efficiency. Experiments on EuRoC and TUM-VI datasets show that our method
notably outperforms state-of-the-art (SOTA) methods in both accuracy and
computational complexity. We will open source our experimental code to benefit
the community.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01617" title="Abstract">arXiv:2312.01617</a> [<a href="/pdf/2312.01617" title="Download PDF">pdf</a>, <a href="/format/2312.01617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heroes: Lightweight Federated Learning with Neural Composition and  Adaptive Local Update in Heterogeneous Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiaming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianchun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianhua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 9 figures, to be published in INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Federated Learning (FL) enables distributed clients to collaboratively train
models without exposing their private data. However, it is difficult to
implement efficient FL due to limited resources. Most existing works compress
the transmitted gradients or prune the global model to reduce the resource
cost, but leave the compressed or pruned parameters under-optimized, which
degrades the training performance. To address this issue, the neural
composition technique constructs size-adjustable models by composing low-rank
tensors, allowing every parameter in the global model to learn the knowledge
from all clients. Nevertheless, some tensors can only be optimized by a small
fraction of clients, thus the global model may get insufficient training,
leading to a long completion time, especially in heterogeneous edge scenarios.
To this end, we enhance the neural composition technique, enabling all
parameters to be fully trained. Further, we propose a lightweight FL framework,
called Heroes, with enhanced neural composition and adaptive local update. A
greedy-based algorithm is designed to adaptively assign the proper tensors and
local update frequencies for participating clients according to their
heterogeneous capabilities and resource budgets. Extensive experiments
demonstrate that Heroes can reduce traffic consumption by about 72.05\% and
provide up to 2.97$\times$ speedup compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01619" title="Abstract">arXiv:2312.01619</a> [<a href="/pdf/2312.01619" title="Download PDF">pdf</a>, <a href="/format/2312.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Validation Labels Do You Need? Exploring the Design Space of  Label-Efficient Model Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The paper introduces LEMR, a framework that reduces annotation costs for
model selection tasks. Our approach leverages ensemble methods to generate
pseudo-labels, employs uncertainty sampling for target acquisition, and
utilizes a Z-score mechanism for iterative committee reelection to refine model
ranks. We present a systematic study across various selection metrics,
demonstrating that LEMR achieves comparable results to fully labeled datasets
with a fraction of the labeling budget. Our findings indicate that LEMR not
only economizes the labeling effort in weak supervision and semi-supervised
learning settings but also effectively guides prompt selection for large
language models. With extensive experiments across 23 tasks, we reveal that our
framework can dramatically decrease the labeling cost without compromising the
accuracy of model selection, thereby offering a cost-effective alternative to
traditional practices.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01623" title="Abstract">arXiv:2312.01623</a> [<a href="/pdf/2312.01623" title="Download PDF">pdf</a>, <a href="/format/2312.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Segmentation at Arbitrary Granularity with Language  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cairong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper aims to achieve universal segmentation of arbitrary semantic
level. Despite significant progress in recent years, specialist segmentation
approaches are limited to specific tasks and data distribution. Retraining a
new model for adaptation to new scenarios or settings takes expensive
computation and time cost, which raises the demand for versatile and universal
segmentation model that can cater to various granularity. Although some
attempts have been made for unifying different segmentation tasks or
generalization to various scenarios, limitations in the definition of paradigms
and input-output spaces make it difficult for them to achieve accurate
understanding of content at arbitrary granularity. To this end, we present
UniLSeg, a universal segmentation model that can perform segmentation at any
semantic level with the guidance of language instructions. For training
UniLSeg, we reorganize a group of tasks from original diverse distributions
into a unified data format, where images with texts describing segmentation
targets as input and corresponding masks are output. Combined with a automatic
annotation engine for utilizing numerous unlabeled data, UniLSeg achieves
excellent performance on various tasks and settings, surpassing both specialist
and unified segmentation models.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01624" title="Abstract">arXiv:2312.01624</a> [<a href="/pdf/2312.01624" title="Download PDF">pdf</a>, <a href="/format/2312.01624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVFs in the Real World: Making Predictions Online for Water Treatment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janjua%2C+M+K">Muhammad Kamran Janjua</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Haseeb Shah</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+M">Martha White</a>, 
<a href="/search/cs?searchtype=author&query=Miahi%2C+E">Erfan Miahi</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+M+C">Marlos C. Machado</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A">Adam White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Machine Learning (2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning (2023): 1-31
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper we investigate the use of reinforcement-learning based
prediction approaches for a real drinking-water treatment plant. Developing
such a prediction system is a critical step on the path to optimizing and
automating water treatment. Before that, there are many questions to answer
about the predictability of the data, suitable neural network architectures,
how to overcome partial observability and more. We first describe this dataset,
and highlight challenges with seasonality, nonstationarity, partial
observability, and heterogeneity across sensors and operation modes of the
plant. We then describe General Value Function (GVF) predictions -- discounted
cumulative sums of observations -- and highlight why they might be preferable
to classical n-step predictions common in time series prediction. We discuss
how to use offline data to appropriately pre-train our temporal difference
learning (TD) agents that learn these GVF predictions, including how to select
hyperparameters for online fine-tuning in deployment. We find that the
TD-prediction agent obtains an overall lower normalized mean-squared error than
the n-step prediction agent. Finally, we show the importance of learning in
deployment, by comparing a TD agent trained purely offline with no online
updating to a TD agent that learns online. This final result is one of the
first to motivate the importance of adapting predictions in real-time, for
non-stationary high-volume systems in the real world.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01625" title="Abstract">arXiv:2312.01625</a> [<a href="/pdf/2312.01625" title="Download PDF">pdf</a>, <a href="/ps/2312.01625" title="Download PostScript">ps</a>, <a href="/format/2312.01625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interference-Constrained Scheduling of a Cognitive Multi-hop Underwater  Acoustic Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+C">Chen Peng</a>, 
<a href="/search/eess?searchtype=author&query=Mitra%2C+U">Urbashi Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper investigates optimal scheduling for a cognitive multi-hop
underwater acoustic network with a primary user interference constraint. The
network consists of primary and secondary users, with multi-hop transmission
adopted for both user types to provide reliable communications. Critical
characteristics of underwater acoustic channels, including significant
propagation delay, distance-and-frequency dependent attenuation, half-duplex
modem, and inter-hop interference, are taken into account in the design and
analysis. In particular, time-slot allocation is found to be more effective
than frequency-slot allocation due to the underwater channel model. The goal of
the network scheduling problem is to maximize the end-to-end throughput of the
overall system while limiting the throughput loss of primary users. Both
centralized and decentralized approaches are considered. Partially Observable
Markov Decision Processes (POMDP) framework is applied to formulate the
optimization problem, and an optimal dynamic programming algorithm is derived.
However, the optimal dynamic programming solution is computationally
intractable. Key properties are shown for the objective function, enabling the
design of approximate schemes with significant complexity reduction. Numerical
results show that the proposed schemes significantly increase system throughput
while maintaining the primary throughput loss constraint. Under certain traffic
conditions, the throughput gain over frequency-slot allocation schemes can be
as high as 50%.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01627" title="Abstract">arXiv:2312.01627</a> [<a href="/pdf/2312.01627" title="Download PDF">pdf</a>, <a href="/ps/2312.01627" title="Download PostScript">ps</a>, <a href="/format/2312.01627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teachers&#x27; trust and perceptions of AI in education: The role of culture  and AI self-efficacy in six countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viberg%2C+O">Olga Viberg</a>, 
<a href="/search/cs?searchtype=author&query=Cukurova%2C+M">Mutlu Cukurova</a>, 
<a href="/search/cs?searchtype=author&query=Feldman-Maggor%2C+Y">Yael Feldman-Maggor</a>, 
<a href="/search/cs?searchtype=author&query=Alexandron%2C+G">Giora Alexandron</a>, 
<a href="/search/cs?searchtype=author&query=Shirai%2C+S">Shizuka Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Kanemune%2C+S">Susumu Kanemune</a>, 
<a href="/search/cs?searchtype=author&query=Wasson%2C+B">Barbara Wasson</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B8mte%2C+C">Cathrine T&#xf8;mte</a>, 
<a href="/search/cs?searchtype=author&query=Spikol%2C+D">Daniel Spikol</a>, 
<a href="/search/cs?searchtype=author&query=Milrad%2C+M">Marcelo Milrad</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+R">Raquel Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Kizilcec%2C+R+F">Ren&#xe9; F. Kizilcec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">AI-based educational technology (AI-EdTech) is increasingly adopted in K-12
education. Teachers play a critical role in this process as they are expected
to use AI-EdTech in ways that support their teaching practice and students'
learning outcomes. Teachers' willingness to meaningfully integrate these
technologies into their everyday educational activities depends on their
attitudes toward AI-EdTech. We surveyed 508 K-12 teachers in six countries
across four continents (Brazil, Israel, Japan, Norway, Sweden, USA) about the
perceived benefits of, concerns about, and trust in AI-EdTech. We examine
demographic, geo-cultural, professional, and psychological factors that might
influence teachers' attitudes. Our results showed that teachers with higher AI
understanding and self-efficacy perceive more benefits, fewer concerns, and
stronger trust. We also found geographic and cultural differences in teachers'
attitudes, including their trust in AI-EdTech, but no demographic differences
emerged based on their age, gender, or level of education. The findings provide
a comprehensive, international account of factors influencing teachers'
attitudes toward AI-EdTech. Efforts to raise teachers' understanding of, and
trust in AI-EdTech, while considering their cultural values are encouraged to
support its adoption in K-12 education.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01629" title="Abstract">arXiv:2312.01629</a> [<a href="/pdf/2312.01629" title="Download PDF">pdf</a>, <a href="/format/2312.01629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAMP: Contrastive LAnguage Model Prompt-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teterwak%2C+P">Piotr Teterwak</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Ximeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have emerged as powerful general-purpose
interfaces for many machine learning problems. Recent work has adapted LLMs to
generative visual tasks like image captioning, visual question answering, and
visual chat, using a relatively small amount of instruction-tuning data. In
this paper, we explore whether modern LLMs can also be adapted to classifying
an image into a set of categories. First, we evaluate multimodal LLMs that are
tuned for generative tasks on zero-shot image classification and find that
their performance is far below that of specialized models like CLIP. We then
propose an approach for light fine-tuning of LLMs using the same contrastive
image-caption matching objective as CLIP. Our results show that LLMs can,
indeed, achieve good image classification performance when adapted this way.
Our approach beats state-of-the-art mLLMs by 13% and slightly outperforms
contrastive learning with a custom text model, while also retaining the LLM's
generative abilities. LLM initialization appears to particularly help
classification in domains under-represented in the visual pre-training data.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01631" title="Abstract">arXiv:2312.01631</a> [<a href="/pdf/2312.01631" title="Download PDF">pdf</a>, <a href="/format/2312.01631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative vs. Teleoperation Control of the Steady Hand Eye Robot with  Adaptive Sclera Force Control: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+M">Mojtaba Esfandiari</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Ji Woong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Botao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Amirkhani%2C+G">Golchehr Amirkhani</a>, 
<a href="/search/cs?searchtype=author&query=Hadi%2C+M">Muhammad Hadi</a>, 
<a href="/search/cs?searchtype=author&query=Gehlbach%2C+P">Peter Gehlbach</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+R+H">Russell H. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I">Iulian Iordachita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A surgeon's physiological hand tremor can significantly impact the outcome of
delicate and precise retinal surgery, such as retinal vein cannulation (RVC)
and epiretinal membrane peeling. Robot-assisted eye surgery technology provides
ophthalmologists with advanced capabilities such as hand tremor cancellation,
hand motion scaling, and safety constraints that enable them to perform these
otherwise challenging and high-risk surgeries with high precision and safety.
Steady-Hand Eye Robot (SHER) with cooperative control mode can filter out
surgeon's hand tremor, yet another important safety feature, that is,
minimizing the contact force between the surgical instrument and sclera surface
for avoiding tissue damage cannot be met in this control mode. Also, other
capabilities, such as hand motion scaling and haptic feedback, require a
teleoperation control framework. In this work, for the first time, we
implemented a teleoperation control mode incorporated with an adaptive sclera
force control algorithm using a PHANTOM Omni haptic device and a force-sensing
surgical instrument equipped with Fiber Bragg Grating (FBG) sensors attached to
the SHER 2.1 end-effector. This adaptive sclera force control algorithm allows
the robot to dynamically minimize the tool-sclera contact force. Moreover, for
the first time, we compared the performance of the proposed adaptive
teleoperation mode with the cooperative mode by conducting a vessel-following
experiment inside an eye phantom under a microscope.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01632" title="Abstract">arXiv:2312.01632</a> [<a href="/pdf/2312.01632" title="Download PDF">pdf</a>, <a href="/format/2312.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianHead: Impressive 3D Gaussian-based Head Avatars with Dynamic  Hybrid Neural Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiucheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hao Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous head avatar methods have mostly relied on fixed explicit primitives
(mesh, point) or implicit surfaces (Sign Distance Function) and volumetric
neural radiance field, it challenging to strike a balance among high fidelity,
training speed, and resource consumption. The recent popularity of hybrid field
has brought novel representation, but is limited by relying on parameterization
factors obtained through fixed mappings. We propose GaussianHead: an head
avatar algorithm based on anisotropic 3D gaussian primitives. We leverage
canonical gaussians to represent dynamic scenes. Using explicit "dynamic"
tri-plane as an efficient container for parameterized head geometry, aligned
well with factors in the underlying geometry and tri-plane, we obtain aligned
canonical factors for the canonical gaussians. With a tiny MLP, factors are
decoded into opacity and spherical harmonic coefficients of 3D gaussian
primitives. Finally, we use efficient differentiable gaussian rasterizer for
rendering. Our approach benefits significantly from our novel representation
based on 3D gaussians, and the proper alignment transformation of underlying
geometry structures and factors in tri-plane eliminates biases introduced by
fixed mappings. Compared to state-of-the-art techniques, we achieve optimal
visual results in tasks such as self-reconstruction, novel view synthesis, and
cross-identity reenactment while maintaining high rendering efficiency (0.12s
per frame). Even the pores around the nose are clearly visible in some cases.
Code and additional video can be found on the project homepage.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01634" title="Abstract">arXiv:2312.01634</a> [<a href="/pdf/2312.01634" title="Download PDF">pdf</a>, <a href="/ps/2312.01634" title="Download PostScript">ps</a>, <a href="/format/2312.01634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Streaming, Sampling, and a Perspective on Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dogariu%2C+E">Evan Dogariu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiatong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work we present an overview of statistical learning, followed by a
survey of robust streaming techniques and challenges, culminating in several
rigorous results proving the relationship that we motivate and hint at
throughout the journey. Furthermore, we unify often disjoint theorems in a
shared framework and notation to clarify the deep connections that are
discovered. We hope that by approaching these results from a shared
perspective, already aware of the technical connections that exist, we can
enlighten the study of both fields and perhaps motivate new and previously
unconsidered directions of research.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01639" title="Abstract">arXiv:2312.01639</a> [<a href="/pdf/2312.01639" title="Download PDF">pdf</a>, <a href="/format/2312.01639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Large Language Models in Domain-Specific Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+C">Chengcheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Juhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaodong Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large language models (LLMs) such as ChatGPT have shown remarkable
capabilities in code generation. Despite their great success, their
effectiveness within particular domains (e.g., web development) necessitates
further evaluation. In this study, we conduct an empirical study of
domain-specific code generation with LLMs. We demonstrate that LLMs exhibit
sub-optimal performance in generating domain-specific code, due to their
limited proficiency in utilizing domain-specific libraries. We further observe
that incorporating API knowledge as prompts can empower LLMs to generate more
professional code. Based on these findings, we further investigate how to
efficiently incorporate API knowledge into the code generation process. We
experiment with three strategies for incorporating domain knowledge, namely,
external knowledge inquirer, chain-of-thought prompting, and chain-of-thought
fine-tuning. We refer to these strategies as a new code generation approach
called DomCoder. Experimental results show that all strategies of DomCoder lead
to improvement in the effectiveness of domain-specific code generation under
certain settings. The results also show that there is still ample room for
further improvement, based on which we suggest possible future works.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01640" title="Abstract">arXiv:2312.01640</a> [<a href="/pdf/2312.01640" title="Download PDF">pdf</a>, <a href="/format/2312.01640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SequencePAR: Understanding Pedestrian Attributes via A Sequence  Generation Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiandong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lili Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Current pedestrian attribute recognition (PAR) algorithms are developed based
on multi-label or multi-task learning frameworks, which aim to discriminate the
attributes using specific classification heads. However, these discriminative
models are easily influenced by imbalanced data or noisy samples. Inspired by
the success of generative models, we rethink the pedestrian attribute
recognition scheme and believe the generative models may perform better on
modeling dependencies and complexity between human attributes. In this paper,
we propose a novel sequence generation paradigm for pedestrian attribute
recognition, termed SequencePAR. It extracts the pedestrian features using a
pre-trained CLIP model and embeds the attribute set into query tokens under the
guidance of text prompts. Then, a Transformer decoder is proposed to generate
the human attributes by incorporating the visual features and attribute query
tokens. The masked multi-head attention layer is introduced into the decoder
module to prevent the model from remembering the next attribute while making
attribute predictions during training. Extensive experiments on multiple widely
used pedestrian attribute recognition datasets fully validated the
effectiveness of our proposed SequencePAR. The source code and pre-trained
models will be released at https://github.com/Event-AHU/OpenPAR.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01642" title="Abstract">arXiv:2312.01642</a> [<a href="/pdf/2312.01642" title="Download PDF">pdf</a>, <a href="/format/2312.01642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voice-Based Smart Assistant System for Vehicles using RASA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paranjape%2C+A">Aditya Paranjape</a>, 
<a href="/search/cs?searchtype=author&query=Patwardhan%2C+Y">Yash Patwardhan</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+V">Vedant Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Darp%2C+A">Aniket Darp</a>, 
<a href="/search/cs?searchtype=author&query=Jagdale%2C+J">Jayashree Jagdale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, accepted at IEEE International Conference on Computational Intelligence, Networks and Security ICCINS-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational AIs, or chatbots, mimic human speech when conversing. Smart
assistants facilitate the automation of several tasks that needed human
intervention earlier. Because of their accuracy, absence of dependence on human
resources, and accessibility around the clock, chatbots can be employed in
vehicles too. Due to people's propensity to divert their attention away from
the task of driving while engaging in other activities like calling, playing
music, navigation, and getting updates on the weather forecast and latest news,
road safety has declined and accidents have increased as a result. It would be
advantageous to automate these tasks using voice commands rather than carrying
them out manually. This paper focuses on the development of a voice-based smart
assistance application for vehicles based on the RASA framework. The smart
assistant provides functionalities like navigation, communication via calls,
getting weather forecasts and the latest news updates, and music that are
completely voice-based in nature.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01643" title="Abstract">arXiv:2312.01643</a> [<a href="/pdf/2312.01643" title="Download PDF">pdf</a>, <a href="/ps/2312.01643" title="Download PostScript">ps</a>, <a href="/format/2312.01643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching meta-analyses through scoping review, bibliometrics, and  alternative impact metrics: Visualizing study characteristics, hidden risk of  bias, societal influence, and research translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yefeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lagisz%2C+M">Malgorzata Lagisz</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+S">Shinichi Nakagawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Applications (stat.AP)

</div>
<p class="mathjax">We present a framework consisting of three approaches that can enhance
meta-analyses: 1) scoping reviews (evidence map), 2) bibliometrics, and 3)
alternative impact metrics. These three "enrichment" approaches facilitate the
research synthesis of both quantitative and qualitative evidence, along with
academic and non-academic influences. While the meta-analysis yields
quantitative insights (e.g., overall estimates), the enrichment analyses
provide user-friendly summaries of qualitative information on the evidence
base. Scoping reviews can visualize study characteristics, unravelling
knowledge gaps and methodological differences. Bibliometric analysis offers a
visual assessment of the non-independent evidence, such as hyper-dominant
authors and countries, and funding sources, potentially informing the risk of
bias. Impact metric analysis employs alternative metrics to gauge societal
influence and research translation (e.g., policy and patent citations) of
studies in the meta-analysis. To illustrate the application of this framework,
we provide sample visualizations and R code.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01645" title="Abstract">arXiv:2312.01645</a> [<a href="/pdf/2312.01645" title="Download PDF">pdf</a>, <a href="/ps/2312.01645" title="Download PostScript">ps</a>, <a href="/format/2312.01645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A text-dependent speaker verification application framework based on  Chinese numerical string corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Litong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Feng Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Researches indicate that text-dependent speaker verification (TD-SV) often
outperforms text-independent verification (TI-SV) in short speech scenarios.
However, collecting large-scale fixed text speech data is challenging, and as
speech length increases, factors like sentence rhythm and pauses affect TDSV's
sensitivity to text sequence. Based on these factors, We propose the hypothesis
that strategies such as more fine-grained pooling methods on time scales and
decoupled representations of speech speaker embedding and text embedding are
more suitable for TD-SV. We have introduced an end-to-end TD-SV system based on
a dataset comprising longer Chinese numerical string texts. It contains a text
embedding network, a speaker embedding network, and back-end fusion. First, we
recorded a dataset consisting of long Chinese numerical text named SHAL, which
is publicly available on the Open-SLR website. We addressed the issue of
dataset scarcity by augmenting it using Tacotron2 and HiFi-GAN. Next, we
introduced a dual representation of speech with text embedding and speaker
embedding. In the text embedding network, we employed an enhanced Transformer
and introduced a triple loss that includes text classification loss, CTC loss,
and decoder loss. For the speaker embedding network, we enhanced a sliding
window attentive statistics pooling (SWASP), combined with attentive statistics
pooling (ASP) to create a multi-scale pooling method. Finally, we fused text
embedding and speaker embedding. Our pooling methods achieved an equal error
rate (EER) performance improvement of 49.2% on Hi-Mia and 75.0% on SHAL,
respectively.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01648" title="Abstract">arXiv:2312.01648</a> [<a href="/pdf/2312.01648" title="Download PDF">pdf</a>, <a href="/format/2312.01648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Large Language Model Geometry Solves Toxicity Detection  and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balestriero%2C+R">Randall Balestriero</a>, 
<a href="/search/cs?searchtype=author&query=Cosentino%2C+R">Romain Cosentino</a>, 
<a href="/search/cs?searchtype=author&query=Shekkizhar%2C+S">Sarath Shekkizhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models~(LLMs) drive current AI breakthroughs despite very
little being known about their internal representations, e.g., how to extract a
few informative features to solve various downstream tasks. To provide a
practical and principled answer, we propose to characterize LLMs from a
geometric perspective. We obtain in closed form (i) the intrinsic dimension in
which the Multi-Head Attention embeddings are constrained to exist and (ii) the
partition and per-region affine mappings of the per-layer feedforward networks.
Our results are informative, do not rely on approximations, and are actionable.
First, we show that, motivated by our geometric interpretation, we can bypass
Llama$2$'s RLHF by controlling its embedding's intrinsic dimension through
informed prompt manipulation. Second, we derive $7$ interpretable spline
features that can be extracted from any (pre-trained) LLM layer, providing a
rich abstract representation of their inputs. Those features alone ($224$ for
Mistral-7B and Llama$2$-7B) are sufficient to help solve toxicity detection,
infer the domain of the prompt, and even tackle the Jigsaw challenge, which
aims at characterizing the type of toxicity of various prompts. Our results
demonstrate how, even in large-scale regimes, exact theoretical results can
answer practical questions in language models. Code:
\url{https://github.com/RandallBalestriero/SplineLLM}.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01650" title="Abstract">arXiv:2312.01650</a> [<a href="/pdf/2312.01650" title="Download PDF">pdf</a>, <a href="/format/2312.01650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Confidence Threshold for ByteTrack in Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Ma%2C+L">Linh Van Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+M+I">Muhammad Ishfaq Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">JongHyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongbae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Moongu Jeon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCAIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We investigate the application of ByteTrack in the realm of multiple object
tracking. ByteTrack, a simple tracking algorithm, enables the simultaneous
tracking of multiple objects by strategically incorporating detections with a
low confidence threshold. Conventionally, objects are initially associated with
high confidence threshold detections. When the association between objects and
detections becomes ambiguous, ByteTrack extends the association to lower
confidence threshold detections. One notable drawback of the existing ByteTrack
approach is its reliance on a fixed threshold to differentiate between high and
low-confidence detections. In response to this limitation, we introduce a novel
and adaptive approach. Our proposed method entails a dynamic adjustment of the
confidence threshold, leveraging insights derived from overall detections.
Through experimentation, we demonstrate the effectiveness of our adaptive
confidence threshold technique while maintaining running time compared to
ByteTrack.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01652" title="Abstract">arXiv:2312.01652</a> [<a href="/pdf/2312.01652" title="Download PDF">pdf</a>, <a href="/format/2312.01652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Expressive Power of Behavior Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Efforts toward a comprehensive description of behavior have indeed
facilitated the development of representation-based approaches that utilize
deep learning to capture behavioral information. As behavior complexity
increases, the expressive power of these models reaches a bottleneck. We coin
the term ``behavioral molecular structure" and propose a new model called the
Behavioral Molecular Structure (BMS). The model characterizes behaviors at the
atomic level, analogizes behavioral attributes to atoms, and concretizes
interrelations at the granularity of atoms using graphs. Here, we design three
different downstream tasks to test the performance of the BMS model on public
datasets. Additionally, we provide a preliminary theoretical analysis
demonstrating that the BMS model can offer effective expressiveness for complex
behaviors.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01653" title="Abstract">arXiv:2312.01653</a> [<a href="/pdf/2312.01653" title="Download PDF">pdf</a>, <a href="/format/2312.01653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An End-to-End Network Pruning Pipeline with Sparsity Enforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dogariu%2C+E">Evan Dogariu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural networks have emerged as a powerful tool for solving complex tasks
across various domains, but their increasing size and computational
requirements have posed significant challenges in deploying them on
resource-constrained devices. Neural network sparsification, and in particular
pruning, has emerged as an effective technique to alleviate these challenges by
reducing model size, computational complexity, and memory footprint while
maintaining competitive performance. However, many pruning pipelines modify the
standard training pipeline at only a single stage, if at all. In this work, we
look to develop an end-to-end training pipeline that befits neural network
pruning and sparsification at all stages of training. To do so, we make use of
nonstandard model parameter initialization, pre-pruning training methodologies,
and post-pruning training optimizations. We conduct experiments utilizing
combinations of these methods, in addition to different techniques used in the
pruning step, and find that our combined pipeline can achieve significant gains
over current state of the art approaches to neural network sparsification.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01656" title="Abstract">arXiv:2312.01656</a> [<a href="/pdf/2312.01656" title="Download PDF">pdf</a>, <a href="/format/2312.01656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Contemporary Art of Image Search: Iterative User Intent Expansion  via Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yilin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shishi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 2024 ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW) (Proc. CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Image search is an essential and user-friendly method to explore vast
galleries of digital images. However, existing image search methods heavily
rely on proximity measurements like tag matching or image similarity, requiring
precise user inputs for satisfactory results.To meet the growing demand for a
contemporary image search engine that enables accurate comprehension of users'
search intentions, we introduce an innovative user intent expansion framework.
Our framework leverages visual-language models to parse and compose multi-modal
user inputs to provide more accurate and satisfying results. It comprises
two-stage processes: 1) a parsing stage that incorporates a language parsing
module with large language models to enhance the comprehension of textual
inputs, along with a visual parsing module that integrates an interactive
segmentation module to swiftly identify detailed visual elements within images;
and 2) a logic composition stage that combines multiple user search intents
into a unified logic expression for more sophisticated operations in complex
searching scenarios. Moreover, the intent expansion framework enables users to
perform flexible contextualized interactions with the search results to further
specify or adjust their detailed search intents iteratively. We implemented the
framework into an image search system for NFT (non-fungible token) search and
conducted a user study to evaluate its usability and novel properties. The
results indicate that the proposed framework significantly improves users'
image search experience. Particularly the parsing and contextualized
interactions prove useful in allowing users to express their search intents
more accurately and engage in a more enjoyable iterative search experience.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01657" title="Abstract">arXiv:2312.01657</a> [<a href="/pdf/2312.01657" title="Download PDF">pdf</a>, <a href="/format/2312.01657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Tuning Neural ODE for Stability, Consistency and Faster Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+S+W">Sheikh Waqas Akhtar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural-ODE parameterize a differential equation using continuous depth neural
network and solve it using numerical ODE-integrator. These models offer a
constant memory cost compared to models with discrete sequence of hidden layers
in which memory cost increases linearly with the number of layers. In addition
to memory efficiency, other benefits of neural-ode include adaptability of
evaluation approach to input, and flexibility to choose numerical precision or
fast training. However, despite having all these benefits, it still has some
limitations. We identify the ODE-integrator (also called ODE-solver) as the
weakest link in the chain as it may have stability, consistency and convergence
(CCS) issues and may suffer from slower convergence or may not converge at all.
We propose a first-order Nesterov's accelerated gradient (NAG) based ODE-solver
which is proven to be tuned vis-a-vis CCS conditions. We empirically
demonstrate the efficacy of our approach by training faster, while achieving
better or comparable performance against neural-ode employing other fixed-step
explicit ODE-solvers as well discrete depth models such as ResNet in three
different tasks including supervised classification, density estimation, and
time-series modelling.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01658" title="Abstract">arXiv:2312.01658</a> [<a href="/pdf/2312.01658" title="Download PDF">pdf</a>, <a href="/format/2312.01658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for  Preconditioning Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yun Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhiling Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiadi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages. Accepted as a conference paper at NeurIPS '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Adaptive optimizers, such as Adam, have achieved remarkable success in deep
learning. A key component of these optimizers is the so-called preconditioning
matrix, providing enhanced gradient information and regulating the step size of
each gradient direction. In this paper, we propose a novel approach to
designing the preconditioning matrix by utilizing the gradient difference
between two successive steps as the diagonal elements. These diagonal elements
are closely related to the Hessian and can be perceived as an approximation of
the inner product between the Hessian row vectors and difference of the
adjacent parameter vectors. Additionally, we introduce an auto-switching
function that enables the preconditioning matrix to switch dynamically between
Stochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these
two techniques, we develop a new optimizer named AGD that enhances the
generalization performance. We evaluate AGD on public datasets of Natural
Language Processing (NLP), Computer Vision (CV), and Recommendation Systems
(RecSys). Our experimental results demonstrate that AGD outperforms the
state-of-the-art (SOTA) optimizers, achieving highly competitive or
significantly better predictive performance. Furthermore, we analyze how AGD is
able to switch automatically between SGD and the adaptive optimizer and its
actual effects on various scenarios. The code is available at
https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01659" title="Abstract">arXiv:2312.01659</a> [<a href="/pdf/2312.01659" title="Download PDF">pdf</a>, <a href="/format/2312.01659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RiskBench: A Scenario-based Benchmark for Risk Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kung%2C+C">Chi-Hsi Kung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chieh-Chi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pao%2C+P">Pang-Yuan Pao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shu-Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Lun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hsin-Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Intelligent driving systems aim to achieve a zero-collision mobility
experience, requiring interdisciplinary efforts to enhance safety performance.
This work focuses on risk identification, the process of identifying and
analyzing risks stemming from dynamic traffic participants and unexpected
events. While significant advances have been made in the community, the current
evaluation of different risk identification algorithms uses independent
datasets, leading to difficulty in direct comparison and hindering collective
progress toward safety performance enhancement. To address this limitation, we
introduce \textbf{RiskBench}, a large-scale scenario-based benchmark for risk
identification. We design a scenario taxonomy and augmentation pipeline to
enable a systematic collection of ground truth risks under diverse scenarios.
We assess the ability of ten algorithms to (1) detect and locate risks, (2)
anticipate risks, and (3) facilitate decision-making. We conduct extensive
experiments and summarize future research on risk identification. Our aim is to
encourage collaborative endeavors in achieving a society with zero collisions.
We have made our dataset and benchmark toolkit publicly on the project page:
https://hcis-lab.github.io/RiskBench/
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01661" title="Abstract">arXiv:2312.01661</a> [<a href="/pdf/2312.01661" title="Download PDF">pdf</a>, <a href="/format/2312.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating  Pre-university Math Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Long%2C+P+P">Phuoc Pham Van Long</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+A">Duc Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+M">Nhat M. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 39th ACM/SIGAPP Symposium On Applied Computing (SAC 2024), Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mathematical questioning is crucial for assessing students problem-solving
skills. Since manually creating such questions requires substantial effort,
automatic methods have been explored. Existing state-of-the-art models rely on
fine-tuning strategies and struggle to generate questions that heavily involve
multiple steps of logical and arithmetic reasoning. Meanwhile, large language
models(LLMs) such as ChatGPT have excelled in many NLP tasks involving logical
and arithmetic reasoning. Nonetheless, their applications in generating
educational questions are underutilized, especially in the field of
mathematics. To bridge this gap, we take the first step to conduct an in-depth
analysis of ChatGPT in generating pre-university math questions. Our analysis
is categorized into two main settings: context-aware and context-unaware. In
the context-aware setting, we evaluate ChatGPT on existing math
question-answering benchmarks covering elementary, secondary, and ternary
classes. In the context-unaware setting, we evaluate ChatGPT in generating math
questions for each lesson from pre-university math curriculums that we crawl.
Our crawling results in TopicMath, a comprehensive and novel collection of
pre-university math curriculums collected from 121 math topics and 428 lessons
from elementary, secondary, and tertiary classes. Through this analysis, we aim
to provide insight into the potential of ChatGPT as a math questioner.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01663" title="Abstract">arXiv:2312.01663</a> [<a href="/pdf/2312.01663" title="Download PDF">pdf</a>, <a href="/format/2312.01663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customize your NeRF: Adaptive Source Driven 3D Scene Editing via  Local-Global Iterative Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Runze He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaofei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+X">Xuecheng Nie</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+T">Tianrui Hui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jizhong Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures, project website: <a href="https://customnerf.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we target the adaptive source driven 3D scene editing task by
proposing a CustomNeRF model that unifies a text description or a reference
image as the editing prompt. However, obtaining desired editing results
conformed with the editing prompt is nontrivial since there exist two
significant challenges, including accurate editing of only foreground regions
and multi-view consistency given a single-view reference image. To tackle the
first challenge, we propose a Local-Global Iterative Editing (LGIE) training
scheme that alternates between foreground region editing and full-image
editing, aimed at foreground-only manipulation while preserving the background.
For the second challenge, we also design a class-guided regularization that
exploits class priors within the generation model to alleviate the
inconsistency problem among different views in image-driven editing. Extensive
experiments show that our CustomNeRF produces precise editing results under
various real scenes for both text- and image-driven settings.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01669" title="Abstract">arXiv:2312.01669</a> [<a href="/pdf/2312.01669" title="Download PDF">pdf</a>, <a href="/ps/2312.01669" title="Download PostScript">ps</a>, <a href="/format/2312.01669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyze Drivers&#x27; Intervention Behavior During Autonomous Driving -- A  VR-incorporated Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given the rapid advance in ITS technologies, future mobility is pointing to
vehicular autonomy. However, there is still a long way before full automation,
and human intervention is required. This work sheds light on understanding
human drivers' intervention behavior involved in the operation of autonomous
vehicles (AVs) and utilizes this knowledge to improve the perception of
critical driving scenarios. Experiment environments were implemented where the
virtual reality (VR) and traffic micro-simulation are integrated, and tests
were carried out under typical and diverse traffic scenes. Performance
indicators such as the probability of intervention, accident rates are defined
and used to quantify and compare the risk levels. By offering novel insights
into drivers' intervention behavior, this work will help improve the
performances of the automated control under similar scenarios. Furthermore,
such an integrated and immersive tool for autonomous driving studies will be
valuable for research on human-to-automation trust. To the best knowledge of
the authors, this work is among the pioneer works making efforts into such
types of tools.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01671" title="Abstract">arXiv:2312.01671</a> [<a href="/pdf/2312.01671" title="Download PDF">pdf</a>, <a href="/format/2312.01671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality-guided Image Style Transfer using Cross-modal GAN  Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+K+D">Kevin Dela Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024. Project website: <a href="https://hywang66.github.io/mmist/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image Style Transfer (IST) is an interdisciplinary topic of computer vision
and art that continuously attracts researchers' interests. Different from
traditional Image-guided Image Style Transfer (IIST) methods that require a
style reference image as input to define the desired style, recent works start
to tackle the problem in a text-guided manner, i.e., Text-guided Image Style
Transfer (TIST). Compared to IIST, such approaches provide more flexibility
with text-specified styles, which are useful in scenarios where the style is
hard to define with reference images. Unfortunately, many TIST approaches
produce undesirable artifacts in the transferred images. To address this issue,
we present a novel method to achieve much improved style transfer based on text
guidance. Meanwhile, to offer more flexibility than IIST and TIST, our method
allows style inputs from multiple sources and modalities, enabling
MultiModality-guided Image Style Transfer (MMIST). Specifically, we realize
MMIST with a novel cross-modal GAN inversion method, which generates style
representations consistent with specified styles. Such style representations
facilitate style transfer and in principle generalize any IIST methods to
MMIST. Large-scale experiments and user studies demonstrate that our method
achieves state-of-the-art performance on TIST task. Furthermore, comprehensive
qualitative results confirm the effectiveness of our method on MMIST task and
cross-modal style interpolation.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01672" title="Abstract">arXiv:2312.01672</a> [<a href="/pdf/2312.01672" title="Download PDF">pdf</a>, <a href="/format/2312.01672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STADEE: STAtistics-based DEEp Detection of Machine Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huming Liu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Advanced Intelligent Computing Technology and Applications,
  ICIC 2023, Lecture Notes in Computer Science, vol 14089. Springer, Singapore
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present STADEE, a \textbf{STA}tistics-based \textbf{DEE}p detection method
to identify machine-generated text, addressing the limitations of current
methods that rely heavily on fine-tuning pre-trained language models (PLMs).
STADEE integrates key statistical text features with a deep classifier,
focusing on aspects like token probability and cumulative probability, crucial
for handling nucleus sampling. Tested across diverse datasets and scenarios
(in-domain, out-of-domain, and in-the-wild), STADEE demonstrates superior
performance, achieving an 87.05% F1 score in-domain and outperforming both
traditional statistical methods and fine-tuned PLMs, especially in
out-of-domain and in-the-wild settings, highlighting its effectiveness and
generalizability.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01674" title="Abstract">arXiv:2312.01674</a> [<a href="/pdf/2312.01674" title="Download PDF">pdf</a>, <a href="/format/2312.01674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDALearn: A Comprehensive RTL-to-Signoff EDA Benchmark for Democratized  and Reproducible ML for EDA Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jingyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chen-Chia Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiyao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The application of Machine Learning (ML) in Electronic Design Automation
(EDA) for Very Large-Scale Integration (VLSI) design has garnered significant
research attention. Despite the requirement for extensive datasets to build
effective ML models, most studies are limited to smaller, internally generated
datasets due to the lack of comprehensive public resources. In response, we
introduce EDALearn, the first holistic, open-source benchmark suite
specifically for ML tasks in EDA. This benchmark suite presents an end-to-end
flow from synthesis to physical implementation, enriching data collection
across various stages. It fosters reproducibility and promotes research into ML
transferability across different technology nodes. Accommodating a wide range
of VLSI design instances and sizes, our benchmark aptly represents the
complexity of contemporary VLSI designs. Additionally, we provide an in-depth
data analysis, enabling users to fully comprehend the attributes and
distribution of our data, which is essential for creating efficient ML models.
Our contributions aim to encourage further advances in the ML-EDA domain.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01677" title="Abstract">arXiv:2312.01677</a> [<a href="/pdf/2312.01677" title="Download PDF">pdf</a>, <a href="/format/2312.01677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Image Restoration Guided By Robust DINO Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Chao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinshan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-task image restoration has gained significant interest due to its
inherent versatility and efficiency compared to its single-task counterpart.
Despite its potential, performance degradation is observed with an increase in
the number of tasks, primarily attributed to the distinct nature of each
restoration task. Addressing this challenge, we introduce
\mbox{\textbf{DINO-IR}}, a novel multi-task image restoration approach
leveraging robust features extracted from DINOv2. Our empirical analysis shows
that while shallow features of DINOv2 capture rich low-level image
characteristics, the deep features ensure a robust semantic representation
insensitive to degradations while preserving high-frequency contour details.
Building on these features, we devise specialized components, including
multi-layer semantic fusion module, DINO-Restore adaption and fusion module,
and DINO perception contrastive loss, to integrate DINOv2 features into the
restoration paradigm. Equipped with the aforementioned components, our DINO-IR
performs favorably against existing multi-task image restoration approaches in
various tasks by a large margin, indicating the superiority and necessity of
reinforcing the robust features for multi-task image restoration.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01678" title="Abstract">arXiv:2312.01678</a> [<a href="/pdf/2312.01678" title="Download PDF">pdf</a>, <a href="/format/2312.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jellyfish: A Large Language Model for Data Preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haochen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuyang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Oyamada%2C+M">Masafumi Oyamada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present Jellyfish, an open-source LLM as a universal task
solver for DP. Built on the Llama 2 13B model, Jellyfish is instruction-tuned
with the datasets of several typical DP tasks including error detection, data
imputation, schema matching, and entity matching, and delivers generalizability
to other tasks. Remarkably, Jellyfish can operate on a local, single, and
low-priced GPU with its 13 billion parameters, ensuring data security and
enabling further tuning. Its proficiency in understanding natural language
allows users to manually craft instructions for DP tasks. Unlike many existing
methods that heavily rely on prior knowledge, Jellyfish acquires domain
knowledge during its tuning process and integrates optional knowledge injection
during inference. A distinctive feature of Jellyfish is its interpreter, which
elucidates its output decisions. To construct Jellyfish, we develop a series of
pre-tuning and DP-tuning techniques. Jellyfish is equipped with an instance
serializer, which automatically translates raw data into model prompts, and a
knowledge injector, which optionally introduces task- and dataset-specific
knowledge to enhance DP performance. Our evaluation of Jellyfish, using a range
of real datasets, shows its competitiveness compared to state-of-the-art
methods and its strong generalizability to unseen tasks. Jellyfish's
performance rivals that of GPT series models, and its interpreter offers
enhanced reasoning capabilities compared to GPT-3.5. Furthermore, our
evaluation highlights the effectiveness of the techniques employed in
constructing Jellyfish. Our model is available at Hugging Face:
https://huggingface.co/NECOUDBFM/Jellyfish .
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01680" title="Abstract">arXiv:2312.01680</a> [<a href="/pdf/2312.01680" title="Download PDF">pdf</a>, <a href="/format/2312.01680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> With Great Humor Comes Great Developer Engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+D">Deepika Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Toady%2C+T">Tim Toady</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>, 
<a href="/search/cs?searchtype=author&query=Baudry%2C+B">Benoit Baudry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The worldwide collaborative effort for the creation of software is
technically and socially demanding. The more engaged developers are, the more
value they impart to the software they create. Engaged developers, such as
Margaret Hamilton programming Apollo 11, can succeed in tackling the most
difficult engineering tasks. In this paper, we dive deep into an original
vector of engagement - humor - and study how it fuels developer engagement.
First, we collect qualitative and quantitative data about the humorous elements
present within three significant, real-world software projects: faker, which
helps developers introduce humor within their tests; lolcommits, which captures
a photograph after each contribution made by a developer; and volkswagen, an
exercise in satire, which accidentally led to the invention of an impactful
software tool. Second, through a developer survey, we receive unique insights
from 125 developers, who share their real-life experiences with humor in
software. Our analysis of the three case studies highlights the prevalence of
humor in software, and unveils the worldwide community of developers who are
enthusiastic about both software and humor. We also learn about the caveats of
humor in software through the valuable insights shared by our survey
respondents. We report clear evidence that, when practiced responsibly, humor
increases developer engagement and supports them in addressing hard engineering
and cognitive tasks. The most actionable highlight of our work is that software
tests and documentation are the best locations in code to practice humor.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01681" title="Abstract">arXiv:2312.01681</a> [<a href="/pdf/2312.01681" title="Download PDF">pdf</a>, <a href="/format/2312.01681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malicious Lateral Movement in 5G Core With Network Slicing And Its  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ayush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Thing%2C+V+L+L">Vrizlynn L.L. Thing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Proceedings of IEEE ITNAC-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">5G networks are susceptible to cyber attacks due to reasons such as
implementation issues and vulnerabilities in 3GPP standard specifications. In
this work, we propose lateral movement strategies in a 5G Core (5GC) with
network slicing enabled, as part of a larger attack campaign by well-resourced
adversaries such as APT groups. Further, we present 5GLatte, a system to detect
such malicious lateral movement. 5GLatte operates on a host-container access
graph built using host/NF container logs collected from the 5GC. Paths inferred
from the access graph are scored based on selected filtering criteria and
subsequently presented as input to a threshold-based anomaly detection
algorithm to reveal malicious lateral movement paths. We evaluate 5GLatte on a
dataset containing attack campaigns (based on MITRE ATT&amp;CK and FiGHT
frameworks) launched in a 5G test environment which shows that compared to
other lateral movement detectors based on state-of-the-art, it can achieve
higher true positive rates with similar false positive rates.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01682" title="Abstract">arXiv:2312.01682</a> [<a href="/pdf/2312.01682" title="Download PDF">pdf</a>, <a href="/format/2312.01682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResEnsemble-DDPM: Residual Denoising Diffusion Probabilistic Models for  Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhenning%2C+S">Shi Zhenning</a>, 
<a href="/search/cs?searchtype=author&query=Changsheng%2C+D">Dong Changsheng</a>, 
<a href="/search/cs?searchtype=author&query=Xueshuo%2C+X">Xie Xueshuo</a>, 
<a href="/search/cs?searchtype=author&query=Bin%2C+P">Pan Bin</a>, 
<a href="/search/cs?searchtype=author&query=Along%2C+H">He Along</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Li Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Nowadays, denoising diffusion probabilistic models have been adapted for many
image segmentation tasks. However, existing end-to-end models have already
demonstrated remarkable capabilities. Rather than using denoising diffusion
probabilistic models alone, integrating the abilities of both denoising
diffusion probabilistic models and existing end-to-end models can better
improve the performance of image segmentation. Based on this, we implicitly
introduce residual term into the diffusion process and propose
ResEnsemble-DDPM, which seamlessly integrates the diffusion model and the
end-to-end model through ensemble learning. The output distributions of these
two models are strictly symmetric with respect to the ground truth
distribution, allowing us to integrate the two models by reducing the residual
term. Experimental results demonstrate that our ResEnsemble-DDPM can further
improve the capabilities of existing models. Furthermore, its ensemble learning
strategy can be generalized to other downstream tasks in image generation and
get strong competitiveness.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01687" title="Abstract">arXiv:2312.01687</a> [<a href="/pdf/2312.01687" title="Download PDF">pdf</a>, <a href="/ps/2312.01687" title="Download PostScript">ps</a>, <a href="/format/2312.01687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Bus Travel: A Novel Approach to Feature Mining with P-KMEANS  and P-LDA Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haotian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Sicheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tengfei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinhuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+B">Bin Ran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Customizing services for bus travel can bolster its attractiveness, optimize
usage, alleviate traffic congestion, and diminish carbon emissions. This
potential is realized by harnessing recent advancements in positioning
communication facilities, the Internet of Things, and artificial intelligence
for feature mining in public transportation. However, the inherent complexities
of disorganized and unstructured public transportation data introduce
substantial challenges to travel feature extraction. This study presents a bus
travel feature extraction method rooted in Point of Interest (POI) data,
employing enhanced P-KMENAS and P-LDA algorithms to overcome these limitations.
While the KMEANS algorithm adeptly segments passenger travel paths into
distinct clusters, its outcomes can be influenced by the initial K value. On
the other hand, Latent Dirichlet Allocation (LDA) excels at feature
identification and probabilistic interpretations yet encounters difficulties
with feature intermingling and nuanced sub-feature interactions. Incorporating
the POI dimension enhances our understanding of travel behavior, aligning it
more closely with passenger attributes and facilitating easier data analysis.
By incorporating POI data, our refined P-KMENAS and P-LDA algorithms grant a
holistic insight into travel behaviors and attributes, effectively mitigating
the limitations above. Consequently, this POI-centric algorithm effectively
amalgamates diverse POI attributes, delineates varied travel contexts, and
imparts probabilistic metrics to feature properties. Our method successfully
mines the diverse aspects of bus travel, such as age, occupation, gender,
sports, cost, safety, and personality traits. It effectively calculates
relationships between individual travel behaviors and assigns explanatory and
evaluative probabilities to POI labels, thereby enhancing bus travel
optimization.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01688" title="Abstract">arXiv:2312.01688</a> [<a href="/pdf/2312.01688" title="Download PDF">pdf</a>, <a href="/format/2312.01688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tab-Attention: Self-Attention-based Stacked Generalization for  Imbalanced Credit Default Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yandan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongbin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=JieWu">JieWu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+H">Hongfeng Chai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Accurately credit default prediction faces challenges due to imbalanced data
and low correlation between features and labels. Existing default prediction
studies on the basis of gradient boosting decision trees (GBDT), deep learning
techniques, and feature selection strategies can have varying degrees of
success depending on the specific task. Motivated by this, we propose
Tab-Attention, a novel self-attention-based stacked generalization method for
credit default prediction. This approach ensembles the potential proprietary
knowledge contributions from multi-view feature spaces, to cope with low
feature correlation and imbalance. We organize multi-view feature spaces
according to the latent linear or nonlinear strengths between features and
labels. Meanwhile, the f1 score assists the model in imbalance training to find
the optimal state for identifying minority default samples. Our Tab-Attention
achieves superior Recall_1 and f1_1 of default intention recognition than
existing GBDT-based models and advanced deep learning by about 32.92% and
16.05% on average, respectively, while maintaining outstanding overall
performance and prediction performance for non-default samples. The proposed
method could ensemble essential knowledge through the self-attention mechanism,
which is of great significance for a more robust future prediction system.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01692" title="Abstract">arXiv:2312.01692</a> [<a href="/pdf/2312.01692" title="Download PDF">pdf</a>, <a href="/format/2312.01692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Controlling Model Selection via Guided Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laufer-Goldshtein%2C+B">Bracha Laufer-Goldshtein</a>, 
<a href="/search/cs?searchtype=author&query=Fisch%2C+A">Adam Fisch</a>, 
<a href="/search/cs?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Adjustable hyperparameters of machine learning models typically impact
various key trade-offs such as accuracy, fairness, robustness, or inference
cost. Our goal in this paper is to find a configuration that adheres to
user-specified limits on certain risks while being useful with respect to other
conflicting metrics. We solve this by combining Bayesian Optimization (BO) with
rigorous risk-controlling procedures, where our core idea is to steer BO
towards an efficient testing strategy. Our BO method identifies a set of Pareto
optimal configurations residing in a designated region of interest. The
resulting candidates are statistically verified and the best-performing
configuration is selected with guaranteed risk levels. We demonstrate the
effectiveness of our approach on a range of tasks with multiple desiderata,
including low error rates, equitable predictions, handling spurious
correlations, managing rate and distortion in generative models, and reducing
computational costs.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01696" title="Abstract">arXiv:2312.01696</a> [<a href="/pdf/2312.01696" title="Download PDF">pdf</a>, <a href="/format/2312.01696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Shiyi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+J+M">Jose M. Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the rise of query-based Transformer decoders is reshaping
camera-based 3D object detection. These query-based decoders are surpassing the
traditional dense BEV (Bird's Eye View)-based methods. However, we argue that
dense BEV frameworks remain important due to their outstanding abilities in
depth estimation and object localization, depicting 3D scenes accurately and
comprehensively. This paper aims to address the drawbacks of the existing dense
BEV-based 3D object detectors by introducing our proposed enhanced components,
including a CRF-modulated depth estimation module enforcing object-level
consistencies, a long-term temporal aggregation module with extended receptive
fields, and a two-stage object decoder combining perspective techniques with
CRF-modulated depth embedding. These enhancements lead to a "modernized" dense
BEV framework dubbed BEVNeXt. On the nuScenes benchmark, BEVNeXt outperforms
both BEV-based and query-based frameworks under various settings, achieving a
state-of-the-art result of 64.2 NDS on the nuScenes test set.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01697" title="Abstract">arXiv:2312.01697</a> [<a href="/pdf/2312.01697" title="Download PDF">pdf</a>, <a href="/format/2312.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hulk: A Universal Knowledge Translator for Human-Centric Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weizhen He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human-centric perception tasks, e.g., human mesh recovery, pedestrian
detection, skeleton-based action recognition, and pose estimation, have wide
industrial applications, such as metaverse and sports analysis. There is a
recent surge to develop human-centric foundation models that can benefit a
broad range of human-centric perception tasks. While many human-centric
foundation models have achieved success, most of them only excel in 2D vision
tasks or require extensive fine-tuning for practical deployment in real-world
scenarios. These limitations severely restrict their usability across various
downstream tasks and situations. To tackle these problems, we present Hulk, the
first multimodal human-centric generalist model, capable of addressing most of
the mainstream tasks simultaneously without task-specific finetuning, covering
2D vision, 3D vision, skeleton-based, and vision-language tasks. The key to
achieving this is condensing various task-specific heads into two general
heads, one for discrete representations, e.g., languages, and the other for
continuous representations, e.g., location coordinates. The outputs of two
heads can be further stacked into four distinct input and output modalities.
This uniform representation enables Hulk to treat human-centric tasks as
modality translation, integrating knowledge across a wide range of tasks. To
validate the effectiveness of our proposed method, we conduct comprehensive
experiments on 11 benchmarks across 8 human-centric tasks. Experimental results
surpass previous methods substantially, demonstrating the superiority of our
proposed method. The code will be available on
https://github.com/OpenGVLab/HumanBench.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01699" title="Abstract">arXiv:2312.01699</a> [<a href="/pdf/2312.01699" title="Download PDF">pdf</a>, <a href="/format/2312.01699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Urban Mobility Prediction: A Super-Multivariate Time Series  Forecasting Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jinguo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuankai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Long-term urban mobility predictions play a crucial role in the effective
management of urban facilities and services. Conventionally, urban mobility
data has been structured as spatiotemporal videos, treating longitude and
latitude grids as fundamental pixels. Consequently, video prediction methods,
relying on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs),
have been instrumental in this domain. In our research, we introduce a fresh
perspective on urban mobility prediction. Instead of oversimplifying urban
mobility data as traditional video data, we regard it as a complex multivariate
time series. This perspective involves treating the time-varying values of each
grid in each channel as individual time series, necessitating a thorough
examination of temporal dynamics, cross-variable correlations, and
frequency-domain insights for precise and reliable predictions. To address this
challenge, we present the Super-Multivariate Urban Mobility Transformer
(SUMformer), which utilizes a specially designed attention mechanism to
calculate temporal and cross-variable correlations and reduce computational
costs stemming from a large number of time series. SUMformer also employs
low-frequency filters to extract essential information for long-term
predictions. Furthermore, SUMformer is structured with a temporal patch merge
mechanism, forming a hierarchical framework that enables the capture of
multi-scale correlations. Consequently, it excels in urban mobility pattern
modeling and long-term prediction, outperforming current state-of-the-art
methods across three real-world datasets.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01700" title="Abstract">arXiv:2312.01700</a> [<a href="/pdf/2312.01700" title="Download PDF">pdf</a>, <a href="/format/2312.01700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Management For Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zige Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data plays a fundamental role in the training of Large Language Models
(LLMs). Effective data management, particularly in the formulation of a
well-suited training dataset, holds significance for enhancing model
performance and improving training efficiency during pretraining and supervised
fine-tuning phases. Despite the considerable importance of data management, the
current research community still falls short in providing a systematic analysis
of the rationale behind management strategy selection, its consequential
effects, methodologies for evaluating curated datasets, and the ongoing pursuit
of improved strategies. Consequently, the exploration of data management has
attracted more and more attention among the research community. This survey
provides a comprehensive overview of current research in data management within
both the pretraining and supervised fine-tuning stages of LLMs, covering
various noteworthy aspects of data management strategy design: data quantity,
data quality, domain/task composition, etc. Looking toward the future, we
extrapolate existing challenges and outline promising directions for
development in this field. Therefore, this survey serves as a guiding resource
for practitioners aspiring to construct powerful LLMs through effective data
management practices. The collection of the latest papers is available at
https://github.com/ZigeW/data_management_LLM.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01701" title="Abstract">arXiv:2312.01701</a> [<a href="/pdf/2312.01701" title="Download PDF">pdf</a>, <a href="/format/2312.01701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Fine-Grained Hallucination by Fine-Tuning Large  Vision-Language Models with Caption Rewrites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabang He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shenshen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Ee-Peng Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MMM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable performance in natural
language processing (NLP) tasks. To comprehend and execute diverse human
instructions over image data, instruction-tuned large vision-language models
(LVLMs) have been introduced. However, LVLMs may suffer from different types of
object hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained
object hallucinations only (i.e., generated objects non-existent in the input
image). The fine-grained object attributes and behaviors non-existent in the
image may still be generated but not measured by the current evaluation
methods. In this paper, we thus focus on reducing fine-grained hallucinations
of LVLMs. We propose \textit{ReCaption}, a framework that consists of two
components: rewriting captions using ChatGPT and fine-tuning the
instruction-tuned LVLMs on the rewritten captions. We also propose a
fine-grained probing-based evaluation method named \textit{Fine-Grained Object
Hallucination Evaluation} (\textit{FGHE}). Our experiment results demonstrate
that ReCaption effectively reduces fine-grained object hallucination for
different LVLM options and improves their text generation quality. The code can
be found at https://github.com/Anonymousanoy/FOHE.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01707" title="Abstract">arXiv:2312.01707</a> [<a href="/pdf/2312.01707" title="Download PDF">pdf</a>, <a href="/format/2312.01707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Dimensions of Physical Properties of Handheld Objects Induced  by Impedance Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Takeru Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+S">Shigeo Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Narumi%2C+T">Takuji Narumi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Haptics in virtual reality is the emerging dimension after audiovisual
experiences. Researchers designed several handheld VR controllers to simulate
haptic experiences in virtual reality environments. Some of these devices,
equipped to deliver active force, can dynamically alter the timing and
intensity of force feedback, potentially offering a wide array of haptic
sensations. Past research primarily used a single index to evaluate how users
perceive physical property parameters, potentially limiting the assessment to
the designer's intended scope and neglecting other potential perceptual
experiences.
<br />Therefore, this study evaluates not how much but how humans feel a physical
property when stimuli are changed. We conducted interviews to investigate how
people feel when a haptic device changes motion impedance. We used thematic
analysis to abstract the results of the interviews and gain an understanding of
how humans attribute force feedback to a phenomenon. We also generated a
vocabulary from the themes obtained from the interviews and asked users to
evaluate force feedback using the semantic difference method. A factor analysis
was used to investigate how changing the basic elements of motion, such as
inertia, viscosity, and stiffness of the motion system, affects haptic
perception. As a result, we obtained four critical factors: size, viscosity,
weight, and flexibility factor, and clarified the correspondence between these
factors and the change of impedance.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01711" title="Abstract">arXiv:2312.01711</a> [<a href="/pdf/2312.01711" title="Download PDF">pdf</a>, <a href="/format/2312.01711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regressor-Segmenter Mutual Prompt Learning for Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhaoyi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Binghui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qixiang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crowd counting has achieved significant progress by training regressors to
predict instance positions. In heavily crowded scenarios, however, regressors
are challenged by uncontrollable annotation variance, which causes density map
bias and context information inaccuracy. In this study, we propose mutual
prompt learning (mPrompt), which leverages a regressor and a segmenter as
guidance for each other, solving bias and inaccuracy caused by annotation
variance while distinguishing foreground from background. In specific, mPrompt
leverages point annotations to tune the segmenter and predict pseudo head masks
in a way of point prompt learning. It then uses the predicted segmentation
masks, which serve as spatial constraint, to rectify biased point annotations
as context prompt learning. mPrompt defines a way of mutual information
maximization from prompt learning, mitigating the impact of annotation variance
while improving model accuracy. Experiments show that mPrompt significantly
reduces the Mean Average Error (MAE), demonstrating the potential to be general
framework for down-stream vision tasks.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01712" title="Abstract">arXiv:2312.01712</a> [<a href="/pdf/2312.01712" title="Download PDF">pdf</a>, <a href="/format/2312.01712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JUNO: Optimizing High-Dimensional Approximate Nearest Neighbour Search  with Sparsity-Aware Algorithm and Ray-Tracing Core Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wentao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jingwen Leng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuhao Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Approximate nearest neighbor (ANN) search is a widely applied technique in
modern intelligent applications, such as recommendation systems and vector
databases. Therefore, efficient and high-throughput execution of ANN search has
become increasingly important. In this paper, we first characterize the
state-of-the-art product quantization-based method of ANN search and identify a
significant source of inefficiency in the form of unnecessary pairwise distance
calculations and accumulations. To improve efficiency, we propose JUNO, an
end-to-end ANN search system that adopts a carefully designed sparsity- and
locality-aware search algorithm. We also present an efficient hardware mapping
that utilizes ray tracing cores in modern GPUs with pipelined execution on
tensor cores to execute our sparsity-aware ANN search algorithm. Our
evaluations on four datasets ranging in size from 1 to 100 million search
points demonstrate 2.2x-8.5x improvements in search throughput. Moreover, our
algorithmic enhancements alone achieve a maximal 2.6x improvement on the
hardware without the acceleration of the RT core.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01713" title="Abstract">arXiv:2312.01713</a> [<a href="/pdf/2312.01713" title="Download PDF">pdf</a>, <a href="/format/2312.01713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Interaction Representation for One-Stage Human-Object  Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xubin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Changxing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yupeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-Object Interaction (HOI) detection is a core task for human-centric
image understanding. Recent one-stage methods adopt a transformer decoder to
collect image-wide cues that are useful for interaction prediction; however,
the interaction representations obtained using this method are entangled and
lack interpretability. In contrast, traditional two-stage methods benefit
significantly from their ability to compose interaction features in a
disentangled and explainable manner. In this paper, we improve the performance
of one-stage methods by enabling them to extract disentangled interaction
representations. First, we propose Shunted Cross-Attention (SCA) to extract
human appearance, object appearance, and global context features using
different cross-attention heads. This is achieved by imposing different masks
on the cross-attention maps produced by the different heads. Second, we
introduce the Interaction-aware Pose Estimation (IPE) task to learn
interaction-relevant human pose features using a disentangled decoder. This is
achieved with a novel attention module that accurately captures the human
keypoints relevant to the current interaction category. Finally, our approach
fuses the appearance feature and pose feature via element-wise addition to form
the interaction representation. Experimental results show that our approach can
be readily applied to existing one-stage HOI detectors. Moreover, we achieve
state-of-the-art performance on two benchmarks: HICO-DET and V-COCO.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01714" title="Abstract">arXiv:2312.01714</a> [<a href="/pdf/2312.01714" title="Download PDF">pdf</a>, <a href="/format/2312.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingshuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Z">Zijun Min</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advancement of Large Language Models(LLMs) has brought substantial
attention to the Chain of Thought(CoT) approach, primarily due to its ability
to enhance the capability of LLMs on tasks requiring complex reasoning.
Moreover, the significance of CoT approaches extends to the application of LLMs
for multi-modal tasks, such as multi-modal question answering. However, the
selection of optimal CoT demonstration examples in multi-modal reasoning for
LLMs remains less explored for LLMs due to the inherent complexity of
multi-modal examples. In this paper, we introduce a novel approach that
addresses this challenge by using retrieval mechanisms to dynamically and
automatically select demonstration examples based on cross-modal similarities.
This method aims to refine the CoT reasoning process in multi-modal scenarios
via informing LLMs with more relevant and informative examples. Furthermore, we
employ a stratified sampling method categorising demonstration examples into
groups based on their types and retrieving examples from different groups
respectively to promote the diversity of demonstration examples. Through a
series of experiments, we demonstrate that our approach significantly improves
the performance of LLMs, achieving state-of-the-art results in multi-modal
reasoning tasks. Specifically, our methods demonstrate significant advancements
on the ScienceQA dataset. While our method based on ChatGPT outperforms the
Chameleon(ChatGPT) by 2.74% with an accuracy of 82.67%, the GPT4-based approach
surpasses the Chameleon(GPT-4) by 0.89%, achieving 87.43% on accuracy under the
same setting. Moreover, our best performing show a 6.05% increase over
Chameleon for ChatGPT-based models and a 4.57% increase for GPT-4-based models.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01720" title="Abstract">arXiv:2312.01720</a> [<a href="/pdf/2312.01720" title="Download PDF">pdf</a>, <a href="/format/2312.01720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure-ISAC: Secure V2X Communication: An Integrated Sensing and  Communication Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiguo Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In Vehicle-to-Everything (V2X) systems, reliable and secure information
exchange plays a pivotal role in road safety and traffic management. Due to the
open nature of the wireless medium and the constant or intermittent mobility of
vehicles, the security of transmissions in V2X is more challenging compared to
traditional wireless networks. Physical layer security (PLS) leverages the
inherent randomness of wireless communication channels to ensure the
confidentiality and security of information transmission. Current PLS schemes
in integrated communications and sensing (ISAC) enabled V2X systems is to
utilize communication interference to significantly impact the eavesdropping
channel more than the legitimate channel. However, in an ISAC-enabled V2X
system, it is crucial to prioritize and address the issue of interference
coupling as it significantly impacts the confidentiality and security of
information exchange. This goes beyond simply relying on the communication
interference. Until now, no discussions or studies on integrating security with
ISAC (Seucue-ISAC) in ISAC-enabled V2X systems, specifically regarding the
exploitation of sensing interference or coupling interference. In this article,
we provide a comprehensive review on PLS metrics and security threats
encountered in V2X communication. And then, we discuss and analyze four popular
PLS techniques and the main challenges associated with their implementation in
ISAC-enabled V2X systems. Finally, we share our vision for PLS studies in
ISAC-based V2X systems to promote Secure-ISAC.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01721" title="Abstract">arXiv:2312.01721</a> [<a href="/pdf/2312.01721" title="Download PDF">pdf</a>, <a href="/format/2312.01721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Self-Loop Paradox: Investigating the Impact of Self-Loops on Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lampert%2C+M">Moritz Lampert</a>, 
<a href="/search/cs?searchtype=author&query=Scholtes%2C+I">Ingo Scholtes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Second Learning on Graphs Conference (LoG 2023) as extended abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many Graph Neural Networks (GNNs) add self-loops to a graph to include
feature information about a node itself at each layer. However, if the GNN
consists of more than one layer, this information can return to its origin via
cycles in the graph topology. Intuition suggests that this "backflow" of
information should be larger in graphs with self-loops compared to graphs
without. In this work, we counter this intuition and show that for certain GNN
architectures, the information a node gains from itself can be smaller in
graphs with self-loops compared to the same graphs without. We adopt an
analytical approach for the study of statistical graph ensembles with a given
degree sequence and show that this phenomenon, which we call the self-loop
paradox, can depend both on the number of GNN layers $k$ and whether $k$ is
even or odd. We experimentally validate our theoretical findings in a synthetic
node classification task and investigate its practical relevance in 23
real-world graphs.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01725" title="Abstract">arXiv:2312.01725</a> [<a href="/pdf/2312.01725" title="Download PDF">pdf</a>, <a href="/format/2312.01725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableVITON: Learning Semantic Correspondence with Latent Diffusion  Model for Virtual Try-On
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Gyojung Gu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minho Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sunghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given a clothing image and a person image, an image-based virtual try-on aims
to generate a customized image that appears natural and accurately reflects the
characteristics of the clothing image. In this work, we aim to expand the
applicability of the pre-trained diffusion model so that it can be utilized
independently for the virtual try-on task.The main challenge is to preserve the
clothing details while effectively utilizing the robust generative capability
of the pre-trained model. In order to tackle these issues, we propose
StableVITON, learning the semantic correspondence between the clothing and the
human body within the latent space of the pre-trained diffusion model in an
end-to-end manner. Our proposed zero cross-attention blocks not only preserve
the clothing details by learning the semantic correspondence but also generate
high-fidelity images by utilizing the inherent knowledge of the pre-trained
model in the warping process. Through our proposed novel attention total
variation loss and applying augmentation, we achieve the sharp attention map,
resulting in a more precise representation of clothing details. StableVITON
outperforms the baselines in qualitative and quantitative evaluation, showing
promising quality in arbitrary person images. Our code is available at
https://github.com/rlawjdghek/StableVITON.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01728" title="Abstract">arXiv:2312.01728</a> [<a href="/pdf/2312.01728" title="Download PDF">pdf</a>, <a href="/format/2312.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImputeFormer: Graph Transformers for Generalizable Spatiotemporal  Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+T">Tong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+G">Guoyang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yuewen Mei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper focuses on the multivariate time series imputation problem using
deep neural architectures. The ubiquitous issue of missing data in both
scientific and engineering tasks necessitates the development of an effective
and general imputation model. Leveraging the wisdom and expertise garnered from
low-rank imputation methods, we power the canonical Transformers with three key
knowledge-driven enhancements, including projected temporal attention, global
adaptive graph convolution, and Fourier imputation loss. These task-agnostic
inductive biases exploit the inherent structures of incomplete time series, and
thus make our model versatile for a variety of imputation problems. We
demonstrate its superiority in terms of accuracy, efficiency, and flexibility
on heterogeneous datasets, including traffic speed, traffic volume, solar
energy, smart metering, and air quality. Comprehensive case studies are
performed to further strengthen the interpretability. Promising empirical
results provide strong conviction that incorporating time series primitives,
such as low-rank properties, can substantially facilitate the development of a
generalizable model to approach a wide range of spatiotemporal imputation
problems.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01729" title="Abstract">arXiv:2312.01729</a> [<a href="/pdf/2312.01729" title="Download PDF">pdf</a>, <a href="/format/2312.01729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly  Detection in Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qilin Li</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Senjian An</a>, 
<a href="/search/cs?searchtype=author&query=Ezard%2C+B">Bradley Ezard</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer-based models for anomaly detection in multivariate time series
can benefit from the self-attention mechanism due to its advantage in modeling
long-term dependencies. However, Transformer-based anomaly detection models
have problems such as a large amount of data being required for training,
standard positional encoding is not suitable for multivariate time series data,
and the interdependence between time series is not considered. To address these
limitations, we propose a novel anomaly detection method, named EdgeConvFormer,
which integrates Time2vec embedding, stacked dynamic graph CNN, and Transformer
to extract global and local spatial-time information. This design of
EdgeConvFormer empowers it with decomposition capacities for complex time
series, progressive spatiotemporal correlation discovery between time series,
and representation aggregation of multi-scale features. Experiments demonstrate
that EdgeConvFormer can learn the spatial-temporal correlations from
multivariate time series data and achieve better anomaly detection performance
than the state-of-the-art approaches on many real-world datasets of different
scales.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01732" title="Abstract">arXiv:2312.01732</a> [<a href="/pdf/2312.01732" title="Download PDF">pdf</a>, <a href="/format/2312.01732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-Aware Semantic Alignment for Full-Spectrum  Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+W">Wei Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Full-spectrum out-of-distribution (F-OOD) detection aims to accurately
recognize in-distribution (ID) samples while encountering semantic and
covariate shifts simultaneously. However, existing out-of-distribution (OOD)
detectors tend to overfit the covariance information and ignore intrinsic
semantic correlation, inadequate for adapting to complex domain
transformations. To address this issue, we propose a Likelihood-Aware Semantic
Alignment (LSA) framework to promote the image-text correspondence into
semantically high-likelihood regions. LSA consists of an offline Gaussian
sampling strategy which efficiently samples semantic-relevant visual embeddings
from the class-conditional Gaussian distribution, and a bidirectional prompt
customization mechanism that adjusts both ID-related and negative context for
discriminative ID/OOD boundary. Extensive experiments demonstrate the
remarkable OOD detection performance of our proposed LSA especially on the
intractable Near-OOD setting, surpassing existing methods by a margin of
$15.26\%$ and $18.88\%$ on two F-OOD benchmarks, respectively.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01734" title="Abstract">arXiv:2312.01734</a> [<a href="/pdf/2312.01734" title="Download PDF">pdf</a>, <a href="/format/2312.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Adapter for Face Recognition in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yu-Ju Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we tackle the challenge of face recognition in the wild, where
images often suffer from low quality and real-world distortions. Traditional
heuristic approaches-either training models directly on these degraded images
or their enhanced counterparts using face restoration techniques-have proven
ineffective, primarily due to the degradation of facial features and the
discrepancy in image domains. To overcome these issues, we propose an effective
adapter for augmenting existing face recognition models trained on high-quality
facial datasets. The key of our adapter is to process both the unrefined and
the enhanced images by two similar structures where one is fixed and the other
trainable. Such design can confer two benefits. First, the dual-input system
minimizes the domain gap while providing varied perspectives for the face
recognition model, where the enhanced image can be regarded as a complex
non-linear transformation of the original one by the restoration model. Second,
both two similar structures can be initialized by the pre-trained models
without dropping the past knowledge. The extensive experiments in zero-shot
settings show the effectiveness of our method by surpassing baselines of about
3%, 4%, and 7% in three datasets. Our code will be publicly available at
https://github.com/liuyunhaozz/FaceAdapter/.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01738" title="Abstract">arXiv:2312.01738</a> [<a href="/pdf/2312.01738" title="Download PDF">pdf</a>, <a href="/format/2312.01738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Political Leaning Inference to Multi-Party Systems:  Insights from the UK Political Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Landa%2C+J+F">Joseba Fernandez de Landa</a>, 
<a href="/search/cs?searchtype=author&query=Zubiaga%2C+A">Arkaitz Zubiaga</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">An ability to infer the political leaning of social media users can help in
gathering opinion polls thereby leading to a better understanding of public
opinion. While there has been a body of research attempting to infer the
political leaning of social media users, this has been typically simplified as
a binary classification problem (e.g. left vs right) and has been limited to a
single location, leading to a dearth of investigation into more complex,
multiclass classification and its generalizability to different locations,
particularly those with multi-party systems. Our work performs the first such
effort by studying political leaning inference in three of the UK's nations
(Scotland, Wales and Northern Ireland), each of which has a different political
landscape composed of multiple parties. To do so, we collect and release a
dataset comprising users labelled by their political leaning as well as
interactions with one another. We investigate the ability to predict the
political leaning of users by leveraging these interactions in challenging
scenarios such as few-shot learning, where training data is scarce, as well as
assessing the applicability to users with different levels of political
engagement. We show that interactions in the form of retweets between users can
be a very powerful feature to enable political leaning inference, leading to
consistent and robust results across different regions with multi-party
systems. However, we also see that there is room for improvement in predicting
the political leaning of users who are less engaged in politics.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01739" title="Abstract">arXiv:2312.01739</a> [<a href="/pdf/2312.01739" title="Download PDF">pdf</a>, <a href="/format/2312.01739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide-and-Conquer Strategy for Large-Scale Dynamic Bayesian Network  Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+H">Hui Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic Bayesian Networks (DBNs), renowned for their interpretability, have
become increasingly vital in representing complex stochastic processes in
various domains such as gene expression analysis, healthcare, and traffic
prediction. Structure learning of DBNs from data is challenging, particularly
for datasets with thousands of variables. Most current algorithms for DBN
structure learning are adaptations from those used in static Bayesian Networks
(BNs), and are typically focused on small-scale problems. In order to solve
large-scale problems while taking full advantage of existing algorithms, this
paper introduces a novel divide-and-conquer strategy, originally developed for
static BNs, and adapts it for large-scale DBN structure learning. In this work,
we specifically concentrate on 2 Time-sliced Bayesian Networks (2-TBNs), a
special class of DBNs. Furthermore, we leverage the prior knowledge of 2-TBNs
to enhance the performance of the strategy we introduce. Our approach
significantly improves the scalability and accuracy of 2-TBN structure
learning. Experimental results demonstrate the effectiveness of our method,
showing substantial improvements over existing algorithms in both computational
efficiency and structure learning accuracy. On problem instances with more than
1,000 variables, our approach improves two accuracy metrics by 74.45% and
110.94% on average , respectively, while reducing runtime by 93.65% on average.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01741" title="Abstract">arXiv:2312.01741</a> [<a href="/pdf/2312.01741" title="Download PDF">pdf</a>, <a href="/format/2312.01741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRSNetwork: Siamese Reconstruction-Segmentation Networks based on  Dynamic-Parameter Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nian%2C+B">Bingkun Nian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fenghe Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jianrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S.Kevin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a high-performance deep neural network for weak
target image segmentation, including medical image segmentation and infrared
image segmentation. To this end, this work analyzes the existing dynamic
convolutions and proposes dynamic parameter convolution (DPConv). Furthermore,
it reevaluates the relationship between reconstruction tasks and segmentation
tasks from the perspective of DPConv, leading to the proposal of a dual-network
model called the Siamese Reconstruction-Segmentation Network (SRSNet). The
proposed model is not only a universal network but also enhances the
segmentation performance without altering its structure, leveraging the
reconstruction task. Additionally, as the amount of training data for the
reconstruction network increases, the performance of the segmentation network
also improves synchronously. On seven datasets including five medical datasets
and two infrared image datasets, our SRSNet consistently achieves the best
segmentation results. The code is released at https://github.com/fidshu/SRSNet.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01742" title="Abstract">arXiv:2312.01742</a> [<a href="/pdf/2312.01742" title="Download PDF">pdf</a>, <a href="/format/2312.01742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Spiking Denoising Diffusion Implicit Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+R">Ryo Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Mukuta%2C+Y">Yusuke Mukuta</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spiking neural networks (SNNs) have garnered considerable attention owing to
their ability to run on neuromorphic devices with super-high speeds and
remarkable energy efficiencies. SNNs can be used in conventional neural
network-based time- and energy-consuming applications. However, research on
generative models within SNNs remains limited, despite their advantages. In
particular, diffusion models are a powerful class of generative models, whose
image generation quality surpass that of the other generative models, such as
GANs. However, diffusion models are characterized by high computational costs
and long inference times owing to their iterative denoising feature. Therefore,
we propose a novel approach fully spiking denoising diffusion implicit model
(FSDDIM) to construct a diffusion model within SNNs and leverage the high speed
and low energy consumption features of SNNs via synaptic current learning
(SCL). SCL fills the gap in that diffusion models use a neural network to
estimate real-valued parameters of a predefined probabilistic distribution,
whereas SNNs output binary spike trains. The SCL enables us to complete the
entire generative process of diffusion models exclusively using SNNs. We
demonstrate that the proposed method outperforms the state-of-the-art fully
spiking generative model.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01745" title="Abstract">arXiv:2312.01745</a> [<a href="/pdf/2312.01745" title="Download PDF">pdf</a>, <a href="/format/2312.01745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Adaptive Dual Association for Text-to-Image Person Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dixuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yixing Peng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+J">Jingke Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image person re-identification (ReID) aims to retrieve images of a
person based on a given textual description. The key challenge is to learn the
relations between detailed information from visual and textual modalities.
Existing works focus on learning a latent space to narrow the modality gap and
further build local correspondences between two modalities. However, these
methods assume that image-to-text and text-to-image associations are
modality-agnostic, resulting in suboptimal associations. In this work, we show
the discrepancy between image-to-text association and text-to-image association
and propose CADA: Cross-Modal Adaptive Dual Association that finely builds
bidirectional image-text detailed associations. Our approach features a
decoder-based adaptive dual association module that enables full interaction
between visual and textual modalities, allowing for bidirectional and adaptive
cross-modal correspondence associations. Specifically, the paper proposes a
bidirectional association mechanism: Association of text Tokens to image
Patches (ATP) and Association of image Regions to text Attributes (ARA). We
adaptively model the ATP based on the fact that aggregating cross-modal
features based on mistaken associations will lead to feature distortion. For
modeling the ARA, since the attributes are typically the first distinguishing
cues of a person, we propose to explore the attribute-level association by
predicting the masked text phrase using the related image region. Finally, we
learn the dual associations between texts and images, and the experimental
results demonstrate the superiority of our dual formulation. Codes will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01746" title="Abstract">arXiv:2312.01746</a> [<a href="/pdf/2312.01746" title="Download PDF">pdf</a>, <a href="/format/2312.01746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-DDVM: A Reproduction and Extension of Diffusion Model for Optical  Flow Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiaole Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Google proposes DDVM which for the first time demonstrates that a
general diffusion model for image-to-image translation task works impressively
well on optical flow estimation task without any specific designs like RAFT.
However, DDVM is still a closed-source model with the expensive and private
Palette-style pretraining. In this technical report, we present the first
open-source DDVM by reproducing it. We study several design choices and find
those important ones. By training on 40k public data with 4 GPUs, our
reproduction achieves comparable performance to the closed-source DDVM. The
code and model have been released in
https://github.com/DQiaole/FlowDiffusion_pytorch.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01747" title="Abstract">arXiv:2312.01747</a> [<a href="/pdf/2312.01747" title="Download PDF">pdf</a>, <a href="/format/2312.01747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous and Adaptive Role Selection for Multi-robot Collaborative  Area Search Based on Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lina Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhichao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuehu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the tasks of multi-robot collaborative area search, we propose the unified
approach for simultaneous mapping for sensing more targets (exploration) while
searching and locating the targets (coverage). Specifically, we implement a
hierarchical multi-agent reinforcement learning algorithm to decouple task
planning from task execution. The role concept is integrated into the
upper-level task planning for role selection, which enables robots to learn the
role based on the state status from the upper-view. Besides, an intelligent
role switching mechanism enables the role selection module to function between
two timesteps, promoting both exploration and coverage interchangeably. Then
the primitive policy learns how to plan based on their assigned roles and local
observation for sub-task execution. The well-designed experiments show the
scalability and generalization of our method compared with state-of-the-art
approaches in the scenes with varying complexity and number of robots.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01748" title="Abstract">arXiv:2312.01748</a> [<a href="/pdf/2312.01748" title="Download PDF">pdf</a>, <a href="/ps/2312.01748" title="Download PostScript">ps</a>, <a href="/format/2312.01748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep CNN for Coherent Seismic Noise Removal: A Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+R">Rohit Shrivastava</a> (1), 
<a href="/search/cs?searchtype=author&query=Asgekar%2C+A">Ashish Asgekar</a> (1), 
<a href="/search/cs?searchtype=author&query=Kramer%2C+E">Evert Kramer</a> (2) ((1) Shell Technology Center, Bengaluru, India, (2) Shell Technology Center, Amsterdam)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, Accepted for oral presentation in 82nd EAGE Conference, 2020, under "ML in Seismic Processing 1 - Noise"
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 82nd EAGE Conference and Exhibition 2020; 8-11 June 2020,
  Amsterdam, The Netherlands
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Seismic denoising is an important processing step before subsequent imaging
and interpretation, which consumes a significant amount of time, whether it is
for Quality control or for the associated computations. We present results of
our work in training convolutional neural networks for denoising seismic data,
specifically attenuation of surface related multiples and removal of overlap of
shot energies during simultaneous-shooting survey. The proposed methodology is
being explored not only for its ability to minimize human involvement but also
because of the trained filter's ability to accelerate the process, hence,
reduce processing time.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01751" title="Abstract">arXiv:2312.01751</a> [<a href="/pdf/2312.01751" title="Download PDF">pdf</a>, <a href="/format/2312.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Task Partitioning and Parallel Scheduling in Device-Assisted  Mobile Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xinlei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bo Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenbo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">With the development of the Internet of Things (IoT), certain IoT devices
have the capability to not only accomplish their own tasks but also
simultaneously assist other resource-constrained devices. Therefore, this paper
considers a device-assisted mobile edge computing system that leverages
auxiliary IoT devices to alleviate the computational burden on the edge
computing server and enhance the overall system performance. In this study,
computationally intensive tasks are decomposed into multiple partitions, and
each task partition can be processed in parallel on an IoT device or the edge
server. The objective of this research is to develop an efficient online
algorithm that addresses the joint optimization of task partitioning and
parallel scheduling under time-varying system states, posing challenges to
conventional numerical optimization methods. To address these challenges, a
framework called online task partitioning action and parallel scheduling policy
generation (OTPPS) is proposed, which is based on deep reinforcement learning
(DRL). Specifically, the framework leverages a deep neural network (DNN) to
learn the optimal partitioning action for each task by mapping input states.
Furthermore, it is demonstrated that the remaining parallel scheduling problem
exhibits NP-hard complexity when considering a specific task partitioning
action. To address this subproblem, a fair and delay-minimized task scheduling
(FDMTS) algorithm is designed. Extensive evaluation results demonstrate that
OTPPS achieves near-optimal average delay performance and consistently high
fairness levels in various environmental states compared to other baseline
schemes.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01752" title="Abstract">arXiv:2312.01752</a> [<a href="/pdf/2312.01752" title="Download PDF">pdf</a>, <a href="/ps/2312.01752" title="Download PostScript">ps</a>, <a href="/format/2312.01752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity threats in FinTech: A systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javaheri%2C+D">Danial Javaheri</a>, 
<a href="/search/cs?searchtype=author&query=Fahmideh%2C+M">Mahdi Fahmideh</a>, 
<a href="/search/cs?searchtype=author&query=Chizari%2C+H">Hassan Chizari</a>, 
<a href="/search/cs?searchtype=author&query=Lalbakhsh%2C+P">Pooia Lalbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junbeom Hur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid evolution of the Smart-everything movement and Artificial
Intelligence (AI) advancements have given rise to sophisticated cyber threats
that traditional methods cannot counteract. Cyber threats are extremely
critical in financial technology (FinTech) as a data-centric sector expected to
provide 24/7 services. This paper introduces a novel and refined taxonomy of
security threats in FinTech and conducts a comprehensive systematic review of
defensive strategies. Through PRISMA methodology applied to 74 selected studies
and topic modeling, we identified 11 central cyber threats, with 43 papers
detailing them, and pinpointed 9 corresponding defense strategies, as covered
in 31 papers. This in-depth analysis offers invaluable insights for
stakeholders ranging from banks and enterprises to global governmental bodies,
highlighting both the current challenges in FinTech and effective
countermeasures, as well as directions for future research.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01753" title="Abstract">arXiv:2312.01753</a> [<a href="/pdf/2312.01753" title="Download PDF">pdf</a>, <a href="/format/2312.01753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Tail Learning with Rebalanced Contrastive Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Alvis%2C+C">Charika De Alvis</a>, 
<a href="/search/cs?searchtype=author&query=Denipitiyage%2C+D">Dishanika Denipitiyage</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+S">Suranga Seneviratne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Integrating supervised contrastive loss to cross entropy-based communication
has recently been proposed as a solution to address the long-tail learning
problem. However, when the class imbalance ratio is high, it requires adjusting
the supervised contrastive loss to support the tail classes, as the
conventional contrastive learning is biased towards head classes by default. To
this end, we present Rebalanced Contrastive Learning (RCL), an efficient means
to increase the long tail classification accuracy by addressing three main
aspects: 1. Feature space balancedness - Equal division of the feature space
among all the classes, 2. Intra-Class compactness - Reducing the distance
between same-class embeddings, 3. Regularization - Enforcing larger margins for
tail classes to reduce overfitting. RCL adopts class frequency-based SoftMax
loss balancing to supervised contrastive learning loss and exploits scalar
multiplied features fed to the contrastive learning loss to enforce
compactness. We implement RCL on the Balanced Contrastive Learning (BCL)
Framework, which has the SOTA performance. Our experiments on three benchmark
datasets demonstrate the richness of the learnt embeddings and increased top-1
balanced accuracy RCL provides to the BCL framework. We further demonstrate
that the performance of RCL as a standalone loss also achieves state-of-the-art
level accuracy.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01756" title="Abstract">arXiv:2312.01756</a> [<a href="/pdf/2312.01756" title="Download PDF">pdf</a>, <a href="/ps/2312.01756" title="Download PostScript">ps</a>, <a href="/format/2312.01756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Literature Review on Sweet Orange Leaf Diseases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emon%2C+Y+R">Yousuf Rayhan Emon</a>, 
<a href="/search/cs?searchtype=author&query=Rabbani%2C+M+G">Md Golam Rabbani</a>, 
<a href="/search/cs?searchtype=author&query=Ahad%2C+D+M+T">Dr. Md. Taimur Ahad</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Faruk Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Sweet orange leaf diseases are significant to agricultural productivity. Leaf
diseases impact fruit quality in the citrus industry. The apparition of machine
learning makes the development of disease finder. Early detection and diagnosis
are necessary for leaf management. Sweet orange leaf disease-predicting
automated systems have already been developed using different image-processing
techniques. This comprehensive literature review is systematically based on
leaf disease and machine learning methodologies applied to the detection of
damaged leaves via image classification. The benefits and limitations of
different machine learning models, including Vision Transformer (ViT), Neural
Network (CNN), CNN with SoftMax and RBF SVM, Hybrid CNN-SVM, HLB-ConvMLP,
EfficientNet-b0, YOLOv5, YOLOv7, Convolutional, Deep CNN. These machine
learning models tested on various datasets and detected the disease. This
comprehensive review study related to leaf disease compares the performance of
the models; those models' accuracy, precision, recall, etc., were used in the
subsisting studies
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01758" title="Abstract">arXiv:2312.01758</a> [<a href="/pdf/2312.01758" title="Download PDF">pdf</a>, <a href="/format/2312.01758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CZL-CIAE: CLIP-driven Zero-shot Learning for Correcting Inverse Age  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Zero-shot age estimation aims to learn feature information about age from
input images and make inferences about a given person's image or video frame
without specific sample data. The development of zero-shot age estimation can
improve the efficiency and accuracy of various applications (e.g., age
verification and secure access control, etc.), while also promoting research on
multi-modal and zero-shot learning in the social media field. For example,
zero-sample age estimation can be used to create social networks focused on
specific age groups. However, existing methods mainly focus on supervised,
labeled age estimation learning, and the prediction effect of zero-shot
learning is very poor. To tackle the above issues, we propose a novel
CLIP-driven Zero-shot Learning for Correcting Inverse Age Estimation
(CZL-CIAE). Specifically, we first introduce the CLIP model to extract image
features and text semantic information respectively, and map them into a highly
semantically aligned high-dimensional feature space. Next, we designed a new
Transformer architecture (i.e., FourierFormer) to achieve channel evolution and
spatial interaction of images, and to fuse image and text semantic information.
Finally, we introduce reversible age estimation, which uses end-to-end error
feedback to reduce the error rate of age predictions. Through extensive
experiments on multiple data sets, CZL-CIAE has achieved better age prediction
results.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01759" title="Abstract">arXiv:2312.01759</a> [<a href="/pdf/2312.01759" title="Download PDF">pdf</a>, <a href="/ps/2312.01759" title="Download PostScript">ps</a>, <a href="/format/2312.01759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Sublinear-Time Edit Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+K">Karl Bringmann</a>, 
<a href="/search/cs?searchtype=author&query=Cassis%2C+A">Alejandro Cassis</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+N">Nick Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Kociumaka%2C+T">Tomasz Kociumaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SODA'24. Shortened abstract for arXiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the fundamental problem of approximating the edit distance of two
strings. After an extensive line of research led to the development of a
constant-factor approximation algorithm in almost-linear time, recent years
have witnessed a notable shift in focus towards sublinear-time algorithms.
Here, the task is typically formalized as the $(k, K)$-gap edit distance
problem: Distinguish whether the edit distance of two strings is at most $k$ or
more than $K$.
<br />Surprisingly, it is still possible to compute meaningful approximations in
this challenging regime. Nevertheless, in almost all previous work, truly
sublinear running time of $O(n^{1-\varepsilon})$ (for a constant $\varepsilon &gt;
0$) comes at the price of at least polynomial gap $K \ge k \cdot
n^{\Omega(\varepsilon)}$. Only recently, [Bringmann, Cassis, Fischer, and
Nakos; STOC'22] broke through this barrier and solved the sub-polynomial $(k,
k^{1+o(1)})$-gap edit distance problem in time $O(n/k + k^{4+o(1)})$, which is
truly sublinear if $n^{\Omega(1)} \le k \le n^{\frac14-\Omega(1)}$.The $n/k$
term is inevitable (already for Hamming distance), but it remains an important
task to optimize the $\mathrm{poly}(k)$ term and, in general, solve the $(k,
k^{1+o(1)})$-gap edit distance problem in sublinear-time for larger values of
$k$.
<br />In this work, we design an improved algorithm for the $(k, k^{1+o(1)})$-gap
edit distance problem in sublinear time $O(n/k + k^{2+o(1)})$, yielding a
significant quadratic speed-up over the previous $O(n/k + k^{4+o(1)})$-time
algorithm. Notably, our algorithm is unconditionally almost-optimal (up to
subpolynomial factors) in the regime where $k \leq n^{\frac13}$ and improves
upon the state of the art for $k \leq n^{\frac12-o(1)}$.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01760" title="Abstract">arXiv:2312.01760</a> [<a href="/pdf/2312.01760" title="Download PDF">pdf</a>, <a href="/format/2312.01760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Gradient Boosted Decision Trees and Neural Rankers: A Case-Study on  Short-Video Recommendations at ShareChat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeunen%2C+O">Olivier Jeunen</a>, 
<a href="/search/cs?searchtype=author&query=Sagtani%2C+H">Hitesh Sagtani</a>, 
<a href="/search/cs?searchtype=author&query=Doi%2C+H">Himanshu Doi</a>, 
<a href="/search/cs?searchtype=author&query=Karimov%2C+R">Rasul Karimov</a>, 
<a href="/search/cs?searchtype=author&query=Pokharna%2C+N">Neeti Pokharna</a>, 
<a href="/search/cs?searchtype=author&query=Kalim%2C+D">Danish Kalim</a>, 
<a href="/search/cs?searchtype=author&query=Ustimenko%2C+A">Aleksei Ustimenko</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+C">Christopher Green</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenzhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+R">Rishabh Mehrotra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing in the Industry Track Proceedings of the Forum for Information Retrieval Evaluation (FIRE '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Practitioners who wish to build real-world applications that rely on ranking
models, need to decide which modelling paradigm to follow. This is not an easy
choice to make, as the research literature on this topic has been shifting in
recent years. In particular, whilst Gradient Boosted Decision Trees (GBDTs)
have reigned supreme for more than a decade, the flexibility of neural networks
has allowed them to catch up, and recent works report accuracy metrics that are
on par. Nevertheless, practical systems require considerations beyond mere
accuracy metrics to decide on a modelling approach.
<br />This work describes our experiences in balancing some of the trade-offs that
arise, presenting a case study on a short-video recommendation application. We
highlight (1) neural networks' ability to handle large training data size,
user- and item-embeddings allows for more accurate models than GBDTs in this
setting, and (2) because GBDTs are less reliant on specialised hardware, they
can provide an equally accurate model at a lower cost. We believe these
findings are of relevance to researchers in both academia and industry, and
hope they can inspire practitioners who need to make similar modelling choices
in the future.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01764" title="Abstract">arXiv:2312.01764</a> [<a href="/pdf/2312.01764" title="Download PDF">pdf</a>, <a href="/format/2312.01764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Erasing Network Based on Multi-Scale Temporal Features for  Weakly Supervised Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guorong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuankai Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hanhua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+L">Laiyun Qing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of weakly supervised video anomaly detection is to learn a detection
model using only video-level labeled data. However, prior studies typically
divide videos into fixed-length segments without considering the complexity or
duration of anomalies. Moreover, these studies usually just detect the most
abnormal segments, potentially overlooking the completeness of anomalies. To
address these limitations, we propose a Dynamic Erasing Network (DE-Net) for
weakly supervised video anomaly detection, which learns multi-scale temporal
features. Specifically, to handle duration variations of abnormal events, we
first propose a multi-scale temporal modeling module, capable of extracting
features from segments of varying lengths and capturing both local and global
visual information across different temporal scales. Then, we design a dynamic
erasing strategy, which dynamically assesses the completeness of the detected
anomalies and erases prominent abnormal segments in order to encourage the
model to discover gentle abnormal segments in a video. The proposed method
obtains favorable performance compared to several state-of-the-art approaches
on three datasets: XD-Violence, TAD, and UCF-Crime. Code will be made available
at https://github.com/ArielZc/DE-Net.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01768" title="Abstract">arXiv:2312.01768</a> [<a href="/pdf/2312.01768" title="Download PDF">pdf</a>, <a href="/format/2312.01768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localizing and Assessing Node Significance in Default Mode Network using  Sub-Community Detection in Mild Cognitive Impairment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Ameiy Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+C+S">Chakka Sai Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+N">Neelam Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our study aims to utilize fMRI to identify the affected brain regions within
the Default Mode Network (DMN) in subjects with Mild Cognitive Impairment
(MCI), using a novel Node Significance Score (NSS). We construct
subject-specific DMN graphs by employing partial correlation of Regions of
Interest (ROIs) that make-up the DMN. For the DMN graph, ROIs are the nodes and
edges are determined based on partial correlation. Four popular community
detection algorithms (Clique Percolation Method (CPM), Louvain algorithm,
Greedy Modularity and Leading Eigenvectors) are applied to determine the
largest sub-community. NSS ratings are derived for each node, considering (I)
frequency in the largest sub-community within a class across all subjects and
(II) occurrence in the largest sub-community according to all four methods.
After computing the NSS of each ROI in both healthy and MCI subjects, we
quantify the score disparity to identify nodes most impacted by MCI. The
results reveal a disparity exceeding 20% for 10 DMN nodes, maximally for PCC
and Fusiform, showing 45.69% and 43.08% disparity. This aligns with existing
medical literature, additionally providing a quantitative measure that enables
the ordering of the affected ROIs. These findings offer valuable insights and
could lead to treatment strategies aggressively targeting the affected nodes.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01771" title="Abstract">arXiv:2312.01771</a> [<a href="/pdf/2312.01771" title="Download PDF">pdf</a>, <a href="/format/2312.01771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiarui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gandelsman%2C+Y">Yossi Gandelsman</a>, 
<a href="/search/cs?searchtype=author&query=Bar%2C+A">Amir Bar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jerryxu.net/IMProv">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In-context learning allows adapting a model to new tasks given a task
description at test time. In this paper, we present IMProv - a generative model
that is able to in-context learn visual tasks from multimodal prompts. Given a
textual description of a visual task (e.g. "Left: input image, Right:
foreground segmentation"), a few input-output visual examples, or both, the
model in-context learns to solve it for a new test input. We train a masked
generative transformer on a new dataset of figures from computer vision papers
and their associated captions, together with a captioned large-scale image-text
dataset. During inference time, we prompt the model with text and/or image task
example(s) and have the model inpaint the corresponding output. We show that
training our model with text conditioning and scaling the dataset size improves
in-context learning for computer vision tasks by over +10\% AP for Foreground
Segmentation, over +5\% gains in AP for Single Object Detection, and almost
20\% lower LPIPS in Colorization. Our empirical results suggest that vision and
language prompts are complementary and it is advantageous to use both to
achieve better in-context learning performance. Project page is available at
https://jerryxu.net/IMProv .
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01779" title="Abstract">arXiv:2312.01779</a> [<a href="/pdf/2312.01779" title="Download PDF">pdf</a>, <a href="/format/2312.01779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viral transmission in pedestrian crowds: Coupling an open-source code  assessing the risks of airborne contagion with diverse pedestrian dynamics  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nicolas%2C+A">Alexandre Nicolas</a> (ILM, CNRS), 
<a href="/search/cs?searchtype=author&query=Mendez%2C+S">Simon Mendez</a> (IMAG)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We study viral transmission in crowds via the short-ranged airborne pathway
using a purely model-based approach. Our goal is two-pronged. Firstly, we
illustrate with a concrete and pedagogical case study how to estimate the risks
of new viral infections by coupling pedestrian simulations with the
transmission algorithm that we recently released as open-source code. The
algorithm hinges on pre-computed viral concentration maps derived from
computational fluid dynamics (CFD) simulations. Secondly, we investigate to
what extent the transmission risk predictions depend on the pedestrian dynamics
model in use. For the simple bidirectional flow under consideration, the
predictions are found to be surprisingly stable across initial conditions and
models, despite the different microscopic arrangements of the simulated crowd,
as long as the crowd evolves in a qualitatively similarly way. On the other
hand, when major changes are observed in the crowd's behaviour, notably
whenever a jam occurs at the centre of the channel, the estimated risks surge
drastically.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01785" title="Abstract">arXiv:2312.01785</a> [<a href="/pdf/2312.01785" title="Download PDF">pdf</a>, <a href="/ps/2312.01785" title="Download PostScript">ps</a>, <a href="/format/2312.01785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed-Form Solutions for Grid-Forming Converters: A Design-Oriented  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+F">Fangzhou Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+T">Tianhua Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Harnefors%2C+L">Lennart Harnefors</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+B">Bo Fan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Heng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Z">Zichao Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiongfei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper derives closed-form solutions for grid-forming converters with
power synchronization control (PSC) by subtly simplifying and factorizing the
complex closed-loop models. The solutions can offer clear analytical insights
into control-loop interactions, enabling guidelines for robust controller
design. It is proved that 1) the proportional gains of PSC and alternating
voltage control (AVC) can introduce negative resistance, which aggravates
synchronous resonance (SR) of power control, 2) the integral gain of AVC is the
cause of sub-synchronous resonance (SSR) in stiff-grid interconnections, albeit
the proportional gain of AVC can help dampen the SSR, and 3) surprisingly, the
current controller that dampens SR actually exacerbates SSR. Controller design
guidelines are given based on analytical insights. The findings are verified by
simulations and experimental results.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01786" title="Abstract">arXiv:2312.01786</a> [<a href="/pdf/2312.01786" title="Download PDF">pdf</a>, <a href="/ps/2312.01786" title="Download PostScript">ps</a>, <a href="/format/2312.01786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output-sensitive Complexity of Multi-Objective Integer Network Flow  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6nen%2C+D">David K&#xf6;nen</a>, 
<a href="/search/cs?searchtype=author&query=Stiglmayr%2C+M">Michael Stiglmayr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">This paper addresses the output-sensitive complexity for linear
multi-objective integer minimum cost flow (MOIMCF) problems and provides
insights about the time complexity for enumerating all supported nondominated
vectors. The paper shows that there can not exist an output-polynomial time
algorithm for the enumeration of all supported nondominated vectors that
determine the vectors in an ordered way in the outcome space unless NP = P.
Moreover, novel methods for identifying supported nondominated vectors in
bi-objective minimum cost flow (BOIMCF) problems are proposed, accompanied by a
numerical comparison between decision- and objective-space methods. A novel,
equivalent and more compact formulation of the minimum cost flow ILP
formulation used in the e-constrained-scalarization approach is introduced,
demonstrating enhanced efficiency in the numerical tests
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01787" title="Abstract">arXiv:2312.01787</a> [<a href="/pdf/2312.01787" title="Download PDF">pdf</a>, <a href="/format/2312.01787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Linguistic Patterns to Mitigate Inherent Human Bias in  Offensive Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanyel%2C+T">Toygar Tanyel</a>, 
<a href="/search/cs?searchtype=author&query=Alkurdi%2C+B">Besher Alkurdi</a>, 
<a href="/search/cs?searchtype=author&query=Ayvaz%2C+S">Serkan Ayvaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the proliferation of social media, there has been a sharp increase in
offensive content, particularly targeting vulnerable groups, exacerbating
social problems such as hatred, racism, and sexism. Detecting offensive
language use is crucial to prevent offensive language from being widely shared
on social media. However, the accurate detection of irony, implication, and
various forms of hate speech on social media remains a challenge. Natural
language-based deep learning models require extensive training with large,
comprehensive, and labeled datasets. Unfortunately, manually creating such
datasets is both costly and error-prone. Additionally, the presence of
human-bias in offensive language datasets is a major concern for deep learning
models. In this paper, we propose a linguistic data augmentation approach to
reduce bias in labeling processes, which aims to mitigate the influence of
human bias by leveraging the power of machines to improve the accuracy and
fairness of labeling processes. This approach has the potential to improve
offensive language classification tasks across multiple languages and reduce
the prevalence of offensive content on social media.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01789" title="Abstract">arXiv:2312.01789</a> [<a href="/pdf/2312.01789" title="Download PDF">pdf</a>, <a href="/format/2312.01789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-stage optimized unified adversarial patch for attacking  visible-infrared cross-modal detectors in the physical world
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengyin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiwen Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Currently, many studies have addressed security concerns related to visible
and infrared detectors independently. In practical scenarios, utilizing
cross-modal detectors for tasks proves more reliable than relying on
single-modal detectors. Despite this, there is a lack of comprehensive security
evaluations for cross-modal detectors. While existing research has explored the
feasibility of attacks against cross-modal detectors, the implementation of a
robust attack remains unaddressed. This work introduces the Two-stage Optimized
Unified Adversarial Patch (TOUAP) designed for performing attacks against
visible-infrared cross-modal detectors in real-world, black-box settings. The
TOUAP employs a two-stage optimization process: firstly, PSO optimizes an
irregular polygonal infrared patch to attack the infrared detector; secondly,
the color QR code is optimized, and the shape information of the infrared patch
from the first stage is used as a mask. The resulting irregular polygon visible
modal patch executes an attack on the visible detector. Through extensive
experiments conducted in both digital and physical environments, we validate
the effectiveness and robustness of the proposed method. As the TOUAP surpasses
baseline performance, we advocate for its widespread attention.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01790" title="Abstract">arXiv:2312.01790</a> [<a href="/pdf/2312.01790" title="Download PDF">pdf</a>, <a href="/format/2312.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multi-Modal Fusion for Image Manipulation Detection and  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Triaridis%2C+K">Konstantinos Triaridis</a>, 
<a href="/search/cs?searchtype=author&query=Mezaris%2C+V">Vasileios Mezaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication, 30th Int. Conf. on MultiMedia Modeling (MMM 2024), Amsterdam, NL, Jan.-Feb. 2024. This is the "submitted manuscript" version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent image manipulation localization and detection techniques usually
leverage forensic artifacts and traces that are produced by a noise-sensitive
filter, such as SRM and Bayar convolution. In this paper, we showcase that
different filters commonly used in such approaches excel at unveiling different
types of manipulations and provide complementary forensic traces. Thus, we
explore ways of merging the outputs of such filters and aim to leverage the
complementary nature of the artifacts produced to perform image manipulation
localization and detection (IMLD). We propose two distinct methods: one that
produces independent features from each forensic filter and then fuses them
(this is referred to as late fusion) and one that performs early mixing of
different modal outputs and produces early combined features (this is referred
to as early fusion). We demonstrate that both approaches achieve competitive
performance for both image manipulation localization and detection,
outperforming state-of-the-art models across several datasets.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01792" title="Abstract">arXiv:2312.01792</a> [<a href="/pdf/2312.01792" title="Download PDF">pdf</a>, <a href="/format/2312.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wild-Tab: A Benchmark For Out-Of-Distribution Generalization In Tabular  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Out-of-Distribution (OOD) generalization, a cornerstone for building robust
machine learning models capable of handling data diverging from the training
set's distribution, is an ongoing challenge in deep learning. While significant
progress has been observed in computer vision and natural language processing,
its exploration in tabular data, ubiquitous in many industrial applications,
remains nascent. To bridge this gap, we present Wild-Tab, a large-scale
benchmark tailored for OOD generalization in tabular regression tasks. The
benchmark incorporates 3 industrial datasets sourced from fields like weather
prediction and power consumption estimation, providing a challenging testbed
for evaluating OOD performance under real-world conditions. Our extensive
experiments, evaluating 10 distinct OOD generalization methods on Wild-Tab,
reveal nuanced insights. We observe that many of these methods often struggle
to maintain high-performance levels on unseen data, with OOD performance
showing a marked drop compared to in-distribution performance. At the same
time, Empirical Risk Minimization (ERM), despite its simplicity, delivers
robust performance across all evaluations, rivaling the results of
state-of-the-art methods. Looking forward, we hope that the release of Wild-Tab
will facilitate further research on OOD generalization and aid in the
deployment of machine learning models in various real-world contexts where
handling distribution shifts is a crucial requirement.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01795" title="Abstract">arXiv:2312.01795</a> [<a href="/pdf/2312.01795" title="Download PDF">pdf</a>, <a href="/format/2312.01795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Continual Learning with CoCoA in High-dimensional Linear  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hellkvist%2C+M">Martin Hellkvist</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96z%C3%A7elikkale%2C+A">Ay&#xe7;a &#xd6;z&#xe7;elikkale</a>, 
<a href="/search/cs?searchtype=author&query=Ahl%C3%A9n%2C+A">Anders Ahl&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider estimation under scenarios where the signals of interest exhibit
change of characteristics over time. In particular, we consider the continual
learning problem where different tasks, e.g., data with different
distributions, arrive sequentially and the aim is to perform well on the newly
arrived task without performance degradation on the previously seen tasks. In
contrast to the continual learning literature focusing on the centralized
setting, we investigate the problem from a distributed estimation perspective.
We consider the well-established distributed learning algorithm COCOA, which
distributes the model parameters and the corresponding features over the
network. We provide exact analytical characterization for the generalization
error of COCOA under continual learning for linear regression in a range of
scenarios, where overparameterization is of particular interest. These
analytical results characterize how the generalization error depends on the
network structure, the task similarity and the number of tasks, and show how
these dependencies are intertwined. In particular, our results show that the
generalization error can be significantly reduced by adjusting the network
size, where the most favorable network size depends on task similarity and the
number of tasks. We present numerical results verifying the theoretical
analysis and illustrate the continual learning performance of COCOA with a
digit classification task.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01796" title="Abstract">arXiv:2312.01796</a> [<a href="/pdf/2312.01796" title="Download PDF">pdf</a>, <a href="/format/2312.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Bayesian Optimization to Design Time Step Size Controllers with  Application to Modified Patankar--Runge--Kutta Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Izgin%2C+T">Thomas Izgin</a>, 
<a href="/search/math?searchtype=author&query=Ranocha%2C+H">Hendrik Ranocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 16 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Modified Patankar--Runge--Kutta (MPRK) methods are linearly implicit time
integration schemes developed to preserve positivity and a linear invariant
such as the total mass in chemical reactions. MPRK methods are naturally
equipped with embedded schemes yielding a local error estimate similar to
Runge--Kutta pairs. To design good time step size controllers using these error
estimates, we propose to use Bayesian optimization. In particular, we design a
novel objective function that captures important properties such as tolerance
convergence and computational stability. We apply our new approach to several
MPRK schemes and controllers based on digital signal processing, extending
classical PI and PID controllers. We demonstrate that the optimization process
yields controllers that are at least as good as the best controllers chosen
from a wide range of suggestions available for classical explicit and implicit
time integration methods.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01797" title="Abstract">arXiv:2312.01797</a> [<a href="/pdf/2312.01797" title="Download PDF">pdf</a>, <a href="/format/2312.01797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM A*: Human in the Loop Large Language Models Enabled A* Search for  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hengjia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This research focuses on how Large Language Models (LLMs) can help with path
planning for mobile embodied agents such as robots, in a human-in-the-loop and
interactive manner. A novel framework named LLM A*, aims to leverage the
commonsense of LLMs, and the utility-optimal A* is proposed to facilitate
few-shot near-optimal path planning. Prompts are used to 1) provide LLMs with
essential information like environment, cost, heuristics, etc.; 2) communicate
human feedback to LLMs on intermediate planning results. This makes the whole
path planning process a `white box' and human feedback guides LLM A* to
converge quickly compared to other data-driven methods such as reinforcement
learning-based (RL) path planning. In addition, it makes code-free path
planning practical, henceforth promoting the inclusiveness of artificial
intelligence techniques. Comparative analysis against A* and RL shows that LLM
A* is more efficient in terms of search space and achieves an on-a-par path
with A* and a better path than RL. The interactive nature of LLM A* also makes
it a promising tool for deployment in collaborative human-robot tasks.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01800" title="Abstract">arXiv:2312.01800</a> [<a href="/pdf/2312.01800" title="Download PDF">pdf</a>, <a href="/format/2312.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Neural Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dall%27Asen%2C+N">Nicola Dall&#x27;Asen</a>, 
<a href="/search/cs?searchtype=author&query=Menapace%2C+W">Willi Menapace</a>, 
<a href="/search/cs?searchtype=author&query=Peruzzo%2C+E">Elia Peruzzo</a>, 
<a href="/search/cs?searchtype=author&query=Sangineto%2C+E">Enver Sangineto</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computer Vision and Image Understanding, project website at <a href="https://fodark.github.io/collaborative-neural-painting/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The process of painting fosters creativity and rational planning. However,
existing generative AI mostly focuses on producing visually pleasant artworks,
without emphasizing the painting process. We introduce a novel task,
Collaborative Neural Painting (CNP), to facilitate collaborative art painting
generation between humans and machines. Given any number of user-input
brushstrokes as the context or just the desired object class, CNP should
produce a sequence of strokes supporting the completion of a coherent painting.
Importantly, the process can be gradual and iterative, so allowing users'
modifications at any phase until the completion. Moreover, we propose to solve
this task using a painting representation based on a sequence of parametrized
strokes, which makes it easy both editing and composition operations. These
parametrized strokes are processed by a Transformer-based architecture with a
novel attention mechanism to model the relationship between the input strokes
and the strokes to complete. We also propose a new masking scheme to reflect
the interactive nature of CNP and adopt diffusion models as the basic learning
process for its effectiveness and diversity in the generative field. Finally,
to develop and validate methods on the novel task, we introduce a new dataset
of painted objects and an evaluation protocol to benchmark CNP both
quantitatively and qualitatively. We demonstrate the effectiveness of our
approach and the potential of the CNP task as a promising avenue for future
research.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01801" title="Abstract">arXiv:2312.01801</a> [<a href="/pdf/2312.01801" title="Download PDF">pdf</a>, <a href="/format/2312.01801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPROUT: Authoring Programming Tutorials with Interactive Visualization  of Large Language Model Generation Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhen Wen</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+L">Luoxuan Weng</a>, 
<a href="/search/cs?searchtype=author&query=Woodman%2C+O">Ollie Woodman</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The rapid development of large language models (LLMs), such as ChatGPT, has
revolutionized the efficiency of creating programming tutorials. LLMs can be
instructed with text prompts to generate comprehensive text descriptions of
code snippets. However, the lack of transparency in the end-to-end generation
process has hindered the understanding of model behavior and limited user
control over the generated results. To tackle this challenge, we introduce a
novel approach that breaks down the programming tutorial creation task into
actionable steps. By employing the tree-of-thought method, LLMs engage in an
exploratory process to generate diverse and faithful programming tutorials. We
then present SPROUT, an authoring tool equipped with a series of interactive
visualizations that empower users to have greater control and understanding of
the programming tutorial creation process. A formal user study demonstrated the
effectiveness of SPROUT, showing that our tool assists users to actively
participate in the programming tutorial creation process, leading to more
reliable and customizable results. By providing users with greater control and
understanding, SPROUT enhances the user experience and improves the overall
quality of programming tutorial. A free copy of this paper and all supplemental
materials are available at
https://osf.io/uez2t/?view_only=5102e958802341daa414707646428f86.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01804" title="Abstract">arXiv:2312.01804</a> [<a href="/pdf/2312.01804" title="Download PDF">pdf</a>, <a href="/ps/2312.01804" title="Download PostScript">ps</a>, <a href="/format/2312.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Maximum Dissatisfaction in the Allocation of Indivisible  Items under a Common Preference Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiarelli%2C+N">Nina Chiarelli</a>, 
<a href="/search/cs?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/cs?searchtype=author&query=Darmann%2C+A">Andreas Darmann</a>, 
<a href="/search/cs?searchtype=author&query=Lendl%2C+S">Stefan Lendl</a>, 
<a href="/search/cs?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Mur%C5%A1i%C4%8D%2C+P">Peter Mur&#x161;i&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Pferschy%2C+U">Ulrich Pferschy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">We consider the task of allocating indivisible items to agents, when the
agents' preferences over the items are identical. The preferences are captured
by means of a directed acyclic graph, with vertices representing items and an
edge $(a,b)$ meaning that each of the agents prefers item $a$ over item $b$.
The dissatisfaction of an agent is measured by the number of items that the
agent does not receive and also does not receive any more preferred item. The
aim is to allocate the items to the agents in a fair way, i.e., to minimize the
maximum dissatisfaction among the agents. We study the status of computational
complexity of that problem and establish the following dichotomy: the problem
is NP-hard for the case of at least three agents, even on fairly restricted
graphs, but polynomially solvable for two agents. We also provide several
polynomial-time results with respect to different underlying graph structures,
such as graphs of width at most two and tree-like structures such as stars and
matchings. These findings are complemented with fixed parameter tractability
results related to path modules and independent set modules. Techniques
employed in the paper include bottleneck assignment problem, greedy algorithm,
dynamic programming, maximum network flow, and integer linear programming.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01809" title="Abstract">arXiv:2312.01809</a> [<a href="/pdf/2312.01809" title="Download PDF">pdf</a>, <a href="/ps/2312.01809" title="Download PostScript">ps</a>, <a href="/format/2312.01809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE-LIO: Semantics-enhanced Solid-State-LiDAR-Inertial Odometry for  Tree-rich Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tisheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Linfu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hailiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Man Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xiaoji Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this letter, we propose a semantics-enhanced solid-state-LiDAR-inertial
odometry (SE-LIO) in tree-rich environments. Multiple LiDAR frames are first
merged and compensated with the inertial navigation system (INS) to increase
the point-cloud coverage, thus improving the accuracy of semantic segmentation.
The unstructured point clouds, such as tree leaves and dynamic objects, are
then removed with the semantic information. Furthermore, the pole-like point
clouds, primarily tree trunks, are modeled as cylinders to improve positioning
accuracy. An adaptive piecewise cylinder-fitting method is proposed to
accommodate environments with a high prevalence of curved tree trunks. Finally,
the iterated error-state Kalman filter (IESKF) is employed for state
estimation. Point-to-cylinder and point-to-plane constraints are tightly
coupled with the prior constraints provided by the INS to obtain the maximum a
posteriori estimation. Targeted experiments are conducted in complex campus and
park environments to evaluate the performance of SE-LIO. The proposed methods,
including removing the unstructured point clouds and the adaptive cylinder
fitting, yield improved accuracy. Specifically, the positioning accuracy of the
proposed SE-LIO is improved by 43.1% compared to the plane-based LIO.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01810" title="Abstract">arXiv:2312.01810</a> [<a href="/pdf/2312.01810" title="Download PDF">pdf</a>, <a href="/format/2312.01810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental and numerical investigations on the acoustoelastic effect  in hyperelastic waveguides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barth%2C+T">Tilmann Barth</a>, 
<a href="/search/cs?searchtype=author&query=Rauter%2C+N">Natalie Rauter</a>, 
<a href="/search/cs?searchtype=author&query=Lammering%2C+R">Rolf Lammering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Guided ultrasonic wave based structural health monitoring has been of
interest over decades. However, the influence of pre-stress states on the
propagation of Lamb waves in thin-walled structures is not fully covered, yet.
So far experimental work presented in the literature only focuses on a few
individual frequencies, which does not allow a comprehensive verification of
the numerous numerical investigations. Furthermore, most work is based on the
strain-energy density function by Murnaghan. To validate the common modeling
approach and to investigate the suitability of other non-linear strain-energy
density functions an extensive experimental and numerical investigation
covering a large frequency range is presented here. The numerical simulation
comprises the use of the Neo-Hooke as well as the Murnaghan material model. It
is found that these two material models show qualitatively similar results.
Furthermore, the comparison with the experimental results reveals, that the
Neo-Hooke material model reproduces the effect of pre-stress on the difference
in the Lamb wave phase velocity very well in most cases. For the $A_0$ wave
mode at higher frequencies, however, the sign of this difference is only
correctly predicted by the Murnaghan model. In contrast to this the Murnaghan
material model fails to predict the sign change for the $S_0$ wave mode.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01811" title="Abstract">arXiv:2312.01811</a> [<a href="/pdf/2312.01811" title="Download PDF">pdf</a>, <a href="/format/2312.01811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based Potential Games for Joint Motion Forecasting and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diehl%2C+C">Christopher Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Klosek%2C+T">Tobias Klosek</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+M">Martin Kr&#xfc;ger</a>, 
<a href="/search/cs?searchtype=author&query=Murzyn%2C+N">Nils Murzyn</a>, 
<a href="/search/cs?searchtype=author&query=Osterburg%2C+T">Timo Osterburg</a>, 
<a href="/search/cs?searchtype=author&query=Bertram%2C+T">Torsten Bertram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning, CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">This work uses game theory as a mathematical framework to address interaction
modeling in multi-agent motion forecasting and control. Despite its
interpretability, applying game theory to real-world robotics, like automated
driving, faces challenges such as unknown game parameters. To tackle these, we
establish a connection between differential games, optimal control, and
energy-based models, demonstrating how existing approaches can be unified under
our proposed Energy-based Potential Game formulation. Building upon this, we
introduce a new end-to-end learning application that combines neural networks
for game-parameter inference with a differentiable game-theoretic optimization
layer, acting as an inductive bias. The analysis provides empirical evidence
that the game-theoretic layer adds interpretability and improves the predictive
performance of various neural network backbones using two simulations and two
real-world driving datasets.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01816" title="Abstract">arXiv:2312.01816</a> [<a href="/pdf/2312.01816" title="Download PDF">pdf</a>, <a href="/format/2312.01816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Symbolic Regression: Gotta Fit &#x27;Em All
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenachi%2C+W">Wassim Tenachi</a>, 
<a href="/search/cs?searchtype=author&query=Ibata%2C+R">Rodrigo Ibata</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7ois%2C+T+L">Thibaut L. Fran&#xe7;ois</a>, 
<a href="/search/cs?searchtype=author&query=Diakogiannis%2C+F+I">Foivos I. Diakogiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 2 tables. Submitted to ApJL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We introduce "Class Symbolic Regression" a first framework for automatically
finding a single analytical functional form that accurately fits multiple
datasets - each governed by its own (possibly) unique set of fitting
parameters. This hierarchical framework leverages the common constraint that
all the members of a single class of physical phenomena follow a common
governing law. Our approach extends the capabilities of our earlier Physical
Symbolic Optimization ($\Phi$-SO) framework for Symbolic Regression, which
integrates dimensional analysis constraints and deep reinforcement learning for
symbolic analytical function discovery from data. We demonstrate the efficacy
of this novel approach by applying it to a panel of synthetic toy case datasets
and showcase its practical utility for astrophysics by successfully extracting
an analytic galaxy potential from a set of simulated orbits approximating
stellar streams.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01818" title="Abstract">arXiv:2312.01818</a> [<a href="/pdf/2312.01818" title="Download PDF">pdf</a>, <a href="/format/2312.01818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Machine Morality through Experience and Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tennant%2C+E">Elizaveta Tennant</a>, 
<a href="/search/cs?searchtype=author&query=Hailes%2C+S">Stephen Hailes</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Increasing interest in ensuring safety of next-generation Artificial
Intelligence (AI) systems calls for novel approaches to embedding morality into
autonomous agents. Traditionally, this has been done by imposing explicit
top-down rules or hard constraints on systems, for example by filtering system
outputs through pre-defined ethical rules. Recently, instead, entirely
bottom-up methods for learning implicit preferences from human behavior have
become increasingly popular, such as those for training and fine-tuning Large
Language Models. In this paper, we provide a systematization of existing
approaches to the problem of introducing morality in machines - modeled as a
continuum, and argue that the majority of popular techniques lie at the
extremes - either being fully hard-coded, or entirely learned, where no
explicit statement of any moral principle is required. Given the relative
strengths and weaknesses of each type of methodology, we argue that more hybrid
solutions are needed to create adaptable and robust, yet more controllable and
interpretable agents.
<br />In particular, we present three case studies of recent works which use
learning from experience (i.e., Reinforcement Learning) to explicitly provide
moral principles to learning agents - either as intrinsic rewards, moral
logical constraints or textual principles for language models. For example,
using intrinsic rewards in Social Dilemma games, we demonstrate how it is
possible to represent classical moral frameworks for agents. We also present an
overview of the existing work in this area in order to provide empirical
evidence for the potential of this hybrid approach. We then discuss strategies
for evaluating the effectiveness of moral learning agents. Finally, we present
open research questions and implications for the future of AI safety and ethics
which are emerging from this framework.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01819" title="Abstract">arXiv:2312.01819</a> [<a href="/pdf/2312.01819" title="Download PDF">pdf</a>, <a href="/format/2312.01819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Completely Monotone Conjecture for R&#xe9;nyi Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Laigang Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we generalize the completely monotone conjecture from Shannon
entropy to the R\'enyi entropy. We confirm this conjecture for the order of
derivative up to $3$, when the order of R\'enyi entropy is in certain regimes.
We also investigate concavity of R\'enyi entropy power and the completely
monotone conjecture for Tsallis entropy. We observe that the completely
monotone conjecture is true for Tsallis entropy of order $2$. Our proofs in
this paper are based on the techniques of integration-by-parts and
sum-of-squares.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01823" title="Abstract">arXiv:2312.01823</a> [<a href="/pdf/2312.01823" title="Download PDF">pdf</a>, <a href="/format/2312.01823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exchange-of-Thought: Enhancing Large Language Model Capabilities through  Cross-Model Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiushi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qipeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Junqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have recently made significant strides in
complex reasoning tasks through the Chain-of-Thought technique. Despite this
progress, their reasoning is often constrained by their intrinsic
understanding, lacking external insights. To address this, we propose
Exchange-of-Thought (EoT), a novel framework that enables cross-model
communication during problem-solving. Drawing inspiration from network
topology, EoT integrates four unique communication paradigms: Memory, Report,
Relay, and Debate. This paper delves into the communication dynamics and volume
associated with each paradigm. To counterbalance the risks of incorrect
reasoning chains, we implement a robust confidence evaluation mechanism within
these communications. Our experiments across diverse complex reasoning tasks
demonstrate that EoT significantly surpasses established baselines,
underscoring the value of external insights in enhancing LLM performance.
Furthermore, we show that EoT achieves these superior results in a
cost-effective manner, marking a promising advancement for efficient and
collaborative AI problem-solving.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01826" title="Abstract">arXiv:2312.01826</a> [<a href="/pdf/2312.01826" title="Download PDF">pdf</a>, <a href="/format/2312.01826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-based Coverage Manifold Estimation: Machine Learning, Stochastic  Geometry, or Simulation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+W+U">Washim Uddin Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Given the necessity of connecting the unconnected, covering blind spots has
emerged as a critical task in the next-generation wireless communication
network. A direct solution involves obtaining a coverage manifold that visually
showcases network coverage performance at each position. Our goal is to devise
different methods that minimize the absolute error between the estimated
coverage manifold and the actual coverage manifold (referred to as accuracy),
while simultaneously maximizing the reduction in computational complexity
(measured by computational latency). Simulation is a common method for
acquiring coverage manifolds. Although accurate, it is computationally
expensive, making it challenging to extend to large-scale networks. In this
paper, we expedite traditional simulation methods by introducing a statistical
model termed line-of-sight probability-based accelerated simulation. Stochastic
geometry is suitable for evaluating the performance of large-scale networks,
albeit in a coarse-grained manner. Therefore, we propose a second method
wherein a model training approach is applied to the stochastic geometry
framework to enhance accuracy and reduce complexity. Additionally, we propose a
machine learning-based method that ensures both low complexity and high
accuracy, albeit with a significant demand for the size and quality of the
dataset. Furthermore, we describe the relationships between these three
methods, compare their complexity and accuracy as performance verification, and
discuss their application scenarios.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01832" title="Abstract">arXiv:2312.01832</a> [<a href="/pdf/2312.01832" title="Download PDF">pdf</a>, <a href="/format/2312.01832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPECRUN: The Danger of Speculative Runahead Execution in Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaoqun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Gang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiliang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Runahead execution is a continuously evolving microarchitectural technique
for processor performance. This paper introduces the first transient execution
attack on the runahead execution, called SPECRUN, which exploits the unresolved
branch prediction during runahead execution. We show that SPECRUN eliminates
the limitation on the number of transient instructions posed by the reorder
buffer size, enhancing the exploitability and harmfulness of the attack. We
concretely demonstrate a proof-of-concept attack that causes leaking secrets
from a victim process, validate the merit of SPECRUN, and design a secure
runahead execution scheme. This paper highlights the need to consider the
security of potential optimization techniques before implementing them in a
processor.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01835" title="Abstract">arXiv:2312.01835</a> [<a href="/pdf/2312.01835" title="Download PDF">pdf</a>, <a href="/format/2312.01835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few Clicks Suffice: Active Test-Time Adaptation for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Longhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhuo He</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Binhui Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Test-time adaptation (TTA) adapts the pre-trained models during inference
using unlabeled test data and has received a lot of research attention due to
its potential practical value. Unfortunately, without any label supervision,
existing TTA methods rely heavily on heuristic or empirical studies. Where to
update the model always falls into suboptimal or brings more computational
resource consumption. Meanwhile, there is still a significant performance gap
between the TTA approaches and their supervised counterparts. Motivated by
active learning, in this work, we propose the active test-time adaptation for
semantic segmentation setup. Specifically, we introduce the human-in-the-loop
pattern during the testing phase, which queries very few labels to facilitate
predictions and model updates in an online manner. To do so, we propose a
simple but effective ATASeg framework, which consists of two parts, i.e., model
adapter and label annotator. Extensive experiments demonstrate that ATASeg
bridges the performance gap between TTA methods and their supervised
counterparts with only extremely few annotations, even one click for labeling
surpasses known SOTA TTA methods by 2.6% average mIoU on ACDC benchmark.
Empirical results imply that progress in either the model adapter or the label
annotator will bring improvements to the ATASeg framework, giving it large
research and reality potential.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01836" title="Abstract">arXiv:2312.01836</a> [<a href="/pdf/2312.01836" title="Download PDF">pdf</a>, <a href="/format/2312.01836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Drill Boom Hole-Seeking Control via Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Haoqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongbo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jingliang Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intelligent drill boom hole-seeking is a promising technology for enhancing
drilling efficiency, mitigating potential safety hazards, and relieving human
operators. Most existing intelligent drill boom control methods rely on a
hierarchical control framework based on inverse kinematics. However, these
methods are generally time-consuming due to the computational complexity of
inverse kinematics and the inefficiency of the sequential execution of multiple
joints. To tackle these challenges, this study proposes an integrated drill
boom control method based on Reinforcement Learning (RL). We develop an
integrated drill boom control framework that utilizes a parameterized policy to
directly generate control inputs for all joints at each time step, taking
advantage of joint posture and target hole information. By formulating the
hole-seeking task as a Markov decision process, contemporary mainstream RL
algorithms can be directly employed to learn a hole-seeking policy, thus
eliminating the need for inverse kinematics solutions and promoting cooperative
multi-joint control. To enhance the drilling accuracy throughout the entire
drilling process, we devise a state representation that combines
Denavit-Hartenberg joint information and preview hole-seeking discrepancy data.
Simulation results show that the proposed method significantly outperforms
traditional methods in terms of hole-seeking accuracy and time efficiency.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01837" title="Abstract">arXiv:2312.01837</a> [<a href="/pdf/2312.01837" title="Download PDF">pdf</a>, <a href="/format/2312.01837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Disentangled Embeddings for Knowledge Graph Completion with  Pre-trained Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuxia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yuhang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J+Z">Jeff Z. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Both graph structures and textual information play a critical role in
Knowledge Graph Completion (KGC). With the success of Pre-trained Language
Models (PLMs) such as BERT, they have been applied for text encoding for KGC.
However, the current methods mostly prefer to fine-tune PLMs, leading to huge
training costs and limited scalability to larger PLMs. In contrast, we propose
to utilize prompts and perform KGC on a frozen PLM with only the prompts
trained. Accordingly, we propose a new KGC method named PDKGC with two prompts
-- a hard task prompt which is to adapt the KGC task to the PLM pre-training
task of token prediction, and a disentangled structure prompt which learns
disentangled graph representation so as to enable the PLM to combine more
relevant structure knowledge with the text information. With the two prompts,
PDKGC builds a textual predictor and a structural predictor, respectively, and
their combination leads to more comprehensive entity prediction. Solid
evaluation on two widely used KGC datasets has shown that PDKGC often
outperforms the baselines including the state-of-the-art, and its components
are all effective. Our codes and data are available at
https://github.com/genggengcss/PDKGC.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01840" title="Abstract">arXiv:2312.01840</a> [<a href="/pdf/2312.01840" title="Download PDF">pdf</a>, <a href="/ps/2312.01840" title="Download PostScript">ps</a>, <a href="/format/2312.01840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI-based solution for the cold start and data sparsity problems in  the recommendation systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sumit%2C+S+S">Shahriar Shakir Sumit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In recent years, the amount of data available on the internet and the number
of users who utilize the Internet have increased at an unparalleled pace. The
exponential development in the quantity of digital information accessible and
the number of Internet users has created the possibility for information
overload, impeding fast access to items of interest on the Internet.
Information retrieval systems like as Google, DevilFinder, and Altavista have
partly overcome this challenge, but prioritizing and customization of
information (where a system maps accessible material to a user's interests and
preferences) were lacking. This has resulted in a higher-than-ever need for
recommender systems. Recommender systems are information filtering systems that
address the issue of information overload by filtering important information
fragments from a huge volume of dynamically produced data based on the user's
interests, favorite things, preferences and ratings on the desired item.
Recommender systems can figure out if a person would like an item or not based
on their profile.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01841" title="Abstract">arXiv:2312.01841</a> [<a href="/pdf/2312.01841" title="Download PDF">pdf</a>, <a href="/format/2312.01841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D  Hybrid Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xusen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xinya Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kangneng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daiheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Audio-driven talking head generation has drawn much attention in recent
years, and many efforts have been made in lip-sync, expressive facial
expressions, natural head pose generation, and high video quality. However, no
model has yet led or tied on all these metrics due to the one-to-many mapping
between audio and motion. In this paper, we propose VividTalk, a two-stage
generic framework that supports generating high-visual quality talking head
videos with all the above properties. Specifically, in the first stage, we map
the audio to mesh by learning two motions, including non-rigid expression
motion and rigid head motion. For expression motion, both blendshape and vertex
are adopted as the intermediate representation to maximize the representation
ability of the model. For natural head motion, a novel learnable head pose
codebook with a two-phase training mechanism is proposed. In the second stage,
we proposed a dual branch motion-vae and a generator to transform the meshes
into dense motion and synthesize high-quality video frame-by-frame. Extensive
experiments show that the proposed VividTalk can generate high-visual quality
talking head videos with lip-sync and realistic enhanced by a large margin, and
outperforms previous state-of-the-art works in objective and subjective
comparisons.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01842" title="Abstract">arXiv:2312.01842</a> [<a href="/pdf/2312.01842" title="Download PDF">pdf</a>, <a href="/format/2312.01842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue  State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yejin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+G">Gary Geunbae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dialogue state tracking plays a crucial role in extracting information in
task-oriented dialogue systems. However, preceding research are limited to
textual modalities, primarily due to the shortage of authentic human audio
datasets. We address this by investigating synthetic audio data for audio-based
DST. To this end, we develop cascading and end-to-end models, train them with
our synthetic audio dataset, and test them on actual human speech data. To
facilitate evaluation tailored to audio modalities, we introduce a novel
PhonemeF1 to capture pronunciation similarity. Experimental results showed that
models trained solely on synthetic datasets can generalize their performance to
human voice data. By eliminating the dependency on human speech data
collection, these insights pave the way for significant practical advancements
in audio-based DST. Data and code are available at
https://github.com/JihyunLee1/E2E-DST.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01847" title="Abstract">arXiv:2312.01847</a> [<a href="/pdf/2312.01847" title="Download PDF">pdf</a>, <a href="/format/2312.01847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical approximation of Dynkin games with asymmetric information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ba%C5%88as%2C+%C4%BD">&#x13d;ubom&#xed;r Ba&#x148;as</a>, 
<a href="/search/math?searchtype=author&query=Ferrari%2C+G">Giorgio Ferrari</a>, 
<a href="/search/math?searchtype=author&query=Randrianasolo%2C+T+A">Tsiry Avisoa Randrianasolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose an implementable, feedforward neural network-based structure
preserving probabilistic numerical approximation for a generalized obstacle
problem describing the value of a zero-sum differential game of optimal
stopping with asymmetric information. The target solution depends on three
variables: the time, the spatial (or state) variable, and a variable from a
standard $(I-1)$-simplex which represents the probabilities with which the $I$
possible configurations of the game are played. The proposed numerical
approximation preserves the convexity of the continuous solution as well as the
lower and upper obstacle bounds. We show convergence of the fully-discrete
scheme to the unique viscosity solution of the continuous problem and present a
range of numerical studies to demonstrate its applicability.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01850" title="Abstract">arXiv:2312.01850</a> [<a href="/pdf/2312.01850" title="Download PDF">pdf</a>, <a href="/format/2312.01850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization by Adaptation: Diffusion-Based Domain Extension for  Domain-Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niemeijer%2C+J">Joshua Niemeijer</a>, 
<a href="/search/cs?searchtype=author&query=Schwonberg%2C+M">Manuel Schwonberg</a>, 
<a href="/search/cs?searchtype=author&query=Term%C3%B6hlen%2C+J">Jan-Aike Term&#xf6;hlen</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+N+M">Nico M. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Fingscheidt%2C+T">Tim Fingscheidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">When models, e.g., for semantic segmentation, are applied to images that are
vastly different from training data, the performance will drop significantly.
Domain adaptation methods try to overcome this issue, but need samples from the
target domain. However, this might not always be feasible for various reasons
and therefore domain generalization methods are useful as they do not require
any target data. We present a new diffusion-based domain extension (DIDEX)
method and employ a diffusion model to generate a pseudo-target domain with
diverse text prompts. In contrast to existing methods, this allows to control
the style and content of the generated images and to introduce a high
diversity. In a second step, we train a generalizing model by adapting towards
this pseudo-target domain. We outperform previous approaches by a large margin
across various datasets and architectures without using any real data. For the
generalization from GTA5, we improve state-of-the-art mIoU performance by 3.8%
absolute on average and for SYNTHIA by 11.8% absolute, marking a big step for
the generalization performance on these benchmarks. Code is available at
https://github.com/JNiemeijer/DIDEX
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01853" title="Abstract">arXiv:2312.01853</a> [<a href="/pdf/2312.01853" title="Download PDF">pdf</a>, <a href="/format/2312.01853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Synesthesia: In-Hand Manipulation with Visuotactile Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+H">Haichuan Che</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhao-Heng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-Won Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Soo-Chul Lim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yingyuan0414.github.io/visuotactile/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Executing contact-rich manipulation tasks necessitates the fusion of tactile
and visual feedback. However, the distinct nature of these modalities poses
significant challenges. In this paper, we introduce a system that leverages
visual and tactile sensory inputs to enable dexterous in-hand manipulation.
Specifically, we propose Robot Synesthesia, a novel point cloud-based tactile
representation inspired by human tactile-visual synesthesia. This approach
allows for the simultaneous and seamless integration of both sensory inputs,
offering richer spatial information and facilitating better reasoning about
robot actions. The method, trained in a simulated environment and then deployed
to a real robot, is applicable to various in-hand object rotation tasks.
Comprehensive ablations are performed on how the integration of vision and
touch can improve reinforcement learning and Sim2Real performance. Our project
page is available at https://yingyuan0414.github.io/visuotactile/ .
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01855" title="Abstract">arXiv:2312.01855</a> [<a href="/pdf/2312.01855" title="Download PDF">pdf</a>, <a href="/format/2312.01855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Control Architecture for Safe Marine Navigation: Reinforcement  Learning and Predictive Safety Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaaler%2C+A">Aksel Vaaler</a>, 
<a href="/search/cs?searchtype=author&query=Husa%2C+S+J">Svein Jostein Husa</a>, 
<a href="/search/cs?searchtype=author&query=Menges%2C+D">Daniel Menges</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+T+N">Thomas Nakken Larsen</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+A">Adil Rasheed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many autonomous systems face safety challenges, requiring robust closed-loop
control to handle physical limitations and safety constraints. Real-world
systems, like autonomous ships, encounter nonlinear dynamics and environmental
disturbances. Reinforcement learning is increasingly used to adapt to complex
scenarios, but standard frameworks ensuring safety and stability are lacking.
Predictive Safety Filters (PSF) offer a promising solution, ensuring constraint
satisfaction in learning-based control without explicit constraint handling.
This modular approach allows using arbitrary control policies, with the safety
filter optimizing proposed actions to meet physical and safety constraints. We
apply this approach to marine navigation, combining RL with PSF on a simulated
Cybership II model. The RL agent is trained on path following and collision
avpodance, while the PSF monitors and modifies control actions for safety.
Results demonstrate the PSF's effectiveness in maintaining safety without
hindering the RL agent's learning rate and performance, evaluated against a
standard RL agent without PSF.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01857" title="Abstract">arXiv:2312.01857</a> [<a href="/pdf/2312.01857" title="Download PDF">pdf</a>, <a href="/format/2312.01857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Intractability of the Picker Routing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prunet%2C+T">Thibault Prunet</a>, 
<a href="/search/cs?searchtype=author&query=Absi%2C+N">Nabil Absi</a>, 
<a href="/search/cs?searchtype=author&query=Cattaruzza%2C+D">Diego Cattaruzza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Picker Routing Problem (PRP), which consists in finding a minimum-length
tour between a set of storage locations in a warehouse, is one of the most
important problems in the warehousing logistics literature. Despite its
popularity, the tractability of the PRP in conventional multi-block warehouses
remains an open question. This technical note aims to fill this research gap by
establishing that the PRP is strongly NP-hard.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01858" title="Abstract">arXiv:2312.01858</a> [<a href="/pdf/2312.01858" title="Download PDF">pdf</a>, <a href="/format/2312.01858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Dependencies in Fact Editing for Language Models: Specificity  and Implication Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Arous%2C+I">Ines Arous</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+C+K">Jackie C.K. Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The potential of using a large language model (LLM) as a knowledge base (KB)
has sparked significant interest. To manage the knowledge acquired by LLMs, we
need to ensure that the editing of learned facts respects internal logical
constraints, which are known as dependency of knowledge. Existing work on
editing LLMs has partially addressed the issue of dependency, when the editing
of a fact should apply to its lexical variations without disrupting irrelevant
ones. However, they neglect the dependency between a fact and its logical
implications. We propose an evaluation protocol with an accompanying
question-answering dataset, DepEdit, that provides a comprehensive assessment
of the editing process considering the above notions of dependency. Our
protocol involves setting up a controlled environment in which we edit facts
and monitor their impact on LLMs, along with their implications based on
If-Then rules. Extensive experiments on DepEdit show that existing knowledge
editing methods are sensitive to the surface form of knowledge, and that they
have limited performance in inferring the implications of edited facts.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01860" title="Abstract">arXiv:2312.01860</a> [<a href="/pdf/2312.01860" title="Download PDF">pdf</a>, <a href="/format/2312.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Objects with SOLA: An Annotation-Free Image Search on the  Object Level for Automotive Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigoll%2C+P">Philipp Rigoll</a>, 
<a href="/search/cs?searchtype=author&query=Langner%2C+J">Jacob Langner</a>, 
<a href="/search/cs?searchtype=author&query=Sax%2C+E">Eric Sax</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Huge image data sets are the fundament for the development of the perception
of automated driving systems. A large number of images is necessary to train
robust neural networks that can cope with diverse situations. A sufficiently
large data set contains challenging situations and objects. For testing the
resulting functions, it is necessary that these situations and objects can be
found and extracted from the data set. While it is relatively easy to record a
large amount of unlabeled data, it is far more difficult to find demanding
situations and objects. However, during the development of perception systems,
it must be possible to access challenging data without having to perform
lengthy and time-consuming annotations. A developer must therefore be able to
search dynamically for specific situations and objects in a data set. Thus, we
designed a method which is based on state-of-the-art neural networks to search
for objects with certain properties within an image. For the ease of use, the
query of this search is described using natural language. To determine the time
savings and performance gains, we evaluated our method qualitatively and
quantitatively on automotive data sets.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01869" title="Abstract">arXiv:2312.01869</a> [<a href="/pdf/2312.01869" title="Download PDF">pdf</a>, <a href="/ps/2312.01869" title="Download PostScript">ps</a>, <a href="/format/2312.01869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCP Slice: A semi-distributed TCP algorithm for Delay-constrained  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Dibbendu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+G">Goutam Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The TCP congestion control protocol serves as the cornerstone of reliable
internet communication. However, as new applications require more specific
guarantees regarding data rate and delay, network management must adapt. Thus,
service providers are shifting from decentralized to centralized control of the
network using a software-defined network controller (SDN). The SDN classifies
applications and allocates logically separate resources called slices, over the
physical network. We propose TCP Slice, a congestion control algorithm that
meets specific delay and bandwidth guarantees. Obtaining closed-form delay
bounds for a client is challenging due to dependencies on other clients and
their traffic stochasticity. We use network calculus to derive the client's
delay bound and incorporate it as a constraint in the Network Utility
Maximization problem. We solve the resulting optimization using dual
decomposition and obtain a semi-distributed TCP protocol that can be
implemented with the help of SDN controller and the use of an Explicit
Congestion Notification (ECN) bit. Additionally, we also propose a proactive
approach for congestion control using digital twin. TCP Slice represents a
significant step towards accommodating evolving internet traffic patterns and
the need for better network management in the face of increasing application
diversity.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01871" title="Abstract">arXiv:2312.01871</a> [<a href="/pdf/2312.01871" title="Download PDF">pdf</a>, <a href="/format/2312.01871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeaInfNet: Diagnosis in Medical Image with Feature-Driven Inference and  Visual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yitao Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lianghua He</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Die Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longzhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shaohua Shang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Interpretable deep learning models have received widespread attention in the
field of image recognition. Due to the unique multi-instance learning of
medical images and the difficulty in identifying decision-making regions, many
interpretability models that have been proposed still have problems of
insufficient accuracy and interpretability in medical image disease diagnosis.
To solve these problems, we propose feature-driven inference network
(FeaInfNet). Our first key innovation involves proposing a feature-based
network reasoning structure, which is applied to FeaInfNet. The network of this
structure compares the similarity of each sub-region image patch with the
disease templates and normal templates that may appear in the region, and
finally combines the comparison of each sub-region to make the final diagnosis.
It simulates the diagnosis process of doctors to make the model interpretable
in the reasoning process, while avoiding the misleading caused by the
participation of normal areas in reasoning. Secondly, we propose local feature
masks (LFM) to extract feature vectors in order to provide global information
for these vectors, thus enhancing the expressive ability of the FeaInfNet.
Finally, we propose adaptive dynamic masks (Adaptive-DM) to interpret feature
vectors and prototypes into human-understandable image patches to provide
accurate visual interpretation. We conducted qualitative and quantitative
experiments on multiple publicly available medical datasets, including RSNA,
iChallenge-PM, Covid-19, ChinaCXRSet, and MontgomerySet. The results of our
experiments validate that our method achieves state-of-the-art performance in
terms of classification accuracy and interpretability compared to baseline
methods in medical image diagnosis. Additional ablation studies verify the
effectiveness of each of our proposed components.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01872" title="Abstract">arXiv:2312.01872</a> [<a href="/pdf/2312.01872" title="Download PDF">pdf</a>, <a href="/format/2312.01872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The CURE To Vulnerabilities in RPKI Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mirdita%2C+D">Donika Mirdita</a>, 
<a href="/search/cs?searchtype=author&query=Schulmann%2C+H">Haya Schulmann</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+N">Niklas Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Waidner%2C+M">Michael Waidner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in NDSS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Over recent years, the Resource Public Key Infrastructure (RPKI) has seen
increasing adoption, with now 37.8% of the major networks filtering bogus BGP
routes. Systems interact with the RPKI over Relying Party (RP) implementations
that fetch RPKI objects and feed BGP routers with the validated
prefix-ownership data. Consequently, any vulnerabilities or flaws within the RP
software can substantially threaten the stability and security of Internet
routing. We uncover severe flaws in all popular RP implementations, making them
susceptible to path traversal attacks, remotely triggered crashes, and inherent
inconsistencies, violating RPKI standards. We report a total of 18
vulnerabilities that canbe exploited to downgrade RPKI validation in border
routers or, worse, enable poisoning of the validation process, resulting in
malicious prefixes being wrongfully validated and legitimate RPKI-covered
prefixes failing validation. Furthermore, our research discloses
inconsistencies in the validation process, with two popular implementations
leaving 8149 prefixes unprotected from hijacks, 6405 of which belong to Amazon.
While these findings are significant in their own right, our principal
contribution lies in developing CURE, the first-of-its-kind system to
systematically detect bugs, vulnerabilities, and RFC compliance issues in RP
implementations via automated test generation. CURE is a powerful RPKI
publication point emulator that enables easy and efficient fuzzing of complex
RP validation pipelines. It is designed with a set of novel techniques,
utilizing differential and stateful fuzzing. We generated over 600 million test
cases and tested all popular RPs on them. Following our disclosure, the vendors
already assigned CVEs to the vulnerabilities we found.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01874" title="Abstract">arXiv:2312.01874</a> [<a href="/pdf/2312.01874" title="Download PDF">pdf</a>, <a href="/ps/2312.01874" title="Download PostScript">ps</a>, <a href="/format/2312.01874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Division via Quantile Shares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babichenko%2C+Y">Yakov Babichenko</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M">Michal Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Holzman%2C+R">Ron Holzman</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+V+V">Vishnu V. Narayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We consider the problem of fair division, where a set of indivisible goods
should be distributed fairly among a set of agents with combinatorial
valuations. To capture fairness, we adopt the notion of shares, where each
agent is entitled to a fair share, based on some fairness criterion, and an
allocation is considered fair if the value of every agent (weakly) exceeds her
fair share. A share-based notion is considered universally feasible if it
admits a fair allocation for every profile of monotone valuations. A major
question arises: is there a non-trivial share-based notion that is universally
feasible? The most well-known share-based notions, namely proportionality and
maximin share, are not universally feasible, nor are any constant
approximations of them.
<br />We propose a novel share notion, where an agent assesses the fairness of a
bundle by comparing it to her valuation in a random allocation. In this
framework, a bundle is considered $q$-quantile fair, for $q\in[0,1]$, if it is
at least as good as a bundle obtained in a uniformly random allocation with
probability at least $q$. Our main question is whether there exists a constant
value of $q$ for which the $q$-quantile share is universally feasible.
<br />Our main result establishes a strong connection between the feasibility of
quantile shares and the classical Erd\H{o}s Matching Conjecture. Specifically,
we show that if a version of this conjecture is true, then the
$\frac{1}{2e}$-quantile share is universally feasible. Furthermore, we provide
unconditional feasibility results for additive, unit-demand and matroid-rank
valuations for constant values of $q$. Finally, we discuss the implications of
our results for other share notions.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01878" title="Abstract">arXiv:2312.01878</a> [<a href="/pdf/2312.01878" title="Download PDF">pdf</a>, <a href="/format/2312.01878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs)
are prominent techniques for homogeneous and heterogeneous graph representation
learning, yet their performance in an end-to-end supervised framework greatly
depends on the availability of task-specific supervision. To reduce the
labeling cost, pre-training on self-supervised pretext tasks has become a
popular paradigm,but there is often a gap between the pre-trained model and
downstream tasks, stemming from the divergence in their objectives. To bridge
the gap, prompt learning has risen as a promising direction especially in
few-shot settings, without the need to fully fine-tune the pre-trained model.
While there has been some early exploration of prompt-based learning on graphs,
they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs
that are prevalent in downstream applications. In this paper, we propose
HGPROMPT, a novel pre-training and prompting framework to unify not only
pre-training and downstream tasks but also homogeneous and heterogeneous graphs
via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to
assist a downstream task in locating the most relevant prior to bridge the gaps
caused by not only feature variations but also heterogeneity differences across
tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive
experiments on three public datasets.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01880" title="Abstract">arXiv:2312.01880</a> [<a href="/pdf/2312.01880" title="Download PDF">pdf</a>, <a href="/ps/2312.01880" title="Download PostScript">ps</a>, <a href="/format/2312.01880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing popularity in linear time via maximum matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9rczi-Kov%C3%A1cs%2C+E">Erika B&#xe9;rczi-Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Kosztol%C3%A1nyi%2C+K">Kata Kosztol&#xe1;nyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Popularity is an approach in mechanism design to find fair structures in a
graph, based on the votes of the nodes. Popular matchings are the relaxation of
stable matchings: given a graph G=(V,E) with strict preferences on the
neighbors of the nodes, a matching M is popular if there is no other matching
M' such that the number of nodes preferring M' is more than those preferring M.
This paper considers the popularity testing problem, when the task is to decide
whether a given matching is popular or not. Previous algorithms applied
reductions to maximum weight matchings. We give a new algorithm for testing
popularity by reducing the problem to maximum matching testing, thus attaining
a linear running time O(|E|).
<br />Linear programming-based characterization of popularity is often applied for
proving the popularity of a certain matching. As a consequence of our algorithm
we derive a more structured dual witness than previous ones. Based on this
result we give a combinatorial characterization of fractional popular
matchings, which are a special class of popular matchings.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01882" title="Abstract">arXiv:2312.01882</a> [<a href="/pdf/2312.01882" title="Download PDF">pdf</a>, <a href="/ps/2312.01882" title="Download PostScript">ps</a>, <a href="/format/2312.01882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Potential of Large Language Model: Zero-shot VQA for  Flood Disaster Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yimin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by The 4th International Conference on Artificial Intelligence and Computer Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual question answering (VQA) is a fundamental and essential AI task, and
VQA-based disaster scenario understanding is a hot research topic. For
instance, we can ask questions about a disaster image by the VQA model and the
answer can help identify whether anyone or anything is affected by the
disaster. However, previous VQA models for disaster damage assessment have some
shortcomings, such as limited candidate answer space, monotonous question
types, and limited answering capability of existing models. In this paper, we
propose a zero-shot VQA model named Zero-shot VQA for Flood Disaster Damage
Assessment (ZFDDA). It is a VQA model for damage assessment without
pre-training. Also, with flood disaster as the main research object, we build a
Freestyle Flood Disaster Image Question Answering dataset (FFD-IQA) to evaluate
our VQA model. This new dataset expands the question types to include
free-form, multiple-choice, and yes-no questions. At the same time, we expand
the size of the previous dataset to contain a total of 2,058 images and 22,422
question-meta ground truth pairs. Most importantly, our model uses
well-designed chain of thought (CoT) demonstrations to unlock the potential of
the large language model, allowing zero-shot VQA to show better performance in
disaster scenarios. The experimental results show that the accuracy in
answering complex questions is greatly improved with CoT prompts. Our study
provides a research basis for subsequent research of VQA for other disaster
scenarios.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01884" title="Abstract">arXiv:2312.01884</a> [<a href="/pdf/2312.01884" title="Download PDF">pdf</a>, <a href="/format/2312.01884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation and Unintended Biases on Univariate and Multivariate  Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Setzu%2C+M">Mattia Setzu</a>, 
<a href="/search/cs?searchtype=author&query=Ruggieri%2C+S">Salvatore Ruggieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decision Trees are accessible, interpretable, and well-performing
classification models. A plethora of variants with increasing expressiveness
has been proposed in the last forty years. We contrast the two families of
univariate DTs, whose split functions partition data through axis-parallel
hyperplanes, and multivariate DTs, whose splits instead partition data through
oblique hyperplanes. The latter include the former, hence multivariate DTs are
in principle more powerful. Surprisingly enough, however, univariate DTs
consistently show comparable performances in the literature. We analyze the
reasons behind this, both with synthetic and real-world benchmark datasets. Our
research questions test whether the pre-processing phase of removing
correlation among features in datasets has an impact on the relative
performances of univariate vs multivariate DTs. We find that existing benchmark
datasets are likely biased towards favoring univariate DTs.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01886" title="Abstract">arXiv:2312.01886</a> [<a href="/pdf/2312.01886" title="Download PDF">pdf</a>, <a href="/format/2312.01886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xunguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhenlan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large vision-language models (LVLMs) have demonstrated their incredible
capability in image understanding and response generation. However, this rich
visual interaction also makes LVLMs vulnerable to adversarial examples. In this
paper, we formulate a novel and practical gray-box attack scenario that the
adversary can only access the visual encoder of the victim LVLM, without the
knowledge of its prompts (which are often proprietary for service providers and
not publicly available) and its underlying large language model (LLM). This
practical setting poses challenges to the cross-prompt and cross-model
transferability of targeted adversarial attack, which aims to confuse the LVLM
to output a response that is semantically similar to the attacker's chosen
target text. To this end, we propose an instruction-tuned targeted attack
(dubbed InstructTA) to deliver the targeted adversarial attack on LVLMs with
high transferability. Initially, we utilize a public text-to-image generative
model to "reverse" the target response into a target image, and employ GPT-4 to
infer a reasonable instruction $\boldsymbol{p}^\prime$ from the target
response. We then form a local surrogate model (sharing the same visual encoder
with the victim LVLM) to extract instruction-aware features of an adversarial
image example and the target image, and minimize the distance between these two
features to optimize the adversarial example. To further improve the
transferability, we augment the instruction $\boldsymbol{p}^\prime$ with
instructions paraphrased from an LLM. Extensive experiments demonstrate the
superiority of our proposed method in targeted attack performance and
transferability.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01887" title="Abstract">arXiv:2312.01887</a> [<a href="/pdf/2312.01887" title="Download PDF">pdf</a>, <a href="/format/2312.01887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Intrusive Load Monitoring for Feeder-Level EV Charging Detection:  Sliding Window-based Approaches to Offline and Online Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martin%2C+C">Cameron Martin</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+F">Fucai Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 7th IEEE Conference on Energy Internet and Energy System Integration (EI2 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Understanding electric vehicle (EV) charging on the distribution network is
key to effective EV charging management and aiding decarbonization across the
energy and transport sectors. Advanced metering infrastructure has allowed
distribution system operators and utility companies to collect high-resolution
load data from their networks. These advancements enable the non-intrusive load
monitoring (NILM) technique to detect EV charging using load measurement data.
While existing studies primarily focused on NILM for EV charging detection in
individual households, there is a research gap on EV charging detection at the
feeder level, presenting unique challenges due to the combined load measurement
from multiple households. In this paper, we develop a novel and effective
approach for EV detection at the feeder level, involving sliding-window feature
extraction and classical machine learning techniques, specifically models like
XGBoost and Random Forest. Our developed method offers a lightweight and
efficient solution, capable of quick training. Moreover, our developed method
is versatile, supporting both offline and online EV charging detection. Our
experimental results demonstrate high-accuracy EV charging detection at the
feeder level, achieving an F-Score of 98.88% in offline detection and 93.01% in
online detection.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01895" title="Abstract">arXiv:2312.01895</a> [<a href="/pdf/2312.01895" title="Download PDF">pdf</a>, <a href="/format/2312.01895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-Depth Survey on Virtualization Technologies in 6G Integrated  Terrestrial and Non-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ammar%2C+S">Sahar Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>, 
<a href="/search/cs?searchtype=author&query=Shihada%2C+B">Basem Shihada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">6G networks are envisioned to deliver a large diversity of applications and
meet stringent quality of service (QoS) requirements. Hence, integrated
terrestrial and non-terrestrial networks (TN-NTNs) are anticipated to be key
enabling technologies. However, the TN-NTNs integration faces a number of
challenges that could be addressed through network virtualization technologies
such as Software-Defined Networking (SDN), Network Function Virtualization
(NFV) and network slicing. In this survey, we provide a comprehensive review on
the adaptation of these networking paradigms in 6G networks. We begin with a
brief overview on NTNs and virtualization techniques. Then, we highlight the
integral role of Artificial Intelligence in improving network virtualization by
summarizing major research areas where AI models are applied. Building on this
foundation, the survey identifies the main issues arising from the adaptation
of SDN, NFV, and network slicing in integrated TN-NTNs, and proposes a taxonomy
of integrated TN-NTNs virtualization offering a thorough review of relevant
contributions. The taxonomy is built on a four-level classification indicating
for each study the level of TN-NTNs integration, the used virtualization
technology, the addressed problem, the type of the study and the proposed
solution, which can be based on conventional or AI-enabled methods. Moreover,
we present a summary on the simulation tools commonly used in the testing and
validation of such networks. Finally, we discuss open issues and give insights
on future research directions for the advancement of integrated TN-NTNs
virtualization in the 6G era.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01896" title="Abstract">arXiv:2312.01896</a> [<a href="/pdf/2312.01896" title="Download PDF">pdf</a>, <a href="/ps/2312.01896" title="Download PostScript">ps</a>, <a href="/format/2312.01896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Linear-time Simulation of Deterministic $d$-Limited Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubtsov%2C+A">Alexander Rubtsov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">A $d$-limited automaton is a Turing machine that uses only the cells with the
input word (and end-markers) and rewrites symbols only in the first $d$ visits.
This model was introduced by T. Hibbard in 1967 and he showed that $d$-limited
automata recognize context-free languages for each $d \geq 2$. He also proved
that languages recognizable by deterministic $d$-limited automata form a
hierarchy and it was shown later by Pighizzini and Pisoni that it begins with
deterministic context-free languages (DCFLs) (for $d=2$).
<br />As well-known, DCFLs are widely used in practice, especially in compilers
since they are linear-time recognizable and have the corresponding CF-grammars
subclass (LR$(1)$-grammars). In this paper we present a linear time recognition
algorithm for deterministic $d$-limited automata (in the RAM model) which opens
an opportunity for their possible practical applications. We also generalize
this algorithm to deterministic $d(n)$-limited automata: the extension of
deterministic $d$-limited automata, where $d$ is not a constant, but a function
depending on the input length $n$.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01897" title="Abstract">arXiv:2312.01897</a> [<a href="/pdf/2312.01897" title="Download PDF">pdf</a>, <a href="/format/2312.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Short-Term Transformers for Action Detection in Untrimmed  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Huan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Ping Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision transformer (ViT) has shown high potential in video recognition, owing
to its flexible design, adaptable self-attention mechanisms, and the efficacy
of masked pre-training. Yet, it still remains unclear how to adapt these
pre-trained short-term ViTs for temporal action detection (TAD) in untrimmed
videos. The existing works treat them as off-the-shelf feature extractors for
each short trimmed snippet without capturing the fine-grained relation among
different snippets in a broader temporal context. To mitigate this issue, this
paper focuses on designing a new mechanism for adapting these pre-trained ViT
models as a unified long-form video transformer to fully unleash its modeling
power in capturing inter-snippet relation, while still keeping low computation
overhead and memory consumption for efficient TAD. To this end, we design
effective cross-snippet propagation modules to gradually exchange short-term
video information among different snippets from two levels. For inner-backbone
information propagation, we introduce a cross-snippet propagation strategy to
enable multi-snippet temporal feature interaction inside the backbone. For
post-backbone information propagation, we propose temporal transformer layers
for further clip-level modeling. With the plain ViT-B pre-trained with
VideoMAE, our end-to-end temporal action detector (ViT-TAD) yields a very
competitive performance to previous temporal action detectors, riching up to
69.0 average mAP on THUMOS14, 37.12 average mAP on ActivityNet-1.3 and 17.20
average mAP on FineAction.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01904" title="Abstract">arXiv:2312.01904</a> [<a href="/pdf/2312.01904" title="Download PDF">pdf</a>, <a href="/format/2312.01904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Anomaly Detection using Aggregated Normative Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frotscher%2C+A">Alexander Frotscher</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+J">Jaivardhan Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Wolfers%2C+T">Thomas Wolfers</a>, 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+C+F">Christian F. Baumgartner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Early detection of anomalies in medical images such as brain MRI is highly
relevant for diagnosis and treatment of many conditions. Supervised machine
learning methods are limited to a small number of pathologies where there is
good availability of labeled data. In contrast, unsupervised anomaly detection
(UAD) has the potential to identify a broader spectrum of anomalies by spotting
deviations from normal patterns. Our research demonstrates that existing
state-of-the-art UAD approaches do not generalise well to diverse types of
anomalies in realistic multi-modal MR data. To overcome this, we introduce a
new UAD method named Aggregated Normative Diffusion (ANDi). ANDi operates by
aggregating differences between predicted denoising steps and ground truth
backwards transitions in Denoising Diffusion Probabilistic Models (DDPMs) that
have been trained on pyramidal Gaussian noise. We validate ANDi against three
recent UAD baselines, and across three diverse brain MRI datasets. We show that
ANDi, in some cases, substantially surpasses these baselines and shows
increased robustness to varying types of anomalies. Particularly in detecting
multiple sclerosis (MS) lesions, ANDi achieves improvements of up to 178% in
terms of AUPRC.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01907" title="Abstract">arXiv:2312.01907</a> [<a href="/pdf/2312.01907" title="Download PDF">pdf</a>, <a href="/ps/2312.01907" title="Download PostScript">ps</a>, <a href="/format/2312.01907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Control Approach to Autonomous Formation Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celik%2C+H">Harun Celik</a>, 
<a href="/search/cs?searchtype=author&query=Kilinc%2C+D">Dilara Kilinc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Turkish language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Formation flight is when multiple objects fly together in a coordination.
Various automatic control methods have been used for the autonomous execution
of formation flight of aerial vehicles. In this paper, the capacity of the
model predictive control (MPC) approach in the autonomous execution of
formation flight is examined. The MPC is a controller that capable of
performing formation flight, maintaining tracking desired trajectory while
avoiding collisions between aerial vehicles, and obstacles faced. Through this
approach, aerial vehicle models with six degrees of freedom in a
three-dimensional environment are performed formation flight autonomously,
mostly in a triangle order. Not only the trajectory for the formation flight
can be tracked through the MPC architecture, also the collision avoidance
strategies of the aerial vehicles can be performed by this architecture.
Simulation studies show that MPC has sufficient capability in both cases.
Therefore, it is concluded that this method can deal with constraints, avoid
obstacles as well as collisions between aerial vehicles. However,
implementation of MPC to aerial vehicles in real time holds challenges.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01912" title="Abstract">arXiv:2312.01912</a> [<a href="/pdf/2312.01912" title="Download PDF">pdf</a>, <a href="/ps/2312.01912" title="Download PostScript">ps</a>, <a href="/format/2312.01912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Leak Checker (RLC#) for C# Code using CodeQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharat%2C+P">Pritam Gharat</a>, 
<a href="/search/cs?searchtype=author&query=Shadab%2C+N">Narges Shadab</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+S">Shrey Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+S">Shuvendu Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+A">Akash Lal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Resource leaks occur when a program fails to release a finite resource after
it is no longer needed. These leaks are a significant cause of real-world
crashes and performance issues. Given their critical impact on software
performance and security, detecting and preventing resource leaks is a crucial
problem.
<br />Recent research has proposed a specify-and-check approach to prevent resource
leaks. In this approach, programmers write resource management specifications
that guide how resources are stored, passed around, and released within an
application. We have developed a tool called RLC#, for detecting resource leaks
in C# code. Inspired by the Resource Leak Checker (RLC) from the Checker
Framework, RLC# employs CodeQL for intraprocedural data flow analysis. The tool
operates in a modular fashion and relies on resource management specifications
integrated at method boundaries for interprocedural analysis.
<br />In practice, RLC# has successfully identified 24 resource leaks in
open-source projects and internal proprietary Azure microservices. Its
implementation is declarative, and it scales well. While it incurs a reasonable
false positive rate, the burden on developers is minimal, involving the
addition of specifications to the source code.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01915" title="Abstract">arXiv:2312.01915</a> [<a href="/pdf/2312.01915" title="Download PDF">pdf</a>, <a href="/format/2312.01915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reliable Representation with Bidirectional Transition Model for Visual  Reinforcement Learning Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kai Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual reinforcement learning has proven effective in solving control tasks
with high-dimensional observations. However, extracting reliable and
generalizable representations from vision-based observations remains a central
challenge. Inspired by the human thought process, when the representation
extracted from the observation can predict the future and trace history, the
representation is reliable and accurate in comprehending the environment. Based
on this concept, we introduce a Bidirectional Transition (BiT) model, which
leverages the ability to bidirectionally predict environmental transitions both
forward and backward to extract reliable representations. Our model
demonstrates competitive generalization performance and sample efficiency on
two settings of the DeepMind Control suite. Additionally, we utilize robotic
manipulation and CARLA simulators to demonstrate the wide applicability of our
method.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01916" title="Abstract">arXiv:2312.01916</a> [<a href="/pdf/2312.01916" title="Download PDF">pdf</a>, <a href="/format/2312.01916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEACE: Prototype lEarning Augmented transferable framework for  Cross-domain rEcommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chunjing Gan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenliang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">To help merchants/customers to provide/access a variety of services through
miniapps, online service platforms have occupied a critical position in the
effective content delivery, in which how to recommend items in the new domain
launched by the service provider for customers has become more urgent. However,
the non-negligible gap between the source and diversified target domains poses
a considerable challenge to cross-domain recommendation systems, which often
leads to performance bottlenecks in industrial settings. While entity graphs
have the potential to serve as a bridge between domains, rudimentary
utilization still fail to distill useful knowledge and even induce the negative
transfer issue. To this end, we propose PEACE, a Prototype lEarning Augmented
transferable framework for Cross-domain rEcommendation. For domain gap
bridging, PEACE is built upon a multi-interest and entity-oriented pre-training
architecture which could not only benefit the learning of generalized knowledge
in a multi-granularity manner, but also help leverage more structural
information in the entity graph. Then, we bring the prototype learning into the
pre-training over source domains, so that representations of users and items
are greatly improved by the contrastive prototype learning module and the
prototype enhanced attention mechanism for adaptive knowledge utilization. To
ease the pressure of online serving, PEACE is carefully deployed in a
lightweight manner, and significant performance improvements are observed in
both online and offline environments.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01919" title="Abstract">arXiv:2312.01919</a> [<a href="/pdf/2312.01919" title="Download PDF">pdf</a>, <a href="/format/2312.01919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qihang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanyun Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The autonomous driving community has shown significant interest in 3D
occupancy prediction, driven by its exceptional geometric perception and
general object recognition capabilities. To achieve this, current works try to
construct a Tri-Perspective View (TPV) or Occupancy (OCC) representation
extending from the Bird-Eye-View perception. However, compressed views like TPV
representation lose 3D geometry information while raw and sparse OCC
representation requires heavy but reducant computational costs. To address the
above limitations, we propose Compact Occupancy TRansformer (COTR), with a
geometry-aware occupancy encoder and a semantic-aware group decoder to
reconstruct a compact 3D OCC representation. The occupancy encoder first
generates a compact geometrical OCC feature through efficient explicit-implicit
view transformation. Then, the occupancy decoder further enhances the semantic
discriminability of the compact OCC representation by a coarse-to-fine semantic
grouping strategy. Empirical experiments show that there are evident
performance gains across multiple baselines, e.g., COTR outperforms baselines
with a relative improvement of 8%-15%, demonstrating the superiority of our
method.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01920" title="Abstract">arXiv:2312.01920</a> [<a href="/pdf/2312.01920" title="Download PDF">pdf</a>, <a href="/ps/2312.01920" title="Download PostScript">ps</a>, <a href="/format/2312.01920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong stabilization in classical control via adjustment of fractional  powers into integers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Faruqi%2C+A+H">Abdul Hannan Faruqi</a>, 
<a href="/search/eess?searchtype=author&query=Chatterjee%2C+A">Anindya Chatterjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We address stabilization of linear time-invariant (LTI), single-input
single-output (SISO) systems in the Laplace domain, with a stable controller in
a single feedback loop. Such stabilization is called strong. Plants that
satisfy a parity interlacing property are known to be strongly stabilizable.
Finding such controllers is a well known difficult problem. Existing general
methods are based on either manual search or a clever use of Nevanlinna-Pick
interpolation with polynomials of possibly high integer order. Here we present
a new, simple, and general method for strongly stabilizing systems of relative
degree less than 3. We call our method adjustment of fractional powers (AFP).
Our theoretical contributions constitute proposing the functional form used,
which involves a product of several terms of the form $\displaystyle \left (
\frac{s+a}{s+b} \right )^m$, showing that real $m$'s will arise whenever the
plant is strongly stabilizable, and proving that integer $m$'s can be obtained
by continuously varying free parameters (i.e., the $a$'s and $b$'s). Our
practical contributions include demonstrating a simple way, based on a
trigonometric trick, to adjust the fractional powers until they take reasonable
integer values. We include brief but necessary associated discussion to make
the paper accessible to a broad audience. We also present ten numerical
examples of successful control design with varying levels of difficulty,
including plants whose transfer functions have relative degrees of 0, 1 or 2;
and with right half plane zeros of multiplicity possibly exceeding one.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01921" title="Abstract">arXiv:2312.01921</a> [<a href="/pdf/2312.01921" title="Download PDF">pdf</a>, <a href="/format/2312.01921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Machine Learning Approach Towards SKILL Code Autocompletion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehaerne%2C+E">Enrique Dehaerne</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+B">Bappaditya Dey</a>, 
<a href="/search/cs?searchtype=author&query=Meert%2C+W">Wannes Meert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for SPIE Advanced Lithography + Patterning, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">As Moore's Law continues to increase the complexity of electronic systems,
Electronic Design Automation (EDA) must advance to meet global demand. An
important example of an EDA technology is SKILL, a scripting language used to
customize and extend EDA software. Recently, code generation models using the
transformer architecture have achieved impressive results in academic settings
and have even been used in commercial developer tools to improve developer
productivity. To the best of our knowledge, this study is the first to apply
transformers to SKILL code autocompletion towards improving the productivity of
hardware design engineers. In this study, a novel, data-efficient methodology
for generating SKILL code is proposed and experimentally validated. More
specifically, we propose a novel methodology for (i) creating a high-quality
SKILL dataset with both unlabeled and labeled data, (ii) a training strategy
where T5 models pre-trained on general programming language code are fine-tuned
on our custom SKILL dataset using unsupervised and supervised learning, and
(iii) evaluating synthesized SKILL code. We show that models trained using the
proposed methodology outperform baselines in terms of human-judgment score and
BLEU score. A major challenge faced was the extremely small amount of available
SKILL code data that can be used to train a transformer model to generate SKILL
code. Despite our validated improvements, the extremely small dataset available
to us was still not enough to train a model that can reliably autocomplete
SKILL code. We discuss this and other limitations as well as future work that
could address these limitations.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01928" title="Abstract">arXiv:2312.01928</a> [<a href="/pdf/2312.01928" title="Download PDF">pdf</a>, <a href="/format/2312.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus-Based Distributed Nonlinear Filtering with Kernel Mean  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liping Guo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jimin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Ji-Feng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes a consensus-based distributed nonlinear filter with
kernel mean embedding (KME). This fills with gap of posterior density
approximation with KME for distributed nonlinear dynamic systems. To
approximate the posterior density, the system state is embedded into a
higher-dimensional reproducing kernel Hilbert space (RKHS), and then the
nonlinear measurement function is linearly converted. As a result, an update
rule of KME of posterior distribution is established in the RKHS. To show the
proposed distributed filter being capable of achieving the centralized
estimation accuracy, a centralized filter, serving as an extension of the
standard Kalman filter in the state space to the RKHS, is developed first.
Benefited from the KME, the proposed distributed filter converges to the
centralized one while maintaining the distributed pattern. Two examples are
introduced to demonstrate the effectiveness of the developed filters in target
tracking scenarios including nearly constantly moving target and turning
target, respectively, with bearing-only, range and bearing measurements.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01934" title="Abstract">arXiv:2312.01934</a> [<a href="/pdf/2312.01934" title="Download PDF">pdf</a>, <a href="/format/2312.01934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency of Unsupervised Anomaly Detection Methods on Software Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nyyss%C3%B6l%C3%A4%2C+J">Jesse Nyyss&#xf6;l&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4ntyl%C3%A4%2C+M">Mika M&#xe4;ntyl&#xe4;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software log analysis can be laborious and time consuming. Time and labeled
data are usually lacking in industrial settings. This paper studies
unsupervised and time efficient methods for anomaly detection. We study two
custom and two established models. The custom models are: an OOV
(Out-Of-Vocabulary) detector, which counts the terms in the test data that are
not present in the training data, and the Rarity Model (RM), which calculates a
rarity score for terms based on their infrequency. The established models are
KMeans and Isolation Forest. The models are evaluated on four public datasets
(BGL, Thunderbird, Hadoop, HDFS) with three different representation techniques
for the log messages (Words, character Trigrams, Parsed events). We used the
AUC-ROC metric for the evaluation. The results reveal discrepancies based on
the dataset and representation technique. Different configurations are advised
based on specific requirements. For speed, the OOV detector with word
representation is optimal. For accuracy, the OOV detector combined with trigram
representation yields the highest AUC-ROC (0.846). When dealing with unfiltered
data where training includes both normal and anomalous instances, the most
effective combination is the Isolation Forest with event representation,
achieving an AUC-ROC of 0.829.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01938" title="Abstract">arXiv:2312.01938</a> [<a href="/pdf/2312.01938" title="Download PDF">pdf</a>, <a href="/format/2312.01938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSText V2: A Comprehensive Video Text Spotting Dataset for Dense and  Small Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yefei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luoming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Z">Zhenyu Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition 2023/2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, video text detection, tracking, and recognition in natural scenes
are becoming very popular in the computer vision community. However, most
existing algorithms and benchmarks focus on common text cases (e.g., normal
size, density) and single scenario, while ignoring extreme video text
challenges, i.e., dense and small text in various scenarios. In this paper, we
establish a video text reading benchmark, named DSText V2, which focuses on
Dense and Small text reading challenges in the video with various scenarios.
Compared with the previous datasets, the proposed dataset mainly include three
new challenges: 1) Dense video texts, a new challenge for video text spotters
to track and read. 2) High-proportioned small texts, coupled with the
blurriness and distortion in the video, will bring further challenges. 3)
Various new scenarios, e.g., Game, Sports, etc. The proposed DSText V2 includes
140 video clips from 7 open scenarios, supporting three tasks, i.e., video text
detection (Task 1), video text tracking (Task 2), and end-to-end video text
spotting (Task 3). In this article, we describe detailed statistical
information of the dataset, tasks, evaluation protocols, and the results
summaries. Most importantly, a thorough investigation and analysis targeting
three unique challenges derived from our dataset are provided, aiming to
provide new insights. Moreover, we hope the benchmark will promise video text
research in the community. DSText v2 is built upon DSText v1, which was
previously introduced to organize the ICDAR 2023 competition for dense and
small video text.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01939" title="Abstract">arXiv:2312.01939</a> [<a href="/pdf/2312.01939" title="Download PDF">pdf</a>, <a href="/format/2312.01939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations for Transfer in Reinforcement Learning: A Taxonomy of  Knowledge Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=Byravan%2C+A">Arunkumar Byravan</a>, 
<a href="/search/cs?searchtype=author&query=Bechtle%2C+S">Sarah Bechtle</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Contemporary artificial intelligence systems exhibit rapidly growing
abilities accompanied by the growth of required resources, expansive datasets
and corresponding investments into computing infrastructure. Although earlier
successes predominantly focus on constrained settings, recent strides in
fundamental research and applications aspire to create increasingly general
systems. This evolving landscape presents a dual panorama of opportunities and
challenges in refining the generalisation and transfer of knowledge - the
extraction from existing sources and adaptation as a comprehensive foundation
for tackling new problems. Within the domain of reinforcement learning (RL),
the representation of knowledge manifests through various modalities, including
dynamics and reward models, value functions, policies, and the original data.
This taxonomy systematically targets these modalities and frames its discussion
based on their inherent properties and alignment with different objectives and
mechanisms for transfer. Where possible, we aim to provide coarse guidance
delineating approaches which address requirements such as limiting environment
interactions, maximising computational efficiency, and enhancing generalisation
across varying axes of change. Finally, we analyse reasons contributing to the
prevalence or scarcity of specific forms of transfer, the inherent potential
behind pushing these frontiers, and underscore the significance of
transitioning from designed to learned transfer.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01941" title="Abstract">arXiv:2312.01941</a> [<a href="/pdf/2312.01941" title="Download PDF">pdf</a>, <a href="/ps/2312.01941" title="Download PostScript">ps</a>, <a href="/format/2312.01941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrusion Detection System with Machine Learning and Multiple Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+H">Haiyan Xuan</a> (1), 
<a href="/search/cs?searchtype=author&query=Manohar%2C+M">Mohith Manohar</a> (2) ((1) Carmel High School, (2) Columbia University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">As Artificial Intelligence (AI) technologies continue to gain traction in the
modern-day world, they ultimately pose an immediate threat to current
cybersecurity systems via exploitative methods. Prompt engineering is a
relatively new field that explores various prompt designs that can hijack large
language models (LLMs). If used by an unethical attacker, it can enable an AI
system to offer malicious insights and code to them. In this paper, an enhanced
intrusion detection system (IDS) that utilizes machine learning (ML) and
hyperparameter tuning is explored, which can improve a model's performance in
terms of accuracy and efficacy. Ultimately, this improved system can be used to
combat the attacks made by unethical hackers. A standard IDS is solely
configured with pre-configured rules and patterns; however, with the
utilization of machine learning, implicit and different patterns can be
generated through the models' hyperparameter settings and parameters. In
addition, the IDS will be equipped with multiple datasets so that the accuracy
of the models improves. We evaluate the performance of multiple ML models and
their respective hyperparameter settings through various metrics to compare
their results to other models and past research work. The results of the
proposed multi-dataset integration method yielded an accuracy score of 99.9%
when equipped with the XGBoost and random forest classifiers and
RandomizedSearchCV hyperparameter technique.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01943" title="Abstract">arXiv:2312.01943</a> [<a href="/pdf/2312.01943" title="Download PDF">pdf</a>, <a href="/format/2312.01943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-guided Cartoon Editing with a Large-scale Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xueting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zhongping Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://cartoonsegmentation.github.io/">this https URL</a> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Cartoon editing, appreciated by both professional illustrators and hobbyists,
allows extensive creative freedom and the development of original narratives
within the cartoon domain. However, the existing literature on cartoon editing
is complex and leans heavily on manual operations, owing to the challenge of
automatic identification of individual character instances. Therefore, an
automated segmentation of these elements becomes imperative to facilitate a
variety of cartoon editing applications such as visual style editing, motion
decomposition and transfer, and the computation of stereoscopic depths for an
enriched visual experience. Unfortunately, most current segmentation methods
are designed for natural photographs, failing to recognize from the intricate
aesthetics of cartoon subjects, thus lowering segmentation quality. The major
challenge stems from two key shortcomings: the rarity of high-quality cartoon
dedicated datasets and the absence of competent models for high-resolution
instance extraction on cartoons. To address this, we introduce a high-quality
dataset of over 100k paired high-resolution cartoon images and their instance
labeling masks. We also present an instance-aware image segmentation model that
can generate accurate, high-resolution segmentation masks for characters in
cartoon images. We present that the proposed approach enables a range of
segmentation-dependent cartoon editing applications like 3D Ken Burns parallax
effects, text-guided cartoon style editing, and puppet animation from
illustrations and manga.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01951" title="Abstract">arXiv:2312.01951</a> [<a href="/pdf/2312.01951" title="Download PDF">pdf</a>, <a href="/format/2312.01951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFTWS for blockchain: Deterministic, Fair and Transparent Winner  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+F">Felix Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Kebschull%2C+U">Udo Kebschull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 Golang code block, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This publication describes the block winner selection process that will be
used in a novel Proof-of-Useful-Work blockchain for High Energy Physics that
the authors are currently working on. Instead of spamming hashing operations to
mine blocks, miners will be running Monte Carlo simulations to support a
real-world HEP experiment with useful data. The block problems will be defined
by a Root Authority which is represented by a HEP experiment like CBM. The
focus in this publication is a mechanism that allows the Root Authority to
select a winner from a list of nodes that solved a block problem. The mechanism
is designed so that winner selection is deterministic, fair and transparent.
This mechanism allows every node to verify the fairness of the winner selection
process without giving the nodes a tool to be able to improve their own winning
chances.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01954" title="Abstract">arXiv:2312.01954</a> [<a href="/pdf/2312.01954" title="Download PDF">pdf</a>, <a href="/format/2312.01954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papaluca%2C+A">Andrea Papaluca</a>, 
<a href="/search/cs?searchtype=author&query=Krefl%2C+D">Daniel Krefl</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+S+M">Sergio Mendez Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Lensky%2C+A">Artem Lensky</a>, 
<a href="/search/cs?searchtype=author&query=Suominen%2C+H">Hanna Suominen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work, we tested the Triplet Extraction (TE) capabilities of a variety
of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots
settings. In detail, we proposed a pipeline that dynamically gathers contextual
information from a Knowledge Base (KB), both in the form of context triplets
and of (sentence, triplets) pairs as examples, and provides it to the LLM
through a prompt. The additional context allowed the LLMs to be competitive
with all the older fully trained baselines based on the Bidirectional Long
Short-Term Memory (BiLSTM) Network architecture. We further conducted a
detailed analysis of the quality of the gathered KB context, finding it to be
strongly correlated with the final TE performance of the model. In contrast,
the size of the model appeared to only logarithmically improve the TE
capabilities of the LLMs.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01957" title="Abstract">arXiv:2312.01957</a> [<a href="/pdf/2312.01957" title="Download PDF">pdf</a>, <a href="/format/2312.01957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled Self-Critique of LLMs with Synthetic Data: a Bayesian  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallego%2C+V">Victor Gallego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR 2024 (TinyPapers track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes an interpretation of RLAIF as Bayesian inference by
introducing distilled Self-Critique (dSC), which refines the outputs of a LLM
through a Gibbs sampler that is later distilled into a fine-tuned model. Only
requiring synthetic data, dSC is exercised in experiments regarding safety,
sentiment, and privacy control, showing it can be a viable and cheap
alternative to align LLMs. Code released at
\url{https://github.com/vicgalle/distilled-self-critique}.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01958" title="Abstract">arXiv:2312.01958</a> [<a href="/pdf/2312.01958" title="Download PDF">pdf</a>, <a href="/format/2312.01958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanical Comparison of Arrangement Strategies for Topological  Interlocking Assemblies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goertzen%2C+T">Tom Goertzen</a>, 
<a href="/search/cs?searchtype=author&query=Macek%2C+D">Domen Macek</a>, 
<a href="/search/cs?searchtype=author&query=Schnelle%2C+L">Lukas Schnelle</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9F%2C+M">Meike Wei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+S">Stefanie Reese</a>, 
<a href="/search/cs?searchtype=author&query=Holthusen%2C+H">Hagen Holthusen</a>, 
<a href="/search/cs?searchtype=author&query=Niemeyer%2C+A+C">Alice C. Niemeyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Topological Interlocking assemblies are arrangements of blocks kinematically
constrained by a fixed frame, such that all rigid body motions of each block
are constrained only by its permanent contact with other blocks and the frame.
In the literature several blocks are introduced that can be arranged into
different interlocking assemblies. In this study we investigate the influence
of arrangement on the overall structural behaviour of the resulting
interlocking assemblies. This is performed using the Versatile Block, as it can
be arranged in three different doubly periodic ways given by wallpaper
symmetries. Our focus lies on the load transfer mechanisms from the assembly
onto the frame. For fast a priori evaluation of the assemblies we introduce a
combinatorial model called Interlocking Flows. To investigate our assemblies
from a mechanical point of view we conduct several finite element studies.
These reveal a strong influence of arrangement on the structural behaviour, for
instance, an impact on both the point and amount of maximum deflection. The
results of the finite element analysis are in very good agreement with the
predictions of the Interlocking Flow model. Our source code, data and examples
are available under https://doi.org/10.5281/zenodo.10246034.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01959" title="Abstract">arXiv:2312.01959</a> [<a href="/pdf/2312.01959" title="Download PDF">pdf</a>, <a href="/format/2312.01959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Approaches to Predictive Monitoring with Conformal  Statistical Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cairoli%2C+F">Francesca Cairoli</a>, 
<a href="/search/cs?searchtype=author&query=Bortolussi%2C+L">Luca Bortolussi</a>, 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+N">Nicola Paoletti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This tutorial focuses on efficient methods to predictive monitoring (PM), the
problem of detecting at runtime future violations of a given requirement from
the current state of a system. While performing model checking at runtime would
offer a precise solution to the PM problem, it is generally computationally
expensive. To address this scalability issue, several lightweight approaches
based on machine learning have recently been proposed. These approaches work by
learning an approximate yet efficient surrogate (deep learning) model of the
expensive model checker. A key challenge remains to ensure reliable
predictions, especially in safety-critical applications. We review our recent
work on predictive monitoring, one of the first to propose learning-based
approximations for CPS verification of temporal logic specifications and the
first in this context to apply conformal prediction (CP) for rigorous
uncertainty quantification. These CP-based uncertainty estimators offer
statistical guarantees regarding the generalization error of the learning
model, and they can be used to determine unreliable predictions that should be
rejected. In this tutorial, we present a general and comprehensive framework
summarizing our approach to the predictive monitoring of CPSs, examining in
detail several variants determined by three main dimensions: system dynamics
(deterministic, non-deterministic, stochastic), state observability, and
semantics of requirements' satisfaction (Boolean or quantitative).
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01963" title="Abstract">arXiv:2312.01963</a> [<a href="/pdf/2312.01963" title="Download PDF">pdf</a>, <a href="/format/2312.01963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Reduction on Manifolds: A differential geometric framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buchfink%2C+P">Patrick Buchfink</a>, 
<a href="/search/math?searchtype=author&query=Glas%2C+S">Silke Glas</a>, 
<a href="/search/math?searchtype=author&query=Haasdonk%2C+B">Bernard Haasdonk</a>, 
<a href="/search/math?searchtype=author&query=Unger%2C+B">Benjamin Unger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Using nonlinear projections and preserving structure in model order reduction
(MOR) are currently active research fields. In this paper, we provide a novel
differential geometric framework for model reduction on smooth manifolds, which
emphasizes the geometric nature of the objects involved. The crucial ingredient
is the construction of an embedding for the low-dimensional submanifold and a
compatible reduction map, for which we discuss several options. Our general
framework allows capturing and generalizing several existing MOR techniques,
such as structure preservation for Lagrangian- or Hamiltonian dynamics, and
using nonlinear projections that are, for instance, relevant in
transport-dominated problems. The joint abstraction can be used to derive
shared theoretical properties for different methods, such as an exact
reproduction result. To connect our framework to existing work in the field, we
demonstrate that various techniques for data-driven construction of nonlinear
projections can be included in our framework.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01964" title="Abstract">arXiv:2312.01964</a> [<a href="/pdf/2312.01964" title="Download PDF">pdf</a>, <a href="/format/2312.01964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-aware Motion Retargeting with Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">ZhiKe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haocheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Lei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaofei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Capturing and preserving motion semantics is essential to motion retargeting
between animation characters. However, most of the previous works neglect the
semantic information or rely on human-designed joint-level representations.
Here, we present a novel Semantics-aware Motion reTargeting (SMT) method with
the advantage of vision-language models to extract and maintain meaningful
motion semantics. We utilize a differentiable module to render 3D motions. Then
the high-level motion semantics are incorporated into the motion retargeting
process by feeding the vision-language model with the rendered images and
aligning the extracted semantic embeddings. To ensure the preservation of
fine-grained motion details and high-level semantics, we adopt a two-stage
pipeline consisting of skeleton-aware pre-training and fine-tuning with
semantics and geometry constraints. Experimental results show the effectiveness
of the proposed method in producing high-quality motion retargeting results
while accurately preserving motion semantics. Project page can be found at
https://sites.google.com/view/smtnet.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01968" title="Abstract">arXiv:2312.01968</a> [<a href="/pdf/2312.01968" title="Download PDF">pdf</a>, <a href="/format/2312.01968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Channel Charting with Classical Wireless Source Localization  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Euchner%2C+F">Florian Euchner</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+P">Phillip Stephan</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Channel Charting aims to construct a map of the radio environment by
leveraging similarity relationships found in high-dimensional channel state
information. Although resulting channel charts usually accurately represent
local neighborhood relationships, even under conditions with strong multipath
propagation, they often fall short in capturing global geometric features. On
the other hand, classical model-based localization methods, such as
triangulation and multilateration, can easily localize signal sources in the
global coordinate frame. However, these methods rely heavily on the assumption
of line-of-sight channels and distributed antenna deployments. Based on
measured data, we compare classical source localization techniques to channel
charts with respect to localization performance. We suggest and evaluate
methods to enhance Channel Charting with model-based localization approaches:
One approach involves using information derived from classical localization
methods to map channel chart locations to physical positions after conventional
training of the forward charting function. Foremost, though, we suggest to
incorporate information from model-based approaches during the training of the
forward charting function in what we call "augmented Channel Charting". We
demonstrate that Channel Charting can outperform classical localization methods
on the considered dataset.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01970" title="Abstract">arXiv:2312.01970</a> [<a href="/pdf/2312.01970" title="Download PDF">pdf</a>, <a href="/format/2312.01970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaRL: Cascade Reinforcement Learning with State Space Splitting for  O-RAN based Traffic Steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chuanneng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+G">Gueyoung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+X">Tuyen Xuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Pompili%2C+D">Dario Pompili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Open Radio Access Network (O-RAN) architecture empowers intelligent and
automated optimization of the RAN through applications deployed on the RAN
Intelligent Controller (RIC) platform, enabling capabilities beyond what is
achievable with traditional RAN solutions. Within this paradigm, Traffic
Steering (TS) emerges as a pivotal RIC application that focuses on optimizing
cell-level mobility settings in near-real-time, aiming to significantly improve
network spectral efficiency. In this paper, we design a novel TS algorithm
based on a Cascade Reinforcement Learning (CaRL) framework. We propose state
space factorization and policy decomposition to reduce the need for large
models and well-labeled datasets. For each sub-state space, an RL sub-policy
will be trained to learn an optimized mapping onto the action space. To apply
CaRL on new network regions, we propose a knowledge transfer approach to
initialize a new sub-policy based on knowledge learned by the trained policies.
To evaluate CaRL, we build a data-driven and scalable RIC digital twin (DT)
that is modeled using important real-world data, including network
configuration, user geo-distribution, and traffic demand, among others, from a
tier-1 mobile operator in the US. We evaluate CaRL on two DT scenarios
representing two network clusters in two different cities and compare its
performance with the business-as-usual (BAU) policy and other competing
optimization approaches using heuristic and Q-table algorithms. Benchmarking
results show that CaRL performs the best and improves the average
cluster-aggregated downlink throughput over the BAU policy by 24% and 18% in
these two scenarios, respectively.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01973" title="Abstract">arXiv:2312.01973</a> [<a href="/pdf/2312.01973" title="Download PDF">pdf</a>, <a href="/ps/2312.01973" title="Download PostScript">ps</a>, <a href="/format/2312.01973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Repairs Under Functional and Inclusion Dependencies via  Argumentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+Y">Yasir Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Virtema%2C+J">Jonni Virtema</a>, 
<a href="/search/cs?searchtype=author&query=Barlag%2C+T">Timon Barlag</a>, 
<a href="/search/cs?searchtype=author&query=Ngomo%2C+A+N">Axel-Cyrille Ngonga Ngomo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We discover a connection between finding subset-maximal repairs for sets of
functional and inclusion dependencies, and computing extensions within
argumentation frameworks (AFs). We study the complexity of the existence of a
repair and deciding whether a given tuple belongs to some (or every) repair, by
simulating the instances of these problems via AFs. We prove that
subset-maximal repairs under functional dependencies correspond to the naive
extensions, which also coincide with the preferred and stable extensions in the
resulting AFs. For inclusion dependencies, one needs a pre-processing step on
the resulting AFs in order for the extensions to coincide. Allowing both types
of dependencies breaks this relationship between extensions, and only preferred
semantics captures the repairs. Finally, we establish that the complexities of
the above decision problems are NP-complete and Pi_2^P-complete, when both
functional and inclusion dependencies are allowed.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01981" title="Abstract">arXiv:2312.01981</a> [<a href="/pdf/2312.01981" title="Download PDF">pdf</a>, <a href="/format/2312.01981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Competition Dynamics in Mobile App Markets through User  Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motger%2C+Q">Quim Motger</a>, 
<a href="/search/cs?searchtype=author&query=Franch%2C+X">Xavier Franch</a>, 
<a href="/search/cs?searchtype=author&query=Gervasi%2C+V">Vincenzo Gervasi</a>, 
<a href="/search/cs?searchtype=author&query=Marco%2C+J">Jordi Marco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">User reviews published in mobile app repositories are essential for
understanding user satisfaction and engagement within a specific market
segment. Manual analysis of these reviews is impractical due to the large
volume of available data, while automatic analysis poses several challenges,
including data synthesis and effective reporting. These challenges complicate
the task for app providers in identifying hidden patterns and significant
events related to app acceptance, especially in assessing the influence of
competitor apps. Furthermore, review-based analysis is mostly limited to a
single app or a single app provider, excluding potential market and competition
analysis. Following a case-study research method in the microblogging app
market, we introduce an automatic, novel approach to support mobile app market
analysis processes through quantitative metrics and event detection techniques
based on newly published user reviews. Significant events are proactively
identified and summarized by comparing metric deviations with historical
baseline indicators within the lifecycle of a mobile app. Results from our case
study show empirical evidence of the detection of relevant events within the
selected market segment, including software- or release-based events,
contextual events and the emergence of new competitors.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01985" title="Abstract">arXiv:2312.01985</a> [<a href="/pdf/2312.01985" title="Download PDF">pdf</a>, <a href="/format/2312.01985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniGS: Unified Representation for Image Generation and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lehan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weidong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel unified representation of diffusion models for
image generation and segmentation. Specifically, we use a colormap to represent
entity-level masks, addressing the challenge of varying entity numbers while
aligning the representation closely with the image RGB domain. Two novel
modules, including the location-aware color palette and progressive dichotomy
module, are proposed to support our mask representation. On the one hand, a
location-aware palette guarantees the colors' consistency to entities'
locations. On the other hand, the progressive dichotomy module can efficiently
decode the synthesized colormap to high-quality entity-level masks in a
depth-first binary search without knowing the cluster numbers. To tackle the
issue of lacking large-scale segmentation training data, we employ an
inpainting pipeline and then improve the flexibility of diffusion models across
various tasks, including inpainting, image synthesis, referring segmentation,
and entity segmentation. Comprehensive experiments validate the efficiency of
our approach, demonstrating comparable segmentation mask quality to
state-of-the-art and adaptability to multiple tasks. The code will be released
at \href{https://github.com/qqlu/Entity}{https://github.com/qqlu/Entity}.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01987" title="Abstract">arXiv:2312.01987</a> [<a href="/pdf/2312.01987" title="Download PDF">pdf</a>, <a href="/format/2312.01987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping SparseFormers from Vision Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziteng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Z">Zhan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K+Q">Kevin Qinghong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Joya Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recently proposed SparseFormer architecture provides an alternative
approach to visual understanding by utilizing a significantly lower number of
visual tokens via adjusting RoIs, greatly reducing computational costs while
still achieving promising performance. However, training SparseFormers from
scratch is still expensive, and scaling up the number of parameters can be
challenging. In this paper, we propose to bootstrap SparseFormers from
ViT-based vision foundation models in a simple and efficient way. Since the
majority of SparseFormer blocks are the standard transformer ones, we can
inherit weights from large-scale pre-trained vision transformers and freeze
them as much as possible. Therefore, we only need to train the
SparseFormer-specific lightweight focusing transformer to adjust token RoIs and
fine-tune a few early pre-trained blocks to align the final token
representation. In such a way, we can bootstrap SparseFormer architectures from
various large-scale pre-trained models (e.g., IN-21K pre-trained AugRegs or
CLIPs) using a rather smaller amount of training samples (e.g., IN-1K) and
without labels or captions within just a few hours. As a result, the
bootstrapped unimodal SparseFormer (from AugReg-ViT-L/16-384) can reach 84.9%
accuracy on IN-1K with only 49 tokens, and the multimodal SparseFormer from
CLIPs also demonstrates notable zero-shot performance with highly reduced
computational cost without seeing any caption during the bootstrapping
procedure. In addition, CLIP-bootstrapped SparseFormers, which align the output
space with language without seeing a word, can serve as efficient vision
encoders in multimodal large language models. Code will be publicly available
at https://github.com/showlab/sparseformer
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01988" title="Abstract">arXiv:2312.01988</a> [<a href="/pdf/2312.01988" title="Download PDF">pdf</a>, <a href="/format/2312.01988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geranos: a Novel Tilted-Rotors Aerial Robot for the Transportation of  Poles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamert%2C+S">Samuel Bamert</a>, 
<a href="/search/cs?searchtype=author&query=Cathomen%2C+R">Rafael Cathomen</a>, 
<a href="/search/cs?searchtype=author&query=Gorlo%2C+N">Nicolas Gorlo</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ppeli%2C+G">Gabriel K&#xe4;ppeli</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Mario M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Reinhart%2C+T">Tim Reinhart</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+H">Henriette Stadler</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cuniato%2C+E">Eugenio Cuniato</a>, 
<a href="/search/cs?searchtype=author&query=Tognon%2C+M">Marco Tognon</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE Robotics and Automation Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In challenging terrains, constructing structures such as antennas and
cable-car masts often requires the use of helicopters to transport loads via
ropes. The swinging of the load, exacerbated by wind, impairs positioning
accuracy, therefore necessitating precise manual placement by ground crews.
This increases costs and risk of injuries. Challenging this paradigm, we
present Geranos: a specialized multirotor Unmanned Aerial Vehicle (UAV)
designed to enhance aerial transportation and assembly. Geranos demonstrates
exceptional prowess in accurately positioning vertical poles, achieving this
through an innovative integration of load transport and precision. Its unique
ring design mitigates the impact of high pole inertia, while a lightweight
two-part grasping mechanism ensures secure load attachment without active
force. With four primary propellers countering gravity and four auxiliary ones
enhancing lateral precision, Geranos achieves comprehensive position and
attitude control around hovering. Our experimental demonstration mimicking
antenna/cable-car mast installations showcases Geranos ability in stacking
poles (3 kg, 2 m long) with remarkable sub-5 cm placement accuracy, without the
need of human manual intervention.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01990" title="Abstract">arXiv:2312.01990</a> [<a href="/pdf/2312.01990" title="Download PDF">pdf</a>, <a href="/format/2312.01990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SARA-RT: Scaling up Robotics Transformers with Self-Adaptive Robust  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leal%2C+I">Isabel Leal</a>, 
<a href="/search/cs?searchtype=author&query=Choromanski%2C+K">Krzysztof Choromanski</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+D">Deepali Jain</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Avinava Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Varley%2C+J">Jake Varley</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M">Michael Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Frederick Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sindhwani%2C+V">Vikas Sindhwani</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Sarlos%2C+T">Tamas Sarlos</a>, 
<a href="/search/cs?searchtype=author&query=Oslund%2C+K">Ken Oslund</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Self-Adaptive Robust Attention for Robotics Transformers
(SARA-RT): a new paradigm for addressing the emerging challenge of scaling up
Robotics Transformers (RT) for on-robot deployment. SARA-RT relies on the new
method of fine-tuning proposed by us, called up-training. It converts
pre-trained or already fine-tuned Transformer-based robotic policies of
quadratic time complexity (including massive billion-parameter
vision-language-action models or VLAs), into their efficient linear-attention
counterparts maintaining high quality. We demonstrate the effectiveness of
SARA-RT by speeding up: (a) the class of recently introduced RT-2 models, the
first VLA robotic policies pre-trained on internet-scale data, as well as (b)
Point Cloud Transformer (PCT) robotic policies operating on large point clouds.
We complement our results with the rigorous mathematical analysis providing
deeper insight into the phenomenon of SARA.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01991" title="Abstract">arXiv:2312.01991</a> [<a href="/pdf/2312.01991" title="Download PDF">pdf</a>, <a href="/format/2312.01991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Modified K-Nearest Neighbor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahedifar%2C+M+A">Mohammad Ali Vahedifar</a>, 
<a href="/search/cs?searchtype=author&query=Akhtarshenas%2C+A">Azim Akhtarshenas</a>, 
<a href="/search/cs?searchtype=author&query=Sabbaghian%2C+M">Mariam Sabbaghian</a>, 
<a href="/search/cs?searchtype=author&query=Rafatpanah%2C+M">Mohammad Rafatpanah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this research paper, we introduce a novel classification method aimed at
improving the performance of the K-Nearest Neighbors (KNN) algorithm. Our
approach leverages Mutual Information (MI) to enhance the significance of
weights and draw inspiration from Shapley values, a concept originating from
cooperative game theory, to refine value allocation. The fundamental concept
underlying KNN is the classification of samples based on the majority thorough
their k-nearest neighbors. While both the distances and labels of these
neighbors are crucial, traditional KNN assigns equal weight to all samples and
prevance considering the varying importance of each neighbor based on their
distances and labels.
<br />In the proposed method, known as Information-Modified KNN (IMKNN), we address
this issue by introducing a straightforward algorithm. To evaluate the
effectiveness of our approach, it is compared with 7 contemporary variants of
KNN, as well as the traditional KNN. Each of these variants exhibits its unique
advantages and limitations. We conduct experiments on 12 widely-used datasets,
assessing the methods' performance in terms of accuracy, precision and recall.
<br />Our study demonstrates that IMKNN consistently outperforms other methods
across different datasets and criteria by highlighting its superior performance
in various classification tasks. These findings underscore the potential of
IMKNN as a valuable tool for enhancing the capabilities of the KNN algorithm in
diverse applications.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01994" title="Abstract">arXiv:2312.01994</a> [<a href="/pdf/2312.01994" title="Download PDF">pdf</a>, <a href="/format/2312.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Self-Supervised Framework using Functional Connectivity in  fMRI Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Keum%2C+S">Seongho Keum</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+E">EungGu Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byung-Hoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Temporal Graph Learning Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Deep neural networks trained on Functional Connectivity (FC) networks
extracted from functional Magnetic Resonance Imaging (fMRI) data have gained
popularity due to the increasing availability of data and advances in model
architectures, including Graph Neural Network (GNN). Recent research on the
application of GNN to FC suggests that exploiting the time-varying properties
of the FC could significantly improve the accuracy and interpretability of the
model prediction. However, the high cost of acquiring high-quality fMRI data
and corresponding phenotypic labels poses a hurdle to their application in
real-world settings, such that a model na\"ively trained in a supervised
fashion can suffer from insufficient performance or a lack of generalization on
a small number of data. In addition, most Self-Supervised Learning (SSL)
approaches for GNNs to date adopt a contrastive strategy, which tends to lose
appropriate semantic information when the graph structure is perturbed or does
not leverage both spatial and temporal information simultaneously. In light of
these challenges, we propose a generative SSL approach that is tailored to
effectively harness spatio-temporal information within dynamic FC. Our
empirical results, experimented with large-scale (&gt;50,000) fMRI datasets,
demonstrate that our approach learns valuable representations and enables the
construction of accurate and robust models when fine-tuned for downstream
tasks.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01996" title="Abstract">arXiv:2312.01996</a> [<a href="/pdf/2312.01996" title="Download PDF">pdf</a>, <a href="/ps/2312.01996" title="Download PostScript">ps</a>, <a href="/format/2312.01996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning of Online Feedback Optimization for setpoint tracking in  centrifugal compressors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zagorowska%2C+M">Marta Zagorowska</a>, 
<a href="/search/eess?searchtype=author&query=Ortmann%2C+L">Lukas Ortmann</a>, 
<a href="/search/eess?searchtype=author&query=Rupenyan%2C+A">Alisa Rupenyan</a>, 
<a href="/search/eess?searchtype=author&query=Mercangoez%2C+M">Mehmet Mercangoez</a>, 
<a href="/search/eess?searchtype=author&query=Imsland%2C+L">Lars Imsland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ADCHEM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Online Feedback Optimization (OFO) controllers steer a system to its optimal
operating point by treating optimization algorithms as auxiliary dynamic
systems. Implementation of OFO controllers requires setting the parameters of
the optimization algorithm that allows reaching convergence, posing a challenge
because the convergence of the optimization algorithm is often decoupled from
the performance of the controlled system. OFO controllers are also typically
designed to ensure steady-state tracking by fixing the sampling time to be
longer than the time constants of the system. In this paper, we first quantify
the impact of OFO parameters and the sampling time on the tracking error and
number of oscillations of the controlled system, showing that adjusting them
allows good tracking without reaching steady states. We then propose a tuning
method for the sampling time of the OFO controller together with the parameters
to allow tracking fast trajectories while reducing oscillations. We validate
the proposed tuning approach in a pressure controller in a centrifugal
compressor, tracking trajectories faster than the time needed to reach the
steady state by the compressor. The results of the validation confirm that
simultaneous tuning of the sampling time and the parameters of OFO yields up to
87% times better tracking performance than manual tuning based on steady state.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01998" title="Abstract">arXiv:2312.01998</a> [<a href="/pdf/2312.01998" title="Download PDF">pdf</a>, <a href="/format/2312.01998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-only Efficient Training of Zero-shot Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Geonmo Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S">Sanghyuk Chun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wonjae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yoohoon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sangdoo Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally; 16 pages, 2.9MB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Composed image retrieval (CIR) task takes a composed query of image and text,
aiming to search relative images for both conditions. Conventional CIR
approaches need a training dataset composed of triplets of query image, query
text, and target image, which is very expensive to collect. Several recent
works have worked on the zero-shot (ZS) CIR paradigm to tackle the issue
without using pre-collected triplets. However, the existing ZS-CIR methods show
limited backbone scalability and generalizability due to the lack of diversity
of the input texts during training. We propose a novel CIR framework, only
using language for its training. Our LinCIR (Language-only training for CIR)
can be trained only with text datasets by a novel self-supervision named
self-masking projection (SMP). We project the text latent embedding to the
token embedding space and construct a new text by replacing the keyword tokens
of the original text. Then, we let the new and original texts have the same
latent embedding vector. With this simple strategy, LinCIR is surprisingly
efficient and highly effective; LinCIR with CLIP ViT-G backbone is trained in
48 minutes and shows the best ZS-CIR performances on four different CIR
benchmarks, CIRCO, GeneCIS, FashionIQ, and CIRR, even outperforming supervised
method on FashionIQ. Code is available at https://github.com/navervision/lincir
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02003" title="Abstract">arXiv:2312.02003</a> [<a href="/pdf/2312.02003" title="Download PDF">pdf</a>, <a href="/format/2312.02003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Large Language Model (LLM) Security and Privacy: The Good,  the Bad, and the Ugly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yifan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinhao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuanfang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+E">Eric Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs), such as GPT-3 and BERT, have revolutionized
natural language understanding and generation. They possess deep language
comprehension, human-like text generation capabilities, contextual awareness,
and robust problem-solving skills, making them invaluable in various domains
(e.g., search engines, customer support, translation). In the meantime, LLMs
have also gained traction in the security community, revealing security
vulnerabilities and showcasing their potential in security-related tasks. This
paper explores the intersection of LLMs with security and privacy.
Specifically, we investigate how LLMs positively impact security and privacy,
potential risks and threats associated with their use, and inherent
vulnerabilities within LLMs. Through a comprehensive literature review, the
paper categorizes findings into "The Good" (beneficial LLM applications), "The
Bad" (offensive applications), and "The Ugly" (vulnerabilities and their
defenses). We have some interesting findings. For example, LLMs have proven to
enhance code and data security, outperforming traditional methods. However,
they can also be harnessed for various attacks (particularly user-level
attacks) due to their human-like reasoning abilities. We have identified areas
that require further research efforts. For example, research on model and
parameter extraction attacks is limited and often theoretical, hindered by LLM
parameter scale and confidentiality. Safe instruction tuning, a recent
development, requires more exploration. We hope that our work can shed light on
the LLMs' potential to both bolster and jeopardize cybersecurity.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02008" title="Abstract">arXiv:2312.02008</a> [<a href="/pdf/2312.02008" title="Download PDF">pdf</a>, <a href="/format/2312.02008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Behavior Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuroki%2C+S">So Kuroki</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+M">Mai Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Kozuno%2C+T">Tadashi Kozuno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper aims to enable multi-agent systems to effectively utilize past
memories to adapt to novel collaborative tasks in a data-efficient fashion. We
propose the Multi-Agent Coordination Skill Database, a repository for storing a
collection of coordinated behaviors associated with the key vector distinctive
to them. Our Transformer-based skill encoder effectively captures
spatio-temporal interactions that contribute to coordination and provide a
skill representation unique to each coordinated behavior. By leveraging a small
number of demonstrations of the target task, the database allows us to train
the policy using a dataset augmented with the retrieved demonstrations.
Experimental evaluations clearly demonstrate that our method achieves a
significantly higher success rate in push manipulation tasks compared to
baseline methods like few-shot imitation learning. Furthermore, we validate the
effectiveness of our retrieve-and-learn framework in a real environment using a
team of wheeled robots.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02010" title="Abstract">arXiv:2312.02010</a> [<a href="/pdf/2312.02010" title="Download PDF">pdf</a>, <a href="/format/2312.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Learning a Generalist Model for Embodied Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Duo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=huang%2C+S">Shijia huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiwu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Building a generalist agent that can interact with the world is the
intriguing target of AI systems, thus spurring the research for embodied
navigation, where an agent is required to navigate according to instructions or
respond to queries. Despite the major progress attained, previous works
primarily focus on task-specific agents and lack generalizability to unseen
scenarios. Recently, LLMs have presented remarkable capabilities across various
fields, and provided a promising opportunity for embodied navigation. Drawing
on this, we propose the first generalist model for embodied navigation,
NaviLLM. It adapts LLMs to embodied navigation by introducing schema-based
instruction. The schema-based instruction flexibly casts various tasks into
generation problems, thereby unifying a wide range of tasks. This approach
allows us to integrate diverse data sources from various datasets into the
training, equipping NaviLLM with a wide range of capabilities required by
embodied navigation. We conduct extensive experiments to evaluate the
performance and generalizability of our model. The experimental results
demonstrate that our unified model achieves state-of-the-art performance on
CVDN, SOON, and ScanQA. Specifically, it surpasses the previous
stats-of-the-art method by a significant margin of 29% in goal progress on
CVDN. Moreover, our model also demonstrates strong generalizability and
presents impressive results on unseen tasks, e.g., embodied question answering
and 3D captioning.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02011" title="Abstract">arXiv:2312.02011</a> [<a href="/pdf/2312.02011" title="Download PDF">pdf</a>, <a href="/ps/2312.02011" title="Download PostScript">ps</a>, <a href="/format/2312.02011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is the disinformation problem? Reviewing the dominant paradigm and  motivating an alternative sociopolitical view
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabb%2C+N">Nicholas Rabb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Disinformation research has proliferated in reaction to widespread false,
problematic beliefs purported to explain major social phenomena. Yet while the
effects of disinformation are well-known, there is less consensus about its
causes; the research spans several disciplines, each focusing on different
pieces. This article contributes to this growing field by reviewing prevalent
U.S. disinformation discourse (academic writing, media, and corporate and
government narrative) and outlining the dominant understanding, or paradigm, of
the disinformation problem by analyzing cross-disciplinary discourse about the
content, individual, group, and institutional layers of the problem. The result
is an individualistic explanation largely blaming social media, malicious
individuals or nations, and irrational people. Yet this understanding has
shortcomings: notably, that its limited, individualistic views of truth and
rationality obscures the influence of oppressive ideologies and media or
domestic actors in creating flawed worldviews and spreading disinformation. The
article then concludes by putting forth an alternative, sociopolitical paradigm
that allows subjective models of the world to govern rationality and
information processing -- largely informed by social and group identity --
which are being formed and catered to by institutional actors (corporations,
media, political parties, and the government) to maintain or gain legitimacy
for their actions.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02012" title="Abstract">arXiv:2312.02012</a> [<a href="/pdf/2312.02012" title="Download PDF">pdf</a>, <a href="/format/2312.02012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Data Generation in Multi-Dimensional Parameter Spaces, using  Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahani%2C+M+R">M. R. Mahani</a>, 
<a href="/search/cs?searchtype=author&query=Nechepurenko%2C+I+A">Igor A. Nechepurenko</a>, 
<a href="/search/cs?searchtype=author&query=Rahimof%2C+Y">Yasmin Rahimof</a>, 
<a href="/search/cs?searchtype=author&query=Wicht%2C+A">Andreas Wicht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applied Physics (physics.app-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Acquiring a substantial number of data points for training accurate machine
learning (ML) models is a big challenge in scientific fields where data
collection is resource-intensive. Here, we propose a novel approach for
constructing a minimal yet highly informative database for training ML models
in complex multi-dimensional parameter spaces. To achieve this, we mimic the
underlying relation between the output and input parameters using Gaussian
process regression (GPR). Using a set of known data, GPR provides predictive
means and standard deviation for the unknown data. Given the predicted standard
deviation by GPR, we select data points using Bayesian optimization to obtain
an efficient database for training ML models. We compare the performance of ML
models trained on databases obtained through this method, with databases
obtained using traditional approaches. Our results demonstrate that the ML
models trained on the database obtained using Bayesian optimization approach
consistently outperform the other two databases, achieving high accuracy with a
significantly smaller number of data points. Our work contributes to the
resource-efficient collection of data in high-dimensional complex parameter
spaces, to achieve high precision machine learning predictions.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02015" title="Abstract">arXiv:2312.02015</a> [<a href="/pdf/2312.02015" title="Download PDF">pdf</a>, <a href="/format/2312.02015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ColonNeRF: Neural Radiance Fields for High-Fidelity Long-Sequence  Colonoscopy Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yufei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Beijia Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for Project Page, see <a href="https://showlab.github.io/ColonNeRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colonoscopy reconstruction is pivotal for diagnosing colorectal cancer.
However, accurate long-sequence colonoscopy reconstruction faces three major
challenges: (1) dissimilarity among segments of the colon due to its meandering
and convoluted shape; (2) co-existence of simple and intricately folded
geometry structures; (3) sparse viewpoints due to constrained camera
trajectories. To tackle these challenges, we introduce a new reconstruction
framework based on neural radiance field (NeRF), named ColonNeRF, which
leverages neural rendering for novel view synthesis of long-sequence
colonoscopy. Specifically, to reconstruct the entire colon in a piecewise
manner, our ColonNeRF introduces a region division and integration module,
effectively reducing shape dissimilarity and ensuring geometric consistency in
each segment. To learn both the simple and complex geometry in a unified
framework, our ColonNeRF incorporates a multi-level fusion module that
progressively models the colon regions from easy to hard. Additionally, to
overcome the challenges from sparse views, we devise a DensiNet module for
densifying camera poses under the guidance of semantic consistency. We conduct
extensive experiments on both synthetic and real-world datasets to evaluate our
ColonNeRF. Quantitatively, our ColonNeRF outperforms existing methods on two
benchmarks over four evaluation metrics. Notably, our LPIPS-ALEX scores exhibit
a substantial increase of about 67%-85% on the SimCol-to-3D dataset.
Qualitatively, our reconstruction visualizations show much clearer textures and
more accurate geometric details. These sufficiently demonstrate our superior
performance over the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02019" title="Abstract">arXiv:2312.02019</a> [<a href="/pdf/2312.02019" title="Download PDF">pdf</a>, <a href="/format/2312.02019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Inference by Maximising Evidence: Zero-Shot Imitation from  Observation with World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Becker-Ehmck%2C+P">Philip Becker-Ehmck</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Smagt%2C+P">Patrick van der Smagt</a>, 
<a href="/search/cs?searchtype=author&query=Karl%2C+M">Maximilian Karl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unlike most reinforcement learning agents which require an unrealistic amount
of environment interactions to learn a new behaviour, humans excel at learning
quickly by merely observing and imitating others. This ability highly depends
on the fact that humans have a model of their own embodiment that allows them
to infer the most likely actions that led to the observed behaviour. In this
paper, we propose Action Inference by Maximising Evidence (AIME) to replicate
this behaviour using world models. AIME consists of two distinct phases. In the
first phase, the agent learns a world model from its past experience to
understand its own body by maximising the ELBO. While in the second phase, the
agent is given some observation-only demonstrations of an expert performing a
novel task and tries to imitate the expert's behaviour. AIME achieves this by
defining a policy as an inference model and maximising the evidence of the
demonstration under the policy and world model. Our method is "zero-shot" in
the sense that it does not require further training for the world model or
online interactions with the environment after given the demonstration. We
empirically validate the zero-shot imitation performance of our method on the
Walker and Cheetah embodiment of the DeepMind Control Suite and find it
outperforms the state-of-the-art baselines. Code is available at:
https://github.com/argmax-ai/aime.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02021" title="Abstract">arXiv:2312.02021</a> [<a href="/pdf/2312.02021" title="Download PDF">pdf</a>, <a href="/format/2312.02021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations  for Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%BCmmer%2C+C">Christoph H&#xfc;mmer</a>, 
<a href="/search/cs?searchtype=author&query=Schwonberg%2C+M">Manuel Schwonberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Liangwei Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Gottschalk%2C+H">Hanno Gottschalk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Domain generalization (DG) remains a significant challenge for perception
based on deep neural networks (DNN), where domain shifts occur due to lighting,
weather, or geolocation changes. In this work, we propose VLTSeg to enhance
domain generalization in semantic segmentation, where the network is solely
trained on the source domain and evaluated on unseen target domains. Our method
leverages the inherent semantic robustness of vision-language models. First, by
substituting traditional vision-only backbones with pre-trained encoders from
CLIP and EVA-CLIP as transfer learning setting we find that in the field of DG,
vision-language pre-training significantly outperforms supervised and
self-supervised vision pre-training. We thus propose a new vision-language
approach for domain generalized segmentation, which improves the domain
generalization SOTA by 7.6% mIoU when training on the synthetic GTA5 dataset.
We further show the superior generalization capabilities of vision-language
segmentation models by reaching 76.48% mIoU on the popular Cityscapes-to-ACDC
benchmark, outperforming the previous SOTA approach by 6.9% mIoU on the test
set at the time of writing. Additionally, our approach shows strong in-domain
generalization capabilities indicated by 86.1% mIoU on the Cityscapes test set,
resulting in a shared first place with the previous SOTA on the current
leaderboard at the time of submission.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02023" title="Abstract">arXiv:2312.02023</a> [<a href="/pdf/2312.02023" title="Download PDF">pdf</a>, <a href="/ps/2312.02023" title="Download PostScript">ps</a>, <a href="/format/2312.02023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency of Relations over Monoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atserias%2C+A">Albert Atserias</a>, 
<a href="/search/cs?searchtype=author&query=Kolaitis%2C+P+G">Phokion G. Kolaitis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The interplay between local consistency and global consistency has been the
object of study in several different areas, including probability theory,
relational databases, and quantum information. For relational databases, Beeri,
Fagin, Maier, and Yannakakis showed that a database schema is acyclic if and
only if it has the local-to-global consistency property for relations, which
means that every collection of pairwise consistent relations over the schema is
globally consistent. More recently, the same result has been shown under bag
semantics. In this paper, we carry out a systematic study of local vs.\ global
consistency for relations over positive commutative monoids, which is a common
generalization of ordinary relations and bags. Let $\mathbb K$ be an arbitrary
positive commutative monoid. We begin by showing that acyclicity of the schema
is a necessary condition for the local-to-global consistency property for
$\mathbb K$-relations to hold. Unlike the case of ordinary relations and bags,
however, we show that acyclicity is not always sufficient. After this, we
characterize the positive commutative monoids for which acyclicity is both
necessary and sufficient for the local-to-global consistency property to hold;
this characterization involves a combinatorial property of monoids, which we
call the \emph{transportation property}. We then identify several different
classes of monoids that possess the transportation property. As our final
contribution, we introduce a modified notion of local consistency of
$\mathbb{K}$-relations, which we call \emph{pairwise consistency up to the free
cover}. We prove that, for all positive commutative monoids $\mathbb{K}$, even
those without the transportation property, acyclicity is both necessary and
sufficient for every family of $\mathbb{K}$-relations that is pairwise
consistent up to the free cover to be globally consistent.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02029" title="Abstract">arXiv:2312.02029</a> [<a href="/pdf/2312.02029" title="Download PDF">pdf</a>, <a href="/format/2312.02029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Learning of Scene Geometry from Poses for Global Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altillawi%2C+M">Mohammad Altillawi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shile Li</a>, 
<a href="/search/cs?searchtype=author&query=Prakhya%2C+S+M">Sai Manoj Prakhya</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Serrat%2C+J">Joan Serrat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE ROBOTICS AND AUTOMATION LETTERS. ACCEPTED NOVEMBER, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Global visual localization estimates the absolute pose of a camera using a
single image, in a previously mapped area. Obtaining the pose from a single
image enables many robotics and augmented/virtual reality applications.
Inspired by latest advances in deep learning, many existing approaches directly
learn and regress 6 DoF pose from an input image. However, these methods do not
fully utilize the underlying scene geometry for pose regression. The challenge
in monocular relocalization is the minimal availability of supervised training
data, which is just the corresponding 6 DoF poses of the images. In this paper,
we propose to utilize these minimal available labels (.i.e, poses) to learn the
underlying 3D geometry of the scene and use the geometry to estimate the 6 DoF
camera pose. We present a learning method that uses these pose labels and rigid
alignment to learn two 3D geometric representations (\textit{X, Y, Z
coordinates}) of the scene, one in camera coordinate frame and the other in
global coordinate frame. Given a single image, it estimates these two 3D scene
representations, which are then aligned to estimate a pose that matches the
pose label. This formulation allows for the active inclusion of additional
learning constraints to minimize 3D alignment errors between the two 3D scene
representations, and 2D re-projection errors between the 3D global scene
representation and 2D image pixels, resulting in improved localization
accuracy. During inference, our model estimates the 3D scene geometry in camera
and global frames and aligns them rigidly to obtain pose in real-time. We
evaluate our work on three common visual localization datasets, conduct
ablation studies, and show that our method exceeds state-of-the-art regression
methods' pose accuracy on all datasets.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02034" title="Abstract">arXiv:2312.02034</a> [<a href="/pdf/2312.02034" title="Download PDF">pdf</a>, <a href="/format/2312.02034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust, distrust, and appropriate reliance in (X)AI: a survey of  empirical evaluation of user trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Visser%2C+R">Roel Visser</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+T+M">Tobias M. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Scharlau%2C+I">Ingrid Scharlau</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">A current concern in the field of Artificial Intelligence (AI) is to ensure
the trustworthiness of AI systems. The development of explainability methods is
one prominent way to address this, which has often resulted in the assumption
that the use of explainability will lead to an increase in the trust of users
and wider society. However, the dynamics between explainability and trust are
not well established and empirical investigations of their relation remain
mixed or inconclusive. In this paper we provide a detailed description of the
concepts of user trust and distrust in AI and their relation to appropriate
reliance. For that we draw from the fields of machine learning, human-computer
interaction, and the social sciences. Furthermore, we have created a survey of
existing empirical studies that investigate the effects of AI systems and XAI
methods on user (dis)trust. With clarifying the concepts and summarizing the
empirical investigations, we aim to provide researchers, who examine user trust
in AI, with an improved starting point for developing user studies to measure
and evaluate the user's attitude towards and reliance on AI systems.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02037" title="Abstract">arXiv:2312.02037</a> [<a href="/pdf/2312.02037" title="Download PDF">pdf</a>, <a href="/format/2312.02037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GFS: Graph-based Feature Synthesis for Prediction over Relational  Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Q">Quan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wipf%2C+D">David Wipf</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, VLDB 2024 under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Relational databases are extensively utilized in a variety of modern
information system applications, and they always carry valuable data patterns.
There are a huge number of data mining or machine learning tasks conducted on
relational databases. However, it is worth noting that there are limited
machine learning models specifically designed for relational databases, as most
models are primarily tailored for single table settings. Consequently, the
prevalent approach for training machine learning models on data stored in
relational databases involves performing feature engineering to merge the data
from multiple tables into a single table and subsequently applying single table
models. This approach not only requires significant effort in feature
engineering but also destroys the inherent relational structure present in the
data. To address these challenges, we propose a novel framework called
Graph-based Feature Synthesis (GFS). GFS formulates the relational database as
a heterogeneous graph, thereby preserving the relational structure within the
data. By leveraging the inductive bias from single table models, GFS
effectively captures the intricate relationships inherent in each table.
Additionally, the whole framework eliminates the need for manual feature
engineering. In the extensive experiment over four real-world multi-table
relational databases, GFS outperforms previous methods designed for relational
databases, demonstrating its superior performance.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02042" title="Abstract">arXiv:2312.02042</a> [<a href="/pdf/2312.02042" title="Download PDF">pdf</a>, <a href="/format/2312.02042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kirchhoff Meets Johnson: In Pursuit of Unconditionally Secure  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, Under review for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
<p class="mathjax">Noise: an enemy to be dealt with and a major factor limiting communication
system performance. However, what if there is gold in that garbage? In
conventional engineering, our focus is primarily on eliminating, suppressing,
combating, or even ignoring noise and its detrimental impacts. Conversely,
could we exploit it similarly to biology, which utilizes noise-alike carrier
signals to convey information? In this context, the utilization of noise, or
noise-alike signals in general, has been put forward as a means to realize
unconditionally secure communication systems in the future. In this tutorial
article, we begin by tracing the origins of thermal noise-based communication
and highlighting one of its significant applications for ensuring
unconditionally secure networks: the Kirchhoff-law-Johnson-noise (KLJN) secure
key exchange scheme. We then delve into the inherent challenges tied to secure
communication and discuss the imperative need for physics-based key
distribution schemes in pursuit of unconditional security. Concurrently, we
provide a concise overview of quantum key distribution (QKD) schemes and draw
comparisons with their KLJN-based counterparts. Finally, extending beyond wired
communication loops, we explore the transmission of noise signals over-the-air
and evaluate their potential for stealth and secure wireless communication
systems.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02048" title="Abstract">arXiv:2312.02048</a> [<a href="/pdf/2312.02048" title="Download PDF">pdf</a>, <a href="/format/2312.02048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isomorphism for Tournaments of Small Twin Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>, 
<a href="/search/cs?searchtype=author&query=Neuen%2C+D">Daniel Neuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We prove that isomorphism of tournaments of twin width at most $k$ can be
decided in time $k^{O(\log k)}n^{O(1)}$. This implies that the isomorphism
problem for classes of tournaments of bounded or moderately growing twin width
is in polynomial time. By comparison, there are classes of undirected graphs of
bounded twin width that are isomorphism complete, that is, the isomorphism
problem for the classes is as hard as the general graph isomorphism problem.
Twin width is a graph parameter that has been introduced only recently (Bonnet
et al., FOCS 2020), but has received a lot of attention in structural graph
theory since then. On directed graphs, it is functionally smaller than clique
width. We prove that on tournaments (but not on general directed graphs) it is
also functionally smaller than directed tree width (and thus, the same also
holds for cut width and directed path width). Hence, our result implies that
tournament isomorphism testing is also fixed-parameter tractable when
parameterized by any of these parameters.
<br />Our isomorphism algorithm heavily employs group-theoretic techniques. This
seems to be necessary: as a second main result, we show that the combinatorial
Weisfeiler-Leman algorithm does not decide isomorphism of tournaments of twin
width at most 35 if its dimension is $o(\sqrt n)$. (Throughout this abstract,
$n$ is the order of the input graphs.)
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02051" title="Abstract">arXiv:2312.02051</a> [<a href="/pdf/2312.02051" title="Download PDF">pdf</a>, <a href="/format/2312.02051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeChat: A Time-sensitive Multimodal Large Language Model for Long  Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Linli Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, code is available at <a href="https://github.com/RenShuhuai-Andy/TimeChat">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This work proposes TimeChat, a time-sensitive multimodal large language model
specifically designed for long video understanding. Our model incorporates two
key architectural contributions: (1) a timestamp-aware frame encoder that binds
visual content with the timestamp of each frame, and (2) a sliding video
Q-Former that produces a video token sequence of varying lengths to accommodate
videos of various durations. Additionally, we construct an instruction-tuning
dataset, encompassing 6 tasks and a total of 125K instances, to further enhance
TimeChat's instruction-following performance. Experiment results across various
video understanding tasks, such as dense captioning, temporal grounding, and
highlight detection, demonstrate TimeChat's strong zero-shot temporal
localization and reasoning capabilities. For example, it achieves +9.2 F1 score
and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5)
on Charades-STA, compared to state-of-the-art video large language models,
holding the potential to serve as a versatile video assistant for long-form
video comprehension tasks and satisfy realistic user requirements.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02052" title="Abstract">arXiv:2312.02052</a> [<a href="/pdf/2312.02052" title="Download PDF">pdf</a>, <a href="/format/2312.02052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUCK: Distance-based Unlearning via Centroid Kinematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotogni%2C+M">Marco Cotogni</a>, 
<a href="/search/cs?searchtype=author&query=Bonato%2C+J">Jacopo Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Sabetta%2C+L">Luigi Sabetta</a>, 
<a href="/search/cs?searchtype=author&query=Pelosin%2C+F">Francesco Pelosin</a>, 
<a href="/search/cs?searchtype=author&query=Nicolosi%2C+A">Alessandro Nicolosi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Unlearning is rising as a new field, driven by the pressing necessity
of ensuring privacy in modern artificial intelligence models. This technique
primarily aims to eradicate any residual influence of a specific subset of data
from the knowledge acquired by a neural model during its training. This work
introduces a novel unlearning algorithm, denoted as Distance-based Unlearning
via Centroid Kinematics (DUCK), which employs metric learning to guide the
removal of samples matching the nearest incorrect centroid in the embedding
space. Evaluation of the algorithm's performance is conducted across various
benchmark datasets in two distinct scenarios, class removal, and homogeneous
sampling removal, obtaining state-of-the-art performance. We introduce a novel
metric, called Adaptive Unlearning Score (AUS), encompassing not only the
efficacy of the unlearning process in forgetting target data but also
quantifying the performance loss relative to the original model. Moreover, we
propose a novel membership inference attack to assess the algorithm's capacity
to erase previously acquired knowledge, designed to be adaptable to future
methodologies.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02054" title="Abstract">arXiv:2312.02054</a> [<a href="/pdf/2312.02054" title="Download PDF">pdf</a>, <a href="/ps/2312.02054" title="Download PostScript">ps</a>, <a href="/format/2312.02054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From High to Low: Simulating Nondeterminism and State with State
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Schrijvers%2C+T">Tom Schrijvers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 120 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Some effects are considered to be higher-level than others. High-level
effects provide expressive and succinct abstraction of programming concepts,
while low-level effects allow more fine-grained control over program execution
and resources. Yet, often it is desirable to write programs using the
convenient abstraction offered by high-level effects, and meanwhile still
benefit from the optimisations enabled by low-level effects. One solution is to
translate high-level effects to low-level ones.
<br />This paper studies how algebraic effects and handlers allow us to simulate
high-level effects in terms of low-level effects. In particular, we focus on
the interaction between state and nondeterminism known as the local state, as
provided by Prolog. We map this high-level semantics in successive steps onto a
low-level composite state effect, similar to that managed by Prolog's Warren
Abstract Machine. We first give a translation from the high-level local-state
semantics to the low-level global-state semantics, by explicitly restoring
state updates on backtracking. Next, we eliminate nondeterminsm altogether in
favor of a lower-level state containing a choicepoint stack. Then we avoid
copying the state by restricting ourselves to incremental, reversible state
updates. We show how these updates can be stored on a trail stack with another
state effect. We prove the correctness of all our steps using program
calculation where the fusion laws of effect handlers play a central role.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02055" title="Abstract">arXiv:2312.02055</a> [<a href="/pdf/2312.02055" title="Download PDF">pdf</a>, <a href="/format/2312.02055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transaction Ordering Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+J+C">Jan Christoph Schlegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We study equilibrium investment into bidding and latency reduction for
different sequencing policies. For a batch auction design, we observe that
bidders shade bids according to the likelihood that competing bidders land in
the current batch. Moreover, in equilibrium, in the ex-ante investment stage
before the auction, bidders invest into latency until they make zero profit in
expectation.
<br />We compare the batch auction design to continuous time bidding policies (time
boost) and observe that (depending on the choice of parameters) they obtain
similar revenue and welfare guarantees.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02057" title="Abstract">arXiv:2312.02057</a> [<a href="/pdf/2312.02057" title="Download PDF">pdf</a>, <a href="/ps/2312.02057" title="Download PostScript">ps</a>, <a href="/format/2312.02057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved bound on sums of square roots via the subspace theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eisenbrand%2C+F">Friedrich Eisenbrand</a>, 
<a href="/search/cs?searchtype=author&query=Haeberle%2C+M">Matthieu Haeberle</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+N">Neta Singer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The sum of square roots is as follows: Given $x_1,\dots,x_n \in \mathbb{Z}$
and $a_1,\dots,a_n \in \mathbb{N}$ decide whether $ E=\sum_{i=1}^n x_i
\sqrt{a_i} \geq 0$. It is a prominent open problem (Problem 33 of the Open
Problems Project), whether this can be decided in polynomial time. The
state-of-the-art methods rely on separation bounds, which are lower bounds on
the minimum nonzero absolute value of $E$. The current best bound shows that
$|E| \geq \left(n \cdot \max_i (|x_i| \cdot \sqrt{a_i})\right)^{-2^n} $, which
is doubly exponentially small.
<br />We provide a new bound of the form $|E| \geq \gamma \cdot (n \cdot
\max_i|x_i|)^{-2n}$ where $\gamma $ is a constant depending on $a_1,\dots,a_n$.
This is singly exponential in $n$ for fixed $a_1,\dots,a_n$. The constant
$\gamma$ is not explicit and stems from the subspace theorem, a deep result in
the geometry of numbers.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02060" title="Abstract">arXiv:2312.02060</a> [<a href="/pdf/2312.02060" title="Download PDF">pdf</a>, <a href="/ps/2312.02060" title="Download PostScript">ps</a>, <a href="/format/2312.02060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Right-sizing compute resource allocations for bioinformatics tools with  Total Perspective Vortex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goonasekera%2C+N">Nuwan Goonasekera</a>, 
<a href="/search/cs?searchtype=author&query=Bromhead%2C+C">Catherine Bromhead</a>, 
<a href="/search/cs?searchtype=author&query=Gladman%2C+S">Simon Gladman</a>, 
<a href="/search/cs?searchtype=author&query=Coraor%2C+N">Nate Coraor</a>, 
<a href="/search/cs?searchtype=author&query=Gruning%2C+B">Bjorn Gruning</a>, 
<a href="/search/cs?searchtype=author&query=Afgan%2C+E">Enis Afgan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In biomedical research, computational methods have become indispensable and
their use is increasing, making the efficient allocation of computing resources
paramount. Practitioners routinely allocate resources far in excess of what is
required for batch processing jobs, leading to not just inflated wait times and
costs, but also unnecessary carbon emissions. This is not without reason
however, as accurately determining resource needs is complex, affected by the
nature of tools, data size, and analysis parameters, especially on popular
servers that handle numerous jobs. The Galaxy platform, a web-based hub for
biomedical analysis used globally by scientists, exemplifies this challenge.
Serving nearly half a million registered users and managing around 2 million
monthly jobs, Galaxy's growth outpaces the resources at its disposal. This is
necessitating smarter resource utilization. To address this, we have developed
a tool named Total Perspective Vortex (TPV) - a software package that
right-sizes resource allocations for each job. TPV is able to dynamically set
resource requirements for individual jobs and perform meta-scheduling across
heterogeneous resources. It also includes a first-ever community-curated
database of default resource requirements for nearly 1,000 popular
bioinformatics tools. Deployments in Galaxy Australia and Europe demonstrate
its effectiveness with meta-scheduling user jobs and an improved experience for
systems administrators managing Galaxy servers.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02065" title="Abstract">arXiv:2312.02065</a> [<a href="/pdf/2312.02065" title="Download PDF">pdf</a>, <a href="/format/2312.02065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rooein%2C+D">Donya Rooein</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) offer a range of new possibilities, including
adapting the text to different audiences and their reading needs. But how well
do they adapt? We evaluate the readability of answers generated by four
state-of-the-art LLMs (commercial and open-source) to science questions when
prompted to target different age groups and education levels. To assess the
adaptability of LLMs to diverse audiences, we compare the readability scores of
the generated responses against the recommended comprehension level of each age
and education group. We find large variations in the readability of the answers
by different LLMs. Our results suggest LLM answers need to be better adapted to
the intended audience demographics to be more comprehensible. They underline
the importance of enhancing the adaptability of LLMs in education settings to
cater to diverse age and education levels. Overall, current LLMs have set
readability ranges and do not adapt well to different audiences, even when
prompted. That limits their potential for educational purposes.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02069" title="Abstract">arXiv:2312.02069</a> [<a href="/pdf/2312.02069" title="Download PDF">pdf</a>, <a href="/format/2312.02069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shenhan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Kirschstein%2C+T">Tobias Kirschstein</a>, 
<a href="/search/cs?searchtype=author&query=Schoneveld%2C+L">Liam Schoneveld</a>, 
<a href="/search/cs?searchtype=author&query=Davoli%2C+D">Davide Davoli</a>, 
<a href="/search/cs?searchtype=author&query=Giebenhain%2C+S">Simon Giebenhain</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://shenhanqian.github.io/gaussian-avatars">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce GaussianAvatars, a new method to create photorealistic head
avatars that are fully controllable in terms of expression, pose, and
viewpoint. The core idea is a dynamic 3D representation based on 3D Gaussian
splats that are rigged to a parametric morphable face model. This combination
facilitates photorealistic rendering while allowing for precise animation
control via the underlying parametric model, e.g., through expression transfer
from a driving sequence or by manually changing the morphable model parameters.
We parameterize each splat by a local coordinate frame of a triangle and
optimize for explicit displacement offset to obtain a more accurate geometric
representation. During avatar reconstruction, we jointly optimize for the
morphable model parameters and Gaussian splat parameters in an end-to-end
fashion. We demonstrate the animation capabilities of our photorealistic avatar
in several challenging scenarios. For instance, we show reenactments from a
driving video, where our method outperforms existing works by a significant
margin.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02071" title="Abstract">arXiv:2312.02071</a> [<a href="/pdf/2312.02071" title="Download PDF">pdf</a>, <a href="/ps/2312.02071" title="Download PostScript">ps</a>, <a href="/format/2312.02071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Claims of &quot;SAT Requires Exhaustive Search&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavrimootoo%2C+M+C">Michael C. Chavrimootoo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yumeng He</a>, 
<a href="/search/cs?searchtype=author&query=Kotler-Berkowitz%2C+M">Matan Kotler-Berkowitz</a>, 
<a href="/search/cs?searchtype=author&query=Liuson%2C+H">Harry Liuson</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zeyu Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper, we take a closer look at the claims made by Xu and Zhou in
their paper "SAT Requires Exhaustive Search" [XZ23], which claims to provide a
lower bound on the complexity of the so-called Model RB. Xu and Zhou conclude
that their result implies a separation between P and NP, since the lower bound
purportedly proves that the Strong Exponential Time Hypothesis (SETH) is true.
In examining Xu and Zhou's arguments, we find a flaw in their main theorems.
The authors assume that an algorithm for Model RB must have a certain structure
that can leverage downward self-reducibility, and argue that such an algorithm
cannot run in polynomial time. We argue that this structure is not guaranteed
to exist and thus their paper neither proves SETH to be true nor proves P
$\neq$ NP.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02073" title="Abstract">arXiv:2312.02073</a> [<a href="/pdf/2312.02073" title="Download PDF">pdf</a>, <a href="/format/2312.02073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Glitch in the Matrix? Locating and Detecting Language Model Grounding  with Fakepedia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monea%2C+G">Giovanni Monea</a>, 
<a href="/search/cs?searchtype=author&query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="/search/cs?searchtype=author&query=Josifoski%2C+M">Martin Josifoski</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vishrav Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=K%C4%B1c%C4%B1man%2C+E">Emre K&#x131;c&#x131;man</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+B">Barun Patra</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive capabilities in
storing and recalling factual knowledge, but also in adapting to novel
in-context information. Yet, the mechanisms underlying their in-context
grounding remain unknown, especially in situations where in-context information
contradicts factual knowledge embedded in the parameters. This is critical for
retrieval-augmented generation methods, which enrich the context with
up-to-date information, hoping that grounding can rectify the outdated
parametric knowledge. In this study, we introduce Fakepedia, a counterfactual
dataset designed to evaluate grounding abilities when the parametric knowledge
clashes with the in-context information. We benchmark various LLMs with
Fakepedia and discover that GPT-4-turbo has a strong preference for its
parametric knowledge. Mistral-7B, on the contrary, is the model that most
robustly chooses the grounded answer. Then, we conduct causal mediation
analysis on LLM components when answering Fakepedia queries. We demonstrate
that inspection of the computational graph alone can predict LLM grounding with
92.8% accuracy, especially because few MLPs in the Transformer can predict
non-grounded behavior. Our results, together with existing findings about
factual recall mechanisms, provide a coherent narrative of how grounding and
factual recall mechanisms interact within LLMs.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02074" title="Abstract">arXiv:2312.02074</a> [<a href="/pdf/2312.02074" title="Download PDF">pdf</a>, <a href="/format/2312.02074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning is Better with Non-Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burlachenko%2C+K">Konstantin Burlachenko</a>, 
<a href="/search/cs?searchtype=author&query=Alrowithi%2C+A">Abdulmajeed Alrowithi</a>, 
<a href="/search/cs?searchtype=author&query=Albalawi%2C+F+A">Fahad Ali Albalawi</a>, 
<a href="/search/cs?searchtype=author&query=Richtarik%2C+P">Peter Richtarik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 10 figures, Accepted to presentation and proceedings to 4th ACM International Workshop on Distributed Machine Learning
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 4th International Workshop on Distributed
  Machine Learning December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Traditional AI methodologies necessitate centralized data collection, which
becomes impractical when facing problems with network communication, data
privacy, or storage capacity. Federated Learning (FL) offers a paradigm that
empowers distributed AI model training without collecting raw data. There are
different choices for providing privacy during FL training. One of the popular
methodologies is employing Homomorphic Encryption (HE) - a breakthrough in
privacy-preserving computation from Cryptography. However, these methods have a
price in the form of extra computation and memory footprint. To resolve these
issues, we propose an innovative framework that synergizes permutation-based
compressors with Classical Cryptography, even though employing Classical
Cryptography was assumed to be impossible in the past in the context of FL. Our
framework offers a way to replace HE with cheaper Classical Cryptography
primitives which provides security for the training process. It fosters
asynchronous communication and provides flexible deployment options in various
communication topologies.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02078" title="Abstract">arXiv:2312.02078</a> [<a href="/pdf/2312.02078" title="Download PDF">pdf</a>, <a href="/format/2312.02078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating AI into CCTV Systems: A Comprehensive Evaluation of Smart  Video Surveillance in Community Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanle Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ardabili%2C+B+R">Babak Rahimi Ardabili</a>, 
<a href="/search/cs?searchtype=author&query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
<a href="/search/cs?searchtype=author&query=Noghre%2C+G+A">Ghazal Alinezhad Noghre</a>, 
<a href="/search/cs?searchtype=author&query=Neff%2C+C">Christopher Neff</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This article presents an AI-enabled Smart Video Surveillance (SVS) designed
to enhance safety in community spaces such as educational and recreational
areas, and small businesses. The proposed system innovatively integrates with
existing CCTV and wired camera networks, simplifying its adoption across
various community cases to leverage recent AI advancements. Our SVS system,
focusing on privacy, uses metadata instead of pixel data for activity
recognition, aligning with ethical standards. It features cloud-based
infrastructure and a mobile app for real-time, privacy-conscious alerts in
communities.
<br />This article notably pioneers a comprehensive real-world evaluation of the
SVS system, covering AI-driven visual processing, statistical analysis,
database management, cloud communication, and user notifications. It's also the
first to assess an end-to-end anomaly detection system's performance, vital for
identifying potential public safety incidents.
<br />For our evaluation, we implemented the system in a community college, serving
as an ideal model to exemplify the proposed system's capabilities. Our findings
in this setting demonstrate the system's robustness, with throughput, latency,
and scalability effectively managing 16 CCTV cameras. The system maintained a
consistent 16.5 frames per second (FPS) over a 21-hour operation. The average
end-to-end latency for detecting behavioral anomalies and alerting users was
26.76 seconds.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02079" title="Abstract">arXiv:2312.02079</a> [<a href="/pdf/2312.02079" title="Download PDF">pdf</a>, <a href="/format/2312.02079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Set Neural Networks for forecasting asynchronous bioprocess  timeseries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borisyak%2C+M">Maxim Borisyak</a>, 
<a href="/search/cs?searchtype=author&query=Born%2C+S">Stefan Born</a>, 
<a href="/search/cs?searchtype=author&query=Neubauer%2C+P">Peter Neubauer</a>, 
<a href="/search/cs?searchtype=author&query=Cruz-Bournazou%2C+N">Nicol&#xe1;s Cruz-Bournazou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cultivation experiments often produce sparse and irregular time series.
Classical approaches based on mechanistic models, like Maximum Likelihood
fitting or Monte-Carlo Markov chain sampling, can easily account for sparsity
and time-grid irregularities, but most statistical and Machine Learning tools
are not designed for handling sparse data out-of-the-box. Among popular
approaches there are various schemes for filling missing values (imputation)
and interpolation into a regular grid (alignment). However, such methods
transfer the biases of the interpolation or imputation models to the target
model. We show that Deep Set Neural Networks equipped with triplet encoding of
the input data can successfully handle bio-process data without any need for
imputation or alignment procedures. The method is agnostic to the particular
nature of the time series and can be adapted for any task, for example, online
monitoring, predictive control, design of experiments, etc. In this work, we
focus on forecasting. We argue that such an approach is especially suitable for
typical cultivation processes, demonstrate the performance of the method on
several forecasting tasks using data generated from macrokinetic growth models
under realistic conditions, and compare the method to a conventional fitting
procedure and methods based on imputation and alignment.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02080" title="Abstract">arXiv:2312.02080</a> [<a href="/pdf/2312.02080" title="Download PDF">pdf</a>, <a href="/ps/2312.02080" title="Download PostScript">ps</a>, <a href="/format/2312.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-point methods for long-term power control and beamforming design  in large-scale MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miretti%2C+L">Lorenzo Miretti</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L. G. Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This study presents novel applications of fixed-point methods to solve
previously open joint power control and beamforming design problems in modern
large-scale MIMO systems, e.g., based on the cell-free massive MIMO and XL-MIMO
concepts. In particular, motivated by the need for scalable system
architectures, we revisit the classical sum power minimization and max-min fair
design criteria by considering long-term power control and beamforming design
based on channel statistics and possibly limited channel state information
(CSI) sharing across distributed processing units. This approach is believed to
mitigate the severe scalability issues of competing short-term optimal
algorithms in the literature, which must be executed for every channel
realization by a central controller endowed with global CSI, hence imposing
very demanding requirements in terms of computation and interconnection
capabilities. The obtained optimal algorithms are then illustrated and compared
against existing short-term and long-term approaches via numerical simulations
in a cell-free massive MIMO setup.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02082" title="Abstract">arXiv:2312.02082</a> [<a href="/pdf/2312.02082" title="Download PDF">pdf</a>, <a href="/format/2312.02082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint State and Input Estimation for Linear Dynamical Systems with  Sparse Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chakraborty%2C+R+K">Rupam Kalyan Chakraborty</a>, 
<a href="/search/eess?searchtype=author&query=Joseph%2C+G">Geethu Joseph</a>, 
<a href="/search/eess?searchtype=author&query=Murthy%2C+C+R">Chandra R. Murthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sparsity constraints on the control inputs of a linear dynamical system
naturally arise in several practical applications such as networked control,
computer vision, seismic signal processing, and cyber-physical systems. In this
work, we consider the problem of jointly estimating the states and sparse
inputs of such systems from low-dimensional (compressive) measurements. Due to
the low-dimensional measurements, conventional Kalman filtering and smoothing
algorithms fail to accurately estimate the states and inputs. We present a
Bayesian approach that exploits the input sparsity to significantly improve
estimation accuracy. Sparsity in the input estimates is promoted by using
different prior distributions on the input. We investigate two main approaches:
regularizer-based MAP, and {Bayesian learning-based estimation}. We also extend
the approaches to handle control inputs with common support and analyze the
time and memory complexities of the presented algorithms. Finally, using
numerical simulations, we show that our algorithms outperform the
state-of-the-art methods in terms of accuracy and time/memory complexities,
especially in the low-dimensional measurement regime.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02087" title="Abstract">arXiv:2312.02087</a> [<a href="/pdf/2312.02087" title="Download PDF">pdf</a>, <a href="/format/2312.02087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoSwap: Customized Video Subject Swapping with Interactive Semantic  Point Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yipin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kevin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://videoswap.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current diffusion-based video editing primarily focuses on
structure-preserved editing by utilizing various dense correspondences to
ensure temporal consistency and motion alignment. However, these approaches are
often ineffective when the target edit involves a shape change. To embark on
video editing with shape change, we explore customized video subject swapping
in this work, where we aim to replace the main subject in a source video with a
target subject having a distinct identity and potentially different shape. In
contrast to previous methods that rely on dense correspondences, we introduce
the VideoSwap framework that exploits semantic point correspondences, inspired
by our observation that only a small number of semantic points are necessary to
align the subject's motion trajectory and modify its shape. We also introduce
various user-point interactions (\eg, removing points and dragging points) to
address various semantic point correspondence. Extensive experiments
demonstrate state-of-the-art video subject swapping results across a variety of
real-world videos.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02088" title="Abstract">arXiv:2312.02088</a> [<a href="/pdf/2312.02088" title="Download PDF">pdf</a>, <a href="/format/2312.02088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Bounds for Noise Filtration using Low-Rank Tensor  Approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Petrov%2C+S">Sergey Petrov</a>, 
<a href="/search/math?searchtype=author&query=Zamarashkin%2C+N">Nikolai Zamarashkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Low-rank tensor approximation error bounds are proposed for the case of noisy
input data that depend on low-rank representation type, rank and the
dimensionality of the tensor. The bounds show that high-dimensional low-rank
structured approximations provide superior noise-filtering properties compared
to matrices with the same rank and total element count.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02089" title="Abstract">arXiv:2312.02089</a> [<a href="/pdf/2312.02089" title="Download PDF">pdf</a>, <a href="/ps/2312.02089" title="Download PostScript">ps</a>, <a href="/format/2312.02089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Sweeps and High Dimensional Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alev%2C+V+L">Vedat Levi Alev</a>, 
<a href="/search/cs?searchtype=author&query=Parzanchevski%2C+O">Ori Parzanchevski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">It is well known that the spectral gap of the down-up walk over an
$n$-partite simplicial complex (also known as Glauber dynamics) cannot be
better than $O(1/n)$ due to natural obstructions such as coboundaries. We study
an alternative random walk over partite simplicial complexes known as the
sequential sweep or the systematic scan Glauber dynamics: Whereas the down-up
walk at each step selects a random coordinate and updates it based on the
remaining coordinates, the sequential sweep goes through each of the
coordinates one by one in a deterministic order and applies the same update
operation. It is natural, thus, to compare $n$-steps of the down-up walk with a
single step of the sequential sweep. Interestingly, while the spectral gap of
the $n$-th power of the down-up walk is still bounded from above by a constant,
under a strong enough local spectral assumption (in the sense of Gur,
Lifschitz, Liu, STOC 2022) we can show that the spectral gap of this walk can
be arbitrarily close to 1. We also study other isoperimetric inequalities for
these walks, and show that under the assumptions of local entropy contraction
(related to the considerations of Gur, Lifschitz, Liu), these walks satisfy an
entropy contraction inequality.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02091" title="Abstract">arXiv:2312.02091</a> [<a href="/pdf/2312.02091" title="Download PDF">pdf</a>, <a href="/format/2312.02091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics simulation capabilities of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali-Dib%2C+M">Mohamad Ali-Dib</a>, 
<a href="/search/cs?searchtype=author&query=Menou%2C+K">Kristen Menou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted. Abridged abstract. 15 pages + appendix, 1 figure. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">[Abridged abstract] Large Language Models (LLMs) can solve some
undergraduate-level to graduate-level physics textbook problems and are
proficient at coding. Combining these two capabilities could one day enable AI
systems to simulate and predict the physical world.
<br />We present an evaluation of state-of-the-art (SOTA) LLMs on PhD-level to
research-level computational physics problems. We condition LLM generation on
the use of well-documented and widely-used packages to elicit coding
capabilities in the physics and astrophysics domains. We contribute $\sim 50$
original and challenging problems in celestial mechanics (with REBOUND),
stellar physics (with MESA), 1D fluid dynamics (with Dedalus) and non-linear
dynamics (with SciPy). Since our problems do not admit unique solutions, we
evaluate LLM performance on several soft metrics: counts of lines that contain
different types of errors (coding, physics, necessity and sufficiency) as well
as a more "educational" Pass-Fail metric focused on capturing the salient
physical ingredients of the problem at hand.
<br />As expected, today's SOTA LLM (GPT4) zero-shot fails most of our problems,
although about 40\% of the solutions could plausibly get a passing grade. About
$70-90 \%$ of the code lines produced are necessary, sufficient and correct
(coding \&amp; physics). Physics and coding errors are the most common, with some
unnecessary or insufficient lines. We observe significant variations across
problem class and difficulty. We identify several failure modes of GPT4 in the
computational physics domain.
<br />Our reconnaissance work provides a snapshot of current computational
capabilities in classical physics and points to obvious improvement targets if
AI systems are ever to reach a basic level of autonomy in physics simulation
capabilities.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02093" title="Abstract">arXiv:2312.02093</a> [<a href="/pdf/2312.02093" title="Download PDF">pdf</a>, <a href="/ps/2312.02093" title="Download PostScript">ps</a>, <a href="/format/2312.02093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cultural Differences in Students&#x27; Privacy Concerns in Learning Analytics  across Germany, South Korea, Spain, Sweden, and the United States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viberg%2C+O">Olga Viberg</a>, 
<a href="/search/cs?searchtype=author&query=Kizilcec%2C+R+F">Ren&#xe9; F. Kizilcec</a>, 
<a href="/search/cs?searchtype=author&query=Jivet%2C+I">Ioana Jivet</a>, 
<a href="/search/cs?searchtype=author&query=Mon%C3%A9s%2C+A+M">Alejandra Mart&#xed;nez Mon&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>, 
<a href="/search/cs?searchtype=author&query=Mutimukwe%2C+C">Chantal Mutimukwe</a>, 
<a href="/search/cs?searchtype=author&query=Hrastinski%2C+S">Stefan Hrastinski</a>, 
<a href="/search/cs?searchtype=author&query=Scheffel%2C+M">Maren Scheffel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Applications of learning analytics (LA) can raise concerns from students
about their privacy in higher education contexts. Developing effective
privacy-enhancing practices requires a systematic understanding of students'
privacy concerns and how they vary across national and cultural dimensions. We
conducted a survey study with established instruments to measure privacy
concerns and cultural values for university students in five countries
(Germany, South Korea, Spain, Sweden, and the United States; N = 762). The
results show that students generally trusted institutions with their data and
disclosed information as they perceived the risks to be manageable even though
they felt somewhat limited in their ability to control their privacy. Across
the five countries, German and Swedish students stood out as the most trusting
and least concerned, especially compared to US students who reported greater
perceived risk and less control. Students in South Korea and Spain responded
similarly on all five privacy dimensions (perceived privacy risk, perceived
privacy control, privacy concerns, trusting beliefs, and non-self-disclosure
behavior), despite their significant cultural differences. Culture measured at
the individual level affected the antecedents and outcomes of privacy concerns
more than country-level culture. Perceived privacy risk and privacy control
increase with power distance. Trusting beliefs increase with a desire for
uncertainty avoidance and lower masculinity. Non-self-disclosure behaviors rise
with power distance and masculinity, and decrease with more uncertainty
avoidance. Thus, cultural values related to trust in institutions, social
equality and risk-taking should be considered when developing privacy-enhancing
practices and policies in higher education.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02095" title="Abstract">arXiv:2312.02095</a> [<a href="/pdf/2312.02095" title="Download PDF">pdf</a>, <a href="/format/2312.02095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-sample versus case-control sampling scheme for Positive Unlabeled  data: the story of two scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mielniczuk%2C+J">Jan Mielniczuk</a>, 
<a href="/search/cs?searchtype=author&query=Wawrze%C5%84czyk%2C+A">Adam Wawrze&#x144;czyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the paper we argue that performance of the classifiers based on Empirical
Risk Minimization (ERM) for positive unlabeled data, which are designed for
case-control sampling scheme may significantly deteriorate when applied to a
single-sample scenario. We reveal why their behavior depends, in all but very
specific cases, on the scenario. Also, we introduce a single-sample case
analogue of the popular non-negative risk classifier designed for case-control
data and compare its performance with the original proposal. We show that the
significant differences occur between them, especiall when half or more
positive of observations are labeled. The opposite case when ERM minimizer
designed for the case-control case is applied for single-sample data is also
considered and similar conclusions are drawn. Taking into account difference of
scenarios requires a sole, but crucial, change in the definition of the
Empirical Risk.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02097" title="Abstract">arXiv:2312.02097</a> [<a href="/pdf/2312.02097" title="Download PDF">pdf</a>, <a href="/ps/2312.02097" title="Download PostScript">ps</a>, <a href="/format/2312.02097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inapproximability of Maximum Diameter Clustering for Few Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fleischmann%2C+H">Henry Fleischmann</a>, 
<a href="/search/cs?searchtype=author&query=Karlov%2C+K">Kyrylo Karlov</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+K+C">Karthik C. S.</a>, 
<a href="/search/cs?searchtype=author&query=Padaki%2C+A">Ashwin Padaki</a>, 
<a href="/search/cs?searchtype=author&query=Zharkov%2C+S">Stepan Zharkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider the k-diameter clustering problem, where the goal is to partition
a set of points in a metric space into $k$ clusters, minimizing the maximum
distance between any two points in the same cluster. In general metrics,
k-diameter is known to be NP-hard, while it has a $2$-approximation algorithm
(Gonzalez'85). Complementing this algorithm, it is known that k-diameter is
NP-hard to approximate within a factor better than $2$ in the $\ell_1$ and
$\ell_\infty$ metrics, and within a factor of $1.969$ in the $\ell_2$ metric
(Feder-Greene'88).
<br />When $k\geq 3$ is fixed, k-diameter remains NP-hard to approximate within a
factor better than $2$ in the $\ell_\infty$ metric (Megiddo'90). However, its
approximability in this setting has not previously been studied in the $\ell_1$
and $\ell_2$ metrics, though a $1.415$-approximation algorithm in the $\ell_2$
metric follows from a known result (Badoiu et al.'02). In this paper, we
address the remaining gap by showing new hardness of approximation results that
hold even when $k=3$. Specifically, we prove that 3-diameter is NP-hard to
approximate within a factor better than $1.5$ in the $\ell_1$ metric, and
within a factor of $1.304$ in the $\ell_2$ metric.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02102" title="Abstract">arXiv:2312.02102</a> [<a href="/pdf/2312.02102" title="Download PDF">pdf</a>, <a href="/format/2312.02102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Data Injection Attacks on Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shalom%2C+O">Or Shalom</a>, 
<a href="/search/cs?searchtype=author&query=Leshem%2C+A">Amir Leshem</a>, 
<a href="/search/cs?searchtype=author&query=Bajwa%2C+W+U">Waheed U. Bajwa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
<p class="mathjax">Federated learning is a technique that allows multiple entities to
collaboratively train models using their data without compromising data
privacy. However, despite its advantages, federated learning can be susceptible
to false data injection attacks. In these scenarios, a malicious entity with
control over specific agents in the network can manipulate the learning
process, leading to a suboptimal model. Consequently, addressing these data
injection attacks presents a significant research challenge in federated
learning systems. In this paper, we propose a novel technique to detect and
mitigate data injection attacks on federated learning systems. Our mitigation
method is a local scheme, performed during a single instance of training by the
coordinating node, allowing the mitigation during the convergence of the
algorithm. Whenever an agent is suspected to be an attacker, its data will be
ignored for a certain period, this decision will often be re-evaluated. We
prove that with probability 1, after a finite time, all attackers will be
ignored while the probability of ignoring a trustful agent becomes 0, provided
that there is a majority of truthful agents. Simulations show that when the
coordinating node detects and isolates all the attackers, the model recovers
and converges to the truthful model.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02103" title="Abstract">arXiv:2312.02103</a> [<a href="/pdf/2312.02103" title="Download PDF">pdf</a>, <a href="/format/2312.02103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Pseudo-Labeler beyond Noun Concepts for Open-Vocabulary Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sunghun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Junbum Cha</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jonghwan Mun</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-vocabulary object detection (OVOD) has recently gained significant
attention as a crucial step toward achieving human-like visual intelligence.
Existing OVOD methods extend target vocabulary from pre-defined categories to
open-world by transferring knowledge of arbitrary concepts from vision-language
pre-training models to the detectors. While previous methods have shown
remarkable successes, they suffer from indirect supervision or limited
transferable concepts. In this paper, we propose a simple yet effective method
to directly learn region-text alignment for arbitrary concepts. Specifically,
the proposed method aims to learn arbitrary image-to-text mapping for
pseudo-labeling of arbitrary concepts, named Pseudo-Labeling for Arbitrary
Concepts (PLAC). The proposed method shows competitive performance on the
standard OVOD benchmark for noun concepts and a large improvement on referring
expression comprehension benchmark for arbitrary concepts.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02105" title="Abstract">arXiv:2312.02105</a> [<a href="/pdf/2312.02105" title="Download PDF">pdf</a>, <a href="/format/2312.02105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Authoring Worked Examples for Java Programming with Human-AI  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassany%2C+M">Mohammad Hassany</a>, 
<a href="/search/cs?searchtype=author&query=Brusilovsky%2C+P">Peter Brusilovsky</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Jiaze Ke</a>, 
<a href="/search/cs?searchtype=author&query=Akhuseyinoglu%2C+K">Kamil Akhuseyinoglu</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A+B+L">Arun Balajiee Lekshmi Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 papers both same content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Worked examples (solutions to typical programming problems presented as a
source code in a certain language and are used to explain the topics from a
programming class) are among the most popular types of learning content in
programming classes. Most approaches and tools for presenting these examples to
students are based on line-by-line explanations of the example code. However,
instructors rarely have time to provide line-by-line explanations for a large
number of examples typically used in a programming class. In this paper, we
explore and assess a human-AI collaboration approach to authoring worked
examples for Java programming. We introduce an authoring system for creating
Java worked examples that generates a starting version of code explanations and
presents it to the instructor to edit if necessary. We also present a study
that assesses the quality of explanations created with this approach.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02109" title="Abstract">arXiv:2312.02109</a> [<a href="/pdf/2312.02109" title="Download PDF">pdf</a>, <a href="/format/2312.02109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArtAdapter: Text-to-Image Style Transfer using Multi-Level Style Encoder  and Explicit Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dar-Yen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tennent%2C+H">Hamish Tennent</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Ching-Wen Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work introduces ArtAdapter, a transformative text-to-image (T2I) style
transfer framework that transcends traditional limitations of color,
brushstrokes, and object shape, capturing high-level style elements such as
composition and distinctive artistic expression. The integration of a
multi-level style encoder with our proposed explicit adaptation mechanism
enables ArtAdapte to achieve unprecedented fidelity in style transfer, ensuring
close alignment with textual descriptions. Additionally, the incorporation of
an Auxiliary Content Adapter (ACA) effectively separates content from style,
alleviating the borrowing of content from style references. Moreover, our novel
fast finetuning approach could further enhance zero-shot style representation
while mitigating the risk of overfitting. Comprehensive evaluations confirm
that ArtAdapter surpasses current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02111" title="Abstract">arXiv:2312.02111</a> [<a href="/pdf/2312.02111" title="Download PDF">pdf</a>, <a href="/format/2312.02111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriDeNT: Triple Deep Network Training for Privileged Knowledge  Distillation in Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farndale%2C+L">Lucas Farndale</a>, 
<a href="/search/cs?searchtype=author&query=Insall%2C+R">Robert Insall</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Ke Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Computational pathology models rarely utilise data that will not be available
for inference. This means most models cannot learn from highly informative data
such as additional immunohistochemical (IHC) stains and spatial
transcriptomics. We present TriDeNT, a novel self-supervised method for
utilising privileged data that is not available during inference to improve
performance. We demonstrate the efficacy of this method for a range of
different paired data including immunohistochemistry, spatial transcriptomics
and expert nuclei annotations. In all settings, TriDeNT outperforms other
state-of-the-art methods in downstream tasks, with observed improvements of up
to 101%. Furthermore, we provide qualitative and quantitative measurements of
the features learned by these models and how they differ from baselines.
TriDeNT offers a novel method to distil knowledge from scarce or costly data
during training, to create significantly better models for routine inputs.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02112" title="Abstract">arXiv:2312.02112</a> [<a href="/pdf/2312.02112" title="Download PDF">pdf</a>, <a href="/format/2312.02112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Optimization with Feasible Set Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meel%2C+S">Shreya Meel</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the setup of a constrained optimization problem with two agents
$E_1$ and $E_2$ who jointly wish to learn the optimal solution set while
keeping their feasible sets $\mathcal{P}_1$ and $\mathcal{P}_2$ private from
each other. The objective function $f$ is globally known and each feasible set
is a collection of points from a global alphabet. We adopt a sequential
symmetric private information retrieval (SPIR) framework where one of the
agents (say $E_1$) privately checks in $\mathcal{P}_2$, the presence of
candidate solutions of the problem constrained to $\mathcal{P}_1$ only, while
learning no further information on $\mathcal{P}_2$ than the solution alone.
Further, we extract an information theoretically private threshold PSI (ThPSI)
protocol from our scheme and characterize its download cost. We show that,
compared to privately acquiring the feasible set $\mathcal{P}_1\cap
\mathcal{P}_2$ using an SPIR-based private set intersection (PSI) protocol, and
finding the optimum, our scheme is better as it incurs less information leakage
and less download cost than the former. Over all possible uniform mappings of
$f$ to a fixed range of values, our scheme outperforms the former with a high
probability.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02113" title="Abstract">arXiv:2312.02113</a> [<a href="/pdf/2312.02113" title="Download PDF">pdf</a>, <a href="/format/2312.02113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Self-Intersecting Surfaces (SOS): Symmetric Optimisation  for Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amend%2C+C">Christian Amend</a>, 
<a href="/search/cs?searchtype=author&query=Goertzen%2C+T">Tom Goertzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Mathematical Software (cs.MS); Combinatorics (math.CO)

</div>
<p class="mathjax">In this paper, we give a stable and efficient method for fixing
self-intersections and non-manifold parts in a given embedded simplicial
complex. In addition, we show how symmetric properties can be used for further
optimisation. We prove an initialisation criterion for computation of the outer
hull of an embedded simplicial complex. To regularise the outer hull of the
retriangulated surface, we present a method to remedy non-manifold edges and
points. We also give a modification of the outer hull algorithm to determine
chambers of complexes which gives rise to many new insights. All of these
methods have applications in many areas, for example in 3D-printing, artistic
realisations of 3D models or fixing errors introduced by scanning equipment
applied for tomography. Implementations of the proposed algorithms are given in
the computer algebra system GAP4. For verification of our methods, we use a
data-set of highly self-intersecting symmetric icosahedra.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02114" title="Abstract">arXiv:2312.02114</a> [<a href="/pdf/2312.02114" title="Download PDF">pdf</a>, <a href="/format/2312.02114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transitions of Solutions and Their Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+G">Gleb Polevoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We broaden the basis of non-cooperative game theory by considering
miscoordination on a solution concept. For any solution concept, we extend the
solution set of a strategic-form game to a transition set. This set contains
profiles where various agents simultaneously follow different solutions,
e.g.~different Nash equilibria. This models the fact that in practice,
complicated agents are rarely perfectly coordinated on the same equilibrium. We
define two efficiency measures, called the price of transition anarchy and
stability, and bound them. We also refine the notion of transition to the
notion of limited transition, where only a limited number of solutions is
simultaneously played, and to stable transitions, which allow for only minor
lack of coordination. We compare the above mentioned efficiency measures and
bound the efficiency of transitions in important cases, including the important
cases of constant-sum and potential games, which span the set of finite games
with the same number of strategies for each agent. We also prove tight
efficiency bounds for routing games and coordination games on graphs. Finally,
we study algorithms to find the transition degree required to make a given
profile a transition, or to render all the profiles transitions. We conclude
that for the sake of efficiency, it is crucial to avoid uncoordinated
transitions, besides certain cases, such as constant-sum games, identical
utility games, some types of routing games, limited transitions in potential
games, and stable transitions in coordination games.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02116" title="Abstract">arXiv:2312.02116</a> [<a href="/pdf/2312.02116" title="Download PDF">pdf</a>, <a href="/format/2312.02116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIVT: Generative Infinite-Vocabulary Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>, 
<a href="/search/cs?searchtype=author&query=Eastwood%2C+C">Cian Eastwood</a>, 
<a href="/search/cs?searchtype=author&query=Mentzer%2C+F">Fabian Mentzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce generative infinite-vocabulary transformers (GIVT) which
generate vector sequences with real-valued entries, instead of discrete tokens
from a finite vocabulary. To this end, we propose two surprisingly simple
modifications to decoder-only transformers: 1) at the input, we replace the
finite-vocabulary lookup table with a linear projection of the input vectors;
and 2) at the output, we replace the logits prediction (usually mapped to a
categorical distribution) with the parameters of a multivariate Gaussian
mixture model. Inspired by the image-generation paradigm of VQ-GAN and MaskGIT,
where transformers are used to model the discrete latent sequences of a VQ-VAE,
we use GIVT to model the unquantized real-valued latent sequences of a VAE.
When applying GIVT to class-conditional image generation with iterative masked
modeling, we show competitive results with MaskGIT, while our approach
outperforms both VQ-GAN and MaskGIT when using it for causal modeling. Finally,
we obtain competitive results outside of image generation when applying our
approach to panoptic segmentation and depth estimation with a VAE-based variant
of the UViM framework.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02118" title="Abstract">arXiv:2312.02118</a> [<a href="/pdf/2312.02118" title="Download PDF">pdf</a>, <a href="/format/2312.02118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When it Rains, it Pours: Modeling Media Storms and the News Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Litterer%2C+B">Benjamin Litterer</a>, 
<a href="/search/cs?searchtype=author&query=Jurgens%2C+D">David Jurgens</a>, 
<a href="/search/cs?searchtype=author&query=Card%2C+D">Dallas Card</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023; 16 pages; 12 figures; 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Most events in the world receive at most brief coverage by the news media.
Occasionally, however, an event will trigger a media storm, with voluminous and
widespread coverage lasting for weeks instead of days. In this work, we develop
and apply a pairwise article similarity model, allowing us to identify story
clusters in corpora covering local and national online news, and thereby create
a comprehensive corpus of media storms over a nearly two year period. Using
this corpus, we investigate media storms at a new level of granularity,
allowing us to validate claims about storm evolution and topical distribution,
and provide empirical support for previously hypothesized patterns of influence
of storms on media coverage and intermedia agenda setting.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02119" title="Abstract">arXiv:2312.02119</a> [<a href="/pdf/2312.02119" title="Download PDF">pdf</a>, <a href="/format/2312.02119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree of Attacks: Jailbreaking Black-Box LLMs Automatically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+A">Anay Mehrotra</a>, 
<a href="/search/cs?searchtype=author&query=Zampetakis%2C+M">Manolis Zampetakis</a>, 
<a href="/search/cs?searchtype=author&query=Kassianik%2C+P">Paul Kassianik</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+B">Blaine Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+H">Hyrum Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+Y">Yaron Singer</a>, 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An implementation of the presented method is available at <a href="https://github.com/RICommunity/TAP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">While Large Language Models (LLMs) display versatile functionality, they
continue to generate harmful, biased, and toxic content, as demonstrated by the
prevalence of human-designed jailbreaks. In this work, we present Tree of
Attacks with Pruning (TAP), an automated method for generating jailbreaks that
only requires black-box access to the target LLM. TAP utilizes an LLM to
iteratively refine candidate (attack) prompts using tree-of-thoughts reasoning
until one of the generated prompts jailbreaks the target. Crucially, before
sending prompts to the target, TAP assesses them and prunes the ones unlikely
to result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate
a large search space of prompts and pruning reduces the total number of queries
sent to the target. In empirical evaluations, we observe that TAP generates
prompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo)
for more than 80% of the prompts using only a small number of queries. This
significantly improves upon the previous state-of-the-art black-box method for
generating jailbreaks.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02120" title="Abstract">arXiv:2312.02120</a> [<a href="/pdf/2312.02120" title="Download PDF">pdf</a>, <a href="/format/2312.02120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magicoder: Source Code Is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yifeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">We introduce Magicoder, a series of fully open-source (code, weights, and
data) Large Language Models (LLMs) for code that significantly closes the gap
with top code models while having no more than 7B parameters. Magicoder models
are trained on 75K synthetic instruction data using OSS-Instruct, a novel
approach to enlightening LLMs with open-source code snippets to generate
high-quality instruction data for code. Our main motivation is to mitigate the
inherent bias of the synthetic data generated by LLMs by empowering them with a
wealth of open-source references for the production of more diverse, realistic,
and controllable data. The orthogonality of OSS-Instruct and other data
generation methods like Evol-Instruct further enables us to build an enhanced
MagicoderS. Both Magicoder and MagicoderS substantially outperform
state-of-the-art code models with similar or even larger sizes on a wide range
of coding benchmarks, including Python text-to-code generation, multilingual
coding, and data-science program completion. Notably, MagicoderS-CL-7B based on
CodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in
pass@1). Overall, OSS-Instruct opens a new direction for low-bias and
high-quality instruction tuning using abundant open-source references.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02121" title="Abstract">arXiv:2312.02121</a> [<a href="/pdf/2312.02121" title="Download PDF">pdf</a>, <a href="/ps/2312.02121" title="Download PostScript">ps</a>, <a href="/format/2312.02121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Supplement for the $\texttt{gsplat}$ Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+V">Vickie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Find the library at: <a href="https://docs.gsplat.studio/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This report provides the mathematical details of the gsplat library, a
modular toolbox for efficient differentiable Gaussian splatting, as proposed by
Kerbl et al. It provides a self-contained reference for the computations
involved in the forward and backward passes of differentiable Gaussian
splatting. To facilitate practical usage and development, we provide a user
friendly Python API that exposes each component of the forward and backward
passes in rasterization at github.com/nerfstudio-project/gsplat .
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02124" title="Abstract">arXiv:2312.02124</a> [<a href="/pdf/2312.02124" title="Download PDF">pdf</a>, <a href="/format/2312.02124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VerA: Versatile Anonymization Fit for Clinical Facial Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helou%2C+M+E">Majed El Helou</a>, 
<a href="/search/cs?searchtype=author&query=Cetin%2C+D">Doruk Cetin</a>, 
<a href="/search/cs?searchtype=author&query=Stamenkovic%2C+P">Petar Stamenkovic</a>, 
<a href="/search/cs?searchtype=author&query=Zund%2C+F">Fabio Zund</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The escalating legislative demand for data privacy in facial image
dissemination has underscored the significance of image anonymization. Recent
advancements in the field surpass traditional pixelation or blur methods, yet
they predominantly address regular single images. This leaves clinical image
anonymization -- a necessity for illustrating medical interventions -- largely
unaddressed. We present VerA, a versatile facial image anonymization that is
fit for clinical facial images where: (1) certain semantic areas must be
preserved to show medical intervention results, and (2) anonymizing image pairs
is crucial for showing before-and-after results. VerA outperforms or is on par
with state-of-the-art methods in de-identification and photorealism for regular
images. In addition, we validate our results on paired anonymization, and on
the anonymization of both single and paired clinical images with extensive
quantitative and qualitative evaluation.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02125" title="Abstract">arXiv:2312.02125</a> [<a href="/pdf/2312.02125" title="Download PDF">pdf</a>, <a href="/ps/2312.02125" title="Download PostScript">ps</a>, <a href="/format/2312.02125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and  Advanced Decoding Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panahandeh%2C+A">Amir Panahandeh</a>, 
<a href="/search/cs?searchtype=author&query=Asemi%2C+H">Hanie Asemi</a>, 
<a href="/search/cs?searchtype=author&query=Nourani%2C+E">Esmail Nourani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in language models (LMs), have demonstrated significant
efficacy in tasks related to the arts and humanities. While LMs have exhibited
exceptional performance across a wide range of natural language processing
tasks, there are notable challenges associated with their utilization on small
datasets and their ability to replicate more creative human capacities. In this
study, we aim to address these challenges by training a Persian classical
poetry generation model using a transformer architecture on a specialized
dataset with no pretraining. Additionally, we propose a novel decoding method
to enhance coherence and meaningfulness in the generated poetry, effectively
managing the tradeoff between diversity and quality. Furthermore, the results
of our training approach and the proposed decoding method are evaluated through
comprehensive set of automatic and human evaluations and showed its superior
capability to generate coherent and meaningful poetry in compare to other
decoding methods and an existing Persian large language model (LLM).
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02126" title="Abstract">arXiv:2312.02126</a> [<a href="/pdf/2312.02126" title="Download PDF">pdf</a>, <a href="/format/2312.02126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplaTAM: Splat, Track &amp; Map 3D Gaussians for Dense RGB-D SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keetha%2C+N">Nikhil Keetha</a>, 
<a href="/search/cs?searchtype=author&query=Karhade%2C+J">Jay Karhade</a>, 
<a href="/search/cs?searchtype=author&query=Jatavallabhula%2C+K+M">Krishna Murthy Jatavallabhula</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gengshan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Luiten%2C+J">Jonathon Luiten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Dense simultaneous localization and mapping (SLAM) is pivotal for embodied
scene understanding. Recent work has shown that 3D Gaussians enable
high-quality reconstruction and real-time rendering of scenes using multiple
posed cameras. In this light, we show for the first time that representing a
scene by 3D Gaussians can enable dense SLAM using a single unposed monocular
RGB-D camera. Our method, SplaTAM, addresses the limitations of prior radiance
field-based representations, including fast rendering and optimization, the
ability to determine if areas have been previously mapped, and structured map
expansion by adding more Gaussians. We employ an online tracking and mapping
pipeline while tailoring it to specifically use an underlying Gaussian
representation and silhouette-guided optimization via differentiable rendering.
Extensive experiments show that SplaTAM achieves up to 2X state-of-the-art
performance in camera pose estimation, map construction, and novel-view
synthesis, demonstrating its superiority over existing approaches, while
allowing real-time rendering of a high-resolution dense 3D map.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02128" title="Abstract">arXiv:2312.02128</a> [<a href="/pdf/2312.02128" title="Download PDF">pdf</a>, <a href="/format/2312.02128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can we truly transfer an actor&#x27;s genuine happiness to avatars? An  investigation into virtual, real, posed and spontaneous faces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peres%2C+V+M+X">Vitor Miguel Xavier Peres</a>, 
<a href="/search/cs?searchtype=author&query=Molin%2C+G+P+D">Greice Pinho Dal Molin</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Simp\'osio Brasileiro de Jogos e Entretenimento Digital - SBGames 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A look is worth a thousand words is a popular phrase. And why is a simple
look enough to portray our feelings about something or someone? Behind this
question are the theoretical foundations of the field of psychology regarding
social cognition and the studies of psychologist Paul Ekman. Facial
expressions, as a form of non-verbal communication, are the primary way to
transmit emotions between human beings. The set of movements and expressions of
facial muscles that convey some emotional state of the individual to their
observers are targets of studies in many areas. Our research aims to evaluate
Ekman's action units in datasets of real human faces, posed and spontaneous,
and virtual human faces resulting from transferring real faces into Computer
Graphics faces. In addition, we also conducted a case study with specific movie
characters, such as SheHulk and Genius. We intend to find differences and
similarities in facial expressions between real and CG datasets, posed and
spontaneous faces, and also to consider the actors' genders in the videos. This
investigation can help several areas of knowledge, whether using real or
virtual human beings, in education, health, entertainment, games, security, and
even legal matters. Our results indicate that AU intensities are greater for
posed than spontaneous datasets, regardless of gender. Furthermore, there is a
smoothing of intensity up to 80 percent for AU6 and 45 percent for AU12 when a
real face is transformed into CG.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02132" title="Abstract">arXiv:2312.02132</a> [<a href="/pdf/2312.02132" title="Download PDF">pdf</a>, <a href="/format/2312.02132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hot PATE: Private Aggregation of Distributions for Diverse Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+E">Edith Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+J">Jelani Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Sarlos%2C+T">Tamas Sarlos</a>, 
<a href="/search/cs?searchtype=author&query=Stemmer%2C+U">Uri Stemmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The Private Aggregation of Teacher Ensembles (PATE)
framework~\cite{PapernotAEGT:ICLR2017} is a versatile approach to
privacy-preserving machine learning. In PATE, teacher models are trained on
distinct portions of sensitive data, and their predictions are privately
aggregated to label new training examples for a student model.
<br />Until now, PATE has primarily been explored with classification-like tasks,
where each example possesses a ground-truth label, and knowledge is transferred
to the student by labeling public examples. Generative AI models, however,
excel in open ended \emph{diverse} tasks with multiple valid responses and
scenarios that may not align with traditional labeled examples. Furthermore,
the knowledge of models is often encapsulated in the response distribution
itself and may be transferred from teachers to student in a more fluid way. We
propose \emph{hot PATE}, tailored for the diverse setting. In hot PATE, each
teacher model produces a response distribution and the aggregation method must
preserve both privacy and diversity of responses. We demonstrate, analytically
and empirically, that hot PATE achieves privacy-utility tradeoffs that are
comparable to, and in diverse settings, significantly surpass, the baseline
``cold'' PATE.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02133" title="Abstract">arXiv:2312.02133</a> [<a href="/pdf/2312.02133" title="Download PDF">pdf</a>, <a href="/format/2312.02133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Aligned Image Generation via Shared Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hertz%2C+A">Amir Hertz</a>, 
<a href="/search/cs?searchtype=author&query=Voynov%2C+A">Andrey Voynov</a>, 
<a href="/search/cs?searchtype=author&query=Fruchter%2C+S">Shlomi Fruchter</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at style-aligned-gen.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale Text-to-Image (T2I) models have rapidly gained prominence across
creative fields, generating visually compelling outputs from textual prompts.
However, controlling these models to ensure consistent style remains
challenging, with existing methods necessitating fine-tuning and manual
intervention to disentangle content and style. In this paper, we introduce
StyleAligned, a novel technique designed to establish style alignment among a
series of generated images. By employing minimal `attention sharing' during the
diffusion process, our method maintains style consistency across images within
T2I models. This approach allows for the creation of style-consistent images
using a reference style through a straightforward inversion operation. Our
method's evaluation across diverse styles and text prompts demonstrates
high-quality synthesis and fidelity, underscoring its efficacy in achieving
consistent style across various inputs.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02134" title="Abstract">arXiv:2312.02134</a> [<a href="/pdf/2312.02134" title="Download PDF">pdf</a>, <a href="/format/2312.02134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single  Video via Animatable 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liangxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Boyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://huliangxiao.github.io/GaussianAvatar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present GaussianAvatar, an efficient approach to creating realistic human
avatars with dynamic 3D appearances from a single video. We start by
introducing animatable 3D Gaussians to explicitly represent humans in various
poses and clothing styles. Such an explicit and animatable representation can
fuse 3D appearances more efficiently and consistently from 2D observations. Our
representation is further augmented with dynamic properties to support
pose-dependent appearance modeling, where a dynamic appearance network along
with an optimizable feature tensor is designed to learn the
motion-to-appearance mapping. Moreover, by leveraging the differentiable motion
condition, our method enables a joint optimization of motions and appearances
during avatar modeling, which helps to tackle the long-standing issue of
inaccurate motion estimation in monocular settings. The efficacy of
GaussianAvatar is validated on both the public dataset and our collected
dataset, demonstrating its superior performances in terms of appearance quality
and rendering efficiency.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02135" title="Abstract">arXiv:2312.02135</a> [<a href="/pdf/2312.02135" title="Download PDF">pdf</a>, <a href="/format/2312.02135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast View Synthesis of Casual Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yao-Chih Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhoutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Blackburn-Matzen%2C+K">Kevin Blackburn-Matzen</a>, 
<a href="/search/cs?searchtype=author&query=Niklaus%2C+S">Simon Niklaus</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://casual-fvs.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel view synthesis from an in-the-wild video is difficult due to challenges
like scene dynamics and lack of parallax. While existing methods have shown
promising results with implicit neural radiance fields, they are slow to train
and render. This paper revisits explicit video representations to synthesize
high-quality novel views from a monocular video efficiently. We treat static
and dynamic video content separately. Specifically, we build a global static
scene model using an extended plane-based scene representation to synthesize
temporally coherent novel video. Our plane-based scene representation is
augmented with spherical harmonics and displacement maps to capture
view-dependent effects and model non-planar complex surface geometry. We opt to
represent the dynamic content as per-frame point clouds for efficiency. While
such representations are inconsistency-prone, minor temporal inconsistencies
are perceptually masked due to motion. We develop a method to quickly estimate
such a hybrid video representation and render novel views in real time. Our
experiments show that our method can render high-quality novel views from an
in-the-wild video with comparable quality to state-of-the-art methods while
being 100x faster in training and enabling real-time rendering.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02136" title="Abstract">arXiv:2312.02136</a> [<a href="/pdf/2312.02136" title="Download PDF">pdf</a>, <a href="/format/2312.02136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D  Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating large-scale 3D scenes cannot simply apply existing 3D object
synthesis technique since 3D scenes usually hold complex spatial configurations
and consist of a number of objects at varying scales. We thus propose a
practical and efficient 3D representation that incorporates an equivariant
radiance field with the guidance of a bird's-eye view (BEV) map. Concretely,
objects of synthesized 3D scenes could be easily manipulated through steering
the corresponding BEV maps. Moreover, by adequately incorporating positional
encoding and low-pass filters into the generator, the representation becomes
equivariant to the given BEV map. Such equivariance allows us to produce
large-scale, even infinite-scale, 3D scenes via synthesizing local scenes and
then stitching them with smooth consistency. Extensive experiments on 3D scene
datasets demonstrate the effectiveness of our approach. Our project website is
at https://zqh0253.github.io/BerfScene/.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02137" title="Abstract">arXiv:2312.02137</a> [<a href="/pdf/2312.02137" title="Download PDF">pdf</a>, <a href="/format/2312.02137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MANUS: Markerless Hand-Object Grasp Capture using Articulated 3D  Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pokhariya%2C+C">Chandradeep Pokhariya</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+I+N">Ishaan N Shah</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+A">Angela Xing</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kefan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Avinash Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srinath Sridhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding how we grasp objects with our hands has important applications
in areas like robotics and mixed reality. However, this challenging problem
requires accurate modeling of the contact between hands and objects. To capture
grasps, existing methods use skeletons, meshes, or parametric models that can
cause misalignments resulting in inaccurate contacts. We present MANUS, a
method for Markerless Hand-Object Grasp Capture using Articulated 3D Gaussians.
We build a novel articulated 3D Gaussians representation that extends 3D
Gaussian splatting for high-fidelity representation of articulating hands.
Since our representation uses Gaussian primitives, it enables us to efficiently
and accurately estimate contacts between the hand and the object. For the most
accurate results, our method requires tens of camera views that current
datasets do not provide. We therefore build MANUS-Grasps, a new dataset that
contains hand-object grasps viewed from 53 cameras across 30+ scenes, 3
subjects, and comprising over 7M frames. In addition to extensive qualitative
results, we also show that our method outperforms others on a quantitative
contact evaluation method that uses paint transfer from the object to the hand.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02139" title="Abstract">arXiv:2312.02139</a> [<a href="/pdf/2312.02139" title="Download PDF">pdf</a>, <a href="/format/2312.02139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffiT: Diffusion Vision Transformers for Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatamizadeh%2C+A">Ali Hatamizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guilin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models with their powerful expressivity and high sample quality
have enabled many new applications and use-cases in various domains. For sample
generation, these models rely on a denoising neural network that generates
images by iterative denoising. Yet, the role of denoising network architecture
is not well-studied with most efforts relying on convolutional residual U-Nets.
In this paper, we study the effectiveness of vision transformers in
diffusion-based generative learning. Specifically, we propose a new model,
denoted as Diffusion Vision Transformers (DiffiT), which consists of a hybrid
hierarchical architecture with a U-shaped encoder and decoder. We introduce a
novel time-dependent self-attention module that allows attention layers to
adapt their behavior at different stages of the denoising process in an
efficient manner. We also introduce latent DiffiT which consists of transformer
model with the proposed self-attention layers, for high-resolution image
generation. Our results show that DiffiT is surprisingly effective in
generating high-fidelity images, and it achieves state-of-the-art (SOTA)
benchmarks on a variety of class-conditional and unconditional synthesis tasks.
In the latent space, DiffiT achieves a new SOTA FID score of 1.73 on
ImageNet-256 dataset. Repository: https://github.com/NVlabs/DiffiT
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02141" title="Abstract">arXiv:2312.02141</a> [<a href="/pdf/2312.02141" title="Download PDF">pdf</a>, <a href="/format/2312.02141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iMatching: Imperative Correspondence Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Z">Zitong Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dasong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yun-Jou Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Youjie Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning feature correspondence is a foundational task in computer vision,
holding immense importance for downstream applications such as visual odometry
and 3D reconstruction. Despite recent progress in data-driven models, feature
correspondence learning is still limited by the lack of accurate per-pixel
correspondence labels. To overcome this difficulty, we introduce a new
self-supervised scheme, imperative learning (IL), for training feature
correspondence. It enables correspondence learning on arbitrary uninterrupted
videos without any camera pose or depth labels, heralding a new era for
self-supervised correspondence learning. Specifically, we formulated the
problem of correspondence learning as a bilevel optimization, which takes the
reprojection error from bundle adjustment as a supervisory signal for the
model. To avoid large memory and computation overhead, we leverage the
stationary point to effectively back-propagate the implicit gradients through
bundle adjustment. Through extensive experiments, we demonstrate superior
performance on tasks including feature matching and pose estimation, in which
we obtained an average of 30% accuracy gain over the state-of-the-art matching
models.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02142" title="Abstract">arXiv:2312.02142</a> [<a href="/pdf/2312.02142" title="Download PDF">pdf</a>, <a href="/format/2312.02142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Recognition as Next Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+K">Kaiyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bor-Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengduo Li</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> auto-regression for recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present an approach to pose object recognition as next token prediction.
The idea is to apply a language decoder that auto-regressively predicts the
text tokens from image embeddings to form labels. To ground this prediction
process in auto-regression, we customize a non-causal attention mask for the
decoder, incorporating two key features: modeling tokens from different labels
to be independent, and treating image tokens as a prefix. This masking
mechanism inspires an efficient method - one-shot sampling - to simultaneously
sample tokens of multiple labels in parallel and rank generated labels by their
probabilities during inference. To further enhance the efficiency, we propose a
simple strategy to construct a compact decoder by simply discarding the
intermediate blocks of a pretrained language model. This approach yields a
decoder that matches the full model's performance while being notably more
efficient. The code is available at https://github.com/kaiyuyue/nxtp
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02143" title="Abstract">arXiv:2312.02143</a> [<a href="/pdf/2312.02143" title="Download PDF">pdf</a>, <a href="/format/2312.02143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competition-Level Problems Are Effective Evaluators of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+F">Fangyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive reasoning
capabilities, yet there is ongoing debate about these abilities and the
potential data contamination problem recently. This paper aims to evaluate the
reasoning capacities of LLMs, specifically in solving recent competition-level
programming problems in Codeforces, which are expert-crafted and unique,
requiring deep understanding and robust reasoning skills. We first provide a
comprehensive evaluation of GPT-4's peiceived zero-shot performance on this
task, considering various aspects such as problems' release time, difficulties,
and types of errors encountered. Surprisingly, the peiceived performance of
GPT-4 has experienced a cliff like decline in problems after September 2021
consistently across all the difficulties and types of problems, which shows the
potential data contamination, as well as the challenges for any existing LLM to
solve unseen complex reasoning problems. We further explore various approaches
such as fine-tuning, Chain-of-Thought prompting and problem description
simplification, unfortunately none of them is able to consistently mitigate the
challenges. Through our work, we emphasis the importance of this excellent data
source for assessing the genuine reasoning capabilities of LLMs, and foster the
development of LLMs with stronger reasoning abilities and better generalization
in the future.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02144" title="Abstract">arXiv:2312.02144</a> [<a href="/pdf/2312.02144" title="Download PDF">pdf</a>, <a href="/format/2312.02144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Camera Configurations for Multi-View Pedestrian Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yunzhong Hou</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+X">Xingjian Leng</a>, 
<a href="/search/cs?searchtype=author&query=Gedeon%2C+T">Tom Gedeon</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Jointly considering multiple camera views (multi-view) is very effective for
pedestrian detection under occlusion. For such multi-view systems, it is
critical to have well-designed camera configurations, including camera
locations, directions, and fields-of-view (FoVs). Usually, these configurations
are crafted based on human experience or heuristics. In this work, we present a
novel solution that features a transformer-based camera configuration
generator. Using reinforcement learning, this generator autonomously explores
vast combinations within the action space and searches for configurations that
give the highest detection accuracy according to the training dataset. The
generator learns advanced techniques like maximizing coverage, minimizing
occlusion, and promoting collaboration. Across multiple simulation scenarios,
the configurations generated by our transformer-based model consistently
outperform random search, heuristic-based methods, and configurations designed
by human experts, shedding light on future camera layout optimization.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02145" title="Abstract">arXiv:2312.02145</a> [<a href="/pdf/2312.02145" title="Download PDF">pdf</a>, <a href="/format/2312.02145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repurposing Diffusion-Based Image Generators for Monocular Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ke%2C+B">Bingxin Ke</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Metzger%2C+N">Nando Metzger</a>, 
<a href="/search/cs?searchtype=author&query=Daudt%2C+R+C">Rodrigo Caye Daudt</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation is a fundamental computer vision task. Recovering
3D depth from a single image is geometrically ill-posed and requires scene
understanding, so it is not surprising that the rise of deep learning has led
to a breakthrough. The impressive progress of monocular depth estimators has
mirrored the growth in model capacity, from relatively modest CNNs to large
Transformer architectures. Still, monocular depth estimators tend to struggle
when presented with images with unfamiliar content and layout, since their
knowledge of the visual world is restricted by the data seen during training,
and challenged by zero-shot generalization to new domains. This motivates us to
explore whether the extensive priors captured in recent generative diffusion
models can enable better, more generalizable depth estimation. We introduce
Marigold, a method for affine-invariant monocular depth estimation that is
derived from Stable Diffusion and retains its rich prior knowledge. The
estimator can be fine-tuned in a couple of days on a single GPU using only
synthetic training data. It delivers state-of-the-art performance across a wide
range of datasets, including over 20% performance gains in specific cases.
Project page: https://marigoldmonodepth.github.io.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02146" title="Abstract">arXiv:2312.02146</a> [<a href="/pdf/2312.02146" title="Download PDF">pdf</a>, <a href="/format/2312.02146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Polynomial Problems with $SL(2,\mathbb{R})$ Equivariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+H">Hannah Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+M+T">Mitchell Tong Harris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Optimizing and certifying the positivity of polynomials are fundamental
primitives across mathematics and engineering applications, from dynamical
systems to operations research. However, solving these problems in practice
requires large semidefinite programs, with poor scaling in dimension and
degree. In this work, we demonstrate for the first time that neural networks
can effectively solve such problems in a data-driven fashion, achieving tenfold
speedups while retaining high accuracy. Moreover, we observe that these
polynomial learning problems are equivariant to the non-compact group
$SL(2,\mathbb{R})$, which consists of area-preserving linear transformations.
We therefore adapt our learning pipelines to accommodate this structure,
including data augmentation, a new $SL(2,\mathbb{R})$-equivariant architecture,
and an architecture equivariant with respect to its maximal compact subgroup,
$SO(2, \mathbb{R})$. Surprisingly, the most successful approaches in practice
do not enforce equivariance to the entire group, which we prove arises from an
unusual lack of architecture universality for $SL(2,\mathbb{R})$ in particular.
A consequence of this result, which is of independent interest, is that there
exists an equivariant function for which there is no sequence of equivariant
polynomials multiplied by arbitrary invariants that approximates the original
function. This is a rare example of a symmetric problem where data augmentation
outperforms a fully equivariant architecture, and provides interesting lessons
in both theory and practice for other problems with non-compact symmetries.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02147" title="Abstract">arXiv:2312.02147</a> [<a href="/pdf/2312.02147" title="Download PDF">pdf</a>, <a href="/format/2312.02147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rejuvenating image-GPT as Strong Visual Representation Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sucheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junfei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Larger models are coming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper enhances image-GPT (iGPT), one of the pioneering works that
introduce autoregressive pretraining to predict next pixels for visual
representation learning. Two simple yet essential changes are made. First, we
shift the prediction target from raw pixels to semantic tokens, enabling a
higher-level understanding of visual content. Second, we supplement the
autoregressive modeling by instructing the model to predict not only the next
tokens but also the visible tokens. This pipeline is particularly effective
when semantic tokens are encoded by discriminatively trained models, such as
CLIP. We introduce this novel approach as D-iGPT. Extensive experiments
showcase that D-iGPT excels as a strong learner of visual representations: A
notable achievement of D-iGPT is its compelling performance on the ImageNet-1K
dataset -- by training on publicly available datasets, D-iGPT achieves 89.5\%
top-1 accuracy with a vanilla ViT-Large model. This model also shows strong
generalization on the downstream task and robustness on out-of-distribution
samples. Code is avaiable at
\href{https://github.com/OliverRensu/D-iGPT}{https://github.com/OliverRensu/D-iGPT}.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02149" title="Abstract">arXiv:2312.02149</a> [<a href="/pdf/2312.02149" title="Download PDF">pdf</a>, <a href="/format/2312.02149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Powers of Ten
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kontkanen%2C+J">Janne Kontkanen</a>, 
<a href="/search/cs?searchtype=author&query=Curless%2C+B">Brian Curless</a>, 
<a href="/search/cs?searchtype=author&query=Seitz%2C+S">Steve Seitz</a>, 
<a href="/search/cs?searchtype=author&query=Kemelmacher%2C+I">Ira Kemelmacher</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P">Pratul Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://powers-of-10.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Graphics (cs.GR)

</div>
<p class="mathjax">We present a method that uses a text-to-image model to generate consistent
content across multiple image scales, enabling extreme semantic zooms into a
scene, e.g., ranging from a wide-angle landscape view of a forest to a macro
shot of an insect sitting on one of the tree branches. We achieve this through
a joint multi-scale diffusion sampling approach that encourages consistency
across different scales while preserving the integrity of each individual
sampling process. Since each generated scale is guided by a different text
prompt, our method enables deeper levels of zoom than traditional
super-resolution methods that may struggle to create new contextual structure
at vastly different scales. We compare our method qualitatively with
alternative techniques in image super-resolution and outpainting, and show that
our method is most effective at generating consistent multi-scale content.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02150" title="Abstract">arXiv:2312.02150</a> [<a href="/pdf/2312.02150" title="Download PDF">pdf</a>, <a href="/format/2312.02150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Readout Guidance: Learning Control from Diffusion Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Grace Luo</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+O">Oliver Wang</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+D+B">Dan B Goldman</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Readout Guidance, a method for controlling text-to-image diffusion
models with learned signals. Readout Guidance uses readout heads, lightweight
networks trained to extract signals from the features of a pre-trained, frozen
diffusion model at every timestep. These readouts can encode single-image
properties, such as pose, depth, and edges; or higher-order properties that
relate multiple images, such as correspondence and appearance similarity.
Furthermore, by comparing the readout estimates to a user-defined target, and
back-propagating the gradient through the readout head, these estimates can be
used to guide the sampling process. Compared to prior methods for conditional
generation, Readout Guidance requires significantly fewer added parameters and
training samples, and offers a convenient and simple recipe for reproducing
different forms of conditional control under a single framework, with a single
architecture and sampling procedure. We showcase these benefits in the
applications of drag-based manipulation, identity-consistent generation, and
spatially aligned control. Project page: https://readout-guidance.github.io.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02151" title="Abstract">arXiv:2312.02151</a> [<a href="/pdf/2312.02151" title="Download PDF">pdf</a>, <a href="/format/2312.02151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarding Barlow Twins Against Overfitting with Mixed Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandara%2C+W+G+C">Wele Gedara Chaminda Bandara</a>, 
<a href="/search/cs?searchtype=author&query=De+Melo%2C+C+M">Celso M. De Melo</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+V+M">Vishal M. Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and checkpoints are available at: <a href="https://github.com/wgcban/mix-bt.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised Learning (SSL) aims to learn transferable feature
representations for downstream applications without relying on labeled data.
The Barlow Twins algorithm, renowned for its widespread adoption and
straightforward implementation compared to its counterparts like contrastive
learning methods, minimizes feature redundancy while maximizing invariance to
common corruptions. Optimizing for the above objective forces the network to
learn useful representations, while avoiding noisy or constant features,
resulting in improved downstream task performance with limited adaptation.
Despite Barlow Twins' proven effectiveness in pre-training, the underlying SSL
objective can inadvertently cause feature overfitting due to the lack of strong
interaction between the samples unlike the contrastive learning approaches.
From our experiments, we observe that optimizing for the Barlow Twins objective
doesn't necessarily guarantee sustained improvements in representation quality
beyond a certain pre-training phase, and can potentially degrade downstream
performance on some datasets. To address this challenge, we introduce Mixed
Barlow Twins, which aims to improve sample interaction during Barlow Twins
training via linearly interpolated samples. This results in an additional
regularization term to the original Barlow Twins objective, assuming linear
interpolation in the input space translates to linearly interpolated features
in the feature space. Pre-training with this regularization effectively
mitigates feature overfitting and further enhances the downstream performance
on CIFAR-10, CIFAR-100, TinyImageNet, STL-10, and ImageNet datasets. The code
and checkpoints are available at: https://github.com/wgcban/mix-bt.git
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02152" title="Abstract">arXiv:2312.02152</a> [<a href="/pdf/2312.02152" title="Download PDF">pdf</a>, <a href="/format/2312.02152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steerers: A framework for rotation equivariant keypoint descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image keypoint descriptions that are discriminative and matchable over large
changes in viewpoint are vital for 3D reconstruction. However, descriptions
output by learned descriptors are typically not robust to camera rotation.
While they can be made more robust by, e.g., data augmentation, this degrades
performance on upright images. Another approach is test-time augmentation,
which incurs a significant increase in runtime. We instead learn a linear
transform in description space that encodes rotations of the input image. We
call this linear transform a steerer since it allows us to transform the
descriptions as if the image was rotated. From representation theory we know
all possible steerers for the rotation group. Steerers can be optimized (A)
given a fixed descriptor, (B) jointly with a descriptor or (C) we can optimize
a descriptor given a fixed steerer. We perform experiments in all of these
three settings and obtain state-of-the-art results on the rotation invariant
image matching benchmarks AIMS and Roto-360. We publish code and model weights
at github.com/georg-bn/rotation-steerers.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02153" title="Abstract">arXiv:2312.02153</a> [<a href="/pdf/2312.02153" title="Download PDF">pdf</a>, <a href="/format/2312.02153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning and Prompting Everything All at Once for Universal Visual  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chaoyou Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peixian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunsheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision foundation models have been explored recently to build general-purpose
vision systems. However, predominant paradigms, driven by casting
instance-level tasks as an object-word alignment, bring heavy cross-modality
interaction, which is not effective in prompting object detection and visual
grounding. Another line of work that focuses on pixel-level tasks often
encounters a large annotation gap of things and stuff, and suffers from mutual
interference between foreground-object and background-class segmentation. In
stark contrast to the prevailing methods, we present APE, a universal visual
perception model for aligning and prompting everything all at once in an image
to perform diverse tasks, i.e., detection, segmentation, and grounding, as an
instance-level sentence-object matching paradigm. Specifically, APE advances
the convergence of detection and grounding by reformulating language-guided
grounding as open-vocabulary detection, which efficiently scales up model
prompting to thousands of category vocabularies and region descriptions while
maintaining the effectiveness of cross-modality fusion. To bridge the
granularity gap of different pixel-level tasks, APE equalizes semantic and
panoptic segmentation to proxy instance learning by considering any isolated
regions as individual instances. APE aligns vision and language representation
on broad data with natural and challenging characteristics all at once without
task-specific fine-tuning. The extensive experiments on over 160 datasets
demonstrate that, with only one-suit of weights, APE outperforms (or is on par
with) the state-of-the-art models, proving that an effective yet universal
perception for anything aligning and prompting is indeed feasible. Codes and
trained models are released at https://github.com/shenyunhang/APE.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02155" title="Abstract">arXiv:2312.02155</a> [<a href="/pdf/2312.02155" title="Download PDF">pdf</a>, <a href="/format/2312.02155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for  Real-time Human Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shunyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Boyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Ruizhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The link to our projectpage is <a href="https://shunyuanzheng.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new approach, termed GPS-Gaussian, for synthesizing novel views
of a character in a real-time manner. The proposed method enables 2K-resolution
rendering under a sparse-view camera setting. Unlike the original Gaussian
Splatting or neural implicit rendering methods that necessitate per-subject
optimizations, we introduce Gaussian parameter maps defined on the source views
and regress directly Gaussian Splatting properties for instant novel view
synthesis without any fine-tuning or optimization. To this end, we train our
Gaussian parameter regression module on a large amount of human scan data,
jointly with a depth estimation module to lift 2D parameter maps to 3D space.
The proposed framework is fully differentiable and experiments on several
datasets demonstrate that our method outperforms state-of-the-art methods while
achieving an exceeding rendering speed.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02156" title="Abstract">arXiv:2312.02156</a> [<a href="/pdf/2312.02156" title="Download PDF">pdf</a>, <a href="/format/2312.02156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Feature-Guided Diffusion Models for Shadow Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+K">Kangfu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+L">Luis Figueroa</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhihong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+S">Scott Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+V+M">Vishal M. Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page see <a href="https://kfmei.page/shadow-diffusion/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recovering textures under shadows has remained a challenging problem due to
the difficulty of inferring shadow-free scenes from shadow images. In this
paper, we propose the use of diffusion models as they offer a promising
approach to gradually refine the details of shadow regions during the diffusion
process. Our method improves this process by conditioning on a learned latent
feature space that inherits the characteristics of shadow-free images, thus
avoiding the limitation of conventional methods that condition on degraded
images only. Additionally, we propose to alleviate potential local optima
during training by fusing noise features with the diffusion network. We
demonstrate the effectiveness of our approach which outperforms the previous
best method by 13% in terms of RMSE on the AISTD dataset. Further, we explore
instance-level shadow removal, where our model outperforms the previous best
method by 82% in terms of RMSE on the DESOBA dataset.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02157" title="Abstract">arXiv:2312.02157</a> [<a href="/pdf/2312.02157" title="Download PDF">pdf</a>, <a href="/format/2312.02157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh-Guided Neural Implicit Field Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mingming He</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://cassiepython.github.io/MNeuEdit/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural implicit fields have emerged as a powerful 3D representation for
reconstructing and rendering photo-realistic views, yet they possess limited
editability. Conversely, explicit 3D representations, such as polygonal meshes,
offer ease of editing but may not be as suitable for rendering high-quality
novel views. To harness the strengths of both representations, we propose a new
approach that employs a mesh as a guiding mechanism in editing the neural
radiance field. We first introduce a differentiable method using marching
tetrahedra for polygonal mesh extraction from the neural implicit field and
then design a differentiable color extractor to assign colors obtained from the
volume renderings to this extracted mesh. This differentiable colored mesh
allows gradient back-propagation from the explicit mesh to the implicit fields,
empowering users to easily manipulate the geometry and color of neural implicit
fields. To enhance user control from coarse-grained to fine-grained levels, we
introduce an octree-based structure into its optimization. This structure
prioritizes the edited regions and the surface part, making our method achieve
fine-grained edits to the neural implicit field and accommodate various user
modifications, including object additions, component removals, specific area
deformations, and adjustments to local and global colors. Through extensive
experiments involving diverse scenes and editing operations, we have
demonstrated the capabilities and effectiveness of our method. Our project page
is: \url{https://cassiepython.github.io/MNeuEdit/}
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02158" title="Abstract">arXiv:2312.02158</a> [<a href="/pdf/2312.02158" title="Download PDF">pdf</a>, <a href="/format/2312.02158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+A">Anh-Quan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>, 
<a href="/search/cs?searchtype=author&query=de+Charette%2C+R">Raoul de Charette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://astra-vision.github.io/PaSCo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose the task of Panoptic Scene Completion (PSC) which extends the
recently popular Semantic Scene Completion (SSC) task with instance-level
information to produce a richer understanding of the 3D scene. Our PSC proposal
utilizes a hybrid mask-based technique on the non-empty voxels from sparse
multi-scale completions. Whereas the SSC literature overlooks uncertainty which
is critical for robotics applications, we instead propose an efficient
ensembling to estimate both voxel-wise and instance-wise uncertainties along
PSC. This is achieved by building on a multi-input multi-output (MIMO)
strategy, while improving performance and yielding better uncertainty for
little additional compute. Additionally, we introduce a technique to aggregate
permutation-invariant mask predictions. Our experiments demonstrate that our
method surpasses all baselines in both Panoptic Scene Completion and
uncertainty estimation on three large-scale autonomous driving datasets. Our
code and data are available at https://astra-vision.github.io/PaSCo .
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue,  5 Dec 23</h3>
<dl>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17166" title="Abstract">arXiv:2311.17166</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2311.17166" title="Download PDF">pdf</a>, <a href="/format/2311.17166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is stochastic thermodynamics the key to understanding the energy costs  of computation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Wolpert%2C+D">David Wolpert</a>, 
<a href="/search/cond-mat?searchtype=author&query=Korbel%2C+J">Jan Korbel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lynn%2C+C">Christopher Lynn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tasnim%2C+F">Farita Tasnim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Grochow%2C+J">Joshua Grochow</a>, 
<a href="/search/cond-mat?searchtype=author&query=Karde%C5%9F%2C+G">G&#xfc;lce Karde&#x15f;</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aimone%2C+J">James Aimone</a>, 
<a href="/search/cond-mat?searchtype=author&query=Balasubramanian%2C+V">Vijay Balasubramanian</a>, 
<a href="/search/cond-mat?searchtype=author&query=de+Giuli%2C+E">Eric de Giuli</a>, 
<a href="/search/cond-mat?searchtype=author&query=Doty%2C+D">David Doty</a>, 
<a href="/search/cond-mat?searchtype=author&query=Freitas%2C+N">Nahuel Freitas</a>, 
<a href="/search/cond-mat?searchtype=author&query=Marsili%2C+M">Matteo Marsili</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ouldridge%2C+T+E">Thomas E. Ouldridge</a>, 
<a href="/search/cond-mat?searchtype=author&query=Richa%2C+A">Andrea Richa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Riechers%2C+P">Paul Riechers</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rold%C3%A1n%2C+%C3%89">&#xc9;dgar Rold&#xe1;n</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rubenstein%2C+B">Brenda Rubenstein</a>, 
<a href="/search/cond-mat?searchtype=author&query=Toroczkai%2C+Z">Zoltan Toroczkai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Paradiso%2C+J">Joseph Paradiso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typo fix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Computational Complexity (cs.CC); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The relationship between the thermodynamic and computational characteristics
of dynamical physical systems has been a major theoretical interest since at
least the 19th century, and has been of increasing practical importance as the
energetic cost of digital devices has exploded over the last half century. One
of the most important thermodynamic features of real-world computers is that
they operate very far from thermal equilibrium, in finite time, with many
quickly (co-)evolving degrees of freedom. Such computers also must almost
always obey multiple physical constraints on how they work. For example, all
modern digital computers are periodic processes, governed by a global clock.
Another example is that many computers are modular, hierarchical systems, with
strong restrictions on the connectivity of their subsystems. This properties
hold both for naturally occurring computers, like brains or Eukaryotic cells,
as well as digital systems. These features of real-world computers are absent
in 20th century analyses of the thermodynamics of computational processes,
which focused on quasi-statically slow processes. However, the field of
stochastic thermodynamics has been developed in the last few decades - and it
provides the formal tools for analyzing systems that have exactly these
features of real-world computers. We argue here that these tools, together with
other tools currently being developed in stochastic thermodynamics, may help us
understand at a far deeper level just how the fundamental physical properties
of dynamic systems are related to the computation that they perform.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00790" title="Abstract">arXiv:2312.00790</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2312.00790" title="Download PDF">pdf</a>, <a href="/format/2312.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank Solution Operator for Forced Linearized Dynamics with Unsteady  Base Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Amiri-Margavi%2C+A">Alireza Amiri-Margavi</a>, 
<a href="/search/physics?searchtype=author&query=Babaee%2C+H">Hessam Babaee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Understanding the linear growth of disturbances due to external forcing is
crucial for flow stability analysis, flow control, and uncertainty
quantification. These applications typically require a large number of forward
simulations of the forced linearized dynamics, often in a brute-force fashion.
When dealing with simple steady-state or periodic base flows, there exist
powerful and cost-effective solution operator techniques. Once constructed,
these operators can be used to determine the response to various forcings with
negligible computational cost. However, these methods are not applicable to
problems with arbitrarily time-dependent base flows. This paper develops and
investigates reduced-order modeling with time-dependent bases (TDBs) to build
low-rank solution operators for forced linearized dynamics with arbitrarily
time-dependent base flows. In particular, we use forced optimally
time-dependent decomposition (f-OTD), which extracts the time-dependent
correlated structures of the flow response to various excitations.
<br />We also demonstrate that in the case of a steady-state mean flow subject to
harmonic forcing, the f-OTD subspace converges to the dominant resolvent
analysis modes. The demonstration includes four cases: a toy model, the Burgers
equation, the 2D temporally evolving jet, and two-dimensional decaying
isotropic turbulence. In these cases, we demonstrate the utility of the
low-rank operator for (i) identifying the excitation that leads to maximum
amplification, and (ii) reconstructing the full-state flow without incurring
additional cost.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00796" title="Abstract">arXiv:2312.00796</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.00796" title="Download PDF">pdf</a>, <a href="/ps/2312.00796" title="Download PostScript">ps</a>, <a href="/format/2312.00796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Protein Profiler 1.0 (MPP): A webserver for predicting and  visualizing physiochemical properties of proteins at the proteome level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Martinez%2C+G+S">Gustavo Sganzerla Martinez</a>, 
<a href="/search/q-bio?searchtype=author&query=Dutt%2C+M">Mansi Dutt</a>, 
<a href="/search/q-bio?searchtype=author&query=Kumar%2C+A">Anuj Kumar</a>, 
<a href="/search/q-bio?searchtype=author&query=Kelvin%2C+D+J">David J Kelvin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Determining the physicochemical properties of a protein can reveal important
insights in their structure, biological functions, stability, and interactions
with other molecules. Although tools for computing properties of proteins
already existed, we could not find a comprehensive tool that enables the
calculations of multiple properties for multiple input proteins on the proteome
level at once. Facing this limitation, we have developed Multiple Protein
Profiler (MPP) 1.0 as an integrated tool that allows the profiling of 12
individual properties of multiple proteins in a significant manner. MPP
provides a tabular and graphic visualization of properties of multiple
proteins. The tool is freely accessible at
https://mproteinprofiler.microbiologyandimmunology.dal.ca/
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00799" title="Abstract">arXiv:2312.00799</a> (cross-list from eess.SP) [<a href="/pdf/2312.00799" title="Download PDF">pdf</a>, <a href="/format/2312.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> hvEEGNet: exploiting hierarchical VAEs on EEG data for neuroscience  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cisotto%2C+G">Giulia Cisotto</a>, 
<a href="/search/eess?searchtype=author&query=Zancanaro%2C+A">Alberto Zancanaro</a>, 
<a href="/search/eess?searchtype=author&query=Zoppis%2C+I+F">Italo F. Zoppis</a>, 
<a href="/search/eess?searchtype=author&query=Manzoni%2C+S+L">Sara L. Manzoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the recent success of artificial intelligence in neuroscience, a number
of deep learning (DL) models were proposed for classification, anomaly
detection, and pattern recognition tasks in electroencephalography (EEG). EEG
is a multi-channel time-series that provides information about the individual
brain activity for diagnostics, neuro-rehabilitation, and other applications
(including emotions recognition). Two main issues challenge the existing
DL-based modeling methods for EEG: the high variability between subjects and
the low signal-to-noise ratio making it difficult to ensure a good quality in
the EEG data. In this paper, we propose two variational autoencoder models,
namely vEEGNet-ver3 and hvEEGNet, to target the problem of high-fidelity EEG
reconstruction. We properly designed their architectures using the blocks of
the well-known EEGNet as the encoder, and proposed a loss function based on
dynamic time warping. We tested the models on the public Dataset 2a - BCI
Competition IV, where EEG was collected from 9 subjects and 22 channels.
hvEEGNet was found to reconstruct the EEG data with very high-fidelity,
outperforming most previous solutions (including our vEEGNet-ver3 ).
Furthermore, this was consistent across all subjects. Interestingly, hvEEGNet
made it possible to discover that this popular dataset includes a number of
corrupted EEG recordings that might have influenced previous literature
results. We also investigated the training behaviour of our models and related
it with the quality and the size of the input EEG dataset, aiming at opening a
new research debate on this relationship. In the future, hvEEGNet could be used
as anomaly (e.g., artefact) detector in large EEG datasets to support the
domain experts, but also the latent representations it provides could be used
in other classification problems and EEG data generation.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00802" title="Abstract">arXiv:2312.00802</a> (cross-list from eess.SP) [<a href="/pdf/2312.00802" title="Download PDF">pdf</a>, <a href="/ps/2312.00802" title="Download PostScript">ps</a>, <a href="/format/2312.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Authentication Using Mouse Clickstream Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Almalki%2C+S">Sultan Almalki</a>, 
<a href="/search/eess?searchtype=author&query=Chatterjee%2C+P">Prosenjit Chatterjee</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Biometrics is used to authenticate an individual based on physiological or
behavioral traits. Mouse dynamics is an example of a behavioral biometric that
can be used to perform continuous authentication as protection against security
breaches. Recent research on mouse dynamics has shown promising results in
identifying users; however, it has not yet reached an acceptable level of
accuracy. In this paper, an empirical evaluation of different classification
techniques is conducted on a mouse dynamics dataset, the Balabit Mouse
Challenge dataset. User identification is carried out using three mouse
actions: mouse move, point and click, and drag and drop. Verification and
authentication methods are conducted using three machine-learning classifiers:
the Decision Tree classifier, the K-Nearest Neighbors classifier, and the
Random Forest classifier. The results show that the three classifiers can
distinguish between a genuine user and an impostor with a relatively high
degree of accuracy. In the verification mode, all the classifiers achieve a
perfect accuracy of 100%. In authentication mode, all three classifiers
achieved the highest accuracy (ACC) and Area Under Curve (AUC) from scenario B
using the point and click action data: (Decision Tree ACC:87.6%, AUC:90.3%),
(K-Nearest Neighbors ACC:99.3%, AUC:99.9%), and (Random Forest ACC:89.9%,
AUC:92.5%).
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00811" title="Abstract">arXiv:2312.00811</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.00811" title="Download PDF">pdf</a>, <a href="/format/2312.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seizure detection from Electroencephalogram signals via Wavelets and  Graph Theory metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Grant%2C+P">Paul Grant</a>, 
<a href="/search/q-bio?searchtype=author&query=Islam%2C+M+Z">Md Zahidul Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Epilepsy is one of the most prevalent neurological conditions, where an
epileptic seizure is a transient occurrence due to abnormal, excessive and
synchronous activity in the brain. Electroencephalogram signals emanating from
the brain may be captured, analysed and then play a significant role in
detection and prediction of epileptic seizures. In this work we enhance upon a
previous approach that relied on the differing properties of the wavelet
transform. Here we apply the Maximum Overlap Discrete Wavelet Transform to both
reduce signal \textit{noise} and use signal variance exhibited at differing
inherent frequency levels to develop various metrics of connection between the
electrodes placed upon the scalp. %The properties of both the noise reduced
signal and the interconnected electrodes differ significantly during the
different brain states.
<br />Using short duration epochs, to approximate close to real time monitoring,
together with simple statistical parameters derived from the reconstructed
noise reduced signals we initiate seizure detection. To further improve
performance we utilise graph theoretic indicators from derived electrode
connectivity. From there we build the attribute space. We utilise open-source
software and publicly available data to highlight the superior
Recall/Sensitivity performance of our approach, when compared to existing
published methods.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00836" title="Abstract">arXiv:2312.00836</a> (cross-list from eess.IV) [<a href="/pdf/2312.00836" title="Download PDF">pdf</a>, <a href="/format/2312.00836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heteroscedastic Uncertainty Estimation for Probabilistic Unsupervised  Registration of Noisy Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaoran Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Pak%2C+D+H">Daniel H. Pak</a>, 
<a href="/search/eess?searchtype=author&query=Ahn%2C+S+S">Shawn S. Ahn</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/eess?searchtype=author&query=You%2C+C">Chenyu You</a>, 
<a href="/search/eess?searchtype=author&query=Staib%2C+L">Lawrence Staib</a>, 
<a href="/search/eess?searchtype=author&query=Sinusas%2C+A+J">Albert J. Sinusas</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+A">Alex Wong</a>, 
<a href="/search/eess?searchtype=author&query=Duncan%2C+J+S">James S. Duncan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper proposes a heteroscedastic uncertainty estimation framework for
unsupervised medical image registration. Existing methods rely on objectives
(e.g. mean-squared error) that assume a uniform noise level across the image,
disregarding the heteroscedastic and input-dependent characteristics of noise
distribution in real-world medical images. This further introduces noisy
gradients due to undesired penalization on outliers, causing unnatural
deformation and performance degradation. To mitigate this, we propose an
adaptive weighting scheme with a relative $\gamma$-exponentiated
signal-to-noise ratio (SNR) for the displacement estimator after modeling the
heteroscedastic noise using a separate variance estimator to prevent the model
from being driven away by spurious gradients from error residuals, leading to
more accurate displacement estimation. To illustrate the versatility and
effectiveness of the proposed method, we tested our framework on two
representative registration architectures across three medical image datasets.
Our proposed framework consistently outperforms other baselines both
quantitatively and qualitatively while also providing accurate and sensible
uncertainty measures. Paired t-tests show that our improvements in registration
accuracy are statistically significant. The code will be publicly available at
\url{https://voldemort108x.github.io/hetero_uncertainty/}.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00837" title="Abstract">arXiv:2312.00837</a> (cross-list from eess.IV) [<a href="/pdf/2312.00837" title="Download PDF">pdf</a>, <a href="/format/2312.00837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Correspondence Scoring Framework for Unsupervised Image  Registration of Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaoran Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Stendahl%2C+J+C">John C. Stendahl</a>, 
<a href="/search/eess?searchtype=author&query=Staib%2C+L">Lawrence Staib</a>, 
<a href="/search/eess?searchtype=author&query=Sinusas%2C+A+J">Albert J. Sinusas</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+A">Alex Wong</a>, 
<a href="/search/eess?searchtype=author&query=Duncan%2C+J+S">James S. Duncan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose an adaptive training scheme for unsupervised medical image
registration. Existing methods rely on image reconstruction as the primary
supervision signal. However, nuisance variables (e.g. noise and covisibility)
often cause the loss of correspondence between medical images, violating the
Lambertian assumption in physical waves (e.g. ultrasound) and consistent
imaging acquisition. As the unsupervised learning scheme relies on intensity
constancy to establish correspondence between images for reconstruction, this
introduces spurious error residuals that are not modeled by the typical
training objective. To mitigate this, we propose an adaptive framework that
re-weights the error residuals with a correspondence scoring map during
training, preventing the parametric displacement estimator from drifting away
due to noisy gradients, which leads to performance degradations. To illustrate
the versatility and effectiveness of our method, we tested our framework on
three representative registration architectures across three medical image
datasets along with other baselines. Our proposed adaptive framework
consistently outperforms other methods both quantitatively and qualitatively.
Paired t-tests show that our improvements are statistically significant. The
code will be publicly available at
\url{https://voldemort108x.github.io/AdaCS/}.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00842" title="Abstract">arXiv:2312.00842</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.00842" title="Download PDF">pdf</a>, <a href="/ps/2312.00842" title="Download PostScript">ps</a>, <a href="/format/2312.00842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESM-NBR: fast and accurate nucleic acid-binding residue prediction via  protein language model feature representation and multi-task learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+W">Wenwu Zeng</a>, 
<a href="/search/q-bio?searchtype=author&query=Lv%2C+D">Dafeng Lv</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+W">Wenjuan Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Peng%2C+S">Shaoliang Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Protein-nucleic acid interactions play a very important role in a variety of
biological activities. Accurate identification of nucleic acid-binding residues
is a critical step in understanding the interaction mechanisms. Although many
computationally based methods have been developed to predict nucleic
acid-binding residues, challenges remain. In this study, a fast and accurate
sequence-based method, called ESM-NBR, is proposed. In ESM-NBR, we first use
the large protein language model ESM2 to extract discriminative biological
properties feature representation from protein primary sequences; then, a
multi-task deep learning model composed of stacked bidirectional long
short-term memory (BiLSTM) and multi-layer perceptron (MLP) networks is
employed to explore common and private information of DNA- and RNA-binding
residues with ESM2 feature as input. Experimental results on benchmark data
sets demonstrate that the prediction performance of ESM2 feature representation
comprehensively outperforms evolutionary information-based hidden Markov model
(HMM) features. Meanwhile, the ESM-NBR obtains the MCC values for DNA-binding
residues prediction of 0.427 and 0.391 on two independent test sets, which are
18.61 and 10.45% higher than those of the second-best methods, respectively.
Moreover, by completely discarding the time-cost multiple sequence alignment
process, the prediction speed of ESM-NBR far exceeds that of existing methods
(5.52s for a protein sequence of length 500, which is about 16 times faster
than the second-fastest method). A user-friendly standalone package and the
data of ESM-NBR are freely available for academic use at:
https://github.com/wwzll123/ESM-NBR.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00854" title="Abstract">arXiv:2312.00854</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.00854" title="Download PDF">pdf</a>, <a href="/format/2312.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Neural Twin for Treatment Planning in Peripheral  Pulmonary Artery Stenosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lee%2C+J+D">John D. Lee</a>, 
<a href="/search/physics?searchtype=author&query=Richter%2C+J">Jakob Richter</a>, 
<a href="/search/physics?searchtype=author&query=Pfaller%2C+M+R">Martin R. Pfaller</a>, 
<a href="/search/physics?searchtype=author&query=Szafron%2C+J+M">Jason M. Szafron</a>, 
<a href="/search/physics?searchtype=author&query=Menon%2C+K">Karthik Menon</a>, 
<a href="/search/physics?searchtype=author&query=Zanoni%2C+A">Andrea Zanoni</a>, 
<a href="/search/physics?searchtype=author&query=Ma%2C+M+R">Michael R. Ma</a>, 
<a href="/search/physics?searchtype=author&query=Feinstein%2C+J+A">Jeffrey A. Feinstein</a>, 
<a href="/search/physics?searchtype=author&query=Kreutzer%2C+J">Jacqueline Kreutzer</a>, 
<a href="/search/physics?searchtype=author&query=Marsden%2C+A+L">Alison L. Marsden</a>, 
<a href="/search/physics?searchtype=author&query=Schiavazzi%2C+D+E">Daniele E. Schiavazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">The substantial computational cost of high-fidelity models in numerical
hemodynamics has, so far, relegated their use mainly to offline treatment
planning. New breakthroughs in data-driven architectures and optimization
techniques for fast surrogate modeling provide an exciting opportunity to
overcome these limitations, enabling the use of such technology for
time-critical decisions. We discuss an application to the repair of multiple
stenosis in peripheral pulmonary artery disease through either transcatheter
pulmonary artery rehabilitation or surgery, where it is of interest to achieve
desired pressures and flows at specific locations in the pulmonary artery tree,
while minimizing the risk for the patient. Since different degrees of success
can be achieved in practice during treatment, we formulate the problem in
probability, and solve it through a sample-based approach. We propose a new
offline-online pipeline for probabilsitic real-time treatment planning which
combines offline assimilation of boundary conditions, model reduction, and
training dataset generation with online estimation of marginal probabilities,
possibly conditioned on the degree of augmentation observed in already repaired
lesions. Moreover, we propose a new approach for the parametrization of
arbitrarily shaped vascular repairs through iterative corrections of a
zero-dimensional approximant. We demonstrate this pipeline for a diseased model
of the pulmonary artery tree available through the Vascular Model Repository.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00859" title="Abstract">arXiv:2312.00859</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.00859" title="Download PDF">pdf</a>, <a href="/format/2312.00859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Walks Performed by Topologically-Specific Agents on Complex  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Benatti%2C+A">Alexandre Benatti</a>, 
<a href="/search/physics?searchtype=author&query=da+F.+Costa%2C+L">Luciano da F. Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Random walks by single-node agents have been systematically conducted on
various types of complex networks in order to investigate how their topologies
can affect the dynamics of the agents. However, by fitting any network node,
these agents do not engage in topological interactions with the network. In the
present work, we describe random walks on complex networks performed by agents
that are actually small graphs. These agents can only occupy admissible
portions of the network onto which they fit topologically, hence their name
being taken as topologically-specific agents. These agents are also allowed to
move to adjacent subgraphs in the network, which have each node adjacent to the
original respective node of the agent. Two types of random walks are considered
here: uniformly random and influenced by an external field. The performance of
the random walks performed by three types of topologically-specific agents is
studied respectively to the obtained coverage considering three types of
complex networks (geometrical, Erd\H{o}s-R\'enyi, and Barab\'asi-Albert). The
number of nodes displaced at each random walk step is also obtained and
analyzed. Several interesting results are reported and discussed, including the
fact that, despite its intrinsic node degree heterogeneity, Barab\'asi-Albert
networks tend to allow relatively smooth and effective coverage by all the
considered topologically-specific agents. Erd\H{o}s-R\'enyi networks were also
found to yield large dispersions of node coverage. In addition, the triangle
agent was found to allow more effective random walks respectively to any of the
three considered networks.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00885" title="Abstract">arXiv:2312.00885</a> (cross-list from math.CO) [<a href="/pdf/2312.00885" title="Download PDF">pdf</a>, <a href="/ps/2312.00885" title="Download PostScript">ps</a>, <a href="/format/2312.00885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divisible minimal codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Minimal codes are linear codes where all non-zero codewords are minimal,
i.e., whose support is not properly contained in the support of another
codeword. The minimum possible length of such a $k$-dimensional linear code
over $\mathbb{F}_q$ is denoted by $m(k,q)$. Here we determine $m(7,2)$,
$m(8,2)$, and $m(9,2)$, as well as full classifications of all codes attaining
$m(k,2)$ for $k\le 7$ and those attaining $m(9,2)$. For $m(11,2)$ and $m(12,2)$
we give improved upper bounds. It turns out that in many cases attaining
extremal codes have the property that the weights of all codewords are
divisible by some constant $\Delta&gt;1$. So, here we study the minimum lengths of
minimal codes where we additionally assume that the weights of the codewords
are divisible by $\Delta$.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00886" title="Abstract">arXiv:2312.00886</a> (cross-list from stat.ML) [<a href="/pdf/2312.00886" title="Download PDF">pdf</a>, <a href="/format/2312.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Munos%2C+R">R&#xe9;mi Munos</a>, 
<a href="/search/stat?searchtype=author&query=Valko%2C+M">Michal Valko</a>, 
<a href="/search/stat?searchtype=author&query=Calandriello%2C+D">Daniele Calandriello</a>, 
<a href="/search/stat?searchtype=author&query=Azar%2C+M+G">Mohammad Gheshlaghi Azar</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+D">Daniel Guo</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+Y">Yunhao Tang</a>, 
<a href="/search/stat?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/stat?searchtype=author&query=M%C3%A9snard%2C+T">Thomas M&#xe9;snard</a>, 
<a href="/search/stat?searchtype=author&query=Michi%2C+A">Andrea Michi</a>, 
<a href="/search/stat?searchtype=author&query=Selvi%2C+M">Marco Selvi</a>, 
<a href="/search/stat?searchtype=author&query=Girgin%2C+S">Sertan Girgin</a>, 
<a href="/search/stat?searchtype=author&query=Momchev%2C+N">Nikola Momchev</a>, 
<a href="/search/stat?searchtype=author&query=Bachem%2C+O">Olivier Bachem</a>, 
<a href="/search/stat?searchtype=author&query=Mankowitz%2C+D+J">Daniel J. Mankowitz</a>, 
<a href="/search/stat?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/stat?searchtype=author&query=Piot%2C+B">Bilal Piot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Reinforcement learning from human feedback (RLHF) has emerged as the main
paradigm for aligning large language models (LLMs) with human preferences.
Typically, RLHF involves the initial step of learning a reward model from human
feedback, often expressed as preferences between pairs of text generations
produced by a pre-trained LLM. Subsequently, the LLM's policy is fine-tuned by
optimizing it to maximize the reward model through a reinforcement learning
algorithm. However, an inherent limitation of current reward models is their
inability to fully represent the richness of human preferences and their
dependency on the sampling distribution.
<br />In this study, we introduce an alternative pipeline for the fine-tuning of
LLMs using pairwise human feedback. Our approach entails the initial learning
of a preference model, which is conditioned on two inputs given a prompt,
followed by the pursuit of a policy that consistently generates responses
preferred over those generated by any competing policy, thus defining the Nash
equilibrium of this preference model. We term this approach Nash learning from
human feedback (NLHF).
<br />In the context of a tabular policy representation, we present a novel
algorithmic solution, Nash-MD, founded on the principles of mirror descent.
This algorithm produces a sequence of policies, with the last iteration
converging to the regularized Nash equilibrium. Additionally, we explore
parametric representations of policies and introduce gradient descent
algorithms for deep-learning architectures. To demonstrate the effectiveness of
our approach, we present experimental results involving the fine-tuning of a
LLM for a text summarization task. We believe NLHF offers a compelling avenue
for preference learning and policy optimization with the potential of advancing
the field of aligning LLMs with human preferences.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00910" title="Abstract">arXiv:2312.00910</a> (cross-list from q-bio.PE) [<a href="/pdf/2312.00910" title="Download PDF">pdf</a>, <a href="/format/2312.00910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectiveness of probabilistic contact tracing in epidemic containment:  the role of super-spreaders and transmission paths reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Muntoni%2C+A+P">A.P. Muntoni</a>, 
<a href="/search/q-bio?searchtype=author&query=Mazza%2C+F">F. Mazza</a>, 
<a href="/search/q-bio?searchtype=author&query=Braunstein%2C+A">A. Braunstein</a>, 
<a href="/search/q-bio?searchtype=author&query=Catania%2C+G">G. Catania</a>, 
<a href="/search/q-bio?searchtype=author&query=Dall%27Asta%2C+L">L. Dall&#x27;Asta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The recent COVID-19 pandemic underscores the significance of early-stage
non-pharmacological intervention strategies. The widespread use of masks and
the systematic implementation of contact tracing strategies provide a
potentially equally effective and socially less impactful alternative to more
conventional approaches, such as large-scale mobility restrictions. However,
manual contact tracing faces strong limitations in accessing the network of
contacts, and the scalability of currently implemented protocols for
smartphone-based digital contact tracing becomes impractical during the rapid
expansion phases of the outbreaks, due to the surge in exposure notifications
and associated tests. A substantial improvement in digital contact tracing can
be obtained through the integration of probabilistic techniques for risk
assessment that can more effectively guide the allocation of new diagnostic
tests. In this study, we first quantitatively analyze the diagnostic and social
costs associated with these containment measures based on contact tracing,
employing three state-of-the-art models of SARS-CoV-2 spreading. Our results
suggest that probabilistic techniques allow for more effective mitigation at a
lower cost. Secondly, our findings reveal a remarkable efficacy of
probabilistic contact-tracing techniques in capturing backward propagations and
super-spreading events, relevant features of the diffusion of many pathogens,
including SARS-CoV-2.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00921" title="Abstract">arXiv:2312.00921</a> (cross-list from eess.IV) [<a href="/pdf/2312.00921" title="Download PDF">pdf</a>, <a href="/ps/2312.00921" title="Download PostScript">ps</a>, <a href="/format/2312.00921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bitstream Organization for Parallel Entropy Coding on Neural  Network-based Video Codecs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Said%2C+A">Amir Said</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+H">Hoang Le</a>, 
<a href="/search/eess?searchtype=author&query=Farhadzadeh%2C+F">Farzad Farhadzadeh</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. IEEE International Conference on Multimedia, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Video compression systems must support increasing bandwidth and data
throughput at low cost and power, and can be limited by entropy coding
bottlenecks. Efficiency can be greatly improved by parallelizing coding, which
can be done at much larger scales with new neural-based codecs, but with some
compression loss related to data organization. We analyze the bit rate overhead
needed to support multiple bitstreams for concurrent decoding, and for its
minimization propose a method for compressing parallel-decoding entry points,
using bidirectional bitstream packing, and a new form of jointly optimizing
arithmetic coding termination. It is shown that those techniques significantly
lower the overhead, making it easier to reduce it to a small fraction of the
average bitstream size, like, for example, less than 1% and 0.1% when the
average number of bitstream bytes is respectively larger than 95 and 1,200
bytes.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00928" title="Abstract">arXiv:2312.00928</a> (cross-list from math.CO) [<a href="/pdf/2312.00928" title="Download PDF">pdf</a>, <a href="/ps/2312.00928" title="Download PostScript">ps</a>, <a href="/format/2312.00928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hat Guessing Number of Cactus Graphs and Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chizewer%2C+J">Jeremy Chizewer</a>, 
<a href="/search/math?searchtype=author&query=McInnis%2C+I+M+J">I.M.J. McInnis</a>, 
<a href="/search/math?searchtype=author&query=Sohrabi%2C+M">Mehrdad Sohrabi</a>, 
<a href="/search/math?searchtype=author&query=Kaistha%2C+S">Shriya Kaistha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study the hat guessing game on graphs. In this game, a player is placed on
each vertex $v$ of a graph $G$ and assigned a colored hat from $h(v)$ possible
colors. Each player makes a deterministic guess on their hat color based on the
colors assigned to the players on neighboring vertices, and the players win if
at least one player correctly guesses his assigned color. If there exists a
strategy that ensures at least one player guesses correctly for every possible
assignment of colors, the game defined by $\langle G,h\rangle$ is called
winning. The hat guessing number of $G$ is the largest integer $q$ so that if
$h(v)=q$ for all $v\in G$ then $\langle G,h\rangle$ is winning.
<br />In this note, we determine whether $\langle G,h\rangle $ is winning for any
$h$ whenever $G$ is a cycle, resolving a conjecture of Kokhas and Latyshev in
the affirmative and extending it. We then use this result to determine the hat
guessing number of every cactus graph, graphs in which every pair of cycles
share at most one vertex.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00967" title="Abstract">arXiv:2312.00967</a> (cross-list from math.DS) [<a href="/pdf/2312.00967" title="Download PDF">pdf</a>, <a href="/format/2312.00967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Level Set Learning for Poincar&#xe9; Plots of Symplectic Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ruth%2C+M">Maximilian Ruth</a>, 
<a href="/search/math?searchtype=author&query=Bindel%2C+D">David Bindel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA); Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">Many important qualities of plasma confinement devices can be determined via
the Poincar\'e plot of a symplectic return map. These qualities include the
locations of periodic orbits, magnetic islands, and chaotic regions of phase
space. However, every evaluation of the magnetic return map requires solving an
ODE, meaning a detailed Poincar\'e plot can be expensive to create. Here, we
propose a kernel-based method of learning a single labeling function that is
approximately invariant under the symplectic map. From the labeling function,
we can recover the locations of invariant circles, islands, and chaos with few
evaluations of the underlying symplectic map. Additionally, the labeling
function comes with a residual, which serves as a measure of how invariant the
label function is, and therefore as an indirect measure of chaos and map
complexity.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00975" title="Abstract">arXiv:2312.00975</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.00975" title="Download PDF">pdf</a>, <a href="/ps/2312.00975" title="Download PostScript">ps</a>, <a href="/format/2312.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy probing dose facilitated dose prediction for pencil beam scanning  proton therapy: physics enhances generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+L">Lian Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Holmes%2C+J+M">Jason M. Holmes</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Feng%2C+H">Hongying Feng</a>, 
<a href="/search/physics?searchtype=author&query=Sio%2C+T+T">Terence T. Sio</a>, 
<a href="/search/physics?searchtype=author&query=Vargas%2C+C+E">Carlos E. Vargas</a>, 
<a href="/search/physics?searchtype=author&query=Keole%2C+S+R">Sameer R. Keole</a>, 
<a href="/search/physics?searchtype=author&query=St%C3%BCtzer%2C+K">Kristin St&#xfc;tzer</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/physics?searchtype=author&query=Shen%2C+J">Jiajian Shen</a>, 
<a href="/search/physics?searchtype=author&query=Wong%2C+W+W">William W. Wong</a>, 
<a href="/search/physics?searchtype=author&query=Vora%2C+S+A">Sujay A. Vora</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Purpose: Prior AI-based dose prediction studies in photon and proton therapy
often neglect underlying physics, limiting their generalizability to handle
outlier clinical cases, especially for pencil beam scanning proton therapy
(PBSPT). Our aim is to design a physics-aware and generalizable AI-based PBSPT
dose prediction method that has the underlying physics considered to achieve
high generalizability to properly handle the outlier clinical cases. Methods
and Materials: This study analyzed PBSPT plans of 103 prostate and 78 lung
cancer patients from our institution,with each case comprising CT images,
structure sets, and plan doses from our Monte-Carlo dose engine (serving as the
ground truth). Three methods were evaluated in the ablation study: the
ROI-based method, the beam mask and sliding window method, and the noisy
probing dose method. Twelve cases with uncommon beam angles or prescription
doses tested the methods' generalizability to rare treatment planning
scenarios. Performance evaluation used DVH indices, 3D Gamma passing rates
(3%/2mm/10%), and dice coefficients for dose agreement. Results: The noisy
probing dose method showed improved agreement of DVH indices, 3D Gamma passing
rates, and dice coefficients compared to the conventional methods for the
testing cases. The noisy probing dose method showed better generalizability in
the 6 outlier cases than the ROI-based and beam mask-based methods with 3D
Gamma passing rates (for prostate cancer, targets: 89.32%$\pm$1.45% vs.
93.48%$\pm$1.51% vs. 96.79%$\pm$0.83%, OARs: 85.87%$\pm$1.73% vs.
91.15%$\pm$1.13% vs. 94.29%$\pm$1.01%). The dose predictions were completed
within 0.3 seconds. Conclusions: We've devised a novel noisy probing dose
method for PBSPT dose prediction in prostate and lung cancer patients. With
more physics included, it enhances the generalizability of dose prediction in
handling outlier clinical cases.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00991" title="Abstract">arXiv:2312.00991</a> (cross-list from stat.ML) [<a href="/pdf/2312.00991" title="Download PDF">pdf</a>, <a href="/format/2312.00991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergences for Minimax Optimization Problems over Infinite-Dimensional  Spaces Towards Stability in Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Furuya%2C+T">Takashi Furuya</a>, 
<a href="/search/stat?searchtype=author&query=Okuda%2C+S">Satoshi Okuda</a>, 
<a href="/search/stat?searchtype=author&query=Suetake%2C+K">Kazuma Suetake</a>, 
<a href="/search/stat?searchtype=author&query=Sawada%2C+Y">Yoshihide Sawada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Training neural networks that require adversarial optimization, such as
generative adversarial networks (GANs) and unsupervised domain adaptations
(UDAs), suffers from instability. This instability problem comes from the
difficulty of the minimax optimization, and there have been various approaches
in GANs and UDAs to overcome this problem. In this study, we tackle this
problem theoretically through a functional analysis. Specifically, we show the
convergence property of the minimax problem by the gradient descent over the
infinite-dimensional spaces of continuous functions and probability measures
under certain conditions. Using this setting, we can discuss GANs and UDAs
comprehensively, which have been studied independently. In addition, we show
that the conditions necessary for the convergence property are interpreted as
stabilization techniques of adversarial training such as the spectral
normalization and the gradient penalty.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01005" title="Abstract">arXiv:2312.01005</a> (cross-list from astro-ph.GA) [<a href="/pdf/2312.01005" title="Download PDF">pdf</a>, <a href="/format/2312.01005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Images of the M87* Black Hole Using GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Mohan%2C+A">Arya Mohan</a>, 
<a href="/search/astro-ph?searchtype=author&query=Protopapas%2C+P">Pavlos Protopapas</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kunnumkai%2C+K">Keerthi Kunnumkai</a>, 
<a href="/search/astro-ph?searchtype=author&query=Garraffo%2C+C">Cecilia Garraffo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Blackburn%2C+L">Lindy Blackburn</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chatterjee%2C+K">Koushik Chatterjee</a>, 
<a href="/search/astro-ph?searchtype=author&query=Doeleman%2C+S+S">Sheperd S. Doeleman</a>, 
<a href="/search/astro-ph?searchtype=author&query=Emami%2C+R">Razieh Emami</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fromm%2C+C+M">Christian M. Fromm</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mizuno%2C+Y">Yosuke Mizuno</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ricarte%2C+A">Angelo Ricarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures. Accepted by Monthly Notices of the Royal Astronomical Society Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we introduce a novel data augmentation methodology based on
Conditional Progressive Generative Adversarial Networks (CPGAN) to generate
diverse black hole (BH) images, accounting for variations in spin and electron
temperature prescriptions. These generated images are valuable resources for
training deep learning algorithms to accurately estimate black hole parameters
from observational data. Our model can generate BH images for any spin value
within the range of [-1, 1], given an electron temperature distribution. To
validate the effectiveness of our approach, we employ a convolutional neural
network to predict the BH spin using both the GRMHD images and the images
generated by our proposed model. Our results demonstrate a significant
performance improvement when training is conducted with the augmented dataset
while testing is performed using GRMHD simulated data, as indicated by the high
R2 score. Consequently, we propose that GANs can be employed as cost effective
models for black hole image generation and reliably augment training datasets
for other parameterization algorithms.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01018" title="Abstract">arXiv:2312.01018</a> (cross-list from q-fin.TR) [<a href="/pdf/2312.01018" title="Download PDF">pdf</a>, <a href="/format/2312.01018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Finance: Protocols, Risks, and Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Capponi%2C+A">Agostino Capponi</a>, 
<a href="/search/q-fin?searchtype=author&query=Iyengar%2C+G">Garud Iyengar</a>, 
<a href="/search/q-fin?searchtype=author&query=Sethuraman%2C+J">Jay Sethuraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Financial markets are undergoing an unprecedented transformation.
Technological advances have brought major improvements to the operations of
financial services. While these advances promote improved accessibility and
convenience, traditional finance shortcomings like lack of transparency and
moral hazard frictions continue to plague centralized platforms, imposing
societal costs. In this paper, we argue how these shortcomings and frictions
are being mitigated by the decentralized finance (DeFi) ecosystem. We delve
into the workings of smart contracts, the backbone of DeFi transactions, with
an emphasis on those underpinning token exchange and lending services. We
highlight the pros and cons of the novel form of decentralized governance
introduced via the ownership of governance tokens. Despite its potential, the
current DeFi infrastructure introduces operational risks to users, which we
segment into five primary categories: consensus mechanisms, protocol, oracle,
frontrunning, and systemic risks. We conclude by emphasizing the need for
future research to focus on the scalability of existing blockchains, the
improved design and interoperability of DeFi protocols, and the rigorous
auditing of smart contracts.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01028" title="Abstract">arXiv:2312.01028</a> (cross-list from math.CO) [<a href="/pdf/2312.01028" title="Download PDF">pdf</a>, <a href="/ps/2312.01028" title="Download PostScript">ps</a>, <a href="/format/2312.01028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A structure theorem for pseudo-segments and its applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fox%2C+J">Jacob Fox</a>, 
<a href="/search/math?searchtype=author&query=Pach%2C+J">Janos Pach</a>, 
<a href="/search/math?searchtype=author&query=Suk%2C+A">Andrew Suk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We prove a far-reaching strengthening of Szemer\'edi's regularity lemma for
intersection graphs of pseudo-segments. It shows that the vertex set of such a
graph can be partitioned into a bounded number of parts of roughly the same
size such that almost all bipartite graphs between different pairs of parts are
complete or empty. We use this to get an improved bound on disjoint edges in
simple topological graphs, showing that every $n$-vertex simple topological
graph with no $k$ pairwise disjoint edges has at most $n(\log n)^{O(\log k)}$
edges.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01036" title="Abstract">arXiv:2312.01036</a> (cross-list from quant-ph) [<a href="/pdf/2312.01036" title="Download PDF">pdf</a>, <a href="/format/2312.01036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Clifford Initial States for Ising Hamiltonians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bhattacharyya%2C+B">Bikrant Bhattacharyya</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ravi%2C+G+S">Gokul Subramanian Ravi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing at The 8th Annual IEEE International Conference on Rebooting Computing (ICRC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Evaluating quantum circuits is currently very noisy. Therefore, developing
classical bootstraps that help minimize the number of times quantum circuits
have to be executed on noisy quantum devices is a powerful technique for
improving the practicality of Variational Quantum Algorithms. CAFQA is a
previously proposed classical bootstrap for VQAs that uses an initial ansatz
that reduces to Clifford operators. CAFQA has been shown to produce fairly
accurate initialization for VQA applied to molecular chemistry Hamiltonians.
Motivated by this result, in this paper we seek to analyze the Clifford states
that optimize the cost function for a new type of Hamiltonian, namely
Transverse Field Ising Hamiltonians. Our primary result connects the problem of
finding the optimal CAFQA initialization to a submodular minimization problem
which in turn can be solved in polynomial time.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01043" title="Abstract">arXiv:2312.01043</a> (cross-list from eess.IV) [<a href="/pdf/2312.01043" title="Download PDF">pdf</a>, <a href="/format/2312.01043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Hippocampal Shape Asymmetry in Alzheimer&#x27;s Disease Using  Optimal Shape Correspondences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+S">Shen Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zawar%2C+I">Ifrah Zawar</a>, 
<a href="/search/eess?searchtype=author&query=Kapur%2C+J">Jaideep Kapur</a>, 
<a href="/search/eess?searchtype=author&query=Fletcher%2C+P+T">P. Thomas Fletcher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hippocampal atrophy in Alzheimer's disease (AD) is asymmetric and spatially
inhomogeneous. While extensive work has been done on volume and shape analysis
of atrophy of the hippocampus in AD, less attention has been given to
hippocampal asymmetry specifically. Previous studies of hippocampal asymmetry
are limited to global volume or shape measures, which don't localize shape
asymmetry at the point level. In this paper, we propose to quantify localized
shape asymmetry by optimizing point correspondences between left and right
hippocampi within a subject, while simultaneously favoring a compact
statistical shape model of the entire sample. To account for related variables
that have impact on AD and healthy subject differences, we build linear models
with other confounding factors. Our results on the OASIS3 dataset demonstrate
that compared to using volumetric information, shape asymmetry reveals
fine-grained, localized differences that indicate the hippocampal regions of
most significant shape asymmetry in AD patients.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01046" title="Abstract">arXiv:2312.01046</a> (cross-list from stat.ML) [<a href="/pdf/2312.01046" title="Download PDF">pdf</a>, <a href="/format/2312.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bagged Regularized $k$-Distances for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cai%2C+Y">Yuchao Cai</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+Y">Yuheng Ma</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+H">Hanfang Yang</a>, 
<a href="/search/stat?searchtype=author&query=Hang%2C+H">Hanyuan Hang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider the paradigm of unsupervised anomaly detection, which involves
the identification of anomalies within a dataset in the absence of labeled
examples. Though distance-based methods are top-performing for unsupervised
anomaly detection, they suffer heavily from the sensitivity to the choice of
the number of the nearest neighbors. In this paper, we propose a new
distance-based algorithm called bagged regularized $k$-distances for anomaly
detection (BRDAD) converting the unsupervised anomaly detection problem into a
convex optimization problem. Our BRDAD algorithm selects the weights by
minimizing the surrogate risk, i.e., the finite sample bound of the empirical
risk of the bagged weighted $k$-distances for density estimation (BWDDE). This
approach enables us to successfully address the sensitivity challenge of the
hyperparameter choice in distance-based algorithms. Moreover, when dealing with
large-scale datasets, the efficiency issues can be addressed by the
incorporated bagging technique in our BRDAD algorithm. On the theoretical side,
we establish fast convergence rates of the AUC regret of our algorithm and
demonstrate that the bagging technique significantly reduces the computational
complexity. On the practical side, we conduct numerical experiments on anomaly
detection benchmarks to illustrate the insensitivity of parameter selection of
our algorithm compared with other state-of-the-art distance-based methods.
Moreover, promising improvements are brought by applying the bagging technique
in our algorithm on real-world datasets.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01047" title="Abstract">arXiv:2312.01047</a> (cross-list from math.OC) [<a href="/pdf/2312.01047" title="Download PDF">pdf</a>, <a href="/format/2312.01047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Random Reshuffling Method for Nonsmooth Nonconvex Finite-sum  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/math?searchtype=author&query=Milzarek%2C+A">Andre Milzarek</a>, 
<a href="/search/math?searchtype=author&query=Qiu%2C+J">Junwen Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we propose and study a novel stochastic optimization algorithm,
termed the normal map-based proximal random reshuffling (norm-PRR) method, for
nonsmooth nonconvex finite-sum problems. Random reshuffling techniques are
prevalent and widely utilized in large-scale applications, e.g., in the
training of neural networks. While the convergence behavior and advantageous
acceleration effects of random reshuffling methods are fairly well understood
in the smooth setting, much less seems to be known in the nonsmooth case and
only few proximal-type random reshuffling approaches with provable guarantees
exist.
<br />We establish the iteration complexity ${\cal O}(n^{-1/3}T^{-2/3})$ for
norm-PRR, where $n$ is the number of component functions and $T$ counts the
total number of iteration. We also provide novel asymptotic convergence results
for norm-PRR. Specifically, under the Kurdyka-{\L}ojasiewicz (KL) inequality,
we establish strong limit-point convergence, i.e., the iterates generated by
norm-PRR converge to a single stationary point. Moreover, we derive last
iterate convergence rates of the form ${\cal O}(k^{-p})$; here, $p \in [0, 1]$
depends on the KL exponent $\theta \in [0,1)$ and step size dynamics. Finally,
we present preliminary numerical results on machine learning problems that
demonstrate the efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01061" title="Abstract">arXiv:2312.01061</a> (cross-list from eess.IV) [<a href="/pdf/2312.01061" title="Download PDF">pdf</a>, <a href="/format/2312.01061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral-wise Implicit Neural Representation for Hyperspectral Image  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Huan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+W">Wangcai Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S">Shiyun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+P">Peifu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jianan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology, to be published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to
recover the 3D spatial-spectral signal from 2D measurement. Existing methods
for reconstructing Hyperspectral Image (HSI) typically involve learning
mappings from a 2D compressed image to a predetermined set of discrete spectral
bands. However, this approach overlooks the inherent continuity of the spectral
information. In this study, we propose an innovative method called
Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward
addressing this limitation. SINR introduces a continuous spectral amplification
process for HSI reconstruction, enabling spectral super-resolution with
customizable magnification factors. To achieve this, we leverage the concept of
implicit neural representation. Specifically, our approach introduces a
spectral-wise attention mechanism that treats individual channels as distinct
tokens, thereby capturing global spectral dependencies. Additionally, our
approach incorporates two components, namely a Fourier coordinate encoder and a
spectral scale factor module. The Fourier coordinate encoder enhances the
SINR's ability to emphasize high-frequency components, while the spectral scale
factor module guides the SINR to adapt to the variable number of spectral
channels. Notably, the SINR framework enhances the flexibility of CASSI
reconstruction by accommodating an unlimited number of spectral bands in the
desired output. Extensive experiments demonstrate that our SINR outperforms
baseline methods. By enabling continuous reconstruction within the CASSI
framework, we take the initial stride toward integrating implicit neural
representation into the field.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01128" title="Abstract">arXiv:2312.01128</a> (cross-list from eess.IV) [<a href="/pdf/2312.01128" title="Download PDF">pdf</a>, <a href="/format/2312.01128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEEDNet: Salient Pyramidal Enhancement Encoder-Decoder Network for  Colonoscopy Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sahu%2C+T">Tushir Sahu</a>, 
<a href="/search/eess?searchtype=author&query=Bhatt%2C+V">Vidhi Bhatt</a>, 
<a href="/search/eess?searchtype=author&query=R%2C+S+C+T">Sai Chandra Teja R</a>, 
<a href="/search/eess?searchtype=author&query=Mittal%2C+S">Sparsh Mittal</a>, 
<a href="/search/eess?searchtype=author&query=S%2C+N+K">Nagesh Kumar S</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate identification and precise delineation of regions of significance,
such as tumors or lesions, is a pivotal goal in medical imaging analysis. This
paper proposes SPEEDNet, a novel architecture for precisely segmenting lesions
within colonoscopy images. SPEEDNet uses a novel block named
Dilated-Involutional Pyramidal Convolution Fusion (DIPC). A DIPC block combines
the dilated involution layers pairwise into a pyramidal structure to convert
the feature maps into a compact space. This lowers the total number of
parameters while improving the learning of representations across an optimal
receptive field, thereby reducing the blurring effect. On the EBHISeg dataset,
SPEEDNet outperforms three previous networks: UNet, FeedNet, and AttesResDUNet.
Specifically, SPEEDNet attains an average dice score of 0.952 and a recall of
0.971. Qualitative results and ablation studies provide additional insights
into the effectiveness of SPEEDNet. The model size of SPEEDNet is 9.81 MB,
significantly smaller than that of UNet (22.84 MB), FeedNet(185.58 MB), and
AttesResDUNet (140.09 MB).
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01133" title="Abstract">arXiv:2312.01133</a> (cross-list from stat.ML) [<a href="/pdf/2312.01133" title="Download PDF">pdf</a>, <a href="/format/2312.01133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student&#x27;s  t and Power Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+J">Juno Kim</a>, 
<a href="/search/stat?searchtype=author&query=Kwon%2C+J">Jaehyuk Kwon</a>, 
<a href="/search/stat?searchtype=author&query=Cho%2C+M">Mincheol Cho</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+H">Hyunjong Lee</a>, 
<a href="/search/stat?searchtype=author&query=Won%2C+J">Joong-Ho Won</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The variational autoencoder (VAE) typically employs a standard normal prior
as a regularizer for the probabilistic latent encoder. However, the Gaussian
tail often decays too quickly to effectively accommodate the encoded points,
failing to preserve crucial structures hidden in the data. In this paper, we
explore the use of heavy-tailed models to combat over-regularization. Drawing
upon insights from information geometry, we propose $t^3$VAE, a modified VAE
framework that incorporates Student's t-distributions for the prior, encoder,
and decoder. This results in a joint model distribution of a power form which
we argue can better fit real-world datasets. We derive a new objective by
reformulating the evidence lower bound as joint optimization of KL divergence
between two statistical manifolds and replacing with $\gamma$-power divergence,
a natural alternative for power families. $t^3$VAE demonstrates superior
generation of low-density regions when trained on heavy-tailed synthetic data.
Furthermore, we show that $t^3$VAE significantly outperforms other models on
CelebA and imbalanced CIFAR-100 datasets.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01152" title="Abstract">arXiv:2312.01152</a> (cross-list from eess.IV) [<a href="/pdf/2312.01152" title="Download PDF">pdf</a>, <a href="/format/2312.01152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Resolution Cascaded Diffusion Model for Gigapixel Image Synthesis  in Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cechnicka%2C+S">Sarah Cechnicka</a>, 
<a href="/search/eess?searchtype=author&query=Reynaud%2C+H">Hadrien Reynaud</a>, 
<a href="/search/eess?searchtype=author&query=Ball%2C+J">James Ball</a>, 
<a href="/search/eess?searchtype=author&query=Simmonds%2C+N">Naomi Simmonds</a>, 
<a href="/search/eess?searchtype=author&query=Horsfield%2C+C">Catherine Horsfield</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+A">Andrew Smith</a>, 
<a href="/search/eess?searchtype=author&query=Roufosse%2C+C">Candice Roufosse</a>, 
<a href="/search/eess?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MedNeurIPS 2023 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diagnoses from histopathology images rely on information from both high and
low resolutions of Whole Slide Images. Ultra-Resolution Cascaded Diffusion
Models (URCDMs) allow for the synthesis of high-resolution images that are
realistic at all magnification levels, focusing not only on fidelity but also
on long-distance spatial coherency. Our model beats existing methods, improving
the pFID-50k [2] score by 110.63 to 39.52 pFID-50k. Additionally, a human
expert evaluation study was performed, reaching a weighted Mean Absolute Error
(MAE) of 0.11 for the Lower Resolution Diffusion Models and a weighted MAE of
0.22 for the URCDM.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01210" title="Abstract">arXiv:2312.01210</a> (cross-list from stat.ME) [<a href="/pdf/2312.01210" title="Download PDF">pdf</a>, <a href="/format/2312.01210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When accurate prediction models yield harmful self-fulfilling prophecies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=van+Amsterdam%2C+W+A+C">Wouter A.C. van Amsterdam</a>, 
<a href="/search/stat?searchtype=author&query=van+Geloven%2C+N">Nan van Geloven</a>, 
<a href="/search/stat?searchtype=author&query=Krijthe%2C+J">Jesse Krijthe</a>, 
<a href="/search/stat?searchtype=author&query=Ranganth%2C+R">Rajesh Ranganth</a>, 
<a href="/search/stat?searchtype=author&query=Cin%C3%A1%2C+G">Giovanni Cin&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML4H 2023 Findings Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Prediction models are popular in medical research and practice. By predicting
an outcome of interest for specific patients, these models may help inform
difficult treatment decisions, and are often hailed as the poster children for
personalized, data-driven healthcare.
<br />We show however, that using prediction models for decision making can lead to
harmful decisions, even when the predictions exhibit good discrimination after
deployment. These models are harmful self-fulfilling prophecies: their
deployment harms a group of patients but the worse outcome of these patients
does not invalidate the predictive power of the model. Our main result is a
formal characterization of a set of such prediction models. Next we show that
models that are well calibrated before} and after deployment are useless for
decision making as they made no change in the data distribution. These results
point to the need to revise standard practices for validation, deployment and
evaluation of prediction models that are used in medical decisions.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01212" title="Abstract">arXiv:2312.01212</a> (cross-list from eess.IV) [<a href="/pdf/2312.01212" title="Download PDF">pdf</a>, <a href="/ps/2312.01212" title="Download PostScript">ps</a>, <a href="/format/2312.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis Towards Melanoma Classification Using Transfer  Learning by Analyzing Dermoscopic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Uddin%2C+M+F">Md. Fahim Uddin</a>, 
<a href="/search/eess?searchtype=author&query=Tafshir%2C+N">Nafisa Tafshir</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+M+M">Mohammad Monirujjaman Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Melanoma is a sort of skin cancer that starts in the cells known as
melanocytes. It is more dangerous than other types of skin cancer because it
can spread to other organs. Melanoma can be fatal if it spreads to other parts
of the body. Early detection is the key to cure, but it requires the skills of
skilled doctors to diagnose it. This paper presents a system that combines deep
learning techniques with established transfer learning methods to enable skin
lesions classification and diagnosis of melanoma skin lesions. Using
Convolutional Neural Networks, it presents a method for categorizing melanoma
images into benign and malignant images in this research (CNNs). Researchers
used 'Deep Learning' techniques to train an expansive number of photos &amp;
essentially to get the expected result deep neural networks to need to be
trained with a huge number of parameters as dermoscopic images are sensitive &amp;
very hard to classify. This paper, has been emphasized building models with
less complexity and comparatively better accuracy with limited datasets &amp;
partially fewer deep networks so that the system can predict Melanoma at ease
from input dermoscopic images as correctly as possible within devices with less
computational power. The dataset has been obtained from ISIC Archive. Multiple
pre-trained models ResNet101, DenseNet, EfficientNet, InceptionV3 have been
implemented using transfer learning techniques to complete the comparative
analysis &amp; every model achieved good accuracy. Before training the models, the
data has been augmented by multiple parameters to improve the accuracy.
Moreover, the results are better than the previous state-of-the-art approaches
&amp; adequate to predict melanoma. Among these architectures, DenseNet performed
better than the others which gives a validation accuracy of 96.64%, validation
loss of 9.43% &amp; test set accuracy of 99.63%.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01228" title="Abstract">arXiv:2312.01228</a> (cross-list from math.OC) [<a href="/pdf/2312.01228" title="Download PDF">pdf</a>, <a href="/format/2312.01228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Integer Optimisation of Graph Neural Networks for Computer-Aided  Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=McDonald%2C+T">Tom McDonald</a>, 
<a href="/search/math?searchtype=author&query=Tsay%2C+C">Calvin Tsay</a>, 
<a href="/search/math?searchtype=author&query=Schweidtmann%2C+A+M">Artur M. Schweidtmann</a>, 
<a href="/search/math?searchtype=author&query=Yorke-Smith%2C+N">Neil Yorke-Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">ReLU neural networks have been modelled as constraints in mixed integer
linear programming (MILP), enabling surrogate-based optimisation in various
domains and efficient solution of machine learning certification problems.
However, previous works are mostly limited to MLPs. Graph neural networks
(GNNs) can learn from non-euclidean data structures such as molecular
structures efficiently and are thus highly relevant to computer-aided molecular
design (CAMD). We propose a bilinear formulation for ReLU Graph Convolutional
Neural Networks and a MILP formulation for ReLU GraphSAGE models. These
formulations enable solving optimisation problems with trained GNNs embedded to
global optimality. We apply our optimization approach to an illustrative CAMD
case study where the formulations of the trained GNNs are used to design
molecules with optimal boiling points.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01239" title="Abstract">arXiv:2312.01239</a> (cross-list from eess.IV) [<a href="/pdf/2312.01239" title="Download PDF">pdf</a>, <a href="/format/2312.01239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-aware Needle Segmentation in Ultrasound Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goel%2C+R">Raghavv Goel</a>, 
<a href="/search/eess?searchtype=author&query=Morales%2C+C">Cecilia Morales</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+M">Manpreet Singh</a>, 
<a href="/search/eess?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>, 
<a href="/search/eess?searchtype=author&query=Galeotti%2C+J">John Galeotti</a>, 
<a href="/search/eess?searchtype=author&query=Choset%2C+H">Howie Choset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Segmenting a moving needle in ultrasound images is challenging due to the
presence of artifacts, noise, and needle occlusion. This task becomes even more
demanding in scenarios where data availability is limited. Convolutional Neural
Networks (CNNs) have been successful in many computer vision applications, but
struggle to accurately segment needles without considering their motion. In
this paper, we present a novel approach for needle segmentation that combines
classical Kalman Filter (KF) techniques with data-driven learning,
incorporating both needle features and needle motion. Our method offers two key
contributions. First, we propose a compatible framework that seamlessly
integrates into commonly used encoder-decoder style architectures. Second, we
demonstrate superior performance compared to recent state-of-the-art needle
segmentation models using our novel convolutional neural network (CNN) based
KF-inspired block, achieving a 15\% reduction in pixel-wise needle tip error
and an 8\% reduction in length error. Third, to our knowledge we are the first
to implement a learnable filter to incorporate non-linear needle motion for
improving needle segmentation.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01252" title="Abstract">arXiv:2312.01252</a> (cross-list from math.CO) [<a href="/pdf/2312.01252" title="Download PDF">pdf</a>, <a href="/ps/2312.01252" title="Download PostScript">ps</a>, <a href="/format/2312.01252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Steiner Trees of the Regular Simplex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fleischmann%2C+H">Henry Fleischmann</a>, 
<a href="/search/math?searchtype=author&query=Q.%2C+G+A+G">Guillermo A. Gamboa Q.</a>, 
<a href="/search/math?searchtype=author&query=S.%2C+K+C">Karthik C. S.</a>, 
<a href="/search/math?searchtype=author&query=Mat%C4%9Bjka%2C+J">Josef Mat&#x11b;jka</a>, 
<a href="/search/math?searchtype=author&query=Petr%2C+J">Jakub Petr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Computational Geometry (cs.CG); Metric Geometry (math.MG)

</div>
<p class="mathjax">In the Euclidean Steiner Tree problem, we are given as input a set of points
(called terminals) in the $\ell_2$-metric space and the goal is to find the
minimum-cost tree connecting them. Additional points (called Steiner points)
from the space can be introduced as nodes in the solution.
<br />The seminal works of Arora [JACM'98] and Mitchell [SICOMP'99] provide a
Polynomial Time Approximation Scheme (PTAS) for solving the Euclidean Steiner
Tree problem in fixed dimensions. However, the problem remains poorly
understood in higher dimensions (such as when the dimension is logarithmic in
the number of terminals) and ruling out a PTAS for the problem in high
dimensions is a notoriously long standing open problem (for example, see
Trevisan [SICOMP'00]). Moreover, the explicit construction of optimal Steiner
trees remains unknown for almost all well-studied high-dimensional point
configurations. Furthermore, a vast majority the state-of-the-art structural
results on (high-dimensional) Euclidean Steiner trees were established in the
1960s, with no noteworthy update in over half a century.
<br />In this paper, we revisit high-dimensional Euclidean Steiner trees, proving
new structural results. We also establish a link between the computational
hardness of the Euclidean Steiner Tree problem and understanding the optimal
Steiner trees of regular simplices (and simplicial complexes), proposing
several conjectures and showing that some of them suffice to resolve the status
of the inapproximability of the Euclidean Steiner Tree problem. Motivated by
this connection, we investigate optimal Steiner trees of regular simplices,
proving new structural properties of their optimal Steiner trees, revisiting an
old conjecture of Smith [Algorithmica'92] about their optimal topology, and
providing the first explicit, general construction of candidate optimal Steiner
trees for that topology.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01272" title="Abstract">arXiv:2312.01272</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.01272" title="Download PDF">pdf</a>, <a href="/format/2312.01272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Topology in Interactomic Network: From Transcriptome to  Antiaddiction Drug Repurposing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Du%2C+H">Hongyan Du</a>, 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+G">Guo-Wei Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Hou%2C+T">Tingjun Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Genomics (q-bio.GN)

</div>
<p class="mathjax">The escalating drug addiction crisis in the United States underscores the
urgent need for innovative therapeutic strategies. This study embarked on an
innovative and rigorous strategy to unearth potential drug repurposing
candidates for opioid and cocaine addiction treatment, bridging the gap between
transcriptomic data analysis and drug discovery. We initiated our approach by
conducting differential gene expression analysis on addiction-related
transcriptomic data to identify key genes. We propose a novel topological
differentiation to identify key genes from a protein-protein interaction (PPI)
network derived from DEGs. This method utilizes persistent Laplacians to
accurately single out pivotal nodes within the network, conducting this
analysis in a multiscale manner to ensure high reliability. Through rigorous
literature validation, pathway analysis, and data-availability scrutiny, we
identified three pivotal molecular targets, mTOR, mGluR5, and NMDAR, for drug
repurposing from DrugBank. We crafted machine learning models employing two
natural language processing (NLP)-based embeddings and a traditional 2D
fingerprint, which demonstrated robust predictive ability in gauging binding
affinities of DrugBank compounds to selected targets. Furthermore, we
elucidated the interactions of promising drugs with the targets and evaluated
their drug-likeness. This study delineates a multi-faceted and comprehensive
analytical framework, amalgamating bioinformatics, topological data analysis
and machine learning, for drug repurposing in addiction treatment, setting the
stage for subsequent experimental validation. The versatility of the methods we
developed allows for applications across a range of diseases and transcriptomic
datasets.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01275" title="Abstract">arXiv:2312.01275</a> (cross-list from q-bio.MN) [<a href="/pdf/2312.01275" title="Download PDF">pdf</a>, <a href="/format/2312.01275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Link Prediction Applications in Network Biology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Musawi%2C+A+F+A">Ahmad F. Al Musawi</a>, 
<a href="/search/q-bio?searchtype=author&query=Roy%2C+S">Satyaki Roy</a>, 
<a href="/search/q-bio?searchtype=author&query=Ghosh%2C+P">Preetam Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In the domain of network biology, the interactions among heterogeneous
genomic and molecular entities are represented through networks. Link
prediction (LP) methodologies are instrumental in inferring missing or
prospective associations within these biological networks. In this review, we
systematically dissect the attributes of local, centrality, and embedding-based
LP approaches, applied to static and dynamic biological networks. We undertake
an examination of the current applications of LP metrics for predicting links
between diseases, genes, proteins, RNA, microbiomes, drugs, and neurons. We
carry out comprehensive performance evaluations on established biological
network datasets to show the practical applications of standard LP models.
Moreover, we compare the similarity in prediction trends among the models and
the specific network attributes that contribute to effective link prediction,
before underscoring the role of LP in addressing the formidable challenges
prevalent in biological systems, ranging from noise, bias, and data sparseness
to interpretability. We conclude the review with an exploration of the
essential characteristics expected from future LP models, poised to advance our
comprehension of the intricate interactions governing biological systems.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01296" title="Abstract">arXiv:2312.01296</a> (cross-list from math.OC) [<a href="/pdf/2312.01296" title="Download PDF">pdf</a>, <a href="/ps/2312.01296" title="Download PostScript">ps</a>, <a href="/format/2312.01296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection Under Uncertainty Using Distributionally Robust  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Noormohammadia%2C+A+H">Amir Hossein Noormohammadia</a>, 
<a href="/search/math?searchtype=author&query=MirHassania%2C+S+A">Seyed Ali MirHassania</a>, 
<a href="/search/math?searchtype=author&query=Khaligh%2C+F+H">Farnaz Hooshmand Khaligh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Anomaly detection is defined as the problem of finding data points that do
not follow the patterns of the majority. Among the various proposed methods for
solving this problem, classification-based methods, including one-class Support
Vector Machines (SVM) are considered effective and state-of-the-art. The
one-class SVM method aims to find a decision boundary to distinguish between
normal data points and anomalies using only the normal data. On the other hand,
most real-world problems involve some degree of uncertainty, where the true
probability distribution of each data point is unknown, and estimating it is
often difficult and costly. Assuming partial distribution information such as
the first and second-order moments is known, a distributionally robust
chance-constrained model is proposed in which the probability of
misclassification is low. By utilizing a mapping function to a higher
dimensional space, the proposed model will be capable of classifying
origin-inseparable datasets. Also, by adopting the kernel idea, the need for
explicitly knowing the mapping is eliminated, computations can be performed in
the input space, and computational complexity is reduced. Computational results
validate the robustness of the proposed model under different probability
distributions and also the superiority of the proposed model compared to the
standard one-class SVM in terms of various evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01313" title="Abstract">arXiv:2312.01313</a> (cross-list from math.OC) [<a href="/pdf/2312.01313" title="Download PDF">pdf</a>, <a href="/format/2312.01313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observer-based Periodic Event-triggered and Self-triggered Boundary  Control of a Class of Parabolic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rathnayake%2C+B">Bhathiya Rathnayake</a>, 
<a href="/search/math?searchtype=author&query=Diagne%2C+M">Mamadou Diagne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces the first observer-based periodic event-triggered
control (PETC) and self-triggered control (STC) for boundary control of a class
of parabolic PDEs using PDE backstepping control. We introduce techniques to
convert a certain class of continuous-time event-triggered control into PETC
and STC, eliminating the need for continuous monitoring of the event-triggering
function. For the PETC, the event-triggering function requires only periodic
evaluations to detect events, while the STC proactively computes the time of
the next event right at the current event time using the system model and the
continuously available measurements. For both strategies, the control input is
updated exclusively at events and is maintained using a zero-order hold between
events. We demonstrate that the closed-loop system is Zeno-free. We offer
criteria for selecting an appropriate sampling period for the PETC and for
determining the time until the next event under the STC. We prove the system's
global exponential convergence to zero in the spatial $L^2$ norm for both
anti-collocated and collocated sensing and actuation under the PETC. For the
STC, local exponential convergence to zero in the spatial $L^2$ norm for
collocated sensing and actuation is proven. Simulations are provided to
illustrate the theoretical claims.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01338" title="Abstract">arXiv:2312.01338</a> (cross-list from eess.IV) [<a href="/pdf/2312.01338" title="Download PDF">pdf</a>, <a href="/format/2312.01338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain  Adaptation for Medical Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Ziqin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+Z">Zhongxi Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zinan Li</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yan Hu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, in IEEE Transactions on Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical imaging provides many valuable clues involving anatomical structure
and pathological characteristics. However, image degradation is a common issue
in clinical practice, which can adversely impact the observation and diagnosis
by physicians and algorithms. Although extensive enhancement models have been
developed, these models require a well pre-training before deployment, while
failing to take advantage of the potential value of inference data after
deployment. In this paper, we raise an algorithm for source-free unsupervised
domain adaptive medical image enhancement (SAME), which adapts and optimizes
enhancement models using test data in the inference phase. A
structure-preserving enhancement network is first constructed to learn a robust
source model from synthesized training data. Then a teacher-student model is
initialized with the source model and conducts source-free unsupervised domain
adaptation (SFUDA) by knowledge distillation with the test data. Additionally,
a pseudo-label picker is developed to boost the knowledge distillation of
enhancement tasks. Experiments were implemented on ten datasets from three
medical image modalities to validate the advantage of the proposed algorithm,
and setting analysis and ablation studies were also carried out to interpret
the effectiveness of SAME. The remarkable enhancement performance and benefits
for downstream tasks demonstrate the potential and generalizability of SAME.
The code is available at
https://github.com/liamheng/Annotation-free-Medical-Image-Enhancement.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01351" title="Abstract">arXiv:2312.01351</a> (cross-list from eess.IV) [<a href="/pdf/2312.01351" title="Download PDF">pdf</a>, <a href="/ps/2312.01351" title="Download PostScript">ps</a>, <a href="/format/2312.01351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning and traditional-based CAD schemes for the pulmonary  embolism diagnosis: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hosseini%2C+S+H">Seyed Hesamoddin Hosseini</a>, 
<a href="/search/eess?searchtype=author&query=Taherinia%2C+A+H">Amir Hossein Taherinia</a>, 
<a href="/search/eess?searchtype=author&query=Saadatmand%2C+M">Mahdi Saadatmand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Nowadays, pulmonary Computed Tomography Angiography (CTA) is the main tool
for detecting Pulmonary Embolism (PE). However, manual interpretation of CTA
volume requires a radiologist, which is time-consuming and error-prone due to
the specific conditions of lung tissue, large volume of data, lack of
experience, and eye fatigue. Therefore, Computer-Aided Design (CAD) systems are
used as a second opinion for the diagnosis of PE. The purpose of this article
is to review, evaluate, and compare the performance of deep learning and
traditional-based CAD system for diagnosis PE and to help physicians and
researchers in this field. In this study, all articles available in databases
such as IEEE, ScienceDirect, Wiley, Springer, Nature, and Wolters Kluwer in the
field of PE diagnosis were examined using traditional and deep learning
methods. From 2002 to 2023, 23 papers were studied to extract the articles with
the considered limitations. Each paper presents an automatic PE detection
system that we evaluate using criteria such as sensitivity, False Positives
(FP), and the number of datasets. This research work includes recent studies,
state-of-the-art research works, and a more comprehensive overview compared to
previously published review articles in this research area.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01379" title="Abstract">arXiv:2312.01379</a> (cross-list from stat.ME) [<a href="/pdf/2312.01379" title="Download PDF">pdf</a>, <a href="/format/2312.01379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation between PLS and OLS regression in terms of the eigenvalue  distribution of the regressor covariance matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=del+Val%2C+D">David del Val</a> (1), 
<a href="/search/stat?searchtype=author&query=Berrendero%2C+J+R">Jos&#xe9; R. Berrendero</a> (1 and 2), 
<a href="/search/stat?searchtype=author&query=Su%C3%A1rez%2C+A">Alberto Su&#xe1;rez</a> (1) ((1) Universidad Aut&#xf3;noma de Madrid UAM, (2) Instituto de Ciencias Matem&#xe1;ticas ICMAT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Partial least squares (PLS) is a dimensionality reduction technique
introduced in the field of chemometrics and successfully employed in many other
areas. The PLS components are obtained by maximizing the covariance between
linear combinations of the regressors and of the target variables. In this
work, we focus on its application to scalar regression problems. PLS regression
consists in finding the least squares predictor that is a linear combination of
a subset of the PLS components. Alternatively, PLS regression can be formulated
as a least squares problem restricted to a Krylov subspace. This equivalent
formulation is employed to analyze the distance between
${\hat{\boldsymbol\beta}\;}_{\mathrm{PLS}}^{\scriptscriptstyle {(L)}}$, the PLS
estimator of the vector of coefficients of the linear regression model based on
$L$ PLS components, and $\hat{\boldsymbol \beta}_{\mathrm{OLS}}$, the one
obtained by ordinary least squares (OLS), as a function of $L$. Specifically,
${\hat{\boldsymbol\beta}\;}_{\mathrm{PLS}}^{\scriptscriptstyle {(L)}}$ is the
vector of coefficients in the aforementioned Krylov subspace that is closest to
$\hat{\boldsymbol \beta}_{\mathrm{OLS}}$ in terms of the Mahalanobis distance
with respect to the covariance matrix of the OLS estimate. We provide a bound
on this distance that depends only on the distribution of the eigenvalues of
the regressor covariance matrix. Numerical examples on synthetic and real-world
data are used to illustrate how the distance between
${\hat{\boldsymbol\beta}\;}_{\mathrm{PLS}}^{\scriptscriptstyle {(L)}}$ and
$\hat{\boldsymbol \beta}_{\mathrm{OLS}}$ depends on the number of clusters in
which the eigenvalues of the regressor covariance matrix are grouped.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01448" title="Abstract">arXiv:2312.01448</a> (cross-list from quant-ph) [<a href="/pdf/2312.01448" title="Download PDF">pdf</a>, <a href="/ps/2312.01448" title="Download PostScript">ps</a>, <a href="/format/2312.01448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Driven transparent quantum graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yusupov%2C+J+R">J.R. Yusupov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ehrhardt%2C+M">M. Ehrhardt</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matyokubov%2C+K+S">Kh.Sh. Matyokubov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matrasulov%2C+D+U">D.U. Matrasulov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we discuss the concept of quantum graphs with transparent
vertices by considering the case where the graph interacts with an external
time-independent field. In particular, we address the problem of transparent
boundary conditions for quantum graphs, building on previous work on
transparent boundary conditions for the stationary Schrodinger equation on a
line. Physically relevant constraints making the vertex transparent under
boundary conditions in the form of (weight) continuity and Kirchhoff rules are
derived using two methods, the scattering approach and transparent boundary
conditions for the time-independent Schrodinger equation. The latter is derived
by extending the transparent boundary condition concept to the time-independent
Schrodinger equation on driven quantum graphs. We also discuss how the
eigenvalues and eigenfunctions of a quantum graph are influenced not only by
its topology, but also by the shape(type) of a potential when an external field
is involved.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01457" title="Abstract">arXiv:2312.01457</a> (cross-list from stat.ML) [<a href="/pdf/2312.01457" title="Download PDF">pdf</a>, <a href="/format/2312.01457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Taufiq%2C+M+F">Muhammad Faaiz Taufiq</a>, 
<a href="/search/stat?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/stat?searchtype=author&query=Cornish%2C+R">Rob Cornish</a>, 
<a href="/search/stat?searchtype=author&query=Ton%2C+J">Jean-Francois Ton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Off-Policy Evaluation (OPE) in contextual bandits is crucial for assessing
new policies using existing data without costly experimentation. However,
current OPE methods, such as Inverse Probability Weighting (IPW) and Doubly
Robust (DR) estimators, suffer from high variance, particularly in cases of low
overlap between target and behavior policies or large action and context
spaces. In this paper, we introduce a new OPE estimator for contextual bandits,
the Marginal Ratio (MR) estimator, which focuses on the shift in the marginal
distribution of outcomes $Y$ instead of the policies themselves. Through
rigorous theoretical analysis, we demonstrate the benefits of the MR estimator
compared to conventional methods like IPW and DR in terms of variance
reduction. Additionally, we establish a connection between the MR estimator and
the state-of-the-art Marginalized Inverse Propensity Score (MIPS) estimator,
proving that MR achieves lower variance among a generalized family of MIPS
estimators. We further illustrate the utility of the MR estimator in causal
inference settings, where it exhibits enhanced performance in estimating
Average Treatment Effects (ATE). Our experiments on synthetic and real-world
datasets corroborate our theoretical findings and highlight the practical
advantages of the MR estimator in OPE for contextual bandits.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01460" title="Abstract">arXiv:2312.01460</a> (cross-list from eess.IV) [<a href="/pdf/2312.01460" title="Download PDF">pdf</a>, <a href="/format/2312.01460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an accurate and generalizable multiple sclerosis lesion  segmentation model using self-ensembled lesion fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jinwei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+L">Lianrui Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Dewey%2C+B+E">Blake E. Dewey</a>, 
<a href="/search/eess?searchtype=author&query=Remedios%2C+S+W">Samuel W. Remedios</a>, 
<a href="/search/eess?searchtype=author&query=Pham%2C+D+L">Dzung L. Pham</a>, 
<a href="/search/eess?searchtype=author&query=Carass%2C+A">Aaron Carass</a>, 
<a href="/search/eess?searchtype=author&query=Prince%2C+J+L">Jerry L. Prince</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Automatic multiple sclerosis (MS) lesion segmentation using multi-contrast
magnetic resonance (MR) images provides improved efficiency and reproducibility
compared to manual delineation. Current state-of-the-art automatic MS lesion
segmentation methods utilize modified U-Net-like architectures. However, in the
literature, dedicated architecture modifications were always required to
maximize their performance. In addition, the best-performing methods have not
proven to be generalizable to diverse test datasets with contrast variations
and image artifacts. In this work, we developed an accurate and generalizable
MS lesion segmentation model using the well-known U-Net architecture without
further modification. A novel test-time self-ensembled lesion fusion strategy
is proposed that not only achieved the best performance using the ISBI 2015 MS
segmentation challenge data but also demonstrated robustness across various
self-ensemble parameter choices. Moreover, equipped with instance normalization
rather than batch normalization widely used in literature, the model trained on
the ISBI challenge data generalized well on clinical test datasets from
different scanners.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01464" title="Abstract">arXiv:2312.01464</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.01464" title="Download PDF">pdf</a>, <a href="/format/2312.01464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Posterior Sampling for Nonlinear CT Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+S">Shudong Li</a>, 
<a href="/search/physics?searchtype=author&query=Tivnan%2C+M">Matthew Tivnan</a>, 
<a href="/search/physics?searchtype=author&query=Shen%2C+Y">Yuan Shen</a>, 
<a href="/search/physics?searchtype=author&query=Stayman%2C+J+W">J. Webster Stayman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, submitted to SPIE Journal of Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Diffusion models have been demonstrated as powerful deep learning tools for
image generation in CT reconstruction and restoration. Recently, diffusion
posterior sampling, where a score-based diffusion prior is combined with a
likelihood model, has been used to produce high quality CT images given
low-quality measurements. This technique is attractive since it permits a
one-time, unsupervised training of a CT prior; which can then be incorporated
with an arbitrary data model. However, current methods only rely on a linear
model of x-ray CT physics to reconstruct or restore images. While it is common
to linearize the transmission tomography reconstruction problem, this is an
approximation to the true and inherently nonlinear forward model. We propose a
new method that solves the inverse problem of nonlinear CT image reconstruction
via diffusion posterior sampling. We implement a traditional unconditional
diffusion model by training a prior score function estimator, and apply Bayes
rule to combine this prior with a measurement likelihood score function derived
from the nonlinear physical model to arrive at a posterior score function that
can be used to sample the reverse-time diffusion process. This plug-and-play
method allows incorporation of a diffusion-based prior with generalized
nonlinear CT image reconstruction into multiple CT system designs with
different forward models, without the need for any additional training. We
develop the algorithm that performs this reconstruction, including an
ordered-subsets variant for accelerated processing and demonstrate the
technique in both fully sampled low dose data and sparse-view geometries using
a single unsupervised training of the prior.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01477" title="Abstract">arXiv:2312.01477</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.01477" title="Download PDF">pdf</a>, <a href="/format/2312.01477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heisenberg machines with programmable spin-circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Bunaiyan%2C+S">Saleh Bunaiyan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Datta%2C+S">Supriyo Datta</a>, 
<a href="/search/cond-mat?searchtype=author&query=Camsari%2C+K+Y">Kerem Y. Camsari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We show that we can harness two recent experimental developments to build a
compact hardware emulator for the classical Heisenberg model in statistical
physics. The first is the demonstration of spin-diffusion lengths in excess of
microns in graphene even at room temperature. The second is the demonstration
of low barrier magnets (LBMs) whose magnetization can fluctuate rapidly even at
sub-nanosecond rates. Using experimentally benchmarked circuit models, we show
that an array of LBMs driven by an external current source has a steady-state
distribution corresponding to a classical system with an energy function of the
form $E = -1/2\sum_{i,j} J_{ij} (\hat{m}_i \cdot \hat{m}_j$). This may seem
surprising for a non-equilibrium system but we show that it can be justified by
a Lyapunov function corresponding to a system of coupled
Landau-Lifshitz-Gilbert (LLG) equations. The Lyapunov function we construct
describes LBMs interacting through the spin currents they inject into the spin
neutral substrate. We suggest ways to tune the coupling coefficients $J_{ij}$
so that it can be used as a hardware solver for optimization problems involving
continuous variables represented by vector magnetizations, similar to the role
of the Ising model in solving optimization problems with binary variables.
Finally, we implement a Heisenberg AND gate based on a network of three coupled
stochastic LLG equations, illustrating the concept of probabilistic computing
with a programmable Heisenberg model.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01527" title="Abstract">arXiv:2312.01527</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.01527" title="Download PDF">pdf</a>, <a href="/ps/2312.01527" title="Download PostScript">ps</a>, <a href="/format/2312.01527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NovoMol: Recurrent Neural Network for Orally Bioavailable Drug Design  and Validation on PDGFR&#x3b1; Receptor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rao%2C+I">Ishir Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures, 4 tables, Submitted to Frontiers in Drug Discovery
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Longer timelines and lower success rates of drug candidates limit the
productivity of clinical trials in the pharmaceutical industry. Promising de
novo drug design techniques help solve this by exploring a broader chemical
space, efficiently generating new molecules, and providing improved therapies.
However, optimizing for molecular characteristics found in approved oral drugs
remains a challenge, limiting de novo usage. In this work, we propose NovoMol,
a novel de novo method using recurrent neural networks to mass-generate drug
molecules with high oral bioavailability, increasing clinical trial time
efficiency. Molecules were optimized for desirable traits and ranked using the
quantitative estimate of drug-likeness (QED). Generated molecules meeting QED's
oral bioavailability threshold were used to retrain the neural network, and,
after five training cycles, 76% of generated molecules passed this strict
threshold and 96% passed the traditionally used Lipinski's Rule of Five. The
trained model was then used to generate specific drug candidates for the
cancer-related PDGFR{\alpha} receptor and 44% of generated candidates had
better binding affinity than the current state-of-the-art drug, Imatinib (with
a receptor binding affinity of -9.4 kcal/mol), and the best-generated candidate
at -12.9 kcal/mol. NovoMol provides a time/cost-efficient AI-based de novo
method offering promising drug candidates for clinical trials.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01530" title="Abstract">arXiv:2312.01530</a> (cross-list from stat.ML) [<a href="/pdf/2312.01530" title="Download PDF">pdf</a>, <a href="/format/2312.01530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Active Feature Acquisition Methods for Time-varying  Feature Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=von+Kleist%2C+H">Henrik von Kleist</a>, 
<a href="/search/stat?searchtype=author&query=Zamanian%2C+A">Alireza Zamanian</a>, 
<a href="/search/stat?searchtype=author&query=Shpitser%2C+I">Ilya Shpitser</a>, 
<a href="/search/stat?searchtype=author&query=Ahmidi%2C+N">Narges Ahmidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 3 tables, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning methods often assume input features are available at no
cost. However, in domains like healthcare, where acquiring features could be
expensive or harmful, it is necessary to balance a feature's acquisition cost
against its predictive value. The task of training an AI agent to decide which
features to acquire is called active feature acquisition (AFA). By deploying an
AFA agent, we effectively alter the acquisition strategy and trigger a
distribution shift. To safely deploy AFA agents under this distribution shift,
we present the problem of active feature acquisition performance evaluation
(AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating
that acquisitions don't affect the underlying feature values; and ii) a no
unobserved confounding (NUC) assumption, stating that retrospective feature
acquisition decisions were only based on observed features. We show that one
can apply offline reinforcement learning under the NUC assumption and missing
data methods under the NDE assumption. When NUC and NDE hold, we propose a
novel semi-offline reinforcement learning framework, which requires a weaker
positivity assumption and yields more data-efficient estimators. We introduce
three novel estimators: a direct method (DM), an inverse probability weighting
(IPW), and a double reinforcement learning (DRL) estimator.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01570" title="Abstract">arXiv:2312.01570</a> (cross-list from quant-ph) [<a href="/pdf/2312.01570" title="Download PDF">pdf</a>, <a href="/format/2312.01570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelizing quantum simulation with decision diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+S">Shaowen Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kimura%2C+Y">Yusuke Kimura</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sato%2C+H">Hiroyuki Sato</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yu%2C+J">Junwei Yu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fujita%2C+M">Masahiro Fujita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recent technological advancements show promise in leveraging quantum
mechanical phenomena for computation. This brings substantial speed-ups to
problems that are once considered to be intractable in the classical world.
However, the physical realization of quantum computers is still far away from
us, and a majority of research work is done using quantum simulators running on
classical computers. Classical computers face a critical obstacle in simulating
quantum algorithms. Quantum states reside in a Hilbert space whose size grows
exponentially to the number of subsystems, i.e., qubits. As a result, the
straightforward statevector approach does not scale due to the exponential
growth of the memory requirement. Decision diagrams have gained attention in
recent years for representing quantum states and operations in quantum
simulations. The main advantage of this approach is its ability to exploit
redundancy. However, mainstream quantum simulators still rely on statevectors
or tensor networks. We consider the absence of decision diagrams due to the
lack of parallelization strategies. This work explores several strategies for
parallelizing decision diagram operations, specifically for quantum
simulations. We propose optimal parallelization strategies. Based on the
experiment results, our parallelization strategy achieves a 2-3 times faster
simulation of Grover's algorithm and random circuits than the state-of-the-art
single-thread DD-based simulator DDSIM.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01573" title="Abstract">arXiv:2312.01573</a> (cross-list from eess.IV) [<a href="/pdf/2312.01573" title="Download PDF">pdf</a>, <a href="/ps/2312.01573" title="Download PostScript">ps</a>, <a href="/format/2312.01573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on deep learning in multimodal medical imaging for cancer  detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhaocheng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Yujun Ma</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruili Wang</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zhihong Gao</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+G">Guohua Cheng</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Linyang He</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+X">Xuran Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The task of multimodal cancer detection is to determine the locations and
categories of lesions by using different imaging techniques, which is one of
the key research methods for cancer diagnosis. Recently, deep learning-based
object detection has made significant developments due to its strength in
semantic feature extraction and nonlinear function fitting. However, multimodal
cancer detection remains challenging due to morphological differences in
lesions, interpatient variability, difficulty in annotation, and imaging
artifacts. In this survey, we mainly investigate over 150 papers in recent
years with respect to multimodal cancer detection using deep learning, with a
focus on datasets and solutions to various challenges such as data annotation,
variance between classes, small-scale lesions, and occlusion. We also provide
an overview of the advantages and drawbacks of each approach. Finally, we
discuss the current scope of work and provide directions for the future
development of multimodal cancer detection.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01586" title="Abstract">arXiv:2312.01586</a> (cross-list from math.OC) [<a href="/pdf/2312.01586" title="Download PDF">pdf</a>, <a href="/ps/2312.01586" title="Download PostScript">ps</a>, <a href="/format/2312.01586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Maximization of Long-Run Reward CVaR for Markov Decision  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xia%2C+L">Li Xia</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+Z">Zhihui Yu</a>, 
<a href="/search/math?searchtype=author&query=Glynn%2C+P+W">Peter W. Glynn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Risk-seeking optimization of CVaR in MDP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the optimization of Markov decision processes (MDPs) from
a risk-seeking perspective, where the risk is measured by conditional
value-at-risk (CVaR). The objective is to find a policy that maximizes the
long-run CVaR of instantaneous rewards over an infinite horizon across all
history-dependent randomized policies. By establishing two optimality
inequalities of opposing directions, we prove that the maximum of long-run CVaR
of MDPs over the set of history-dependent randomized policies can be found
within the class of stationary randomized policies. In contrast to classical
MDPs, we find that there may not exist an optimal stationary deterministic
policy for maximizing CVaR. Instead, we prove the existence of an optimal
stationary randomized policy that requires randomizing over at most two
actions. Via a convex optimization representation of CVaR, we convert the
long-run CVaR maximization MDP into a minimax problem, where we prove the
interchangeability of minimum and maximum and the related existence of saddle
point solutions. Furthermore, we propose an algorithm that finds the saddle
point solution by solving two linear programs. These results are then extended
to objectives that involve maximizing some combination of mean and CVaR of
rewards simultaneously. Finally, we conduct numerical experiments to
demonstrate the main results.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01638" title="Abstract">arXiv:2312.01638</a> (cross-list from eess.IV) [<a href="/pdf/2312.01638" title="Download PDF">pdf</a>, <a href="/format/2312.01638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> J-Net: Improved U-Net for Terahertz Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeo%2C+W">Woon-Ha Yeo</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+S">Seung-Hwan Jung</a>, 
<a href="/search/eess?searchtype=author&query=Oh%2C+S+J">Seung Jae Oh</a>, 
<a href="/search/eess?searchtype=author&query=Maeng%2C+I">Inhee Maeng</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+E+S">Eui Su Lee</a>, 
<a href="/search/eess?searchtype=author&query=Ryu%2C+H">Han-Cheol Ryu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Terahertz (THz) waves are electromagnetic waves in the 0.1 to 10 THz
frequency range, and THz imaging is utilized in a range of applications,
including security inspections, biomedical fields, and the non-destructive
examination of materials. However, THz images have low resolution due to the
long wavelength of THz waves. Therefore, improving the resolution of THz images
is one of the current hot research topics. We propose a novel network
architecture called J-Net which is improved version of U-Net to solve the THz
image super-resolution. It employs the simple baseline blocks which can extract
low resolution (LR) image features and learn the mapping of LR images to
highresolution (HR) images efficiently. All training was conducted using the
DIV2K+Flickr2K dataset, and we employed the peak signal-to-noise ratio (PSNR)
for quantitative comparison. In our comparisons with other THz image
super-resolution methods, JNet achieved a PSNR of 32.52 dB, surpassing other
techniques by more than 1 dB. J-Net also demonstrates superior performance on
real THz images compared to other methods. Experiments show that the proposed
J-Net achieves better PSNR and visual improvement compared with other THz image
super-resolution methods.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01641" title="Abstract">arXiv:2312.01641</a> (cross-list from math.OC) [<a href="/pdf/2312.01641" title="Download PDF">pdf</a>, <a href="/format/2312.01641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fluid-particle decomposition approach to matching market design for  crowdsourced delivery systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Akamatsu%2C+T">Takashi Akamatsu</a>, 
<a href="/search/math?searchtype=author&query=Oyama%2C+Y">Yuki Oyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This paper considers a crowdsourced delivery (CSD) system that effectively
utilizes the existing trips to fulfill parcel delivery as a matching problem
between CSD drivers and delivery tasks. This matching problem has two major
challenges. First, it is a large-scale combinatorial optimization problem that
is hard to solve in a reasonable computational time. Second, the evaluation of
the objective function for socially optimal matching contains the utility of
drivers for performing the tasks, which is generally unobservable private
information. To address these challenges, this paper proposes a hierarchical
distribution mechanism of CSD tasks that decomposes the matching problem into
the task partition (master problem) and individual task-driver matching within
smaller groups of drivers (sub-problems). We incorporate an auction mechanism
with truth-telling and efficiency into the sub-problems so that the drivers'
perceived utilities are revealed through their bids. Furthermore, we formulate
the master problem as a fluid model based on continuously approximated decision
variables. By exploiting the random utility framework, we analytically
represent the objective function of the problem using continuous variables,
without explicitly knowing the drivers' utilities. The numerical experiment
shows that the proposed approach solved large-scale matching problems at least
100 times faster than a naive LP solver and approximated the original objective
value with errors of less than 1%.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01644" title="Abstract">arXiv:2312.01644</a> (cross-list from eess.IV) [<a href="/pdf/2312.01644" title="Download PDF">pdf</a>, <a href="/ps/2312.01644" title="Download PostScript">ps</a>, <a href="/format/2312.01644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMSR: Tiny Multi-path CNNs for Super Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chia-Hung Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hsieh%2C+T">Tzu-Hsin Hsieh</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kuan-Yu Huang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+P">Pei-Yin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, published in the IEEE Eurasia Conference on IoT, Communication and Engineering proceedings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we proposed a tiny multi-path CNN-based Super-Resolution (SR)
method, called TMSR. We mainly refer to some tiny CNN-based SR methods, under
5k parameters. The main contribution of the proposed method is the improved
multi-path learning and self-defined activated function. The experimental
results show that TMSR obtains competitive image quality (i.e. PSNR and SSIM)
compared to the related works under 5k parameters.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01655" title="Abstract">arXiv:2312.01655</a> (cross-list from quant-ph) [<a href="/pdf/2312.01655" title="Download PDF">pdf</a>, <a href="/format/2312.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Polar Metric Learning: Efficient Classically Learned Quantum  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sharma%2C+V">Vinayak Sharma</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shrivastava%2C+A">Aviral Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep metric learning has recently shown extremely promising results in the
classical data domain, creating well-separated feature spaces. This idea was
also adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL
consists of a 2 step process with a classical model to compress the data to fit
into the limited number of qubits, then train a Parameterized Quantum
Circuit(PQC) to create better separation in Hilbert Space. However, on Noisy
Intermediate Scale Quantum (NISQ) devices. QMeL solutions result in high
circuit width and depth, both of which limit scalability. We propose Quantum
Polar Metric Learning (QPMeL) that uses a classical model to learn the
parameters of the polar form of a qubit. We then utilize a shallow PQC with
$R_y$ and $R_z$ gates to create the state and a trainable layer of
$ZZ(\theta)$-gates to learn entanglement. The circuit also computes fidelity
via a SWAP Test for our proposed Fidelity Triplet Loss function, used to train
both classical and quantum components. When compared to QMeL approaches, QPMeL
achieves 3X better multi-class separation, while using only 1/2 the number of
gates and depth. We also demonstrate that QPMeL outperforms classical networks
with similar configurations, presenting a promising avenue for future research
on fully classical models with quantum loss functions.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01662" title="Abstract">arXiv:2312.01662</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.01662" title="Download PDF">pdf</a>, <a href="/ps/2312.01662" title="Download PostScript">ps</a>, <a href="/format/2312.01662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Deoxidation of Semiconductor Substrates Assisted by  Machine-Learning and Real-Time-Feedback-Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+C">Chao Shen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhan%2C+W">Wenkang Zhan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wu%2C+Z">Zhaofeng Wu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhao%2C+C">Chao Zhao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Z">Zhanguo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Thin film deposition is an essential step in the semiconductor process.
During preparation or loading, the substrate is exposed to the air unavoidably,
which has motivated studies of the process control to remove the surface oxide
before thin film deposition. Optimizing the deoxidation process in molecular
beam epitaxy (MBE) for a random substrate is a multidimensional challenge and
sometimes controversial. Due to variations in semiconductor materials and
growth processes, the determination of substrate deoxidation temperature is
highly dependent on the grower's expertise; the same substrate may yield
inconsistent results when evaluated by different growers. Here, we employ a
machine learning (ML) hybrid convolution and vision transformer (CNN-ViT)
model. This model utilizes reflection high-energy electron diffraction (RHEED)
video as input to determine the deoxidation status of the substrate as output,
enabling automated substrate deoxidation under a controlled architecture. This
also extends to the successful application of deoxidation processes on other
substrates. Furthermore, we showcase the potential of models trained on data
from a single MBE equipment to achieve high-accuracy deployment on other
equipment. In contrast to traditional methods, our approach holds exceptional
practical value. It standardizes deoxidation temperatures across various
equipment and substrate materials, advancing the standardization research
process in semiconductor preparation, a significant milestone in thin film
growth technology. The concepts and methods demonstrated in this work are
anticipated to revolutionize semiconductor manufacturing in optoelectronics and
microelectronics industries by applying them to diverse material growth
processes.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01679" title="Abstract">arXiv:2312.01679</a> (cross-list from eess.IV) [<a href="/pdf/2312.01679" title="Download PDF">pdf</a>, <a href="/format/2312.01679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Medical Image with Hierarchical Feature Hiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+Q">Qingsong Yao</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Z">Zecheng He</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuexiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+K">Kai Ma</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at \url{<a href="https://github.com/qsyao/Hierarchical_Feature_Constraint">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning based methods for medical images can be easily compromised by
adversarial examples (AEs), posing a great security flaw in clinical
decision-making. It has been discovered that conventional adversarial attacks
like PGD which optimize the classification logits, are easy to distinguish in
the feature space, resulting in accurate reactive defenses. To better
understand this phenomenon and reassess the reliability of the reactive
defenses for medical AEs, we thoroughly investigate the characteristic of
conventional medical AEs. Specifically, we first theoretically prove that
conventional adversarial attacks change the outputs by continuously optimizing
vulnerable features in a fixed direction, thereby leading to outlier
representations in the feature space. Then, a stress test is conducted to
reveal the vulnerability of medical images, by comparing with natural images.
Interestingly, this vulnerability is a double-edged sword, which can be
exploited to hide AEs. We then propose a simple-yet-effective hierarchical
feature constraint (HFC), a novel add-on to conventional white-box attacks,
which assists to hide the adversarial feature in the target feature
distribution. The proposed method is evaluated on three medical datasets, both
2D and 3D, with different modalities. The experimental results demonstrate the
superiority of HFC, \emph{i.e.,} it bypasses an array of state-of-the-art
adversarial medical AE detectors more efficiently than competing adaptive
attacks, which reveals the deficiencies of medical reactive defense and allows
to develop more robust defenses in future.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01689" title="Abstract">arXiv:2312.01689</a> (cross-list from eess.IV) [<a href="/pdf/2312.01689" title="Download PDF">pdf</a>, <a href="/format/2312.01689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and accurate sparse-view CBCT reconstruction using meta-learned  neural attenuation field and hash-encoding regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shin%2C+H">Heejun Shin</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+T">Taehee Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jongho Lee</a>, 
<a href="/search/eess?searchtype=author&query=Chun%2C+S">Seyoung Chun</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+S">Seungryung Cho</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+D">Dongmyung Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Cone beam computed tomography (CBCT) is an emerging medical imaging technique
to visualize the internal anatomical structures of patients. During a CBCT
scan, several projection images of different angles or views are collectively
utilized to reconstruct a tomographic image. However, reducing the number of
projections in a CBCT scan while preserving the quality of a reconstructed
image is challenging due to the nature of an ill-posed inverse problem.
Recently, a neural attenuation field (NAF) method was proposed by adopting a
neural radiance field algorithm as a new way for CBCT reconstruction,
demonstrating fast and promising results using only 50 views. However,
decreasing the number of projections is still preferable to reduce potential
radiation exposure, and a faster reconstruction time is required considering a
typical scan time. In this work, we propose a fast and accurate sparse-view
CBCT reconstruction (FACT) method to provide better reconstruction quality and
faster optimization speed in the minimal number of view acquisitions ($&lt;$ 50
views). In the FACT method, we meta-trained a neural network and a hash-encoder
using a few scans (= 15), and a new regularization technique is utilized to
reconstruct the details of an anatomical structure. In conclusion, we have
shown that the FACT method produced better, and faster reconstruction results
over the other conventional algorithms based on CBCT scans of different body
parts (chest, head, and abdomen) and CT vendors (Siemens, Phillips, and GE).
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01691" title="Abstract">arXiv:2312.01691</a> (cross-list from astro-ph.SR) [<a href="/pdf/2312.01691" title="Download PDF">pdf</a>, <a href="/format/2312.01691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Coronal Mass Ejection Mass and Kinetic Energy by Fusion of  Multiple Deep-learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Alobaid%2C+K+A">Khalid A. Alobaid</a>, 
<a href="/search/astro-ph?searchtype=author&query=Abduallah%2C+Y">Yasser Abduallah</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+J+T+L">Jason T. L. Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+H">Haimin Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fan%2C+S">Shen Fan</a>, 
<a href="/search/astro-ph?searchtype=author&query=Li%2C+J">Jialiang Li</a>, 
<a href="/search/astro-ph?searchtype=author&query=Cavus%2C+H">Huseyin Cavus</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yurchyshyn%2C+V">Vasyl Yurchyshyn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Astrophysical Journal Letters, 958:L34, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Machine Learning (cs.LG); Space Physics (physics.space-ph)

</div>
<p class="mathjax">Coronal mass ejections (CMEs) are massive solar eruptions, which have a
significant impact on Earth. In this paper, we propose a new method, called
DeepCME, to estimate two properties of CMEs, namely, CME mass and kinetic
energy. Being able to estimate these properties helps better understand CME
dynamics. Our study is based on the CME catalog maintained at the Coordinated
Data Analysis Workshops (CDAW) Data Center, which contains all CMEs manually
identified since 1996 using the Large Angle and Spectrometric Coronagraph
(LASCO) on board the Solar and Heliospheric Observatory (SOHO). We use LASCO C2
data in the period between January 1996 and December 2020 to train, validate
and test DeepCME through 10-fold cross validation. The DeepCME method is a
fusion of three deep learning models, including ResNet, InceptionNet, and
InceptionResNet. Our fusion model extracts features from LASCO C2 images,
effectively combining the learning capabilities of the three component models
to jointly estimate the mass and kinetic energy of CMEs. Experimental results
show that the fusion model yields a mean relative error (MRE) of 0.013 (0.009,
respectively) compared to the MRE of 0.019 (0.017, respectively) of the best
component model InceptionResNet (InceptionNet, respectively) in estimating the
CME mass (kinetic energy, respectively). To our knowledge, this is the first
time that deep learning has been used for CME mass and kinetic energy
estimations.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01709" title="Abstract">arXiv:2312.01709</a> (cross-list from math.OC) [<a href="/pdf/2312.01709" title="Download PDF">pdf</a>, <a href="/ps/2312.01709" title="Download PostScript">ps</a>, <a href="/format/2312.01709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Challenging Curve Fitting Benchmark Test Set for Global  Optimization Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicong Cheng</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicheng Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Benchmark sets are extremely important for evaluating and developing global
optimization algorithms and related solvers. A new test set named PCC benchmark
is proposed especially for optimization problem of nonlinear curve fitting for
the first time, with the aspiration of investigating and comparing the
performance of different global optimization solvers. Compared with the
well-known classical nonlinear curve fitting benchmark set given by the
National Institute of Standards and Technology (NIST) of USA, the most
important features of the PCC benchmark are small problem dimensions, free
search domain and high level of difficulty for obtaining global optimization
solutions, which makes the PCC benchmark be not only suitable for validating
the effectiveness of various global optimization algorithms, but also more
ideal for verifying and comparing various solvers with global optimization
solving capabilities. Based on PCC and NIST benchmark, seven of the world's
leading global optimization solvers, including Baron, Antigone, Couenne, Lingo,
Scip, Matlab GA and 1stOpt, are thoroughly tested and compared in terms of both
effectiveness and efficiency. The results showed that the NIST benchmark is
relatively simple and not suitable for global optimization testing, while the
PCC benchmark is a unique, challengeable and effective test dataset for testing
and verifying global optimization algorithms and related solvers. 1stOpt solver
gives the overall best performance in both NIST and PCC benchmark.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01726" title="Abstract">arXiv:2312.01726</a> (cross-list from eess.IV) [<a href="/pdf/2312.01726" title="Download PDF">pdf</a>, <a href="/format/2312.01726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D  Networks for 3D Coherent Layer Segmentation of Retinal OCT Images with Full  and Sparse Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+D">Dong Wei</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+D">Donghuan Lu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+X">Xiaoying Tang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Liansheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MIA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Layer segmentation is important to quantitative analysis of retinal optical
coherence tomography (OCT). Recently, deep learning based methods have been
developed to automate this task and yield remarkable performance. However, due
to the large spatial gap and potential mismatch between the B-scans of an OCT
volume, all of them were based on 2D segmentation of individual B-scans, which
may lose the continuity and diagnostic information of the retinal layers in 3D
space. Besides, most of these methods required dense annotation of the OCT
volumes, which is labor-intensive and expertise-demanding. This work presents a
novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to
obtain continuous 3D retinal layer surfaces from OCT volumes, which works well
with both full and sparse annotations. The 2D features of individual B-scans
are extracted by an encoder consisting of 2D convolutions. These 2D features
are then used to produce the alignment displacement vectors and layer
segmentation by two 3D decoders coupled via a spatial transformer module. Two
losses are proposed to utilize the retinal layers' natural property of being
smooth for B-scan alignment and layer segmentation, respectively, and are the
key to the semi-supervised learning with sparse annotation. The entire
framework is trained end-to-end. To the best of our knowledge, this is the
first work that attempts 3D retinal layer segmentation in volumetric OCT images
based on CNNs. Experiments on a synthetic dataset and three public clinical
datasets show that our framework can effectively align the B-scans for
potential motion correction, and achieves superior performance to
state-of-the-art 2D deep learning methods in terms of both layer segmentation
accuracy and cross-B-scan 3D continuity in both fully and semi-supervised
settings, thus offering more clinical values than previous works.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01740" title="Abstract">arXiv:2312.01740</a> (cross-list from eess.IV) [<a href="/pdf/2312.01740" title="Download PDF">pdf</a>, <a href="/format/2312.01740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileUtr: Revisiting the relationship between light-weight CNN and  Transformer for efficient medical image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+F">Fenghe Tang</a>, 
<a href="/search/eess?searchtype=author&query=Nian%2C+B">Bingkun Nian</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+J">Jianrui Ding</a>, 
<a href="/search/eess?searchtype=author&query=Quan%2C+Q">Quan Quan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S.Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to the scarcity and specific imaging characteristics in medical images,
light-weighting Vision Transformers (ViTs) for efficient medical image
segmentation is a significant challenge, and current studies have not yet paid
attention to this issue. This work revisits the relationship between CNNs and
Transformers in lightweight universal networks for medical image segmentation,
aiming to integrate the advantages of both worlds at the infrastructure design
level. In order to leverage the inductive bias inherent in CNNs, we abstract a
Transformer-like lightweight CNNs block (ConvUtr) as the patch embeddings of
ViTs, feeding Transformer with denoised, non-redundant and highly condensed
semantic information. Moreover, an adaptive Local-Global-Local (LGL) block is
introduced to facilitate efficient local-to-global information flow exchange,
maximizing Transformer's global context information extraction capabilities.
Finally, we build an efficient medical image segmentation model (MobileUtr)
based on CNN and Transformer. Extensive experiments on five public medical
image datasets with three different modalities demonstrate the superiority of
MobileUtr over the state-of-the-art methods, while boasting lighter weights and
lower computational cost. Code is available at
https://github.com/FengheTan9/MobileUtr.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01761" title="Abstract">arXiv:2312.01761</a> (cross-list from physics.optics) [<a href="/pdf/2312.01761" title="Download PDF">pdf</a>, <a href="/format/2312.01761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Light Field Imaging in the Restrictive Object Space based on Flexible  Angular Plane
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhou%2C+P">Ping Zhou</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+Y">Yuda Xu</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+C">Chengcai Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In some applications, the object space of light field imaging system is
restrictive, such as industrial and medical endoscopes. If the traditional
light field imaging system is used in the restrictive object space (ROS)
directly but without any specific considerations, the ROS will lead to severe
microlens image distortions and then affects light field decoding, calibration
and 3D reconstruction. The light field imaging in restrictive object space
(ROS-LF) is complicated but significant. In this paper, we first deduce that
the reason of the microlens image deviation is the position variation of the
angular plane, then we propose the flexible angular plane for ROS-LF, while in
the traditional light field the angular plane always coincides with the main
lens plane. Subsequently, we propose the microlens image non-distortion
principle for ROS-LF and introduce the ROS-LF imaging principle. We demonstrate
that the difference is an aperture constant term between the ROS-LF and
traditional light field imaging models. At last, we design a ROS-LF simulated
system and calibrate it to verify principles proposed in this paper.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01777" title="Abstract">arXiv:2312.01777</a> (cross-list from eess.SP) [<a href="/pdf/2312.01777" title="Download PDF">pdf</a>, <a href="/ps/2312.01777" title="Download PostScript">ps</a>, <a href="/format/2312.01777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly 1-Bit Quantized Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Atzeni%2C+I">Italo Atzeni</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+D+H+N">Duy H. N. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Swindlehurst%2C+A+L">A. Lee Swindlehurst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the IEEE Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Enabling communications in the (sub-)THz band will call for massive
multiple-input multiple-output (MIMO) arrays at either the transmit- or
receive-side, or at both. To scale down the complexity and power consumption
when operating across massive frequency and antenna dimensions, a sacrifice in
the resolution of the digital-to-analog/analog-to-digital converters
(DACs/ADCs) will be inevitable. In this paper, we analyze the extreme scenario
where both the transmit- and receive-side are equipped with fully digital
massive MIMO arrays and 1-bit DACs/ADCs, which leads to a system with minimum
radio-frequency complexity, cost, and power consumption. Building upon the
Bussgang decomposition, we derive a tractable approximation of the mean squared
error (MSE) between the transmitted data symbols and their soft estimates.
Numerical results show that, despite its simplicity, a doubly 1-bit quantized
massive MIMO system with very large antenna arrays can deliver an impressive
performance in terms of MSE and symbol error rate.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01808" title="Abstract">arXiv:2312.01808</a> (cross-list from eess.AS) [<a href="/pdf/2312.01808" title="Download PDF">pdf</a>, <a href="/ps/2312.01808" title="Download PostScript">ps</a>, <a href="/format/2312.01808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Head Orientation Estimation with Distributed Microphones Using Speech  Radiation Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+K">Kaspar M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=%C3%87akmak%2C+B">Bilgesu &#xc7;akmak</a>, 
<a href="/search/eess?searchtype=author&query=Didier%2C+P">Paul Didier</a>, 
<a href="/search/eess?searchtype=author&query=Doclo%2C+S">Simon Doclo</a>, 
<a href="/search/eess?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a>, 
<a href="/search/eess?searchtype=author&query=Wolff%2C+T">Tobias Wolff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to 57th Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, CA, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Determining the head orientation of a talker is not only beneficial for
various speech signal processing applications, such as source localization or
speech enhancement, but also facilitates intuitive voice control and
interaction with smart environments or modern car assistants. Most approaches
for head orientation estimation are based on visual cues. However, this
requires camera systems which often are not available. We present an approach
which purely uses audio signals captured with only a few distributed
microphones around the talker. Specifically, we propose a novel method that
directly incorporates measured or modeled speech radiation patterns to infer
the talker's orientation during active speech periods based on a cosine
similarity measure. Moreover, an automatic gain adjustment technique is
proposed for uncalibrated, irregular microphone setups, such as ad-hoc sensor
networks. In experiments with signals recorded in both anechoic and reverberant
environments, the proposed method outperforms state-of-the-art approaches,
using either measured or modeled speech radiation patterns.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01817" title="Abstract">arXiv:2312.01817</a> (cross-list from cond-mat.soft) [<a href="/pdf/2312.01817" title="Download PDF">pdf</a>, <a href="/format/2312.01817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simulation method for the wetting dynamics of liquid droplets on  deformable membranes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Mokbel%2C+M">Marcel Mokbel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mokbel%2C+D">Dominic Mokbel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liese%2C+S">Susanne Liese</a>, 
<a href="/search/cond-mat?searchtype=author&query=Weber%2C+C+A">Christoph A. Weber</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aland%2C+S">Sebastian Aland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Computational Engineering, Finance, and Science (cs.CE); Biological Physics (physics.bio-ph); Computational Physics (physics.comp-ph); Subcellular Processes (q-bio.SC)

</div>
<p class="mathjax">Biological cells utilize membranes and liquid-like droplets, known as
biomolecular condensates, to structure their interior. The interaction of
droplets and membranes, despite being involved in several key biological
processes, is so far little-understood. Here, we present a first numerical
method to simulate the continuum dynamics of droplets interacting with
deformable membranes via wetting. The method combines the advantages of the
phase field method for multi-phase flow simulation and the arbitrary
Lagrangian-Eulerian (ALE) method for an explicit description of the elastic
surface. The model is thermodynamically consistent, coupling bulk hydrodynamics
with capillary forces, as well as bending, tension, and stretching of a thin
membrane. The method is validated by comparing simulations for single droplets
to theoretical results of shape equations, and its capabilities are illustrated
in 2D and 3D axisymmetric scenarios.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01831" title="Abstract">arXiv:2312.01831</a> (cross-list from eess.IV) [<a href="/pdf/2312.01831" title="Download PDF">pdf</a>, <a href="/format/2312.01831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant plug-and-play image reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Terris%2C+M">Matthieu Terris</a>, 
<a href="/search/eess?searchtype=author&query=Moreau%2C+T">Thomas Moreau</a>, 
<a href="/search/eess?searchtype=author&query=Pustelnik%2C+N">Nelly Pustelnik</a>, 
<a href="/search/eess?searchtype=author&query=Tachella%2C+J">Julian Tachella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Plug-and-play algorithms constitute a popular framework for solving inverse
imaging problems that rely on the implicit definition of an image prior via a
denoiser. These algorithms can leverage powerful pre-trained denoisers to solve
a wide range of imaging tasks, circumventing the necessity to train models on a
per-task basis. Unfortunately, plug-and-play methods often show unstable
behaviors, hampering their promise of versatility and leading to suboptimal
quality of reconstructed images. In this work, we show that enforcing
equivariance to certain groups of transformations (rotations, reflections,
and/or translations) on the denoiser strongly improves the stability of the
algorithm as well as its reconstruction quality. We provide a theoretical
analysis that illustrates the role of equivariance on better performance and
stability. We present a simple algorithm that enforces equivariance on any
existing denoiser by simply applying a random transformation to the input of
the denoiser and the inverse transformation to the output at each iteration of
the algorithm. Experiments on multiple imaging modalities and denoising
networks show that the equivariant plug-and-play algorithm improves both the
reconstruction performance and the stability compared to their non-equivariant
counterparts.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01898" title="Abstract">arXiv:2312.01898</a> (cross-list from math.OC) [<a href="/pdf/2312.01898" title="Download PDF">pdf</a>, <a href="/format/2312.01898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking optimal batch size schedules using continuous-time control and  perturbation theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Perko%2C+S">Stefan Perko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Stochastic Gradient Descent (SGD) and its variants are almost universally
used to train neural networks and to fit a variety of other parametric models.
An important hyperparameter in this context is the batch size, which determines
how many samples are processed before an update of the parameters occurs.
Previous studies have demonstrated the benefits of using variable batch sizes.
In this work, we will theoretically derive optimal batch size schedules for SGD
and similar algorithms, up to an error that is quadratic in the learning rate.
To achieve this, we approximate the discrete process of parameter updates using
a family of stochastic differential equations indexed by the learning rate. To
better handle the state-dependent diffusion coefficient, we further expand the
solution of this family into a series with respect to the learning rate. Using
this setup, we derive a continuous-time optimal batch size schedule for a large
family of diffusion coefficients and then apply the results in the setting of
linear regression.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01935" title="Abstract">arXiv:2312.01935</a> (cross-list from math.CO) [<a href="/pdf/2312.01935" title="Download PDF">pdf</a>, <a href="/format/2312.01935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on the 2-Colored Rectilinear Crossing Number of Random Point Sets  in the Unit Square
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cabello%2C+S">Sergio Cabello</a>, 
<a href="/search/math?searchtype=author&query=Czabarka%2C+%C3%89">&#xc9;va Czabarka</a>, 
<a href="/search/math?searchtype=author&query=Fabila-Monroy%2C+R">Ruy Fabila-Monroy</a>, 
<a href="/search/math?searchtype=author&query=Higashikawa%2C+Y">Yuya Higashikawa</a>, 
<a href="/search/math?searchtype=author&query=Seidel%2C+R">Raimund Seidel</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%A9kely%2C+L">L&#xe1;szl&#xf3; Sz&#xe9;kely</a>, 
<a href="/search/math?searchtype=author&query=Tkadlec%2C+J">Josef Tkadlec</a>, 
<a href="/search/math?searchtype=author&query=Wesolek%2C+A">Alexandra Wesolek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Let $S$ be a set of four points chosen independently, uniformly at random
from a square. Join every pair of points of $S$ with a straight line segment.
Color these edges red if they have positive slope and blue, otherwise. We show
that the probability that $S$ defines a pair of crossing edges of the same
color is equal to $1/4$. This is connected to a recent result of Aichholzer et
al. [GD 2019] who showed that by 2-colouring the edges of a geometric graph and
counting monochromatic crossings instead of crossings, the number of crossings
can be more than halfed. Our result shows that for the described random
drawings, there is a coloring of the edges such that the number of
monochromatic crossings is in expectation $\frac{1}{2}-\frac{7}{50}$ of the
total number of crossings.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01947" title="Abstract">arXiv:2312.01947</a> (cross-list from quant-ph) [<a href="/pdf/2312.01947" title="Download PDF">pdf</a>, <a href="/format/2312.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximising Quantum-Computing Expressive Power through Randomised  Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+Y">Yingli Yang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Z">Zongkang Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+A">Anbang Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+X">Xiaosi Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xiaoting Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Ying Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the noisy intermediate-scale quantum era, variational quantum algorithms
(VQAs) have emerged as a promising avenue to obtain quantum advantage. However,
the success of VQAs depends on the expressive power of parameterised quantum
circuits, which is constrained by the limited gate number and the presence of
barren plateaus. In this work, we propose and numerically demonstrate a novel
approach for VQAs, utilizing randomised quantum circuits to generate the
variational wavefunction. We parameterize the distribution function of these
random circuits using artificial neural networks and optimize it to find the
solution. This random-circuit approach presents a trade-off between the
expressive power of the variational wavefunction and time cost, in terms of the
sampling cost of quantum circuits. Given a fixed gate number, we can
systematically increase the expressive power by extending the quantum-computing
time. With a sufficiently large permissible time cost, the variational
wavefunction can approximate any quantum state with arbitrary accuracy.
Furthermore, we establish explicit relationships between expressive power, time
cost, and gate number for variational quantum eigensolvers. These results
highlight the promising potential of the random-circuit approach in achieving a
high expressive power in quantum computing.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01982" title="Abstract">arXiv:2312.01982</a> (cross-list from math.MG) [<a href="/pdf/2312.01982" title="Download PDF">pdf</a>, <a href="/format/2312.01982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and Approximations for Decorated Reeb Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Curry%2C+J">Justin Curry</a>, 
<a href="/search/math?searchtype=author&query=Mio%2C+W">Washington Mio</a>, 
<a href="/search/math?searchtype=author&query=Needham%2C+T">Tom Needham</a>, 
<a href="/search/math?searchtype=author&query=Okutan%2C+O+B">Osman Berat Okutan</a>, 
<a href="/search/math?searchtype=author&query=Russold%2C+F">Florian Russold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Computational Geometry (cs.CG); Algebraic Topology (math.AT)

</div>
<p class="mathjax">Given a map $f:X \to M$ from a topological space $X$ to a metric space $M$, a
decorated Reeb space consists of the Reeb space, together with an attribution
function whose values recover geometric information lost during the
construction of the Reeb space. For example, when $M=\mathbb{R}$ is the real
line, the Reeb space is the well-known Reeb graph, and the attributions may
consist of persistence diagrams summarizing the level set topology of $f$. In
this paper, we introduce decorated Reeb spaces in various flavors and prove
that our constructions are Gromov-Hausdorff stable. We also provide results on
approximating decorated Reeb spaces from finite samples and leverage these to
develop a computational framework for applying these constructions to point
cloud data.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01999" title="Abstract">arXiv:2312.01999</a> (cross-list from eess.IV) [<a href="/pdf/2312.01999" title="Download PDF">pdf</a>, <a href="/format/2312.01999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRTransGAN: Image Super-Resolution using Transformer based Generative  Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baghel%2C+N">Neeraj Baghel</a>, 
<a href="/search/eess?searchtype=author&query=Dubey%2C+S+R">Shiv Ram Dubey</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+S+K">Satish Kumar Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Image super-resolution aims to synthesize high-resolution image from a
low-resolution image. It is an active area to overcome the resolution
limitations in several applications like low-resolution object-recognition,
medical image enhancement, etc. The generative adversarial network (GAN) based
methods have been the state-of-the-art for image super-resolution by utilizing
the convolutional neural networks (CNNs) based generator and discriminator
networks. However, the CNNs are not able to exploit the global information very
effectively in contrast to the transformers, which are the recent breakthrough
in deep learning by exploiting the self-attention mechanism. Motivated from the
success of transformers in language and vision applications, we propose a
SRTransGAN for image super-resolution using transformer based GAN.
Specifically, we propose a novel transformer-based encoder-decoder network as a
generator to generate 2x images and 4x images. We design the discriminator
network using vision transformer which uses the image as sequence of patches
and hence useful for binary classification between synthesized and real
high-resolution images. The proposed SRTransGAN outperforms the existing
methods by 4.38 % on an average of PSNR and SSIM scores. We also analyze the
saliency map to understand the learning ability of the proposed method.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02017" title="Abstract">arXiv:2312.02017</a> (cross-list from eess.IV) [<a href="/pdf/2312.02017" title="Download PDF">pdf</a>, <a href="/format/2312.02017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-channel cycleGAN for CBCT to CT synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sargeant%2C+C+A+H">Chelsea A. H. Sargeant</a>, 
<a href="/search/eess?searchtype=author&query=Henderson%2C+E+G+A">Edward G. A. Henderson</a>, 
<a href="/search/eess?searchtype=author&query=McSweeney%2C+D+M">D&#xf3;nal M. McSweeney</a>, 
<a href="/search/eess?searchtype=author&query=Rankin%2C+A+G">Aaron G. Rankin</a>, 
<a href="/search/eess?searchtype=author&query=Page%2C+D">Denis Page</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RRRocket_Lollies submission for the Synthesizing computed tomography for radiotherapy (SynthRAD2023) Challenge at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Image synthesis is used to generate synthetic CTs (sCTs) from on-treatment
cone-beam CTs (CBCTs) with a view to improving image quality and enabling
accurate dose computation to facilitate a CBCT-based adaptive radiotherapy
workflow. As this area of research gains momentum, developments in sCT
generation methods are difficult to compare due to the lack of large public
datasets and sizeable variation in training procedures. To compare and assess
the latest advancements in sCT generation, the SynthRAD2023 challenge provides
a public dataset and evaluation framework for both MR and CBCT to sCT
synthesis. Our contribution focuses on the second task, CBCT-to-sCT synthesis.
By leveraging a multi-channel input to emphasize specific image features, our
approach effectively addresses some of the challenges inherent in CBCT imaging,
whilst restoring the contrast necessary for accurate visualisation of patients'
anatomy. Additionally, we introduce an auxiliary fusion network to further
enhance the fidelity of generated sCT images.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02025" title="Abstract">arXiv:2312.02025</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2312.02025" title="Download PDF">pdf</a>, <a href="/format/2312.02025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Synchronized Trichel Pulse Trains in Multi-Point Corona Discharge  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shaygani%2C+A">Afshin Shaygani</a>, 
<a href="/search/physics?searchtype=author&query=Adamiak%2C+K">Kazimierz Adamiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">Evidence of self-synchronization has been observed in multi-electrode corona
discharge systems, where the application of high negative DC voltages induces a
self-sustained mode of current pulse trains. These pulses, historically
referred to as Trichel pulses, characterize the operation of a two-electrode
system where the discharge electrode is subjected to a high negative DC
voltage. The numerical algorithm reveals that in a two electrode discharge
system, each of which is composed of a pair of electrodes operating in a pulsed
mode, synchronization occurs due to weak yet significant interactions. These
interactions arise from the mutual influence of electric fields and space
charges generated by each discharge pair. This influence extends beyond
individual systems, leading to a synchronization between both pairs, both in a
pulsed mode. A three-species model of discharge was employed to simulate this
process and it was based on the finite element method formulation. Two
different numerical models were investigated, a 2D model, consisting of two
discharge electrodes and a third grounded electrode, and two 1D-axisymmetric
models, consisting dual and triple pairs of discharge systems. Experiments show
a multi-stable nature of the coupled pulsed discharge systems, indicating that
under appropriate conditions the pulse trains exhibit two distinct modes of
synchronization: in-phase synchronization and anti-phase synchronization. The
occurrence of each mode depends on factors such as interaction strength,
applied voltage level, and various system parameters. Furthermore, variations
in these factors can lead to additional outcomes, including out of phase
synchronization, as well as scenarios involving near-harmonic oscillations and
quenching.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02027" title="Abstract">arXiv:2312.02027</a> (cross-list from math.OC) [<a href="/pdf/2312.02027" title="Download PDF">pdf</a>, <a href="/format/2312.02027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Optimal Control Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Domingo-Enrich%2C+C">Carles Domingo-Enrich</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+J">Jiequn Han</a>, 
<a href="/search/math?searchtype=author&query=Amos%2C+B">Brandon Amos</a>, 
<a href="/search/math?searchtype=author&query=Bruna%2C+J">Joan Bruna</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Stochastic optimal control, which has the goal of driving the behavior of
noisy systems, is broadly applicable in science, engineering and artificial
intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a
novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal
control that stems from the same philosophy as the conditional score matching
loss for diffusion models. That is, the control is learned via a least squares
problem by trying to fit a matching vector field. The training loss, which is
closely connected to the cross-entropy loss, is optimized with respect to both
the control function and a family of reparameterization matrices which appear
in the matching vector field. The optimization with respect to the
reparameterization matrices aims at minimizing the variance of the matching
vector field. Experimentally, our algorithm achieves lower error than all the
existing IDO techniques for stochastic optimal control for four different
control settings. The key idea underlying SOCM is the path-wise
reparameterization trick, a novel technique that is of independent interest,
e.g., for generative modeling.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02031" title="Abstract">arXiv:2312.02031</a> (cross-list from quant-ph) [<a href="/pdf/2312.02031" title="Download PDF">pdf</a>, <a href="/format/2312.02031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Quantum Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yu-Ao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhu%2C+C">Chengkai Zhu</a>, 
<a href="/search/quant-ph?searchtype=author&query=He%2C+K">Keming He</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jing%2C+M">Mingrui Jing</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Retrieval (cs.IR); Information Theory (cs.IT); High Energy Physics - Theory (hep-th)

</div>
<p class="mathjax">Quantum Markov chains generalize classical Markov chains for random variables
to the quantum realm and exhibit unique inherent properties, making them an
important feature in quantum information theory. In this work, we propose the
concept of virtual quantum Markov chains (VQMCs), focusing on scenarios where
subsystems retain classical information about global systems from measurement
statistics. As a generalization of quantum Markov chains, VQMCs characterize
states where arbitrary global shadow information can be recovered from
subsystems through local quantum operations and measurements. We present an
algebraic characterization for virtual quantum Markov chains and show that the
virtual quantum recovery is fully determined by the block matrices of a quantum
state on its subsystems. Notably, we find a distinction between two classes of
tripartite entanglement by showing that the W state is a VQMC while the GHZ
state is not. Furthermore, we establish semidefinite programs to determine the
optimal sampling overhead and the robustness of virtual quantum Markov chains.
We demonstrate the optimal sampling overhead is additive, indicating no free
lunch to further reduce the sampling cost of recovery from parallel calls of
the VQMC states. Our findings elucidate distinctions between quantum Markov
chains and virtual quantum Markov chains, extending our understanding of
quantum recovery to scenarios prioritizing classical information from
measurement statistics.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02063" title="Abstract">arXiv:2312.02063</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.02063" title="Download PDF">pdf</a>, <a href="/format/2312.02063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The GPU Phase Folding and Deep Learning Method for Detecting Exoplanet  Transits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+K">Kaitlyn Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ge%2C+J">Jian Ge</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zhao%2C+Y">Yinan Zhao</a>, 
<a href="/search/astro-ph?searchtype=author&query=Willis%2C+K">Kevin Willis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 17 figures; To be published in the Monthly Notices of the Royal Astronomical Society (MNRAS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents GPFC, a novel Graphics Processing Unit (GPU) Phase
Folding and Convolutional Neural Network (CNN) system to detect exoplanets
using the transit method. We devise a fast folding algorithm parallelized on a
GPU to amplify low signal-to-noise ratio transit signals, allowing a search at
high precision and speed. A CNN trained on two million synthetic light curves
reports a score indicating the likelihood of a planetary signal at each period.
GPFC improves on speed by three orders of magnitude over the predominant
Box-fitting Least Squares (BLS) method. Our simulation results show GPFC
achieves 97% training accuracy, higher true positive rate at the same false
positive rate of detection, and higher precision at the same recall rate when
compared to BLS. GPFC recovers 100% of known ultra-short-period planets in
Kepler light curves from a blind search. These results highlight the promise of
GPFC as an alternative approach to the traditional BLS algorithm for finding
new transiting exoplanets in data taken with Kepler and other space transit
missions such as K2, TESS and future PLATO and Earth 2.0.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02098" title="Abstract">arXiv:2312.02098</a> (cross-list from math.PR) [<a href="/pdf/2312.02098" title="Download PDF">pdf</a>, <a href="/format/2312.02098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Ziv-Merhav theorem beyond Markovianity II: A thermodynamic  approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barnfield%2C+N">Nicholas Barnfield</a>, 
<a href="/search/math?searchtype=author&query=Grondin%2C+R">Rapha&#xeb;l Grondin</a>, 
<a href="/search/math?searchtype=author&query=Pozzoli%2C+G">Gaia Pozzoli</a>, 
<a href="/search/math?searchtype=author&query=Raqu%C3%A9pas%2C+R">Renaud Raqu&#xe9;pas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We prove asymptotic results for a modification of the cross-entropy estimator
originally introduced by Ziv and Merhav in the Markovian setting in 1993. Our
results concern a more general class of decoupled measures. In particular, our
results imply strong asymptotic consistency of the modified estimator for all
pairs of functions of stationary, irreducible, finite-state Markov chains
satisfying a mild decay condition. {Our approach is based on the study of a
rescaled cumulant-generating function called the cross-entropic pressure,
importing to information theory some techniques from the study of large
deviations within the thermodynamic formalism.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue,  5 Dec 23</h3>
<dl>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.03923" title="Abstract">arXiv:2003.03923</a> (replaced) [<a href="/pdf/2003.03923" title="Download PDF">pdf</a>, <a href="/format/2003.03923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deconfounded Image Captioning: A Causal Retrospect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.11968" title="Abstract">arXiv:2004.11968</a> (replaced) [<a href="/pdf/2004.11968" title="Download PDF">pdf</a>, <a href="/format/2004.11968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing key features in X-ray images of epoxy resins for improved  material classification using singular value decomposition of deep learning  features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avalos%2C+E">Edgar Avalos</a>, 
<a href="/search/cs?searchtype=author&query=Akagi%2C+K">Kazuto Akagi</a>, 
<a href="/search/cs?searchtype=author&query=Nishiura%2C+Y">Yasumasa Nishiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> COMMAT Volume 186, January 2021, 109996
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.13456" title="Abstract">arXiv:2006.13456</a> (replaced) [<a href="/e-print/2006.13456" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-Free Gaussian Process for Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shikuri%2C+Y">Yuta Shikuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There was an error in the proposed method
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.02180" title="Abstract">arXiv:2010.02180</a> (replaced) [<a href="/pdf/2010.02180" title="Download PDF">pdf</a>, <a href="/format/2010.02180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto Probing: Trading Off Accuracy for Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tiago Pimentel and Naomi Saphra contributed equally to this work. Camera ready version of EMNLP 2020 publication. In this new version, we fixed some notation issues in the appendix, and added a new appendix section describing our MLP. Code available in <a href="https://github.com/rycolab/pareto-probing">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.08158" title="Abstract">arXiv:2010.08158</a> (replaced) [<a href="/pdf/2010.08158" title="Download PDF">pdf</a>, <a href="/format/2010.08158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accurate and Fully-Automated Ensemble Model for Weekly Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godahewa%2C+R">Rakshitha Godahewa</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Montero-Manso%2C+P">Pablo Montero-Manso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 figure, 9 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Forecasting 39 (2022) 641-658
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.01936" title="Abstract">arXiv:2102.01936</a> (replaced) [<a href="/pdf/2102.01936" title="Download PDF">pdf</a>, <a href="/format/2102.01936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Federated Learning Framework with Online Laplace  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liangxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guo-Jun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Ling Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.16669" title="Abstract">arXiv:2103.16669</a> (replaced) [<a href="/pdf/2103.16669" title="Download PDF">pdf</a>, <a href="/format/2103.16669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-depth Analysis of Passage-Level Label Transfer for Contextual  Document Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudra%2C+K">Koustav Rudra</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+Z+T">Zeon Trevor Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Avishek Anand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper is about the performance analysis of contextual ranking strategies in an ad-hoc document retrieval
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.13742" title="Abstract">arXiv:2104.13742</a> (replaced) [<a href="/pdf/2104.13742" title="Download PDF">pdf</a>, <a href="/format/2104.13742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to  Limited Data Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Garcia%2C+A">Abel Gonzalez-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenshen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Herranz%2C+L">Luis Herranz</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Jui%2C+S">Shangling Jui</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IJCV. arXiv admin note: substantial text overlap with <a href="/abs/1912.05270">arXiv:1912.05270</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.06024" title="Abstract">arXiv:2105.06024</a> (replaced) [<a href="/pdf/2105.06024" title="Download PDF">pdf</a>, <a href="/ps/2105.06024" title="Download PostScript">ps</a>, <a href="/format/2105.06024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Type-Based Termination for Futures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Somayyajula%2C+S">Siva Somayyajula</a>, 
<a href="/search/cs?searchtype=author&query=Pfenning%2C+F">Frank Pfenning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. Extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.13123" title="Abstract">arXiv:2106.13123</a> (replaced) [<a href="/pdf/2106.13123" title="Download PDF">pdf</a>, <a href="/ps/2106.13123" title="Download PostScript">ps</a>, <a href="/format/2106.13123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Queen&#x27;s Guard: A Secure Enforcement of Fine-grained Access Control  In Distributed Data Analytics Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaon%2C+F">Fahad Shaon</a> (1), 
<a href="/search/cs?searchtype=author&query=Rahaman%2C+S">Sazzadur Rahaman</a> (2), 
<a href="/search/cs?searchtype=author&query=Kantarcioglu%2C+M">Murat Kantarcioglu</a> (1) ((1) Data Security Technologies, (2) University of Arizona)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.03863" title="Abstract">arXiv:2107.03863</a> (replaced) [<a href="/pdf/2107.03863" title="Download PDF">pdf</a>, <a href="/format/2107.03863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchpress: A Scalable and Versatile Workflow for Benchmarking Structure  Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rios%2C+F+L">Felix L. Rios</a>, 
<a href="/search/stat?searchtype=author&query=Moffa%2C+G">Giusi Moffa</a>, 
<a href="/search/stat?searchtype=author&query=Kuipers%2C+J">Jack Kuipers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 8 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.07468" title="Abstract">arXiv:2107.07468</a> (replaced) [<a href="/pdf/2107.07468" title="Download PDF">pdf</a>, <a href="/format/2107.07468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A modular U-Net for automated segmentation of X-ray tomography images in  composite materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bertoldo%2C+J+P+C">Jo&#xe3;o P C Bertoldo</a>, 
<a href="/search/eess?searchtype=author&query=Decenci%C3%A8re%2C+E">Etienne Decenci&#xe8;re</a>, 
<a href="/search/eess?searchtype=author&query=Ryckelynck%2C+D">David Ryckelynck</a>, 
<a href="/search/eess?searchtype=author&query=Proudhon%2C+H">Henry Proudhon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Front. Mater., 25 November 2021 Sec. Computational Materials
  Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08758" title="Abstract">arXiv:2109.08758</a> (replaced) [<a href="/pdf/2109.08758" title="Download PDF">pdf</a>, <a href="/format/2109.08758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denial-of-Service Attack Detection via Differential Analysis of  Generalized Entropy Progressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subasi%2C+O">Omer Subasi</a>, 
<a href="/search/cs?searchtype=author&query=Manzano%2C+J">Joseph Manzano</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Kevin Barker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.09302" title="Abstract">arXiv:2111.09302</a> (replaced) [<a href="/pdf/2111.09302" title="Download PDF">pdf</a>, <a href="/format/2111.09302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Modeling for Multi-Receiver Molecular Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaylali%2C+G">Gokberk Yaylali</a>, 
<a href="/search/cs?searchtype=author&query=Akdeniz%2C+B+C">Bayram Cevdet Akdeniz</a>, 
<a href="/search/cs?searchtype=author&query=Tugcu%2C+T">Tuna Tugcu</a>, 
<a href="/search/cs?searchtype=author&query=Pusane%2C+A+E">Ali Emre Pusane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures. Published in IEEE Transactions on Communications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Communications, vol. 71, no. 8, pp.
  4499-4512, Aug. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10890" title="Abstract">arXiv:2112.10890</a> (replaced) [<a href="/pdf/2112.10890" title="Download PDF">pdf</a>, <a href="/format/2112.10890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Game Representations: The~Hidden Costs of Efficiency  in~Sequential Decision-making Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C5%99%C3%ADk%2C+V">Vojt&#x11b;ch Kova&#x159;&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Milec%2C+D">David Milec</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0ustr%2C+M">Michal &#x160;ustr</a>, 
<a href="/search/cs?searchtype=author&query=Seitz%2C+D">Dominik Seitz</a>, 
<a href="/search/cs?searchtype=author&query=Lis%C3%BD%2C+V">Viliam Lis&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11122" title="Abstract">arXiv:2112.11122</a> (replaced) [<a href="/pdf/2112.11122" title="Download PDF">pdf</a>, <a href="/format/2112.11122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Chord Progression from Melody with Flexible Harmonic Rhythm  and Controllable Harmonic Density
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangda Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobing Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 1 table, accepted by EURASIP JASMP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.01592" title="Abstract">arXiv:2201.01592</a> (replaced) [<a href="/pdf/2201.01592" title="Download PDF">pdf</a>, <a href="/format/2201.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biphasic Face Photo-Sketch Synthesis via Semantic-Driven Generative  Adversarial Network with Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Muyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+C">Caifeng Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07657" title="Abstract">arXiv:2201.07657</a> (replaced) [<a href="/pdf/2201.07657" title="Download PDF">pdf</a>, <a href="/format/2201.07657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiblock ADMM for nonsmooth nonconvex optimization with nonlinear  coupling constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hien%2C+L+T+K">Le Thi Khanh Hien</a>, 
<a href="/search/math?searchtype=author&query=Papadimitriou%2C+D">Dimitri Papadimitriou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07740" title="Abstract">arXiv:2201.07740</a> (replaced) [<a href="/pdf/2201.07740" title="Download PDF">pdf</a>, <a href="/format/2201.07740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More is Merrier: Relax the Non-Collusion Assumption in Multi-Server PIR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tiantian Gong</a>, 
<a href="/search/cs?searchtype=author&query=Henry%2C+R">Ryan Henry</a>, 
<a href="/search/cs?searchtype=author&query=Psomas%2C+A">Alexandros Psomas</a>, 
<a href="/search/cs?searchtype=author&query=Kate%2C+A">Aniket Kate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00959" title="Abstract">arXiv:2202.00959</a> (replaced) [<a href="/pdf/2202.00959" title="Download PDF">pdf</a>, <a href="/format/2202.00959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Random Walks on Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schwarz%2C+S">Simon Schwarz</a>, 
<a href="/search/math?searchtype=author&query=Herrmann%2C+M">Michael Herrmann</a>, 
<a href="/search/math?searchtype=author&query=Sturm%2C+A">Anja Sturm</a>, 
<a href="/search/math?searchtype=author&query=Wardetzky%2C+M">Max Wardetzky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; v3: published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Foundations of Computational Mathematics (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02149" title="Abstract">arXiv:2202.02149</a> (replaced) [<a href="/pdf/2202.02149" title="Download PDF">pdf</a>, <a href="/format/2202.02149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Point Cloud Registration with Learning-based Matching Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yanagi%2C+R">Rintaro Yanagi</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+A">Atsushi Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Sone%2C+S">Shusaku Sone</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08063" title="Abstract">arXiv:2202.08063</a> (replaced) [<a href="/pdf/2202.08063" title="Download PDF">pdf</a>, <a href="/ps/2202.08063" title="Download PostScript">ps</a>, <a href="/format/2202.08063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Extraction in Low-Resource Scenarios: Survey and Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yubo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress. Paper List: \url{<a href="https://github.com/zjunlp/Low-resource-KEPapers">this https URL</a>}; Data and Code: \url{ <a href="https://github.com/mayubo2333/LLM_project">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10887" title="Abstract">arXiv:2202.10887</a> (replaced) [<a href="/pdf/2202.10887" title="Download PDF">pdf</a>, <a href="/format/2202.10887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Evaluation for Temporal and/or Spatial Dependent Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Luo%2C+S">Shikai Luo</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+Y">Ying Yang</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+C">Chengchun Shi</a>, 
<a href="/search/stat?searchtype=author&query=Yao%2C+F">Fang Yao</a>, 
<a href="/search/stat?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+H">Hongtu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12193" title="Abstract">arXiv:2202.12193</a> (replaced) [<a href="/pdf/2202.12193" title="Download PDF">pdf</a>, <a href="/format/2202.12193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition-Based Synthesis for Applying Divide-and-Conquer-Like  Algorithmic Paradigms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Ruyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yingfei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhenjiang Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.12860" title="Abstract">arXiv:2204.12860</a> (replaced) [<a href="/pdf/2204.12860" title="Download PDF">pdf</a>, <a href="/format/2204.12860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualization Psychology for Eye Tracking Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+M">Maurice Koch</a>, 
<a href="/search/cs?searchtype=author&query=Kurzhals%2C+K">Kuno Kurzhals</a>, 
<a href="/search/cs?searchtype=author&query=Burch%2C+M">Michael Burch</a>, 
<a href="/search/cs?searchtype=author&query=Weiskopf%2C+D">Daniel Weiskopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01313" title="Abstract">arXiv:2205.01313</a> (replaced) [<a href="/pdf/2205.01313" title="Download PDF">pdf</a>, <a href="/format/2205.01313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cuPSO: GPU Parallelization for Particle Swarm Optimization Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuan-Chi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+C">Chun-Yen Ho</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chia-Heng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+S">Shih-Hao Hung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03408" title="Abstract">arXiv:2205.03408</a> (replaced) [<a href="/pdf/2205.03408" title="Download PDF">pdf</a>, <a href="/ps/2205.03408" title="Download PostScript">ps</a>, <a href="/format/2205.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High-Resolution Chest CT-Scan Image Dataset for COVID-19 Diagnosis and  Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abedi%2C+I">Iraj Abedi</a>, 
<a href="/search/eess?searchtype=author&query=Vali%2C+M">Mahsa Vali</a>, 
<a href="/search/eess?searchtype=author&query=Shahreza%2C+B+O">Bentolhoda Otroshi Shahreza</a>, 
<a href="/search/eess?searchtype=author&query=Bolhasani%2C+H">Hamidreza Bolhasani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11720" title="Abstract">arXiv:2205.11720</a> (replaced) [<a href="/pdf/2205.11720" title="Download PDF">pdf</a>, <a href="/format/2205.11720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENS-t-SNE: Embedding Neighborhoods Simultaneously t-SNE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miller%2C+J">Jacob Miller</a>, 
<a href="/search/cs?searchtype=author&query=Huroyan%2C+V">Vahan Huroyan</a>, 
<a href="/search/cs?searchtype=author&query=Navarrete%2C+R">Raymundo Navarrete</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+I">Md Iqbal Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Kobourov%2C+S">Stephen Kobourov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02598" title="Abstract">arXiv:2206.02598</a> (replaced) [<a href="/pdf/2206.02598" title="Download PDF">pdf</a>, <a href="/format/2206.02598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> [Reproducibility Report] Explainable Deep One-Class Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoldo%2C+J+P+C">Joao P. C. Bertoldo</a>, 
<a href="/search/cs?searchtype=author&query=Decenci%C3%A8re%2C+E">Etienne Decenci&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the ML Reproducibility Challenge 2021 Fall
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03809" title="Abstract">arXiv:2206.03809</a> (replaced) [<a href="/pdf/2206.03809" title="Download PDF">pdf</a>, <a href="/format/2206.03809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control with Patterns Based on D-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kai-Yuan Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05043" title="Abstract">arXiv:2206.05043</a> (replaced) [<a href="/pdf/2206.05043" title="Download PDF">pdf</a>, <a href="/ps/2206.05043" title="Download PostScript">ps</a>, <a href="/format/2206.05043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast synchronization of inhomogenous random automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gerencs%C3%A9r%2C+B">Bal&#xe1;zs Gerencs&#xe9;r</a>, 
<a href="/search/math?searchtype=author&query=V%C3%A1rkonyi%2C+Z">Zsombor V&#xe1;rkonyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05654" title="Abstract">arXiv:2206.05654</a> (replaced) [<a href="/pdf/2206.05654" title="Download PDF">pdf</a>, <a href="/format/2206.05654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Matrix Decomposition Model Based on Feature Factors in Movie  Recommendation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hou-biao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05669" title="Abstract">arXiv:2206.05669</a> (replaced) [<a href="/pdf/2206.05669" title="Download PDF">pdf</a>, <a href="/ps/2206.05669" title="Download PostScript">ps</a>, <a href="/format/2206.05669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universality and approximation bounds for echo state networks with  random weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunfei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11318" title="Abstract">arXiv:2206.11318</a> (replaced) [<a href="/pdf/2206.11318" title="Download PDF">pdf</a>, <a href="/format/2206.11318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An accurate and efficient scheme for function extensions on smooth  domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Epstein%2C+C+L">Charles L. Epstein</a>, 
<a href="/search/math?searchtype=author&query=Fryklund%2C+F">Fredrik Fryklund</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+S">Shidong Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 38 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05784" title="Abstract">arXiv:2207.05784</a> (replaced) [<a href="/pdf/2207.05784" title="Download PDF">pdf</a>, <a href="/format/2207.05784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for  Low-Resource Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Harlin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+A">Aaqib Saeed</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition Letters, vol. 177, pp. 15-19, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12544" title="Abstract">arXiv:2207.12544</a> (replaced) [<a href="/pdf/2207.12544" title="Download PDF">pdf</a>, <a href="/format/2207.12544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-User Puppeteering of Expressive Movements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Martelaro%2C+N">Nikolas Martelaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at PD/EUP Workshop, 2022 (<a href="/abs/cs/4404636">arXiv:cs/4404636</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13381" title="Abstract">arXiv:2207.13381</a> (replaced) [<a href="/pdf/2207.13381" title="Download PDF">pdf</a>, <a href="/format/2207.13381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Closer to Your Enemy: Learning to Attack via Teacher-Student  Mimicking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianxiong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+D">Dingwen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhiqing Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00339" title="Abstract">arXiv:2208.00339</a> (replaced) [<a href="/pdf/2208.00339" title="Download PDF">pdf</a>, <a href="/format/2208.00339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion  Recognition in Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+G">Guoqing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03326" title="Abstract">arXiv:2208.03326</a> (replaced) [<a href="/pdf/2208.03326" title="Download PDF">pdf</a>, <a href="/format/2208.03326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Autoencoders for Anomaly Detection in Respiratory Sounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cozzatti%2C+M">Michele Cozzatti</a>, 
<a href="/search/cs?searchtype=author&query=Simonetta%2C+F">Federico Simonetta</a>, 
<a href="/search/cs?searchtype=author&query=Ntalampiras%2C+S">Stavros Ntalampiras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICANN 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04798" title="Abstract">arXiv:2208.04798</a> (replaced) [<a href="/pdf/2208.04798" title="Download PDF">pdf</a>, <a href="/format/2208.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Tomographic Phase Retrieval and Unwrapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fannjiang%2C+A">Albert Fannjiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision of the previously titled "3D UNWRAPPED PHASE RETRIEVAL WITH CODED APERTURE IS REDUCIBLE TO PROJECTION TOMOGRAPHY"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Applied Physics (physics.app-ph); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09590" title="Abstract">arXiv:2208.09590</a> (replaced) [<a href="/pdf/2208.09590" title="Download PDF">pdf</a>, <a href="/format/2208.09590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Causal Effect Estimation Based on Graphical Causal  Modelling: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+D">Thuc Duy Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 10 figures and 2 table, Accepted by ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13219" title="Abstract">arXiv:2208.13219</a> (replaced) [<a href="/pdf/2208.13219" title="Download PDF">pdf</a>, <a href="/format/2208.13219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing high-dimensional loss landscapes with Hessian directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttcher%2C+L">Lucas B&#xf6;ttcher</a>, 
<a href="/search/cs?searchtype=author&query=Wheeler%2C+G">Gregory Wheeler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01432" title="Abstract">arXiv:2209.01432</a> (replaced) [<a href="/pdf/2209.01432" title="Download PDF">pdf</a>, <a href="/format/2209.01432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Monte Carlo to neural networks approximations of boundary value  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beznea%2C+L">Lucian Beznea</a>, 
<a href="/search/math?searchtype=author&query=Cimpean%2C+I">Iulian Cimpean</a>, 
<a href="/search/math?searchtype=author&query=Lupascu-Stamate%2C+O">Oana Lupascu-Stamate</a>, 
<a href="/search/math?searchtype=author&query=Popescu%2C+I">Ionel Popescu</a>, 
<a href="/search/math?searchtype=author&query=Zarnescu%2C+A">Arghir Zarnescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02973" title="Abstract">arXiv:2209.02973</a> (replaced) [<a href="/pdf/2209.02973" title="Download PDF">pdf</a>, <a href="/format/2209.02973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of probability-raising causality in Markov decision  processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baier%2C+C">Christel Baier</a>, 
<a href="/search/cs?searchtype=author&query=Piribauer%2C+J">Jakob Piribauer</a>, 
<a href="/search/cs?searchtype=author&query=Ziemek%2C+R">Robin Ziemek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission for Logical Methods in Computer Science (special issue FoSSaCS 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03054" title="Abstract">arXiv:2209.03054</a> (replaced) [<a href="/pdf/2209.03054" title="Download PDF">pdf</a>, <a href="/format/2209.03054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Search Algorithm for the Min-Sum Submodular Cover Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hellerstein%2C+L">Lisa Hellerstein</a>, 
<a href="/search/cs?searchtype=author&query=Lidbetter%2C+T">Thomas Lidbetter</a>, 
<a href="/search/cs?searchtype=author&query=Witter%2C+R+T">R. Teal Witter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correct funding information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03320" title="Abstract">arXiv:2209.03320</a> (replaced) [<a href="/pdf/2209.03320" title="Download PDF">pdf</a>, <a href="/format/2209.03320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What does a platypus look like? Generating customized prompts for  zero-shot image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratt%2C+S">Sarah Pratt</a>, 
<a href="/search/cs?searchtype=author&query=Covert%2C+I">Ian Covert</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rosanne Liu</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11638" title="Abstract">arXiv:2209.11638</a> (replaced) [<a href="/pdf/2209.11638" title="Download PDF">pdf</a>, <a href="/ps/2209.11638" title="Download PostScript">ps</a>, <a href="/format/2209.11638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSP-Based MAP Estimation of Graph Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sagi%2C+G">Guy Sagi</a>, 
<a href="/search/eess?searchtype=author&query=Routtenberg%2C+T">Tirza Routtenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15146" title="Abstract">arXiv:2209.15146</a> (replaced) [<a href="/pdf/2209.15146" title="Download PDF">pdf</a>, <a href="/format/2209.15146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Machine Learning Model Trained on a New Synthesized Dataset  Generalizes Well for Stress Prediction Using Wearable Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vos%2C+G">Gideon Vos</a>, 
<a href="/search/cs?searchtype=author&query=Trinh%2C+K">Kelly Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Sarnyai%2C+Z">Zoltan Sarnyai</a>, 
<a href="/search/cs?searchtype=author&query=Azghadi%2C+M+R">Mostafa Rahimi Azghadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15451" title="Abstract">arXiv:2209.15451</a> (replaced) [<a href="/pdf/2209.15451" title="Download PDF">pdf</a>, <a href="/format/2209.15451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Domain Generalization for Cardiac Magnetic Resonance  Image Segmentation with High Quality Pseudo Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Wanqin Ma</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+H">Huifeng Yao</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yiqun Lin</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiarong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Workshop on Statistical Atlases and Computational Models of the Heart (STACOM2022) of MICCAI2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> STACOM2022.13593(2022)383-391
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00094" title="Abstract">arXiv:2210.00094</a> (replaced) [<a href="/pdf/2210.00094" title="Download PDF">pdf</a>, <a href="/format/2210.00094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness with Adaptive Weight Decay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghiasi%2C+A">Amin Ghiasi</a>, 
<a href="/search/cs?searchtype=author&query=Shafahi%2C+A">Ali Shafahi</a>, 
<a href="/search/cs?searchtype=author&query=Ardekani%2C+R">Reza Ardekani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03728" title="Abstract">arXiv:2210.03728</a> (replaced) [<a href="/pdf/2210.03728" title="Download PDF">pdf</a>, <a href="/format/2210.03728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Data as Atoms: Unifying Intra- and Inter-Sample  Relationship to Discretize Data Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuan%2C+Y">Yi-Lin Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+Z">Zih-Yun Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05371" title="Abstract">arXiv:2210.05371</a> (replaced) [<a href="/pdf/2210.05371" title="Download PDF">pdf</a>, <a href="/format/2210.05371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On skip connections and normalisation layers in deep optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+L+E">Lachlan Ewen MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Valmadre%2C+J">Jack Valmadre</a>, 
<a href="/search/cs?searchtype=author&query=Saratchandran%2C+H">Hemanth Saratchandran</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07876" title="Abstract">arXiv:2210.07876</a> (replaced) [<a href="/pdf/2210.07876" title="Download PDF">pdf</a>, <a href="/format/2210.07876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control, Confidentiality, and the Right to be Forgotten
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Aloni Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Adam Smith</a>, 
<a href="/search/cs?searchtype=author&query=Swanberg%2C+M">Marika Swanberg</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+P+N">Prashant Nalini Vasudevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09168" title="Abstract">arXiv:2210.09168</a> (replaced) [<a href="/pdf/2210.09168" title="Download PDF">pdf</a>, <a href="/format/2210.09168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially scalable recursive estimation of Gaussian process terrain maps  using local basis functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viset%2C+F+M">Frida Marie Viset</a>, 
<a href="/search/cs?searchtype=author&query=Helmons%2C+R">Rudy Helmons</a>, 
<a href="/search/cs?searchtype=author&query=Kok%2C+M">Manon Kok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11388" title="Abstract">arXiv:2210.11388</a> (replaced) [<a href="/pdf/2210.11388" title="Download PDF">pdf</a>, <a href="/ps/2210.11388" title="Download PostScript">ps</a>, <a href="/format/2210.11388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Deep Diffusion MRI Reconstruction with Synthetic Data:  Break Training Data Bottleneck in Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Y">Yuncheng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+M">Mingyang Han</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ruan%2C+D">Dan Ruan</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Y">Yu Shen</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yiping Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yirong Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chengyan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+B">Boyu Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhigang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiazheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Liuhong Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+T">Taishan Kang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jianzhong Lin</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+T">Tao Gong</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Fei%2C+G">Guoqiang Fei</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+M">Meijin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+D">Di Guo</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jianjun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Meiyun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+X">Xiaobo Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12503" title="Abstract">arXiv:2210.12503</a> (replaced) [<a href="/pdf/2210.12503" title="Download PDF">pdf</a>, <a href="/ps/2210.12503" title="Download PostScript">ps</a>, <a href="/format/2210.12503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Axiomatic Characterization of Split Cycle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ding%2C+Y">Yifeng Ding</a>, 
<a href="/search/econ?searchtype=author&query=Holliday%2C+W+H">Wesley H. Holliday</a>, 
<a href="/search/econ?searchtype=author&query=Pacuit%2C+E">Eric Pacuit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version including new Section 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13452" title="Abstract">arXiv:2210.13452</a> (replaced) [<a href="/pdf/2210.13452" title="Download PDF">pdf</a>, <a href="/format/2210.13452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaFormer Baselines for Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenyang Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Mi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TPAMI. Code: <a href="https://github.com/sail-sg/metaformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13770" title="Abstract">arXiv:2210.13770</a> (replaced) [<a href="/pdf/2210.13770" title="Download PDF">pdf</a>, <a href="/format/2210.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Virality of Hate Speech on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maarouf%2C+A">Abdurahman Maarouf</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%B6llochs%2C+N">Nicolas Pr&#xf6;llochs</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CSCW 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14986" title="Abstract">arXiv:2210.14986</a> (replaced) [<a href="/pdf/2210.14986" title="Download PDF">pdf</a>, <a href="/format/2210.14986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters  for Implicature Resolution by LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruis%2C+L">Laura Ruis</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Akbir Khan</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Spotlight at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02658" title="Abstract">arXiv:2211.02658</a> (replaced) [<a href="/pdf/2211.02658" title="Download PDF">pdf</a>, <a href="/format/2211.02658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dealing with Drift of Adaptation Spaces in Learning-based Self-Adaptive  Systems using Lifelong Self-Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheibi%2C+O">Omid Gheibi</a>, 
<a href="/search/cs?searchtype=author&query=Weyns%2C+D">Danny Weyns</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03570" title="Abstract">arXiv:2211.03570</a> (replaced) [<a href="/pdf/2211.03570" title="Download PDF">pdf</a>, <a href="/format/2211.03570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do highly over-parameterized neural networks generalize since bad  solutions are rare?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinetz%2C+J">Julius Martinetz</a>, 
<a href="/search/cs?searchtype=author&query=Martinetz%2C+T">Thomas Martinetz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08412" title="Abstract">arXiv:2211.08412</a> (replaced) [<a href="/pdf/2211.08412" title="Download PDF">pdf</a>, <a href="/format/2211.08412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Factual Consistency of Large Language Models Through News  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tam%2C+D">Derek Tam</a>, 
<a href="/search/cs?searchtype=author&query=Mascarenhas%2C+A">Anisha Mascarenhas</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+S">Sarah Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09983" title="Abstract">arXiv:2211.09983</a> (replaced) [<a href="/pdf/2211.09983" title="Download PDF">pdf</a>, <a href="/ps/2211.09983" title="Download PostScript">ps</a>, <a href="/format/2211.09983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Approximation Property of Fully Convolutional Neural Networks  with Zero Padding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Geonho Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myungjoo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09997" title="Abstract">arXiv:2211.09997</a> (replaced) [<a href="/pdf/2211.09997" title="Download PDF">pdf</a>, <a href="/format/2211.09997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond ExaBricks: GPU Volume Path Tracing of AMR Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zellmann%2C+S">Stefan Zellmann</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sahistan%2C+A">Alper Sahistan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kwan-Liu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wald%2C+I">Ingo Wald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11530" title="Abstract">arXiv:2211.11530</a> (replaced) [<a href="/pdf/2211.11530" title="Download PDF">pdf</a>, <a href="/format/2211.11530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Set Object Detection Using Classification-free Object Proposal and  Instance-level Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhongxiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13507" title="Abstract">arXiv:2211.13507</a> (replaced) [<a href="/pdf/2211.13507" title="Download PDF">pdf</a>, <a href="/format/2211.13507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability of nonlinear ODE Models with Time-Varying Parameters:  the General Analytical Solution and Applications in Viral Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinelli%2C+A">Agostino Martinelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13739" title="Abstract">arXiv:2211.13739</a> (replaced) [<a href="/pdf/2211.13739" title="Download PDF">pdf</a>, <a href="/format/2211.13739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Approximation of Gaussian random fields on Closed Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonito%2C+A">Andrea Bonito</a>, 
<a href="/search/math?searchtype=author&query=Guignard%2C+D">Diane Guignard</a>, 
<a href="/search/math?searchtype=author&query=Lei%2C+W">Wenyu Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02345" title="Abstract">arXiv:2212.02345</a> (replaced) [<a href="/pdf/2212.02345" title="Download PDF">pdf</a>, <a href="/format/2212.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wrapping Cycles in Delaunay Complexes: Bridging Persistent Homology and  Discrete Morse Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bauer%2C+U">Ulrich Bauer</a>, 
<a href="/search/math?searchtype=author&query=Roll%2C+F">Fabian Roll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. Updated exposition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Geometric Topology (math.GT)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03181" title="Abstract">arXiv:2212.03181</a> (replaced) [<a href="/pdf/2212.03181" title="Download PDF">pdf</a>, <a href="/format/2212.03181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Funnel-based Reward Shaping for Signal Temporal Logic Tasks in  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saxena%2C+N">Naman Saxena</a>, 
<a href="/search/eess?searchtype=author&query=Sandeep%2C+G">Gorantla Sandeep</a>, 
<a href="/search/eess?searchtype=author&query=Jagtap%2C+P">Pushpak Jagtap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09209" title="Abstract">arXiv:2212.09209</a> (replaced) [<a href="/pdf/2212.09209" title="Download PDF">pdf</a>, <a href="/format/2212.09209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDIO-CT collaborative strategy for solving complex STEM problems in  system modeling and simulation: an illustration of solving the period of  mathematical pendulum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+H">Hong-Yan Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Y">Yu-Tao Li</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+F">Fu-Yun Li</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+Y">Yong-Hui Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 12 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Applications in Engineering Education, 2023(11): e22698
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Computers and Society (cs.CY); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09512" title="Abstract">arXiv:2212.09512</a> (replaced) [<a href="/pdf/2212.09512" title="Download PDF">pdf</a>, <a href="/format/2212.09512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Label Smoothing on Multi-hop Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiannian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, accepted by CCL2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09928" title="Abstract">arXiv:2212.09928</a> (replaced) [<a href="/pdf/2212.09928" title="Download PDF">pdf</a>, <a href="/format/2212.09928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Robustness of Summarization Models by Detecting and  Removing Input Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K">Kundan Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarayanan%2C+B">Balaji Lakshminarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiaming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Saleh%2C+M">Mohammad Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10789" title="Abstract">arXiv:2212.10789</a> (replaced) [<a href="/pdf/2212.10789" title="Download PDF">pdf</a>, <a href="/format/2212.10789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Molecule Structure-text Model for Text-based Retrieval and  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weili Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Zhuoran Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12474" title="Abstract">arXiv:2212.12474</a> (replaced) [<a href="/pdf/2212.12474" title="Download PDF">pdf</a>, <a href="/format/2212.12474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Gaussian Process Regression Generalizes Linear PDE  Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pf%C3%B6rtner%2C+M">Marvin Pf&#xf6;rtner</a>, 
<a href="/search/cs?searchtype=author&query=Steinwart%2C+I">Ingo Steinwart</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>, 
<a href="/search/cs?searchtype=author&query=Wenger%2C+J">Jonathan Wenger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01901" title="Abstract">arXiv:2301.01901</a> (replaced) [<a href="/pdf/2301.01901" title="Download PDF">pdf</a>, <a href="/format/2301.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAC+: Optimizing Error-Bounded Lossy Compression for 3D AMR Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daoce Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pulido%2C+J">Jesus Pulido</a>, 
<a href="/search/cs?searchtype=author&query=Grosset%2C+P">Pascal Grosset</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiannan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Arhens%2C+J">James Arhens</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 30 figures, 5 tables, accepted by IEEE TPDS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02833" title="Abstract">arXiv:2301.02833</a> (replaced) [<a href="/pdf/2301.02833" title="Download PDF">pdf</a>, <a href="/format/2301.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Weihrauch degree of the additive Ramsey theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pauly%2C+A">Arno Pauly</a>, 
<a href="/search/cs?searchtype=author&query=Pradic%2C+C">C&#xe9;cilia Pradic</a>, 
<a href="/search/cs?searchtype=author&query=Solda%2C+G">Giovanni Solda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04003" title="Abstract">arXiv:2301.04003</a> (replaced) [<a href="/pdf/2301.04003" title="Download PDF">pdf</a>, <a href="/format/2301.04003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Change Propagation Without Joins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Binyang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Ke Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the VLDB paper, correcting some errors from the original paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04517" title="Abstract">arXiv:2301.04517</a> (replaced) [<a href="/pdf/2301.04517" title="Download PDF">pdf</a>, <a href="/format/2301.04517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new sampling methodology for defining heterogeneous subsets of samples  for training image segmentation algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+V">Matheus Viana da Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Carvalho+Santos%2C+N">Nat&#xe1;lia de Carvalho Santos</a>, 
<a href="/search/cs?searchtype=author&query=Ouellette%2C+J">Julie Ouellette</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste%2C+B">Baptiste Lacoste</a>, 
<a href="/search/cs?searchtype=author&query=Comin%2C+C+H">Cesar Henrique Comin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04603" title="Abstract">arXiv:2301.04603</a> (replaced) [<a href="/pdf/2301.04603" title="Download PDF">pdf</a>, <a href="/format/2301.04603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility and Regularity Analysis of Safe Stabilizing Controllers  under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mestres%2C+P">Pol Mestres</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07475" title="Abstract">arXiv:2301.07475</a> (replaced) [<a href="/pdf/2301.07475" title="Download PDF">pdf</a>, <a href="/ps/2301.07475" title="Download PostScript">ps</a>, <a href="/format/2301.07475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curvilinear object segmentation in medical images based on ODoS filter  and deep learning network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yuanyuan Peng</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+L">Lin Pan</a>, 
<a href="/search/eess?searchtype=author&query=Luan%2C+P">Pengpeng Luan</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+H">Hongbin Tu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures. Applied Intelligence, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07902" title="Abstract">arXiv:2301.07902</a> (replaced) [<a href="/pdf/2301.07902" title="Download PDF">pdf</a>, <a href="/ps/2301.07902" title="Download PostScript">ps</a>, <a href="/format/2301.07902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonstochastic Control Approach to Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08505" title="Abstract">arXiv:2301.08505</a> (replaced) [<a href="/pdf/2301.08505" title="Download PDF">pdf</a>, <a href="/ps/2301.08505" title="Download PostScript">ps</a>, <a href="/format/2301.08505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Behavior of Zero-Forcing Precoding based on Imperfect Channel  Knowledge for Massive MISO FDD Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amor%2C+D+B">Donia Ben Amor</a>, 
<a href="/search/eess?searchtype=author&query=Joham%2C+M">Michael Joham</a>, 
<a href="/search/eess?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09602" title="Abstract">arXiv:2301.09602</a> (replaced) [<a href="/pdf/2301.09602" title="Download PDF">pdf</a>, <a href="/format/2301.09602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoldo%2C+J+P+C">Joao P. C. Bertoldo</a>, 
<a href="/search/cs?searchtype=author&query=Velasco-Forero%2C+S">Santiago Velasco-Forero</a>, 
<a href="/search/cs?searchtype=author&query=Angulo%2C+J">Jesus Angulo</a>, 
<a href="/search/cs?searchtype=author&query=Decenci%C3%A8re%2C+E">Etienne Decenci&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 2023 IEEE International Conference on Image Processing (ICIP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13687" title="Abstract">arXiv:2301.13687</a> (replaced) [<a href="/pdf/2301.13687" title="Download PDF">pdf</a>, <a href="/ps/2301.13687" title="Download PostScript">ps</a>, <a href="/format/2301.13687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crossover Can Guarantee Exponential Speed-Ups in Evolutionary  Multi-Objective Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+D">Duc-Cuong Dang</a>, 
<a href="/search/cs?searchtype=author&query=Opris%2C+A">Andre Opris</a>, 
<a href="/search/cs?searchtype=author&query=Sudholt%2C+D">Dirk Sudholt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a significant extension of the previous version. We extend the results to uniform crossover and also investigate effects of hypermutation. The previous version is available both on arXiv (<a href="/abs/2301.13687">arXiv:2301.13687v1</a>) and in AAAI Publications (<a href="https://ojs.aaai.org/index.php/AAAI/article/view/26460">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01178" title="Abstract">arXiv:2302.01178</a> (replaced) [<a href="/pdf/2302.01178" title="Download PDF">pdf</a>, <a href="/format/2302.01178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Operators for robust and accurate learning of PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raoni%C4%87%2C+B">Bogdan Raoni&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Molinaro%2C+R">Roberto Molinaro</a>, 
<a href="/search/cs?searchtype=author&query=De+Ryck%2C+T">Tim De Ryck</a>, 
<a href="/search/cs?searchtype=author&query=Rohner%2C+T">Tobias Rohner</a>, 
<a href="/search/cs?searchtype=author&query=Bartolucci%2C+F">Francesca Bartolucci</a>, 
<a href="/search/cs?searchtype=author&query=Alaifari%2C+R">Rima Alaifari</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=de+B%C3%A9zenac%2C+E">Emmanuel de B&#xe9;zenac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03750" title="Abstract">arXiv:2302.03750</a> (replaced) [<a href="/pdf/2302.03750" title="Download PDF">pdf</a>, <a href="/format/2302.03750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linking convolutional kernel size to generalization bias in face  analysis CNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Hao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Caro%2C+J+O">Josue Ortega Caro</a>, 
<a href="/search/cs?searchtype=author&query=Maheshri%2C+V">Vikram Maheshri</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+A+B">Ankit B. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+G">Guha Balakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04440" title="Abstract">arXiv:2302.04440</a> (replaced) [<a href="/pdf/2302.04440" title="Download PDF">pdf</a>, <a href="/format/2302.04440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Likelihood Score: Evaluating the Generalization of Generative  Models Using Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiralerspong%2C+M">Marco Jiralerspong</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+A+J">Avishek Joey Bose</a>, 
<a href="/search/cs?searchtype=author&query=Gemp%2C+I">Ian Gemp</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chongli Qin</a>, 
<a href="/search/cs?searchtype=author&query=Bachrach%2C+Y">Yoram Bachrach</a>, 
<a href="/search/cs?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04611" title="Abstract">arXiv:2302.04611</a> (replaced) [<a href="/pdf/2302.04611" title="Download PDF">pdf</a>, <a href="/format/2302.04611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Text-guided Protein Design Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoxinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Gitter%2C+A">Anthony Gitter</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yutao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weili Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Arvind Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04974" title="Abstract">arXiv:2302.04974</a> (replaced) [<a href="/pdf/2302.04974" title="Download PDF">pdf</a>, <a href="/ps/2302.04974" title="Download PostScript">ps</a>, <a href="/format/2302.04974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of orthogonalization-free conjugate gradient method  for extreme eigenvalues of Hermitian matrices: a Riemannian optimization  interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+S">Shixin Zheng</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Haizhao Yang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangxiong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06884" title="Abstract">arXiv:2302.06884</a> (replaced) [<a href="/pdf/2302.06884" title="Download PDF">pdf</a>, <a href="/format/2302.06884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservative State Value Estimation for Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhengdao Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Moscibroda%2C+T">Thomas Moscibroda</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08224" title="Abstract">arXiv:2302.08224</a> (replaced) [<a href="/pdf/2302.08224" title="Download PDF">pdf</a>, <a href="/format/2302.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09597" title="Abstract">arXiv:2302.09597</a> (replaced) [<a href="/e-print/2302.09597" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing The Effect of Combining Carbon Price and Border Adjustments in  The US Power Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+H+T+T">Huynh Trung Thanh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H+T">Hieu Trung Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I am an author of this article, due to it quality, I want to remove it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11323" title="Abstract">arXiv:2302.11323</a> (replaced) [<a href="/pdf/2302.11323" title="Download PDF">pdf</a>, <a href="/format/2302.11323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsampling in ensemble Kalman inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hanu%2C+M">Matei Hanu</a>, 
<a href="/search/math?searchtype=author&query=Latz%2C+J">Jonas Latz</a>, 
<a href="/search/math?searchtype=author&query=Schillings%2C+C">Claudia Schillings</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published by IOP Publishing Ltd, Inverse Problems, Volume 39,
  Number 9, Year 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00571" title="Abstract">arXiv:2303.00571</a> (replaced) [<a href="/pdf/2303.00571" title="Download PDF">pdf</a>, <a href="/ps/2303.00571" title="Download PostScript">ps</a>, <a href="/format/2303.00571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly Efficient Year-Round Energy and Comfort Optimization of HVAC  Systems in Electric City Buses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Widmer%2C+F">Fabio Widmer</a>, 
<a href="/search/eess?searchtype=author&query=Ritter%2C+A">Andreas Ritter</a>, 
<a href="/search/eess?searchtype=author&query=Achermann%2C+M">Mathias Achermann</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%BCeler%2C+F">Fabian B&#xfc;eler</a>, 
<a href="/search/eess?searchtype=author&query=Bagajo%2C+J">Joshua Bagajo</a>, 
<a href="/search/eess?searchtype=author&query=Onder%2C+C+H">Christopher H. Onder</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFAC-PapersOnLine, vol. 56, no. 2. Elsevier BV, pp. 10656-10663,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01287" title="Abstract">arXiv:2303.01287</a> (replaced) [<a href="/pdf/2303.01287" title="Download PDF">pdf</a>, <a href="/ps/2303.01287" title="Download PostScript">ps</a>, <a href="/format/2303.01287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-throughput optical neural networks based on temporal computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weifeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03307" title="Abstract">arXiv:2303.03307</a> (replaced) [<a href="/pdf/2303.03307" title="Download PDF">pdf</a>, <a href="/format/2303.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Efficient Coding of Natural Images with Maximum Manifold  Capacity Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yerxa%2C+T">Thomas Yerxa</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Y">Yilun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Simoncelli%2C+E">Eero Simoncelli</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">SueYeon Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03983" title="Abstract">arXiv:2303.03983</a> (replaced) [<a href="/pdf/2303.03983" title="Download PDF">pdf</a>, <a href="/ps/2303.03983" title="Download PostScript">ps</a>, <a href="/format/2303.03983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Choreographic Programming: Full-Duplex Asynchrony and  Interoperability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lugovi%C4%87%2C+L">Lovro Lugovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Montesi%2C+F">Fabrizio Montesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04729" title="Abstract">arXiv:2303.04729</a> (replaced) [<a href="/pdf/2303.04729" title="Download PDF">pdf</a>, <a href="/format/2303.04729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stealing the Decoding Algorithms of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naseh%2C+A">Ali Naseh</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K">Kalpesh Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>, 
<a href="/search/cs?searchtype=author&query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 ACM SIGSAC Conference on Computer and
  Communications Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04788" title="Abstract">arXiv:2303.04788</a> (replaced) [<a href="/pdf/2303.04788" title="Download PDF">pdf</a>, <a href="/format/2303.04788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Non-Linear Quantum Operations through Variational Quantum  Splines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Inajetovic%2C+M+A">Matteo Antonio Inajetovic</a>, 
<a href="/search/quant-ph?searchtype=author&query=Orazi%2C+F">Filippo Orazi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Macaluso%2C+A">Antonio Macaluso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lodi%2C+S">Stefano Lodi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sartori%2C+C">Claudio Sartori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06222" title="Abstract">arXiv:2303.06222</a> (replaced) [<a href="/pdf/2303.06222" title="Download PDF">pdf</a>, <a href="/format/2303.06222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust MADER: Decentralized Multiagent Trajectory Planner Robust to  Communication Delay in Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondo%2C+K">Kota Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+R">Reinaldo Figueroa</a>, 
<a href="/search/cs?searchtype=author&query=Rached%2C+J">Juan Rached</a>, 
<a href="/search/cs?searchtype=author&query=Tordesillas%2C+J">Jesus Tordesillas</a>, 
<a href="/search/cs?searchtype=author&query=Lusk%2C+P+C">Parker C. Lusk</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pagers, 10 figures,. arXiv admin note: substantial text overlap with <a href="/abs/2209.13667">arXiv:2209.13667</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06470" title="Abstract">arXiv:2303.06470</a> (replaced) [<a href="/pdf/2303.06470" title="Download PDF">pdf</a>, <a href="/format/2303.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prefix-Tree Decoding for Predicting Mass Spectra from Molecules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Goldman%2C+S">Samuel Goldman</a>, 
<a href="/search/q-bio?searchtype=author&query=Bradshaw%2C+J">John Bradshaw</a>, 
<a href="/search/q-bio?searchtype=author&query=Xin%2C+J">Jiayi Xin</a>, 
<a href="/search/q-bio?searchtype=author&query=Coley%2C+C+W">Connor W. Coley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06908" title="Abstract">arXiv:2303.06908</a> (replaced) [<a href="/pdf/2303.06908" title="Download PDF">pdf</a>, <a href="/format/2303.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossFormer++: A Versatile Vision Transformer Hinging on Cross-scale  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Q">Qibo Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07026" title="Abstract">arXiv:2303.07026</a> (replaced) [<a href="/pdf/2303.07026" title="Download PDF">pdf</a>, <a href="/format/2303.07026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual-Policy Learning through Multi-Camera View to Single-Camera View  Knowledge Distillation for Robot Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acar%2C+C">Cihan Acar</a>, 
<a href="/search/cs?searchtype=author&query=Binici%2C+K">Kuluhan Binici</a>, 
<a href="/search/cs?searchtype=author&query=Tekirda%C4%9F%2C+A">Alp Tekirda&#x11f;</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08240" title="Abstract">arXiv:2303.08240</a> (replaced) [<a href="/pdf/2303.08240" title="Download PDF">pdf</a>, <a href="/format/2303.08240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parametric Surface Constrained Upsampler Network for Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pingping Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update Supplementary Files
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence. 37,
  1 (Jun. 2023), 250-258
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09051" title="Abstract">arXiv:2303.09051</a> (replaced) [<a href="/pdf/2303.09051" title="Download PDF">pdf</a>, <a href="/format/2303.09051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Evaluation of Diffusion-Based Adversarial Purification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minjong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongwoo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023, oral presentation. Code is available at <a href="https://github.com/ml-postech/robust-evaluation-of-diffusion-based-purification">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12484" title="Abstract">arXiv:2303.12484</a> (replaced) [<a href="/pdf/2303.12484" title="Download PDF">pdf</a>, <a href="/format/2303.12484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-Efficient Deep Learning in Medical Image Analysis: Challenges and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhengrui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update 2023 papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13397" title="Abstract">arXiv:2303.13397</a> (replaced) [<a href="/pdf/2303.13397" title="Download PDF">pdf</a>, <a href="/format/2303.13397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffMesh: A Motion-aware Diffusion-like Framework for Human Mesh  Recovery from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianfu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guo-Jun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13514" title="Abstract">arXiv:2303.13514</a> (replaced) [<a href="/pdf/2303.13514" title="Download PDF">pdf</a>, <a href="/format/2303.13514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAOR: Single-View Articulated Object Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayg%C3%BCn%2C+M">Mehmet Ayg&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Aodha%2C+O">Oisin Mac Aodha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://mehmetaygun.github.io/saor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13534" title="Abstract">arXiv:2303.13534</a> (replaced) [<a href="/pdf/2303.13534" title="Download PDF">pdf</a>, <a href="/format/2303.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting AI Art: An Investigation into the Creative Skill of Prompt  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oppenlaender%2C+J">Jonas Oppenlaender</a>, 
<a href="/search/cs?searchtype=author&query=Linder%2C+R">Rhema Linder</a>, 
<a href="/search/cs?searchtype=author&query=Silvennoinen%2C+J">Johanna Silvennoinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13843" title="Abstract">arXiv:2303.13843</a> (replaced) [<a href="/pdf/2303.13843" title="Download PDF">pdf</a>, <a href="/format/2303.13843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D  Scene Layout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haotian Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yuanhuiyi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lutao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16563" title="Abstract">arXiv:2303.16563</a> (replaced) [<a href="/pdf/2303.16563" title="Download PDF">pdf</a>, <a href="/format/2303.16563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skill Reinforcement Learning and Planning for Open-World Long-Horizon  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haoqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Feiyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Penglin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, presented in Foundation Models for Decision Making Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17580" title="Abstract">arXiv:2303.17580</a> (replaced) [<a href="/pdf/2303.17580" title="Download PDF">pdf</a>, <a href="/format/2303.17580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging  Face
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yongliang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17783" title="Abstract">arXiv:2303.17783</a> (replaced) [<a href="/pdf/2303.17783" title="Download PDF">pdf</a>, <a href="/format/2303.17783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with  Wavelet Augmentation Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+Y">Yuang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoqiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00306" title="Abstract">arXiv:2304.00306</a> (replaced) [<a href="/pdf/2304.00306" title="Download PDF">pdf</a>, <a href="/format/2304.00306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CapsFlow: Optical Flow Estimation with Capsule Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chand%2C+R">Rahul Chand</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+R">Rajat Arora</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+K+R">K Ram Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+R+V">R Venkatesh Babu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Newer version added to correct issue in the conference name of the previous version uploaded on April 1st
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01196" title="Abstract">arXiv:2304.01196</a> (replaced) [<a href="/pdf/2304.01196" title="Download PDF">pdf</a>, <a href="/format/2304.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on  Self-Chat Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Canwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Daya Guo</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Baize v2; EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04150" title="Abstract">arXiv:2304.04150</a> (replaced) [<a href="/pdf/2304.04150" title="Download PDF">pdf</a>, <a href="/format/2304.04150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboPianist: Dexterous Piano Playing with Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zakka%2C+K">Kevin Zakka</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Philipp Wu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+L">Laura Smith</a>, 
<a href="/search/cs?searchtype=author&query=Gileadi%2C+N">Nimrod Gileadi</a>, 
<a href="/search/cs?searchtype=author&query=Howell%2C+T">Taylor Howell</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X+B">Xue Bin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sumeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tassa%2C+Y">Yuval Tassa</a>, 
<a href="/search/cs?searchtype=author&query=Florence%2C+P">Pete Florence</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Conference on Robot Learning (CORL) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05467" title="Abstract">arXiv:2304.05467</a> (replaced) [<a href="/pdf/2304.05467" title="Download PDF">pdf</a>, <a href="/format/2304.05467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured IQC Synthesis of Robust $\mathcal{H}_2$ Controllers in the  Frequency Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sch%C3%BCtte%2C+M">Maximilian Sch&#xfc;tte</a>, 
<a href="/search/eess?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/eess?searchtype=author&query=Werner%2C+H">Herbert Werner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, accepted for IFAC World Congress 2023. Shortened to satisfy submission page limit (removed one numerical example and compressed remaining text)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFAC-PapersOnLine Volume 56, Issue 2, 2023, Pages 10408-10413
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06433" title="Abstract">arXiv:2304.06433</a> (replaced) [<a href="/pdf/2304.06433" title="Download PDF">pdf</a>, <a href="/format/2304.06433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Zero-Shot Texture Anomaly Localization Using Feature  Correspondence Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardelean%2C+A">Andrei-Timotei Ardelean</a>, 
<a href="/search/cs?searchtype=author&query=Weyrich%2C+T">Tim Weyrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08424" title="Abstract">arXiv:2304.08424</a> (replaced) [<a href="/pdf/2304.08424" title="Download PDF">pdf</a>, <a href="/format/2304.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term Forecasting with TiDE: Time-series Dense Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Das%2C+A">Abhimanyu Das</a>, 
<a href="/search/stat?searchtype=author&query=Kong%2C+W">Weihao Kong</a>, 
<a href="/search/stat?searchtype=author&query=Leach%2C+A">Andrew Leach</a>, 
<a href="/search/stat?searchtype=author&query=Mathur%2C+S">Shaan Mathur</a>, 
<a href="/search/stat?searchtype=author&query=Sen%2C+R">Rajat Sen</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10159" title="Abstract">arXiv:2304.10159</a> (replaced) [<a href="/pdf/2304.10159" title="Download PDF">pdf</a>, <a href="/format/2304.10159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Q Learning with Hybrid Quantum Neural Network on Solving Maze  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+H">Hao-Yuan Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chang%2C+Y">Yen-Jui Chang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liao%2C+S">Shih-Wei Liao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chang%2C+C">Ching-Ray Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10513" title="Abstract">arXiv:2304.10513</a> (replaced) [<a href="/pdf/2304.10513" title="Download PDF">pdf</a>, <a href="/ps/2304.10513" title="Download PostScript">ps</a>, <a href="/format/2304.10513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Does ChatGPT Fall Short in Providing Truthful Answers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10613" title="Abstract">arXiv:2304.10613</a> (replaced) [<a href="/pdf/2304.10613" title="Download PDF">pdf</a>, <a href="/format/2304.10613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Conditional Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lie He</a>, 
<a href="/search/cs?searchtype=author&query=Kasiviswanathan%2C+S+P">Shiva Prasad Kasiviswanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11464" title="Abstract">arXiv:2304.11464</a> (replaced) [<a href="/pdf/2304.11464" title="Download PDF">pdf</a>, <a href="/format/2304.11464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Learning of Two-Stage Beamformers for Passive IRS-Aided  Network Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hashmi%2C+H">Hassaan Hashmi</a>, 
<a href="/search/eess?searchtype=author&query=Pougkakiotis%2C+S">Spyridon Pougkakiotis</a>, 
<a href="/search/eess?searchtype=author&query=Kalogerias%2C+D+S">Dionysios S. Kalogerias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11761" title="Abstract">arXiv:2304.11761</a> (replaced) [<a href="/pdf/2304.11761" title="Download PDF">pdf</a>, <a href="/format/2304.11761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hier-RTLMP: A Hierarchical Automatic Macro Placer for Large-scale  Complex IP Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kahng%2C+A+B">Andrew B. Kahng</a>, 
<a href="/search/eess?searchtype=author&query=Varadarajan%2C+R">Ravi Varadarajan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12872" title="Abstract">arXiv:2304.12872</a> (replaced) [<a href="/pdf/2304.12872" title="Download PDF">pdf</a>, <a href="/format/2304.12872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anti-crossings occurrence as exponentially closing gaps in Quantum  Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Braida%2C+A">Arthur Braida</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martiel%2C+S">Simon Martiel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Todinca%2C+I">Ioan Todinca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13695" title="Abstract">arXiv:2304.13695</a> (replaced) [<a href="/pdf/2304.13695" title="Download PDF">pdf</a>, <a href="/format/2304.13695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Approximation for Subgraph-Hitting Problems in Sparse Graphs  and Geometric Intersection Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvo%C5%99%C3%A1k%2C+Z">Zden&#x11b;k Dvo&#x159;&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Lokshtanov%2C+D">Daniel Lokshtanov</a>, 
<a href="/search/cs?searchtype=author&query=Panolan%2C+F">Fahad Panolan</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jie Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zehavi%2C+M">Meirav Zehavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, subsuming the article <a href="/abs/2304.12789">arXiv:2304.12789</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02217" title="Abstract">arXiv:2305.02217</a> (replaced) [<a href="/pdf/2305.02217" title="Download PDF">pdf</a>, <a href="/format/2305.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Perspective of Machine Learning with Computational  Resource Concerns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhi-Hua Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03047" title="Abstract">arXiv:2305.03047</a> (replaced) [<a href="/pdf/2305.03047" title="Download PDF">pdf</a>, <a href="/format/2305.03047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principle-Driven Self-Alignment of Language Models from Scratch with  Minimal Human Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qinhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+D">David Cox</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 (Spotlight). Project page: <a href="https://github.com/IBM/Dromedary">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04721" title="Abstract">arXiv:2305.04721</a> (replaced) [<a href="/pdf/2305.04721" title="Download PDF">pdf</a>, <a href="/ps/2305.04721" title="Download PostScript">ps</a>, <a href="/format/2305.04721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Menger-type theorem for two induced paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Albrechtsen%2C+S">Sandra Albrechtsen</a>, 
<a href="/search/math?searchtype=author&query=Huynh%2C+T">Tony Huynh</a>, 
<a href="/search/math?searchtype=author&query=Jacobs%2C+R+W">Raphael W. Jacobs</a>, 
<a href="/search/math?searchtype=author&query=Knappe%2C+P">Paul Knappe</a>, 
<a href="/search/math?searchtype=author&query=Wollan%2C+P">Paul Wollan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures. New title. Referee suggestions implemented
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04782" title="Abstract">arXiv:2305.04782</a> (replaced) [<a href="/pdf/2305.04782" title="Download PDF">pdf</a>, <a href="/format/2305.04782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HistAlign: Improving Context Dependency in Language Generation by  Aligning with History
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+D">David Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (20 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04881" title="Abstract">arXiv:2305.04881</a> (replaced) [<a href="/pdf/2305.04881" title="Download PDF">pdf</a>, <a href="/ps/2305.04881" title="Download PostScript">ps</a>, <a href="/format/2305.04881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skolem and Positivity Completeness of Ergodic Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahanwala%2C+M">Mihir Vahanwala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06898" title="Abstract">arXiv:2305.06898</a> (replaced) [<a href="/pdf/2305.06898" title="Download PDF">pdf</a>, <a href="/format/2305.06898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying vital nodes through augmented random walks on higher-order  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yujie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiao-Long Ren</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+L">Linyuan L&#xfc;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08419" title="Abstract">arXiv:2305.08419</a> (replaced) [<a href="/pdf/2305.08419" title="Download PDF">pdf</a>, <a href="/ps/2305.08419" title="Download PostScript">ps</a>, <a href="/format/2305.08419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tractable and Intractable Entailment Problems in Separation Logic with  Inductively Defined Predicates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echenim%2C+M">Mnacho Echenim</a>, 
<a href="/search/cs?searchtype=author&query=Peltier%2C+N">Nicolas Peltier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08901" title="Abstract">arXiv:2305.08901</a> (replaced) [<a href="/pdf/2305.08901" title="Download PDF">pdf</a>, <a href="/format/2305.08901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical spectra of the Laplacian for line bundles on Calabi-Yau  hypersurfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-th?searchtype=author&query=Ashmore%2C+A">Anthony Ashmore</a>, 
<a href="/search/hep-th?searchtype=author&query=He%2C+Y">Yang-Hui He</a>, 
<a href="/search/hep-th?searchtype=author&query=Heyes%2C+E">Elli Heyes</a>, 
<a href="/search/hep-th?searchtype=author&query=Ovrut%2C+B+A">Burt A. Ovrut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 6 figures; v2 - corrected typo in quintic equation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Theory (hep-th)</span>; Differential Geometry (math.DG); Numerical Analysis (math.NA); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10601" title="Abstract">arXiv:2305.10601</a> (replaced) [<a href="/pdf/2305.10601" title="Download PDF">pdf</a>, <a href="/format/2305.10601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree of Thoughts: Deliberate Problem Solving with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jeffrey Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shafran%2C+I">Izhak Shafran</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Karthik Narasimhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready version. Code repo with all prompts: <a href="https://github.com/princeton-nlp/tree-of-thought-llm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11032" title="Abstract">arXiv:2305.11032</a> (replaced) [<a href="/pdf/2305.11032" title="Download PDF">pdf</a>, <a href="/ps/2305.11032" title="Download PostScript">ps</a>, <a href="/format/2305.11032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Natural Policy Gradient: a Simple Efficient Policy  Optimization Framework for Online RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Weisz%2C+G">Gell&#xe9;rt Weisz</a>, 
<a href="/search/cs?searchtype=author&query=Gy%C3%B6rgy%2C+A">Andr&#xe1;s Gy&#xf6;rgy</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11550" title="Abstract">arXiv:2305.11550</a> (replaced) [<a href="/pdf/2305.11550" title="Download PDF">pdf</a>, <a href="/format/2305.11550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viewing Knowledge Transfer in Multilingual Machine Translation Through a  Representational Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stap%2C+D">David Stap</a>, 
<a href="/search/cs?searchtype=author&query=Niculae%2C+V">Vlad Niculae</a>, 
<a href="/search/cs?searchtype=author&query=Monz%2C+C">Christof Monz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13256" title="Abstract">arXiv:2305.13256</a> (replaced) [<a href="/pdf/2305.13256" title="Download PDF">pdf</a>, <a href="/format/2305.13256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskWeb: Selecting Better Source Tasks for Multi-task NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joongwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Asai%2C+A">Akari Asai</a>, 
<a href="/search/cs?searchtype=author&query=Ilharco%2C+G">Gabriel Ilharco</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13269" title="Abstract">arXiv:2305.13269</a> (replaced) [<a href="/pdf/2305.13269" title="Download PDF">pdf</a>, <a href="/format/2305.13269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chia%2C+Y+K">Yew Ken Chia</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bosheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13289" title="Abstract">arXiv:2305.13289</a> (replaced) [<a href="/pdf/2305.13289" title="Download PDF">pdf</a>, <a href="/format/2305.13289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving the Minimax Optimal Sample Complexity of Offline Reinforcement  Learning: A DRO-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shaofeng Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13622" title="Abstract">arXiv:2305.13622</a> (replaced) [<a href="/pdf/2305.13622" title="Download PDF">pdf</a>, <a href="/format/2305.13622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Strong Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T">Tao Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13998" title="Abstract">arXiv:2305.13998</a> (replaced) [<a href="/pdf/2305.13998" title="Download PDF">pdf</a>, <a href="/format/2305.13998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and  Mixed Variables Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saves%2C+P">Paul Saves</a>, 
<a href="/search/cs?searchtype=author&query=Lafage%2C+R">Remi Lafage</a>, 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+N">Nathalie Bartoli</a>, 
<a href="/search/cs?searchtype=author&query=Diouane%2C+Y">Youssef Diouane</a>, 
<a href="/search/cs?searchtype=author&query=Bussemaker%2C+J">Jasper Bussemaker</a>, 
<a href="/search/cs?searchtype=author&query=Lefebvre%2C+T">Thierry Lefebvre</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+T">John T. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Morlier%2C+J">Joseph Morlier</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+J+R+R+A">Joaquim R. R. A. Martins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14296" title="Abstract">arXiv:2305.14296</a> (replaced) [<a href="/pdf/2305.14296" title="Download PDF">pdf</a>, <a href="/format/2305.14296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USB: A Unified Summarization Benchmark Across Tasks and Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K">Kundan Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Prakhar Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ramprasad%2C+S">Sanjana Ramprasad</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Bigham%2C+J+P">Jeffrey P. Bigham</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14735" title="Abstract">arXiv:2305.14735</a> (replaced) [<a href="/pdf/2305.14735" title="Download PDF">pdf</a>, <a href="/format/2305.14735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+V">Vyoma Raman</a>, 
<a href="/search/cs?searchtype=author&query=Fleisig%2C+E">Eve Fleisig</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14912" title="Abstract">arXiv:2305.14912</a> (replaced) [<a href="/pdf/2305.14912" title="Download PDF">pdf</a>, <a href="/format/2305.14912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu-Bang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xi-Le Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Junhua Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng-Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Ting-Zhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15712" title="Abstract">arXiv:2305.15712</a> (replaced) [<a href="/pdf/2305.15712" title="Download PDF">pdf</a>, <a href="/format/2305.15712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Diffusion for Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mingkai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shan You</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16746" title="Abstract">arXiv:2305.16746</a> (replaced) [<a href="/pdf/2305.16746" title="Download PDF">pdf</a>, <a href="/format/2305.16746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN Feature Map Augmentation for Single-Source Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ballas%2C+A">Aristotelis Ballas</a>, 
<a href="/search/cs?searchtype=author&query=Diou%2C+C">Christos Diou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings of IEEE BigDataService2023 (<a href="https://ieeebigdataservice.com/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17691" title="Abstract">arXiv:2305.17691</a> (replaced) [<a href="/pdf/2305.17691" title="Download PDF">pdf</a>, <a href="/format/2305.17691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-and-Play Knowledge Injection for Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huadong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Deming Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaojun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19125" title="Abstract">arXiv:2305.19125</a> (replaced) [<a href="/pdf/2305.19125" title="Download PDF">pdf</a>, <a href="/format/2305.19125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Generation with $K^2$-trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yunhui Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19518" title="Abstract">arXiv:2305.19518</a> (replaced) [<a href="/pdf/2305.19518" title="Download PDF">pdf</a>, <a href="/format/2305.19518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-Retrieval-Augmented Diffusion Models for Learning from Noisy  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rohan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyou Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00392" title="Abstract">arXiv:2306.00392</a> (replaced) [<a href="/pdf/2306.00392" title="Download PDF">pdf</a>, <a href="/format/2306.00392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coneheads: Hierarchy Aware Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+A">Albert Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+J+B">Toni J.B. Liu</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00783" title="Abstract">arXiv:2306.00783</a> (replaced) [<a href="/pdf/2306.00783" title="Download PDF">pdf</a>, <a href="/format/2306.00783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceDNeRF: Semantics-Driven Face Reconstruction, Prompt Editing and  Relighting with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tianyuan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01140" title="Abstract">arXiv:2306.01140</a> (replaced) [<a href="/pdf/2306.01140" title="Download PDF">pdf</a>, <a href="/format/2306.01140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time discontinuous Galerkin method for coupled  poroelasticity-elasticity problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Botti%2C+M">Michele Botti</a>, 
<a href="/search/math?searchtype=author&query=Mazzieri%2C+I">Ilario Mazzieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01242" title="Abstract">arXiv:2306.01242</a> (replaced) [<a href="/pdf/2306.01242" title="Download PDF">pdf</a>, <a href="/format/2306.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible Task Automation: Empowering Large Language Models as  Responsible Task Automators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenxuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02956" title="Abstract">arXiv:2306.02956</a> (replaced) [<a href="/pdf/2306.02956" title="Download PDF">pdf</a>, <a href="/format/2306.02956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+T">Thomas Walker</a>, 
<a href="/search/cs?searchtype=author&query=Mariotti%2C+O">Octave Mariotti</a>, 
<a href="/search/cs?searchtype=author&query=Vaxman%2C+A">Amir Vaxman</a>, 
<a href="/search/cs?searchtype=author&query=Bilen%2C+H">Hakan Bilen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03072" title="Abstract">arXiv:2306.03072</a> (replaced) [<a href="/pdf/2306.03072" title="Download PDF">pdf</a>, <a href="/format/2306.03072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore to Generalize in Zero-Shot RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zisselman%2C+E">Ev Zisselman</a>, 
<a href="/search/cs?searchtype=author&query=Lavie%2C+I">Itai Lavie</a>, 
<a href="/search/cs?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>, 
<a href="/search/cs?searchtype=author&query=Tamar%2C+A">Aviv Tamar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03292" title="Abstract">arXiv:2306.03292</a> (replaced) [<a href="/pdf/2306.03292" title="Download PDF">pdf</a>, <a href="/format/2306.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Relaxation for Fokker-Planck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yian Chen</a>, 
<a href="/search/math?searchtype=author&query=Khoo%2C+Y">Yuehaw Khoo</a>, 
<a href="/search/math?searchtype=author&query=Lim%2C+L">Lek-Heng Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03997" title="Abstract">arXiv:2306.03997</a> (replaced) [<a href="/pdf/2306.03997" title="Download PDF">pdf</a>, <a href="/format/2306.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment Analysis in Finance: From Transformers Back to eXplainable  Lexicons (XLex)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizinski%2C+M">Maryan Rizinski</a>, 
<a href="/search/cs?searchtype=author&query=Peshov%2C+H">Hristijan Peshov</a>, 
<a href="/search/cs?searchtype=author&query=Mishev%2C+K">Kostadin Mishev</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovik%2C+M">Milos Jovanovik</a>, 
<a href="/search/cs?searchtype=author&query=Trajanov%2C+D">Dimitar Trajanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04527" title="Abstract">arXiv:2306.04527</a> (replaced) [<a href="/pdf/2306.04527" title="Download PDF">pdf</a>, <a href="/format/2306.04527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContriMix: Unsupervised disentanglement of content and attribute for  domain generalization in microscopy image analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T+H">Tan H. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Juyal%2C+D">Dinkar Juyal</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/eess?searchtype=author&query=Prakash%2C+A">Aaditya Prakash</a>, 
<a href="/search/eess?searchtype=author&query=Nofallah%2C+S">Shima Nofallah</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+C">Chintan Shah</a>, 
<a href="/search/eess?searchtype=author&query=Gullapally%2C+S+C">Sai Chowdary Gullapally</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Limin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Griffin%2C+M">Michael Griffin</a>, 
<a href="/search/eess?searchtype=author&query=Sampat%2C+A">Anand Sampat</a>, 
<a href="/search/eess?searchtype=author&query=Abel%2C+J">John Abel</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Justin Lee</a>, 
<a href="/search/eess?searchtype=author&query=Taylor-Weiner%2C+A">Amaro Taylor-Weiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04633" title="Abstract">arXiv:2306.04633</a> (replaced) [<a href="/pdf/2306.04633" title="Download PDF">pdf</a>, <a href="/format/2306.04633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast  Contrastive Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhalgat%2C+Y">Yash Bhalgat</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Spotlight). Code: <a href="https://github.com/yashbhalgat/Contrastive-Lift">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04848" title="Abstract">arXiv:2306.04848</a> (replaced) [<a href="/pdf/2306.04848" title="Download PDF">pdf</a>, <a href="/format/2306.04848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting and Improving Diffusion Models Using the Euclidean Distance  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Permenter%2C+F">Frank Permenter</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chenyang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04910" title="Abstract">arXiv:2306.04910</a> (replaced) [<a href="/pdf/2306.04910" title="Download PDF">pdf</a>, <a href="/format/2306.04910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tansferability Metric Using Scene Similarity and Local Map Observation  for DRL Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+S">Shiwei Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feitian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06082" title="Abstract">arXiv:2306.06082</a> (replaced) [<a href="/pdf/2306.06082" title="Download PDF">pdf</a>, <a href="/format/2306.06082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation-aware Self-supervised Learning with Conditioned Projector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Przewi%C4%99%C5%BAlikowski%2C+M">Marcin Przewi&#x119;&#x17a;likowski</a>, 
<a href="/search/cs?searchtype=author&query=Pyla%2C+M">Mateusz Pyla</a>, 
<a href="/search/cs?searchtype=author&query=Zieli%C5%84ski%2C+B">Bartosz Zieli&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Amieja%2C+M">Marek &#x15a;mieja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Prepint under review. Code: <a href="https://github.com/gmum/CASSLE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06614" title="Abstract">arXiv:2306.06614</a> (replaced) [<a href="/pdf/2306.06614" title="Download PDF">pdf</a>, <a href="/ps/2306.06614" title="Download PostScript">ps</a>, <a href="/format/2306.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-reduction implicit exponential Runge-Kutta methods for highly  oscillatory systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+X">Xianfa Hu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+W">Wansheng Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Fang%2C+Y">Yonglei Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07581" title="Abstract">arXiv:2306.07581</a> (replaced) [<a href="/pdf/2306.07581" title="Download PDF">pdf</a>, <a href="/format/2306.07581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Seungjoo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaesik Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Project page: <a href="https://seungjooshin.github.io/BiRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08089" title="Abstract">arXiv:2306.08089</a> (replaced) [<a href="/pdf/2306.08089" title="Download PDF">pdf</a>, <a href="/format/2306.08089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360TripleView: 360-Degree Video View Management System Driven by  Convergence Value of Viewing Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+M">Michael Zink</a>, 
<a href="/search/cs?searchtype=author&query=Sitaraman%2C+R">Ramesh Sitaraman</a>, 
<a href="/search/cs?searchtype=author&query=Nahrstedt%2C+K">Klara Nahrstedt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08736" title="Abstract">arXiv:2306.08736</a> (replaced) [<a href="/pdf/2306.08736" title="Download PDF">pdf</a>, <a href="/format/2306.08736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoSh: Long-Short Text Joint Prediction Network for Referring Video  Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Linfeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zijie Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08939" title="Abstract">arXiv:2306.08939</a> (replaced) [<a href="/pdf/2306.08939" title="Download PDF">pdf</a>, <a href="/format/2306.08939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Stereo Triangulation in UAV Distance Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jiafan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Duan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rihong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weixin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenji Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhun Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09267" title="Abstract">arXiv:2306.09267</a> (replaced) [<a href="/pdf/2306.09267" title="Download PDF">pdf</a>, <a href="/ps/2306.09267" title="Download PostScript">ps</a>, <a href="/format/2306.09267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are ChatGPT and Other Similar Systems the Modern Lernaean Hydras of AI?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+D">Dimitrios Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>, 
<a href="/search/cs?searchtype=author&query=Bowne%2C+A">Andrew Bowne</a>, 
<a href="/search/cs?searchtype=author&query=Bryant%2C+H+S">Harriet S. Bryant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 100+ references, to appear in Fordham Law Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09396" title="Abstract">arXiv:2306.09396</a> (replaced) [<a href="/pdf/2306.09396" title="Download PDF">pdf</a>, <a href="/format/2306.09396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Federated Frequency Estimation: Adapting to the Hardness of the  Instance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wennan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kairouz%2C+P">Peter Kairouz</a>, 
<a href="/search/cs?searchtype=author&query=Braverman%2C+V">Vladimir Braverman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09639" title="Abstract">arXiv:2306.09639</a> (replaced) [<a href="/pdf/2306.09639" title="Download PDF">pdf</a>, <a href="/ps/2306.09639" title="Download PostScript">ps</a>, <a href="/format/2306.09639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling BIM-Driven Robotic Construction Workflows with Closed-Loop  Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongrui Yu</a>, 
<a href="/search/cs?searchtype=author&query=McGee%2C+W">Wes McGee</a>, 
<a href="/search/cs?searchtype=author&query=Menassa%2C+C+C">Carol C. Menassa</a>, 
<a href="/search/cs?searchtype=author&query=Kamat%2C+V+R">Vineet R. Kamat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10174" title="Abstract">arXiv:2306.10174</a> (replaced) [<a href="/pdf/2306.10174" title="Download PDF">pdf</a>, <a href="/format/2306.10174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Vortex Damping Outflow Forcing for Multiphase Flows with Sharp  Interfacial Jumps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint Submitted to Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10933" title="Abstract">arXiv:2306.10933</a> (replaced) [<a href="/pdf/2306.10933" title="Download PDF">pdf</a>, <a href="/format/2306.10933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-World Recommendation with Knowledge Augmentation from Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+Y">Yunjia Xi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaoling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11300" title="Abstract">arXiv:2306.11300</a> (replaced) [<a href="/pdf/2306.11300" title="Download PDF">pdf</a>, <a href="/format/2306.11300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS5M: A Large Scale Vision-Language Dataset for Remote Sensing  Vision-Language Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zilun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiancheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yulong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianwei Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RS5M dataset v5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12059" title="Abstract">arXiv:2306.12059</a> (replaced) [<a href="/pdf/2306.12059" title="Download PDF">pdf</a>, <a href="/format/2306.12059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EquiformerV2: Improved Equivariant Transformer for Scaling to  Higher-Degree Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yi-Lun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+B">Brandon Wood</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhishek Das</a>, 
<a href="/search/cs?searchtype=author&query=Smidt%2C+T">Tess Smidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12509" title="Abstract">arXiv:2306.12509</a> (replaced) [<a href="/pdf/2306.12509" title="Download PDF">pdf</a>, <a href="/format/2306.12509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Prompt Optimization of Stacked LLMs using Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sordoni%2C+A">Alessandro Sordoni</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingdi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%B4t%C3%A9%2C+M">Marc-Alexandre C&#xf4;t&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+M">Matheus Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Trischler%2C+A">Adam Trischler</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Ziang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+A">Arian Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Niedtner%2C+F">Friederike Niedtner</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+N+L">Nicolas Le Roux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13387" title="Abstract">arXiv:2306.13387</a> (replaced) [<a href="/e-print/2306.13387" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Competitive Ratios for Online Bipartite Matching on Degree  Bounded Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yilong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaowei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shengwei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some error was discovered in the analysis for the stochastic setting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13440" title="Abstract">arXiv:2306.13440</a> (replaced) [<a href="/pdf/2306.13440" title="Download PDF">pdf</a>, <a href="/format/2306.13440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trading-off price for data quality to achieve fair online allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molina%2C+M">Mathieu Molina</a>, 
<a href="/search/cs?searchtype=author&query=Gast%2C+N">Nicolas Gast</a>, 
<a href="/search/cs?searchtype=author&query=Loiseau%2C+P">Patrick Loiseau</a>, 
<a href="/search/cs?searchtype=author&query=Perchet%2C+V">Vianney Perchet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15427" title="Abstract">arXiv:2306.15427</a> (replaced) [<a href="/pdf/2306.15427" title="Download PDF">pdf</a>, <a href="/format/2306.15427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and  New Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gosch%2C+L">Lukas Gosch</a>, 
<a href="/search/cs?searchtype=author&query=Geisler%2C+S">Simon Geisler</a>, 
<a href="/search/cs?searchtype=author&query=Sturm%2C+D">Daniel Sturm</a>, 
<a href="/search/cs?searchtype=author&query=Charpentier%2C+B">Bertrand Charpentier</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%BCgner%2C+D">Daniel Z&#xfc;gner</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16646" title="Abstract">arXiv:2306.16646</a> (replaced) [<a href="/pdf/2306.16646" title="Download PDF">pdf</a>, <a href="/ps/2306.16646" title="Download PostScript">ps</a>, <a href="/format/2306.16646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Reverse Information Projections and Optimal E-statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lardy%2C+T">Tyron Lardy</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%BCnwald%2C+P">Peter Gr&#xfc;nwald</a>, 
<a href="/search/cs?searchtype=author&query=Harremo%C3%ABs%2C+P">Peter Harremo&#xeb;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A five-page abstract of this paper, containing a subset of the theorems but no proofs, was presented at ISIT 2023, Taipei
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17100" title="Abstract">arXiv:2306.17100</a> (replaced) [<a href="/pdf/2306.17100" title="Download PDF">pdf</a>, <a href="/format/2306.17100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL4CO: a Unified Reinforcement Learning for Combinatorial Optimization  Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berto%2C+F">Federico Berto</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+C">Chuanbo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Jiwoo Son</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haeyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joungho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a workshop paper at the NeurIPS 2023 GLFrontiers Workshop (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01197" title="Abstract">arXiv:2307.01197</a> (replaced) [<a href="/pdf/2307.01197" title="Download PDF">pdf</a>, <a href="/format/2307.01197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Meets Point Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raji%C4%8D%2C+F">Frano Raji&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+L">Lei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01708" title="Abstract">arXiv:2307.01708</a> (replaced) [<a href="/pdf/2307.01708" title="Download PDF">pdf</a>, <a href="/format/2307.01708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Model Equivalence for Risk-Sensitive Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kastner%2C+T">Tyler Kastner</a>, 
<a href="/search/cs?searchtype=author&query=Erdogdu%2C+M+A">Murat A. Erdogdu</a>, 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+A">Amir-massoud Farahmand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02129" title="Abstract">arXiv:2307.02129</a> (replaced) [<a href="/pdf/2307.02129" title="Download PDF">pdf</a>, <a href="/format/2307.02129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Deep Neural Networks Learn Compositional Data: The Random Hierarchy  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cagnetta%2C+F">Francesco Cagnetta</a>, 
<a href="/search/cs?searchtype=author&query=Petrini%2C+L">Leonardo Petrini</a>, 
<a href="/search/cs?searchtype=author&query=Tomasini%2C+U+M">Umberto M. Tomasini</a>, 
<a href="/search/cs?searchtype=author&query=Favero%2C+A">Alessandro Favero</a>, 
<a href="/search/cs?searchtype=author&query=Wyart%2C+M">Matthieu Wyart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02779" title="Abstract">arXiv:2307.02779</a> (replaced) [<a href="/pdf/2307.02779" title="Download PDF">pdf</a>, <a href="/format/2307.02779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Empowered Autonomous Edge AI for Connected  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yifei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiawei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Magazine paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02842" title="Abstract">arXiv:2307.02842</a> (replaced) [<a href="/pdf/2307.02842" title="Download PDF">pdf</a>, <a href="/format/2307.02842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient Iterated CVaR Reinforcement Learning with Function  Approximation and Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yihan Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pihe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Desheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03166" title="Abstract">arXiv:2307.03166</a> (replaced) [<a href="/pdf/2307.03166" title="Download PDF">pdf</a>, <a href="/format/2307.03166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoGLUE: Video General Understanding Evaluation of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangzhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gundavarapu%2C+N+B">Nitesh Bharadwaj Gundavarapu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Menglin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Weyand%2C+T">Tobias Weyand</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+L">Luke Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Sirotenko%2C+M">Mikhail Sirotenko</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Schroff%2C+F">Florian Schroff</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixes some typos and include project open-source page: <a href="https://github.com/tensorflow/models/tree/master/official/projects/videoglue">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03242" title="Abstract">arXiv:2307.03242</a> (replaced) [<a href="/pdf/2307.03242" title="Download PDF">pdf</a>, <a href="/format/2307.03242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFA-tuned matrix-free multigrid method for the elastic Helmholtz  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yovel%2C+R">Rachel Yovel</a>, 
<a href="/search/math?searchtype=author&query=Treister%2C+E">Eran Treister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. Accepted to SIAM journal on scientific computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03288" title="Abstract">arXiv:2307.03288</a> (replaced) [<a href="/e-print/2307.03288" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Scalarizations for Sublinear Hypervolume Regret
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiuyi Zhang</a> (Richard)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version coming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06377" title="Abstract">arXiv:2307.06377</a> (replaced) [<a href="/pdf/2307.06377" title="Download PDF">pdf</a>, <a href="/format/2307.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curve Fitting Simplified: Exploring the Intuitive Features of CurvPy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+S+S">Sidharth S S</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06614" title="Abstract">arXiv:2307.06614</a> (replaced) [<a href="/pdf/2307.06614" title="Download PDF">pdf</a>, <a href="/format/2307.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable 2D Vision Models for 3D Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="/search/eess?searchtype=author&query=Erdur%2C+A+C">Ayhan Can Erdur</a>, 
<a href="/search/eess?searchtype=author&query=Trigui%2C+M">Marwa Trigui</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%BCvenir%2C+A">Alp G&#xfc;venir</a>, 
<a href="/search/eess?searchtype=author&query=Mueller%2C+T+T">Tamara T. Mueller</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+P">Philip M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Jungmann%2C+F">Friederike Jungmann</a>, 
<a href="/search/eess?searchtype=author&query=Brandt%2C+J">Johannes Brandt</a>, 
<a href="/search/eess?searchtype=author&query=Peeken%2C+J">Jan Peeken</a>, 
<a href="/search/eess?searchtype=author&query=Braren%2C+R">Rickmer Braren</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07566" title="Abstract">arXiv:2307.07566</a> (replaced) [<a href="/pdf/2307.07566" title="Download PDF">pdf</a>, <a href="/format/2307.07566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of 3-Axis Seismocardiogram from Right-to-left and  Head-to-foot Components Using A Long Short-Term Memory Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rahman%2C+M+M">Mohammad Muntasir Rahman</a>, 
<a href="/search/physics?searchtype=author&query=Taebi%2C+A">Amirtah&#xe0; Taebi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07607" title="Abstract">arXiv:2307.07607</a> (replaced) [<a href="/pdf/2307.07607" title="Download PDF">pdf</a>, <a href="/format/2307.07607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubT-MRS Dataset: Pushing SLAM Towards All-weather Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuanjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+D">Damanpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rushan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sarawata%2C+M">Mansi Sarawata</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Whittaker%2C+W">Warren Whittaker</a>, 
<a href="/search/cs?searchtype=author&query=Higgins%2C+I">Ian Higgins</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yi Du</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shaoshu Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">John Keller</a>, 
<a href="/search/cs?searchtype=author&query=Karhade%2C+J">Jay Karhade</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+L">Lucas Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sourojit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07816" title="Abstract">arXiv:2307.07816</a> (replaced) [<a href="/pdf/2307.07816" title="Download PDF">pdf</a>, <a href="/format/2307.07816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Random Code Learning with Mean-KL Parameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J+A">Jihao Andreas Lin</a>, 
<a href="/search/cs?searchtype=author&query=Flamich%2C+G">Gergely Flamich</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML Neural Compression Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08053" title="Abstract">arXiv:2307.08053</a> (replaced) [<a href="/pdf/2307.08053" title="Download PDF">pdf</a>, <a href="/ps/2307.08053" title="Download PostScript">ps</a>, <a href="/format/2307.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Extended Codes of Some Linear Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhonghua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Cunsheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tingfang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08165" title="Abstract">arXiv:2307.08165</a> (replaced) [<a href="/pdf/2307.08165" title="Download PDF">pdf</a>, <a href="/ps/2307.08165" title="Download PostScript">ps</a>, <a href="/format/2307.08165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On short edges in complete topological graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Suk%2C+A">Andrew Suk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08304" title="Abstract">arXiv:2307.08304</a> (replaced) [<a href="/pdf/2307.08304" title="Download PDF">pdf</a>, <a href="/ps/2307.08304" title="Download PostScript">ps</a>, <a href="/format/2307.08304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation of Counterfactual Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaffalon%2C+M">Marco Zaffalon</a>, 
<a href="/search/cs?searchtype=author&query=Antonucci%2C+A">Alessandro Antonucci</a>, 
<a href="/search/cs?searchtype=author&query=Caba%C3%B1as%2C+R">Rafael Caba&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+D">David Huber</a>, 
<a href="/search/cs?searchtype=author&query=Azzimonti%2C+D">Dario Azzimonti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08596" title="Abstract">arXiv:2307.08596</a> (replaced) [<a href="/pdf/2307.08596" title="Download PDF">pdf</a>, <a href="/format/2307.08596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Omnipotent Adversarial Training in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09105" title="Abstract">arXiv:2307.09105</a> (replaced) [<a href="/pdf/2307.09105" title="Download PDF">pdf</a>, <a href="/format/2307.09105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-based Model Predictive Control Leveraging Parallelizable  Physics Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pezzato%2C+C">Corrado Pezzato</a>, 
<a href="/search/cs?searchtype=author&query=Salmi%2C+C">Chadi Salmi</a>, 
<a href="/search/cs?searchtype=author&query=Spahn%2C+M">Max Spahn</a>, 
<a href="/search/cs?searchtype=author&query=Trevisan%2C+E">Elia Trevisan</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>, 
<a href="/search/cs?searchtype=author&query=Corbato%2C+C+H">Carlos Hernandez Corbato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to RA-L. Code and videos available at <a href="https://sites.google.com/view/mppi-isaac/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10135" title="Abstract">arXiv:2307.10135</a> (replaced) [<a href="/pdf/2307.10135" title="Download PDF">pdf</a>, <a href="/format/2307.10135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Architecture for Neural Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bowen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+H+W">Henrik Wann Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Montazeri%2C+Z">Zahra Montazeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10205" title="Abstract">arXiv:2307.10205</a> (replaced) [<a href="/pdf/2307.10205" title="Download PDF">pdf</a>, <a href="/format/2307.10205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating the Effect of Data Imbalance on Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10605" title="Abstract">arXiv:2307.10605</a> (replaced) [<a href="/pdf/2307.10605" title="Download PDF">pdf</a>, <a href="/format/2307.10605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model order reduction with novel discrete empirical interpolation  methods in space-time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mueller%2C+N">Nicholas Mueller</a>, 
<a href="/search/math?searchtype=author&query=Badia%2C+S">Santiago Badia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10936" title="Abstract">arXiv:2307.10936</a> (replaced) [<a href="/pdf/2307.10936" title="Download PDF">pdf</a>, <a href="/format/2307.10936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PASTA: Pretrained Action-State Transformer Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boige%2C+R">Raphael Boige</a>, 
<a href="/search/cs?searchtype=author&query=Flet-Berliac%2C+Y">Yannis Flet-Berliac</a>, 
<a href="/search/cs?searchtype=author&query=Flajolet%2C+A">Arthur Flajolet</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Guillaume Richard</a>, 
<a href="/search/cs?searchtype=author&query=Pierrot%2C+T">Thomas Pierrot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12212" title="Abstract">arXiv:2307.12212</a> (replaced) [<a href="/pdf/2307.12212" title="Download PDF">pdf</a>, <a href="/format/2307.12212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content Censorship in the InterPlanetary File System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srivatsan Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Ascigil%2C+O">Onur Ascigil</a>, 
<a href="/search/cs?searchtype=author&query=Keizer%2C+N">Navin Keizer</a>, 
<a href="/search/cs?searchtype=author&query=Genon%2C+F">Fran&#xe7;ois Genon</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+S">S&#xe9;bastien Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Psaras%2C+Y">Yiannis Psaras</a>, 
<a href="/search/cs?searchtype=author&query=Rivi%C3%A8re%2C+E">Etienne Rivi&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%B3l%2C+M">Micha&#x142; Kr&#xf3;l</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages (including references and appendices), 15 figures. Accepted to be published at the Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13771" title="Abstract">arXiv:2307.13771</a> (replaced) [<a href="/pdf/2307.13771" title="Download PDF">pdf</a>, <a href="/ps/2307.13771" title="Download PostScript">ps</a>, <a href="/format/2307.13771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accuracy Improvement in Differentially Private Logistic Regression: A  Pre-training Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoseinpour%2C+M">Mohammad Hoseinpour</a>, 
<a href="/search/cs?searchtype=author&query=Hoseinpour%2C+M">Milad Hoseinpour</a>, 
<a href="/search/cs?searchtype=author&query=Aghagolzadeh%2C+A">Ali Aghagolzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15996" title="Abstract">arXiv:2307.15996</a> (replaced) [<a href="/pdf/2307.15996" title="Download PDF">pdf</a>, <a href="/format/2307.15996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locked Polyomino Tilings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tucker-Foltz%2C+J">Jamie Tucker-Foltz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16449" title="Abstract">arXiv:2307.16449</a> (replaced) [<a href="/pdf/2307.16449" title="Download PDF">pdf</a>, <a href="/format/2307.16449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MovieChat: From Dense Token to Sparse Memory for Long Video  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+E">Enxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yucheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+H">Haozhe Chi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. First three authors contribute equally to this work. Project Website <a href="https://rese1f.github.io/MovieChat/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16764" title="Abstract">arXiv:2307.16764</a> (replaced) [<a href="/pdf/2307.16764" title="Download PDF">pdf</a>, <a href="/format/2307.16764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking of Flatness-based Control of the Heat Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Scholz%2C+S">Stephan Scholz</a>, 
<a href="/search/math?searchtype=author&query=Berger%2C+L">Lothar Berger</a>, 
<a href="/search/math?searchtype=author&query=Lebiedz%2C+D">Dirk Lebiedz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 13 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00820" title="Abstract">arXiv:2308.00820</a> (replaced) [<a href="/pdf/2308.00820" title="Download PDF">pdf</a>, <a href="/format/2308.00820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry preserving numerical methods for physical systems with  finite-dimensional Lie algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blanco%2C+L">L. Blanco</a>, 
<a href="/search/math?searchtype=author&query=Alburquerque%2C+F+J">F. Jim&#xe9;nez Alburquerque</a>, 
<a href="/search/math?searchtype=author&query=de+Lucas%2C+J">J. de Lucas</a>, 
<a href="/search/math?searchtype=author&query=Sard%C3%B3n%2C+C">C. Sard&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New theoretical remarks and applications added. Presentation improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01719" title="Abstract">arXiv:2308.01719</a> (replaced) [<a href="/pdf/2308.01719" title="Download PDF">pdf</a>, <a href="/format/2308.01719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Data Conversion Bottleneck in Analog Computing Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meech%2C+J+T">James T. Meech</a>, 
<a href="/search/cs?searchtype=author&query=Tsoutsouras%2C+V">Vasileios Tsoutsouras</a>, 
<a href="/search/cs?searchtype=author&query=Stanley-Marbell%2C+P">Phillip Stanley-Marbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the First Workshop on Machine Learning with New Compute Paradigms at NeurIPS 2023 (MLNPCP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01729" title="Abstract">arXiv:2308.01729</a> (replaced) [<a href="/pdf/2308.01729" title="Download PDF">pdf</a>, <a href="/format/2308.01729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telematics Combined Actuarial Neural Networks for Cross-Sectional and  Longitudinal Claim Count Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Duval%2C+F">Francis Duval</a>, 
<a href="/search/stat?searchtype=author&query=Boucher%2C+J">Jean-Philippe Boucher</a>, 
<a href="/search/stat?searchtype=author&query=Pigeon%2C+M">Mathieu Pigeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01987" title="Abstract">arXiv:2308.01987</a> (replaced) [<a href="/pdf/2308.01987" title="Download PDF">pdf</a>, <a href="/format/2308.01987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bengali Fake Reviews: A Benchmark Dataset and Detection System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahariar%2C+G+M">G. M. Shahariar</a>, 
<a href="/search/cs?searchtype=author&query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+F+M">Faisal Muhammad Shah</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+S">Mohammad Shafiul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Mahbub%2C+M+S">Md. Shahriar Mahbub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02715" title="Abstract">arXiv:2308.02715</a> (replaced) [<a href="/pdf/2308.02715" title="Download PDF">pdf</a>, <a href="/format/2308.02715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluid Viscosity Prediction Leveraging Computer Vision and Robot  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J+H">Jong Hoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Dalwankar%2C+G+P">Gauri Pramod Dalwankar</a>, 
<a href="/search/cs?searchtype=author&query=Bartsch%2C+A">Alison Bartsch</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+A">Abraham George</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03982" title="Abstract">arXiv:2308.03982</a> (replaced) [<a href="/pdf/2308.03982" title="Download PDF">pdf</a>, <a href="/format/2308.03982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+M">Ming Nie</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yujing Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chaoqiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingqiu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04371" title="Abstract">arXiv:2308.04371</a> (replaced) [<a href="/pdf/2308.04371" title="Download PDF">pdf</a>, <a href="/format/2308.04371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cumulative Reasoning with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A+C">Andrew Chi-Chih Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04405" title="Abstract">arXiv:2308.04405</a> (replaced) [<a href="/pdf/2308.04405" title="Download PDF">pdf</a>, <a href="/format/2308.04405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear parametric models of viscoelastic fluid flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Oishi%2C+C+M">Cassio M. Oishi</a>, 
<a href="/search/physics?searchtype=author&query=Kaptanoglu%2C+A+A">Alan A. Kaptanoglu</a>, 
<a href="/search/physics?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>, 
<a href="/search/physics?searchtype=author&query=Brunton%2C+S+L">Steven L. Brunton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04774" title="Abstract">arXiv:2308.04774</a> (replaced) [<a href="/pdf/2308.04774" title="Download PDF">pdf</a>, <a href="/format/2308.04774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E$^3$-UAV: An Edge-based Energy-Efficient Object Detection System for  Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suo%2C+J">Jiashun Suo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingzhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weisong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Internet of Things Journal, Early Access 1-1 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05096" title="Abstract">arXiv:2308.05096</a> (replaced) [<a href="/pdf/2308.05096" title="Download PDF">pdf</a>, <a href="/format/2308.05096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Flexible Consensus and its Application to Ethereum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neu%2C+J">Joachim Neu</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srivatsan Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at the IEEE Symposium on Security &amp; Privacy 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05361" title="Abstract">arXiv:2308.05361</a> (replaced) [<a href="/pdf/2308.05361" title="Download PDF">pdf</a>, <a href="/format/2308.05361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WeaverBird: Empowering Financial Decision-Making with Large Language  Model, Knowledge Base, and Search Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongyan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qingyang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Caigao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shuo Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianshan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">James Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hongyuan Mei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06744" title="Abstract">arXiv:2308.06744</a> (replaced) [<a href="/pdf/2308.06744" title="Download PDF">pdf</a>, <a href="/format/2308.06744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Scaled Logit Distillation for Ternary Weight Generative Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sihwa Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Janghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sukjin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Du-Seong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+W">Wonyong Sung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwook Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06762" title="Abstract">arXiv:2308.06762</a> (replaced) [<a href="/pdf/2308.06762" title="Download PDF">pdf</a>, <a href="/format/2308.06762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance  from High-Quality Isotropic Volumes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Shijie Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xukun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhiming Cui</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Geng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, 5 tables, Fetal MRI, Brain tissue segmentation, Unsupervised domain adaptation, Cycle-consistency
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08693" title="Abstract">arXiv:2308.08693</a> (replaced) [<a href="/pdf/2308.08693" title="Download PDF">pdf</a>, <a href="/format/2308.08693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI planning in the imagination: High-level planning on learned abstract  search spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martin%2C+C">Carlos Martin</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09296" title="Abstract">arXiv:2308.09296</a> (replaced) [<a href="/pdf/2308.09296" title="Download PDF">pdf</a>, <a href="/format/2308.09296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARLA: Self-supervised Contrastive Representation Learning for Time  Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darban%2C+Z+Z">Zahra Zamanzadeh Darban</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+C+C">Charu C. Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11138" title="Abstract">arXiv:2308.11138</a> (replaced) [<a href="/pdf/2308.11138" title="Download PDF">pdf</a>, <a href="/format/2308.11138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLP-based detection of systematic anomalies among the narratives of  consumer complaints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gao%2C+P">Peiheng Gao</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+N">Ning Sun</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+X">Xuefeng Wang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zitikis%2C+R">Ri&#x10d;ardas Zitikis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computation and Language (cs.CL); Risk Management (q-fin.RM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11239" title="Abstract">arXiv:2308.11239</a> (replaced) [<a href="/pdf/2308.11239" title="Download PDF">pdf</a>, <a href="/format/2308.11239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and  Bootstrapped Self-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Silky Singh</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+S">Shripad Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+M">Mausoom Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+B">Balaji Krishnamurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to British Machine Vision Conference (BMVC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12502" title="Abstract">arXiv:2308.12502</a> (replaced) [<a href="/pdf/2308.12502" title="Download PDF">pdf</a>, <a href="/format/2308.12502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentivized Federated Learning and Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ningning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+E">Ermin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+R">Randall Berry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14015" title="Abstract">arXiv:2308.14015</a> (replaced) [<a href="/pdf/2308.14015" title="Download PDF">pdf</a>, <a href="/format/2308.14015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yi-Feng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+R">Rui-Yao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+D">Dai-Bao Hou</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+H">Hai-Zhong Weng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bo-Wen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Ke-Jie Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xing Lin</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen-Hui Li</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+C">Chao-Yuan Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14435" title="Abstract">arXiv:2308.14435</a> (replaced) [<a href="/pdf/2308.14435" title="Download PDF">pdf</a>, <a href="/format/2308.14435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Successful Researchers Reach the Self-Organized Critical Point?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Asim Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+B+K">Bikas K. Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Invited contribution to Galam Special Issue in Physics (MDPI, in press)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14831" title="Abstract">arXiv:2308.14831</a> (replaced) [<a href="/pdf/2308.14831" title="Download PDF">pdf</a>, <a href="/format/2308.14831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Dynamic Sparse Training: Exploring Algorithms  for Effective Model Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+M+O">Murat Onur Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+E+C+G">Elif Ceren Gok Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Sokar%2C+G">Ghada Sokar</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15452" title="Abstract">arXiv:2308.15452</a> (replaced) [<a href="/pdf/2308.15452" title="Download PDF">pdf</a>, <a href="/format/2308.15452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Do Program-of-Thoughts Work for Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+Z">Zhen Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yinuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guozhou Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15984" title="Abstract">arXiv:2308.15984</a> (replaced) [<a href="/pdf/2308.15984" title="Download PDF">pdf</a>, <a href="/format/2308.15984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Structure-from-Motion with Graph Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brynte%2C+L">Lucas Brynte</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias%2C+J+P">Jos&#xe9; Pedro Iglesias</a>, 
<a href="/search/cs?searchtype=author&query=Olsson%2C+C">Carl Olsson</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added additional metrics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16389" title="Abstract">arXiv:2308.16389</a> (replaced) [<a href="/pdf/2308.16389" title="Download PDF">pdf</a>, <a href="/format/2308.16389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Biased Journey of MSD_AUDIO.ZIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haven Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Keunwoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Modrzejewski%2C+M">Mateusz Modrzejewski</a>, 
<a href="/search/cs?searchtype=author&query=Liem%2C+C+C+S">Cynthia C. S. Liem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Late-breaking/Demo ISMIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computers and Society (cs.CY); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16458" title="Abstract">arXiv:2308.16458</a> (replaced) [<a href="/pdf/2308.16458" title="Download PDF">pdf</a>, <a href="/format/2308.16458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+B">Bill Qian</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rick Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiakang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gerstein%2C+M">Mark Gerstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01597" title="Abstract">arXiv:2309.01597</a> (replaced) [<a href="/pdf/2309.01597" title="Download PDF">pdf</a>, <a href="/format/2309.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the True Cost of Local Privacy: An Auditing Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcolezi%2C+H+H">H&#xe9;ber H. Arcolezi</a>, 
<a href="/search/cs?searchtype=author&query=Gambs%2C+S">S&#xe9;bastien Gambs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02539" title="Abstract">arXiv:2309.02539</a> (replaced) [<a href="/pdf/2309.02539" title="Download PDF">pdf</a>, <a href="/format/2309.02539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Bandsplit Neural Network for Cinematic Audio Source  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Watcharasupat%2C+K+N">Karn N. Watcharasupat</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chih-Wei Wu</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+Y">Yiwei Ding</a>, 
<a href="/search/eess?searchtype=author&query=Orife%2C+I">Iroro Orife</a>, 
<a href="/search/eess?searchtype=author&query=Hipple%2C+A+J">Aaron J. Hipple</a>, 
<a href="/search/eess?searchtype=author&query=Williams%2C+P+A">Phillip A. Williams</a>, 
<a href="/search/eess?searchtype=author&query=Kramer%2C+S">Scott Kramer</a>, 
<a href="/search/eess?searchtype=author&query=Lerch%2C+A">Alexander Lerch</a>, 
<a href="/search/eess?searchtype=author&query=Wolcott%2C+W">William Wolcott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IEEE Open Journal of Signal Processing (ICASSP 2024 Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03886" title="Abstract">arXiv:2309.03886</a> (replaced) [<a href="/pdf/2309.03886" title="Download PDF">pdf</a>, <a href="/format/2309.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIND: A Function Description Benchmark for Evaluating Interpretability  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwettmann%2C+S">Sarah Schwettmann</a>, 
<a href="/search/cs?searchtype=author&query=Shaham%2C+T+R">Tamar Rott Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Materzynska%2C+J">Joanna Materzynska</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+N">Neil Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04730" title="Abstract">arXiv:2309.04730</a> (replaced) [<a href="/pdf/2309.04730" title="Download PDF">pdf</a>, <a href="/format/2309.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Robotics Networks with Co-optimization of Drone Placement and  Air-Ground Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+M">Menghao Hu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Guoliang Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yingyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by VTC2023-Fall, 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05073" title="Abstract">arXiv:2309.05073</a> (replaced) [<a href="/pdf/2309.05073" title="Download PDF">pdf</a>, <a href="/format/2309.05073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeMan: Towards Benchmarking 3D Human Pose Estimation under Real-World  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+W">Wenbo Gou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Danqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yijun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yanqing Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 16 figures. Project page: <a href="https://wangjiongw.github.io/freeman/">this https URL</a> ; API: <a href="https://github.com/wangjiongw/FreeMan_API">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05751" title="Abstract">arXiv:2309.05751</a> (replaced) [<a href="/pdf/2309.05751" title="Download PDF">pdf</a>, <a href="/format/2309.05751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Intrinsic Dimension on Metric Learning under Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palias%2C+E">Efstratios Palias</a>, 
<a href="/search/cs?searchtype=author&query=Kab%C3%A1n%2C+A">Ata Kab&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05853" title="Abstract">arXiv:2309.05853</a> (replaced) [<a href="/pdf/2309.05853" title="Download PDF">pdf</a>, <a href="/ps/2309.05853" title="Download PostScript">ps</a>, <a href="/format/2309.05853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChemSpaceAL: An Efficient Active Learning Methodology Applied to  Protein-Specific Molecular Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kyro%2C+G+W">Gregory W. Kyro</a>, 
<a href="/search/cs?searchtype=author&query=Morgunov%2C+A">Anton Morgunov</a>, 
<a href="/search/cs?searchtype=author&query=Brent%2C+R+I">Rafael I. Brent</a>, 
<a href="/search/cs?searchtype=author&query=Batista%2C+V+S">Victor S. Batista</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06550" title="Abstract">arXiv:2309.06550</a> (replaced) [<a href="/pdf/2309.06550" title="Download PDF">pdf</a>, <a href="/format/2309.06550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Text Generation using Hypergraph Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+N">Natraj Raman</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sameena Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06647" title="Abstract">arXiv:2309.06647</a> (replaced) [<a href="/pdf/2309.06647" title="Download PDF">pdf</a>, <a href="/format/2309.06647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composing Control Barrier Functions for Complex Safety Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/eess?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IEEE Control System Letters (L-CSS) and the 2024 American Control Conference (ACC). 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06838" title="Abstract">arXiv:2309.06838</a> (replaced) [<a href="/pdf/2309.06838" title="Download PDF">pdf</a>, <a href="/ps/2309.06838" title="Download PostScript">ps</a>, <a href="/format/2309.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Machine Learning and Physics based Machine Learning approach  for prediction of peak temperature distribution in Additive Friction Stir  Deposition of Aluminium Alloy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Akshansh Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07064" title="Abstract">arXiv:2309.07064</a> (replaced) [<a href="/pdf/2309.07064" title="Download PDF">pdf</a>, <a href="/ps/2309.07064" title="Download PostScript">ps</a>, <a href="/format/2309.07064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Analysis of the Role of Artificial Intelligence and  Machine Learning in Modern Digital Forensics and Incident Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunsin%2C+D">Dipo Dunsin</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed C. Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Ouazzane%2C+K">Karim Ouazzane</a>, 
<a href="/search/cs?searchtype=author&query=Vassilev%2C+V">Vassil Vassilev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 2 post peer review Forensic Science International Digital Investigation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08248" title="Abstract">arXiv:2309.08248</a> (replaced) [<a href="/pdf/2309.08248" title="Download PDF">pdf</a>, <a href="/format/2309.08248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable Privacy-Preserving Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bontekoe%2C+T">Tariq Bontekoe</a>, 
<a href="/search/cs?searchtype=author&query=Karastoyanova%2C+D">Dimka Karastoyanova</a>, 
<a href="/search/cs?searchtype=author&query=Turkmen%2C+F">Fatih Turkmen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08420" title="Abstract">arXiv:2309.08420</a> (replaced) [<a href="/pdf/2309.08420" title="Download PDF">pdf</a>, <a href="/format/2309.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09039" title="Abstract">arXiv:2309.09039</a> (replaced) [<a href="/pdf/2309.09039" title="Download PDF">pdf</a>, <a href="/format/2309.09039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microscale 3-D Capacitance Tomography with a CMOS Sensor Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelatty%2C+M">Manar Abdelatty</a>, 
<a href="/search/cs?searchtype=author&query=Incandela%2C+J">Joseph Incandela</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kangping Hu</a>, 
<a href="/search/cs?searchtype=author&query=Larkin%2C+J+W">Joseph W. Larkin</a>, 
<a href="/search/cs?searchtype=author&query=Reda%2C+S">Sherief Reda</a>, 
<a href="/search/cs?searchtype=author&query=Rosenstein%2C+J+K">Jacob K. Rosenstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09126" title="Abstract">arXiv:2309.09126</a> (replaced) [<a href="/pdf/2309.09126" title="Download PDF">pdf</a>, <a href="/format/2309.09126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How much can ChatGPT really help Computational Biologists in  Programming?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+C+R">Chowdhury Rafeed Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Limsoon Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11759" title="Abstract">arXiv:2309.11759</a> (replaced) [<a href="/pdf/2309.11759" title="Download PDF">pdf</a>, <a href="/format/2309.11759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbol Detection for Coarsely Quantized OTFS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junwei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haochuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huimin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11991" title="Abstract">arXiv:2309.11991</a> (replaced) [<a href="/pdf/2309.11991" title="Download PDF">pdf</a>, <a href="/ps/2309.11991" title="Download PostScript">ps</a>, <a href="/format/2309.11991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Feature Importance of Games and Strategies via Shapley  Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+S">Satoru Fujii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing on The Advances in Computer Games conference (ACG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12566" title="Abstract">arXiv:2309.12566</a> (replaced) [<a href="/pdf/2309.12566" title="Download PDF">pdf</a>, <a href="/format/2309.12566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances in Path Integral Control for Trajectory Optimization: An  Overview in Theoretical and Algorithmic Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazim%2C+M">Muhammad Kazim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">JunGee Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Min-Gyeom Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+K">Kwang-Ki K. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12742" title="Abstract">arXiv:2309.12742</a> (replaced) [<a href="/pdf/2309.12742" title="Download PDF">pdf</a>, <a href="/format/2309.12742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make the U in UDA Matter: Invariant Consistency Learning for  Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhongqi Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qianru Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13132" title="Abstract">arXiv:2309.13132</a> (replaced) [<a href="/pdf/2309.13132" title="Download PDF">pdf</a>, <a href="/format/2309.13132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Calibration of Deep Neural Networks for Medical Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sambyal%2C+A+S">Abhishek Singh Sambyal</a>, 
<a href="/search/cs?searchtype=author&query=Niyaz%2C+U">Usma Niyaz</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+N+C">Narayanan C. Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Bathula%2C+D+R">Deepti R. Bathula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Computer Methods and Programs in Biomedicine Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13409" title="Abstract">arXiv:2309.13409</a> (replaced) [<a href="/pdf/2309.13409" title="Download PDF">pdf</a>, <a href="/ps/2309.13409" title="Download PostScript">ps</a>, <a href="/format/2309.13409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Series Forecasting: Unleashing Long-Term Dependencies with  Fractionally Differenced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+V">Vivek Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+S">Srashti Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Sukanya Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+G+K">Goutam Kumar Kundu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13550" title="Abstract">arXiv:2309.13550</a> (replaced) [<a href="/pdf/2309.13550" title="Download PDF">pdf</a>, <a href="/format/2309.13550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-AI: A Controllable &amp; Interpretable AI System for Decoding  Radiologists&#x27; Intense Focus for Accurate CXR Diagnoses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+T">Trong Thang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Brecheisen%2C+J">Jacob Brecheisen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13925" title="Abstract">arXiv:2309.13925</a> (replaced) [<a href="/pdf/2309.13925" title="Download PDF">pdf</a>, <a href="/format/2309.13925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Surveillance Video-and-Language Understanding: New Dataset,  Baselines, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tongtong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuange Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Z">Zhenzhen Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14608" title="Abstract">arXiv:2309.14608</a> (replaced) [<a href="/pdf/2309.14608" title="Download PDF">pdf</a>, <a href="/format/2309.14608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Demand-Supply Cooperative Responding Strategy in Power System with  High Renewable Energy Penetration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuanzheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Long%2C+X">Xinxin Long</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+Y">Yizhou Ding</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15191" title="Abstract">arXiv:2309.15191</a> (replaced) [<a href="/pdf/2309.15191" title="Download PDF">pdf</a>, <a href="/format/2309.15191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Optimization of Trajectories for Quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiatao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15325" title="Abstract">arXiv:2309.15325</a> (replaced) [<a href="/pdf/2309.15325" title="Download PDF">pdf</a>, <a href="/format/2309.15325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Operators for Accelerating Scientific Simulations and Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizzadenesheli%2C+K">Kamyar Azizzadenesheli</a>, 
<a href="/search/cs?searchtype=author&query=Kovachki%2C+N">Nikola Kovachki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu-Schiaffini%2C+M">Miguel Liu-Schiaffini</a>, 
<a href="/search/cs?searchtype=author&query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15400" title="Abstract">arXiv:2309.15400</a> (replaced) [<a href="/pdf/2309.15400" title="Download PDF">pdf</a>, <a href="/ps/2309.15400" title="Download PostScript">ps</a>, <a href="/format/2309.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable AI-Driven Discovery of Terrain-Precipitation Relationships  for Enhanced Climate Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/physics?searchtype=author&query=Zeng%2C+Z">Zhenzhong Zeng</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+N">Nina Li</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+D">Dongxiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16583" title="Abstract">arXiv:2309.16583</a> (replaced) [<a href="/pdf/2309.16583" title="Download PDF">pdf</a>, <a href="/format/2309.16583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+C">Chenguang Xi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16849" title="Abstract">arXiv:2309.16849</a> (replaced) [<a href="/pdf/2309.16849" title="Download PDF">pdf</a>, <a href="/format/2309.16849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Attention with Shifted Non-Local Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gauen%2C+K">Kent Gauen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Stanley Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17228" title="Abstract">arXiv:2309.17228</a> (replaced) [<a href="/pdf/2309.17228" title="Download PDF">pdf</a>, <a href="/format/2309.17228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roundoff error analysis of the double exponential formula-based method  for the matrix sign function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miyashita%2C+T">Tomoya Miyashita</a>, 
<a href="/search/math?searchtype=author&query=Kudo%2C+S">Shuhei Kudo</a>, 
<a href="/search/math?searchtype=author&query=Yamamoto%2C+Y">Yusaku Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00052" title="Abstract">arXiv:2310.00052</a> (replaced) [<a href="/pdf/2310.00052" title="Download PDF">pdf</a>, <a href="/format/2310.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI ensemble for signal detection of higher order gravitational wave  modes of quasi-circular, spinning, non-precessing binary black hole mergers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Tian%2C+M">Minyang Tian</a>, 
<a href="/search/astro-ph?searchtype=author&query=Huerta%2C+E+A">E. A. Huerta</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zheng%2C+H">Huihuo Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, 1 table; v2: 5 pages, 2 figures, 1 table, accepted to NeurIPS 2023 workshop on Machine Learning and the Physical Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI); General Relativity and Quantum Cosmology (gr-qc)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00119" title="Abstract">arXiv:2310.00119</a> (replaced) [<a href="/pdf/2310.00119" title="Download PDF">pdf</a>, <a href="/format/2310.00119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fewshot learning on global multimodal embeddings for earth observation  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allen%2C+M">Matt Allen</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+F">Francisco Dorr</a>, 
<a href="/search/cs?searchtype=author&query=Gallego-Mejia%2C+J+A">Joseph A. Gallego-Mejia</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ferrer%2C+L">Laura Mart&#xed;nez-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Jungbluth%2C+A">Anna Jungbluth</a>, 
<a href="/search/cs?searchtype=author&query=Kalaitzis%2C+F">Freddie Kalaitzis</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, presented on NeurIPS workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00749" title="Abstract">arXiv:2310.00749</a> (replaced) [<a href="/pdf/2310.00749" title="Download PDF">pdf</a>, <a href="/format/2310.00749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEED: Domain-Specific Data Curation With Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Madden%2C+S">Sam Madden</a>, 
<a href="/search/cs?searchtype=author&query=Kraska%2C+T">Tim Kraska</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zeyuan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Ju Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+N">Nan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zihui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cafarella%2C+M">Michael Cafarella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00826" title="Abstract">arXiv:2310.00826</a> (replaced) [<a href="/pdf/2310.00826" title="Download PDF">pdf</a>, <a href="/format/2310.00826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Masked Autoencoding for Reducing Label Requirements on SAR  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allen%2C+M">Matt Allen</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+F">Francisco Dorr</a>, 
<a href="/search/cs?searchtype=author&query=Gallego-Mejia%2C+J+A">Joseph A. Gallego-Mejia</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ferrer%2C+L">Laura Mart&#xed;nez-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Jungbluth%2C+A">Anna Jungbluth</a>, 
<a href="/search/cs?searchtype=author&query=Kalaitzis%2C+F">Freddie Kalaitzis</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00996" title="Abstract">arXiv:2310.00996</a> (replaced) [<a href="/pdf/2310.00996" title="Download PDF">pdf</a>, <a href="/format/2310.00996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARN: A Comprehensive Framework and Benchmark for Analogical Reasoning on  Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Sommerauer%2C+P">Pia Sommerauer</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01596" title="Abstract">arXiv:2310.01596</a> (replaced) [<a href="/pdf/2310.01596" title="Download PDF">pdf</a>, <a href="/format/2310.01596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImagenHub: Standardizing the evaluation of conditional image generation  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%2C+M">Max Ku</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianle Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Wenwen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01779" title="Abstract">arXiv:2310.01779</a> (replaced) [<a href="/pdf/2310.01779" title="Download PDF">pdf</a>, <a href="/format/2310.01779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HallE-Switch: Controlling Object Hallucination in Large Vision Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Bohan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shijia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Manling Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02048" title="Abstract">arXiv:2310.02048</a> (replaced) [<a href="/pdf/2310.02048" title="Download PDF">pdf</a>, <a href="/format/2310.02048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Generalisability of Self-Distillation with No Labels for  SAR-Based Vegetation Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ferrer%2C+L">Laura Mart&#xed;nez-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Jungbluth%2C+A">Anna Jungbluth</a>, 
<a href="/search/cs?searchtype=author&query=Gallego-Mejia%2C+J+A">Joseph A. Gallego-Mejia</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+M">Matt Allen</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+F">Francisco Dorr</a>, 
<a href="/search/cs?searchtype=author&query=Kalaitzis%2C+F">Freddie Kalaitzis</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02066" title="Abstract">arXiv:2310.02066</a> (replaced) [<a href="/pdf/2310.02066" title="Download PDF">pdf</a>, <a href="/format/2310.02066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De Novo Drug Design with Joint Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izdebski%2C+A">Adam Izdebski</a>, 
<a href="/search/cs?searchtype=author&query=Weglarz-Tomczak%2C+E">Ewelina Weglarz-Tomczak</a>, 
<a href="/search/cs?searchtype=author&query=Szczurek%2C+E">Ewa Szczurek</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J+M">Jakub M. Tomczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Generative AI and Biology Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02261" title="Abstract">arXiv:2310.02261</a> (replaced) [<a href="/pdf/2310.02261" title="Download PDF">pdf</a>, <a href="/format/2310.02261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Online Non-stochastic Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mhaisen%2C+N">Naram Mhaisen</a>, 
<a href="/search/math?searchtype=author&query=Iosifidis%2C+G">George Iosifidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02637" title="Abstract">arXiv:2310.02637</a> (replaced) [<a href="/pdf/2310.02637" title="Download PDF">pdf</a>, <a href="/format/2310.02637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Matching and Bottleneck Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabello%2C+S">Sergio Cabello</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siu-Wing Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheong%2C+O">Otfried Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Knauer%2C+C">Christian Knauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02980" title="Abstract">arXiv:2310.02980</a> (replaced) [<a href="/pdf/2310.02980" title="Download PDF">pdf</a>, <a href="/format/2310.02980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Train from Scratch: Fair Comparison of Long-Sequence Models  Requires Data-Driven Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amos%2C+I">Ido Amos</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03234" title="Abstract">arXiv:2310.03234</a> (replaced) [<a href="/pdf/2310.03234" title="Download PDF">pdf</a>, <a href="/format/2310.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+Q">Quanqi Hu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+D">Dixian Zhu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03513" title="Abstract">arXiv:2310.03513</a> (replaced) [<a href="/pdf/2310.03513" title="Download PDF">pdf</a>, <a href="/format/2310.03513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring DINO: Emergent Properties and Limitations for Synthetic  Aperture Radar Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallego-Mejia%2C+J+A">Joseph A. Gallego-Mejia</a>, 
<a href="/search/cs?searchtype=author&query=Jungbluth%2C+A">Anna Jungbluth</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ferrer%2C+L">Laura Mart&#xed;nez-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+M">Matt Allen</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+F">Francisco Dorr</a>, 
<a href="/search/cs?searchtype=author&query=Kalaitzis%2C+F">Freddie Kalaitzis</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04376" title="Abstract">arXiv:2310.04376</a> (replaced) [<a href="/pdf/2310.04376" title="Download PDF">pdf</a>, <a href="/format/2310.04376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-linear Time Dispersion of Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudo%2C+Y">Yuichi Sudo</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+M">Masahiro Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+J">Junya Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yonghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Masuzawa%2C+T">Toshimitsu Masuzawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04513" title="Abstract">arXiv:2310.04513</a> (replaced) [<a href="/pdf/2310.04513" title="Download PDF">pdf</a>, <a href="/ps/2310.04513" title="Download PostScript">ps</a>, <a href="/format/2310.04513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Data Security: Practices from Cybersecurity and Challenges  of Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Padmaksha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+J">Jaganmohan Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Lanus%2C+E">Erin Lanus</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+L">Laura Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+J">Jeremy Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05102" title="Abstract">arXiv:2310.05102</a> (replaced) [<a href="/pdf/2310.05102" title="Download PDF">pdf</a>, <a href="/ps/2310.05102" title="Download PostScript">ps</a>, <a href="/format/2310.05102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Federated Learning Algorithms Development Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Miroslav Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Marko Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Kastelan%2C+I">Ivan Kastelan</a>, 
<a href="/search/cs?searchtype=author&query=Djukic%2C+M">Miodrag Djukic</a>, 
<a href="/search/cs?searchtype=author&query=Basicevic%2C+I">Ilija Basicevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures, 5 algorithms, submitted to ECBS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Springer, LNCS 14390, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05953" title="Abstract">arXiv:2310.05953</a> (replaced) [<a href="/pdf/2310.05953" title="Download PDF">pdf</a>, <a href="/format/2310.05953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Spam URLs Using Machine Learning Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Odeh%2C+O+H">Omar Husni Odeh</a>, 
<a href="/search/cs?searchtype=author&query=Arram%2C+A">Anas Arram</a>, 
<a href="/search/cs?searchtype=author&query=Njoum%2C+M">Murad Njoum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07944" title="Abstract">arXiv:2310.07944</a> (replaced) [<a href="/e-print/2310.07944" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoRepo: A general framework for multi-modal LLM-based automated  construction reporting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+H">Hongxu Pu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xincong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Runhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We believe that keeping this version of the paper publicly available may lead to confusion or misinterpretation regarding our current research direction and findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09219" title="Abstract">arXiv:2310.09219</a> (replaced) [<a href="/pdf/2310.09219" title="Download PDF">pdf</a>, <a href="/format/2310.09219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Kelly is a Warm Person, Joseph is a Role Model&quot;: Gender Biases in  LLM-Generated Reference Letters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">George Pu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Garimella%2C+A">Aparna Garimella</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09718" title="Abstract">arXiv:2310.09718</a> (replaced) [<a href="/pdf/2310.09718" title="Download PDF">pdf</a>, <a href="/format/2310.09718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Effective Deep Multi-view Subspace Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuxiu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Caiming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09909" title="Abstract">arXiv:2310.09909</a> (replaced) [<a href="/pdf/2310.09909" title="Download PDF">pdf</a>, <a href="/format/2310.09909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for  Multimodal Medical Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qiaoyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weike Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weixiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09971" title="Abstract">arXiv:2310.09971</a> (replaced) [<a href="/pdf/2310.09971" title="Download PDF">pdf</a>, <a href="/format/2310.09971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+J">Jake Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Linxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10316" title="Abstract">arXiv:2310.10316</a> (replaced) [<a href="/pdf/2310.10316" title="Download PDF">pdf</a>, <a href="/ps/2310.10316" title="Download PostScript">ps</a>, <a href="/format/2310.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral representation of two-sided signals from $\ell_\infty$ and  applications to signal processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dokuchaev%2C+N">Nikolai Dokuchaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10737" title="Abstract">arXiv:2310.10737</a> (replaced) [<a href="/pdf/2310.10737" title="Download PDF">pdf</a>, <a href="/ps/2310.10737" title="Download PostScript">ps</a>, <a href="/format/2310.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft-output (SO) GRAND and long, low rate codes to outperform 5 LDPCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peihong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Medard%2C+M">Muriel Medard</a>, 
<a href="/search/cs?searchtype=author&query=Galligan%2C+K">Kevin Galligan</a>, 
<a href="/search/cs?searchtype=author&query=Duffy%2C+K+R">Ken R. Duffy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.05777">arXiv:2305.05777</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11211" title="Abstract">arXiv:2310.11211</a> (replaced) [<a href="/pdf/2310.11211" title="Download PDF">pdf</a>, <a href="/format/2310.11211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Fairness Surrogate Functions in Algorithmic Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11730" title="Abstract">arXiv:2310.11730</a> (replaced) [<a href="/e-print/2310.11730" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Heterogeneous Graph Neural Network for Privacy-preserving  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenchuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> some mistakes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11753" title="Abstract">arXiv:2310.11753</a> (replaced) [<a href="/pdf/2310.11753" title="Download PDF">pdf</a>, <a href="/format/2310.11753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias in Emotion Recognition with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wake%2C+N">Naoki Wake</a>, 
<a href="/search/cs?searchtype=author&query=Kanehira%2C+A">Atsushi Kanehira</a>, 
<a href="/search/cs?searchtype=author&query=Sasabuchi%2C+K">Kazuhiro Sasabuchi</a>, 
<a href="/search/cs?searchtype=author&query=Takamatsu%2C+J">Jun Takamatsu</a>, 
<a href="/search/cs?searchtype=author&query=Ikeuchi%2C+K">Katsushi Ikeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11829" title="Abstract">arXiv:2310.11829</a> (replaced) [<a href="/pdf/2310.11829" title="Download PDF">pdf</a>, <a href="/format/2310.11829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Graph Foundation Models: A Survey and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11994" title="Abstract">arXiv:2310.11994</a> (replaced) [<a href="/pdf/2310.11994" title="Download PDF">pdf</a>, <a href="/ps/2310.11994" title="Download PostScript">ps</a>, <a href="/format/2310.11994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral homogeneity cross frequencies can be a quality metric for the  large-scale resting EEG preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jie Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+N">Nicolas Langer</a>, 
<a href="/search/cs?searchtype=author&query=Bosch-Bayard%2C+J">Jorge Bosch-Bayard</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dezhong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Valdes-Sosa%2C+P+A">Pedro Antonio Valdes-Sosa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13135" title="Abstract">arXiv:2310.13135</a> (replaced) [<a href="/pdf/2310.13135" title="Download PDF">pdf</a>, <a href="/format/2310.13135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeTFuser: Light-weight End-to-end Transformer-Based Sensor Fusion for  Autonomous Driving with Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agand%2C+P">Pedram Agand</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavian%2C+M">Mohammad Mahdavian</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, 3 tables. CVPR Workshops (VCAD). 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13760" title="Abstract">arXiv:2310.13760</a> (replaced) [<a href="/pdf/2310.13760" title="Download PDF">pdf</a>, <a href="/format/2310.13760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Abstractiveness of Summarization Models through Calibrated  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Shalyminov%2C+I">Igor Shalyminov</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siffi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kaisheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP-Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14580" title="Abstract">arXiv:2310.14580</a> (replaced) [<a href="/pdf/2310.14580" title="Download PDF">pdf</a>, <a href="/format/2310.14580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic BPE for Speech Generation with Discrete Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures; submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14714" title="Abstract">arXiv:2310.14714</a> (replaced) [<a href="/pdf/2310.14714" title="Download PDF">pdf</a>, <a href="/format/2310.14714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BatteryML:An Open-source platform for Machine Learning on Battery  Degradation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiaofan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14746" title="Abstract">arXiv:2310.14746</a> (replaced) [<a href="/pdf/2310.14746" title="Download PDF">pdf</a>, <a href="/format/2310.14746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogenized lattice Boltzmann methods for fluid flow through porous  media -- part I: kinetic model derivation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Simonis%2C+S">Stephan Simonis</a>, 
<a href="/search/math?searchtype=author&query=Hafen%2C+N">Nicolas Hafen</a>, 
<a href="/search/math?searchtype=author&query=Je%C3%9Fberger%2C+J">Julius Je&#xdf;berger</a>, 
<a href="/search/math?searchtype=author&query=Dapelo%2C+D">Davide Dapelo</a>, 
<a href="/search/math?searchtype=author&query=Th%C3%A4ter%2C+G">Gudrun Th&#xe4;ter</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+M+J">Mathias J. Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15015" title="Abstract">arXiv:2310.15015</a> (replaced) [<a href="/pdf/2310.15015" title="Download PDF">pdf</a>, <a href="/ps/2310.15015" title="Download PostScript">ps</a>, <a href="/format/2310.15015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naghshzan%2C+A">AmirHossein Naghshzan</a>, 
<a href="/search/cs?searchtype=author&query=Guerrouj%2C+L">Latifa Guerrouj</a>, 
<a href="/search/cs?searchtype=author&query=Baysal%2C+O">Olga Baysal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15020" title="Abstract">arXiv:2310.15020</a> (replaced) [<a href="/pdf/2310.15020" title="Download PDF">pdf</a>, <a href="/format/2310.15020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariance is Key to Generalization: Examining the Role of  Representation in Sim-to-Real Transfer for Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhanxin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">David Hsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by the 18th International Symposium on Experimental Robotics (ISER 2023) and published within the Springer Proceedings in Advanced Robotics (SPAR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15400" title="Abstract">arXiv:2310.15400</a> (replaced) [<a href="/pdf/2310.15400" title="Download PDF">pdf</a>, <a href="/format/2310.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A practical approach to computing Lyapunov exponents of renewal and  delay equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breda%2C+D">Dimitri Breda</a>, 
<a href="/search/math?searchtype=author&query=Liessi%2C+D">Davide Liessi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15896" title="Abstract">arXiv:2310.15896</a> (replaced) [<a href="/pdf/2310.15896" title="Download PDF">pdf</a>, <a href="/format/2310.15896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs  with Multi-turn Health Conversations Polished by ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaofen Xing</a>, 
<a href="/search/cs?searchtype=author&query=zheng%2C+h">huimin zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhipei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jieling Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangmin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16267" title="Abstract">arXiv:2310.16267</a> (replaced) [<a href="/pdf/2310.16267" title="Download PDF">pdf</a>, <a href="/format/2310.16267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student Classroom Behavior Detection based on Spatio-Temporal Network  and Multi-Model Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.02522">arXiv:2310.02522</a>; text overlap with <a href="/abs/2306.03318">arXiv:2306.03318</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17378" title="Abstract">arXiv:2310.17378</a> (replaced) [<a href="/pdf/2310.17378" title="Download PDF">pdf</a>, <a href="/format/2310.17378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization dependent generalization bound for ReLU networks based on  sensitivity in the tangent bundle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%A1cz%2C+D">D&#xe1;niel R&#xe1;cz</a>, 
<a href="/search/cs?searchtype=author&query=Petreczky%2C+M">Mih&#xe1;ly Petreczky</a>, 
<a href="/search/cs?searchtype=author&query=Csert%C3%A1n%2C+A">Andr&#xe1;s Csert&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Dar%C3%B3czy%2C+B">B&#xe1;lint Dar&#xf3;czy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, OPT2023: 15th Annual Workshop on Optimization for Machine Learning at the 37th NeurIPS 2023, New Orleans, LA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17769" title="Abstract">arXiv:2310.17769</a> (replaced) [<a href="/pdf/2310.17769" title="Download PDF">pdf</a>, <a href="/format/2310.17769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Contract AI: Aligning AI Assistants with Implicit Group Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fr%C3%A4nken%2C+J">Jan-Philipp Fr&#xe4;nken</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+S">Sam Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peixuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+K">Kanishk Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Arumugam%2C+D">Dilip Arumugam</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Jared Moore</a>, 
<a href="/search/cs?searchtype=author&query=Tamkin%2C+A">Alex Tamkin</a>, 
<a href="/search/cs?searchtype=author&query=Gerstenberg%2C+T">Tobias Gerstenberg</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SoLaR NeurIPS 2023 Workshop (<a href="https://solar-neurips.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18116" title="Abstract">arXiv:2310.18116</a> (replaced) [<a href="/pdf/2310.18116" title="Download PDF">pdf</a>, <a href="/format/2310.18116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Unsupervised Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salmon%2C+B">Benjamin Salmon</a>, 
<a href="/search/cs?searchtype=author&query=Krull%2C+A">Alexander Krull</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV) Workshops, 2023, pp. 3838-3845
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18144" title="Abstract">arXiv:2310.18144</a> (replaced) [<a href="/pdf/2310.18144" title="Download PDF">pdf</a>, <a href="/format/2310.18144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Intrinsic Exploration by Creating Stationary Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castanyer%2C+R+C">Roger Creus Castanyer</a>, 
<a href="/search/cs?searchtype=author&query=Romoff%2C+J">Joshua Romoff</a>, 
<a href="/search/cs?searchtype=author&query=Berseth%2C+G">Glen Berseth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ALOE 2023 Workshop at NeurIPS. Under Review at ICLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18534" title="Abstract">arXiv:2310.18534</a> (replaced) [<a href="/pdf/2310.18534" title="Download PDF">pdf</a>, <a href="/format/2310.18534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Time Scale World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaj%2C+V">Vaisakh Shaj</a>, 
<a href="/search/cs?searchtype=author&query=Zadeh%2C+S+G">Saleh Gholam Zadeh</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+O">Ozan Demir</a>, 
<a href="/search/cs?searchtype=author&query=Douat%2C+L+R">Luiz Ricardo Douat</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as spotlight at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18940" title="Abstract">arXiv:2310.18940</a> (replaced) [<a href="/pdf/2310.18940" title="Download PDF">pdf</a>, <a href="/format/2310.18940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Agents with Reinforcement Learning for Strategic Play in the  Werewolf Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zelai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18961" title="Abstract">arXiv:2310.18961</a> (replaced) [<a href="/pdf/2310.18961" title="Download PDF">pdf</a>, <a href="/format/2310.18961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19112" title="Abstract">arXiv:2310.19112</a> (replaced) [<a href="/pdf/2310.19112" title="Download PDF">pdf</a>, <a href="/format/2310.19112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient IoT Inference via Context-Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastikerdar%2C+M+M">Mohammad Mehdi Rastikerdar</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shiwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hui Guan</a>, 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+D">Deepak Ganesan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19308" title="Abstract">arXiv:2310.19308</a> (replaced) [<a href="/pdf/2310.19308" title="Download PDF">pdf</a>, <a href="/format/2310.19308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free from Bellman Completeness: Trajectory Stitching via Model-based  Return-conditioned Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhaoyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuning Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Runlong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qiwen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon Shaolei Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19702" title="Abstract">arXiv:2310.19702</a> (replaced) [<a href="/pdf/2310.19702" title="Download PDF">pdf</a>, <a href="/format/2310.19702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank and Select on Degenerate Strings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bille%2C+P">Philip Bille</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B8rtz%2C+I+L">Inge Li G&#xf8;rtz</a>, 
<a href="/search/cs?searchtype=author&query=Stordalen%2C+T">Tord Stordalen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19788" title="Abstract">arXiv:2310.19788</a> (replaced) [<a href="/pdf/2310.19788" title="Download PDF">pdf</a>, <a href="/format/2310.19788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case Optimal Multi-Armed Gaussian Best Arm Identification with a  Fixed Budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00176" title="Abstract">arXiv:2311.00176</a> (replaced) [<a href="/pdf/2311.00176" title="Download PDF">pdf</a>, <a href="/format/2311.00176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChipNeMo: Domain-Adapted LLMs for Chip Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ene%2C+T">Teodor-Dumitru Ene</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+R">Robert Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chris Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Pinckney%2C+N">Nathaniel Pinckney</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Rongjian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Alben%2C+J">Jonah Alben</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+H">Himyanshu Anand</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sanmitra Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Bayraktaroglu%2C+I">Ismet Bayraktaroglu</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskaran%2C+B">Bonita Bhaskaran</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+A">Arjun Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Clay%2C+S">Sharon Clay</a>, 
<a href="/search/cs?searchtype=author&query=Dally%2C+B">Bill Dally</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+L">Laura Dang</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+P">Parikshit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Dhodhi%2C+S">Siddhanth Dhodhi</a>, 
<a href="/search/cs?searchtype=author&query=Halepete%2C+S">Sameer Halepete</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+E">Eric Hill</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiashang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sumit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Khailany%2C+B">Brucek Khailany</a>, 
<a href="/search/cs?searchtype=author&query=Kokai%2C+G">George Kokai</a>, 
<a href="/search/cs?searchtype=author&query=Kunal%2C+K">Kishor Kunal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lind%2C+C">Charley Lind</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Oberman%2C+S">Stuart Oberman</a>, 
<a href="/search/cs?searchtype=author&query=Omar%2C+S">Sujeet Omar</a>, 
<a href="/search/cs?searchtype=author&query=Pratty%2C+S">Sreedhar Pratty</a>, 
<a href="/search/cs?searchtype=author&query=Raiman%2C+J">Jonathan Raiman</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Ambar Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhengjiang Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hanfei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Suthar%2C+P+P">Pratik P Suthar</a>, 
<a href="/search/cs?searchtype=author&query=Tej%2C+V">Varun Tej</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+W">Walker Turner</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaizhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00226" title="Abstract">arXiv:2311.00226</a> (replaced) [<a href="/pdf/2311.00226" title="Download PDF">pdf</a>, <a href="/format/2311.00226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers are Efficient In-Context Estimators for Wireless  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajagopalan%2C+V">Vicram Rajagopalan</a>, 
<a href="/search/eess?searchtype=author&query=Kunde%2C+V+T">Vishnu Teja Kunde</a>, 
<a href="/search/eess?searchtype=author&query=Valmeekam%2C+C+S+K">Chandra Shekhara Kaushik Valmeekam</a>, 
<a href="/search/eess?searchtype=author&query=Narayanan%2C+K">Krishna Narayanan</a>, 
<a href="/search/eess?searchtype=author&query=Shakkottai%2C+S">Srinivas Shakkottai</a>, 
<a href="/search/eess?searchtype=author&query=Kalathil%2C+D">Dileep Kalathil</a>, 
<a href="/search/eess?searchtype=author&query=Chamberland%2C+J">Jean-Francois Chamberland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 2 tables, preprint; abstract and references modified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00587" title="Abstract">arXiv:2311.00587</a> (replaced) [<a href="/pdf/2311.00587" title="Download PDF">pdf</a>, <a href="/format/2311.00587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crosslingual Retrieval Augmented In-context Learning for Bangla
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+E">Ercong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Sheng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In The 1st Bangla Language Processing (BLP) Workshop, held in conjunction with The Conference on Empirical Methods in Natural Language Processing (EMNLP), December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00611" title="Abstract">arXiv:2311.00611</a> (replaced) [<a href="/pdf/2311.00611" title="Download PDF">pdf</a>, <a href="/ps/2311.00611" title="Download PostScript">ps</a>, <a href="/format/2311.00611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Threshold Selection for Set Membership State Estimation with  Quantized Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Casini%2C+M">Marco Casini</a>, 
<a href="/search/eess?searchtype=author&query=Garulli%2C+A">Andrea Garulli</a>, 
<a href="/search/eess?searchtype=author&query=Vicino%2C+A">Antonio Vicino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00690" title="Abstract">arXiv:2311.00690</a> (replaced) [<a href="/pdf/2311.00690" title="Download PDF">pdf</a>, <a href="/format/2311.00690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What User Behaviors Make the Differences During the Process of Visual  Analytics?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zekun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Doroudian%2C+S">Shahin Doroudian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+A">Aidong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version corrects the issues of previous versions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00854" title="Abstract">arXiv:2311.00854</a> (replaced) [<a href="/pdf/2311.00854" title="Download PDF">pdf</a>, <a href="/format/2311.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $2$-Fault-Tolerant Strong Connectivity Oracles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiadis%2C+L">Loukas Georgiadis</a>, 
<a href="/search/cs?searchtype=author&query=Kosinas%2C+E">Evangelos Kosinas</a>, 
<a href="/search/cs?searchtype=author&query=Tsokaktsis%2C+D">Daniel Tsokaktsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version to appear in the proceedings of ALENEX 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01619" title="Abstract">arXiv:2311.01619</a> (replaced) [<a href="/pdf/2311.01619" title="Download PDF">pdf</a>, <a href="/format/2311.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InsPLAD: A Dataset and Benchmark for Power Line Asset Inspection in UAV  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+A+L+B+V+e">Andr&#xe9; Luiz Buarque Vieira e Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Castro+Felix%2C+H">Heitor de Castro Felix</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F+P+M">Franscisco Paulo Magalh&#xe3;es Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Teichrieb%2C+V">Veronica Teichrieb</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+M+M+d">Michel Mozinho dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Santiago%2C+H">Hemir Santiago</a>, 
<a href="/search/cs?searchtype=author&query=Sgotti%2C+V">Virginia Sgotti</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+H+L">Henrique Lott Neto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an original manuscript of an article published by Taylor &amp; Francis in the International Journal of Remote Sensing on 29 Nov 2023, available online: <a href="https://doi.org/10.1080/01431161.2023.2283900">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03255" title="Abstract">arXiv:2311.03255</a> (replaced) [<a href="/pdf/2311.03255" title="Download PDF">pdf</a>, <a href="/format/2311.03255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Arrangements of Spherical Geodesics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04472" title="Abstract">arXiv:2311.04472</a> (replaced) [<a href="/pdf/2311.04472" title="Download PDF">pdf</a>, <a href="/ps/2311.04472" title="Download PostScript">ps</a>, <a href="/format/2311.04472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Advanced Aerial Mobility -- An End-to-end Autonomy Framework  for UAVs and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Sakshi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Palanisamy%2C+P">Praveen Palanisamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04625" title="Abstract">arXiv:2311.04625</a> (replaced) [<a href="/pdf/2311.04625" title="Download PDF">pdf</a>, <a href="/format/2311.04625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Summarization and Evaluation of Feature Refinement  Modules for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Li Shang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05076" title="Abstract">arXiv:2311.05076</a> (replaced) [<a href="/pdf/2311.05076" title="Download PDF">pdf</a>, <a href="/format/2311.05076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating diversion and treatment policies for opioid use disorder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+V+M">Veronica M. White</a>, 
<a href="/search/cs?searchtype=author&query=Albert%2C+L+A">Laura A. Albert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05435" title="Abstract">arXiv:2311.05435</a> (replaced) [<a href="/pdf/2311.05435" title="Download PDF">pdf</a>, <a href="/ps/2311.05435" title="Download PostScript">ps</a>, <a href="/format/2311.05435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parkinson&#x27;s Disease Detection through Vocal Biomarkers and Advanced  Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Md Abu Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Tayaba%2C+M">Maliha Tayaba</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+T">MD Tanvir Islam</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+M+E+U+I">Md Eyasin Ul Islam Pavel</a>, 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+T">Md Tuhin Mia</a>, 
<a href="/search/cs?searchtype=author&query=Ayon%2C+E+H">Eftekhar Hossain Ayon</a>, 
<a href="/search/cs?searchtype=author&query=Nob%2C+N">Nur Nob</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+B+P">Bishnu Padh Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05966" title="Abstract">arXiv:2311.05966</a> (replaced) [<a href="/pdf/2311.05966" title="Download PDF">pdf</a>, <a href="/ps/2311.05966" title="Download PostScript">ps</a>, <a href="/format/2311.05966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Proposal for a Lean and Functional Delivery versus Payment across two  Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fries%2C+C+P">Christian P. Fries</a>, 
<a href="/search/cs?searchtype=author&query=Kohl-Landgraf%2C+P">Peter Kohl-Landgraf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06477" title="Abstract">arXiv:2311.06477</a> (replaced) [<a href="/pdf/2311.06477" title="Download PDF">pdf</a>, <a href="/format/2311.06477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report of the 1st Workshop on Generative AI and Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>, 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Christopher Callison-Burch</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Mireshghallah%2C+N">Niloofar Mireshghallah</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Mimno%2C+D">David Mimno</a>, 
<a href="/search/cs?searchtype=author&query=Choksi%2C+M+Z">Madiha Zahrah Choksi</a>, 
<a href="/search/cs?searchtype=author&query=Balkin%2C+J+M">Jack M. Balkin</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+D">Deep Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Gipson%2C+B">Bryant Gipson</a>, 
<a href="/search/cs?searchtype=author&query=Guadamuz%2C+A">Andres Guadamuz</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+S+L">Swee Leng Harris</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+A+Z">Abigail Z. Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Joh%2C+E">Elizabeth Joh</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+G">Gautam Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Lemley%2C+M">Mark Lemley</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+C">Cass Matthews</a>, 
<a href="/search/cs?searchtype=author&query=McLeavey%2C+C">Christine McLeavey</a>, 
<a href="/search/cs?searchtype=author&query=McSherry%2C+C">Corynne McSherry</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Ohm%2C+P">Paul Ohm</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+A">Adam Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Rubin%2C+T">Tom Rubin</a>, 
<a href="/search/cs?searchtype=author&query=Samuelson%2C+P">Pamela Samuelson</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+L">Ludwig Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Vaccaro%2C+K">Kristen Vaccaro</a>, 
<a href="/search/cs?searchtype=author&query=Villa%2C+L">Luis Villa</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Felix Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zeide%2C+E">Elana Zeide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06595" title="Abstract">arXiv:2311.06595</a> (replaced) [<a href="/pdf/2311.06595" title="Download PDF">pdf</a>, <a href="/format/2311.06595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Classification to Generation: Insights into Crosslingual Retrieval  Augmented ICL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+E">Ercong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Sheng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In The Workshop on Instruction Tuning and Instruction Following, held in conjunction with The Conference on NeurIPS 2023, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06650" title="Abstract">arXiv:2311.06650</a> (replaced) [<a href="/pdf/2311.06650" title="Download PDF">pdf</a>, <a href="/format/2311.06650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristic Optimal Transport in Branching Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Andrecut%2C+M">M. Andrecut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06851" title="Abstract">arXiv:2311.06851</a> (replaced) [<a href="/pdf/2311.06851" title="Download PDF">pdf</a>, <a href="/format/2311.06851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Textual Normalization for Hate Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+T">Anh Thi-Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+H">Dung Ha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+T">Nguyet Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+K+T">Khanh Thanh-Duy Ho</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to present at 2023 International Conference on Intelligent Systems Design and Applications (ISDA2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06906" title="Abstract">arXiv:2311.06906</a> (replaced) [<a href="/pdf/2311.06906" title="Download PDF">pdf</a>, <a href="/ps/2311.06906" title="Download PostScript">ps</a>, <a href="/format/2311.06906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle-based algorithm for stochastic optimal control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07265" title="Abstract">arXiv:2311.07265</a> (replaced) [<a href="/pdf/2311.07265" title="Download PDF">pdf</a>, <a href="/format/2311.07265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quotient Space Quantum Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Xia%2C+J">Jing-Lei Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08105" title="Abstract">arXiv:2311.08105</a> (replaced) [<a href="/pdf/2311.08105" title="Download PDF">pdf</a>, <a href="/format/2311.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiLoCo: Distributed Low-Communication Training of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Douillard%2C+A">Arthur Douillard</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qixuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Rusu%2C+A+A">Andrei A. Rusu</a>, 
<a href="/search/cs?searchtype=author&query=Chhaparia%2C+R">Rachita Chhaparia</a>, 
<a href="/search/cs?searchtype=author&query=Donchev%2C+Y">Yani Donchev</a>, 
<a href="/search/cs?searchtype=author&query=Kuncoro%2C+A">Adhiguna Kuncoro</a>, 
<a href="/search/cs?searchtype=author&query=Ranzato%2C+M">Marc&#x27;Aurelio Ranzato</a>, 
<a href="/search/cs?searchtype=author&query=Szlam%2C+A">Arthur Szlam</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiajun Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08239" title="Abstract">arXiv:2311.08239</a> (replaced) [<a href="/pdf/2311.08239" title="Download PDF">pdf</a>, <a href="/format/2311.08239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Physics-Inspired Regularization for Medical Image Registration  with Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reithmeir%2C+A">Anna Reithmeir</a>, 
<a href="/search/eess?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>, 
<a href="/search/eess?searchtype=author&query=Zimmer%2C+V+A">Veronika A. Zimmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript accepted at SPIE Medical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08843" title="Abstract">arXiv:2311.08843</a> (replaced) [<a href="/pdf/2311.08843" title="Download PDF">pdf</a>, <a href="/format/2311.08843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Video Relighting Using Casual Light Stage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+M">Jun Myeong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Christman%2C+M">Max Christman</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+R">Roni Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09018" title="Abstract">arXiv:2311.09018</a> (replaced) [<a href="/pdf/2311.09018" title="Download PDF">pdf</a>, <a href="/ps/2311.09018" title="Download PostScript">ps</a>, <a href="/format/2311.09018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Foundation of Distributionally Robust Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+N">Nian Si</a>, 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+J">Jose Blanchet</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10292" title="Abstract">arXiv:2311.10292</a> (replaced) [<a href="/pdf/2311.10292" title="Download PDF">pdf</a>, <a href="/format/2311.10292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realization of a programmable multi-purpose photonic quantum memory with  over-thousand qubit manipulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+J">Jixuan Shi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cui%2C+Z">Zhaibin Cui</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+Y">Yukai Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Duan%2C+L">Luming Duan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pu%2C+Y">Yunfei Pu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10538" title="Abstract">arXiv:2311.10538</a> (replaced) [<a href="/pdf/2311.10538" title="Download PDF">pdf</a>, <a href="/format/2311.10538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Language Model Agents Safely in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naihin%2C+S">Silen Naihin</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+M">Marc Green</a>, 
<a href="/search/cs?searchtype=author&query=Hamadi%2C+M">Merwane Hamadi</a>, 
<a href="/search/cs?searchtype=author&query=Swift%2C+C">Craig Swift</a>, 
<a href="/search/cs?searchtype=author&query=Schonholtz%2C+D">Douglas Schonholtz</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10637" title="Abstract">arXiv:2311.10637</a> (replaced) [<a href="/pdf/2311.10637" title="Download PDF">pdf</a>, <a href="/format/2311.10637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Rectangles Induced by Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashur%2C+S">Stav Ashur</a>, 
<a href="/search/cs?searchtype=author&query=Har-Peled%2C+S">Sariel Har-Peled</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10777" title="Abstract">arXiv:2311.10777</a> (replaced) [<a href="/pdf/2311.10777" title="Download PDF">pdf</a>, <a href="/ps/2311.10777" title="Download PostScript">ps</a>, <a href="/format/2311.10777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,  Methods, and Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y+C">Yan Cathy Hua</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Taskova%2C+K">Katerina Taskova</a>, 
<a href="/search/cs?searchtype=author&query=Wicker%2C+J">J&#xf6;rg Wicker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11284" title="Abstract">arXiv:2311.11284</a> (replaced) [<a href="/pdf/2311.11284" title="Download PDF">pdf</a>, <a href="/format/2311.11284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval  Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yixun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiantao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work. Our code will be available at: <a href="https://github.com/EnVision-Research/LucidDreamer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11629" title="Abstract">arXiv:2311.11629</a> (replaced) [<a href="/pdf/2311.11629" title="Download PDF">pdf</a>, <a href="/format/2311.11629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Realistic Counterfactuals for Retinal Fundus and OCT Images  using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ilanchezian%2C+I">Indu Ilanchezian</a>, 
<a href="/search/cs?searchtype=author&query=Boreiko%2C+V">Valentyn Boreiko</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChlewein%2C+L">Laura K&#xfc;hlewein</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ayhan%2C+M+S">Murat Se&#xe7;kin Ayhan</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+L">Lisa Koch</a>, 
<a href="/search/cs?searchtype=author&query=Berens%2C+P">Philipp Berens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11824" title="Abstract">arXiv:2311.11824</a> (replaced) [<a href="/pdf/2311.11824" title="Download PDF">pdf</a>, <a href="/format/2311.11824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Graph Collaborative Filtering Using Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehkordi%2C+N+S+F">Narges Sadat Fazeli Dehkordi</a>, 
<a href="/search/cs?searchtype=author&query=Zare%2C+H">Hadi Zare</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+P">Parham Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Jalili%2C+M">Mahdi Jalili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for PAKDD2024 conference,12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12275" title="Abstract">arXiv:2311.12275</a> (replaced) [<a href="/pdf/2311.12275" title="Download PDF">pdf</a>, <a href="/format/2311.12275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling On-Device Large Language Model Personalization with  Self-Supervised Data Selection and Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Ruiyang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhenge Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ahmed Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingtong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12553" title="Abstract">arXiv:2311.12553</a> (replaced) [<a href="/pdf/2311.12553" title="Download PDF">pdf</a>, <a href="/format/2311.12553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoVer-UNet: Accelerating HoVerNet with UNet-based multi-class nuclei  segmentation via knowledge distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tommasino%2C+C">Cristian Tommasino</a>, 
<a href="/search/eess?searchtype=author&query=Russo%2C+C">Cristiano Russo</a>, 
<a href="/search/eess?searchtype=author&query=Rinaldi%2C+A+M">Antonio Maria Rinaldi</a>, 
<a href="/search/eess?searchtype=author&query=Ciompi%2C+F">Francesco Ciompi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, submitted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12589" title="Abstract">arXiv:2311.12589</a> (replaced) [<a href="/e-print/2311.12589" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Source-Free Target Adaptation with Vision Transformers  Leveraging Domain Representation Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sawhney%2C+G">Gauransh Sawhney</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Adeel Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiechao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Saleem%2C+K">Khalid Saleem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Requesting withdrawal due to significant overlap with prior research that wasn't appropriately acknowledged in our manuscript. The decision is made to uphold academic integrity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12713" title="Abstract">arXiv:2311.12713</a> (replaced) [<a href="/pdf/2311.12713" title="Download PDF">pdf</a>, <a href="/format/2311.12713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alpha Zero for Physics: Application of Symbolic Regression with Alpha  Zero to find the analytical methods in physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Michishita%2C+Y">Yoshihiro Michishita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, and source codes are uploaded on Git Hub
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12775" title="Abstract">arXiv:2311.12775</a> (replaced) [<a href="/pdf/2311.12775" title="Download PDF">pdf</a>, <a href="/format/2311.12775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh  Reconstruction and High-Quality Mesh Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%C3%A9don%2C+A">Antoine Gu&#xe9;don</a>, 
<a href="/search/cs?searchtype=author&query=Lepetit%2C+V">Vincent Lepetit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We identified a minor typographical error in Equation 6; We updated the paper accordingly. Project Webpage: <a href="https://anttwo.github.io/sugar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12919" title="Abstract">arXiv:2311.12919</a> (replaced) [<a href="/pdf/2311.12919" title="Download PDF">pdf</a>, <a href="/format/2311.12919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPOT! Revisiting Video-Language Models for Event Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Jinhe Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13162" title="Abstract">arXiv:2311.13162</a> (replaced) [<a href="/pdf/2311.13162" title="Download PDF">pdf</a>, <a href="/format/2311.13162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-L Most Influential Community Detection Over Social Networks  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiang Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13398" title="Abstract">arXiv:2311.13398</a> (replaced) [<a href="/pdf/2311.13398" title="Download PDF">pdf</a>, <a href="/format/2311.13398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jaeyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jeongtaek Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures; Project page: robot0321.github.io/DepthRegGS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13743" title="Abstract">arXiv:2311.13743</a> (replaced) [<a href="/pdf/2311.13743" title="Download PDF">pdf</a>, <a href="/format/2311.13743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and  Character Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yu%2C+Y">Yangyang Yu</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+H">Haohang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/q-fin?searchtype=author&query=Jiang%2C+Y">Yuechen Jiang</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+D">Denghui Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Liu%2C+R">Rong Liu</a>, 
<a href="/search/q-fin?searchtype=author&query=Suchow%2C+J+W">Jordan W. Suchow</a>, 
<a href="/search/q-fin?searchtype=author&query=Khashanah%2C+K">Khaldoun Khashanah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13862" title="Abstract">arXiv:2311.13862</a> (replaced) [<a href="/e-print/2311.13862" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reduced basis warm-start iterative solver for the parameterized  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hou%2C+S">Shijin Hou</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yanlai Chen</a>, 
<a href="/search/math?searchtype=author&query=Xia%2C+Y">Yinhua Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The authors believe that the paper requires significant revision, which may take a considerable amount of time. Therefore, we would like to withdraw the paper in its current state. Thank you for your assistance!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14168" title="Abstract">arXiv:2311.14168</a> (replaced) [<a href="/pdf/2311.14168" title="Download PDF">pdf</a>, <a href="/format/2311.14168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Policy Learning for Linear Quadratic Control with Entropy  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14648" title="Abstract">arXiv:2311.14648</a> (replaced) [<a href="/pdf/2311.14648" title="Download PDF">pdf</a>, <a href="/format/2311.14648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Language Models Must Hallucinate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Vempala%2C+S+S">Santosh S. Vempala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14743" title="Abstract">arXiv:2311.14743</a> (replaced) [<a href="/pdf/2311.14743" title="Download PDF">pdf</a>, <a href="/format/2311.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze  Foundation Models Under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pikus%2C+B">Ben Pikus</a>, 
<a href="/search/cs?searchtype=author&query=LeVine%2C+W">Will LeVine</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14750" title="Abstract">arXiv:2311.14750</a> (replaced) [<a href="/pdf/2311.14750" title="Download PDF">pdf</a>, <a href="/format/2311.14750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute-Aware Representation Rectification for Generalized Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhijie Rao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaocheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14836" title="Abstract">arXiv:2311.14836</a> (replaced) [<a href="/pdf/2311.14836" title="Download PDF">pdf</a>, <a href="/format/2311.14836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Custom Data Augmentation for low resource ASR using Bark and  Retrieval-Based Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamble%2C+A">Anand Kamble</a>, 
<a href="/search/cs?searchtype=author&query=Tathe%2C+A">Aniket Tathe</a>, 
<a href="/search/cs?searchtype=author&query=Kumbharkar%2C+S">Suyash Kumbharkar</a>, 
<a href="/search/cs?searchtype=author&query=Bhandare%2C+A">Atharva Bhandare</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A+C">Anirban C. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14916" title="Abstract">arXiv:2311.14916</a> (replaced) [<a href="/pdf/2311.14916" title="Download PDF">pdf</a>, <a href="/format/2311.14916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Game-Theoretic Planner for Automated Lane Merging with  Multi-Modal Behavior Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Luyao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+S">Shaohang Han</a>, 
<a href="/search/eess?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15112" title="Abstract">arXiv:2311.15112</a> (replaced) [<a href="/pdf/2311.15112" title="Download PDF">pdf</a>, <a href="/format/2311.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everybody Needs a Little HELP: Explaining Graphs via Hierarchical  Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%BCr%C3%9F%2C+J">Jonas J&#xfc;r&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Magister%2C+L+C">Lucie Charlotte Magister</a>, 
<a href="/search/cs?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Simidjievski%2C+N">Nikola Simidjievski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 16 figures, accepted at the NeurIPS 2023 GLFrontiers Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15209" title="Abstract">arXiv:2311.15209</a> (replaced) [<a href="/pdf/2311.15209" title="Download PDF">pdf</a>, <a href="/format/2311.15209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> See and Think: Embodied Agent in Virtual Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhonghan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boyi%2C+L">Li Boyi</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shengyu Hao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. First three authors contribute equally to this work. Project Website <a href="https://rese1f.github.io/STEVE/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15500" title="Abstract">arXiv:2311.15500</a> (replaced) [<a href="/pdf/2311.15500" title="Download PDF">pdf</a>, <a href="/format/2311.15500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function-constrained Program Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajali%2C+P">Patrick Hajali</a>, 
<a href="/search/cs?searchtype=author&query=Budvytis%2C+I">Ignas Budvytis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 2023 NeurIPS R0-Fomo Workshop; corrected typo on fig 1 caption
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15565" title="Abstract">arXiv:2311.15565</a> (replaced) [<a href="/pdf/2311.15565" title="Download PDF">pdf</a>, <a href="/ps/2311.15565" title="Download PostScript">ps</a>, <a href="/format/2311.15565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing  AI-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+F">Finbarrs Oketunji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15786" title="Abstract">arXiv:2311.15786</a> (replaced) [<a href="/pdf/2311.15786" title="Download PDF">pdf</a>, <a href="/ps/2311.15786" title="Download PostScript">ps</a>, <a href="/format/2311.15786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YUAN 2.0: A Large Language Model with Localized Filtering-based  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shaohua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xudong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiangang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16450" title="Abstract">arXiv:2311.16450</a> (replaced) [<a href="/pdf/2311.16450" title="Download PDF">pdf</a>, <a href="/format/2311.16450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typhoon Intensity Prediction with Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengshuai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huichou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, accepted by Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16552" title="Abstract">arXiv:2311.16552</a> (replaced) [<a href="/pdf/2311.16552" title="Download PDF">pdf</a>, <a href="/format/2311.16552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandyPriors: Physically Consistent Perception of Hand-Object  Interactions with Differentiable Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yi-Ling Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guanglei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Heiden%2C+E">Eric Heiden</a>, 
<a href="/search/cs?searchtype=author&query=Turpin%2C+D">Dylan Turpin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Macklin%2C+M">Miles Macklin</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16565" title="Abstract">arXiv:2311.16565</a> (replaced) [<a href="/pdf/2311.16565" title="Download PDF">pdf</a>, <a href="/format/2311.16565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D  Face Diffuser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaobao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yitong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+N">Naiming Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xingyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16614" title="Abstract">arXiv:2311.16614</a> (replaced) [<a href="/pdf/2311.16614" title="Download PDF">pdf</a>, <a href="/format/2311.16614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multivariate Unimodality Test Harnessing the Dip Statistic of  Mahalanobis Distances Over Random Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kolyvakis%2C+P">Prodromos Kolyvakis</a>, 
<a href="/search/stat?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16860" title="Abstract">arXiv:2311.16860</a> (replaced) [<a href="/pdf/2311.16860" title="Download PDF">pdf</a>, <a href="/format/2311.16860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-efficient operator learning for solving high Mach number fluid flow  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ford%2C+N">Noah Ford</a>, 
<a href="/search/cs?searchtype=author&query=Leon%2C+V+J">Victor J. Leon</a>, 
<a href="/search/cs?searchtype=author&query=Mrema%2C+H">Honest Mrema</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+J">Jeffrey Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=New%2C+A">Alexander New</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17005" title="Abstract">arXiv:2311.17005</a> (replaced) [<a href="/pdf/2311.17005" title="Download PDF">pdf</a>, <a href="/format/2311.17005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVBench: A Comprehensive Multi-modal Video Understanding Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yinan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jilan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, 19 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17009" title="Abstract">arXiv:2311.17009</a> (replaced) [<a href="/pdf/2311.17009" title="Download PDF">pdf</a>, <a href="/format/2311.17009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yatim%2C+D">Danah Yatim</a>, 
<a href="/search/cs?searchtype=author&query=Fridman%2C+R">Rafail Fridman</a>, 
<a href="/search/cs?searchtype=author&query=Bar-Tal%2C+O">Omer Bar-Tal</a>, 
<a href="/search/cs?searchtype=author&query=Kasten%2C+Y">Yoni Kasten</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+T">Tali Dekel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://diffusion-motion-transfer.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17065" title="Abstract">arXiv:2311.17065</a> (replaced) [<a href="/pdf/2311.17065" title="Download PDF">pdf</a>, <a href="/format/2311.17065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deep Speech Understanding at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Rongxiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17135" title="Abstract">arXiv:2311.17135</a> (replaced) [<a href="/pdf/2311.17135" title="Download PDF">pdf</a>, <a href="/format/2311.17135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLControl: Trajectory and Language Control for Human Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+D">Dinesh Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17213" title="Abstract">arXiv:2311.17213</a> (replaced) [<a href="/pdf/2311.17213" title="Download PDF">pdf</a>, <a href="/ps/2311.17213" title="Download PostScript">ps</a>, <a href="/format/2311.17213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General-Purpose vs. Domain-Adapted Large Language Models for Extraction  of Data from Thoracic Radiology Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhanaliwala%2C+A+H">Ali H. Dhanaliwala</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Rikhiya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Karn%2C+S+K">Sanjeev Kumar Karn</a>, 
<a href="/search/cs?searchtype=author&query=Ullaskrishnan%2C+P">Poikavila Ullaskrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Farri%2C+O">Oladimeji Farri</a>, 
<a href="/search/cs?searchtype=author&query=Comaniciu%2C+D">Dorin Comaniciu</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C+E">Charles E. Kahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17245" title="Abstract">arXiv:2311.17245</a> (replaced) [<a href="/pdf/2311.17245" title="Download PDF">pdf</a>, <a href="/format/2311.17245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and  200+ FPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kairun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages, 8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17259" title="Abstract">arXiv:2311.17259</a> (replaced) [<a href="/pdf/2311.17259" title="Download PDF">pdf</a>, <a href="/format/2311.17259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoUnD Framework: Analyzing (So)cial Representation in (Un)structured  (D)ata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+M">Mark D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Dev%2C+S">Sunipa Dev</a>, 
<a href="/search/cs?searchtype=author&query=Reif%2C+E">Emily Reif</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+E">Emily Denton</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17280" title="Abstract">arXiv:2311.17280</a> (replaced) [<a href="/pdf/2311.17280" title="Download PDF">pdf</a>, <a href="/format/2311.17280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Ishika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by O-DRUM @ CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17405" title="Abstract">arXiv:2311.17405</a> (replaced) [<a href="/pdf/2311.17405" title="Download PDF">pdf</a>, <a href="/format/2311.17405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Autonomy for Extraterrestrial Terrain Sampling: An  Experience Report from OWLAT Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thangeda%2C+P">Pranay Thangeda</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashish Goel</a>, 
<a href="/search/cs?searchtype=author&query=Tevere%2C+E">Erica Tevere</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+E">Erik Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Daca%2C+A">Adriana Daca</a>, 
<a href="/search/cs?searchtype=author&query=Nayar%2C+H">Hari Nayar</a>, 
<a href="/search/cs?searchtype=author&query=Hauser%2C+K">Kris Hauser</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated references to include recent work on autonomy for ocean worlds
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17431" title="Abstract">arXiv:2311.17431</a> (replaced) [<a href="/pdf/2311.17431" title="Download PDF">pdf</a>, <a href="/format/2311.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Foundation Models through Federated Transfer Learning: A  General Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress. fixed some typos and revised the text a little bit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17465" title="Abstract">arXiv:2311.17465</a> (replaced) [<a href="/pdf/2311.17465" title="Download PDF">pdf</a>, <a href="/format/2311.17465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentAvatar: Disentangling Planning, Driving and Rendering for  Photorealistic Avatar Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Duomin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://dorniwang.github.io/AgentAvatar_project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17629" title="Abstract">arXiv:2311.17629</a> (replaced) [<a href="/pdf/2311.17629" title="Download PDF">pdf</a>, <a href="/format/2311.17629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Decoder for End-to-End Oriented Object Detection in Remote  Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zeyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hancheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wenliang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+R">Rui Yao</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17947" title="Abstract">arXiv:2311.17947</a> (replaced) [<a href="/pdf/2311.17947" title="Download PDF">pdf</a>, <a href="/format/2311.17947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Reduction of a Piecewise Linear Flexible Mechanical Oscillator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhattacharyya%2C+S">Suparno Bhattacharyya</a>, 
<a href="/search/eess?searchtype=author&query=Cusumano%2C+J+P">Joseph. P. Cusumano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Chaotic Dynamics (nlin.CD); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17971" title="Abstract">arXiv:2311.17971</a> (replaced) [<a href="/pdf/2311.17971" title="Download PDF">pdf</a>, <a href="/format/2311.17971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and  Consistent 3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Baorui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haoge Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Shen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and Demo: <a href="https://github.com/baaivision/GeoDream">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18061" title="Abstract">arXiv:2311.18061</a> (replaced) [<a href="/pdf/2311.18061" title="Download PDF">pdf</a>, <a href="/format/2311.18061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural  Architecture Search in Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages , 4 figures, It will submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18068" title="Abstract">arXiv:2311.18068</a> (replaced) [<a href="/pdf/2311.18068" title="Download PDF">pdf</a>, <a href="/format/2311.18068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALSTER: A Local Spatio-Temporal Expert for Online 3D Semantic  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weder%2C+S">Silvan Weder</a>, 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+F">Francis Engelmann</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nberger%2C+J+L">Johannes L. Sch&#xf6;nberger</a>, 
<a href="/search/cs?searchtype=author&query=Seki%2C+A">Akihito Seki</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18206" title="Abstract">arXiv:2311.18206</a> (replaced) [<a href="/pdf/2311.18206" title="Download PDF">pdf</a>, <a href="/format/2311.18206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCOPE-RL: A Python Library for Offline Reinforcement Learning and  Off-Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiyohara%2C+H">Haruka Kiyohara</a>, 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+R">Ren Kishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+K">Kosuke Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Ken Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+K">Kazuhide Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuta Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, open-source software: <a href="https://github.com/hakuhodo-technologies/scope-rl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18207" title="Abstract">arXiv:2311.18207</a> (replaced) [<a href="/pdf/2311.18207" title="Download PDF">pdf</a>, <a href="/format/2311.18207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiyohara%2C+H">Haruka Kiyohara</a>, 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+R">Ren Kishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+K">Kosuke Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Ken Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+K">Kazuhide Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuta Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18233" title="Abstract">arXiv:2311.18233</a> (replaced) [<a href="/pdf/2311.18233" title="Download PDF">pdf</a>, <a href="/format/2311.18233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Bound and Multi Types, Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Accattoli%2C+B">Beniamino Accattoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CSL 2024 paper with Appendix. arXiv admin note: text overlap with <a href="/abs/2104.13979">arXiv:2104.13979</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18426" title="Abstract">arXiv:2311.18426</a> (replaced) [<a href="/pdf/2311.18426" title="Download PDF">pdf</a>, <a href="/format/2311.18426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Fractional Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aggarwal%2C+A">Ashwani Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures. Submitted to TMLR. Updated to TMLR format. Minor corrections in Figure 1 description, statements of Theorem 14, 18 and Corollary 17. Minor clarification in statement of Theorem 10, 21. Moved most proofs to appendix and added sketches, moved remarks within proofs into main body
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18539" title="Abstract">arXiv:2311.18539</a> (replaced) [<a href="/pdf/2311.18539" title="Download PDF">pdf</a>, <a href="/format/2311.18539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Both Worlds in Semantics and Time: Domain Knowledge Based  Analysis and Correlation of Industrial Process Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ike%2C+M">Moses Ike</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+K">Kandy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Badapanda%2C+A">Anwesh Badapanda</a>, 
<a href="/search/cs?searchtype=author&query=Landen%2C+M">Matthew Landen</a>, 
<a href="/search/cs?searchtype=author&query=Sadoski%2C+K">Keaton Sadoski</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wanda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Asfahan Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zonouz%2C+S">Saman Zonouz</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wenke Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18545" title="Abstract">arXiv:2311.18545</a> (replaced) [<a href="/pdf/2311.18545" title="Download PDF">pdf</a>, <a href="/format/2311.18545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Deepfake Detection Blockchain Network using Dynamic  Algorithm management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dipankar Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18605" title="Abstract">arXiv:2311.18605</a> (replaced) [<a href="/pdf/2311.18605" title="Download PDF">pdf</a>, <a href="/format/2311.18605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Triangular Distribution in Visual World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengtao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dichao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanlin Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18743" title="Abstract">arXiv:2311.18743</a> (replaced) [<a href="/pdf/2311.18743" title="Download PDF">pdf</a>, <a href="/format/2311.18743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlignBench: Benchmarking Chinese Alignment of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuanyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuoer Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bosi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tam%2C+W+L">Weng Lam Tam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18797" title="Abstract">arXiv:2311.18797</a> (replaced) [<a href="/pdf/2311.18797" title="Download PDF">pdf</a>, <a href="/ps/2311.18797" title="Download PostScript">ps</a>, <a href="/format/2311.18797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3b5;$-Uniform Mixing in Discrete Quantum Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhan%2C+H">Hanmeng Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18803" title="Abstract">arXiv:2311.18803</a> (replaced) [<a href="/pdf/2311.18803" title="Download PDF">pdf</a>, <a href="/format/2311.18803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioCLIP: A Vision Foundation Model for the Tree of Life
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaman Wu</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+M+J">Matthew J Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Campolongo%2C+E+G">Elizabeth G Campolongo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C+H">Chan Hee Song</a>, 
<a href="/search/cs?searchtype=author&query=Carlyn%2C+D+E">David Edward Carlyn</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dahdul%2C+W+M">Wasila M Dahdul</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Charles Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages; updated title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18828" title="Abstract">arXiv:2311.18828</a> (replaced) [<a href="/pdf/2311.18828" title="Download PDF">pdf</a>, <a href="/format/2311.18828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-step Diffusion with Distribution Matching Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+T">Tianwei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Micha&#xeb;l Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+F">Fredo Durand</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tianweiy.github.io/dmd/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00018" title="Abstract">arXiv:2312.00018</a> (replaced) [<a href="/pdf/2312.00018" title="Download PDF">pdf</a>, <a href="/format/2312.00018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Challenges in Autonomous Systems Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamad%2C+M">Mohammad Hamad</a>, 
<a href="/search/cs?searchtype=author&query=Steinhorst%2C+S">Sebastian Steinhorst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00022" title="Abstract">arXiv:2312.00022</a> (replaced) [<a href="/pdf/2312.00022" title="Download PDF">pdf</a>, <a href="/format/2312.00022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A finite element method for stochastic diffusion equations using  fluctuating hydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mart%C3%ADnez-Lera%2C+P">P. Mart&#xed;nez-Lera</a>, 
<a href="/search/math?searchtype=author&query=De+Corato%2C+M">M. De Corato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00102" title="Abstract">arXiv:2312.00102</a> (replaced) [<a href="/pdf/2312.00102" title="Download PDF">pdf</a>, <a href="/ps/2312.00102" title="Download PostScript">ps</a>, <a href="/format/2312.00102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network  And Feature Embedding Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lele Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings on Engineering Sciences
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings on Engineering Sciences, 2620-2832, 2023/10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00311" title="Abstract">arXiv:2312.00311</a> (replaced) [<a href="/pdf/2312.00311" title="Download PDF">pdf</a>, <a href="/format/2312.00311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Face Reconstruction with the Geometric Guidance of Facial Part  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zidu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianshuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baiqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00360" title="Abstract">arXiv:2312.00360</a> (replaced) [<a href="/pdf/2312.00360" title="Download PDF">pdf</a>, <a href="/format/2312.00360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shaohua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yunhe Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00372" title="Abstract">arXiv:2312.00372</a> (replaced) [<a href="/pdf/2312.00372" title="Download PDF">pdf</a>, <a href="/format/2312.00372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-driven Real-time Retrieval in Web Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shusen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoling Bai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hualong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianhua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00475" title="Abstract">arXiv:2312.00475</a> (replaced) [<a href="/pdf/2312.00475" title="Download PDF">pdf</a>, <a href="/ps/2312.00475" title="Download PostScript">ps</a>, <a href="/format/2312.00475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathologists light level preferences using the microscope -- a study to  guide digital pathology display use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jennings%2C+C">Charlotte Jennings</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Treanor%2C+D">Darren Treanor</a> (1,2 and 3), 
<a href="/search/cs?searchtype=author&query=Brettle%2C+D">David Brettle</a> (1) ((1) Leeds Teaching Hospitals NHS Trust, (2) University of Leeds, (3) Link&#xf6;ping University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper 25 pages, 12 figures, 2 tables (including supplementary material)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00656" title="Abstract">arXiv:2312.00656</a> (replaced) [<a href="/pdf/2312.00656" title="Download PDF">pdf</a>, <a href="/format/2312.00656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Transferability Estimation for Regression Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+N">Cuong N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+P">Phong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L+S+T">Lam Si Tung Ho</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+V">Vu Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A+T">Anh T. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hassner%2C+T">Tal Hassner</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+V">Cuong V. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper published at The 39th Conference on Uncertainty in Artificial Intelligence (UAI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00737" title="Abstract">arXiv:2312.00737</a> (replaced) [<a href="/e-print/2312.00737" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do correlations shape the landscape of information?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Ching-Peng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Required some modifications on soft matter
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG); Biological Physics (physics.bio-ph); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00760" title="Abstract">arXiv:2312.00760</a> (replaced) [<a href="/pdf/2312.00760" title="Download PDF">pdf</a>, <a href="/format/2312.00760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ${L}^{\infty}$-norm computation for linear time-invariant systems  depending on parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quadrat%2C+A">Alban Quadrat</a>, 
<a href="/search/cs?searchtype=author&query=Rouillier%2C+F">Fabrice Rouillier</a>, 
<a href="/search/cs?searchtype=author&query=Younes%2C+G">Grace Younes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00761" title="Abstract">arXiv:2312.00761</a> (replaced) [<a href="/pdf/2312.00761" title="Download PDF">pdf</a>, <a href="/format/2312.00761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unlearning: Fast and Efficient Training-free Approach to Controlled  Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kodge%2C+S">Sangamesh Kodge</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+G">Gobinda Saha</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item584">Cross-lists</a></li>
<li><a href="#item663">Replacements</a></li>
</ul>
<small>[ total of 1070 entries:  <b>1-1070</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
