<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 13 Dec 23  to  Thu 14 Dec 23, announced Fri, 15 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item404">Cross-lists</a></li>
<li><a href="#item456">Replacements</a></li>
</ul>
<small>[ total of 708 entries:  <b>1-708</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 15 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08374" title="Abstract">arXiv:2312.08374</a> [<a href="/pdf/2312.08374" title="Download PDF">pdf</a>, <a href="/format/2312.08374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Social Event Detection via Hybrid Graph Contrastive  Learning and Reinforced Incremental Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zehua Zang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lixiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpted by Knowledge-Based Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting events from social media data streams is gradually attracting
researchers. The innate challenge for detecting events is to extract
discriminative information from social media data thereby assigning the data
into different events. Due to the excessive diversity and high updating
frequency of social data, using supervised approaches to detect events from
social messages is hardly achieved. To this end, recent works explore learning
discriminative information from social messages by leveraging graph contrastive
learning (GCL) and embedding clustering in an unsupervised manner. However, two
intrinsic issues exist in benchmark methods: conventional GCL can only roughly
explore partial attributes, thereby insufficiently learning the discriminative
information of social messages; for benchmark methods, the learned embeddings
are clustered in the latent space by taking advantage of certain specific prior
knowledge, which conflicts with the principle of unsupervised learning
paradigm. In this paper, we propose a novel unsupervised social media event
detection method via hybrid graph contrastive learning and reinforced
incremental clustering (HCRC), which uses hybrid graph contrastive learning to
comprehensively learn semantic and structural discriminative information from
social messages and reinforced incremental clustering to perform efficient
clustering in a solidly unsupervised manner. We conduct comprehensive
experiments to evaluate HCRC on the Twitter and Maven datasets. The
experimental results demonstrate that our approach yields consistent
significant performance boosts. In traditional incremental setting,
semi-supervised incremental setting and solidly unsupervised setting, the model
performance has achieved maximum improvements of 53%, 45%, and 37%,
respectively.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08375" title="Abstract">arXiv:2312.08375</a> [<a href="/pdf/2312.08375" title="Download PDF">pdf</a>, <a href="/format/2312.08375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Encoding of Abstract Dialectical Frameworks into Higher-Order Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martina%2C+A">Antoine Martina</a>, 
<a href="/search/cs?searchtype=author&query=Steen%2C+A">Alexander Steen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An approach for encoding abstract dialectical frameworks and their semantics
into classical higher-order logic is presented. Important properties and
semantic relationships are formally encoded and proven using the proof
assistant Isabelle/HOL. This approach allows for the computer-assisted analysis
of abstract dialectical frameworks using automated and interactive reasoning
tools within a uniform logic environment. Exemplary applications include the
formal analysis and verification of meta-theoretical properties, and the
generation of interpretations and extensions under specific semantic
constraints.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08376" title="Abstract">arXiv:2312.08376</a> [<a href="/pdf/2312.08376" title="Download PDF">pdf</a>, <a href="/ps/2312.08376" title="Download PostScript">ps</a>, <a href="/format/2312.08376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A global optimization SAR image segmentation model can be easily  transformed to a general ROF denoising model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages,49 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel locally statistical active contour model
(LACM) based on Aubert-Aujol (AA) denoising model and variational level set
method, which can be used for SAR images segmentation with intensity
inhomogeneity. Then we transform the proposed model into a global optimization
model by using convex relaxation technique. Firstly, we apply the Split Bregman
technique to transform the global optimization model into two alternating
optimization processes of Shrink operator and Laplace operator, which is called
SB_LACM model. Moreover, we propose two fast models to solve the global
optimization model , which are more efficient than the SB_LACM model. The first
model is: we add the proximal function to transform the global optimization
model to a general ROF model[29], which can be solved by a fast denoising
algorithm proposed by R.-Q.Jia, and H.Zhao; Thus we obtain a fast segmentation
algorithm with global optimization solver that does not involve partial
differential equations or difference equation, and only need simple difference
computation. The second model is: we use a different splitting approach than
one model to transform the global optimization model into a differentiable term
and a general ROF model term, which can be solved by the same technique as the
first model. Experiments using some challenging synthetic images and Envisat
SAR images demonstrate the superiority of our proposed models with respect to
the state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08377" title="Abstract">arXiv:2312.08377</a> [<a href="/pdf/2312.08377" title="Download PDF">pdf</a>, <a href="/format/2312.08377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALGNet: Attention Light Graph Memory Network for Medical Recommendation  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh-Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duy-Thinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+B">Bac-Hoai Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Medication recommendation is a vital task for improving patient care and
reducing adverse events. However, existing methods often fail to capture the
complex and dynamic relationships among patient medical records, drug efficacy
and safety, and drug-drug interactions (DDI). In this paper, we propose ALGNet,
a novel model that leverages light graph convolutional networks (LGCN) and
augmentation memory networks (AMN) to enhance medication recommendation. LGCN
can efficiently encode the patient records and the DDI graph into
low-dimensional embeddings, while AMN can augment the patient representation
with external knowledge from a memory module. We evaluate our model on the
MIMIC-III dataset and show that it outperforms several baselines in terms of
recommendation accuracy and DDI avoidance. We also conduct an ablation study to
analyze the effects of different components of our model. Our results
demonstrate that ALGNet can achieve superior performance with less computation
and more interpretability. The implementation of this paper can be found at:
https://github.com/huyquoctrinh/ALGNet.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08378" title="Abstract">arXiv:2312.08378</a> [<a href="/pdf/2312.08378" title="Download PDF">pdf</a>, <a href="/format/2312.08378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singular Value Penalization and Semantic Data Augmentation for Fully  Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Houcheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daixian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengzhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures,aaai2024(score:5422)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Fully test-time adaptation (FTTA) adapts a model that is trained on a source
domain to a target domain during the testing phase, where the two domains
follow different distributions and source data is unavailable during the
training phase. Existing methods usually adopt entropy minimization to reduce
the uncertainty of target prediction results, and improve the FTTA performance
accordingly. However, they fail to ensure the diversity in target prediction
results. Recent domain adaptation study has shown that maximizing the sum of
singular values of prediction results can simultaneously enhance their
confidence (discriminability) and diversity. However, during the training
phase, larger singular values usually take up a dominant position in loss
maximization. This results in the model being more inclined to enhance
discriminability for easily distinguishable classes, and the improvement in
diversity is insufficiently effective. Furthermore, the adaptation and
prediction in FTTA only use data from the current batch, which may lead to the
risk of overfitting. To address the aforementioned issues, we propose
maximizing the sum of singular values while minimizing their variance. This
enables the model's focus toward the smaller singular values, enhancing
discriminability between more challenging classes and effectively increasing
the diversity of prediction results. Moreover, we incorporate data from the
previous batch to realize semantic data augmentation for the current batch,
reducing the risk of overfitting. Extensive experiments on benchmark datasets
show our proposed approach outperforms some compared state-of-the-art FTTA
methods.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08381" title="Abstract">arXiv:2312.08381</a> [<a href="/pdf/2312.08381" title="Download PDF">pdf</a>, <a href="/ps/2312.08381" title="Download PostScript">ps</a>, <a href="/format/2312.08381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable Machine Learning Framework for the Accurate Diagnosis of  Ovarian Cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Newaz%2C+A">Asif Newaz</a>, 
<a href="/search/cs?searchtype=author&query=Taharat%2C+A">Abdullah Taharat</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Sakibul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Akanda%2C+A+G+M+F+H">A.G.M. Fuad Hasan Akanda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ovarian cancer (OC) is one of the most prevalent types of cancer in women.
Early and accurate diagnosis is crucial for the survival of the patients.
However, the majority of women are diagnosed in advanced stages due to the lack
of effective biomarkers and accurate screening tools. While previous studies
sought a common biomarker, our study suggests different biomarkers for the
premenopausal and postmenopausal populations. This can provide a new
perspective in the search for novel predictors for the effective diagnosis of
OC. Lack of explainability is one major limitation of current AI systems. The
stochastic nature of the ML algorithms raises concerns about the reliability of
the system as it is difficult to interpret the reasons behind the decisions. To
increase the trustworthiness and accountability of the diagnostic system as
well as to provide transparency and explanations behind the predictions,
explainable AI has been incorporated into the ML framework. SHAP is employed to
quantify the contributions of the selected biomarkers and determine the most
discriminative features. A hybrid decision support system has been established
that can eliminate the bottlenecks caused by the black-box nature of the ML
algorithms providing a safe and trustworthy AI tool. The diagnostic accuracy
obtained from the proposed system outperforms the existing methods as well as
the state-of-the-art ROMA algorithm by a substantial margin which signifies its
potential to be an effective tool in the differential diagnosis of OC.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08383" title="Abstract">arXiv:2312.08383</a> [<a href="/pdf/2312.08383" title="Download PDF">pdf</a>, <a href="/ps/2312.08383" title="Download PostScript">ps</a>, <a href="/format/2312.08383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving age prediction: Utilizing LSTM-based dynamic forecasting for  data augmentation in multivariate time series analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yutong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+C+A">Charles A. Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Calhoun%2C+V+D">Vince D. Calhoun</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+R+L">Robyn L. Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 PAGES, 3 FIGURES, CONFERENCE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The high dimensionality and complexity of neuroimaging data necessitate large
datasets to develop robust and high-performing deep learning models. However,
the neuroimaging field is notably hampered by the scarcity of such datasets. In
this work, we proposed a data augmentation and validation framework that
utilizes dynamic forecasting with Long Short-Term Memory (LSTM) networks to
enrich datasets. We extended multivariate time series data by predicting the
time courses of independent component networks (ICNs) in both one-step and
recursive configurations. The effectiveness of these augmented datasets was
then compared with the original data using various deep learning models
designed for chronological age prediction tasks. The results suggest that our
approach improves model performance, providing a robust solution to overcome
the challenges presented by the limited size of neuroimaging datasets.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08384" title="Abstract">arXiv:2312.08384</a> [<a href="/pdf/2312.08384" title="Download PDF">pdf</a>, <a href="/ps/2312.08384" title="Download PostScript">ps</a>, <a href="/format/2312.08384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking it further: leveraging pseudo labels for field delineation across  label-scarce smallholder regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rufin%2C+P">Philippe Rufin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sherrie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lisboa%2C+S+N">S&#xe1; Nogueira Lisboa</a>, 
<a href="/search/cs?searchtype=author&query=Hemmerling%2C+J">Jan Hemmerling</a>, 
<a href="/search/cs?searchtype=author&query=Tulbure%2C+M+G">Mirela G. Tulbure</a>, 
<a href="/search/cs?searchtype=author&query=Meyfroidt%2C+P">Patrick Meyfroidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning allows for resource-efficient geographic transfer of
pre-trained field delineation models. However, the scarcity of labeled data for
complex and dynamic smallholder landscapes, particularly in Sub-Saharan Africa,
remains a major bottleneck for large-area field delineation. This study
explores opportunities of using sparse field delineation pseudo labels for
fine-tuning models across geographies and sensor characteristics. We build on a
FracTAL ResUNet trained for crop field delineation in India (median field size
of 0.24 ha) and use this pre-trained model to generate pseudo labels in
Mozambique (median field size of 0.06 ha). We designed multiple pseudo label
selection strategies and compared the quantities, area properties, seasonal
distribution, and spatial agreement of the pseudo labels against
human-annotated training labels (n = 1,512). We then used the human-annotated
labels and the pseudo labels for model fine-tuning and compared predictions
against human field annotations (n = 2,199). Our results indicate i) a good
baseline performance of the pre-trained model in both field delineation and
field size estimation, and ii) the added value of regional fine-tuning with
performance improvements in nearly all experiments. Moreover, we found iii)
substantial performance increases when using only pseudo labels (up to 77% of
the IoU increases and 68% of the RMSE decreases obtained by human labels), and
iv) additional performance increases when complementing human annotations with
pseudo labels. Pseudo labels can be efficiently generated at scale and thus
facilitate domain adaptation in label-scarce settings. The workflow presented
here is a stepping stone for overcoming the persisting data gaps in
heterogeneous smallholder agriculture of Sub-Saharan Africa, where labels are
commonly scarce.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08385" title="Abstract">arXiv:2312.08385</a> [<a href="/pdf/2312.08385" title="Download PDF">pdf</a>, <a href="/ps/2312.08385" title="Download PostScript">ps</a>, <a href="/format/2312.08385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structural Complexity Analysis of Synchronous Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Hamm%2C+T">Thekla Hamm</a>, 
<a href="/search/cs?searchtype=author&query=Korchemna%2C+V">Viktoriia Korchemna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared at AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Synchronous dynamic systems are well-established models that have been used
to capture a range of phenomena in networks, including opinion diffusion,
spread of disease and product adoption. We study the three most notable
problems in synchronous dynamic systems: whether the system will transition to
a target configuration from a starting configuration, whether the system will
reach convergence from a starting configuration, and whether the system is
guaranteed to converge from every possible starting configuration. While all
three problems were known to be intractable in the classical sense, we initiate
the study of their exact boundaries of tractability from the perspective of
structural parameters of the network by making use of the more fine-grained
parameterized complexity paradigm.
<br />As our first result, we consider treewidth - as the most prominent and
ubiquitous structural parameter - and show that all three problems remain
intractable even on instances of constant treewidth. We complement this
negative finding with fixed-parameter algorithms for the former two problems
parameterized by treedepth, a well-studied restriction of treewidth. While it
is possible to rule out a similar algorithm for convergence guarantee under
treedepth, we conclude with a fixed-parameter algorithm for this last problem
when parameterized by treedepth and the maximum in-degree.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08386" title="Abstract">arXiv:2312.08386</a> [<a href="/pdf/2312.08386" title="Download PDF">pdf</a>, <a href="/format/2312.08386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerfactTailor: Scale-Preserving 2D Pattern Adjustment Driven by 3D  Garment Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+A">Anran Qi</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+T">Takeo Igarashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We address the problem of modifying a given well-designed 2D sewing pattern
to accommodate garment edits in the 3D space. Existing methods usually adjust
the sewing pattern by applying uniform flattening to the 3D garment. The
problems are twofold: first, it ignores local scaling of the 2D sewing pattern
such as shrinking ribs of cuffs; second, it does not respect the implicit
design rules and conventions of the industry, such as the use of straight edges
for simplicity and precision in sewing. To address those problems, we present a
pattern adjustment method that considers the non-uniform local scaling of the
2D sewing pattern by utilizing the intrinsic scale matrix. In addition, we
preserve the original boundary shape by an as-similar-as-possible geometric
constraint when desirable. We build a prototype with a set of commonly used
alteration operations and showcase the capability of our method via a number of
alteration examples throughout the paper.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08387" title="Abstract">arXiv:2312.08387</a> [<a href="/pdf/2312.08387" title="Download PDF">pdf</a>, <a href="/format/2312.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JMAC Protocol: A Cross-Layer Multi-Hop Protocol for LoRa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Escobar%2C+J+J+L">Juan Jos&#xe9; L&#xf3;pez Escobar</a>, 
<a href="/search/cs?searchtype=author&query=Gil-Casti%C3%B1eira%2C+F">Felipe Gil-Casti&#xf1;eira</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2020, vol. 20, no 23, p. 6893
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The emergence of Low-Power Wide-Area Network (LPWAN) technologies allowed the
development of revolutionary Internet Of Things (IoT) applications covering
large areas with thousands of devices. However, connectivity may be a challenge
for non-line-of-sight indoor operation or for areas without good coverage.
Technologies such as LoRa and Sigfox allow connectivity for up to 50,000
devices per cell, several devices that may be exceeded in many scenarios. To
deal with these problems, this paper introduces a new multi-hop protocol,
called JMAC, designed for improving long range wireless communication networks
that may support monitoring in scenarios such smart cities or Industry 4.0.
JMAC uses the LoRa radio technology to keep low consumption and extend coverage
area, and exploits the potential mesh behaviour of wireless networks to improve
coverage and increase the number of supported devices per cell. \mbox{JMAC is}
based on predictive wake-up to reach long lifetime on sensor devices. Our
proposal was validated using the OMNeT++ simulator to analyze how it performs
under different conditions with promising results
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08388" title="Abstract">arXiv:2312.08388</a> [<a href="/pdf/2312.08388" title="Download PDF">pdf</a>, <a href="/format/2312.08388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Graph Based Approaches for Author Name Disambiguation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Chetanya Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Prabhat Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In many applications, such as scientific literature management, researcher
search, social network analysis and etc, Name Disambiguation (aiming at
disambiguating WhoIsWho) has been a challenging problem. In addition, the
growth of scientific literature makes the problem more difficult and urgent.
Although name disambiguation has been extensively studied in academia and
industry, the problem has not been solved well due to the clutter of data and
the complexity of the same name scenario. In this work, we aim to explore
models that can perform the task of name disambiguation using the network
structure that is intrinsic to the problem and present an analysis of the
models.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08389" title="Abstract">arXiv:2312.08389</a> [<a href="/pdf/2312.08389" title="Download PDF">pdf</a>, <a href="/format/2312.08389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation for Dataflow Applications in FANETs using Anypath  Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Escobar%2C+J+J+L">Juan Jos&#xe9; L&#xf3;pez Escobar</a>, 
<a href="/search/cs?searchtype=author&query=Ricardo%2C+M">Manuel Ricardo</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Rui Campos</a>, 
<a href="/search/cs?searchtype=author&query=Gil-Casti%C3%B1eira%2C+F">Felipe Gil-Casti&#xf1;eira</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Internet of Things, 2023, vol. 22, p. 100761
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Management of network resources in advanced IoT applications is a challenging
topic due to their distributed nature from the Edge to the Cloud, and the heavy
demand of real-time data from many sources to take action in the deployment.
FANETs (Flying Ad-hoc Networks) are a clear example of heterogeneous
multi-modal use cases, which require strict quality in the network
communications, as well as the coordination of the computing capabilities, in
order to operate correctly the final service. In this paper, we present a
Virtual Network Embedding (VNE) framework designed for the allocation of
dataflow applications, composed of nano-services that produce or consume data,
in a wireless infrastructure, such as an airborne network. To address the
problem, an anypath-based heuristic algorithm that considers the quality demand
of the communication between nano-services is proposed, coined as
Quality-Revenue Paired Anypath Dataflow VNE (QRPAD-VNE). We also provide a
simulation environment for the evaluation of its performance according to the
virtual network (VN) request load in the system. Finally, we show the
suitability of a multi-parameter framework in conjunction with anypath routing
in order to have better performance results that guarantee minimum quality in
the wireless communications.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08393" title="Abstract">arXiv:2312.08393</a> [<a href="/pdf/2312.08393" title="Download PDF">pdf</a>, <a href="/format/2312.08393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-criteria recommendation systems to foster online grocery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafez%2C+M+M">Manar Mohamed Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Paz%C3%B3%2C+H+O">H&#xe9;ctor Olivera Paz&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 8 images, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2021, vol. 21, no 11, p. 3747
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the exponential increase in information, it has become imperative to
design mechanisms that allow users to access what matters to them as quickly as
possible. The recommendation system ($RS$) with information technology
development is the solution, it is an intelligent system. Various types of data
can be collected on items of interest to users and presented as
recommendations. $RS$ also play a very important role in e-commerce. The
purpose of recommending a product is to designate the most appropriate
designation for a specific product. The major challenges when recommending
products are insufficient information about the products and the categories to
which they belong. In this paper, we transform the product data using two
methods of document representation: bag-of-words (BOW) and the neural
network-based document combination known as vector-based (Doc2Vec). We propose
three-criteria recommendation systems (product, package, and health) for each
document representation method to foster online grocery, which depends on
product characteristics such as (composition, packaging, nutrition table,
allergen, etc.). For our evaluation, we conducted a user and expert survey.
Finally, we have compared the performance of these three criteria for each
document representation method, discovering that the neural network-based
(Doc2Vec) performs better and completely alters the results.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08394" title="Abstract">arXiv:2312.08394</a> [<a href="/pdf/2312.08394" title="Download PDF">pdf</a>, <a href="/format/2312.08394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From HODL to MOON: Understanding Community Evolution, Emotional  Dynamics, and Price Interplay in the Cryptocurrency Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadamou%2C+K">Kostantinos Papadamou</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+J">Jay Patel</a>, 
<a href="/search/cs?searchtype=author&query=Blackburn%2C+J">Jeremy Blackburn</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+P">Philipp Jovanovic</a>, 
<a href="/search/cs?searchtype=author&query=De+Cristofaro%2C+E">Emiliano De Cristofaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper presents a large-scale analysis of the cryptocurrency community on
Reddit, shedding light on the intricate relationship between the evolution of
their activity, emotional dynamics, and price movements. We analyze over 130M
posts on 122 cryptocurrency-related subreddits using temporal analysis,
statistical modeling, and emotion detection. While /r/CryptoCurrency and
/r/dogecoin are the most active subreddits, we find an overall surge in
cryptocurrency-related activity in 2021, followed by a sharp decline. We also
uncover a strong relationship in terms of cross-correlation between online
activity and the price of various coins, with the changes in the number of
posts mostly leading the price changes. Backtesting analysis shows that a
straightforward strategy based on the cross-correlation where one buys/sells a
coin if the daily number of posts about it is greater/less than the previous
would have led to a 3x return on investment. Finally, we shed light on the
emotional dynamics of the cryptocurrency communities, finding that joy becomes
a prominent indicator during upward market performance, while a decline in the
market manifests an increase in anger.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08395" title="Abstract">arXiv:2312.08395</a> [<a href="/pdf/2312.08395" title="Download PDF">pdf</a>, <a href="/format/2312.08395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The complex-step Newton method and its convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mitsotakis%2C+D">Dimitrios Mitsotakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Considered herein is a Jacobian-free Newton method for the numerical solution
of nonlinear equations where the Jacobian is approximated using the
complex-step derivative approximation. We demonstrate that this method
converges for complex-step values sufficiently small and not necessarily tiny.
Notably, in the case of scalar equations the convergence rate becomes quadratic
as the complex-step tends to zero. On the other hand, in the case of systems of
equations the rate is quadratic for any appropriately small value of the
complex-step and not just in the limit to zero. This assertion is substantiated
through numerical experiments. Furthermore, we demonstrate the method's
seamless applicability in solving nonlinear systems that arise in the context
of differential equations, employing it as a Jacobian-free Newton-Krylov
method.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08396" title="Abstract">arXiv:2312.08396</a> [<a href="/pdf/2312.08396" title="Download PDF">pdf</a>, <a href="/format/2312.08396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards SSH3: how HTTP/3 improves secure shells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michel%2C+F">Fran&#xe7;ois Michel</a>, 
<a href="/search/cs?searchtype=author&query=Bonaventure%2C+O">Olivier Bonaventure</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The SSH protocol was designed in the late nineties to cope with the security
problems of the telnetf family of protocols. It brought authentication and
confidentiality to remote access protocols and is now widely used. Almost 30
years after the initial design, we revisit SSH in the light of recent protocols
including QUIC, TLS 1.3 and HTTP/3. We propose, implement and evaluate SSH3, a
protocol that provides an enhanced feature set without compromise compared to
SSHv2. SSH3 leverages HTTP-based authorization mechanisms to enable new
authentication methods in addition to the classical password-based and
private/public key pair authentications. SSH3 users can now configure their
remote server to be accessed through the identity provider of their
organization or using their Google or Github account. Relying on HTTP/3 and the
QUIC protocol, SSH3 offers UDP port forwarding in addition to regular TCP
forwarding as well as a faster and secure session establishment. We implement
SSH3 over quic-go and evaluate its performance.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08397" title="Abstract">arXiv:2312.08397</a> [<a href="/pdf/2312.08397" title="Download PDF">pdf</a>, <a href="/format/2312.08397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Decision Supports based on Theory of Mind Modeling and  Explainable Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huao Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Keyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Michael Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE SMC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we propose a novel personalized decision support system that
combines Theory of Mind (ToM) modeling and explainable Reinforcement Learning
(XRL) to provide effective and interpretable interventions. Our method
leverages DRL to provide expert action recommendations while incorporating ToM
modeling to understand users' mental states and predict their future actions,
enabling appropriate timing for intervention. To explain interventions, we use
counterfactual explanations based on RL's feature importance and users' ToM
model structure. Our proposed system generates accurate and personalized
interventions that are easily interpretable by end-users. We demonstrate the
effectiveness of our approach through a series of crowd-sourcing experiments in
a simulated team decision-making task, where our system outperforms control
baselines in terms of task performance. Our proposed approach is agnostic to
task environment and RL model structure, therefore has the potential to be
generalized to a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08398" title="Abstract">arXiv:2312.08398</a> [<a href="/pdf/2312.08398" title="Download PDF">pdf</a>, <a href="/format/2312.08398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Meta-Learning by Sharing Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The success of gradient-based meta-learning is primarily attributed to its
ability to leverage related tasks to learn task-invariant information. However,
the absence of interactions between different tasks in the inner loop leads to
task-specific over-fitting in the initial phase of meta-training. While this is
eventually corrected by the presence of these interactions in the outer loop,
it comes at a significant cost of slower meta-learning. To address this
limitation, we explicitly encode task relatedness via an inner loop
regularization mechanism inspired by multi-task learning. Our algorithm shares
gradient information from previously encountered tasks as well as concurrent
tasks in the same task batch, and scales their contribution with meta-learned
parameters. We show using two popular few-shot classification datasets that
gradient sharing enables meta-learning under bigger inner loop learning rates
and can accelerate the meta-training process by up to 134%.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08399" title="Abstract">arXiv:2312.08399</a> [<a href="/pdf/2312.08399" title="Download PDF">pdf</a>, <a href="/format/2312.08399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principled Weight Initialization for Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/cs?searchtype=author&query=Flokas%2C+L">Lampros Flokas</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Hypernetworks are meta neural networks that generate weights for a main
neural network in an end-to-end differentiable manner. Despite extensive
applications ranging from multi-task learning to Bayesian deep learning, the
problem of optimizing hypernetworks has not been studied to date. We observe
that classical weight initialization methods like Glorot &amp; Bengio (2010) and He
et al. (2015), when applied directly on a hypernet, fail to produce weights for
the mainnet in the correct scale. We develop principled techniques for weight
initialization in hypernets, and show that they lead to more stable mainnet
weights, lower training loss, and faster convergence.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08400" title="Abstract">arXiv:2312.08400</a> [<a href="/pdf/2312.08400" title="Download PDF">pdf</a>, <a href="/format/2312.08400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S+Y">Sang Yun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+G">Gagan Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Nagoudi%2C+E+M+B">El Moatez Billah Nagoudi</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.04492">arXiv:2308.04492</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) finetuned to follow human instruction have
recently exhibited significant capabilities in various English NLP tasks.
However, their performance in grammatical error correction (GEC), especially on
languages other than English, remains significantly unexplored. In this work,
we evaluate the abilities of instruction finetuned LLMs in Arabic GEC, a
complex task due to Arabic's rich morphology. Our findings suggest that various
prompting methods, coupled with (in-context) few-shot learning, demonstrate
considerable effectiveness, with GPT-4 achieving up to $65.49$ F$_{1}$ score
under expert prompting (approximately $5$ points higher than our established
baseline). Despite these positive results, we find that instruction finetuned
models, regardless of their size, are still outperformed by fully finetuned
ones, even if they are significantly smaller in size. This disparity highlights
substantial room for improvements for LLMs. Inspired by methods used in
low-resource machine translation, we also develop a method exploiting synthetic
data that significantly outperforms previous models on two standard Arabic
benchmarks. Our best model achieves a new SOTA on Arabic GEC, with $73.29$ and
$73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively, compared to
peer-reviewed published baselines.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08401" title="Abstract">arXiv:2312.08401</a> [<a href="/pdf/2312.08401" title="Download PDF">pdf</a>, <a href="/ps/2312.08401" title="Download PostScript">ps</a>, <a href="/format/2312.08401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced and Deterministic Weight-sharing Helps Network Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Weight-sharing plays a significant role in the success of many deep neural
networks, by increasing memory efficiency and incorporating useful inductive
priors about the problem into the network. But understanding how weight-sharing
can be used effectively in general is a topic that has not been studied
extensively. Chen et al. [2015] proposed HashedNets, which augments a
multi-layer perceptron with a hash table, as a method for neural network
compression. We generalize this method into a framework (ArbNets) that allows
for efficient arbitrary weight-sharing, and use it to study the role of
weight-sharing in neural networks. We show that common neural networks can be
expressed as ArbNets with different hash functions. We also present two novel
hash functions, the Dirichlet hash and the Neighborhood hash, and use them to
demonstrate experimentally that balanced and deterministic weight-sharing helps
with the performance of a neural network.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08402" title="Abstract">arXiv:2312.08402</a> [<a href="/pdf/2312.08402" title="Download PDF">pdf</a>, <a href="/format/2312.08402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic  Memory Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingjin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Daniel Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of the Association for Computational Linguistics: EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid development of large language models (LLMs), it is highly
demanded that LLMs can be adopted to make decisions to enable the artificial
general intelligence. Most approaches leverage manually crafted examples to
prompt the LLMs to imitate the decision process of human. However, designing
optimal prompts is difficult and the patterned prompts can hardly be
generalized to more complex environments. In this paper, we propose a novel
model named Large Decision Model with Memory (LDM$^2$), which leverages a
dynamic memory mechanism to construct dynamic prompts, guiding the LLMs in
making proper decisions according to the faced state. LDM$^2$ consists of two
stages: memory formation and memory refinement. In the former stage, human
behaviors are decomposed into state-action tuples utilizing the powerful
summarizing ability of LLMs. Then, these tuples are stored in the memory, whose
indices are generated by the LLMs, to facilitate the retrieval of the most
relevant subset of memorized tuples based on the current state. In the latter
stage, our LDM$^2$ employs tree exploration to discover more suitable decision
processes and enrich the memory by adding valuable state-action tuples. The
dynamic circle of exploration and memory enhancement provides LDM$^2$ a better
understanding of the global environment. Extensive experiments conducted in two
interactive environments have shown that our LDM$^2$ outperforms the baselines
in terms of both score and success rate, which demonstrates its effectiveness.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08403" title="Abstract">arXiv:2312.08403</a> [<a href="/pdf/2312.08403" title="Download PDF">pdf</a>, <a href="/format/2312.08403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Earthfarseer: Versatile Spatio-Temporal Dynamical Systems Modeling in  One Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Efficiently modeling spatio-temporal (ST) physical processes and observations
presents a challenging problem for the deep learning community. Many recent
studies have concentrated on meticulously reconciling various advantages,
leading to designed models that are neither simple nor practical. To address
this issue, this paper presents a systematic study on existing shortcomings
faced by off-the-shelf models, including lack of local fidelity, poor
prediction performance over long time-steps,low scalability, and inefficiency.
To systematically address the aforementioned problems, we propose an
EarthFarseer, a concise framework that combines parallel local convolutions and
global Fourier-based transformer architectures, enabling dynamically capture
the local-global spatial interactions and dependencies. EarthFarseer also
incorporates a multi-scale fully convolutional and Fourier architectures to
efficiently and effectively capture the temporal evolution. Our proposal
demonstrates strong adaptability across various tasks and datasets, with fast
convergence and better local fidelity in long time-steps predictions. Extensive
experiments and visualizations over eight human society physical and natural
physical datasets demonstrates the state-of-the-art performance of
EarthFarseer. We release our code at
https://github.com/easylearningscores/EarthFarseer.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08408" title="Abstract">arXiv:2312.08408</a> [<a href="/pdf/2312.08408" title="Download PDF">pdf</a>, <a href="/ps/2312.08408" title="Download PostScript">ps</a>, <a href="/format/2312.08408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI in Grassland Monitoring: Enhancing Model Performance and  Domain Adaptability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shanghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hedstr%C3%B6m%2C+A">Anna Hedstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Basavegowda%2C+D+H">Deepak Hanike Basavegowda</a>, 
<a href="/search/cs?searchtype=author&query=Weltzien%2C+C">Cornelia Weltzien</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6hne%2C+M+M+-">Marina M.-C. H&#xf6;hne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Grasslands are known for their high biodiversity and ability to provide
multiple ecosystem services. Challenges in automating the identification of
indicator plants are key obstacles to large-scale grassland monitoring. These
challenges stem from the scarcity of extensive datasets, the distributional
shifts between generic and grassland-specific datasets, and the inherent
opacity of deep learning models. This paper delves into the latter two
challenges, with a specific focus on transfer learning and eXplainable
Artificial Intelligence (XAI) approaches to grassland monitoring, highlighting
the novelty of XAI in this domain. We analyze various transfer learning methods
to bridge the distributional gaps between generic and grassland-specific
datasets. Additionally, we showcase how explainable AI techniques can unveil
the model's domain adaptation capabilities, employing quantitative assessments
to evaluate the model's proficiency in accurately centering relevant input
features around the object of interest. This research contributes valuable
insights for enhancing model performance through transfer learning and
measuring domain adaptability with explainable AI, showing significant promise
for broader applications within the agricultural community.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08409" title="Abstract">arXiv:2312.08409</a> [<a href="/pdf/2312.08409" title="Download PDF">pdf</a>, <a href="/format/2312.08409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe and Collaborative Robotic Ultrasound Tissue Scanning in  Neurosurgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dyck%2C+M">Michael Dyck</a>, 
<a href="/search/cs?searchtype=author&query=Weld%2C+A">Alistair Weld</a>, 
<a href="/search/cs?searchtype=author&query=Klodmann%2C+J">Julian Klodmann</a>, 
<a href="/search/cs?searchtype=author&query=Kirst%2C+A">Alexander Kirst</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+L">Luke Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Anichini%2C+G">Giulio Anichini</a>, 
<a href="/search/cs?searchtype=author&query=Camp%2C+S">Sophie Camp</a>, 
<a href="/search/cs?searchtype=author&query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Sch&#xe4;ffer</a>, 
<a href="/search/cs?searchtype=author&query=Giannarou%2C+S">Stamatia Giannarou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 7 figures, accepted (05 December 2023) for publication in IEEE Transaction on Medical Robotics and Bionics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Intraoperative ultrasound imaging is used to facilitate safe brain tumour
resection. However, due to challenges with image interpretation and the
physical scanning, this tool has yet to achieve widespread adoption in
neurosurgery. In this paper, we introduce the components and workflow of a
novel, versatile robotic platform for intraoperative ultrasound tissue scanning
in neurosurgery. An RGB-D camera attached to the robotic arm allows for
automatic object localisation with ArUco markers, and 3D surface reconstruction
as a triangular mesh using the ImFusion Suite software solution. Impedance
controlled guidance of the US probe along arbitrary surfaces, represented as a
mesh, enables collaborative US scanning, i.e., autonomous, teleoperated and
hands-on guided data acquisition. A preliminary experiment evaluates the
suitability of the conceptual workflow and system components for probe landing
on a custom-made soft-tissue phantom. Further assessment in future experiments
will be necessary to prove the effectiveness of the presented platform.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08410" title="Abstract">arXiv:2312.08410</a> [<a href="/pdf/2312.08410" title="Download PDF">pdf</a>, <a href="/format/2312.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Approximation Property of Random Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>, 
<a href="/search/cs?searchtype=author&query=Schmocker%2C+P">Philipp Schmocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 64 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study random neural networks which are single-hidden-layer
feedforward neural networks whose weights and biases are randomly initialized.
After this random initialization, only the linear readout needs to be trained,
which can be performed efficiently, e.g., by the least squares method. By
viewing random neural networks as Banach space-valued random variables, we
prove their universal approximation properties within suitable Bochner spaces.
Hereby, the corresponding Banach space can be more general than the space of
continuous functions over a compact subset of a Euclidean space, namely, e.g.,
an $L^p$-space or a Sobolev space, where the latter includes the approximation
of the derivatives. Moreover, we derive some approximation rates and develop an
explicit algorithm to learn a deterministic function by a random neural
network. In addition, we provide a full error analysis and study when random
neural networks overcome the curse of dimensionality in the sense that the
training costs scale at most polynomially in the input and output dimension.
Furthermore, we show in two numerical examples the empirical advantages of
random neural networks compared to fully trained deterministic neural networks.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08411" title="Abstract">arXiv:2312.08411</a> [<a href="/pdf/2312.08411" title="Download PDF">pdf</a>, <a href="/format/2312.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose and shear-based tactile servoing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lloyd%2C+J">John Lloyd</a>, 
<a href="/search/cs?searchtype=author&query=Lepora%2C+N+F">Nathan F. Lepora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in International Journal of Robotics Research (IJRR). 29 pages, 20 figures. Related technical report: <a href="/abs/2306.08560">arXiv:2306.08560</a>. Video: <a href="https://www.youtube.com/watch?v=xVs4hd34ek0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tactile servoing is an important technique because it enables robots to
manipulate objects with precision and accuracy while adapting to changes in
their environments in real-time. One approach for tactile servo control with
high-resolution soft tactile sensors is to estimate the contact pose relative
to an object surface using a convolutional neural network (CNN) for use as a
feedback signal. In this paper, we investigate how the surface pose estimation
model can be extended to include shear, and utilize these combined
pose-and-shear models to develop a tactile robotic system that can be
programmed for diverse non-prehensile manipulation tasks, such as object
tracking, surface following, single-arm object pushing and dual-arm object
pushing. In doing this, two technical challenges had to be overcome. Firstly,
the use of tactile data that includes shear-induced slippage can lead to
error-prone estimates unsuitable for accurate control, and so we modified the
CNN into a Gaussian-density neural network and used a discriminative Bayesian
filter to improve the predictions with a state dynamics model that utilizes the
robot kinematics. Secondly, to achieve smooth robot motion in 3D space while
interacting with objects, we used SE(3) velocity-based servo control, which
required re-deriving the Bayesian filter update equations using Lie group
theory, as many standard assumptions do not hold for state variables defined on
non-Euclidean manifolds. In future, we believe that pose and shear-based
tactile servoing will enable many object manipulation tasks and the
fully-dexterous utilization of multi-fingered tactile robot hands. Video:
https://www.youtube.com/watch?v=xVs4hd34ek0
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08413" title="Abstract">arXiv:2312.08413</a> [<a href="/pdf/2312.08413" title="Download PDF">pdf</a>, <a href="/ps/2312.08413" title="Download PostScript">ps</a>, <a href="/format/2312.08413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Constrained Fairness Estimation for Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Steen%2C+F">Florian van der Steen</a>, 
<a href="/search/cs?searchtype=author&query=Vink%2C+F">Fr&#xe9; Vink</a>, 
<a href="/search/cs?searchtype=author&query=Kaya%2C+H">Heysem Kaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, under review in Applied Intelligence journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
<p class="mathjax">The protection of sensitive data becomes more vital, as data increases in
value and potency. Furthermore, the pressure increases from regulators and
society on model developers to make their Artificial Intelligence (AI) models
non-discriminatory. To boot, there is a need for interpretable, transparent AI
models for high-stakes tasks. In general, measuring the fairness of any AI
model requires the sensitive attributes of the individuals in the dataset, thus
raising privacy concerns. In this work, the trade-offs between fairness,
privacy and interpretability are further explored. We specifically examine the
Statistical Parity (SP) of Decision Trees (DTs) with Differential Privacy (DP),
that are each popular methods in their respective subfield. We propose a novel
method, dubbed Privacy-Aware Fairness Estimation of Rules (PAFER), that can
estimate SP in a DP-aware manner for DTs. DP, making use of a third-party legal
entity that securely holds this sensitive data, guarantees privacy by adding
noise to the sensitive data. We experimentally compare several DP mechanisms.
We show that using the Laplacian mechanism, the method is able to estimate SP
with low error while guaranteeing the privacy of the individuals in the dataset
with high certainty. We further show experimentally and theoretically that the
method performs better for DTs that humans generally find easier to interpret.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08417" title="Abstract">arXiv:2312.08417</a> [<a href="/pdf/2312.08417" title="Download PDF">pdf</a>, <a href="/format/2312.08417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmbAu: A Novel Technique to Embed Audio Data Using Shuffled Frog Leaping  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nokhwal%2C+S">Sahil Nokhwal</a>, 
<a href="/search/cs?searchtype=author&query=Pahune%2C+S">Saurabh Pahune</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Ankit Chaudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The aim of steganographic algorithms is to identify the appropriate pixel
positions in the host or cover image, where bits of sensitive information can
be concealed for data encryption. Work is being done to improve the capacity to
integrate sensitive information and to maintain the visual appearance of the
steganographic image. Consequently, steganography is a challenging research
area. In our currently proposed image steganographic technique, we used the
Shuffled Frog Leaping Algorithm (SFLA) to determine the order of pixels by
which sensitive information can be placed in the cover image. To achieve
greater embedding capacity, pixels from the spatial domain of the cover image
are carefully chosen and used for placing the sensitive data. Bolstered via
image steganography, the final image after embedding is resistant to
steganalytic attacks. The SFLA algorithm serves in the optimal pixels selection
of any colored (RGB) cover image for secret bit embedding. Using the fitness
function, the SFLA benefits by reaching a minimum cost value in an acceptable
amount of time. The pixels for embedding are meticulously chosen to minimize
the host image's distortion upon embedding. Moreover, an effort has been taken
to make the detection of embedded data in the steganographic image a formidable
challenge. Due to the enormous need for audio data encryption in the current
world, we feel that our suggested method has significant potential in
real-world applications. In this paper, we propose and compare our strategy to
existing steganographic methods.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08418" title="Abstract">arXiv:2312.08418</a> [<a href="/pdf/2312.08418" title="Download PDF">pdf</a>, <a href="/ps/2312.08418" title="Download PostScript">ps</a>, <a href="/format/2312.08418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Bug Detection in Games using LSTM Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizi%2C+E">Elham Azizi</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+L">Loutfouz Zaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Conference on Games 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">We introduced a new framework to detect perceptual bugs using a Long
Short-Term Memory (LSTM) network, which detects bugs in video games as
anomalies. The detected buggy frames are then clustered to determine the
category of the occurred bug. The framework was evaluated on two First Person
Shooter (FPS) games. Results show the effectiveness of the framework.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08459" title="Abstract">arXiv:2312.08459</a> [<a href="/pdf/2312.08459" title="Download PDF">pdf</a>, <a href="/format/2312.08459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aneja%2C+S">Shivangi Aneja</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Video: <a href="https://youtu.be/7Jf0kawrA3Q">this https URL</a> Project Page: <a href="https://shivangi-aneja.github.io/projects/facetalk/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce FaceTalk, a novel generative approach designed for synthesizing
high-fidelity 3D motion sequences of talking human heads from input audio
signal. To capture the expressive, detailed nature of human heads, including
hair, ears, and finer-scale eye movements, we propose to couple speech signal
with the latent space of neural parametric head models to create high-fidelity,
temporally coherent motion sequences. We propose a new latent diffusion model
for this task, operating in the expression space of neural parametric head
models, to synthesize audio-driven realistic head sequences. In the absence of
a dataset with corresponding NPHM expressions to audio, we optimize for these
correspondences to produce a dataset of temporally-optimized NPHM expressions
fit to audio-video recordings of people talking. To the best of our knowledge,
this is the first work to propose a generative approach for realistic and
high-quality motion synthesis of volumetric human heads, representing a
significant advancement in the field of audio-driven 3D animation. Notably, our
approach stands out in its ability to generate plausible motion sequences that
can produce high-fidelity head animation coupled with the NPHM shape space. Our
experimental results substantiate the effectiveness of FaceTalk, consistently
achieving superior and visually natural motion, encompassing diverse facial
expressions and styles, outperforming existing methods by 75% in perceptual
user study evaluation.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08461" title="Abstract">arXiv:2312.08461</a> [<a href="/pdf/2312.08461" title="Download PDF">pdf</a>, <a href="/format/2312.08461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Approximation with Shallow Neural Networks in Fourier  Lebesgue spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdeljawad%2C+A">Ahmed Abdeljawad</a>, 
<a href="/search/cs?searchtype=author&query=Dittrich%2C+T">Thomas Dittrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Approximation capabilities of shallow neural networks (SNNs) form an integral
part in understanding the properties of deep neural networks (DNNs). In the
study of these approximation capabilities some very popular classes of target
functions are the so-called spectral Barron spaces. This spaces are of special
interest when it comes to the approximation of partial differential equation
(PDE) solutions. It has been shown that the solution of certain static PDEs
will lie in some spectral Barron space. In order to alleviate the limitation to
static PDEs and include a time-domain that might have a different regularity
than the space domain, we extend the notion of spectral Barron spaces to
anisotropic weighted Fourier-Lebesgue spaces. In doing so, we consider target
functions that have two blocks of variables, among which each block is allowed
to have different decay and integrability properties. For these target
functions we first study the inclusion of anisotropic weighted Fourier-Lebesgue
spaces in the Bochner-Sobolev spaces. With that we can now also measure the
approximation error in terms of an anisotropic Sobolev norm, namely the
Bochner-Sobolev norm. We use this observation in a second step where we
establish a bound on the approximation rate for functions from the anisotropic
weighted Fourier-Lebesgue spaces and approximation via SNNs in the
Bochner-Sobolev norm.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08463" title="Abstract">arXiv:2312.08463</a> [<a href="/pdf/2312.08463" title="Download PDF">pdf</a>, <a href="/format/2312.08463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How much can change in a year? Revisiting Evaluation in Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siddarth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+O">Omayma Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=de+Kock%2C+R">Ruan de Kock</a>, 
<a href="/search/cs?searchtype=author&query=Khlifi%2C+W">Wiem Khlifi</a>, 
<a href="/search/cs?searchtype=author&query=Vall%2C+A">Abidine Vall</a>, 
<a href="/search/cs?searchtype=author&query=Tessera%2C+K">Kale-ab Tessera</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, AAAI XAI4DRL workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Establishing sound experimental standards and rigour is important in any
growing field of research. Deep Multi-Agent Reinforcement Learning (MARL) is
one such nascent field. Although exciting progress has been made, MARL has
recently come under scrutiny for replicability issues and a lack of
standardised evaluation methodology, specifically in the cooperative setting.
Although protocols have been proposed to help alleviate the issue, it remains
important to actively monitor the health of the field. In this work, we extend
the database of evaluation methodology previously published by containing
meta-data on MARL publications from top-rated conferences and compare the
findings extracted from this updated database to the trends identified in their
work. Our analysis shows that many of the worrying trends in performance
reporting remain. This includes the omission of uncertainty quantification, not
reporting all relevant evaluation details and a narrowing of algorithmic
development classes. Promisingly, we do observe a trend towards more difficult
scenarios in SMAC-v1, which if continued into SMAC-v2 will encourage novel
algorithmic development. Our data indicate that replicability needs to be
approached more proactively by the MARL community to ensure trust in the field
as we move towards exciting new frontiers.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08466" title="Abstract">arXiv:2312.08466</a> [<a href="/pdf/2312.08466" title="Download PDF">pdf</a>, <a href="/format/2312.08466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Quantifying Individual Agent Importance in Cooperative MARL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+O">Omayma Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=de+Kock%2C+R">Ruan de Kock</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siddarth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Khlifi%2C+W">Wiem Khlifi</a>, 
<a href="/search/cs?searchtype=author&query=Vall%2C+A">Abidine Vall</a>, 
<a href="/search/cs?searchtype=author&query=Tessera%2C+K">Kale-ab Tessera</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, AAAI XAI4DRL workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Measuring the contribution of individual agents is challenging in cooperative
multi-agent reinforcement learning (MARL). In cooperative MARL, team
performance is typically inferred from a single shared global reward. Arguably,
among the best current approaches to effectively measure individual agent
contributions is to use Shapley values. However, calculating these values is
expensive as the computational complexity grows exponentially with respect to
the number of agents. In this paper, we adapt difference rewards into an
efficient method for quantifying the contribution of individual agents,
referred to as Agent Importance, offering a linear computational complexity
relative to the number of agents. We show empirically that the computed values
are strongly correlated with the true Shapley values, as well as the true
underlying individual agent rewards, used as the ground truth in environments
where these are available. We demonstrate how Agent Importance can be used to
help study MARL systems by diagnosing algorithmic failures discovered in prior
MARL benchmarking work. Our analysis illustrates Agent Importance as a valuable
explainability component for future MARL benchmarks.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08467" title="Abstract">arXiv:2312.08467</a> [<a href="/pdf/2312.08467" title="Download PDF">pdf</a>, <a href="/ps/2312.08467" title="Download PostScript">ps</a>, <a href="/format/2312.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Culturally Responsive Artificial Intelligence -- Problems, Challenges  and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%C5%BCegalska-%C5%81ukasik%2C+N">Natalia O&#x17c;egalska-&#x141;ukasik</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81ukasik%2C+S">Szymon &#x141;ukasik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the contemporary interconnected world, the concept of cultural
responsibility occupies paramount importance. As the lines between nations
become less distinct, it is incumbent upon individuals, communities, and
institutions to assume the responsibility of safeguarding and valuing the
landscape of diverse cultures that constitute our global society. This paper
explores the socio-cultural and ethical challenges stemming from the
implementation of AI algorithms and highlights the necessity for their
culturally responsive development. It also offers recommendations on essential
elements required to enhance AI systems' adaptability to meet the demands of
contemporary multicultural societies. The paper highlights the need for further
multidisciplinary research to create AI models that effectively address these
challenges. It also advocates the significance of AI enculturation and
underlines the importance of regulatory measures to promote cultural
responsibility in AI systems.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08468" title="Abstract">arXiv:2312.08468</a> [<a href="/pdf/2312.08468" title="Download PDF">pdf</a>, <a href="/format/2312.08468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Diagnostics for Understanding Agent Training Behaviour in Cooperative  MARL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khlifi%2C+W">Wiem Khlifi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siddarth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+O">Omayma Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=de+Kock%2C+R">Ruan de Kock</a>, 
<a href="/search/cs?searchtype=author&query=Vall%2C+A">Abidine Vall</a>, 
<a href="/search/cs?searchtype=author&query=Gorsane%2C+R">Rihab Gorsane</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, AAAI XAI4DRL workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Cooperative multi-agent reinforcement learning (MARL) has made substantial
strides in addressing the distributed decision-making challenges. However, as
multi-agent systems grow in complexity, gaining a comprehensive understanding
of their behaviour becomes increasingly challenging. Conventionally, tracking
team rewards over time has served as a pragmatic measure to gauge the
effectiveness of agents in learning optimal policies. Nevertheless, we argue
that relying solely on the empirical returns may obscure crucial insights into
agent behaviour. In this paper, we explore the application of explainable AI
(XAI) tools to gain profound insights into agent behaviour. We employ these
diagnostics tools within the context of Level-Based Foraging and Multi-Robot
Warehouse environments and apply them to a diverse array of MARL algorithms. We
demonstrate how our diagnostics can enhance the interpretability and
explainability of MARL systems, providing a better understanding of agent
behaviour.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08472" title="Abstract">arXiv:2312.08472</a> [<a href="/pdf/2312.08472" title="Download PDF">pdf</a>, <a href="/format/2312.08472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoNumerics-Zero: Automated Discovery of State-of-the-Art Mathematical  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Real%2C+E">Esteban Real</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rossini%2C+M">Mirko Rossini</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+C">Connal de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+M">Manav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Verghese%2C+A">Akhil Verghese</a>, 
<a href="/search/cs?searchtype=author&query=Firsching%2C+M">Moritz Firsching</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+Q+V">Quoc V. Le</a>, 
<a href="/search/cs?searchtype=author&query=Cubuk%2C+E+D">Ekin Dogus Cubuk</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D+H">David H. Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Computers calculate transcendental functions by approximating them through
the composition of a few limited-precision instructions. For example, an
exponential can be calculated with a Taylor series. These approximation methods
were developed over the centuries by mathematicians, who emphasized the
attainability of arbitrary precision. Computers, however, operate on few
limited precision types, such as the popular float32. In this study, we show
that when aiming for limited precision, existing approximation methods can be
outperformed by programs automatically discovered from scratch by a simple
evolutionary algorithm. In particular, over real numbers, our method can
approximate the exponential function reaching orders of magnitude more
precision for a given number of operations when compared to previous
approaches. More practically, over float32 numbers and constrained to less than
1 ULP of error, the same method attains a speedup over baselines by generating
code that triggers better XLA/LLVM compilation paths. In other words, in both
cases, evolution searched a vast space of possible programs, without knowledge
of mathematics, to discover previously unknown optimized approximations to high
precision, for the first time. We also give evidence that these results extend
beyond the exponential. The ubiquity of transcendental functions suggests that
our method has the potential to reduce the cost of scientific computing
applications.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08477" title="Abstract">arXiv:2312.08477</a> [<a href="/pdf/2312.08477" title="Download PDF">pdf</a>, <a href="/format/2312.08477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E&amp;V: Prompting Large Language Models to Perform Static Analysis by  Pseudo-code Execution and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yu Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiteng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weidong Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, under submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Static analysis, the process of examining code without executing it, is
crucial for identifying software issues. Yet, static analysis is hampered by
its complexity and the need for customization for different targets.
Traditional static analysis tools require extensive human effort and are often
limited to specific target programs and programming languages. Recent
advancements in Large Language Models (LLMs), such as GPT-4 and Llama, offer
new capabilities for software engineering tasks. However, their application in
static analysis, especially in understanding complex code structures, remains
under-explored. This paper introduces a novel approach named E&amp;V , which
leverages LLMs to perform static analysis. Specifically, E&amp;V employs LLMs to
simulate the execution of pseudo-code, effectively conducting static analysis
encoded in the pseudo-code with minimal human effort, thereby improving the
accuracy of results. E&amp;V includes a verification process for pseudo-code
execution without needing an external oracle. This process allows E&amp;V to
mitigate hallucinations of LLMs and enhance the accuracy of static analysis
results. We have implemented E&amp;V in a prototype tool designed for triaging
crashes through backward taint analysis. This prototype, paired with GPT-4-32k,
has been applied to triage 170 recently fixed Linux kernel bugs across seven
bug categories. Our experiments demonstrate that the prototype correctly
identifies the blamed function in 81.2% of the cases. Additionally, we observe
that our novel verification process significantly improves the accuracy,
increasing it from 28.2% to 81.2%.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08479" title="Abstract">arXiv:2312.08479</a> [<a href="/pdf/2312.08479" title="Download PDF">pdf</a>, <a href="/ps/2312.08479" title="Download PostScript">ps</a>, <a href="/format/2312.08479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformer-Based Deep Learning for Histologic Classification of  Endometrial Cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+M">Manu Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Tafe%2C+L+J">Laura J. Tafe</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J+X">James X. Feng</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+K+E">Kristen E. Muller</a>, 
<a href="/search/cs?searchtype=author&query=Hondelink%2C+L">Liesbeth Hondelink</a>, 
<a href="/search/cs?searchtype=author&query=Bentz%2C+J+L">Jessica L. Bentz</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S">Saeed Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Tables and 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Endometrial cancer, the sixth most common cancer in females worldwide,
presents as a heterogeneous group with certain types prone to recurrence.
Precise histologic evaluation of endometrial cancer is essential for effective
patient management and determining the best treatment modalities. This study
introduces EndoNet, a transformer-based deep learning approach for histologic
classification of endometrial cancer. EndoNet uses convolutional neural
networks for extracting histologic features and a vision transformer for
aggregating these features and classifying slides based on their visual
characteristics. The model was trained on 929 digitized hematoxylin and
eosin-stained whole slide images of endometrial cancer from hysterectomy cases
at Dartmouth Health. It classifies these slides into low grade (Endometroid
Grades 1 and 2) and high-grade (endometroid carcinoma FIGO grade 3, uterine
serous carcinoma, carcinosarcoma) categories. EndoNet was evaluated on an
internal test set of 218 slides and an external test set of 100 random slides
from the public TCGA database. The model achieved a weighted average F1-score
of 0.92 (95% CI: 0.87-0.95) and an AUC of 0.93 (95% CI: 0.88-0.96) on the
internal test, and 0.86 (95% CI: 0.80-0.94) for F1-score and 0.86 (95% CI:
0.75-0.93) for AUC on the external test. Pending further validation, EndoNet
has the potential to assist pathologists in classifying challenging gynecologic
pathology tumors and enhancing patient care.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08484" title="Abstract">arXiv:2312.08484</a> [<a href="/pdf/2312.08484" title="Download PDF">pdf</a>, <a href="/format/2312.08484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-learners Can Provably Collude in the Iterated Prisoner&#x27;s Dilemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+Q">Quentin Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=Duque%2C+J">Juan Duque</a>, 
<a href="/search/cs?searchtype=author&query=Calvano%2C+E">Emilio Calvano</a>, 
<a href="/search/cs?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The deployment of machine learning systems in the market economy has
triggered academic and institutional fears over potential tacit collusion
between fully automated agents. Multiple recent economics studies have
empirically shown the emergence of collusive strategies from agents guided by
machine learning algorithms. In this work, we prove that multi-agent Q-learners
playing the iterated prisoner's dilemma can learn to collude. The complexity of
the cooperative multi-agent setting yields multiple fixed-point policies for
$Q$-learning: the main technical contribution of this work is to characterize
the convergence towards a specific cooperative policy. More precisely, in the
iterated prisoner's dilemma, we show that with optimistic Q-values, any
self-play Q-learner can provably learn a cooperative policy called Pavlov, also
referred to as win-stay, lose-switch policy, which strongly differs from the
vanilla Pareto-dominated always defect policy.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08488" title="Abstract">arXiv:2312.08488</a> [<a href="/pdf/2312.08488" title="Download PDF">pdf</a>, <a href="/format/2312.08488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PnP for Two-Dimensional Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Joshua Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose a PnP algorithm for a camera constrained to two-dimensional
movement (applicable, for instance, to many wheeled robotics platforms).
Leveraging this assumption allows performance improvements over 3D PnP
algorithms due to the reduction in search space dimensionality. It also reduces
the incidence of ambiguous pose estimates (as, in most cases, the spurious
solutions fall outside the plane of movement). Our algorithm finds an
approximate solution using geometric criteria and refines its prediction
iteratively. We compare this algorithm to existing 3D PnP algorithms in the
cases of general and coplanar point configurations.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08489" title="Abstract">arXiv:2312.08489</a> [<a href="/pdf/2312.08489" title="Download PDF">pdf</a>, <a href="/ps/2312.08489" title="Download PostScript">ps</a>, <a href="/format/2312.08489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connectivity Oracles for Predictable Vertex Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bingbing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kosinas%2C+E">Evangelos Kosinas</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+A">Adam Polak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The problem of designing connectivity oracles supporting vertex failures is
one of the basic data structures problems for undirected graphs. It is already
well understood: previous works [Duan--Pettie STOC'10; Long--Saranurak FOCS'22]
achieve query time linear in the number of failed vertices, and it is
conditionally optimal as long as we require preprocessing time polynomial in
the size of the graph and update time polynomial in the number of failed
vertices.
<br />We revisit this problem in the paradigm of algorithms with predictions: we
ask if the query time can be improved if the set of failed vertices can be
predicted beforehand up to a small number of errors. More specifically, we
design a data structure that, given a graph $G=(V,E)$ and a set of vertices
predicted to fail $\widehat{D} \subseteq V$ of size $d=|\widehat{D}|$,
preprocesses it in time $\tilde{O}(d|E|)$ and then can receive an update given
as the symmetric difference between the predicted and the actual set of failed
vertices $\widehat{D} \triangle D = (\widehat{D} \setminus D) \cup (D \setminus
\widehat{D})$ of size $\eta = |\widehat{D} \triangle D|$, process it in time
$\tilde{O}(\eta^4)$, and after that answer connectivity queries in $G \setminus
D$ in time $O(\eta)$. Viewed from another perspective, our data structure
provides an improvement over the state of the art for the \emph{fully dynamic
subgraph connectivity problem} in the \emph{sensitivity setting}
[Henzinger--Neumann ESA'16].
<br />We argue that the preprocessing time and query time of our data structure are
conditionally optimal under standard fine-grained complexity assumptions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08494" title="Abstract">arXiv:2312.08494</a> [<a href="/pdf/2312.08494" title="Download PDF">pdf</a>, <a href="/format/2312.08494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerMod: Perceptually Grounded Voice Modification with Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Netzorg%2C+R">Robin Netzorg</a>, 
<a href="/search/cs?searchtype=author&query=Jalal%2C+A">Ajil Jalal</a>, 
<a href="/search/cs?searchtype=author&query=McNulty%2C+L">Luna McNulty</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala Krishna Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Perceptual modification of voice is an elusive goal. While non-experts can
modify an image or sentence perceptually with available tools, it is not clear
how to similarly modify speech along perceptual axes. Voice conversion does
make it possible to convert one voice to another, but these modifications are
handled by black box models, and the specifics of what perceptual qualities to
modify and how to modify them are unclear. Towards allowing greater perceptual
control over voice, we introduce PerMod, a conditional latent diffusion model
that takes in an input voice and a perceptual qualities vector, and produces a
voice with the matching perceptual qualities. Unlike prior work, PerMod
generates a new voice corresponding to specific perceptual modifications.
Evaluating perceptual quality vectors with RMSE from both human and predicted
labels, we demonstrate that PerMod produces voices with the desired perceptual
qualities for typical voices, but performs poorly on atypical voices.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08495" title="Abstract">arXiv:2312.08495</a> [<a href="/pdf/2312.08495" title="Download PDF">pdf</a>, <a href="/format/2312.08495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Accuracy: Automated De-Identification of Large Real-World  Clinical Text Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocaman%2C+V">Veysel Kocaman</a>, 
<a href="/search/cs?searchtype=author&query=Haq%2C+H+U">Hasham Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Talby%2C+D">David Talby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research advances achieve human-level accuracy for de-identifying
free-text clinical notes on research datasets, but gaps remain in reproducing
this in large real-world settings. This paper summarizes lessons learned from
building a system used to de-identify over one billion real clinical notes, in
a fully automated way, that was independently certified by multiple
organizations for production use. A fully automated solution requires a very
high level of accuracy that does not require manual review. A hybrid
context-based model architecture is described, which outperforms a Named Entity
Recogniton (NER) - only model by 10% on the i2b2-2014 benchmark. The proposed
system makes 50%, 475%, and 575% fewer errors than the comparable AWS, Azure,
and GCP services respectively while also outperforming ChatGPT by 33%. It
exceeds 98% coverage of sensitive data across 7 European languages, without a
need for fine tuning. A second set of described models enable data obfuscation
-- replacing sensitive data with random surrogates -- while retaining name,
date, gender, clinical, and format consistency. Both the practical need and the
solution architecture that provides for reliable &amp; linked anonymized documents
are described.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08499" title="Abstract">arXiv:2312.08499</a> [<a href="/pdf/2312.08499" title="Download PDF">pdf</a>, <a href="/ps/2312.08499" title="Download PostScript">ps</a>, <a href="/format/2312.08499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNTuple: Towards First-Class Support for HPC data centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miotto%2C+G+L">Giovanna Lazzari Miotto</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Gomez%2C+J">Javier Lopez-Gomez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21st International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2022), 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Accelerator Physics (physics.acc-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Compared to LHC Run 1 and Run 2, future HEP experiments, e.g., at the HL-LHC,
will increase the volume of generated data by an order of magnitude. In order
to sustain the expected analysis throughput, ROOT's RNTuple I/O subsystem has
been engineered to overcome the bottlenecks of the TTree I/O subsystem,
focusing also on a compact data format, asynchronous and parallel requests, and
a layered architecture that allows supporting distributed filesystem-less
storage systems, e.g. HPC-oriented object stores. In a previous publication, we
introduced and evaluated the RNTuple's native backend for Intel DAOS. Since its
first prototype, we carried out a number of improvements both on RNTuple and
its DAOS backend aiming to saturate the physical link, such as support for
vector writes and an improved RNTuple-to-DAOS mapping, only to name a few. In
parallel, the latest developments allow for better integration between RNTuple
and ROOT's storage-agnostic, declarative interface to write HEP analyses,
RDataFrame. In this work, we contribute with the following: (i) a redesign of
the RNTuple DAOS backend, including a mechanism for efficient population of the
object store based on existing data; and (ii) an experimental evaluation on a
single-node platform, showing a significant increase in the analysis throughput
for typical HEP workflows.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08504" title="Abstract">arXiv:2312.08504</a> [<a href="/pdf/2312.08504" title="Download PDF">pdf</a>, <a href="/ps/2312.08504" title="Download PostScript">ps</a>, <a href="/format/2312.08504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1/2 Approximate MMS Allocation for Separable Piecewise Linear Concave  Valuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chekuri%2C+C">Chandra Chekuri</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+P">Pooja Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+R">Rucha Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+R">Ruta Mehta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI Conference on Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study fair distribution of a collection of m indivisible goods among a
group of n agents, using the widely recognized fairness principles of Maximin
Share (MMS) and Any Price Share (APS). These principles have undergone thorough
investigation within the context of additive valuations. We explore these
notions for valuations that extend beyond additivity.
<br />First, we study approximate MMS under the separable (piecewise-linear)
concave (SPLC) valuations, an important class generalizing additive, where the
best known factor was 1/3-MMS. We show that 1/2-MMS allocation exists and can
be computed in polynomial time, significantly improving the state-of-the-art.
We note that SPLC valuations introduce an elevated level of intricacy in
contrast to additive. For instance, the MMS value of an agent can be as high as
her value for the entire set of items. Further, the equilibrium computation
problem, which is polynomial-time for additive valuations, becomes intractable
for SPLC. We use a relax-and-round paradigm that goes through competitive
equilibrium and LP relaxation. Our result extends to give (symmetric) 1/2-APS,
a stronger guarantee than MMS.
<br />APS is a stronger notion that generalizes MMS by allowing agents with
arbitrary entitlements. We study the approximation of APS under submodular
valuation functions. We design and analyze a simple greedy algorithm using
concave extensions of submodular functions. We prove that the algorithm gives a
1/3-APS allocation which matches the current best-known factor. Concave
extensions are hard to compute in polynomial time and are, therefore, generally
not used in approximation algorithms. Our approach shows a way to utilize it
within analysis (while bypassing its computation), and might be of independent
interest.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08509" title="Abstract">arXiv:2312.08509</a> [<a href="/pdf/2312.08509" title="Download PDF">pdf</a>, <a href="/ps/2312.08509" title="Download PostScript">ps</a>, <a href="/format/2312.08509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating APS under Submodular and XOS valuations with Binary  Marginals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+P">Pooja Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+R">Rucha Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+R">Ruta Mehta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the problem of fairly dividing indivisible goods among a set of
agents under the fairness notion of Any Price Share (APS). APS is known to
dominate the widely studied Maximin share (MMS). Since an exact APS allocation
may not exist, the focus has traditionally been on the computation of
approximate APS allocations. Babaioff et al. studied the problem under additive
valuations, and asked (i) how large can the APS value be compared to the MMS
value? and (ii) what guarantees can one achieve beyond additive functions. We
partly answer these questions by considering valuations beyond additive, namely
submodular and XOS functions, with binary marginals.
<br />For the submodular functions with binary marginals, also known as matroid
rank functions (MRFs), we show that APS is exactly equal to MMS. Consequently,
we get that an exact APS allocation exists and can be computed efficiently
while maximizing the social welfare. Complementing this result, we show that it
is NP-hard to compute the APS value within a factor of 5/6 for submodular
valuations with three distinct marginals of {0, 1/2, 1}.
<br />We then consider binary XOS functions, which are immediate generalizations of
binary submodular functions in the complement free hierarchy. In contrast to
the MRFs setting, MMS and APS values are not equal under this case.
Nevertheless, we show that under binary XOS valuations, $MMS \leq APS \leq 2
\cdot MMS + 1$. Further, we show that this is almost the tightest bound we can
get using MMS, by giving an instance where $APS \geq 2 \cdot MMS$. The upper
bound on APS, implies a ~0.1222-approximation for APS under binary XOS
valuations. And the lower bound implies the non-existence of better than
0.5-APS even when agents have identical valuations, which is in sharp contrast
to the guaranteed existence of exact MMS allocation when agent valuations are
identical.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08510" title="Abstract">arXiv:2312.08510</a> [<a href="/pdf/2312.08510" title="Download PDF">pdf</a>, <a href="/format/2312.08510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance evaluation of Private and Public Blockchains for multi-cloud  service federation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahir%2C+A">Adam Zahir</a>, 
<a href="/search/cs?searchtype=author&query=Groshev%2C+M">Milan Groshev</a>, 
<a href="/search/cs?searchtype=author&query=Antevski%2C+K">Kiril Antevski</a>, 
<a href="/search/cs?searchtype=author&query=Bernardos%2C+C+J">Carlos J.Bernardos</a>, 
<a href="/search/cs?searchtype=author&query=Ayimba%2C+C">Constantine Ayimba</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Oliva%2C+A">Antonio de la Oliva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The stringent low-latency, high reliability, availability and resilience
requirements of 6G use cases will present challenges to cloud providers.
Currently, cloud providers lack simple, efficient, and secure implementation of
provisioning solutions that meet these challenges. Multi-cloud federation is a
promising approach. In this paper, we evaluate the application of private and
public blockchain networks for multi-cloud federation. We compare the
performance of blockchain-based federation in private and public blockchain
networks and their integration with a production-ready orchestration solution.
Our results show that the public blockchain needs approximately 91 seconds to
complete the federation procedure compared to the 48 seconds in the private
blockchain scenario.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08511" title="Abstract">arXiv:2312.08511</a> [<a href="/pdf/2312.08511" title="Download PDF">pdf</a>, <a href="/format/2312.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Relative Value of Prediction in Algorithmic Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perdomo%2C+J+C">Juan Carlos Perdomo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Theoretical Economics (econ.TH); Machine Learning (stat.ML)

</div>
<p class="mathjax">Algorithmic predictions are increasingly used to inform the allocations of
goods and interventions in the public sphere. In these domains, predictions
serve as a means to an end. They provide stakeholders with insights into
likelihood of future events as a means to improve decision making quality, and
enhance social welfare. However, if maximizing welfare is the ultimate goal,
prediction is only a small piece of the puzzle. There are various other policy
levers a social planner might pursue in order to improve bottom-line outcomes,
such as expanding access to available goods, or increasing the effect sizes of
interventions.
<br />Given this broad range of design decisions, a basic question to ask is: What
is the relative value of prediction in algorithmic decision making? How do the
improvements in welfare arising from better predictions compare to those of
other policy levers? The goal of our work is to initiate the formal study of
these questions. Our main results are theoretical in nature. We identify
simple, sharp conditions determining the relative value of prediction
vis-\`a-vis expanding access, within several statistical models that are
popular amongst quantitative social scientists. Furthermore, we illustrate how
these theoretical insights may be used to guide the design of algorithmic
decision making systems in practice.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08514" title="Abstract">arXiv:2312.08514</a> [<a href="/pdf/2312.08514" title="Download PDF">pdf</a>, <a href="/format/2312.08514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3T: Multi-Scale Memory Matching for Video Object Segmentation and  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+R">Raghav Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wan-Cyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Siam%2C+M">Mennatullah Siam</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures and 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Object Segmentation (VOS) has became increasingly important with
availability of larger datasets and more complex and realistic settings, which
involve long videos with global motion (e.g, in egocentric settings), depicting
small objects undergoing both rigid and non-rigid (including state)
deformations. While a number of recent approaches have been explored for this
task, these data characteristics still present challenges. In this work we
propose a novel, DETR-style encoder-decoder architecture, which focuses on
systematically analyzing and addressing aforementioned challenges.
Specifically, our model enables on-line inference with long videos in a
windowed fashion, by breaking the video into clips and propagating context
among them using time-coded memory. We illustrate that short clip length and
longer memory with learned time-coding are important design choices for
achieving state-of-the-art (SoTA) performance. Further, we propose multi-scale
matching and decoding to ensure sensitivity and accuracy for small objects.
Finally, we propose a novel training strategy that focuses learning on portions
of the video where an object undergoes significant deformations -- a form of
"soft" hard-negative mining, implemented as loss-reweighting. Collectively,
these technical contributions allow our model to achieve SoTA performance on
two complex datasets -- VISOR and VOST. A series of detailed ablations validate
our design choices as well as provide insights into the importance of parameter
choices and their impact on performance.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08515" title="Abstract">arXiv:2312.08515</a> [<a href="/pdf/2312.08515" title="Download PDF">pdf</a>, <a href="/format/2312.08515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplicial Representation Learning with Neural $k$-forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maggs%2C+K">Kelly Maggs</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+C">Celia Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+B">Bastian Rieck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages; comments and feedback are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">Geometric deep learning extends deep learning to incorporate information
about the geometry and topology data, especially in complex domains like
graphs. Despite the popularity of message passing in this field, it has
limitations such as the need for graph rewiring, ambiguity in interpreting
data, and over-smoothing. In this paper, we take a different approach, focusing
on leveraging geometric information from simplicial complexes embedded in
$\mathbb{R}^n$ using node coordinates. We use differential k-forms in
\mathbb{R}^n to create representations of simplices, offering interpretability
and geometric consistency without message passing. This approach also enables
us to apply differential geometry tools and achieve universal approximation.
Our method is efficient, versatile, and applicable to various input complexes,
including graphs, simplicial complexes, and cell complexes. It outperforms
existing message passing neural networks in harnessing information from
geometrical graphs with node features serving as coordinates.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08516" title="Abstract">arXiv:2312.08516</a> [<a href="/pdf/2312.08516" title="Download PDF">pdf</a>, <a href="/ps/2312.08516" title="Download PostScript">ps</a>, <a href="/format/2312.08516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A shooting-Newton procedure for solving fractional terminal value  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brugnano%2C+L">Luigi Brugnano</a>, 
<a href="/search/math?searchtype=author&query=Gurioli%2C+G">Gianmarco Gurioli</a>, 
<a href="/search/math?searchtype=author&query=Iavernaro%2C+F">Felice Iavernaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we consider the numerical solution of fractional terminal value
problems (FDE-TVPs). In particular, the proposed procedure uses a Newton-type
iteration which is particularly efficient when coupled with a
recently-introduced step-by-step procedure for solving fractional initial value
problems (FDE-IVPs), able to produce spectrally accurate solutions of FDE
problems. Some numerical tests are reported to make evidence of its
effectiveness.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08517" title="Abstract">arXiv:2312.08517</a> [<a href="/pdf/2312.08517" title="Download PDF">pdf</a>, <a href="/format/2312.08517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Debiased) Contrastive Learning Loss for Recommendation (Technical  Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruoming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript was initially submitted for review in February 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we perform a systemic examination of the recommendation
losses, including listwise (softmax), pairwise(BPR), and pointwise
(mean-squared error, MSE, and Cosine Contrastive Loss, CCL) losses through the
lens of contrastive learning. We introduce and study both debiased InfoNCE and
mutual information neural estimator (MINE), for the first time, under the
recommendation setting. We also relate and differentiate these two losses with
the BPR loss through the lower bound analysis. Furthermore, we present the
debiased pointwise loss (for both MSE and CCL) and theoretically certify both
iALS and EASE, two of the most popular linear models, are inherently debiased.
The empirical experimental results demonstrate the effectiveness of the
debiased losses and newly introduced mutual-information losses outperform the
existing (biased) ones.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08520" title="Abstract">arXiv:2312.08520</a> [<a href="/pdf/2312.08520" title="Download PDF">pdf</a>, <a href="/format/2312.08520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Recommendation Loss Functions through Contrastive Learning  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruoming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript was initially submitted for review in August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Inspired by the success of contrastive learning, we systematically examine
recommendation losses, including listwise (softmax), pairwise (BPR), and
pointwise (MSE and CCL) losses. In this endeavor, we introduce InfoNCE+, an
optimized generalization of InfoNCE with balance coefficients, and highlight
its performance advantages, particularly when aligned with our new decoupled
contrastive loss, MINE+. We also leverage debiased InfoNCE to debias pointwise
recommendation loss (CCL) as Debiased CCL. Interestingly, our analysis reveals
that linear models like iALS and EASE are inherently debiased. Empirical
results demonstrates the effectiveness of MINE+ and Debiased-CCL.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08523" title="Abstract">arXiv:2312.08523</a> [<a href="/pdf/2312.08523" title="Download PDF">pdf</a>, <a href="/format/2312.08523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Inductance and Thermal Regression and Optimization for  Automatic Layout Design of Power Modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parque%2C+V">Victor Parque</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+A">Aiki Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Miyashita%2C+T">Tomoyuki Miyashita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper presented at 2023 IEEE CPMT Symposium Japan (ICSJ)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computational Engineering, Finance, and Science (cs.CE); Performance (cs.PF); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Power modules with excellent inductance and temperature metrics are
significant to meet the rising sophistication of energy demand in new
technologies. In this paper, we use a surrogate-based approach to render
optimal layouts of power modules with feasible and attractive
inductance-temperature ratios at low computational budget. In particular, we
use the class of feedforward networks to estimate the surrogate relationships
between power module layout-design variables and inductance-temperature factors
rendered from simulations; and Differential Evolution algorithms to optimize
and locate feasible layout configurations of power module substrates minimizing
inductance and temperature ratios. Our findings suggest the desirable classes
of feedforward networks and gradient-free optimization algorithms being able to
estimate and optimize power module layouts efficiently and effectively.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08528" title="Abstract">arXiv:2312.08528</a> [<a href="/pdf/2312.08528" title="Download PDF">pdf</a>, <a href="/format/2312.08528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> auto-sktime: Automated Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%B6ller%2C+M">Marc-Andr&#xe9; Z&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M+F">Marco F. Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In today's data-driven landscape, time series forecasting is pivotal in
decision-making across various sectors. Yet, the proliferation of more diverse
time series data, coupled with the expanding landscape of available forecasting
methods, poses significant challenges for forecasters. To meet the growing
demand for efficient forecasting, we introduce auto-sktime, a novel framework
for automated time series forecasting. The proposed framework uses the power of
automated machine learning (AutoML) techniques to automate the creation of the
entire forecasting pipeline. The framework employs Bayesian optimization, to
automatically construct pipelines from statistical, machine learning (ML) and
deep neural network (DNN) models. Furthermore, we propose three essential
improvements to adapt AutoML to time series data: First, pipeline templates to
account for the different supported forecasting models. Second, a novel
warm-starting technique to start the optimization from prior optimization runs.
Third, we adapt multi-fidelity optimizations to make them applicable to a
search space containing statistical, ML and DNN models. Experimental results on
64 diverse real-world time series datasets demonstrate the effectiveness and
efficiency of the framework, outperforming traditional methods while requiring
minimal human involvement.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08531" title="Abstract">arXiv:2312.08531</a> [<a href="/pdf/2312.08531" title="Download PDF">pdf</a>, <a href="/ps/2312.08531" title="Download PostScript">ps</a>, <a href="/format/2312.08531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The preliminary version was submitted in September 2023. This extended version was finished in November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the past several years, the convergence of the last iterate of the
Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due
to its good performance in practice but lack of theoretical understanding. For
Lipschitz and convex functions, different works have established the optimal
$O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$
high-probability convergence rates for the final iterate, where $T$ is the time
horizon and $\delta$ is the failure probability. However, to prove these
bounds, all the existing works are limited to compact domains or require almost
surely bounded noises. It is natural to ask whether the last iterate of SGD can
still guarantee the optimal convergence rate but without these two restrictive
assumptions. Besides this important question, there are still lots of
theoretical problems lacking an answer. For example, compared with the last
iterate convergence of SGD for non-smooth problems, only few results for smooth
optimization have yet been developed. Additionally, the existing results are
all limited to a non-composite objective and the standard Euclidean norm. It
still remains unclear whether the last-iterate convergence can be provably
extended to wider composite optimization and non-Euclidean norms. In this work,
to address the issues mentioned above, we revisit the last-iterate convergence
of stochastic gradient methods and provide the first unified way to prove the
convergence rates both in expectation and in high probability to accommodate
general domains, composite objectives, non-Euclidean norms, Lipschitz
conditions, smoothness and (strong) convexity simultaneously. Additionally, we
extend our analysis to obtain the last-iterate convergence under heavy-tailed
noises.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08532" title="Abstract">arXiv:2312.08532</a> [<a href="/pdf/2312.08532" title="Download PDF">pdf</a>, <a href="/format/2312.08532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Learning for Cost-Adaptive Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xingli Fang</a>, 
<a href="/search/cs?searchtype=author&query=Bradford%2C+R">Richard Bradford</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jung-Eun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a cooperative training framework for deep neural network
architectures that enables the runtime network depths to change to satisfy
dynamic computing resource requirements. In our framework, the number of layers
participating in computation can be chosen dynamically to meet performance-cost
trade-offs at inference runtime. Our method trains two Teammate nets and a
Leader net, and two sets of Teammate sub-networks with various depths through
knowledge distillation. The Teammate nets derive sub-networks and transfer
knowledge to them, and to each other, while the Leader net guides Teammate nets
to ensure accuracy. The approach trains the framework atomically at once
instead of individually training various sizes of models; in a sense, the
various-sized networks are all trained at once, in a "package deal." The
proposed framework is not tied to any specific architecture but can incorporate
any existing models/architectures, therefore it can maintain stable results and
is insensitive to the size of a dataset's feature map. Compared with other
related approaches, it provides comparable accuracy to its full network while
various sizes of models are available.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08533" title="Abstract">arXiv:2312.08533</a> [<a href="/pdf/2312.08533" title="Download PDF">pdf</a>, <a href="/format/2312.08533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> World Models via Policy-Guided Trajectory Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigter%2C+M">Marc Rigter</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+J">Jun Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">World models are a powerful tool for developing intelligent agents. By
predicting the outcome of a sequence of actions, world models enable policies
to be optimised via on-policy reinforcement learning (RL) using synthetic data,
i.e. in ``in imagination''. Existing world models are autoregressive, and
interleave predicting the next state with sampling the next action from the
policy. Thus, the prediction error inevitably compounds as the trajectory
length grows. In this work, we propose a novel world modelling approach that is
not autoregressive and generates entire on-policy trajectories via a single
pass through a diffusion model. Our approach, Policy-Guided Trajectory
Diffusion (PolyGRAD), leverages a denoising model in addition to the gradient
of the action distribution of the policy to diffuse a trajectory of initially
random states and actions into an on-policy synthetic trajectory. We analyse
the capabilities of our approach and demonstrate that it obtains competitive
prediction errors to state-of-the-art autoregressive baselines. PolyGRAD also
enables performant policies to be trained via on-policy RL in imagination. We
believe that PolyGRAD introduces a promising paradigm for world modelling with
many possible extensions to explore in future work.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08535" title="Abstract">arXiv:2312.08535</a> [<a href="/pdf/2312.08535" title="Download PDF">pdf</a>, <a href="/format/2312.08535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occupancy Detection Based on Electricity Consumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brilland%2C+T">Thomas Brilland</a>, 
<a href="/search/cs?searchtype=author&query=Matheron%2C+G">Guillaume Matheron</a>, 
<a href="/search/cs?searchtype=author&query=Leduc%2C+L">Laetitia Leduc</a>, 
<a href="/search/cs?searchtype=author&query=Nakada%2C+Y">Yukihide Nakada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">This article presents a new methodology for extracting intervals when a home
is vacant from low-frequency electricity consumption data. The approach
combines multiple algorithms, including change point detection, classification,
period detection, and periodic spikes retrieval. It shows encouraging results
on both simulated and real consumption curves. This approach offers practical
insights for optimizing energy use and holds potential benefits for residential
consumers and utility companies in terms of energy cost reduction and
sustainability. Further research is needed to enhance its applicability in
diverse settings and with larger datasets.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08536" title="Abstract">arXiv:2312.08536</a> [<a href="/pdf/2312.08536" title="Download PDF">pdf</a>, <a href="/format/2312.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov Decision Processes with Noisy State Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afsharrad%2C+A">Amirhossein Afsharrad</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+S">Sanjay Lall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the challenge of a particular class of noisy state
observations in Markov Decision Processes (MDPs), a common issue in various
real-world applications. We focus on modeling this uncertainty through a
confusion matrix that captures the probabilities of misidentifying the true
state. Our primary goal is to estimate the inherent measurement noise, and to
this end, we propose two novel algorithmic approaches. The first, the method of
second-order repetitive actions, is designed for efficient noise estimation
within a finite time window, providing identifiable conditions for system
analysis. The second approach comprises a family of Bayesian algorithms, which
we thoroughly analyze and compare in terms of performance and limitations. We
substantiate our theoretical findings with simulations, demonstrating the
effectiveness of our methods in different scenarios, particularly highlighting
their behavior in environments with varying stationary distributions. Our work
advances the understanding of reinforcement learning in noisy environments,
offering robust techniques for more accurate state estimation in MDPs.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08537" title="Abstract">arXiv:2312.08537</a> [<a href="/pdf/2312.08537" title="Download PDF">pdf</a>, <a href="/format/2312.08537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Conformance Alignments with Synchronization (Extended  Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gianola%2C+A">Alessandro Gianola</a>, 
<a href="/search/cs?searchtype=author&query=Montali%2C+M">Marco Montali</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+S">Sarah Winkler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Real-world processes operate on objects that are inter-dependent. To
accurately reflect the nature of such processes, object-centric process mining
techniques are needed, notably conformance checking. However, while the
object-centric perspective has recently gained traction, few concrete process
mining techniques have been presented so far. Moreover, existing approaches are
severely limited in their abilities to keep track of object identity and object
dependencies. Consequently, serious problems in logs remain undetected. In this
paper, we present a new formalism that combines the key modelling features of
two existing approaches, in particular the ability of object-centric Petri nets
to capture one-to-many relations and the one of Petri nets with identifiers to
compare and synchronize objects based on their identity. We call the resulting
formalism 'object-centric Petri nets with identifiers', and define alignments
and the conformance checking task for this setting. We propose a conformance
checking approach for such nets based on an encoding in satisfiability modulo
theories (SMT), and illustrate how it can be effectively used to overcome
shortcomings of earlier work. To assess its practicality, we perform an
evaluation on data from the literature.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08538" title="Abstract">arXiv:2312.08538</a> [<a href="/pdf/2312.08538" title="Download PDF">pdf</a>, <a href="/format/2312.08538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contractive error feedback for gradient compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+P">Parameswaran Raman</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">On-device memory concerns in distributed deep learning have become severe due
to (i) the growth of model size in multi-GPU training, and (ii) the wide
adoption of deep neural networks for federated learning on IoT devices which
have limited storage. In such settings, communication efficient optimization
methods are attractive alternatives, however they still struggle with memory
issues. To tackle these challenges, we propose an communication efficient
method called contractive error feedback (ConEF). As opposed to SGD with
error-feedback (EFSGD) that inefficiently manages memory, ConEF obtains the
sweet spot of convergence and memory usage, and achieves communication
efficiency by leveraging biased and all-reducable gradient compression. We
empirically validate ConEF on various learning tasks that include image
classification, language modeling, and machine translation and observe that
ConEF saves 80\% - 90\% of the extra memory in EFSGD with almost no loss on
test performance, while also achieving 1.3x - 5x speedup of SGD. Through our
work, we also demonstrate the feasibility and convergence of ConEF to clear up
the theoretical barrier of integrating ConEF to popular memory efficient
frameworks such as ZeRO-3.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08539" title="Abstract">arXiv:2312.08539</a> [<a href="/pdf/2312.08539" title="Download PDF">pdf</a>, <a href="/format/2312.08539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Searching for Minimal Integer Representation of Undirected Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parque%2C+V">Victor Parque</a>, 
<a href="/search/cs?searchtype=author&query=Miyashita%2C+T">Tomoyuki Miyashita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted and presented at The 30th International Conference on Neural Information Processing (ICONIP2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Neural and Evolutionary Computing (cs.NE); Combinatorics (math.CO)

</div>
<p class="mathjax">Minimal and efficient graph representations are key to store, communicate,
and sample the search space of graphs and networks while meeting user-defined
criteria. In this paper, we investigate the feasibility of gradient-free
optimization heuristics based on Differential Evolution to search for minimal
integer representations of undirected graphs. The class of Differential
Evolution algorithms are population-based gradient-free optimization heuristics
having found a relevant attention in the nonconvex and nonlinear optimization
communities. Our computational experiments using eight classes of Differential
Evolution schemes and graph instances with varying degrees of sparsity have
shown the merit of attaining minimal numbers for graph encoding/representation
rendered by exploration-oriented strategies within few function evaluations.
Our results have the potential to elucidate new number-based encoding and
sample-based algorithms for graph representation, network design and
optimization.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08540" title="Abstract">arXiv:2312.08540</a> [<a href="/pdf/2312.08540" title="Download PDF">pdf</a>, <a href="/format/2312.08540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covering Rectilinear Polygons with Area-Weighted Rectangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanauer%2C+K">Kathrin Hanauer</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+M+P">Martin P. Seybold</a>, 
<a href="/search/cs?searchtype=author&query=Unterweger%2C+J">Julian Unterweger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ALENEX 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Representing a polygon using a set of simple shapes has numerous applications
in different use-case scenarios. We consider the problem of covering the
interior of a rectilinear polygon with holes by a set of area-weighted,
axis-aligned rectangles such that the total weight of the rectangles in the
cover is minimized. Already the unit-weight case is known to be NP-hard and the
general problem has, to the best of our knowledge, not been studied
experimentally before.
<br />We show a new basic property of optimal solutions of the weighted problem.
This allows us to speed up existing algorithms for the unit-weight case, obtain
an improved ILP formulation for both the weighted and unweighted problem, and
develop several approximation algorithms and heuristics for the weighted case.
<br />All our algorithms are evaluated in a large experimental study on 186 837
polygons combined with six cost functions, which provides evidence that our
algorithms are both fast and yield close-to-optimal solutions in practice.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08543" title="Abstract">arXiv:2312.08543</a> [<a href="/pdf/2312.08543" title="Download PDF">pdf</a>, <a href="/format/2312.08543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Diversity: Empowering OSS Project Leaders with Community  Diversity and Turnover Dashboards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guizani%2C+M">Mariam Guizani</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zixuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Arteaga%2C+E+J">Emily Judith Arteaga</a>, 
<a href="/search/cs?searchtype=author&query=Ca%C3%B1as-D%C3%ADaz%2C+L">Luis Ca&#xf1;as-D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Serebrenik%2C+A">Alexander Serebrenik</a>, 
<a href="/search/cs?searchtype=author&query=Sarma%2C+A">Anita Sarma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Managing open-source software (OSS) projects requires managing communities of
contributors. In particular, it is essential for project leaders to understand
their community's diversity and turnover. We present CommunityTapestry, a
dynamic real-time community dashboard, which presents key diversity and
turnover signals that we identified from the literature and through
participatory design sessions with stakeholders. We evaluated CommunityTapestry
with an OSS project's contributors and Project Management Committee members,
who explored the dashboard using their own project data. Our study results
demonstrate that CommunityTapestry increased participants' awareness of their
community composition and the diversity and turnover rates in the project. It
helped them identify areas of improvement and gave them actionable information.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08548" title="Abstract">arXiv:2312.08548</a> [<a href="/pdf/2312.08548" title="Download PDF">pdf</a>, <a href="/format/2312.08548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVP: Enhanced Visual Perception using Inverse Multi-Attentive Feature  Refinement and Regularized Image-Text Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lavreniuk%2C+M">Mykola Lavreniuk</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S+F">Shariq Farooq Bhat</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Matthias M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents the network architecture EVP (Enhanced Visual Perception).
EVP builds on the previous work VPD which paved the way to use the Stable
Diffusion network for computer vision tasks. We propose two major enhancements.
First, we develop the Inverse Multi-Attentive Feature Refinement (IMAFR) module
which enhances feature learning capabilities by aggregating spatial information
from higher pyramid levels. Second, we propose a novel image-text alignment
module for improved feature extraction of the Stable Diffusion backbone. The
resulting architecture is suitable for a wide variety of tasks and we
demonstrate its performance in the context of single-image depth estimation
with a specialized decoder using classification-based bins and referring
segmentation with an off-the-shelf decoder. Comprehensive experiments conducted
on established datasets show that EVP achieves state-of-the-art results in
single-image depth estimation for indoor (NYU Depth v2, 11.8% RMSE improvement
over VPD) and outdoor (KITTI) environments, as well as referring segmentation
(RefCOCO, 2.53 IoU improvement over ReLA). The code and pre-trained models are
publicly available at https://github.com/Lavreniuk/EVP.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08549" title="Abstract">arXiv:2312.08549</a> [<a href="/pdf/2312.08549" title="Download PDF">pdf</a>, <a href="/format/2312.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A COLREGs-Compliant Conflict Resolution Strategy for Autonomous Surface  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakar%2C+R">Raghav Thakar</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+R">Rajat Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=PB%2C+S">Sujit PB</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel conflict resolution strategy for autonomous
surface vehicles (ASVs) to safely navigate and avoid collisions in a
multi-vessel environment at sea. Collisions between two or more marine vessels
must be avoided by following the International Regulations for Preventing
Collisions at Sea (COLREGs). We propose strategy a two-phase strategy called as
COLREGs Compliant Conflict-Resolving (COMCORE) strategy, that generates
collision-free trajectories for ASVs while complying with COLREGs. In phase-1,
a shortest path for each agent is determined, while in phase-2 conflicts are
detected and resolved by modifying the path in compliance with COLREGs. COMCORE
solution optimises vessel trajectories for lower costs while also providing a
safe and collision-free plan for each vessel. Simulation results are presented
to show the applicability of COMCORE for larger number agents with very low
computational requirement and hence scalable. Further, we experimentally
demonstrate COMCORE for two ASVs in a lake to show its ability to determine
solution and implementation capability in the real-world.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08550" title="Abstract">arXiv:2312.08550</a> [<a href="/pdf/2312.08550" title="Download PDF">pdf</a>, <a href="/format/2312.08550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonics of Learning: Universal Fourier Features Emerge in Invariant  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marchetti%2C+G+L">Giovanni Luca Marchetti</a>, 
<a href="/search/cs?searchtype=author&query=Hillar%2C+C">Christopher Hillar</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we formally prove that, under certain conditions, if a neural
network is invariant to a finite group then its weights recover the Fourier
transform on that group. This provides a mathematical explanation for the
emergence of Fourier features -- a ubiquitous phenomenon in both biological and
artificial learning systems. The results hold even for non-commutative groups,
in which case the Fourier transform encodes all the irreducible unitary group
representations. Our findings have consequences for the problem of symmetry
discovery. Specifically, we demonstrate that the algebraic structure of an
unknown group can be recovered from the weights of a network that is at least
approximately invariant within certain bounds. Overall, this work contributes
to a foundation for an algebraic learning theory of invariant neural network
representations.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08554" title="Abstract">arXiv:2312.08554</a> [<a href="/pdf/2312.08554" title="Download PDF">pdf</a>, <a href="/format/2312.08554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Robot Coordination: A Subproblem-based Approach for Hybrid  Multi-Robot Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solis%2C+I">Irving Solis</a>, 
<a href="/search/cs?searchtype=author&query=Motes%2C+J">James Motes</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Mike Qin</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+M">Marco Morales</a>, 
<a href="/search/cs?searchtype=author&query=Amato%2C+N+M">Nancy M. Amato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This work presents Adaptive Robot Coordination (ARC), a novel hybrid
framework for multi-robot motion planning (MRMP) that employs local subproblems
to resolve inter-robot conflicts. ARC creates subproblems centered around
conflicts, and the solutions represent the robot motions required to resolve
these conflicts. The use of subproblems enables an inexpensive hybrid
exploration of the multi-robot planning space. ARC leverages the hybrid
exploration by dynamically adjusting the coupling and decoupling of the
multi-robot planning space. This allows ARC to adapt the levels of coordination
efficiently by planning in decoupled spaces, where robots can operate
independently, and in coupled spaces where coordination is essential. ARC is
probabilistically complete, can be used for any robot, and produces efficient
cost solutions in reduced planning times. Through extensive evaluation across
representative scenarios with different robots requiring various levels of
coordination, ARC demonstrates its ability to provide simultaneous scalability
and precise coordination. ARC is the only method capable of solving all the
scenarios and is competitive with coupled, decoupled, and hybrid baselines.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08557" title="Abstract">arXiv:2312.08557</a> [<a href="/pdf/2312.08557" title="Download PDF">pdf</a>, <a href="/format/2312.08557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating and Querying Data Cubes in Python using pyCube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vang%2C+S">Sigmundur Vang</a>, 
<a href="/search/cs?searchtype=author&query=Thomsen%2C+C">Christian Thomsen</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T+B">Torben Bach Pedersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data cubes are used for analyzing large data sets usually contained in data
warehouses. The most popular data cube tools use graphical user interfaces
(GUI) to do the data analysis. Traditionally this was fine since data analysts
were not expected to be technical people. However, in the subsequent decades
the data landscape changed dramatically requiring companies to employ large
teams of highly technical data scientists in order to manage and use the ever
increasing amount of data. These data scientists generally use tools like
Python, interactive notebooks, pandas, etc. while modern data cube tools are
still GUI based. This paper proposes a Python-based data cube tool called
pyCube. pyCube is able to semi-automatically create data cubes for data stored
in an RDBMS and manages the data cube metadata. pyCube's programmatic interface
enables data scientist to query data cubes by specifying the expected metadata
of the result. pyCube is experimentally evaluated on Star Schema Benchmark
(SSB). The results show that pyCube vastly outperforms different
implementations of SSB queries in pandas in both runtime and memory while being
easier to read and write.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08558" title="Abstract">arXiv:2312.08558</a> [<a href="/pdf/2312.08558" title="Download PDF">pdf</a>, <a href="/format/2312.08558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-MEMP: Gaze-Enhanced Multimodal Ego-Motion Prediction in Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbiyik%2C+M+E">M. Eren Akbiyik</a>, 
<a href="/search/cs?searchtype=author&query=Savov%2C+N">Nedko Savov</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+N">Nikola Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Vater%2C+C">Christian Vater</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding the decision-making process of drivers is one of the keys to
ensuring road safety. While the driver intent and the resulting ego-motion
trajectory are valuable in developing driver-assistance systems, existing
methods mostly focus on the motions of other vehicles. In contrast, we focus on
inferring the ego trajectory of a driver's vehicle using their gaze data. For
this purpose, we first collect a new dataset, GEM, which contains high-fidelity
ego-motion videos paired with drivers' eye-tracking data and GPS coordinates.
Next, we develop G-MEMP, a novel multimodal ego-trajectory prediction network
that combines GPS and video input with gaze data. We also propose a new metric
called Path Complexity Index (PCI) to measure the trajectory complexity. We
perform extensive evaluations of the proposed method on both GEM and DR(eye)VE,
an existing benchmark dataset. The results show that G-MEMP significantly
outperforms state-of-the-art methods in both benchmarks. Furthermore, ablation
studies demonstrate over 20% improvement in average displacement using gaze
data, particularly in challenging driving scenarios with a high PCI. The data,
code, and models can be found at https://eth-ait.github.io/g-memp/.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08559" title="Abstract">arXiv:2312.08559</a> [<a href="/pdf/2312.08559" title="Download PDF">pdf</a>, <a href="/format/2312.08559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Active Learning in Low-Data Regimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camilleri%2C+R">Romain Camilleri</a>, 
<a href="/search/cs?searchtype=author&query=Wagenmaker%2C+A">Andrew Wagenmaker</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstern%2C+J">Jamie Morgenstern</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+L">Lalit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">In critical machine learning applications, ensuring fairness is essential to
avoid perpetuating social inequities. In this work, we address the challenges
of reducing bias and improving accuracy in data-scarce environments, where the
cost of collecting labeled data prohibits the use of large, labeled datasets.
In such settings, active learning promises to maximize marginal accuracy gains
of small amounts of labeled data. However, existing applications of active
learning for fairness fail to deliver on this, typically requiring large
labeled datasets, or failing to ensure the desired fairness tolerance is met on
the population distribution.
<br />To address such limitations, we introduce an innovative active learning
framework that combines an exploration procedure inspired by posterior sampling
with a fair classification subroutine. We demonstrate that this framework
performs effectively in very data-scarce regimes, maximizing accuracy while
satisfying fairness constraints with high probability. We evaluate our proposed
approach using well-established real-world benchmark datasets and compare it
against state-of-the-art methods, demonstrating its effectiveness in producing
fair models, and improvement over existing methods.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08563" title="Abstract">arXiv:2312.08563</a> [<a href="/pdf/2312.08563" title="Download PDF">pdf</a>, <a href="/format/2312.08563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient-NeRF2NeRF: Streamlining Text-Driven 3D Editing with Multiview  Correspondence-Enhanced Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liangchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liangliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://lsongx.github.io/projects/en2n.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advancement of text-driven 3D content editing has been blessed by the
progress from 2D generative diffusion models. However, a major obstacle
hindering the widespread adoption of 3D content editing is its time-intensive
processing. This challenge arises from the iterative and refining steps
required to achieve consistent 3D outputs from 2D image-based generative
models. Recent state-of-the-art methods typically require optimization time
ranging from tens of minutes to several hours to edit a 3D scene using a single
GPU. In this work, we propose that by incorporating correspondence
regularization into diffusion models, the process of 3D editing can be
significantly accelerated. This approach is inspired by the notion that the
estimated samples during diffusion should be multiview-consistent during the
diffusion generation process. By leveraging this multiview consistency, we can
edit 3D content at a much faster speed. In most scenarios, our proposed
technique brings a 10$\times$ speed-up compared to the baseline method and
completes the editing of a 3D scene in 2 minutes with comparable quality.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08566" title="Abstract">arXiv:2312.08566</a> [<a href="/pdf/2312.08566" title="Download PDF">pdf</a>, <a href="/format/2312.08566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning adaptive planning representations with natural language  guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lionel Wong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Pratyusha Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+Z+S">Zachary S. Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiahai Feng</a>, 
<a href="/search/cs?searchtype=author&query=Korneev%2C+N">Noa Korneev</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">Effective planning in the real world requires not only world knowledge, but
the ability to leverage that knowledge to build the right representation of the
task at hand. Decades of hierarchical planning techniques have used
domain-specific temporal action abstractions to support efficient and accurate
planning, almost always relying on human priors and domain knowledge to
decompose hard tasks into smaller subproblems appropriate for a goal or set of
goals. This paper describes Ada (Action Domain Acquisition), a framework for
automatically constructing task-specific planning representations using
task-general background knowledge from language models (LMs). Starting with a
general-purpose hierarchical planner and a low-level goal-conditioned policy,
Ada interactively learns a library of planner-compatible high-level action
abstractions and low-level controllers adapted to a particular domain of
planning tasks. On two language-guided interactive planning benchmarks (Mini
Minecraft and ALFRED Household Tasks), Ada strongly outperforms other
approaches that use LMs for sequential decision-making, offering more accurate
plans and better generalization to complex tasks.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08568" title="Abstract">arXiv:2312.08568</a> [<a href="/pdf/2312.08568" title="Download PDF">pdf</a>, <a href="/format/2312.08568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NViST: In the Wild New View Synthesis from a Single Image with  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+W">Wonbong Jang</a>, 
<a href="/search/cs?searchtype=author&query=Agapito%2C+L">Lourdes Agapito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://wbjang.github.io/nvist_webpage">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose NViST, a transformer-based model for novel-view synthesis from a
single image, trained on a large-scale dataset of in-the-wild images with
complex backgrounds. NViST transforms image inputs directly into a radiance
field, adopting a scalable transformer-based architecture. In practice, NViST
exploits the self-supervised features learnt by a masked autoencoder (MAE), and
learns a novel decoder that translates features to 3D tokens via
cross-attention and adaptive layer normalization. Our model is efficient at
inference since only a single forward-pass is needed to predict a 3D
representation, unlike methods that require test-time optimization or sampling
such as 3D-aware diffusion models. We tackle further limitations of current
new-view synthesis models. First, unlike most generative models that are
trained in a category-specific manner, often on synthetic datasets or on masked
inputs, our model is trained on MVImgNet, a large-scale dataset of real-world,
casually-captured videos containing hundreds of object categories with diverse
backgrounds. Secondly, our model does not require canonicalization of the
training data - i.e. aligning all objects with a frontal view - only needing
relative pose at training time which removes a substantial barrier to it being
used on casually captured datasets. We show results on unseen objects and
categories on MVImgNet and even casual phone captures. We conduct qualitative
and quantitative evaluations on MVImgNet and ShapeNet to show that our model
represents a step forward towards enabling true in-the-wild novel-view
synthesis from a single image.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08571" title="Abstract">arXiv:2312.08571</a> [<a href="/pdf/2312.08571" title="Download PDF">pdf</a>, <a href="/format/2312.08571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhasePerturbation: Speech Data Augmentation via Phase Perturbation for  Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chengxi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Satwinder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+F">Feng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaoyun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruili Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Most of the current speech data augmentation methods operate on either the
raw waveform or the amplitude spectrum of speech. In this paper, we propose a
novel speech data augmentation method called PhasePerturbation that operates
dynamically on the phase spectrum of speech. Instead of statically rotating a
phase by a constant degree, PhasePerturbation utilizes three dynamic phase
spectrum operations, i.e., a randomization operation, a frequency masking
operation, and a temporal masking operation, to enhance the diversity of speech
data. We conduct experiments on wav2vec2.0 pre-trained ASR models by
fine-tuning them with the PhasePerturbation augmented TIMIT corpus. The
experimental results demonstrate 10.9\% relative reduction in the word error
rate (WER) compared with the baseline model fine-tuned without any augmentation
operation. Furthermore, the proposed method achieves additional improvements
(12.9\% and 15.9\%) in WER by complementing the Vocal Tract Length Perturbation
(VTLP) and the SpecAug, which are both amplitude spectrum-based augmentation
methods. The results highlight the capability of PhasePerturbation to improve
the current amplitude spectrum-based augmentation methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08577" title="Abstract">arXiv:2312.08577</a> [<a href="/pdf/2312.08577" title="Download PDF">pdf</a>, <a href="/ps/2312.08577" title="Download PostScript">ps</a>, <a href="/format/2312.08577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Wireless Applications: A Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muttepawar%2C+V+L">Varun Laxman Muttepawar</a>, 
<a href="/search/cs?searchtype=author&query=Mehra%2C+A">Arjun Mehra</a>, 
<a href="/search/cs?searchtype=author&query=Shaban%2C+Z">Zubair Shaban</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+R">Ranjitha Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Jagadeesh%2C+H">Harshan Jagadeesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COMSNETS 2024 Demo Track (Accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Wireless embedded edge devices are ubiquitous in our daily lives, enabling
them to gather immense data via onboard sensors and mobile applications. This
offers an amazing opportunity to train machine learning (ML) models in the
realm of wireless devices for decision-making. Training ML models in a wireless
setting necessitates transmitting datasets collected at the edge to a cloud
parameter server, which is infeasible due to bandwidth constraints, security,
and privacy issues. To tackle these challenges, Federated Learning (FL) has
emerged as a distributed optimization approach to the decentralization of the
model training process. In this work, we present a novel prototype to examine
FL's effectiveness over bandwidth-constrained wireless channels. Through a
novel design consisting of Zigbee and NI USRP devices, we propose a
configuration that allows clients to broadcast synergistically local ML model
updates to a central server to obtain a generalized global model. We assess the
efficacy of this prototype using metrics such as global model accuracy and time
complexity under varying conditions of transmission power, data heterogeneity
and local learning.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08578" title="Abstract">arXiv:2312.08578</a> [<a href="/pdf/2312.08578" title="Download PDF">pdf</a>, <a href="/format/2312.08578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Picture is Worth More Than 77 Text Tokens: Evaluating CLIP-Style  Models on Dense Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urbanek%2C+J">Jack Urbanek</a>, 
<a href="/search/cs?searchtype=author&query=Bordes%2C+F">Florian Bordes</a>, 
<a href="/search/cs?searchtype=author&query=Astolfi%2C+P">Pietro Astolfi</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+M">Mary Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Romero-Soriano%2C+A">Adriana Romero-Soriano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Curation methods for massive vision-language datasets trade off between
dataset size and quality. However, even the highest quality of available
curated captions are far too short to capture the rich visual detail in an
image. To show the value of dense and highly-aligned image-text pairs, we
collect the Densely Captioned Images (DCI) dataset, containing 8012 natural
images human-annotated with mask-aligned descriptions averaging above 1000
words each. With precise and reliable captions associated with specific parts
of an image, we can evaluate vision-language models' (VLMs) understanding of
image content with a novel task that matches each caption with its
corresponding subcrop. As current models are often limited to 77 text tokens,
we also introduce a summarized version (sDCI) in which each caption length is
limited. We show that modern techniques that make progress on standard
benchmarks do not correspond with significant improvement on our sDCI based
benchmark. Lastly, we finetune CLIP using sDCI and show significant
improvements over the baseline despite a small training set. By releasing the
first human annotated dense image captioning dataset, we hope to enable the
development of new benchmarks or fine-tuning recipes for the next generation of
VLMs to come.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08579" title="Abstract">arXiv:2312.08579</a> [<a href="/pdf/2312.08579" title="Download PDF">pdf</a>, <a href="/ps/2312.08579" title="Download PostScript">ps</a>, <a href="/format/2312.08579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Planetary Names in Astronomy Papers: A Multi-Step Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapurian%2C+G">Golnaz Shapurian</a>, 
<a href="/search/cs?searchtype=author&query=Kurtz%2C+M+J">Michael J Kurtz</a>, 
<a href="/search/cs?searchtype=author&query=Accomazzi%2C+A">Alberto Accomazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">The automatic identification of planetary feature names in astronomy
publications presents numerous challenges. These features include craters,
defined as roughly circular depressions resulting from impact or volcanic
activity; dorsas, which are elongate raised structures or wrinkle ridges; and
lacus, small irregular patches of dark, smooth material on the Moon, referred
to as "lake" (Planetary Names Working Group, n.d.). Many feature names overlap
with places or people's names that they are named after, for example, Syria,
Tempe, Einstein, and Sagan, to name a few (U.S. Geological Survey, n.d.). Some
feature names have been used in many contexts, for instance, Apollo, which can
refer to mission, program, sample, astronaut, seismic, seismometers, core, era,
data, collection, instrument, and station, in addition to the crater on the
Moon. Some feature names can appear in the text as adjectives, like the lunar
craters Black, Green, and White. Some feature names in other contexts serve as
directions, like craters West and South on the Moon. Additionally, some
features share identical names across different celestial bodies, requiring
disambiguation, such as the Adams crater, which exists on both the Moon and
Mars. We present a multi-step pipeline combining rule-based filtering,
statistical relevance analysis, part-of-speech (POS) tagging, named entity
recognition (NER) model, hybrid keyword harvesting, knowledge graph (KG)
matching, and inference with a locally installed large language model (LLM) to
reliably identify planetary names despite these challenges. When evaluated on a
dataset of astronomy papers from the Astrophysics Data System (ADS), this
methodology achieves an F1-score over 0.97 in disambiguating planetary feature
names.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08583" title="Abstract">arXiv:2312.08583</a> [<a href="/pdf/2312.08583" title="Download PDF">pdf</a>, <a href="/format/2312.08583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroQuant(4+2): Redefining LLMs Quantization with a New FP6-Centric  Strategy for Diverse Generative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haojun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+S">Stephen Youn</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bakhtiari%2C+A">Arash Bakhtiari</a>, 
<a href="/search/cs?searchtype=author&query=Wyatt%2C+M">Michael Wyatt</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>, 
<a href="/search/cs?searchtype=author&query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Leon Song</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This study examines 4-bit quantization methods like GPTQ in large language
models (LLMs), highlighting GPTQ's overfitting and limited enhancement in
Zero-Shot tasks. While prior works merely focusing on zero-shot measurement, we
extend task scope to more generative categories such as code generation and
abstractive summarization, in which we found that INT4 quantization can
significantly underperform. However, simply shifting to higher precision
formats like FP6 has been particularly challenging, thus overlooked, due to
poor performance caused by the lack of sophisticated integration and system
acceleration strategies on current AI hardware. Our results show that FP6, even
with a coarse-grain quantization scheme, performs robustly across various
algorithms and tasks, demonstrating its superiority in accuracy and
versatility. Notably, with the FP6 quantization, \codestar-15B model performs
comparably to its FP16 counterpart in code generation, and for smaller models
like the 406M it closely matches their baselines in summarization. Neither can
be achieved by INT4. To better accommodate various AI hardware and achieve the
best system performance, we propose a novel 4+2 design for FP6 to achieve
similar latency to the state-of-the-art INT4 fine-grain quantization. With our
design, FP6 can become a promising solution to the current 4-bit quantization
methods used in LLMs.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08584" title="Abstract">arXiv:2312.08584</a> [<a href="/pdf/2312.08584" title="Download PDF">pdf</a>, <a href="/format/2312.08584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Content Dynamic Recommendation System Based in Adapted Tags and  Applied to Digital Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furtado%2C+T+B">Thiago Bellotti Furtado</a>, 
<a href="/search/cs?searchtype=author&query=Esmin%2C+A">Ahmed Esmin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The technological evolution of the library in the academic environment
brought a lot of information and documents that are available to access, but
these systems do not always have mechanisms to search in an integrated way the
relevant information for the user. To alleviate this problem, we propose a
recommendation system that generates the user profile through tags that are
reshaped over time. To trace the user profile the system uses information from
your lending history stored in the library database and it collects their
opinions (feedback) through a list of recommendations. These data are
integrated with the document base of institutional repository.Thus, the
recommendation system assists users in identifying relevant items and makes
suggestions for content in an integrated environment that contains
institutional repository documents and the university library database. The
proposed recommendation system uses a hybrid approach being applied in an
academic environment with the participation of the users.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08585" title="Abstract">arXiv:2312.08585</a> [<a href="/pdf/2312.08585" title="Download PDF">pdf</a>, <a href="/format/2312.08585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Key Factors of Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruifeng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge distillation, a technique for model compression and performance
enhancement, has gained significant traction in Neural Machine Translation
(NMT). However, existing research primarily focuses on empirical applications,
and there is a lack of comprehensive understanding of how student model
capacity, data complexity, and decoding strategies collectively influence
distillation effectiveness. Addressing this gap, our study conducts an in-depth
investigation into these factors, particularly focusing on their interplay in
word-level and sequence-level distillation within NMT. Through extensive
experimentation across datasets like IWSLT13 En$\rightarrow$Fr, IWSLT14
En$\rightarrow$De, and others, we empirically validate hypotheses related to
the impact of these factors on knowledge distillation. Our research not only
elucidates the significant influence of model capacity, data complexity, and
decoding strategies on distillation effectiveness but also introduces a novel,
optimized distillation approach. This approach, when applied to the IWSLT14
de$\rightarrow$en translation task, achieves state-of-the-art performance,
demonstrating its practical efficacy in advancing the field of NMT.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08586" title="Abstract">arXiv:2312.08586</a> [<a href="/pdf/2312.08586" title="Download PDF">pdf</a>, <a href="/format/2312.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating calibration error under label shift without labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popordanoska%2C+T">Teodora Popordanoska</a>, 
<a href="/search/cs?searchtype=author&query=Radevski%2C+G">Gorjan Radevski</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the face of dataset shift, model calibration plays a pivotal role in
ensuring the reliability of machine learning systems. Calibration error (CE) is
an indicator of the alignment between the predicted probabilities and the
classifier accuracy. While prior works have delved into the implications of
dataset shift on calibration, existing CE estimators assume access to labels
from the target domain, which are often unavailable in practice, i.e., when the
model is deployed and used. This work addresses such challenging scenario, and
proposes a novel CE estimator under label shift, which is characterized by
changes in the marginal label distribution $p(Y)$, while keeping the
conditional $p(X|Y)$ constant between the source and target distributions. Our
contribution is an approach, which, by leveraging importance re-weighting of
the labeled source distribution, provides consistent and asymptotically
unbiased CE estimation with respect to the shifted target distribution.
Empirical results across diverse real-world datasets, under various conditions
and label-shift intensities, demonstrate the effectiveness and reliability of
the proposed estimator.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08589" title="Abstract">arXiv:2312.08589</a> [<a href="/pdf/2312.08589" title="Download PDF">pdf</a>, <a href="/format/2312.08589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent and Asymptotically Unbiased Estimation of Proper Calibration  Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popordanoska%2C+T">Teodora Popordanoska</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+S+G">Sebastian G. Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Tiulpin%2C+A">Aleksei Tiulpin</a>, 
<a href="/search/cs?searchtype=author&query=Buettner%2C+F">Florian Buettner</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Proper scoring rules evaluate the quality of probabilistic predictions,
playing an essential role in the pursuit of accurate and well-calibrated
models. Every proper score decomposes into two fundamental components -- proper
calibration error and refinement -- utilizing a Bregman divergence. While
uncertainty calibration has gained significant attention, current literature
lacks a general estimator for these quantities with known statistical
properties. To address this gap, we propose a method that allows consistent,
and asymptotically unbiased estimation of all proper calibration errors and
refinement terms. In particular, we introduce Kullback--Leibler calibration
error, induced by the commonly used cross-entropy loss. As part of our results,
we prove the relation between refinement and f-divergences, which implies
information monotonicity in neural networks, regardless of which proper scoring
rule is optimized. Our experiments validate empirically the claimed properties
of the proposed estimator and suggest that the selection of a post-hoc
calibration method should be determined by the particular calibration error of
interest.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08591" title="Abstract">arXiv:2312.08591</a> [<a href="/pdf/2312.08591" title="Download PDF">pdf</a>, <a href="/format/2312.08591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint2Human: High-quality 3D Human Generation via Compact Spherical  Embedding of 3D Joints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhou Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D human generation is increasingly significant in various applications.
However, the direct use of 2D generative methods in 3D generation often results
in significant loss of local details, while methods that reconstruct geometry
from generated images struggle with global view consistency. In this work, we
introduce Joint2Human, a novel method that leverages 2D diffusion models to
generate detailed 3D human geometry directly, ensuring both global structure
and local details. To achieve this, we employ the Fourier occupancy field (FOF)
representation, enabling the direct production of 3D shapes as preliminary
results using 2D generative models. With the proposed high-frequency enhancer
and the multi-view recarving strategy, our method can seamlessly integrate the
details from different views into a uniform global shape.To better utilize the
3D human prior and enhance control over the generated geometry, we introduce a
compact spherical embedding of 3D joints. This allows for effective application
of pose guidance during the generation process. Additionally, our method is
capable of generating 3D humans guided by textual inputs. Our experimental
results demonstrate the capability of our method to ensure global structure,
local details, high resolution, and low computational cost, simultaneously.
More results and code can be found on our project page at
<a href="http://cic.tju.edu.cn/faculty/likun/projects/Joint2Human.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08592" title="Abstract">arXiv:2312.08592</a> [<a href="/pdf/2312.08592" title="Download PDF">pdf</a>, <a href="/format/2312.08592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dietary Assessment with Multimodal ChatGPT: A Systematic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+F+P+-">Frank P.-W. Lo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bo Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Giannarou%2C+S">Stamatia Giannarou</a>, 
<a href="/search/cs?searchtype=author&query=Frost%2C+G">Gary Frost</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+B">Benny Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional approaches to dietary assessment are primarily grounded in
self-reporting methods or structured interviews conducted under the supervision
of dietitians. These methods, however, are often subjective, potentially
inaccurate, and time-intensive. Although artificial intelligence (AI)-based
solutions have been devised to automate the dietary assessment process, these
prior AI methodologies encounter challenges in their ability to generalize
across a diverse range of food types, dietary behaviors, and cultural contexts.
This results in AI applications in the dietary field that possess a narrow
specialization and limited accuracy. Recently, the emergence of multimodal
foundation models such as GPT-4V powering the latest ChatGPT has exhibited
transformative potential across a wide range of tasks (e.g., Scene
understanding and image captioning) in numerous research domains. These models
have demonstrated remarkable generalist intelligence and accuracy, capable of
processing various data modalities. In this study, we explore the application
of multimodal ChatGPT within the realm of dietary assessment. Our findings
reveal that GPT-4V excels in food detection under challenging conditions with
accuracy up to 87.5% without any fine-tuning or adaptation using food-specific
datasets. By guiding the model with specific language prompts (e.g., African
cuisine), it shifts from recognizing common staples like rice and bread to
accurately identifying regional dishes like banku and ugali. Another GPT-4V's
standout feature is its contextual awareness. GPT-4V can leverage surrounding
objects as scale references to deduce the portion sizes of food items, further
enhancing its accuracy in translating food weight into nutritional content.
This alignment with the USDA National Nutrient Database underscores GPT-4V's
potential to advance nutritional science and dietary assessment techniques.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08593" title="Abstract">arXiv:2312.08593</a> [<a href="/pdf/2312.08593" title="Download PDF">pdf</a>, <a href="/ps/2312.08593" title="Download PostScript">ps</a>, <a href="/format/2312.08593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOSaiC: a Web-based Platform for Collaborative Medical Video Assessment  and Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazellier%2C+J">Jean-Paul Mazellier</a>, 
<a href="/search/cs?searchtype=author&query=Boujon%2C+A">Antoine Boujon</a>, 
<a href="/search/cs?searchtype=author&query=Bour-Lang%2C+M">M&#xe9;line Bour-Lang</a>, 
<a href="/search/cs?searchtype=author&query=Erharhd%2C+M">Ma&#xeb;l Erharhd</a>, 
<a href="/search/cs?searchtype=author&query=Waechter%2C+J">Julien Waechter</a>, 
<a href="/search/cs?searchtype=author&query=Wernert%2C+E">Emilie Wernert</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report presents MOSaiC 3.6.2, a web-based collaborative
platform designed for the annotation and evaluation of medical videos. MOSaiC
is engineered to facilitate video-based assessment and accelerate surgical data
science projects. We provide an overview of MOSaiC's key functionalities,
encompassing group and video management, annotation tools, ontologies,
assessment capabilities, and user administration. Finally, we briefly describe
several medical data science studies where MOSaiC has been instrumental in the
dataset development.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08594" title="Abstract">arXiv:2312.08594</a> [<a href="/pdf/2312.08594" title="Download PDF">pdf</a>, <a href="/format/2312.08594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CT-MVSNet: Efficient Multi-View Stereo with Cross-scale Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Lei Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 30th International Conference on Multimedia Modeling (MMM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent deep multi-view stereo (MVS) methods have widely incorporated
transformers into cascade network for high-resolution depth estimation,
achieving impressive results. However, existing transformer-based methods are
constrained by their computational costs, preventing their extension to finer
stages. In this paper, we propose a novel cross-scale transformer (CT) that
processes feature representations at different stages without additional
computation. Specifically, we introduce an adaptive matching-aware transformer
(AMT) that employs different interactive attention combinations at multiple
scales. This combined strategy enables our network to capture intra-image
context information and enhance inter-image feature relationships. Besides, we
present a dual-feature guided aggregation (DFGA) that embeds the coarse global
semantic information into the finer cost volume construction to further
strengthen global and local feature awareness. Meanwhile, we design a feature
metric loss (FM Loss) that evaluates the feature bias before and after
transformation to reduce the impact of feature mismatch on depth estimation.
Extensive experiments on DTU dataset and Tanks and Temples (T\&amp;T) benchmark
demonstrate that our method achieves state-of-the-art results. Code is
available at https://github.com/wscstrive/CT-MVSNet.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08595" title="Abstract">arXiv:2312.08595</a> [<a href="/pdf/2312.08595" title="Download PDF">pdf</a>, <a href="/format/2312.08595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits to the Energy Efficiency of CMOS Microprocessors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+A">Anson Ho</a>, 
<a href="/search/cs?searchtype=author&query=Erdil%2C+E">Ege Erdil</a>, 
<a href="/search/cs?searchtype=author&query=Besiroglu%2C+T">Tamay Besiroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">CMOS microprocessors have achieved massive energy efficiency gains but may
reach limits soon. This paper presents an approach to estimating the limits on
the maximum floating point operations per Joule (FLOP/J) for CMOS
microprocessors. We analyze the three primary sources of energy dissipation:
transistor switching, interconnect capacitances and leakage power. Using
first-principles calculations of minimum energy costs based on Landauer's
principle, prior estimates of relevant parameters, and empirical data on
hardware, we derive the energy cost per FLOP for each component. Combining
these yields a geometric mean estimate of 4.7e15 FP4/J for the maximum CMOS
energy efficiency, roughly two hundred-fold more efficient than current
microprocessors.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08598" title="Abstract">arXiv:2312.08598</a> [<a href="/pdf/2312.08598" title="Download PDF">pdf</a>, <a href="/format/2312.08598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotherNet: A Foundational Hypernetwork for Tabular Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+A">Andreas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Curino%2C+C">Carlo Curino</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+R">Raghu Ramakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The advent of Foundation Models is transforming machine learning across many
modalities (e.g., language, images, videos) with prompt engineering replacing
training in many settings. Recent work on tabular data (e.g., TabPFN) hints at
a similar opportunity to build Foundation Models for classification for
numerical data. In this paper, we go one step further and propose a
hypernetwork architecture that we call MotherNet, trained on millions of
classification tasks, that, once prompted with a never-seen-before training set
generates the weights of a trained ``child'' neural-network. Like other
Foundation Models, MotherNet replaces training on specific datasets with
in-context learning through a single forward pass. In contrast to existing
hypernetworks that were either task-specific or trained for relatively
constraint multi-task settings, MotherNet is trained to generate networks to
perform multiclass classification on arbitrary tabular datasets without any
dataset specific gradient descent.
<br />The child network generated by MotherNet using in-context learning
outperforms neural networks trained using gradient descent on small datasets,
and is competitive with predictions by TabPFN and standard ML methods like
Gradient Boosting. Unlike a direct application of transformer models like
TabPFN, MotherNet generated networks are highly efficient at inference time.
This methodology opens up a new approach to building predictive models on
tabular data that is both efficient and robust, without any dataset-specific
training.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08600" title="Abstract">arXiv:2312.08600</a> [<a href="/pdf/2312.08600" title="Download PDF">pdf</a>, <a href="/ps/2312.08600" title="Download PostScript">ps</a>, <a href="/format/2312.08600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CartoMark: a benchmark dataset for map pattern recognition and 1 map  content retrieval with machine intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kaiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhenfeng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhigang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Maps are fundamental medium to visualize and represent the real word in a
simple and 16 philosophical way. The emergence of the 3rd wave information has
made a proportion of maps are available to be generated ubiquitously, which
would significantly enrich the dimensions and perspectives to understand the
characteristics of the real world. However, a majority of map dataset have
never been discovered, acquired and effectively used, and the map data used in
many applications might not be completely fitted for the authentic demands of
these applications. This challenge is emerged due to the lack of numerous
well-labelled benchmark datasets for implementing the deep learning approaches
into identifying complicated map content. Thus, we develop a large-scale
benchmark dataset that includes well-labelled dataset for map text annotation
recognition, map scene classification, map super-resolution reconstruction, and
map style transferring. Furthermore, these well-labelled datasets would
facilitate the state-of-the-art machine intelligence technologies to conduct
map feature detection, map pattern recognition and map content retrieval. We
hope our efforts would be useful for AI-enhanced cartographical applications.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08602" title="Abstract">arXiv:2312.08602</a> [<a href="/pdf/2312.08602" title="Download PDF">pdf</a>, <a href="/format/2312.08602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Omega-Regular Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahn%2C+E+M">Ernst Moritz Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+M">Mateo Perez</a>, 
<a href="/search/cs?searchtype=author&query=Schewe%2C+S">Sven Schewe</a>, 
<a href="/search/cs?searchtype=author&query=Somenzi%2C+F">Fabio Somenzi</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ashutosh Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Wojtczak%2C+D">Dominik Wojtczak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Regular decision processes (RDPs) are a subclass of non-Markovian decision
processes where the transition and reward functions are guarded by some regular
property of the past (a lookback). While RDPs enable intuitive and succinct
representation of non-Markovian decision processes, their expressive power
coincides with finite-state Markov decision processes (MDPs). We introduce
omega-regular decision processes (ODPs) where the non-Markovian aspect of the
transition and reward functions are extended to an omega-regular lookahead over
the system evolution. Semantically, these lookaheads can be considered as
promises made by the decision maker or the learning agent about her future
behavior. In particular, we assume that, if the promised lookaheads are not
met, then the payoff to the decision maker is $\bot$ (least desirable payoff),
overriding any rewards collected by the decision maker. We enable optimization
and learning for ODPs under the discounted-reward objective by reducing them to
lexicographic optimization and learning over finite MDPs. We present
experimental results demonstrating the effectiveness of the proposed reduction.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08604" title="Abstract">arXiv:2312.08604</a> [<a href="/pdf/2312.08604" title="Download PDF">pdf</a>, <a href="/format/2312.08604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Neural Reachable Tubes via Scenario Optimization and  Conformal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+A">Albert Lin</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Somil Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 6th Annual Learning for Dynamics &amp; Control Conference. arXiv admin note: text overlap with <a href="/abs/2209.12336">arXiv:2209.12336</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Learning-based approaches for controlling safety-critical systems are rapidly
growing in popularity; thus, it is important to assure their performance and
safety. Hamilton-Jacobi (HJ) reachability analysis is a popular formal
verification tool for providing such guarantees, since it can handle general
nonlinear system dynamics, bounded adversarial system disturbances, and state
and input constraints. However, its computational and memory complexity scales
exponentially with the state dimension, making it intractable for large-scale
systems. To overcome this challenge, neural approaches, such as DeepReach, have
been used to synthesize reachable tubes and safety controllers for
high-dimensional systems. However, verifying these neural reachable tubes
remains challenging. In this work, we propose two verification methods, based
on robust scenario optimization and conformal prediction, to provide
probabilistic safety guarantees for neural reachable tubes. Our methods allow a
direct trade-off between resilience to outlier errors in the neural tube, which
are inevitable in a learning-based approach, and the strength of the
probabilistic safety guarantee. Furthermore, we show that split conformal
prediction, a widely used method in the machine learning community for
uncertainty quantification, reduces to a scenario-based approach, making the
two methods equivalent not only for verification of neural reachable tubes but
also more generally. To our knowledge, our proof is the first in the literature
to show a strong relationship between conformal prediction and scenario
optimization. Finally, we propose an outlier-adjusted verification approach
that uses the error distribution in neural reachable tubes to recover greater
safe volumes. We demonstrate the efficacy of the proposed approaches for the
high-dimensional problems of multi-vehicle collision avoidance and rocket
landing with no-go zones.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08606" title="Abstract">arXiv:2312.08606</a> [<a href="/pdf/2312.08606" title="Download PDF">pdf</a>, <a href="/format/2312.08606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQCNIR: Clearer Night Image Restoration with Vector-Quantized Codebook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wenbin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongxia Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shasha Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongsheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sixiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Night photography often struggles with challenges like low light and
blurring, stemming from dark environments and prolonged exposures. Current
methods either disregard priors and directly fitting end-to-end networks,
leading to inconsistent illumination, or rely on unreliable handcrafted priors
to constrain the network, thereby bringing the greater error to the final
result. We believe in the strength of data-driven high-quality priors and
strive to offer a reliable and consistent prior, circumventing the restrictions
of manual priors. In this paper, we propose Clearer Night Image Restoration
with Vector-Quantized Codebook (VQCNIR) to achieve remarkable and consistent
restoration outcomes on real-world and synthetic benchmarks. To ensure the
faithful restoration of details and illumination, we propose the incorporation
of two essential modules: the Adaptive Illumination Enhancement Module (AIEM)
and the Deformable Bi-directional Cross-Attention (DBCA) module. The AIEM
leverages the inter-channel correlation of features to dynamically maintain
illumination consistency between degraded features and high-quality codebook
features. Meanwhile, the DBCA module effectively integrates texture and
structural information through bi-directional cross-attention and deformable
convolution, resulting in enhanced fine-grained detail and structural fidelity
across parallel decoders. Extensive experiments validate the remarkable
benefits of VQCNIR in enhancing image quality under low-light conditions,
showcasing its state-of-the-art performance on both synthetic and real-world
datasets. The code is available at https://github.com/AlexZou14/VQCNIR.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08611" title="Abstract">arXiv:2312.08611</a> [<a href="/pdf/2312.08611" title="Download PDF">pdf</a>, <a href="/format/2312.08611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniTeam: Open Vocabulary Mobile Manipulation Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnik%2C+A">Andrew Melnik</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCttner%2C+M">Michael B&#xfc;ttner</a>, 
<a href="/search/cs?searchtype=author&query=Harz%2C+L">Leon Harz</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+L">Lyon Brown</a>, 
<a href="/search/cs?searchtype=author&query=Nandi%2C+G+C">Gora Chand Nandi</a>, 
<a href="/search/cs?searchtype=author&query=PS%2C+A">Arjun PS</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+G+K">Gaurav Kumar Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Kala%2C+R">Rahul Kala</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This report introduces our UniTeam agent - an improved baseline for the
"HomeRobot: Open Vocabulary Mobile Manipulation" challenge. The challenge poses
problems of navigation in unfamiliar environments, manipulation of novel
objects, and recognition of open-vocabulary object classes. This challenge aims
to facilitate cross-cutting research in embodied AI using recent advances in
machine learning, computer vision, natural language, and robotics. In this
work, we conducted an exhaustive evaluation of the provided baseline agent;
identified deficiencies in perception, navigation, and manipulation skills; and
improved the baseline agent's performance. Notably, enhancements were made in
perception - minimizing misclassifications; navigation - preventing infinite
loop commitments; picking - addressing failures due to changing object
visibility; and placing - ensuring accurate positioning for successful object
placement.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08614" title="Abstract">arXiv:2312.08614</a> [<a href="/pdf/2312.08614" title="Download PDF">pdf</a>, <a href="/format/2312.08614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factorization Vision Transformer: Modeling Long Range Dependency with  Local Window Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haolin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Z">Ziyang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have astounding representational power but typically consume
considerable computation which is quadratic with image resolution. The
prevailing Swin transformer reduces computational costs through a local window
strategy. However, this strategy inevitably causes two drawbacks: (1) the local
window-based self-attention hinders global dependency modeling capability; (2)
recent studies point out that local windows impair robustness. To overcome
these challenges, we pursue a preferable trade-off between computational cost
and performance. Accordingly, we propose a novel factorization self-attention
mechanism (FaSA) that enjoys both the advantages of local window cost and
long-range dependency modeling capability. By factorizing the conventional
attention matrix into sparse sub-attention matrices, FaSA captures long-range
dependencies while aggregating mixed-grained information at a computational
cost equivalent to the local window-based self-attention. Leveraging FaSA, we
present the factorization vision transformer (FaViT) with a hierarchical
structure. FaViT achieves high performance and robustness, with linear
computational complexity concerning input image spatial resolution. Extensive
experiments have shown FaViT's advanced performance in classification and
downstream tasks. Furthermore, it also exhibits strong model robustness to
corrupted and biased data and hence demonstrates benefits in favor of practical
applications. In comparison to the baseline model Swin-T, our FaViT-B2
significantly improves classification accuracy by 1% and robustness by 7%,
while reducing model parameters by 14%. Our code will soon be publicly
available at https://github.com/q2479036243/FaViT.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08616" title="Abstract">arXiv:2312.08616</a> [<a href="/pdf/2312.08616" title="Download PDF">pdf</a>, <a href="/format/2312.08616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Neural Diffusion Framework on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent studies reveal the connection between GNNs and the diffusion process,
which motivates many diffusion-based GNNs to be proposed. However, since these
two mechanisms are closely related, one fundamental question naturally arises:
Is there a general diffusion framework that can formally unify these GNNs? The
answer to this question can not only deepen our understanding of the learning
process of GNNs, but also may open a new door to design a broad new class of
GNNs. In this paper, we propose a general diffusion equation framework with the
fidelity term, which formally establishes the relationship between the
diffusion process with more GNNs. Meanwhile, with this framework, we identify
one characteristic of graph diffusion networks, i.e., the current neural
diffusion process only corresponds to the first-order diffusion equation.
However, by an experimental investigation, we show that the labels of
high-order neighbors actually exhibit monophily property, which induces the
similarity based on labels among high-order neighbors without requiring the
similarity among first-order neighbors. This discovery motives to design a new
high-order neighbor-aware diffusion equation, and derive a new type of graph
diffusion network (HiD-Net) based on the framework. With the high-order
diffusion equation, HiD-Net is more robust against attacks and works on both
homophily and heterophily graphs. We not only theoretically analyze the
relation between HiD-Net with high-order random walk, but also provide a
theoretical convergence guarantee. Extensive experimental results well
demonstrate the effectiveness of HiD-Net over state-of-the-art graph diffusion
networks.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08617" title="Abstract">arXiv:2312.08617</a> [<a href="/pdf/2312.08617" title="Download PDF">pdf</a>, <a href="/format/2312.08617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTLCoder: Outperforming GPT-3.5 in Design RTL Generation with Our  Open-Source Dataset and Lightweight Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+W">Wenji Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiyao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">The automatic generation of RTL code (e.g., Verilog) using natural language
instructions and large language models (LLMs) has attracted significant
research interest recently. However, most existing approaches heavily rely on
commercial LLMs such as ChatGPT, while open-source LLMs tailored for this
specific design generation task exhibit notably inferior performance. The
absence of high-quality open-source solutions restricts the flexibility and
data privacy of this emerging technique. In this study, we present a new
customized LLM solution with a modest parameter count of only 7B, achieving
better performance than GPT-3.5 on two representative benchmarks for RTL code
generation. This remarkable balance between accuracy and efficiency is made
possible by leveraging our new RTL code dataset and a customized LLM algorithm,
both of which will be made fully open-source. Furthermore, we have successfully
quantized our LLM to 4-bit with a total size of 4GB, enabling it to function on
a single laptop with only slight performance degradation. This efficiency
allows the RTL generator to serve as a local assistant for engineers, ensuring
all design privacy concerns are addressed.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08618" title="Abstract">arXiv:2312.08618</a> [<a href="/pdf/2312.08618" title="Download PDF">pdf</a>, <a href="/format/2312.08618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zebra: Extending Context Window with Layerwise Grouped Local-Global  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiqiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sangwoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaoman Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper introduces a novel approach to enhance the capabilities of Large
Language Models (LLMs) in processing and understanding extensive text
sequences, a critical aspect in applications requiring deep comprehension and
synthesis of large volumes of information. Recognizing the inherent challenges
in extending the context window for LLMs, primarily built on Transformer
architecture, we propose a new model architecture, referred to as Zebra. This
architecture efficiently manages the quadratic time and memory complexity
issues associated with full attention in the Transformer by employing grouped
local-global attention layers. Our model, akin to a zebra's alternating
stripes, balances local and global attention layers, significantly reducing
computational requirements and memory consumption. Comprehensive experiments,
including pretraining from scratch, continuation of long context adaptation
training, and long instruction tuning, are conducted to evaluate the Zebra's
performance. The results show that Zebra achieves comparable or superior
performance on both short and long sequence benchmarks, while also enhancing
training and inference efficiency.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08621" title="Abstract">arXiv:2312.08621</a> [<a href="/pdf/2312.08621" title="Download PDF">pdf</a>, <a href="/format/2312.08621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadrupedal Locomotion Control On Inclined Surfaces Using Collocation  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salagame%2C+A">Adarsh Salagame</a>, 
<a href="/search/cs?searchtype=author&query=Gianello%2C+M">Maria Gianello</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+K">Kaushik Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Pitroda%2C+S">Shreyansh Pitroda</a>, 
<a href="/search/cs?searchtype=author&query=Rajput%2C+R">Rohit Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Sihite%2C+E">Eric Sihite</a>, 
<a href="/search/cs?searchtype=author&query=Leeser%2C+M">Miriam Leeser</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+A">Alireza Ramezani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.00179">arXiv:2306.00179</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Inspired by Chukars wing-assisted incline running (WAIR), in this work, we
employ a high-fidelity model of our Husky Carbon quadrupedal-legged robot to
walk over steep slopes of up to 45 degrees. Chukars use the aerodynamic forces
generated by their flapping wings to manipulate ground contact forces and
traverse steep slopes and even overhangs. By exploiting the thrusters on Husky,
we employed a collocation approach to rapidly resolving the joint and thruster
actions. Our approach uses a polynomial approximation of the reduced-order
dynamics of Husky, called HROM, to quickly and efficiently find optimal control
actions that permit high-slope walking without violating friction cone
conditions.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08624" title="Abstract">arXiv:2312.08624</a> [<a href="/pdf/2312.08624" title="Download PDF">pdf</a>, <a href="/format/2312.08624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Reality Communication for Medical Procedures: Teaching the  Placement of a Central Venous Catheter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rebol%2C+M">Manuel Rebol</a>, 
<a href="/search/cs?searchtype=author&query=Pietroszek%2C+K">Krzysztof Pietroszek</a>, 
<a href="/search/cs?searchtype=author&query=Ranniger%2C+C">Claudia Ranniger</a>, 
<a href="/search/cs?searchtype=author&query=Hood%2C+C">Colton Hood</a>, 
<a href="/search/cs?searchtype=author&query=Rutenberg%2C+A">Adam Rutenberg</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+N">Neal Sikka</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">David Li</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCtl%2C+C">Christian G&#xfc;tl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Symposium on Mixed and Augmented Reality
  (ISMAR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Medical procedures are an essential part of healthcare delivery, and the
acquisition of procedural skills is a critical component of medical education.
Unfortunately, procedural skill is not evenly distributed among medical
providers. Skills may vary within departments or institutions, and across
geographic regions, depending on the provider's training and ongoing
experience. We present a mixed reality real-time communication system to
increase access to procedural skill training and to improve remote emergency
assistance. Our system allows a remote expert to guide a local operator through
a medical procedure. RGBD cameras capture a volumetric view of the local scene
including the patient, the operator, and the medical equipment. The volumetric
capture is augmented onto the remote expert's view to allow the expert to
spatially guide the local operator using visual and verbal instructions. We
evaluated our mixed reality communication system in a study in which experts
teach the ultrasound-guided placement of a central venous catheter (CVC) to
students in a simulation setting. The study compares state-of-the-art video
communication against our system. The results indicate that our system enhances
and offers new possibilities for visual communication compared to video
teleconference-based training.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08628" title="Abstract">arXiv:2312.08628</a> [<a href="/pdf/2312.08628" title="Download PDF">pdf</a>, <a href="/ps/2312.08628" title="Download PostScript">ps</a>, <a href="/format/2312.08628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLO-OB: An improved anchor-free real-time multiscale colon polyp  detector in colonoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+E">Enmin Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guangzhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yunfeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bowen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianyuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colon cancer is expected to become the second leading cause of cancer death
in the United States in 2023. Although colonoscopy is one of the most effective
methods for early prevention of colon cancer, up to 30% of polyps may be missed
by endoscopists, thereby increasing patients' risk of developing colon cancer.
Though deep neural networks have been proven to be an effective means of
enhancing the detection rate of polyps. However, the variation of polyp size
brings the following problems: (1) it is difficult to design an efficient and
sufficient multi-scale feature fusion structure; (2) matching polyps of
different sizes with fixed-size anchor boxes is a hard challenge. These
problems reduce the performance of polyp detection and also lower the model's
training and detection efficiency. To address these challenges, this paper
proposes a new model called YOLO-OB. Specifically, we developed a bidirectional
multiscale feature fusion structure, BiSPFPN, which could enhance the feature
fusion capability across different depths of a CNN. We employed the ObjectBox
detection head, which used a center-based anchor-free box regression strategy
that could detect polyps of different sizes on feature maps of any scale.
Experiments on the public dataset SUN and the self-collected colon polyp
dataset Union demonstrated that the proposed model significantly improved
various performance metrics of polyp detection, especially the recall rate.
Compared to the state-of-the-art results on the public dataset SUN, the
proposed method achieved a 6.73% increase on recall rate from 91.5% to 98.23%.
Furthermore, our YOLO-OB was able to achieve real-time polyp detection at a
speed of 39 frames per second using a RTX3090 graphics card. The implementation
of this paper can be found here: https://github.com/seanyan62/YOLO-OB.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08629" title="Abstract">arXiv:2312.08629</a> [<a href="/pdf/2312.08629" title="Download PDF">pdf</a>, <a href="/ps/2312.08629" title="Download PostScript">ps</a>, <a href="/format/2312.08629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatSOS: LLM-based knowledge Q&amp;A system for safety engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haiyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Q">Qingzhao Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have notably propelled
natural language processing (NLP) capabilities, demonstrating significant
potential in safety engineering applications. Despite these advancements, LLMs
face constraints in processing specialized tasks, attributed to factors such as
corpus size, input processing limitations, and privacy concerns. Obtaining
useful information from reliable sources in a limited time is crucial for LLM.
Addressing this, our study introduces an LLM-based Q&amp;A system for safety
engineering, enhancing the comprehension and response accuracy of the model. We
employed prompt engineering to incorporate external knowledge databases, thus
enriching the LLM with up-to-date and reliable information. The system analyzes
historical incident reports through statistical methods, utilizes vector
embedding to construct a vector database, and offers an efficient
similarity-based search functionality. Our findings indicate that the
integration of external knowledge significantly augments the capabilities of
LLM for in-depth problem analysis and autonomous task assignment. It
effectively summarizes accident reports and provides pertinent recommendations.
This integration approach not only expands LLM applications in safety
engineering but also sets a precedent for future developments towards
automation and intelligent systems.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08631" title="Abstract">arXiv:2312.08631</a> [<a href="/pdf/2312.08631" title="Download PDF">pdf</a>, <a href="/format/2312.08631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Semantic Segmentation Meets Masked Modeling:Fine-grained  Locality Learning Matters in Consistency Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wentao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiangpeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+R+K">Raymond Kai-yu Tong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jianhua Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised semantic segmentation aims to utilize limited labeled images
and abundant unlabeled images to achieve label-efficient learning, wherein the
weak-to-strong consistency regularization framework, popularized by FixMatch,
is widely used as a benchmark scheme. Despite its effectiveness, we observe
that such scheme struggles with satisfactory segmentation for the local
regions. This can be because it originally stems from the image classification
task and lacks specialized mechanisms to capture fine-grained local semantics
that prioritizes in dense prediction. To address this issue, we propose a novel
framework called \texttt{MaskMatch}, which enables fine-grained locality
learning to achieve better dense segmentation. On top of the original
teacher-student framework, we design a masked modeling proxy task that
encourages the student model to predict the segmentation given the unmasked
image patches (even with 30\% only) and enforces the predictions to be
consistent with pseudo-labels generated by the teacher model using the complete
image. Such design is motivated by the intuition that if the predictions are
more consistent given insufficient neighboring information, stronger
fine-grained locality perception is achieved. Besides, recognizing the
importance of reliable pseudo-labels in the above locality learning and the
original consistency learning scheme, we design a multi-scale ensembling
strategy that considers context at different levels of abstraction for
pseudo-label generation. Extensive experiments on benchmark datasets
demonstrate the superiority of our method against previous approaches and its
plug-and-play flexibility.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08636" title="Abstract">arXiv:2312.08636</a> [<a href="/pdf/2312.08636" title="Download PDF">pdf</a>, <a href="/format/2312.08636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MmAP : Multi-modal Alignment Prompt for Cross-domain Multi-task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yi Xin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junlong Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shouhong Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-Task Learning (MTL) is designed to train multiple correlated tasks
simultaneously, thereby enhancing the performance of individual tasks.
Typically, a multi-task network structure consists of a shared backbone and
task-specific decoders. However, the complexity of the decoders increases with
the number of tasks. To tackle this challenge, we integrate the decoder-free
vision-language model CLIP, which exhibits robust zero-shot generalization
capability. Recently, parameter-efficient transfer learning methods have been
extensively explored with CLIP for adapting to downstream tasks, where prompt
tuning showcases strong potential. Nevertheless, these methods solely fine-tune
a single modality (text or visual), disrupting the modality structure of CLIP.
In this paper, we first propose Multi-modal Alignment Prompt (MmAP) for CLIP,
which aligns text and visual modalities during fine-tuning process. Building
upon MmAP, we develop an innovative multi-task prompt learning framework. On
the one hand, to maximize the complementarity of tasks with high similarity, we
utilize a gradient-driven task grouping method that partitions tasks into
several disjoint groups and assign a group-shared MmAP to each group. On the
other hand, to preserve the unique characteristics of each task, we assign an
task-specific MmAP to each task. Comprehensive experiments on two large
multi-task learning datasets demonstrate that our method achieves significant
performance improvements compared to full fine-tuning while only utilizing
approximately 0.09% of trainable parameters.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08639" title="Abstract">arXiv:2312.08639</a> [<a href="/pdf/2312.08639" title="Download PDF">pdf</a>, <a href="/format/2312.08639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the complexity of list $\mathcal H$-packing for sparse graph classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gima%2C+T">Tatsuya Gima</a>, 
<a href="/search/cs?searchtype=author&query=Hanaka%2C+T">Tesshu Hanaka</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+Y">Yasuaki Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Otachi%2C+Y">Yota Otachi</a>, 
<a href="/search/cs?searchtype=author&query=Shirai%2C+T">Tomohito Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+A">Akira Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Tamura%2C+Y">Yuma Tamura</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The problem of packing as many subgraphs isomorphic to $H \in \mathcal H$ as
possible in a graph for a class $\mathcal H$ of graphs is well studied in the
literature. Both vertex-disjoint and edge-disjoint versions are known to be
NP-complete for $H$ that contains at least three vertices and at least three
edges, respectively. In this paper, we consider ``list variants'' of these
problems: Given a graph $G$, an integer $k$, and a collection $\mathcal
L_{\mathcal H}$ of subgraphs of $G$ isomorphic to some $H \in \mathcal H$, the
goal is to compute $k$ subgraphs in $\mathcal L_{\mathcal H}$ that are pairwise
vertex- or edge-disjoint. We show several positive and negative results,
focusing on classes of sparse graphs, such as bounded-degree graphs, planar
graphs, and bounded-treewidth graphs.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08642" title="Abstract">arXiv:2312.08642</a> [<a href="/pdf/2312.08642" title="Download PDF">pdf</a>, <a href="/format/2312.08642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metacognition-Enhanced Few-Shot Prompting With Positive Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot prompting elicits the remarkable abilities of large language models
by equipping them with a few demonstration examples in the input. However, the
traditional method of providing large language models with all demonstration
input-output pairs at once may not effectively guide large language models to
learn the specific input-output mapping relationship. In this paper, inspired
by the regulatory and supportive role of metacognition in students' learning,
we propose a novel metacognition-enhanced few-shot prompting, which guides
large language models to reflect on their thought processes to comprehensively
learn the given demonstration examples. Furthermore, considering that positive
reinforcement can improve students' learning motivation, we introduce positive
reinforcement into our metacognition-enhanced few-shot prompting to promote the
few-shot learning of large language models by providing response-based positive
feedback. The experimental results on two real-world datasets show that our
metacognition-enhanced few-shot prompting with positive reinforcement surpasses
traditional few-shot prompting in classification accuracy and macro F1.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08644" title="Abstract">arXiv:2312.08644</a> [<a href="/pdf/2312.08644" title="Download PDF">pdf</a>, <a href="/format/2312.08644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Model-based Feature Knowledge Distillation for Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guiqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yanjiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusen Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge distillation (KD), a technique widely employed in computer vision,
has emerged as a de facto standard for improving the performance of small
neural networks. However, prevailing KD-based approaches in video tasks
primarily focus on designing loss functions and fusing cross-modal information.
This overlooks the spatial-temporal feature semantics, resulting in limited
advancements in model compression. Addressing this gap, our paper introduces an
innovative knowledge distillation framework, with the generative model for
training a lightweight student model. In particular, the framework is organized
into two steps: the initial phase is Feature Representation, wherein a
generative model-based attention module is trained to represent feature
semantics; Subsequently, the Generative-based Feature Distillation phase
encompasses both Generative Distillation and Attention Distillation, with the
objective of transferring attention-based feature semantics with the generative
model. The efficacy of our approach is demonstrated through comprehensive
experiments on diverse popular datasets, proving considerable enhancements in
video action recognition task. Moreover, the effectiveness of our proposed
framework is validated in the context of more intricate video action detection
task. Our code is available at https://github.com/aaai-24/Generative-based-KD.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08646" title="Abstract">arXiv:2312.08646</a> [<a href="/pdf/2312.08646" title="Download PDF">pdf</a>, <a href="/format/2312.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarding the Grid: Enhancing Resilience in Automated Residential Demand  Response Against False Data Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dayaratne%2C+T">Thusitha Dayaratne</a>, 
<a href="/search/eess?searchtype=author&query=Rudolph%2C+C">Carsten Rudolph</a>, 
<a href="/search/eess?searchtype=author&query=Liebman%2C+A">Ariel Liebman</a>, 
<a href="/search/eess?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Utility companies are increasingly leveraging residential demand flexibility
and the proliferation of smart/IoT devices to enhance the effectiveness of
residential demand response (DR) programs through automated device scheduling.
However, the adoption of distributed architectures in these systems exposes
them to the risk of false data injection attacks (FDIAs), where adversaries can
manipulate decision-making processes by injecting false data. Given the limited
control utility companies have over these distributed systems and data, the
need for reliable implementations to enhance the resilience of residential DR
schemes against FDIAs is paramount. In this work, we present a comprehensive
framework that combines DR optimisation, anomaly detection, and strategies for
mitigating the impacts of attacks to create a resilient and automated device
scheduling system. To validate the robustness of our framework against FDIAs,
we performed an evaluation using real-world data sets, highlighting its
effectiveness in securing residential DR systems.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08648" title="Abstract">arXiv:2312.08648</a> [<a href="/pdf/2312.08648" title="Download PDF">pdf</a>, <a href="/format/2312.08648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-guided Federated Learning on Heterogeneous and Long-Tailed Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shanshan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangbo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanyun Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning (FL) provides a decentralized machine learning paradigm
where a server collaborates with a group of clients to learn a global model
without accessing the clients' data. User heterogeneity is a significant
challenge for FL, which together with the class-distribution imbalance further
enhances the difficulty of FL. Great progress has been made in large
vision-language models, such as Contrastive Language-Image Pre-training (CLIP),
which paves a new way for image classification and object recognition. Inspired
by the success of CLIP on few-shot and zero-shot learning, we use CLIP to
optimize the federated learning between server and client models under its
vision-language supervision. It is promising to mitigate the user heterogeneity
and class-distribution balance due to the powerful cross-modality
representation and rich open-vocabulary prior knowledge. In this paper, we
propose the CLIP-guided FL (CLIP2FL) method on heterogeneous and long-tailed
data. In CLIP2FL, the knowledge of the off-the-shelf CLIP model is transferred
to the client-server models, and a bridge is built between the client and
server. Specifically, for client-side learning, knowledge distillation is
conducted between client models and CLIP to improve the ability of client-side
feature representation. For server-side learning, in order to mitigate the
heterogeneity and class-distribution imbalance, we generate federated features
to retrain the server model. A prototype contrastive learning with the
supervision of the text encoder of CLIP is introduced to generate federated
features depending on the client-side gradients, and they are used to retrain a
balanced server classifier.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08650" title="Abstract">arXiv:2312.08650</a> [<a href="/pdf/2312.08650" title="Download PDF">pdf</a>, <a href="/format/2312.08650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhyOT: Physics-informed object tracking in surveillance cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamtue%2C+K">Kawisorn Kamtue</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J+M+F">Jose M.F. Moura</a>, 
<a href="/search/cs?searchtype=author&query=Sangpetch%2C+O">Orathai Sangpetch</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+P">Paulo Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ICASSP 2024 on December 13, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">While deep learning has been very successful in computer vision, real world
operating conditions such as lighting variation, background clutter, or
occlusion hinder its accuracy across several tasks. Prior work has shown that
hybrid models -- combining neural networks and heuristics/algorithms -- can
outperform vanilla deep learning for several computer vision tasks, such as
classification or tracking. We consider the case of object tracking, and
evaluate a hybrid model (PhyOT) that conceptualizes deep neural networks as
``sensors'' in a Kalman filter setup, where prior knowledge, in the form of
Newtonian laws of motion, is used to fuse sensor observations and to perform
improved estimations. Our experiments combine three neural networks, performing
position, indirect velocity and acceleration estimation, respectively, and
evaluate such a formulation on two benchmark datasets: a warehouse security
camera dataset that we collected and annotated and a traffic camera open
dataset. Results suggest that our PhyOT can track objects in extreme conditions
that the state-of-the-art deep neural networks fail while its performance in
general cases does not degrade significantly from that of existing deep
learning approaches. Results also suggest that our PhyOT components are
generalizable and transferable.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08651" title="Abstract">arXiv:2312.08651</a> [<a href="/pdf/2312.08651" title="Download PDF">pdf</a>, <a href="/format/2312.08651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Inductive Robustness: Distilling and Fostering Wave-induced  Resonance in Transductive GCNs Against Graph Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenshan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Beibei Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have recently been shown to be vulnerable to
adversarial attacks, where slight perturbations in the graph structure can lead
to erroneous predictions. However, current robust models for defending against
such attacks inherit the transductive limitations of graph convolutional
networks (GCNs). As a result, they are constrained by fixed structures and do
not naturally generalize to unseen nodes. Here, we discover that transductive
GCNs inherently possess a distillable robustness, achieved through a
wave-induced resonance process. Based on this, we foster this resonance to
facilitate inductive and robust learning. Specifically, we first prove that the
signal formed by GCN-driven message passing (MP) is equivalent to the
edge-based Laplacian wave, where, within a wave system, resonance can naturally
emerge between the signal and its transmitting medium. This resonance provides
inherent resistance to malicious perturbations inflicted on the signal system.
We then prove that merely three MP iterations within GCNs can induce signal
resonance between nodes and edges, manifesting as a coupling between nodes and
their distillable surrounding local subgraph. Consequently, we present Graph
Resonance-fostering Network (GRN) to foster this resonance via learning node
representations from their distilled resonating subgraphs. By capturing the
edge-transmitted signals within this subgraph and integrating them with the
node signal, GRN embeds these combined signals into the central node's
representation. This node-wise embedding approach allows for generalization to
unseen nodes. We validate our theoretical findings with experiments, and
demonstrate that GRN generalizes robustness to unseen nodes, whilst maintaining
state-of-the-art classification accuracy on perturbed graphs.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08653" title="Abstract">arXiv:2312.08653</a> [<a href="/pdf/2312.08653" title="Download PDF">pdf</a>, <a href="/format/2312.08653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Knowledge Distillation Framework for Open-world Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuailei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuefeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Ying Wei</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiaqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.11623">arXiv:2303.11623</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open World Object Detection (OWOD) is a novel computer vision task with a
considerable challenge, bridging the gap between classic object detection (OD)
benchmarks and real-world object detection. In addition to detecting and
classifying seen/known objects, OWOD algorithms are expected to localize all
potential unseen/unknown objects and incrementally learn them. The large
pre-trained vision-language grounding models (VLM,eg, GLIP) have rich knowledge
about the open world, but are limited by text prompts and cannot localize
indescribable objects. However, there are many detection scenarios which
pre-defined language descriptions are unavailable during inference. In this
paper, we attempt to specialize the VLM model for OWOD task by distilling its
open-world knowledge into a language-agnostic detector. Surprisingly, we
observe that the combination of a simple knowledge distillation approach and
the automatic pseudo-labeling mechanism in OWOD can achieve better performance
for unknown object detection, even with a small amount of data. Unfortunately,
knowledge distillation for unknown objects severely affects the learning of
detectors with conventional structures for known objects, leading to
catastrophic forgetting. To alleviate these problems, we propose the
down-weight loss function for knowledge distillation from vision-language to
single vision modality. Meanwhile, we decouple the learning of localization and
recognition to reduce the impact of category interactions of known and unknown
objects on the localization learning process. Comprehensive experiments
performed on MS-COCO and PASCAL VOC demonstrate the effectiveness of our
methods.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08654" title="Abstract">arXiv:2312.08654</a> [<a href="/pdf/2312.08654" title="Download PDF">pdf</a>, <a href="/ps/2312.08654" title="Download PostScript">ps</a>, <a href="/format/2312.08654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated detection of Zika and dengue in Aedes aegypti using neural  spiking analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharifrazi%2C+D">Danial Sharifrazi</a>, 
<a href="/search/cs?searchtype=author&query=Javed%2C+N">Nouman Javed</a>, 
<a href="/search/cs?searchtype=author&query=Alizadehsani%2C+R">Roohallah Alizadehsani</a>, 
<a href="/search/cs?searchtype=author&query=Paradkar%2C+P+N">Prasad N. Paradkar</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+U+R">U. Rajendra Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+A">Asim Bhatti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Mosquito-borne diseases present considerable risks to the health of both
animals and humans. Aedes aegypti mosquitoes are the primary vectors for
numerous medically important viruses such as dengue, Zika, yellow fever, and
chikungunya. To characterize this mosquito neural activity, it is essential to
classify the generated electrical spikes. However, no open-source neural spike
classification method is currently available for mosquitoes. Our work presented
in this paper provides an innovative artificial intelligence-based method to
classify the neural spikes in uninfected, dengue-infected, and Zika-infected
mosquitoes. Aiming for outstanding performance, the method employs a fusion of
normalization, feature importance, and dimension reduction for the
preprocessing and combines convolutional neural network and extra gradient
boosting (XGBoost) for classification. The method uses the electrical spiking
activity data of mosquito neurons recorded by microelectrode array technology.
We used data from 0, 1, 2, 3, and 7 days post-infection, containing over 15
million samples, to analyze the method's performance. The performance of the
proposed method was evaluated using accuracy, precision, recall, and the F1
scores. The results obtained from the method highlight its remarkable
performance in differentiating infected vs uninfected mosquito samples,
achieving an average of 98.1%. The performance was also compared with 6 other
machine learning algorithms to further assess the method's capability. The
method outperformed all other machine learning algorithms' performance.
Overall, this research serves as an efficient method to classify the neural
spikes of Aedes aegypti mosquitoes and can assist in unraveling the complex
interactions between pathogens and mosquitoes.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08656" title="Abstract">arXiv:2312.08656</a> [<a href="/pdf/2312.08656" title="Download PDF">pdf</a>, <a href="/format/2312.08656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural  Networks Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shivdikar%2C+K">Kaustubh Shivdikar</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+A">MD Amit Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+O">Omer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kaeli%2C+D">David Kaeli</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASPLOS 2024 accepted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the acceleration of deep neural network training, the GPU has become the
mainstream platform. GPUs face substantial challenges on GNNs, such as workload
imbalance and memory access irregularities, leading to underutilized hardware.
Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks
partially address these challenges but memory traffic is still significant.
<br />We argue that drastic performance improvements can only be achieved by the
vertical optimization of algorithm and system innovations, rather than treating
the speedup optimization as an "after-thought" (i.e., (i) given a GNN
algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing
the GNN algorithm). In this paper, we present MaxK-GNN, an advanced
high-performance GPU training system integrating algorithm and system
innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical
analysis of MaxK nonlinearity as a universal approximator, and present the
Compressed Balanced Sparse Row (CBSR) format, designed to store the data and
index of the feature matrix after nonlinearity; (ii) We design a coalescing
enhanced forward computation with row-wise product-based SpGEMM Kernel using
CBSR for input feature matrix fetching and strategic placement of a sparse
output accumulation buffer in shared memory; (iii) We develop an optimized
backward computation with outer product-based and SSpMM Kernel.
<br />We conduct extensive evaluations of MaxK-GNN and report the end-to-end system
run-time. Experiments show that MaxK-GNN system could approach the theoretical
speedup limit according to Amdahl's law. We achieve comparable accuracy to SOTA
GNNs, but at a significantly increased speed: 3.22/4.24 times speedup (vs.
theoretical limits, 5.52/7.27 times) on Reddit compared to DGL and GNNAdvisor
implementations.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08659" title="Abstract">arXiv:2312.08659</a> [<a href="/pdf/2312.08659" title="Download PDF">pdf</a>, <a href="/format/2312.08659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Image-Based Detection of Tomato and Corn leaves Diseases : An  in-depth comparative experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasin%2C+A">Affan Yasin</a>, 
<a href="/search/cs?searchtype=author&query=Fatima%2C+R">Rubia Fatima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The research introduces a novel plant disease detection model based on
Convolutional Neural Networks (CNN) for plant image classification, marking a
significant contribution to image categorization. The innovative training
approach enables a streamlined and efficient system implementation. The model
classifies two distinct plant diseases into four categories, presenting a novel
technique for plant disease identification. In Experiment 1, Inception-V3,
Dense-Net-121, ResNet-101-V2, and Xception models were employed for CNN
training. The newly created plant disease image dataset includes 1963 tomato
plant images and 7316 corn plant images from the PlantVillage dataset. Of
these, 1374 tomato images and 5121 corn images were used for training, while
589 tomato images and 2195 corn images were used for testing/validation.
Results indicate that the Xception model outperforms the other three models,
yielding val_accuracy values of 95.08% and 92.21% for the tomato and corn
datasets, with corresponding val_loss values of 0.3108 and 0.4204,
respectively. In Experiment 2, CNN with Batch Normalization achieved disease
detection rates of approximately 99.89% in the training set and val_accuracy
values exceeding 97.52%, accompanied by a val_loss of 0.103. Experiment 3
employed a CNN architecture as the base model, introducing additional layers in
Model 2, skip connections in Model 3, and regularizations in Model 4. Detailed
experiment results and model efficiency are outlined in the paper's sub-section
1.5. Experiment 4 involved combining all corn and tomato images, utilizing
various models, including MobileNet (val_accuracy=86.73%), EfficientNetB0
(val_accuracy=93.973%), Xception (val_accuracy=74.91%), InceptionResNetV2
(val_accuracy=31.03%), and CNN (59.79%). Additionally, our proposed model
achieved a val_accuracy of 84.42%.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08660" title="Abstract">arXiv:2312.08660</a> [<a href="/pdf/2312.08660" title="Download PDF">pdf</a>, <a href="/format/2312.08660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank constrained multichannel signal denoising considering  channel-dependent sensitivity inspired by self-supervised learning for  optical fiber sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonami%2C+N">Noriyuki Tonami</a>, 
<a href="/search/cs?searchtype=author&query=Kohno%2C+W">Wataru Kohno</a>, 
<a href="/search/cs?searchtype=author&query=Mishima%2C+S">Sakiko Mishima</a>, 
<a href="/search/cs?searchtype=author&query=Arai%2C+Y">Yumi Arai</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+R">Reishi Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Hino%2C+T">Tomoyuki Hino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Optical fiber sensing is a technology wherein audio, vibrations, and
temperature are detected using an optical fiber; especially the
audio/vibrations-aware sensing is called distributed acoustic sensing (DAS). In
DAS, observed data, which is comprised of multichannel data, has suffered from
severe noise levels because of the optical noise or the installation methods.
In conventional methods for denoising DAS data, signal-processing- or
deep-neural-network (DNN)-based models have been studied. The
signal-processing-based methods have the interpretability, i.e., non-black box.
The DNN-based methods are good at flexibility designing network architectures
and objective functions, that is, priors. However, there is no balance between
the interpretability and the flexibility of priors in the DAS studies. The
DNN-based methods also require a large amount of training data in general. To
address the problems, we propose a DNN-structure signal-processing-based
denoising method in this paper. As the priors of DAS, we employ spatial
knowledge; low rank and channel-dependent sensitivity using the DNN-based
structure. The result of fiber-acoustic sensing shows that the proposed method
outperforms the conventional methods and the robustness to the number of the
spatial ranks. Moreover, the optimized parameters of the proposed method
indicate the relationship with the channel sensitivity; the interpretability.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08662" title="Abstract">arXiv:2312.08662</a> [<a href="/pdf/2312.08662" title="Download PDF">pdf</a>, <a href="/format/2312.08662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Centralized to Self-Supervised: Pursuing Realistic Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+V">Violet Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Cross%2C+L">Logan Cross</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%A4nken%2C+J">Jan-Philipp Fr&#xe4;nken</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+N">Nick Haber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">In real-world environments, autonomous agents rely on their egocentric
observations. They must learn adaptive strategies to interact with others who
possess mixed motivations, discernible only through visible cues. Several
Multi-Agent Reinforcement Learning (MARL) methods adopt centralized approaches
that involve either centralized training or reward-sharing, often violating the
realistic ways in which living organisms, like animals or humans, process
information and interact. MARL strategies deploying decentralized training with
intrinsic motivation offer a self-supervised approach, enable agents to develop
flexible social strategies through the interaction of autonomous agents.
However, by contrasting the self-supervised and centralized methods, we reveal
that populations trained with reward-sharing methods surpass those using
self-supervised methods in a mixed-motive environment. We link this superiority
to specialized role emergence and an agent's expertise in its role.
Interestingly, this gap shrinks in pure-motive settings, emphasizing the need
for evaluations in more complex, realistic environments (mixed-motive). Our
preliminary results suggest a gap in population performance that can be closed
by improving self-supervised methods and thereby pushing MARL closer to
real-world readiness.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08664" title="Abstract">arXiv:2312.08664</a> [<a href="/pdf/2312.08664" title="Download PDF">pdf</a>, <a href="/format/2312.08664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point  Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kezheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Maoji Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chenglu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud registration, a fundamental task in 3D computer vision, has
remained largely unexplored in cross-source point clouds and unstructured
scenes. The primary challenges arise from noise, outliers, and variations in
scale and density. However, neglected geometric natures of point clouds
restricts the performance of current methods. In this paper, we propose a novel
method termed SPEAL to leverage skeletal representations for effective learning
of intrinsic topologies of point clouds, facilitating robust capture of
geometric intricacy. Specifically, we design the Skeleton Extraction Module to
extract skeleton points and skeletal features in an unsupervised manner, which
is inherently robust to noise and density variances. Then, we propose the
Skeleton-Aware GeoTransformer to encode high-level skeleton-aware features. It
explicitly captures the topological natures and inter-point-cloud skeletal
correlations with the noise-robust and density-invariant skeletal
representations. Next, we introduce the Correspondence Dual-Sampler to
facilitate correspondences by augmenting the correspondence set with skeletal
correspondences. Furthermore, we construct a challenging novel large-scale
cross-source point cloud dataset named KITTI CrossSource for benchmarking
cross-source point cloud registration methods. Extensive quantitative and
qualitative experiments are conducted to demonstrate our approach's superiority
and robustness on both cross-source and same-source datasets. To the best of
our knowledge, our approach is the first to facilitate point cloud registration
with skeletal geometric priors.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08667" title="Abstract">arXiv:2312.08667</a> [<a href="/pdf/2312.08667" title="Download PDF">pdf</a>, <a href="/format/2312.08667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data and Model Poisoning Backdoor Attacks on Wireless Federated  Learning, and the Defense Mechanisms: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yichen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Youyang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Longxiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the greatly improved capabilities of devices, massive data, and
increasing concern about data privacy, Federated Learning (FL) has been
increasingly considered for applications to wireless communication networks
(WCNs). Wireless FL (WFL) is a distributed method of training a global deep
learning model in which a large number of participants each train a local model
on their training datasets and then upload the local model updates to a central
server. However, in general, non-independent and identically distributed
(non-IID) data of WCNs raises concerns about robustness, as a malicious
participant could potentially inject a "backdoor" into the global model by
uploading poisoned data or models over WCN. This could cause the model to
misclassify malicious inputs as a specific target class while behaving normally
with benign inputs. This survey provides a comprehensive review of the latest
backdoor attacks and defense mechanisms. It classifies them according to their
targets (data poisoning or model poisoning), the attack phase (local data
collection, training, or aggregation), and defense stage (local training,
before aggregation, during aggregation, or after aggregation). The strengths
and limitations of existing attack strategies and defense mechanisms are
analyzed in detail. Comparisons of existing attack methods and defense designs
are carried out, pointing to noteworthy findings, open challenges, and
potential future research directions related to security and privacy of WFL.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08668" title="Abstract">arXiv:2312.08668</a> [<a href="/pdf/2312.08668" title="Download PDF">pdf</a>, <a href="/format/2312.08668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Versatile Telescopic-Wheeled-Legged Locomotion of Tachyon 3 via  Full-Centroidal Nonlinear Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katayama%2C+S">Sotaro Katayama</a>, 
<a href="/search/cs?searchtype=author&query=Takasugi%2C+N">Noriaki Takasugi</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Mitsuhisa Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Kinoshita%2C+M">Masaya Kinoshita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a nonlinear model predictive control (NMPC) toward
versatile motion generation for the telescopic-wheeled-legged robot Tachyon 3,
the unique hardware structure of which poses challenges in control and motion
planning. We apply the full-centroidal NMPC formulation with dedicated
constraints that can capture the accurate kinematics and dynamics of Tachyon 3.
We have developed a control pipeline that includes an internal state integrator
to apply NMPC to Tachyon 3, the actuators of which employ high-gain
position-controllers. We conducted simulation and hardware experiments on the
perceptive locomotion of Tachyon 3 over structured terrains and demonstrated
that the proposed method can achieve smooth and dynamic motion generation under
harsh physical and environmental constraints.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08671" title="Abstract">arXiv:2312.08671</a> [<a href="/pdf/2312.08671" title="Download PDF">pdf</a>, <a href="/format/2312.08671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uplifting the Expressive Power of Graph Neural Networks through Graph  Partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hevapathige%2C+A">Asela Hevapathige</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have paved its way for being a cornerstone in
graph related learning tasks. From a theoretical perspective, the expressive
power of GNNs is primarily characterised according to their ability to
distinguish non-isomorphic graphs. It is a well-known fact that most of the
conventional GNNs are upper-bounded by Weisfeiler-Lehman graph isomorphism test
(1-WL). In this work, we study the expressive power of graph neural networks
through the lens of graph partitioning. This follows from our observation that
permutation invariant graph partitioning enables a powerful way of exploring
structural interactions among vertex sets and subgraphs, and can help uplifting
the expressive power of GNNs efficiently. Based on this, we first establish a
theoretical connection between graph partitioning and graph isomorphism. Then
we introduce a novel GNN architecture, namely Graph Partitioning Neural
Networks (GPNNs). We theoretically analyse how a graph partitioning scheme and
different kinds of structural interactions relate to the k-WL hierarchy.
Empirically, we demonstrate its superior performance over existing GNN models
in a variety of graph benchmark tasks.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08672" title="Abstract">arXiv:2312.08672</a> [<a href="/pdf/2312.08672" title="Download PDF">pdf</a>, <a href="/format/2312.08672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Silu He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qinyao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinsha Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Ling Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Ronghua Du</a>, 
<a href="/search/cs?searchtype=author&query=Lia%2C+H">Haifeng Lia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 17 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Science 2023 sumitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph
Attention Networks (GATs) is designed to adaptively learn the importance of
neighboring nodes for better local aggregation on the graph, which can bring
the representations of similar neighbors closer effectively, thus showing
stronger discrimination ability. However, existing GATs suffer from a
significant discrimination ability decline in heterophilic graphs because the
high proportion of dissimilar neighbors can weaken the self-attention of the
central node, jointly resulting in the deviation of the central node from
similar nodes in the representation space. This kind of effect generated by
neighboring nodes is called the Distraction Effect (DE) in this paper. To
estimate and weaken the DE of neighboring nodes, we propose a Causally graph
Attention network for Trimming heterophilic graph (CAT). To estimate the DE,
since the DE are generated through two paths (grab the attention assigned to
neighbors and reduce the self-attention of the central node), we use Total
Effect to model DE, which is a kind of causal estimand and can be estimated
from intervened data; To weaken the DE, we identify the neighbors with the
highest DE (we call them Distraction Neighbors) and remove them. We adopt three
representative GATs as the base model within the proposed CAT framework and
conduct experiments on seven heterophilic datasets in three different sizes.
Comparative experiments show that CAT can improve the node classification
accuracy of all base GAT models. Ablation experiments and visualization further
validate the enhancement of discrimination ability brought by CAT. The source
code is available at https://github.com/GeoX-Lab/CAT.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08673" title="Abstract">arXiv:2312.08673</a> [<a href="/pdf/2312.08673" title="Download PDF">pdf</a>, <a href="/format/2312.08673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Beyond View: Handling Partially Missing Modality for  Audio-Visual Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Renjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsiang-Ting Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Augmented Reality (AR) devices, emerging as prominent mobile interaction
platforms, face challenges in user safety, particularly concerning oncoming
vehicles. While some solutions leverage onboard camera arrays, these cameras
often have limited field-of-view (FoV) with front or downward perspectives.
Addressing this, we propose a new out-of-view semantic segmentation task and
Segment Beyond View (SBV), a novel audio-visual semantic segmentation method.
SBV supplements the visual modality, which miss the information beyond FoV,
with the auditory information using a teacher-student distillation model
(Omni2Ego). The model consists of a vision teacher utilising panoramic
information, an auditory teacher with 8-channel audio, and an audio-visual
student that takes views with limited FoV and binaural audio as input and
produce semantic segmentation for objects outside FoV. SBV outperforms existing
models in comparative evaluations and shows a consistent performance across
varying FoV ranges and in monaural audio settings.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08675" title="Abstract">arXiv:2312.08675</a> [<a href="/pdf/2312.08675" title="Download PDF">pdf</a>, <a href="/format/2312.08675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVA: Inconspicuous Attribute Variation-based Adversarial Attack  bypassing DeepFake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangtao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shanqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingchuan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">While DeepFake applications are becoming popular in recent years, their
abuses pose a serious privacy threat. Unfortunately, most related detection
algorithms to mitigate the abuse issues are inherently vulnerable to
adversarial attacks because they are built atop DNN-based classification
models, and the literature has demonstrated that they could be bypassed by
introducing pixel-level perturbations. Though corresponding mitigation has been
proposed, we have identified a new attribute-variation-based adversarial attack
(AVA) that perturbs the latent space via a combination of Gaussian prior and
semantic discriminator to bypass such mitigation. It perturbs the semantics in
the attribute space of DeepFake images, which are inconspicuous to human beings
(e.g., mouth open) but can result in substantial differences in DeepFake
detection. We evaluate our proposed AVA attack on nine state-of-the-art
DeepFake detection algorithms and applications. The empirical results
demonstrate that AVA attack defeats the state-of-the-art black box attacks
against DeepFake detectors and achieves more than a 95% success rate on two
commercial DeepFake detectors. Moreover, our human study indicates that
AVA-generated DeepFake images are often imperceptible to humans, which presents
huge security and privacy concerns.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08676" title="Abstract">arXiv:2312.08676</a> [<a href="/pdf/2312.08676" title="Download PDF">pdf</a>, <a href="/format/2312.08676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Zero-shot voice conversion (VC) aims to transfer the source speaker timbre to
arbitrary unseen target speaker timbre, while keeping the linguistic content
unchanged. Although the voice of generated speech can be controlled by
providing the speaker embedding of the target speaker, the speaker similarity
still lags behind the ground truth recordings. In this paper, we propose
SEF-VC, a speaker embedding free voice conversion model, which is designed to
learn and incorporate speaker timbre from reference speech via a powerful
position-agnostic cross-attention mechanism, and then reconstruct waveform from
HuBERT semantic tokens in a non-autoregressive manner. The concise design of
SEF-VC enhances its training stability and voice conversion performance.
Objective and subjective evaluations demonstrate the superiority of SEF-VC to
generate high-quality speech with better similarity to target reference than
strong zero-shot VC baselines, even for very short reference speeches.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08677" title="Abstract">arXiv:2312.08677</a> [<a href="/pdf/2312.08677" title="Download PDF">pdf</a>, <a href="/format/2312.08677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Shortcut Debiasing for Online Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Dongmin Park</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yooju Shin</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+J">Jihwan Bang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Gil Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a novel framework DropTop that suppresses the shortcut bias in
online continual learning (OCL) while being adaptive to the varying degree of
the shortcut bias incurred by continuously changing environment. By the
observed high-attention property of the shortcut bias, highly-activated
features are considered candidates for debiasing. More importantly, resolving
the limitation of the online environment where prior knowledge and auxiliary
data are not ready, two novel techniques -- feature map fusion and adaptive
intensity shifting -- enable us to automatically determine the appropriate
level and proportion of the candidate shortcut features to be dropped.
Extensive experiments on five benchmark datasets demonstrate that, when
combined with various OCL algorithms, DropTop increases the average accuracy by
up to 10.4% and decreases the forgetting by up to 63.2%.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08678" title="Abstract">arXiv:2312.08678</a> [<a href="/pdf/2312.08678" title="Download PDF">pdf</a>, <a href="/format/2312.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning with Physics Priors as Generalized Regularizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Frank Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A">Agniva Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages main text, 13 pages supplemental materials, title of the workshop at NeurIPS 2023: AI for Scientific Discovery: From Theory to Practice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In various scientific and engineering applications, there is typically an
approximate model of the underlying complex system, even though it contains
both aleatoric and epistemic uncertainties. In this paper, we present a
principled method to incorporate these approximate models as physics priors in
modeling, to prevent overfitting and enhancing the generalization capabilities
of the trained models. Utilizing the structural risk minimization (SRM)
inductive principle pioneered by Vapnik, this approach structures the physics
priors into generalized regularizers. The experimental results demonstrate that
our method achieves up to two orders of magnitude of improvement in testing
accuracy.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08679" title="Abstract">arXiv:2312.08679</a> [<a href="/pdf/2312.08679" title="Download PDF">pdf</a>, <a href="/format/2312.08679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Appearance Model for Volumetric Capture of Diverse Hairstyle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+G">Giljoo Nam</a>, 
<a href="/search/cs?searchtype=author&query=Bozic%2C+A">Aljaz Bozic</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Saragih%2C+J">Jason Saragih</a>, 
<a href="/search/cs?searchtype=author&query=Zollhoefer%2C+M">Michael Zollhoefer</a>, 
<a href="/search/cs?searchtype=author&query=Hodgins%2C+J">Jessica Hodgins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Hair plays a significant role in personal identity and appearance, making it
an essential component of high-quality, photorealistic avatars. Existing
approaches either focus on modeling the facial region only or rely on
personalized models, limiting their generalizability and scalability. In this
paper, we present a novel method for creating high-fidelity avatars with
diverse hairstyles. Our method leverages the local similarity across different
hairstyles and learns a universal hair appearance prior from multi-view
captures of hundreds of people. This prior model takes 3D-aligned features as
input and generates dense radiance fields conditioned on a sparse point cloud
with color. As our model splits different hairstyles into local primitives and
builds prior at that level, it is capable of handling various hair topologies.
Through experiments, we demonstrate that our model captures a diverse range of
hairstyles and generalizes well to challenging new hairstyles. Empirical
results show that our method improves the state-of-the-art approaches in
capturing and generating photorealistic, personalized avatars with complete
hair.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08680" title="Abstract">arXiv:2312.08680</a> [<a href="/pdf/2312.08680" title="Download PDF">pdf</a>, <a href="/format/2312.08680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Graph Neural Architecture Search with GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haoyuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haishuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Heterogeneous graph neural architecture search (HGNAS) represents a powerful
tool for automatically designing effective heterogeneous graph neural networks.
However, existing HGNAS algorithms suffer from inefficient searches and
unstable results. In this paper, we present a new GPT-4 based HGNAS model to
improve the search efficiency and search accuracy of HGNAS. Specifically, we
present a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search
(GHGNAS for short). The basic idea of GHGNAS is to design a set of prompts that
can guide GPT-4 toward the task of generating new heterogeneous graph neural
architectures. By iteratively asking GPT-4 with the prompts, GHGNAS continually
validates the accuracy of the generated HGNNs and uses the feedback to further
optimize the prompts. Experimental results show that GHGNAS can design new
HGNNs by leveraging the powerful generalization capability of GPT-4. Moreover,
GHGNAS runs more effectively and stably than previous HGNAS models based on
reinforcement learning and differentiable search algorithms.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08684" title="Abstract">arXiv:2312.08684</a> [<a href="/pdf/2312.08684" title="Download PDF">pdf</a>, <a href="/format/2312.08684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stein-MAP: A Sequential Variational Inference Framework for Maximum A  Posteriori Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Min-Won Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kia%2C+S+S">Solmaz S. Kia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">State estimation poses substantial challenges in robotics, often involving
encounters with multimodality in real-world scenarios. To address these
challenges, it is essential to calculate Maximum a posteriori (MAP) sequences
from joint probability distributions of latent states and observations over
time. However, it generally involves a trade-off between approximation errors
and computational complexity. In this article, we propose a new method for MAP
sequence estimation called Stein-MAP, which effectively manages multimodality
with fewer approximation errors while significantly reducing computational and
memory burdens. Our key contribution lies in the introduction of a sequential
variational inference framework designed to handle temporal dependencies among
transition states within dynamical system models. The framework integrates
Stein's identity from probability theory and reproducing kernel Hilbert space
(RKHS) theory, enabling computationally efficient MAP sequence estimation. As a
MAP sequence estimator, Stein-MAP boasts a computational complexity of O(N),
where N is the number of particles, in contrast to the O(N^2) complexity of the
Viterbi algorithm. The proposed method is empirically validated through
real-world experiments focused on range-only (wireless) localization. The
results demonstrate a substantial enhancement in state estimation compared to
existing methods. A remarkable feature of Stein-MAP is that it can attain
improved state estimation with only 40 to 50 particles, as opposed to the 1000
particles that the particle filter or its variants require.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08685" title="Abstract">arXiv:2312.08685</a> [<a href="/pdf/2312.08685" title="Download PDF">pdf</a>, <a href="/format/2312.08685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Amplification by Iteration for ADMM with (Strongly) Convex  Objective Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+H">T-H. Hubert Chan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengshi Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Optimization and Control (math.OC)

</div>
<p class="mathjax">We examine a private ADMM variant for (strongly) convex objectives which is a
primal-dual iterative method. Each iteration has a user with a private function
used to update the primal variable, masked by Gaussian noise for local privacy,
without directly adding noise to the dual variable. Privacy amplification by
iteration explores if noises from later iterations can enhance the privacy
guarantee when releasing final variables after the last iteration. Cyffers et
al. [ICML 2023] explored privacy amplification by iteration for the proximal
ADMM variant, where a user's entire private function is accessed and noise is
added to the primal variable. In contrast, we examine a private ADMM variant
requiring just one gradient access to a user's function, but both primal and
dual variables must be passed between successive iterations. To apply Balle et
al.'s [NeurIPS 2019] coupling framework to the gradient ADMM variant, we tackle
technical challenges with novel ideas. First, we address the non-expansive
mapping issue in ADMM iterations by using a customized norm. Second, because
the dual variables are not masked with any noise directly, their privacy
guarantees are achieved by treating two consecutive noisy ADMM iterations as a
Markov operator. Our main result is that the privacy guarantee for the gradient
ADMM variant can be amplified proportionally to the number of iterations. For
strongly convex objective functions, this amplification exponentially increases
with the number of iterations. These amplification results align with the
previously studied special case of stochastic gradient descent.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08688" title="Abstract">arXiv:2312.08688</a> [<a href="/pdf/2312.08688" title="Download PDF">pdf</a>, <a href="/format/2312.08688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TigerBot: An Open Multilingual Multitask LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ye Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liangmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Z">Zhanxuan Xin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cong Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We release and introduce the TigerBot family of large language models (LLMs),
consisting of base and chat models, sized from 7, 13, 70 and 180 billion
parameters. We develop our models embarking from Llama-2 and BLOOM, and push
the boundary further in data, training algorithm, infrastructure, and
application tools. Our models yield meaningful performance gain over SOTA
open-source models, e.g., Llama-2, specifically 6\% gain in English and 20\%
gain in Chinese. TigerBot model family also achieves leading performance in
major academic and industrial benchmarks and leaderboards. We believe that
TigerBot represents just a snapshot of lightning-fast progression in LLM
open-source community. Therefore, we are thrilled to give back by publicly
releasing our models and reporting our approach behind, with additional
emphases on building SOTA LLMs in a democratized way and making LLMs of use in
real-world applications.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08689" title="Abstract">arXiv:2312.08689</a> [<a href="/pdf/2312.08689" title="Download PDF">pdf</a>, <a href="/format/2312.08689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Critical Coordination of Legged Robots via Layered Controllers  and Forward Reachable Set based Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures. arXiv admin note: substantial text overlap with <a href="/abs/2303.13630">arXiv:2303.13630</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a safety-critical approach to the coordination of robots
in dynamic environments. To this end, we leverage control barrier functions
(CBFs) with the forward reachable set to guarantee the safe coordination of the
robots while preserving a desired trajectory via a layered controller. The
top-level planner generates a safety-ensured trajectory for each agent,
accounting for the dynamic constraints in the environment. This planner
leverages high-order CBFs based on the forward reachable set to ensure
safety-critical coordination control, i.e., guarantee the safe coordination of
the robots during locomotion. The middle-level trajectory planner employs
single rigid body (SRB) dynamics to generate optimal ground reaction forces
(GRFs) to track the safety-ensured trajectories from the top-level planner. The
whole-body motions to adhere to the optimal GRFs while ensuring the friction
cone condition at the end of each stance leg are generated from the low-level
controller. The effectiveness of the approach is demonstrated through
simulation and hardware experiments.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08692" title="Abstract">arXiv:2312.08692</a> [<a href="/pdf/2312.08692" title="Download PDF">pdf</a>, <a href="/format/2312.08692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpectralNeRF: Physically Based Spectral Rendering with Neural Radiance  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ru Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanghui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose SpectralNeRF, an end-to-end Neural Radiance Field
(NeRF)-based architecture for high-quality physically based rendering from a
novel spectral perspective. We modify the classical spectral rendering into two
main steps, 1) the generation of a series of spectrum maps spanning different
wavelengths, 2) the combination of these spectrum maps for the RGB output. Our
SpectralNeRF follows these two steps through the proposed multi-layer
perceptron (MLP)-based architecture (SpectralMLP) and Spectrum Attention UNet
(SAUNet). Given the ray origin and the ray direction, the SpectralMLP
constructs the spectral radiance field to obtain spectrum maps of novel views,
which are then sent to the SAUNet to produce RGB images of white-light
illumination. Applying NeRF to build up the spectral rendering is a more
physically-based way from the perspective of ray-tracing. Further, the spectral
radiance fields decompose difficult scenes and improve the performance of
NeRF-based methods. Comprehensive experimental results demonstrate the proposed
SpectralNeRF is superior to recent NeRF-based methods when synthesizing new
views on synthetic and real datasets. The codes and datasets are available at
https://github.com/liru0126/SpectralNeRF.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08695" title="Abstract">arXiv:2312.08695</a> [<a href="/pdf/2312.08695" title="Download PDF">pdf</a>, <a href="/format/2312.08695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPST: Comprehension-Preserving Style Transfer for Multi-Modal Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jhala%2C+A">Arnav Jhala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">We investigate the challenges of style transfer in multi-modal visual
narratives. Among static visual narratives such as comics and manga, there are
distinct visual styles in terms of presentation. They include style features
across multiple dimensions, such as panel layout, size, shape, and color. They
include both visual and text media elements. The layout of both text and media
elements is also significant in terms of narrative communication. The
sequential transitions between panels are where readers make inferences about
the narrative world. These feature differences provide an interesting challenge
for style transfer in which there are distinctions between the processing of
features for each modality. We introduce the notion of comprehension-preserving
style transfer (CPST) in such multi-modal domains. CPST requires not only
traditional metrics of style transfer but also metrics of narrative
comprehension. To spur further research in this area, we present an annotated
dataset of comics and manga and an initial set of algorithms that utilize
separate style transfer modules for the visual, textual, and layout parameters.
To test whether the style transfer preserves narrative semantics, we evaluate
this algorithm through visual story cloze tests inspired by work in
computational cognition of narrative systems. Understanding the connection
between style and narrative semantics provides insight for applications ranging
from informational brochure designs to data storytelling.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08696" title="Abstract">arXiv:2312.08696</a> [<a href="/pdf/2312.08696" title="Download PDF">pdf</a>, <a href="/ps/2312.08696" title="Download PostScript">ps</a>, <a href="/format/2312.08696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the conservation properties of the two-level linearized methods for  Navier-Stokes equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/math?searchtype=author&query=Feng%2C+M">Minfu Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 table, and 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This manuscript is devoted to investigating the conservation laws of
incompressible Navier-Stokes equations(NSEs), written in the
energy-momentum-angular momentum conserving(EMAC) formulation, after being
linearized by the two-level methods. With appropriate correction steps(e.g.,
Stoke/Newton corrections), we show that the two-level methods, discretized from
EMAC NSEs, could preserve momentum, angular momentum, and asymptotically
preserve energy. Error estimates and (asymptotic) conservative properties are
analyzed and obtained, and numerical experiments are conducted to validate the
theoretical results, mainly confirming that the two-level linearized methods
indeed possess the property of (almost) retainability on conservation laws.
Moreover, experimental error estimates and optimal convergence rates of two
newly defined types of pressure approximation in EMAC NSEs are also obtained.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08697" title="Abstract">arXiv:2312.08697</a> [<a href="/pdf/2312.08697" title="Download PDF">pdf</a>, <a href="/format/2312.08697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incomplete Contrastive Multi-View Clustering with High-Confidence  Guiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chao%2C+G">Guoqing Chao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+D">Dianhui Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, and it has been accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Incomplete multi-view clustering becomes an important research problem, since
multi-view data with missing values are ubiquitous in real-world applications.
Although great efforts have been made for incomplete multi-view clustering,
there are still some challenges: 1) most existing methods didn't make full use
of multi-view information to deal with missing values; 2) most methods just
employ the consistent information within multi-view data but ignore the
complementary information; 3) For the existing incomplete multi-view clustering
methods, incomplete multi-view representation learning and clustering are
treated as independent processes, which leads to performance gap. In this work,
we proposed a novel Incomplete Contrastive Multi-View Clustering method with
high-confidence guiding (ICMVC). Firstly, we proposed a multi-view consistency
relation transfer plus graph convolutional network to tackle missing values
problem. Secondly, instance-level attention fusion and high-confidence guiding
are proposed to exploit the complementary information while instance-level
contrastive learning for latent representation is designed to employ the
consistent information. Thirdly, an end-to-end framework is proposed to
integrate multi-view missing values handling, multi-view representation
learning and clustering assignment for joint optimization. Experiments compared
with state-of-the-art approaches demonstrated the effectiveness and superiority
of our method. Our code is publicly available at
https://github.com/liunian-Jay/ICMVC.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08700" title="Abstract">arXiv:2312.08700</a> [<a href="/pdf/2312.08700" title="Download PDF">pdf</a>, <a href="/format/2312.08700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RdimKD: Generic Distillation Paradigm by Dimensionality Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiqian He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haotong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+V+T">Van Tung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shouda Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> particularly favored in industry
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Knowledge Distillation (KD) emerges as one of the most promising compression
technologies to run advanced deep neural networks on resource-limited devices.
In order to train a small network (student) under the guidance of a large
network (teacher), the intuitive method is regularizing the feature maps or
logits of the student using the teacher's information. However, existing
methods either over-restrict the student to learn all information from the
teacher, which lead to some bad local minimum, or use various fancy and
elaborate modules to process and align features, which are complex and lack
generality. In this work, we proposed an abstract and general paradigm for the
KD task, referred to as DIMensionality Reduction KD (RdimKD), which solely
relies on dimensionality reduction, with a very minor modification to naive L2
loss. RdimKD straightforwardly utilizes a projection matrix to project both the
teacher's and student's feature maps onto a low-dimensional subspace, which are
then optimized during training. RdimKD achieves the goal in the simplest way
that not only does the student get valuable information from the teacher, but
it also ensures sufficient flexibility to adapt to the student's low-capacity
reality. Our extensive empirical findings indicate the effectiveness of RdimKD
across various learning tasks and diverse network architectures.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08701" title="Abstract">arXiv:2312.08701</a> [<a href="/pdf/2312.08701" title="Download PDF">pdf</a>, <a href="/format/2312.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling End-to-End Secure Federated Learning in Biomedical Research on  Heterogeneous Computing Environments with APPFLx
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Trung-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Fuhrman%2C+J">Jordan Fuhrman</a>, 
<a href="/search/cs?searchtype=author&query=Madduri%2C+R">Ravi Madduri</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+P">Pranshu Chaturvedi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zilinghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+M">Minseok Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+R">Ryan Chard</a>, 
<a href="/search/cs?searchtype=author&query=Huerta%2C+E+A">E. A. Huerta</a>, 
<a href="/search/cs?searchtype=author&query=Giger%2C+M">Maryellen Giger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Facilitating large-scale, cross-institutional collaboration in biomedical
machine learning projects requires a trustworthy and resilient federated
learning (FL) environment to ensure that sensitive information such as
protected health information is kept confidential. In this work, we introduce
APPFLx, a low-code FL framework that enables the easy setup, configuration, and
running of FL experiments across organizational and administrative boundaries
while providing secure end-to-end communication, privacy-preserving
functionality, and identity management. APPFLx is completely agnostic to the
underlying computational infrastructure of participating clients. We
demonstrate the capability of APPFLx as an easy-to-use framework for
accelerating biomedical studies across institutions and healthcare systems
while maintaining the protection of private medical data in two case studies:
(1) predicting participant age from electrocardiogram (ECG) waveforms, and (2)
detecting COVID-19 disease from chest radiographs. These experiments were
performed securely across heterogeneous compute resources, including a mixture
of on-premise high-performance computing and cloud computing, and highlight the
role of federated learning in improving model generalizability and performance
when aggregating data from multiple healthcare systems. Finally, we demonstrate
that APPFLx serves as a convenient and easy-to-use framework for accelerating
biomedical studies across institutions and healthcare system while maintaining
the protection of private medical data.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08702" title="Abstract">arXiv:2312.08702</a> [<a href="/pdf/2312.08702" title="Download PDF">pdf</a>, <a href="/format/2312.08702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided  by Self-presentation Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+L">Liping Bu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Having the ability to empathize is crucial for accurately representing human
behavior during conversations. Despite numerous research aim to improve the
cognitive capability of models by incorporating external knowledge, there has
been limited attention on the sensible and rational expression of the
conversation itself, which are crucial components of the cognitive empathy.
Guided by self-presentation theory in sociology, we have designed an innovative
categorical approach that segregates historical dialogues into sensible and
rational sentences and subsequently elucidate the context through the designed
attention mechanism. However, the rational information within the conversation
is restricted and the external knowledge used in previous methods have
limitations of semantic contradiction and narrow vision field. Considering the
impressive performance of LLM in the domain of intelligent agent. We employ
LLaMA2-70b as a rational brain to analyze the profound logical information
maintained in conversations, which assists the model assessing the balance of
sensibility and rationality to produce quality empathetic responses.
Experimental evaluations demonstrate that our method outperforms other
comparable methods on both automatic and human evaluations.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08704" title="Abstract">arXiv:2312.08704</a> [<a href="/pdf/2312.08704" title="Download PDF">pdf</a>, <a href="/format/2312.08704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PairingNet: A Learning-based Pair-searching and -matching Network for  Image Fragments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Rixin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+D">Ding Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+H">Honglin Pang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuntao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 16 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this paper, we propose a learning-based image fragment pair-searching and
-matching approach to solve the challenging restoration problem. Existing works
use rule-based methods to match similar contour shapes or textures, which are
always difficult to tune hyperparameters for extensive data and computationally
time-consuming. Therefore, we propose a neural network that can effectively
utilize neighbor textures with contour shape information to fundamentally
improve performance. First, we employ a graph-based network to extract the
local contour and texture features of fragments. Then, for the pair-searching
task, we adopt a linear transformer-based module to integrate these local
features and use contrastive loss to encode the global features of each
fragment. For the pair-matching task, we design a weighted fusion module to
dynamically fuse extracted local contour and texture features, and formulate a
similarity matrix for each pair of fragments to calculate the matching score
and infer the adjacent segment of contours. To faithfully evaluate our proposed
network, we created a new image fragment dataset through an algorithm we
designed that tears complete images into irregular fragments. The experimental
results show that our proposed network achieves excellent pair-searching
accuracy, reduces matching errors, and significantly reduces computational
time. Details, sourcecode, and data are available in our supplementary
material.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08708" title="Abstract">arXiv:2312.08708</a> [<a href="/pdf/2312.08708" title="Download PDF">pdf</a>, <a href="/format/2312.08708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Manufacturing and Networking in Future Factories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malanchini%2C+I">Ilaria Malanchini</a>, 
<a href="/search/cs?searchtype=author&query=Michailow%2C+N">Nicola Michailow</a>, 
<a href="/search/cs?searchtype=author&query=Agostini%2C+P">Patrick Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Ali-Tolppa%2C+J">Janne Ali-Tolppa</a>, 
<a href="/search/cs?searchtype=author&query=Hock%2C+D">David Hock</a>, 
<a href="/search/cs?searchtype=author&query=Kasparick%2C+M">Martin Kasparick</a>, 
<a href="/search/cs?searchtype=author&query=Lieto%2C+A">Alessandro Lieto</a>, 
<a href="/search/cs?searchtype=author&query=Marchenko%2C+N">Nikolaj Marchenko</a>, 
<a href="/search/cs?searchtype=author&query=Alba%2C+A+M">Alberto Martinez Alba</a>, 
<a href="/search/cs?searchtype=author&query=Pries%2C+R">Rastin Pries</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiuheng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The roll out of 5G has been mainly characterized by its distinct support for
vertical industries, especially manufacturing. Leveraging synergies among these
two worlds, namely production facilities and network systems, is a fundamental
aspect to enable flexibility and economic viability in future factories. This
work highlights the potential for intelligent networking and advanced machine
learning-based solutions in 5G-and-beyond systems in the context of Industry
4.0 and flexible manufacturing. The intersection thereof allows to create
versatile machines and dynamic communication networks that can adapt to changes
in the manufacturing process, factory layout and communication environment,
supporting real-time interaction between humans, machines, and systems. We
present a vision and corresponding framework by introducing the network-aware
and production-aware principles, outlining results achieved in this context and
summarizing them into three key use cases. Finally, we discuss a selection of
remaining open challenges in private networks as well as give an outlook on
future 6G research directions.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08710" title="Abstract">arXiv:2312.08710</a> [<a href="/pdf/2312.08710" title="Download PDF">pdf</a>, <a href="/format/2312.08710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Informed Proximal Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+S">Sanghyun Son</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L+Y">Laura Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+R">Ryan Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yi-Ling Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M+C">Ming C. Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, NeurIPS 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a novel policy learning method that integrates analytical
gradients from differentiable environments with the Proximal Policy
Optimization (PPO) algorithm. To incorporate analytical gradients into the PPO
framework, we introduce the concept of an {\alpha}-policy that stands as a
locally superior policy. By adaptively modifying the {\alpha} value, we can
effectively manage the influence of analytical policy gradients during
learning. To this end, we suggest metrics for assessing the variance and bias
of analytical gradients, reducing dependence on these gradients when high
variance or bias is detected. Our proposed approach outperforms baseline
algorithms in various scenarios, such as function optimization, physics
simulations, and traffic control environments. Our code can be found online:
https://github.com/SonSang/gippo.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08714" title="Abstract">arXiv:2312.08714</a> [<a href="/pdf/2312.08714" title="Download PDF">pdf</a>, <a href="/format/2312.08714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aerial STAR-RIS Empowered MEC: A DRL Approach for Energy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aung%2C+P+S">Pyae Sone Aung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+X">Loc X. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+K">Yan Kyaw Tun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multi-access Edge Computing (MEC) addresses computational and battery
limitations in devices by allowing them to offload computation tasks. To
overcome the difficulties in establishing line-of-sight connections,
integrating unmanned aerial vehicles (UAVs) has proven beneficial, offering
enhanced data exchange, rapid deployment, and mobility. The utilization of
reconfigurable intelligent surfaces (RIS), specifically simultaneously
transmitting and reflecting RIS (STAR-RIS) technology, further extends coverage
capabilities and introduces flexibility in MEC. This study explores the
integration of UAV and STAR-RIS to facilitate communication between IoT devices
and an MEC server. The formulated problem aims to minimize energy consumption
for IoT devices and aerial STAR-RIS by jointly optimizing task offloading,
aerial STAR-RIS trajectory, amplitude and phase shift coefficients, and
transmit power. Given the non-convexity of the problem and the dynamic
environment, solving it directly within a polynomial time frame is challenging.
Therefore, deep reinforcement learning (DRL), particularly proximal policy
optimization (PPO), is introduced for its sample efficiency and stability.
Simulation results illustrate the effectiveness of the proposed system compared
to benchmark schemes in the literature.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08715" title="Abstract">arXiv:2312.08715</a> [<a href="/pdf/2312.08715" title="Download PDF">pdf</a>, <a href="/format/2312.08715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes3D: fast learning and inference in structured generative models of  3D objects and scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gothoskar%2C+N">Nishad Gothoskar</a>, 
<a href="/search/cs?searchtype=author&query=Ghavami%2C+M">Matin Ghavami</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Eric Li</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+A">Aidan Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Noseworthy%2C+M">Michael Noseworthy</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+K">Karen Chung</a>, 
<a href="/search/cs?searchtype=author&query=Patton%2C+B">Brian Patton</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Klukas%2C+M">Mirko Klukas</a>, 
<a href="/search/cs?searchtype=author&query=Mansinghka%2C+V+K">Vikash K. Mansinghka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots cannot yet match humans' ability to rapidly learn the shapes of novel
3D objects and recognize them robustly despite clutter and occlusion. We
present Bayes3D, an uncertainty-aware perception system for structured 3D
scenes, that reports accurate posterior uncertainty over 3D object shape, pose,
and scene composition in the presence of clutter and occlusion. Bayes3D
delivers these capabilities via a novel hierarchical Bayesian model for 3D
scenes and a GPU-accelerated coarse-to-fine sequential Monte Carlo algorithm.
Quantitative experiments show that Bayes3D can learn 3D models of novel objects
from just a handful of views, recognizing them more robustly and with orders of
magnitude less training data than neural baselines, and tracking 3D objects
faster than real time on a single GPU. We also demonstrate that Bayes3D learns
complex 3D object models and accurately infers 3D scene composition when used
on a Panda robot in a tabletop scenario.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08717" title="Abstract">arXiv:2312.08717</a> [<a href="/pdf/2312.08717" title="Download PDF">pdf</a>, <a href="/format/2312.08717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reactive Synthesis Using Mode Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brizzio%2C+M">Mat&#xed;as Brizzio</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+C">C&#xe9;sar S&#xe1;nchez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Developing critical components, such as mission controllers or embedded
systems, is a challenging task. Reactive synthesis is a technique to
automatically produce correct controllers. Given a high-level specification
written in LTL, reactive synthesis consists of computing a system that
satisfies the specification as long as the environment respects the
assumptions. Unfortunately, LTL synthesis suffers from high computational
complexity which precludes its use for many large cases. A promising approach
to improve synthesis scalability consists of decomposing a safety specification
into smaller specifications, that can be processed independently and composed
into a solution for the original specification. Previous decomposition methods
focus on identifying independent parts of the specification whose systems are
combined via simultaneous execution. In this work, we propose a novel
decomposition algorithm based on modes, which consists of decomposing a complex
safety specification into smaller problems whose solution is then composed
sequentially (instead of simultaneously). The input to our algorithm is the
original specification and the description of the modes. We show how to
generate sub-specifications automatically and we prove that if all sub-problems
are realizable then the full specification is realizable. Moreover, we show how
to construct a system for the original specification from sub-systems for the
decomposed specifications. We finally illustrate the feasibility of our
approach with multiple case studies using off-the-self synthesis tools to
process the obtained sub-problems.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08718" title="Abstract">arXiv:2312.08718</a> [<a href="/pdf/2312.08718" title="Download PDF">pdf</a>, <a href="/format/2312.08718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Planning and Control of Hybrid Flying-Crawling Quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dongnan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Ruihao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Hybrid Flying-Crawling Quadrotors (HyFCQs) are transformable robots with the
ability of terrestrial and aerial hybrid motion. This article presents a motion
planning and control framework designed for HyFCQs. A kinodynamic
path-searching method with the crawling limitation of HyFCQs is proposed to
guarantee the dynamical feasibility of trajectories. Subsequently, a
hierarchical motion controller is designed to map the execution of the flight
autopilot to both crawling and flying modes. Considering the distinct driving
methods for crawling and flying, we introduce a motion state machine for
autonomous locomotion regulation. Real-world experiments in diverse scenarios
validate the exceptional performance of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08720" title="Abstract">arXiv:2312.08720</a> [<a href="/pdf/2312.08720" title="Download PDF">pdf</a>, <a href="/format/2312.08720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panel Transitions for Genre Analysis in Visual Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jhala%2C+A">Arnav Jhala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">Understanding how humans communicate and perceive narratives is important for
media technology research and development. This is particularly important in
current times when there are tools and algorithms that are easily available for
amateur users to create high-quality content. Narrative media develops over
time a set of recognizable patterns of features across similar artifacts. Genre
is one such grouping of artifacts for narrative media with similar patterns,
tropes, and story structures. While much work has been done on genre-based
classifications in text and video, we present a novel approach to do a
multi-modal analysis of genre based on comics and manga-style visual
narratives. We present a systematic feature analysis of an annotated dataset
that includes a variety of western and eastern visual books with annotations
for high-level narrative patterns. We then present a detailed analysis of the
contributions of high-level features to genre classification for this medium.
We highlight some of the limitations and challenges of our existing
computational approaches in modeling subjective labels. Our contributions to
the community are: a dataset of annotated manga books, a multi-modal analysis
of visual panels and text in a constrained and popular medium through
high-level features, and a systematic process for incorporating subjective
narrative patterns in computational models.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08722" title="Abstract">arXiv:2312.08722</a> [<a href="/pdf/2312.08722" title="Download PDF">pdf</a>, <a href="/format/2312.08722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Divergence for Human-AI Collaboration and Cognitive Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kural%2C+M">M&#xfc;ge Kural</a>, 
<a href="/search/cs?searchtype=author&query=Gebe%C5%9F%C3%A7e%2C+A">Ali Gebe&#x15f;&#xe7;e</a>, 
<a href="/search/cs?searchtype=author&query=Chubakov%2C+T">Tilek Chubakov</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Predicting the collaboration likelihood and measuring cognitive trust to AI
systems is more important than ever. To do that, previous research mostly focus
solely on the model features (e.g., accuracy, confidence) and ignore the human
factor. To address that, we propose several decision-making similarity measures
based on divergence metrics (e.g., KL, JSD) calculated over the labels acquired
from humans and a wide range of models. We conduct a user study on a textual
entailment task, where the users are provided with soft labels from various
models and asked to pick the closest option to them. The users are then shown
the similarities/differences to their most similar model and are surveyed for
their likelihood of collaboration and cognitive trust to the selected system.
Finally, we qualitatively and quantitatively analyze the relation between the
proposed decision-making similarity measures and the survey results. We find
that people tend to collaborate with their most similar models -- measured via
JSD -- yet this collaboration does not necessarily imply a similar level of
cognitive trust. We release all resources related to the user study (e.g.,
design, outputs), models, and metrics at our repo.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08723" title="Abstract">arXiv:2312.08723</a> [<a href="/pdf/2312.08723" title="Download PDF">pdf</a>, <a href="/ps/2312.08723" title="Download PostScript">ps</a>, <a href="/format/2312.08723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StemGen: A music generation model that listens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parker%2C+J+D">Julian D. Parker</a>, 
<a href="/search/cs?searchtype=author&query=Spijkervet%2C+J">Janne Spijkervet</a>, 
<a href="/search/cs?searchtype=author&query=Kosta%2C+K">Katerina Kosta</a>, 
<a href="/search/cs?searchtype=author&query=Yesiler%2C+F">Furkan Yesiler</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+B">Boris Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Ju-Chiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Avent%2C+M">Matt Avent</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jitong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">End-to-end generation of musical audio using deep learning techniques has
seen an explosion of activity recently. However, most models concentrate on
generating fully mixed music in response to abstract conditioning information.
In this work, we present an alternative paradigm for producing music generation
models that can listen and respond to musical context. We describe how such a
model can be constructed using a non-autoregressive, transformer-based model
architecture and present a number of novel architectural and sampling
improvements. We train the described architecture on both an open-source and a
proprietary dataset. We evaluate the produced models using standard quality
metrics and a new approach based on music information retrieval descriptors.
The resulting model reaches the audio quality of state-of-the-art
text-conditioned models, as well as exhibiting strong musical coherence with
its context.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08724" title="Abstract">arXiv:2312.08724</a> [<a href="/pdf/2312.08724" title="Download PDF">pdf</a>, <a href="/format/2312.08724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Path Recourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dat Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces Personalized Path Recourse, a novel method that
generates recourse paths for an agent. The objective is to achieve desired
goals (e.g., better outcomes compared to the agent's original paths of action),
while ensuring a high similarity to the agent's original paths and being
personalized to the agent. Personalization refers to the extent to which the
new path is tailored to the agent's observed behavior patterns from their
policy function. We train a personalized recourse agent to generate such
personalized paths, which are obtained using reward functions that consider the
goal, similarity, and personalization. The proposed method is applicable to
both reinforcement learning and supervised learning settings for correcting or
improving sequences of actions or sequences of data to achieve a pre-determined
goal. The method is evaluated in various settings and demonstrates promising
results.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08725" title="Abstract">arXiv:2312.08725</a> [<a href="/pdf/2312.08725" title="Download PDF">pdf</a>, <a href="/format/2312.08725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Fine-Tuned LLMs and Few-Shot Learning of LLMs  for Financial Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+S">Sorouralsadat Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuheng Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Financial sentiment analysis plays a crucial role in uncovering latent
patterns and detecting emerging trends, enabling individuals to make
well-informed decisions that may yield substantial advantages within the
constantly changing realm of finance. Recently, Large Language Models (LLMs)
have demonstrated their effectiveness in diverse domains, showcasing remarkable
capabilities even in zero-shot and few-shot in-context learning for various
Natural Language Processing (NLP) tasks. Nevertheless, their potential and
applicability in the context of financial sentiment analysis have not been
thoroughly explored yet. To bridge this gap, we employ two approaches:
in-context learning (with a focus on gpt-3.5-turbo model) and fine-tuning LLMs
on a finance-domain dataset. Given the computational costs associated with
fine-tuning LLMs with large parameter sizes, our focus lies on smaller LLMs,
spanning from 250M to 3B parameters for fine-tuning. We then compare the
performances with state-of-the-art results to evaluate their effectiveness in
the finance-domain. Our results demonstrate that fine-tuned smaller LLMs can
achieve comparable performance to state-of-the-art fine-tuned LLMs, even with
models having fewer parameters and a smaller training dataset. Additionally,
the zero-shot and one-shot performance of LLMs produces comparable results with
fine-tuned smaller LLMs and state-of-the-art outcomes. Furthermore, our
analysis demonstrates that there is no observed enhancement in performance for
finance-domain sentiment analysis when the number of shots for in-context
learning is increased.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08726" title="Abstract">arXiv:2312.08726</a> [<a href="/pdf/2312.08726" title="Download PDF">pdf</a>, <a href="/format/2312.08726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Labels Need Prompts Too Mask Matching for Natural Language Understanding  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quansen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, Regular Paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Textual label names (descriptions) are typically semantically rich in many
natural language understanding (NLU) tasks. In this paper, we incorporate the
prompting methodology, which is widely used to enrich model input, into the
label side for the first time. Specifically, we propose a Mask Matching method,
which equips an input with a prompt and its label with another, and then makes
predictions by matching their mask representations. We evaluate our method
extensively on 8 NLU tasks with 14 datasets. The experimental results show that
Mask Matching significantly outperforms its counterparts of fine-tuning and
conventional prompt-tuning, setting up state-of-the-art performances in several
datasets. Mask Matching is particularly good at handling NLU tasks with large
label counts and informative label names. As pioneering efforts that
investigate the label-side prompt, we also discuss open issues for future
study.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08727" title="Abstract">arXiv:2312.08727</a> [<a href="/pdf/2312.08727" title="Download PDF">pdf</a>, <a href="/format/2312.08727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration-compatible Listwise Distillation of Privileged Features for  CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiaoqiang Gui</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yueyao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">Xiang-Rong Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by WSDM'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In machine learning systems, privileged features refer to the features that
are available during offline training but inaccessible for online serving.
Previous studies have recognized the importance of privileged features and
explored ways to tackle online-offline discrepancies. A typical practice is
privileged features distillation (PFD): train a teacher model using all
features (including privileged ones) and then distill the knowledge from the
teacher model using a student model (excluding the privileged features), which
is then employed for online serving. In practice, the pointwise cross-entropy
loss is often adopted for PFD. However, this loss is insufficient to distill
the ranking ability for CTR prediction. First, it does not consider the
non-i.i.d. characteristic of the data distribution, i.e., other items on the
same page significantly impact the click probability of the candidate item.
Second, it fails to consider the relative item order ranked by the teacher
model's predictions, which is essential to distill the ranking ability. To
address these issues, we first extend the pointwise-based PFD to the
listwise-based PFD. We then define the calibration-compatible property of
distillation loss and show that commonly used listwise losses do not satisfy
this property when employed as distillation loss, thus compromising the model's
calibration ability, which is another important measure for CTR prediction. To
tackle this dilemma, we propose Calibration-compatible LIstwise Distillation
(CLID), which employs carefully-designed listwise distillation loss to achieve
better ranking ability than the pointwise-based PFD while preserving the
model's calibration ability. We theoretically prove it is
calibration-compatible. Extensive experiments on public datasets and a
production dataset collected from the display advertising system of Alibaba
further demonstrate the effectiveness of CLID.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08730" title="Abstract">arXiv:2312.08730</a> [<a href="/pdf/2312.08730" title="Download PDF">pdf</a>, <a href="/format/2312.08730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust and Expressive Whole-body Human Pose and Shape Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=EnPang%2C+H">Hui EnPang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Q">Qingyi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Whole-body pose and shape estimation aims to jointly predict different
behaviors (e.g., pose, hand gesture, facial expression) of the entire human
body from a monocular image. Existing methods often exhibit degraded
performance under the complexity of in-the-wild scenarios. We argue that the
accuracy and reliability of these models are significantly affected by the
quality of the predicted \textit{bounding box}, e.g., the scale and alignment
of body parts. The natural discrepancy between the ideal bounding box
annotations and model detection results is particularly detrimental to the
performance of whole-body pose and shape estimation. In this paper, we propose
a novel framework to enhance the robustness of whole-body pose and shape
estimation. Our framework incorporates three new modules to address the above
challenges from three perspectives: \textbf{1) Localization Module} enhances
the model's awareness of the subject's location and semantics within the image
space. \textbf{2) Contrastive Feature Extraction Module} encourages the model
to be invariant to robust augmentations by incorporating contrastive loss with
dedicated positive samples. \textbf{3) Pixel Alignment Module} ensures the
reprojected mesh from the predicted camera and body model parameters are
accurate and pixel-aligned. We perform comprehensive experiments to demonstrate
the effectiveness of our proposed framework on body, hands, face and whole-body
benchmarks. Codebase is available at
\url{https://github.com/robosmplx/robosmplx}.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08731" title="Abstract">arXiv:2312.08731</a> [<a href="/pdf/2312.08731" title="Download PDF">pdf</a>, <a href="/format/2312.08731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Hybrid Eye Typing Interfaces with Word and Letter Prediction:  A Comprehensive Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhe Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Siebert%2C+F+W">Felix Wilhelm Siebert</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hailong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Eye typing interfaces enable a person to enter text into an interface using
only their own eyes. But despite the inherent advantages of touchless operation
and intuitive design, such eye-typing interfaces often suffer from slow typing
speeds, resulting in slow words per minute (WPM) counts. In this study, we add
word and letter prediction to the eye-typing interface and investigate users'
typing performance as well as their subjective experience while using the
interface. In experiment 1, we compared three typing interfaces with letter
prediction (LP), letter+word prediction (L+WP), and no prediction (NoP),
respectively. We found that the interface with L+WP achieved the highest
average text entry speed (5.48 WPM), followed by the interface with LP (3.42
WPM), and the interface with NoP (3.39 WPM). Participants were able to quickly
understand the procedural design for word prediction and perceived this
function as very helpful. Compared to LP and NoP, participants needed more time
to familiarize themselves with L+WP in order to reach a plateau regarding text
entry speed. Experiment 2 explored training effects in L+WP interfaces. Two
moving speeds were implemented: slow (6.4{\deg}/s same speed as in experiment
1) and fast (10{\deg}/s). The study employed a mixed experimental design,
incorporating moving speeds as a between-subjects factor, to evaluate its
influence on typing performance throughout 10 consecutive training sessions.
The results showed that the typing speed reached 6.17 WPM for the slow group
and 7.35 WPM for the fast group after practice. Overall, the two experiments
show that adding letter and word prediction to eye-typing interfaces increases
typing speeds. We also find that more extended training is required to achieve
these high typing speeds.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08732" title="Abstract">arXiv:2312.08732</a> [<a href="/pdf/2312.08732" title="Download PDF">pdf</a>, <a href="/format/2312.08732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIA: A Teaching Intonation Assessment Dataset in Real Teaching  Situations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binshuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+N">Niantong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Huanting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huayu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 4 tables, accepted by 2024 International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Intonation is one of the important factors affecting the teaching language
arts, so it is an urgent problem to be addressed by evaluating the teachers'
intonation through artificial intelligence technology. However, the lack of an
intonation assessment dataset has hindered the development of the field. To
this end, this paper constructs a Teaching Intonation Assessment (TIA) dataset
for the first time in real teaching situations. This dataset covers 9
disciplines, 396 teachers, total of 11,444 utterance samples with a length of
15 seconds. In order to test the validity of the dataset, this paper proposes a
teaching intonation assessment model (TIAM) based on low-level and deep-level
features of speech. The experimental results show that TIAM based on the
dataset constructed in this paper is basically consistent with the results of
manual evaluation, and the results are better than the baseline models, which
proves the effectiveness of the evaluation model.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08733" title="Abstract">arXiv:2312.08733</a> [<a href="/pdf/2312.08733" title="Download PDF">pdf</a>, <a href="/format/2312.08733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VMT-Adapter: Parameter-Efficient Transfer Learning for Multi-Task Dense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yi Xin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junlong Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale pre-trained models have achieved remarkable success in various
computer vision tasks. A standard approach to leverage these models is to
fine-tune all model parameters for downstream tasks, which poses challenges in
terms of computational and storage costs. Recently, inspired by Natural
Language Processing (NLP), parameter-efficient transfer learning has been
successfully applied to vision tasks. However, most existing techniques
primarily focus on single-task adaptation, and despite limited research on
multi-task adaptation, these methods often exhibit suboptimal training and
inference efficiency. In this paper, we first propose an once-for-all Vision
Multi-Task Adapter (VMT-Adapter), which strikes approximately O(1) training and
inference efficiency w.r.t task number. Concretely, VMT-Adapter shares the
knowledge from multiple tasks to enhance cross-task interaction while preserves
task-specific knowledge via independent knowledge extraction modules. Notably,
since task-specific modules require few parameters, VMT-Adapter can handle an
arbitrary number of tasks with a negligible increase of trainable parameters.
We also propose VMT-Adapter-Lite, which further reduces the trainable
parameters by learning shared parameters between down- and up-projections.
Extensive experiments on four dense scene understanding tasks demonstrate the
superiority of VMT-Adapter(-Lite), achieving a 3.96%(1.34%) relative
improvement compared to single-task full fine-tuning, while utilizing merely
~1% (0.36%) trainable parameters of the pre-trained model.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08735" title="Abstract">arXiv:2312.08735</a> [<a href="/pdf/2312.08735" title="Download PDF">pdf</a>, <a href="/format/2312.08735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polyper: Boundary Sensitive Polyp Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Hao Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new boundary sensitive framework for polyp segmentation, called
Polyper. Our method is motivated by a clinical approach that seasoned medical
practitioners often leverage the inherent features of interior polyp regions to
tackle blurred boundaries.Inspired by this, we propose explicitly leveraging
polyp regions to bolster the model's boundary discrimination capability while
minimizing computation. Our approach first extracts boundary and polyp regions
from the initial segmentation map through morphological operators. Then, we
design the boundary sensitive attention that concentrates on augmenting the
features near the boundary regions using the interior polyp regions's
characteristics to generate good segmentation results. Our proposed method can
be seamlessly integrated with classical encoder networks, like ResNet-50,
MiT-B1, and Swin Transformer. To evaluate the effectiveness of Polyper, we
conduct experiments on five publicly available challenging datasets, and
receive state-of-the-art performance on all of them. Code is available at
https://github.com/haoshao-nku/medical_seg.git.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08736" title="Abstract">arXiv:2312.08736</a> [<a href="/pdf/2312.08736" title="Download PDF">pdf</a>, <a href="/format/2312.08736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank multipatch isogeometric method based on Tucker tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montardini%2C+M">Monica Montardini</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">Giancarlo Sangalli</a>, 
<a href="/search/math?searchtype=author&query=Tani%2C+M">Mattia Tani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a low-rank method for conforming multipatch
discretizations of compressible linear elasticity problems using Isogeometric
Analysis. The proposed technique is a non-trivial extension of [M. Montardini,
G. Sangalli, and M. Tani. A low-rank isogeometric solver based on Tucker
tensors. Comput. Methods Appl. Mech. Engrg., page 116472, 2023.] to multipatch
geometries. We tackle the model problem using an overlapping Schwarz method,
where the subdomains can be defined as unions of neighbouring patches. Then on
each subdomain we approximate the blocks of the linear system matrix and of the
right-hand side vector using Tucker matrices and Tucker vectors, respectively.
We use the Truncated Preconditioned Conjugate Gradient as a linear solver,
coupled with a suited preconditioner. The numerical experiments show the
advantages of this approach in terms of memory storage. Moreover, the number of
iterations is robust with respect to the relevant parameters.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08737" title="Abstract">arXiv:2312.08737</a> [<a href="/pdf/2312.08737" title="Download PDF">pdf</a>, <a href="/format/2312.08737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JPIS: A Joint Model for Profile-based Intent Detection and Slot Filling  with Slot-to-Intent Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thinh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Dat Quoc Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024 (Accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Profile-based intent detection and slot filling are important tasks aimed at
reducing the ambiguity in user utterances by leveraging user-specific
supporting profile information. However, research in these two tasks has not
been extensively explored. To fill this gap, we propose a joint model, namely
JPIS, designed to enhance profile-based intent detection and slot filling. JPIS
incorporates the supporting profile information into its encoder and introduces
a slot-to-intent attention mechanism to transfer slot information
representations to intent detection. Experimental results show that our JPIS
substantially outperforms previous profile-based models, establishing a new
state-of-the-art performance in overall accuracy on the Chinese benchmark
dataset ProSLU.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08740" title="Abstract">arXiv:2312.08740</a> [<a href="/pdf/2312.08740" title="Download PDF">pdf</a>, <a href="/format/2312.08740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Low-Rank Feature Representation: Achieving Better Trade-Off  between Stability and Plasticity in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenrong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yik-Chung Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the proceedings of ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In continual learning, networks confront a trade-off between stability and
plasticity when trained on a sequence of tasks. To bolster plasticity without
sacrificing stability, we propose a novel training algorithm called LRFR. This
approach optimizes network parameters in the null space of the past tasks'
feature representation matrix to guarantee the stability. Concurrently, we
judiciously select only a subset of neurons in each layer of the network while
training individual tasks to learn the past tasks' feature representation
matrix in low-rank. This increases the null space dimension when designing
network parameters for subsequent tasks, thereby enhancing the plasticity.
Using CIFAR-100 and TinyImageNet as benchmark datasets for continual learning,
the proposed approach consistently outperforms state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08743" title="Abstract">arXiv:2312.08743</a> [<a href="/pdf/2312.08743" title="Download PDF">pdf</a>, <a href="/format/2312.08743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAPP: Fast and Adaptive Perception and Planning for UAVs in Dynamic  Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Minghao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Obstacle avoidance for Unmanned Aerial Vehicles (UAVs) in cluttered
environments is significantly challenging. Existing obstacle avoidance for UAVs
either focuses on fully static environments or static environments with only a
few dynamic objects. In this paper, we take the initiative to consider the
obstacle avoidance of UAVs in dynamic cluttered environments in which dynamic
objects are the dominant objects. This type of environment poses significant
challenges to both perception and planning. Multiple dynamic objects possess
various motions, making it extremely difficult to estimate and predict their
motions using one motion model. The planning must be highly efficient to avoid
cluttered dynamic objects. This paper proposes Fast and Adaptive Perception and
Planning (FAPP) for UAVs flying in complex dynamic cluttered environments. A
novel and efficient point cloud segmentation strategy is proposed to
distinguish static and dynamic objects. To address multiple dynamic objects
with different motions, an adaptive estimation method with covariance
adaptation is proposed to quickly and accurately predict their motions. Our
proposed trajectory optimization algorithm is highly efficient, enabling it to
avoid fast objects. Furthermore, an adaptive re-planning method is proposed to
address the case when the trajectory optimization cannot find a feasible
solution, which is common for dynamic cluttered environments. Extensive
validations in both simulation and real-world experiments demonstrate the
effectiveness of our proposed system for highly dynamic and cluttered
environments.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08744" title="Abstract">arXiv:2312.08744</a> [<a href="/pdf/2312.08744" title="Download PDF">pdf</a>, <a href="/format/2312.08744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOEnFusion: Gradient Origin Encodings for 3D Forward Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karnewar%2C+A">Animesh Karnewar</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Novotny%2C+D">David Novotny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page at: <a href="https://holodiffusion.github.io/goenfusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The recently introduced Forward-Diffusion method allows to train a 3D
diffusion model using only 2D images for supervision. However, it does not
easily generalise to different 3D representations and requires a
computationally expensive auto-regressive sampling process to generate the
underlying 3D scenes. In this paper, we propose GOEn: Gradient Origin Encoding
(pronounced "gone"). GOEn can encode input images into any type of 3D
representation without the need to use a pre-trained image feature extractor.
It can also handle single, multiple or no source view(s) alike, by design, and
tries to maximise the information transfer from the views to the encodings. Our
proposed GOEnFusion model pairs GOEn encodings with a realisation of the
Forward-Diffusion model which addresses the limitations of the vanilla
Forward-Diffusion realisation. We evaluate how much information the GOEn
mechanism transfers to the encoded representations, and how well it captures
the prior distribution over the underlying 3D scenes, through the lens of a
partial AutoEncoder. Lastly, the efficacy of the GOEnFusion model is evaluated
on the recently proposed OmniObject3D dataset while comparing to the
state-of-the-art Forward and non-Forward-Diffusion models and other 3D
generative models.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08746" title="Abstract">arXiv:2312.08746</a> [<a href="/pdf/2312.08746" title="Download PDF">pdf</a>, <a href="/format/2312.08746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamDrone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">Hanyang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Dongze Lian</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce DreamDrone, an innovative method for generating unbounded
flythrough scenes from textual prompts. Central to our method is a novel
feature-correspondence-guidance diffusion process, which utilizes the strong
correspondence of intermediate features in the diffusion model. Leveraging this
guidance strategy, we further propose an advanced technique for editing the
intermediate latent code, enabling the generation of subsequent novel views
with geometric consistency. Extensive experiments reveal that DreamDrone
significantly surpasses existing methods, delivering highly authentic scene
generation with exceptional visual quality. This approach marks a significant
step in zero-shot perpetual view generation from textual prompts, enabling the
creation of diverse scenes, including natural landscapes like oases and caves,
as well as complex urban settings such as Lego-style street views. Our code is
publicly available.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08747" title="Abstract">arXiv:2312.08747</a> [<a href="/pdf/2312.08747" title="Download PDF">pdf</a>, <a href="/format/2312.08747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting vocabulary biases datasets through statistical testing and  automated data augmentation for artifact mitigation in Natural Language  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+T">Dat Thanh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, the availability of large-scale annotated datasets, such as
the Stanford Natural Language Inference and the Multi-Genre Natural Language
Inference, coupled with the advent of pre-trained language models, has
significantly contributed to the development of the natural language inference
domain. However, these crowdsourced annotated datasets often contain biases or
dataset artifacts, leading to overestimated model performance and poor
generalization. In this work, we focus on investigating dataset artifacts and
developing strategies to address these issues. Through the utilization of a
novel statistical testing procedure, we discover a significant association
between vocabulary distribution and text entailment classes, emphasizing
vocabulary as a notable source of biases. To mitigate these issues, we propose
several automatic data augmentation strategies spanning character to word
levels. By fine-tuning the ELECTRA pre-trained language model, we compare the
performance of boosted models with augmented data against their baseline
counterparts. The experiments demonstrate that the proposed approaches
effectively enhance model accuracy and reduce biases by up to 0.66% and 1.14%,
respectively.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08748" title="Abstract">arXiv:2312.08748</a> [<a href="/pdf/2312.08748" title="Download PDF">pdf</a>, <a href="/format/2312.08748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All-to-all reconfigurability with sparse Ising machines: the XORSAT  challenge with p-bits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aadit%2C+N+A">Navid Anjum Aadit</a>, 
<a href="/search/cs?searchtype=author&query=Nikhar%2C+S">Srijan Nikhar</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S">Sidharth Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S">Shuvro Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Camsari%2C+K+Y">Kerem Y. Camsari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Emerging Technologies (cs.ET); Neural and Evolutionary Computing (cs.NE); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Domain-specific hardware to solve computationally hard optimization problems
has generated tremendous excitement recently. Here, we evaluate probabilistic
bit (p-bit) based Ising Machines (IM), or p-computers with a benchmark
combinatorial optimization problem, namely the 3-regular 3-XOR Satisfiability
(3R3X). The 3R3X problem has a glassy energy landscape and it has recently been
used to benchmark various IMs and other solvers. We introduce a multiplexed
architecture where p-computers emulate all-to-all (complete) graph
functionality despite being interconnected in highly sparse networks, enabling
highly parallelized Gibbs sampling. We implement this architecture in FPGAs and
show that p-bit networks running an adaptive version of the powerful parallel
tempering algorithm demonstrate competitive algorithmic and prefactor
advantages over alternative IMs by D-Wave, Toshiba and others. Scaled magnetic
nanodevice-based realizations of p-computers could lead to orders-of-magnitude
further improvement according to experimentally established projections.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08749" title="Abstract">arXiv:2312.08749</a> [<a href="/pdf/2312.08749" title="Download PDF">pdf</a>, <a href="/format/2312.08749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Label Bias in Machine Learning: Fairness through Confident  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zenan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Discrimination can occur when the underlying unbiased labels are overwritten
by an agent with potential bias, resulting in biased datasets that unfairly
harm specific groups and cause classifiers to inherit these biases. In this
paper, we demonstrate that despite only having access to the biased labels, it
is possible to eliminate bias by filtering the fairest instances within the
framework of confident learning. In the context of confident learning, low
self-confidence usually indicates potential label errors; however, this is not
always the case. Instances, particularly those from underrepresented groups,
might exhibit low confidence scores for reasons other than labeling errors. To
address this limitation, our approach employs truncation of the confidence
score and extends the confidence interval of the probabilistic threshold.
Additionally, we incorporate with co-teaching paradigm for providing a more
robust and reliable selection of fair instances and effectively mitigating the
adverse effects of biased labels. Through extensive experimentation and
evaluation of various datasets, we demonstrate the efficacy of our approach in
promoting fairness and reducing the impact of label bias in machine learning
models.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08751" title="Abstract">arXiv:2312.08751</a> [<a href="/pdf/2312.08751" title="Download PDF">pdf</a>, <a href="/format/2312.08751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improve Robustness of Reinforcement Learning against Observation  Perturbations via $l_\infty$ Lipschitz Policy Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+B">Buqing Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jingtian Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yangqing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper on AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep Reinforcement Learning (DRL) has achieved remarkable advances in
sequential decision tasks. However, recent works have revealed that DRL agents
are susceptible to slight perturbations in observations. This vulnerability
raises concerns regarding the effectiveness and robustness of deploying such
agents in real-world applications. In this work, we propose a novel robust
reinforcement learning method called SortRL, which improves the robustness of
DRL policies against observation perturbations from the perspective of the
network architecture. We employ a novel architecture for the policy network
that incorporates global $l_\infty$ Lipschitz continuity and provide a
convenient method to enhance policy robustness based on the output margin.
Besides, a training framework is designed for SortRL, which solves given tasks
while maintaining robustness against $l_\infty$ bounded perturbations on the
observations. Several experiments are conducted to evaluate the effectiveness
of our method, including classic control tasks and video games. The results
demonstrate that SortRL achieves state-of-the-art robustness performance
against different perturbation strength.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08753" title="Abstract">arXiv:2312.08753</a> [<a href="/pdf/2312.08753" title="Download PDF">pdf</a>, <a href="/format/2312.08753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDARS Empowered Massive MIMO System: Two-Timescale Transceiver Design  with Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengzhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we investigate a novel reconfigurable distributed antennas and
reflecting surface (RDARS) aided multi-user massive MIMO system with imperfect
CSI and propose a practical two-timescale (TTS) transceiver design to reduce
the communication overhead and computational complexity of the system. In the
RDARS-aided system, not only distribution gain but also reflection gain can be
obtained by a flexible combination of the distributed antennas and reflecting
surface, which differentiates the system from the others and also makes the TTS
design challenging. To enable the optimal TTS transceiver design, the
achievable rate of the system is first derived in closed-form. Then the TTS
design aiming at the weighted sum rate maximization is considered. To solve the
challenging non-convex optimization problem with high-order design variables,
i.e., the transmit powers and the phase shifts at the RDARS, a block coordinate
descent based method is proposed to find the optimal solutions in semi-closed
forms iteratively. Specifically, two efficient algorithms are proposed with
provable convergence for the optimal phase shift design, i.e., Riemannian
Gradient Ascent based algorithm by exploiting the unit-modulus constraints, and
Two-Tier Majorization-Minimization based algorithm with closed-form optimal
solutions in each iteration. Simulation results validate the effectiveness of
the proposed algorithm and demonstrate the superiority of deploying RDARS in
massive MIMO systems to provide substantial rate improvement with a
significantly reduced total number of active antennas/RF chains and lower
transmit power when compared to the DAS and RIS-aided systems.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08754" title="Abstract">arXiv:2312.08754</a> [<a href="/pdf/2312.08754" title="Download PDF">pdf</a>, <a href="/format/2312.08754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniDream: Unifying Diffusion Priors for Relightable Text-to-3D  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zexiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youtian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Ding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in text-to-3D generation technology have significantly
advanced the conversion of textual descriptions into imaginative
well-geometrical and finely textured 3D objects. Despite these developments, a
prevalent limitation arises from the use of RGB data in diffusion or
reconstruction models, which often results in models with inherent lighting and
shadows effects that detract from their realism, thereby limiting their
usability in applications that demand accurate relighting capabilities. To
bridge this gap, we present UniDream, a text-to-3D generation framework by
incorporating unified diffusion priors. Our approach consists of three main
components: (1) a dual-phase training process to get albedo-normal aligned
multi-view diffusion and reconstruction models, (2) a progressive generation
procedure for geometry and albedo-textures based on Score Distillation Sample
(SDS) using the trained reconstruction and diffusion models, and (3) an
innovative application of SDS for finalizing PBR generation while keeping a
fixed albedo based on Stable Diffusion model. Extensive evaluations demonstrate
that UniDream surpasses existing methods in generating 3D objects with clearer
albedo textures, smoother surfaces, enhanced realism, and superior relighting
capabilities.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08755" title="Abstract">arXiv:2312.08755</a> [<a href="/pdf/2312.08755" title="Download PDF">pdf</a>, <a href="/format/2312.08755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROPRES: Investigating the Projectivity of Presupposition with Various  Triggers and Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asami%2C+D">Daiki Asami</a>, 
<a href="/search/cs?searchtype=author&query=Sugawara%2C+S">Saku Sugawara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 27th Conference on Computational Natural Language Learning (CoNLL2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">What makes a presupposition of an utterance -- information taken for granted
by its speaker -- different from other pragmatic inferences such as an
entailment is projectivity (e.g., the negative sentence the boy did not stop
shedding tears presupposes the boy had shed tears before). The projectivity may
vary depending on the combination of presupposition triggers and environments.
However, prior natural language understanding studies fail to take it into
account as they either use no human baseline or include only negation as an
entailment-canceling environment to evaluate models' performance. The current
study attempts to reconcile these issues. We introduce a new dataset,
projectivity of presupposition (PROPRES, which includes 12k premise-hypothesis
pairs crossing six triggers involving some lexical variety with five
environments. Our human evaluation reveals that humans exhibit variable
projectivity in some cases. However, the model evaluation shows that the
best-performed model, DeBERTa, does not fully capture it. Our findings suggest
that probing studies on pragmatic inferences should take extra care of the
human judgment variability and the combination of linguistic items.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08759" title="Abstract">arXiv:2312.08759</a> [<a href="/pdf/2312.08759" title="Download PDF">pdf</a>, <a href="/ps/2312.08759" title="Download PostScript">ps</a>, <a href="/format/2312.08759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3c7;$-binding functions for squares of bipartite graphs and its  subclasses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Dibyayan Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+L+S">L. Sunil Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+D">Dalu Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Pillai%2C+R+R">Raji R. Pillai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">A class of graphs $\mathcal{G}$ is $\chi$-bounded if there exists a function
$f$ such that $\chi(G) \leq f(\omega(G))$ for each graph $G \in \mathcal{G}$,
where $\chi(G)$ and $\omega(G)$ are the chromatic and clique number of $G$,
respectively. The square of a graph $G$, denoted as $G^2$, is the graph with
the same vertex set as $G$ in which two vertices are adjacent when they are at
a distance at most two in $G$. In this paper, we study the $\chi$-boundedness
of squares of bipartite graphs and its subclasses. Note that the class of
squares of graphs, in general, admit a quadratic $\chi$-binding function.
Moreover there exist bipartite graphs $B$ for which $\chi\left(B^2\right)$ is
$\Omega\left(\frac{\left(\omega\left(B^2\right)\right)^2 }{\log
\omega\left(B^2\right)}\right)$. We first ask the following question: "What
sub-classes of bipartite graphs have a linear $\chi$-binding function?" We
focus on the class of convex bipartite graphs and prove the following result:
for any convex bipartite graph $G$, $\chi\left(G^2\right) \leq \frac{3
\omega\left(G^2\right)}{2}$. Our proof also yields a polynomial-time
$3/2$-approximation algorithm for coloring squares of convex bipartite graphs.
We then introduce a notion called "partite testable properties" for the squares
of bipartite graphs. We say that a graph property $P$ is partite testable for
the squares of bipartite graphs if for a bipartite graph $G=(A,B,E)$, whenever
the induced subgraphs $G^2[A]$ and $G^2[B]$ satisfies the property $P$ then
$G^2$ also satisfies the property $P$. Here, we discuss whether some of the
well-known graph properties like perfectness, chordality, (anti-hole)-freeness,
etc. are partite testable or not. As a consequence, we prove that the squares
of biconvex bipartite graphs are perfect.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08760" title="Abstract">arXiv:2312.08760</a> [<a href="/pdf/2312.08760" title="Download PDF">pdf</a>, <a href="/format/2312.08760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qingsong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaiyong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiaowen Chu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+F">Fei Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have demonstrated impressive performance in
novel view synthesis. However, NeRF and most of its variants still rely on
traditional complex pipelines to provide extrinsic and intrinsic camera
parameters, such as COLMAP. Recent works, like NeRFmm, BARF, and L2G-NeRF,
directly treat camera parameters as learnable and estimate them through
differential volume rendering. However, these methods work for forward-looking
scenes with slight motions and fail to tackle the rotation scenario in
practice. To overcome this limitation, we propose a novel \underline{c}amera
parameter \underline{f}ree neural radiance field (CF-NeRF), which incrementally
reconstructs 3D representations and recovers the camera parameters inspired by
incremental structure from motion (SfM). Given a sequence of images, CF-NeRF
estimates the camera parameters of images one by one and reconstructs the scene
through initialization, implicit localization, and implicit optimization. To
evaluate our method, we use a challenging real-world dataset NeRFBuster which
provides 12 scenes under complex trajectories. Results demonstrate that CF-NeRF
is robust to camera rotation and achieves state-of-the-art results without
providing prior information and constraints.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08762" title="Abstract">arXiv:2312.08762</a> [<a href="/pdf/2312.08762" title="Download PDF">pdf</a>, <a href="/format/2312.08762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Latent Space Learning for Chain-of-Thought Reasoning in  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liqi He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiantao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Chain-of-thought (CoT) reasoning has exhibited impressive performance in
language models for solving complex tasks and answering questions. However,
many real-world questions require multi-modal information, such as text and
images. Previous research on multi-modal CoT has primarily focused on
extracting fixed image features from off-the-shelf vision models and then
fusing them with text using attention mechanisms. This approach has limitations
because these vision models were not designed for complex reasoning tasks and
do not align well with language thoughts. To overcome this limitation, we
introduce a novel approach for multi-modal CoT reasoning that utilizes latent
space learning via diffusion processes to generate effective image features
that align with language thoughts. Our method fuses image features and text
representations at a deep level and improves the complex reasoning ability of
multi-modal CoT. We demonstrate the efficacy of our proposed method on
multi-modal ScienceQA and machine translation benchmarks, achieving
state-of-the-art performance on ScienceQA. Overall, our approach offers a more
robust and effective solution for multi-modal reasoning in language models,
enhancing their ability to tackle complex real-world problems.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08763" title="Abstract">arXiv:2312.08763</a> [<a href="/pdf/2312.08763" title="Download PDF">pdf</a>, <a href="/format/2312.08763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Polar Representation: An Extreme-Adaptive Model for  Long-Term Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Anastasiu%2C+D+C">David C. Anastasiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the hydrology field, time series forecasting is crucial for efficient
water resource management, improving flood and drought control and increasing
the safety and quality of life for the general population. However, predicting
long-term streamflow is a complex task due to the presence of extreme events.
It requires the capture of long-range dependencies and the modeling of rare but
important extreme values. Existing approaches often struggle to tackle these
dual challenges simultaneously. In this paper, we specifically delve into these
issues and propose Distance-weighted Auto-regularized Neural network (DAN), a
novel extreme-adaptive model for long-range forecasting of stremflow enhanced
by polar representation learning. DAN utilizes a distance-weighted multi-loss
mechanism and stackable blocks to dynamically refine indicator sequences from
exogenous data, while also being able to handle uni-variate time-series by
employing Gaussian Mixture probability modeling to improve robustness to severe
events. We also introduce Kruskal-Wallis sampling and gate control vectors to
handle imbalanced extreme data. On four real-life hydrologic streamflow
datasets, we demonstrate that DAN significantly outperforms both
state-of-the-art hydrologic time series prediction methods and general methods
designed for long-term time series prediction.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08764" title="Abstract">arXiv:2312.08764</a> [<a href="/pdf/2312.08764" title="Download PDF">pdf</a>, <a href="/format/2312.08764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CattleEyeView: A Multi-task Top-down View Cattle Dataset for Smarter  Precision Livestock Farming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ong%2C+K+E">Kian Eng Ong</a>, 
<a href="/search/cs?searchtype=author&query=Retta%2C+S">Sivaji Retta</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+R">Ramarajulu Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shawn Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at VCIP 2023. Dataset and code available at <a href="https://github.com/AnimalEyeQ/CattleEyeView">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cattle farming is one of the important and profitable agricultural
industries. Employing intelligent automated precision livestock farming systems
that can count animals, track the animals and their poses will raise
productivity and significantly reduce the heavy burden on its already limited
labor pool. To achieve such intelligent systems, a large cattle video dataset
is essential in developing and training such models. However, many current
animal datasets are tailored to few tasks or other types of animals, which
result in poorer model performance when applied to cattle. Moreover, they do
not provide top-down views of cattle. To address such limitations, we introduce
CattleEyeView dataset, the first top-down view multi-task cattle video dataset
for a variety of inter-related tasks (i.e., counting, detection, pose
estimation, tracking, instance segmentation) that are useful to count the
number of cows and assess their growth and well-being. The dataset contains 753
distinct top-down cow instances in 30,703 frames (14 video sequences). We
perform benchmark experiments to evaluate the model's performance for each
task. The dataset and codes can be found at
https://github.com/AnimalEyeQ/CattleEyeView.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08768" title="Abstract">arXiv:2312.08768</a> [<a href="/pdf/2312.08768" title="Download PDF">pdf</a>, <a href="/format/2312.08768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Conditional Controlling for Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zekai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=lu%2C+q">qinglin lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have exhibited impressive prowess in the text-to-image task.
Recent methods add image-level controls, e.g., edge and depth maps, to
manipulate the generation process together with text prompts to obtain desired
images. This controlling process is globally operated on the entire image,
which limits the flexibility of control regions. In this paper, we introduce a
new simple yet practical task setting: local control. It focuses on controlling
specific local areas according to user-defined image conditions, where the rest
areas are only conditioned by the original text prompt. This manner allows the
users to flexibly control the image generation in a fine-grained way. However,
it is non-trivial to achieve this goal. The naive manner of directly adding
local conditions may lead to the local control dominance problem. To mitigate
this problem, we propose a training-free method that leverages the updates of
noised latents and parameters in the cross-attention map during the denosing
process to promote concept generation in non-control areas. Moreover, we use
feature mask constraints to mitigate the degradation of synthesized image
quality caused by information differences inside and outside the local control
area. Extensive experiments demonstrate that our method can synthesize
high-quality images to the prompt under local control conditions. Code is
available at https://github.com/YibooZhao/Local-Control.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08773" title="Abstract">arXiv:2312.08773</a> [<a href="/pdf/2312.08773" title="Download PDF">pdf</a>, <a href="/format/2312.08773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offshore Wind Plant Instance Segmentation Using Sentinel-1 Time Series,  GIS, and Semantic Segmentation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Carvalho%2C+O+L+F">Osmar Luiz Ferreira de Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=de+Carvalho+Junior%2C+O+A">Osmar Abilio de Carvalho Junior</a>, 
<a href="/search/cs?searchtype=author&query=de+Albuquerque%2C+A+O">Anesmar Olino de Albuquerque</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+D+G+e">Daniel Guerreiro e Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Offshore wind farms represent a renewable energy source with a significant
global growth trend, and their monitoring is strategic for territorial and
environmental planning. This study's primary objective is to detect offshore
wind plants at an instance level using semantic segmentation models and
Sentinel-1 time series. The secondary objectives are: (a) to develop a database
consisting of labeled data and S-1 time series; (b) to compare the performance
of five deep semantic segmentation architectures (U-Net, U-Net++, Feature
Pyramid Network - FPN, DeepLabv3+, and LinkNet); (c) develop a novel
augmentation strategy that shuffles the positions of the images within the time
series; (d) investigate different dimensions of time series intervals (1, 5,
10, and 15 images); and (e) evaluate the semantic-to-instance conversion
procedure. LinkNet was the top-performing model, followed by U-Net++ and U-Net,
while FPN and DeepLabv3+ presented the worst results. The evaluation of
semantic segmentation models reveals enhanced Intersection over Union (IoU)
(25%) and F-score metrics (18%) with the augmentation of time series images.
The study showcases the augmentation strategy's capability to mitigate biases
and precisely detect invariant targets. Furthermore, the conversion from
semantic to instance segmentation demonstrates its efficacy in accurately
isolating individual instances within classified regions - simplifying training
data and reducing annotation effort and complexity.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08774" title="Abstract">arXiv:2312.08774</a> [<a href="/pdf/2312.08774" title="Download PDF">pdf</a>, <a href="/format/2312.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VSFormer: Visual-Spatial Fusion Transformer for Correspondence Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tangfei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Li Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guobao Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Correspondence pruning aims to find correct matches (inliers) from an initial
set of putative correspondences, which is a fundamental task for many
applications. The process of finding is challenging, given the varying inlier
ratios between scenes/image pairs due to significant visual differences.
However, the performance of the existing methods is usually limited by the
problem of lacking visual cues (\eg texture, illumination, structure) of
scenes. In this paper, we propose a Visual-Spatial Fusion Transformer
(VSFormer) to identify inliers and recover camera poses accurately. Firstly, we
obtain highly abstract visual cues of a scene with the cross attention between
local features of two-view images. Then, we model these visual cues and
correspondences by a joint visual-spatial fusion module, simultaneously
embedding visual cues into correspondences for pruning. Additionally, to mine
the consistency of correspondences, we also design a novel module that combines
the KNN-based graph and the transformer, effectively capturing both local and
global contexts. Extensive experiments have demonstrated that the proposed
VSFormer outperforms state-of-the-art methods on outdoor and indoor benchmarks.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08776" title="Abstract">arXiv:2312.08776</a> [<a href="/pdf/2312.08776" title="Download PDF">pdf</a>, <a href="/format/2312.08776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Integer Solution Counts over Linear Arithmetic Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Cunjing Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counting integer solutions of linear constraints has found interesting
applications in various fields. It is equivalent to the problem of counting
lattice points inside a polytope. However, state-of-the-art algorithms for this
problem become too slow for even a modest number of variables. In this paper,
we propose a new framework to approximate the lattice counts inside a polytope
with a new random-walk sampling method. The counts computed by our approach has
been proved approximately bounded by a $(\epsilon, \delta)$-bound. Experiments
on extensive benchmarks show that our algorithm could solve polytopes with
dozens of dimensions, which significantly outperforms state-of-the-art
counters.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08782" title="Abstract">arXiv:2312.08782</a> [<a href="/pdf/2312.08782" title="Download PDF">pdf</a>, <a href="/format/2312.08782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward General-Purpose Robots via Foundation Models: A Survey and  Meta-Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yafei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Quanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vidhi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+J">Jonathan Francis</a>, 
<a href="/search/cs?searchtype=author&query=Patrikar%2C+J">Jay Patrikar</a>, 
<a href="/search/cs?searchtype=author&query=Keetha%2C+N">Nikhil Keetha</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yaqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+Y">Yu-Quan Chong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>, 
<a href="/search/cs?searchtype=author&query=Johnson-Roberson%2C+M">Matthew Johnson-Roberson</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Bisk%2C+Y">Yonatan Bisk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Building general-purpose robots that can operate seamlessly, in any
environment, with any object, and utilizing various skills to complete diverse
tasks has been a long-standing goal in Artificial Intelligence. Unfortunately,
however, most existing robotic systems have been constrained - having been
designed for specific tasks, trained on specific datasets, and deployed within
specific environments. These systems usually require extensively-labeled data,
rely on task-specific models, have numerous generalization issues when deployed
in real-world scenarios, and struggle to remain robust to distribution shifts.
Motivated by the impressive open-set performance and content generation
capabilities of web-scale, large-capacity pre-trained models (i.e., foundation
models) in research fields such as Natural Language Processing (NLP) and
Computer Vision (CV), we devote this survey to exploring (i) how these existing
foundation models from NLP and CV can be applied to the field of robotics, and
also exploring (ii) what a robotics-specific foundation model would look like.
We begin by providing an overview of what constitutes a conventional robotic
system and the fundamental barriers to making it universally applicable. Next,
we establish a taxonomy to discuss current work exploring ways to leverage
existing foundation models for robotics and develop ones catered to robotics.
Finally, we discuss key challenges and promising future directions in using
foundation models for enabling general-purpose robotic systems. We encourage
readers to view our ``living`` GitHub repository of resources, including papers
reviewed in this survey as well as related projects and repositories for
developing foundation models for robotics.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08785" title="Abstract">arXiv:2312.08785</a> [<a href="/pdf/2312.08785" title="Download PDF">pdf</a>, <a href="/format/2312.08785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing the unknown: a survey on Open Set Recognition and tangential  areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barcina-Blanco%2C+M">Marcos Barcina-Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Lobo%2C+J+L">Jesus L. Lobo</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Bringas%2C+P">Pablo Garcia-Bringas</a>, 
<a href="/search/cs?searchtype=author&query=Del+Ser%2C+J">Javier Del Ser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 1 figure, 1 table. Submitted to "Knowledge-Based Systems"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In real-world scenarios classification models are often required to perform
robustly when predicting samples belonging to classes that have not appeared
during its training stage. Open Set Recognition addresses this issue by
devising models capable of detecting unknown classes from samples arriving
during the testing phase, while maintaining a good level of performance in the
classification of samples belonging to known classes. This review
comprehensively overviews the recent literature related to Open Set
Recognition, identifying common practices, limitations, and connections of this
field with other machine learning research areas, such as continual learning,
out-of-distribution detection, novelty detection, and uncertainty estimation.
Our work also uncovers open problems and suggests several research directions
that may motivate and articulate future efforts towards more safe Artificial
Intelligence methods.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08786" title="Abstract">arXiv:2312.08786</a> [<a href="/pdf/2312.08786" title="Download PDF">pdf</a>, <a href="/format/2312.08786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogenous Network Analytics of Small Group Teamwork: Using Multimodal  Data to Uncover Individual Behavioral Engagement Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shihui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lixiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Linxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+R+M">Roberto Martinez Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Individual behavioral engagement is an important indicator of active learning
in collaborative settings, encompassing multidimensional behaviors mediated
through various interaction modes. Little existing work has explored the use of
multimodal process data to understand individual behavioral engagement in
face-to-face collaborative learning settings. In this study we bridge this gap,
for the first time, introducing a heterogeneous tripartite network approach to
analyze the interconnections among multimodal process data in collaborative
learning. Students' behavioral engagement strategies are analyzed based on
their interaction patterns with various spatial locations and verbal
communication types using a heterogeneous tripartite network. The multimodal
collaborative learning process data were collected from 15 teams of four
students. We conducted stochastic blockmodeling on a projection of the
heterogeneous tripartite network to cluster students into groups that shared
similar spatial and oral engagement patterns. We found two distinct clusters of
students, whose characteristic behavioural engagement strategies were
identified by extracting interaction patterns that were statistically
significant relative to a multinomial null model. The two identified clusters
also exhibited a statistically significant difference regarding students'
perceived collaboration satisfaction and teacher-assessed team performance
level. This study advances collaboration analytics methodology and provides new
insights into personalized support in collaborative learning.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08793" title="Abstract">arXiv:2312.08793</a> [<a href="/pdf/2312.08793" title="Download PDF">pdf</a>, <a href="/format/2312.08793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forbidden Facts: An Investigation of Competing Objectives in Llama-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+T">Tony T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miles Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+K">Kaivu Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Shavit%2C+N">Nir Shavit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ATTRIB and SoLaR workshops at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">LLMs often face competing pressures (for example helpfulness vs.
harmlessness). To understand how models resolve such conflicts, we study
Llama-2-chat models on the forbidden fact task. Specifically, we instruct
Llama-2 to truthfully complete a factual recall statement while forbidding it
from saying the correct answer. This often makes the model give incorrect
answers. We decompose Llama-2 into 1000+ components, and rank each one with
respect to how useful it is for forbidding the correct answer. We find that in
aggregate, around 35 components are enough to reliably implement the full
suppression behavior. However, these components are fairly heterogeneous and
many operate using faulty heuristics. We discover that one of these heuristics
can be exploited via a manually designed adversarial attack which we call The
California Attack. Our results highlight some roadblocks standing in the way of
being able to successfully interpret advanced ML systems. Project website
available at https://forbiddenfacts.github.io .
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08798" title="Abstract">arXiv:2312.08798</a> [<a href="/pdf/2312.08798" title="Download PDF">pdf</a>, <a href="/ps/2312.08798" title="Download PostScript">ps</a>, <a href="/format/2312.08798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Participation Incentives in Approval-Based Committee Elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+M">Martin Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chris Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lederer%2C+P">Patrick Lederer</a>, 
<a href="/search/cs?searchtype=author&query=Mehler%2C+C">Clara Mehler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">In approval-based committee (ABC) voting, the goal is to choose a subset of
predefined size of the candidates based on the voters' approval preferences
over the candidates. While this problem has attracted significant attention in
recent years, the incentives for voters to participate in an election for a
given ABC voting rule have been neglected so far. This paper is thus the first
to explicitly study this property, typically called participation, for ABC
voting rules. In particular, we show that all ABC scoring rules even satisfy
group participation, whereas most sequential rules severely fail participation.
We furthermore explore several escape routes to the impossibility for
sequential ABC voting rules: we prove for many sequential rules that (i) they
satisfy participation on laminar profiles, (ii) voters who approve none of the
elected candidates cannot benefit by abstaining, and (iii) it is NP-hard for a
voter to decide whether she benefits from abstaining.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08799" title="Abstract">arXiv:2312.08799</a> [<a href="/pdf/2312.08799" title="Download PDF">pdf</a>, <a href="/ps/2312.08799" title="Download PostScript">ps</a>, <a href="/format/2312.08799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Characterizations of Approval-based Committee Scoring Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+C">Chris Dang</a>, 
<a href="/search/cs?searchtype=author&query=Lederer%2C+P">Patrick Lederer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">In approval-based committee (ABC) elections, the goal is to select a
fixed-size subset of the candidates, a so-called committee, based on the
voters' approval ballots over the candidates. One of the most popular classes
of ABC voting rules are ABC scoring rules, which have recently been
characterized by Lackner and Skowron (2021). However, this characterization
relies on a model where the output is a ranking of committees instead of a set
of winning committees and no full characterization of ABC scoring rules exists
in the latter standard setting. We address this issue by characterizing two
important subclasses of ABC scoring rules in the standard ABC election model,
thereby both extending the result of Lackner and Skowron (2021) to the standard
setting and refining it to subclasses. In more detail, by relying on a
consistency axiom for variable electorates, we characterize (i) the prominent
class of Thiele rules and (ii) a new class of ABC voting rules called ballot
size weighted approval voting. Based on these theorems, we also infer
characterizations of three well-known ABC voting rules, namely multi-winner
approval voting, proportional approval voting, and satisfaction approval
voting.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08800" title="Abstract">arXiv:2312.08800</a> [<a href="/pdf/2312.08800" title="Download PDF">pdf</a>, <a href="/format/2312.08800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models for Health-related Queries with  Presuppositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaur%2C+N">Navreet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M">Monojit Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Pruthi%2C+D">Danish Pruthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">As corporations rush to integrate large language models (LLMs) to their
search offerings, it is critical that they provide factually accurate
information that is robust to any presuppositions that a user may express. In
this work, we introduce UPHILL, a dataset consisting of health-related queries
with varying degrees of presuppositions. Using UPHILL, we evaluate the factual
accuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find
that while model responses rarely disagree with true health claims (posed as
questions), they often fail to challenge false claims: responses from
InstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.
As we increase the extent of presupposition in input queries, the responses
from InstructGPT and ChatGPT agree with the claim considerably more often,
regardless of its veracity. Responses from BingChat, which rely on retrieved
webpages, are not as susceptible. Given the moderate factual accuracy, and the
inability of models to consistently correct false assumptions, our work calls
for a careful assessment of current LLMs for use in high-stakes scenarios.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08801" title="Abstract">arXiv:2312.08801</a> [<a href="/pdf/2312.08801" title="Download PDF">pdf</a>, <a href="/format/2312.08801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Process Planning Based on a Semantic Capability Model and SMT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6cher%2C+A">Aljosha K&#xf6;cher</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+L+M+V">Luis Miguel Vieira da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Fay%2C+A">Alexander Fay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In research of manufacturing systems and autonomous robots, the term
capability is used for a machine-interpretable specification of a system
function. Approaches in this research area develop information models that
capture all information relevant to interpret the requirements, effects and
behavior of functions. These approaches are intended to overcome the
heterogeneity resulting from the various types of processes and from the large
number of different vendors. However, these models and associated methods do
not offer solutions for automated process planning, i.e. finding a sequence of
individual capabilities required to manufacture a certain product or to
accomplish a mission using autonomous robots. Instead, this is a typical task
for AI planning approaches, which unfortunately require a high effort to create
the respective planning problem descriptions. In this paper, we present an
approach that combines these two topics: Starting from a semantic capability
model, an AI planning problem is automatically generated. The planning problem
is encoded using Satisfiability Modulo Theories and uses an existing solver to
find valid capability sequences including required parameter values. The
approach also offers possibilities to integrate existing human expertise and to
provide explanations for human operators in order to help understand planning
decisions.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08803" title="Abstract">arXiv:2312.08803</a> [<a href="/pdf/2312.08803" title="Download PDF">pdf</a>, <a href="/format/2312.08803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering with Few Disks to Minimize the Sum of Radii
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrahamsen%2C+M">Mikkel Abrahamsen</a>, 
<a href="/search/cs?searchtype=author&query=de+Berg%2C+S">Sarita de Berg</a>, 
<a href="/search/cs?searchtype=author&query=Meijer%2C+L">Lucas Meijer</a>, 
<a href="/search/cs?searchtype=author&query=Nusser%2C+A">Andr&#xe9; Nusser</a>, 
<a href="/search/cs?searchtype=author&query=Theocharous%2C+L">Leonidas Theocharous</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Given a set of $n$ points in the Euclidean plane, the $k$-MinSumRadius
problem asks to cover this point set using $k$ disks with the objective of
minimizing the sum of the radii of the disks. After a long line of research on
related problems, it was finally discovered that this problem admits a
polynomial time algorithm [GKKPV~'12]; however, the running time of this
algorithm is $O(n^{881})$, and its relevance is thereby mostly of theoretical
nature. A practically and structurally interesting special case of the
$k$-MinSumRadius problem is that of small $k$. For the $2$-MinSumRadius
problem, a near-quadratic time algorithm with expected running time $O(n^2
\log^2 n \log^2 \log n)$ was given over 30 years ago [Eppstein~'92].
<br />We present the first improvement of this result, namely, a near-linear time
algorithm to compute the $2$-MinSumRadius that runs in expected $O(n \log^2 n
\log^2 \log n)$ time. We generalize this result to any constant dimension $d$,
for which we give an $O(n^{2-1/(\lceil d/2\rceil + 1) + \varepsilon})$ time
algorithm. Additionally, we give a near-quadratic time algorithm for
$3$-MinSumRadius in the plane that runs in expected $O(n^2 \log^2 n \log^2 \log
n)$ time. All of these algorithms rely on insights that uncover a surprisingly
simple structure of optimal solutions: we can specify a linear number of lines
out of which one separates one of the clusters from the remaining clusters in
an optimal solution.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08805" title="Abstract">arXiv:2312.08805</a> [<a href="/pdf/2312.08805" title="Download PDF">pdf</a>, <a href="/format/2312.08805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zoom in on the Plant: Fine-grained Analysis of Leaf, Stem and Vein  Instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCldenring%2C+R">Ronja G&#xfc;ldenring</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+R+E">Rasmus Eckholdt Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Nalpantidis%2C+L">Lazaros Nalpantidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robot perception is far from what humans are capable of. Humans do not only
have a complex semantic scene understanding but also extract fine-grained
intra-object properties for the salient ones. When humans look at plants, they
naturally perceive the plant architecture with its individual leaves and
branching system. In this work, we want to advance the granularity in plant
understanding for agricultural precision robots. We develop a model to extract
fine-grained phenotypic information, such as leaf-, stem-, and vein instances.
The underlying dataset RumexLeaves is made publicly available and is the first
of its kind with keypoint-guided polyline annotations leading along the line
from the lowest stem point along the leaf basal to the leaf apex. Furthermore,
we introduce an adapted metric POKS complying with the concept of
keypoint-guided polylines. In our experimental evaluation, we provide baseline
results for our newly introduced dataset while showcasing the benefits of POKS
over OKS.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08806" title="Abstract">arXiv:2312.08806</a> [<a href="/pdf/2312.08806" title="Download PDF">pdf</a>, <a href="/format/2312.08806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Google Tag Manager: Hidden Data Leaks and its Potential Violations under  EU Data Protection Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mertens%2C+G">Gilles Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Bielova%2C+N">Nataliia Bielova</a>, 
<a href="/search/cs?searchtype=author&query=Roca%2C+V">Vincent Roca</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+C">Cristiana Santos</a>, 
<a href="/search/cs?searchtype=author&query=Toth%2C+M">Michael Toth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Tag Management Systems were developed in order to support website publishers
in installing multiple third-party JavaScript scripts (Tags) on their websites.
In 2012, Google developed its own TMS called "Google Tag Manager" (GTM) that is
currently present on 28 million live websites. In 2020, a new "Server-side" GTM
was introduced, allowing publishers to include Tags directly on the server.
However, neither version of GTM has yet been thoroughly evaluated by the
academic research community. In this work, we study, for the first time, the
two versions of the Google Tag Management (GTM) architectures: Client- and
Server-side GTM. By analyzing these systems with 78 Client-side Tags, 8
Server-side Tags and two Consent Management Platforms (CMPs) from the inside,
we discover multiple hidden data leaks, Tags bypassing GTM permission system to
inject scripts, and consent enabled by default. With a legal expert, we perform
an in-depth legal analysis of GTM and its actors to identify potential legal
violations and their liabilities. We provide recommendations and propose
numerous improvements for GTM to facilitate legal compliance.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08810" title="Abstract">arXiv:2312.08810</a> [<a href="/pdf/2312.08810" title="Download PDF">pdf</a>, <a href="/ps/2312.08810" title="Download PostScript">ps</a>, <a href="/format/2312.08810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Cyber-Attack Detection Model for Smart Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mojtaba Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Aflaki%2C+A">Arshia Aflaki</a>, 
<a href="/search/cs?searchtype=author&query=Kavousifard%2C+A">Abdollah Kavousifard</a>, 
<a href="/search/cs?searchtype=author&query=Gitizadeh%2C+M">Mohsen Gitizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, a novel artificial intelligence-based cyber-attack detection
model for smart grids is developed to stop data integrity cyber-attacks (DIAs)
on the received load data by supervisory control and data acquisition (SCADA).
In the proposed model, first the load data is forecasted using a regression
model and after processing stage, the processed data is clustered using the
unsupervised learning method. In this work, in order to achieve the best
performance, three load forecasting methods (i.e. extra tree regression (ETR),
long short-term memory (LSTM) and bidirectional long short-term memory
(BiLSTM)) are utilized as regression models and their performance is compared.
For clustering and outlying detection, the covariance elliptic envelope (EE) is
employed as an unsupervised learning method. To examine the proposed model, the
hourly load data of the power company of the city of Johor in Malaysia is
employed and Two common DIAs, which are DIAs targeting economic loss and DIAs
targeting blackouts, are used to evaluate the accuracy of detection methods in
several scenarios. The simulation results show that the proposed EE-BiLSTM
method can perform more robust and accurate compared to the other two methods.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08815" title="Abstract">arXiv:2312.08815</a> [<a href="/pdf/2312.08815" title="Download PDF">pdf</a>, <a href="/ps/2312.08815" title="Download PostScript">ps</a>, <a href="/format/2312.08815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implement services for business scenarios by combining basic emulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.16146">arXiv:2311.16146</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This article mainly introduces how to use various basic emulators to form a
combined emulator in the Jiutian Intelligence Network Simulation Platform to
realize simulation service functions in different business scenarios. Among
them, the combined emulator is included. The business scenarios include
different practical applications such as multi-objective antenna optimization,
high traffic of business, CSI (channel state information) compression feedback,
etc.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08818" title="Abstract">arXiv:2312.08818</a> [<a href="/pdf/2312.08818" title="Download PDF">pdf</a>, <a href="/ps/2312.08818" title="Download PostScript">ps</a>, <a href="/format/2312.08818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyber-Physical Architecture for Microgrids based on Deep learning and  LORA Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mojtaba Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=KavousiFard%2C+A">Abdollah KavousiFard</a>, 
<a href="/search/cs?searchtype=author&query=Dabbaghjamanesh%2C+M">Mortza Dabbaghjamanesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper proposes a cyber-physical architecture for the secured social
operation of isolated hybrid microgrids (HMGs). On the physical side of the
proposed architecture, an optimal scheduling scheme considering various
renewable energy sources (RESs) and fossil fuel-based distributed generation
units (DGs) is proposed. Regarding the cyber layer of MGs, a wireless
architecture based on low range wide area (LORA) technology is introduced for
advanced metering infrastructure (AMI) in smart electricity grids. In the
proposed architecture, the LORA data frame is described in detail and designed
for the application of smart meters considering DGs and ac-dc converters.
Additionally, since the cyber layer of smart grids is highly vulnerable to
cyber-attacks, t1his paper proposes a deep-learning-based cyber-attack
detection model (CADM) based on bidirectional long short-term memory (BLSTM)
and sequential hypothesis testing (SHT) to detect false data injection attacks
(FDIA) on the smart meters within AMI. The performance of the proposed energy
management architecture is evaluated using the IEEE 33-bus test system. In
order to investigate the effect of FDIA on the isolated HMGs and highlight the
interactions between the cyber layer and physical layer, an FDIA is launched
against the test system. The results showed that a successful attack can highly
damage the system and cause widespread load shedding. Also, the performance of
the proposed CADM is examined using a real-world dataset. Results prove the
effectiveness of the proposed CADM in detecting the attacks using only two
samples.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08820" title="Abstract">arXiv:2312.08820</a> [<a href="/pdf/2312.08820" title="Download PDF">pdf</a>, <a href="/format/2312.08820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task  Planning for Humanoid Assistive Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemken%2C+N">Niklas Hemken</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+F">Florian Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Peller-Konrad%2C+F">Fabian Peller-Konrad</a>, 
<a href="/search/cs?searchtype=author&query=Kartmann%2C+R">Rainer Kartmann</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>, 
<a href="/search/cs?searchtype=author&query=Hartenstein%2C+H">Hannes Hartenstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, follow-up extended version of our SACMAT 2023 poster abstract: "Poster: How to Raise a Robot - Beyond Access Control Constraints in Assistive Humanoid Robots" <a href="https://dl.acm.org/doi/abs/10.1145/3589608.3595078">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Humanoid robots will be able to assist humans in their daily life, in
particular due to their versatile action capabilities. However, while these
robots need a certain degree of autonomy to learn and explore, they also should
respect various constraints, for access control and beyond. We explore the
novel field of incorporating privacy, security, and access control constraints
with robot task planning approaches. We report preliminary results on the
classical symbolic approach, deep-learned neural networks, and modern ideas
using large language models as knowledge base. From analyzing their trade-offs,
we conclude that a hybrid approach is necessary, and thereby present a new use
case for the emerging field of neuro-symbolic artificial intelligence.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08822" title="Abstract">arXiv:2312.08822</a> [<a href="/pdf/2312.08822" title="Download PDF">pdf</a>, <a href="/format/2312.08822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning and Rendering: Towards End-to-End Product Poster Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Honghe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jingjing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenglu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">End-to-end product poster generation significantly optimizes design
efficiency and reduces production costs. Prevailing methods predominantly rely
on image-inpainting methods to generate clean background images for given
products. Subsequently, poster layout generation methods are employed to
produce corresponding layout results. However, the background images may not be
suitable for accommodating textual content due to their complexity, and the
fixed location of products limits the diversity of layout results. To alleviate
these issues, we propose a novel product poster generation framework named
P\&amp;R. The P\&amp;R draws inspiration from the workflow of designers in creating
posters, which consists of two stages: Planning and Rendering. At the planning
stage, we propose a PlanNet to generate the layout of the product and other
visual components considering both the appearance features of the product and
semantic features of the text, which improves the diversity and rationality of
the layouts. At the rendering stage, we propose a RenderNet to generate the
background for the product while considering the generated layout, where a
spatial fusion module is introduced to fuse the layout of different visual
components. To foster the advancement of this field, we propose the first
end-to-end product poster generation dataset PPG30k, comprising 30k exquisite
product poster images along with comprehensive image and text annotations. Our
method outperforms the state-of-the-art product poster generation methods on
PPG30k. The PPG30k will be released soon.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08825" title="Abstract">arXiv:2312.08825</a> [<a href="/pdf/2312.08825" title="Download PDF">pdf</a>, <a href="/format/2312.08825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Diffusion from Self-Supervised Diffusion Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunlu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Caron%2C+M">Mathilde Caron</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Ommer%2C+B">Bjorn Ommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work In Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Guidance serves as a key concept in diffusion models, yet its effectiveness
is often limited by the need for extra data annotation or classifier
pretraining. That is why guidance was harnessed from self-supervised learning
backbones, like DINO. However, recent studies have revealed that the feature
representation derived from diffusion model itself is discriminative for
numerous downstream tasks as well, which prompts us to propose a framework to
extract guidance from, and specifically for, diffusion models. Our research has
yielded several significant contributions. Firstly, the guidance signals from
diffusion models are on par with those from class-conditioned diffusion models.
Secondly, feature regularization, when based on the Sinkhorn-Knopp algorithm,
can further enhance feature discriminability in comparison to unconditional
diffusion models. Thirdly, we have constructed an online training approach that
can concurrently derive guidance from diffusion models for diffusion models.
Lastly, we have extended the application of diffusion models along the constant
velocity path of ODE to achieve a more favorable balance between sampling steps
and fidelity. The performance of our methods has been outstanding,
outperforming related baseline comparisons in large-resolution datasets, such
as ImageNet256, ImageNet256-100 and LSUN-Churches. Our code will be released.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08826" title="Abstract">arXiv:2312.08826</a> [<a href="/pdf/2312.08826" title="Download PDF">pdf</a>, <a href="/format/2312.08826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A manual categorization of new quality issues on automatically-generated  tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galindo-Gutierrez%2C+G">Geraldine Galindo-Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Maxilimiliano%2C+N">Narea Maxilimiliano</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+B+A">Blanco Alison Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Anquetil%2C+N">Nicolas Anquetil</a>, 
<a href="/search/cs?searchtype=author&query=Sandoval%2C+A+J+P">Alcocer Juan Pablo Sandoval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Diverse studies have analyzed the quality of automatically generated test
cases by using test smells as the main quality attribute. But recent work
reported that generated tests may suffer a number of quality issues not
necessarily considered in previous studies. Little is known about these issues
and their frequency within generated tests. In this paper, we report on a
manual analysis of an external dataset consisting of 2,340 automatically
generated tests. This analysis aimed at detecting new quality issues, not
covered by past recognized test smells. We use thematic analysis to group and
categorize the new quality issues found. As a result, we propose a taxonomy of
13 new quality issues grouped in four categories. We also report on the
frequency of these new quality issues within the dataset and present eight
recommendations that test generators may consider to improve the quality and
usefulness of the automatically generated tests.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08827" title="Abstract">arXiv:2312.08827</a> [<a href="/pdf/2312.08827" title="Download PDF">pdf</a>, <a href="/ps/2312.08827" title="Download PostScript">ps</a>, <a href="/format/2312.08827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence and Human Geography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages; chapter in the Encyclopedia of Human Geography
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper examines the recent advances and applications of AI in human
geography especially the use of machine (deep) learning, including place
representation and modeling, spatial analysis and predictive mapping, and urban
planning and design. AI technologies have enabled deeper insights into complex
human-environment interactions, contributing to more effective scientific
exploration, understanding of social dynamics, and spatial decision-making.
Furthermore, human geography offers crucial contributions to AI, particularly
in context-aware model development, human-centered design, biases and ethical
considerations, and data privacy. The synergy beween AI and human geography is
essential for addressing global challenges like disaster resilience, poverty,
and equitable resource access. This interdisciplinary collaboration between AI
and geography will help advance the development of GeoAI and promise a better
and sustainable world for all.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08837" title="Abstract">arXiv:2312.08837</a> [<a href="/pdf/2312.08837" title="Download PDF">pdf</a>, <a href="/format/2312.08837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Safety Constraints From Demonstration Using One-Class Decision  Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baert%2C+M">Mattijs Baert</a>, 
<a href="/search/cs?searchtype=author&query=Leroux%2C+S">Sam Leroux</a>, 
<a href="/search/cs?searchtype=author&query=Simoens%2C+P">Pieter Simoens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for AAAI 2024 Workshop on Neuro-Symbolic Learning and Reasoning in the Era of Large Language Models (NucLeaR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The alignment of autonomous agents with human values is a pivotal challenge
when deploying these agents within physical environments, where safety is an
important concern. However, defining the agent's objective as a reward and/or
cost function is inherently complex and prone to human errors. In response to
this challenge, we present a novel approach that leverages one-class decision
trees to facilitate learning from expert demonstrations. These decision trees
provide a foundation for representing a set of constraints pertinent to the
given environment as a logical formula in disjunctive normal form. The learned
constraints are subsequently employed within an oracle constrained
reinforcement learning framework, enabling the acquisition of a safe policy. In
contrast to other methods, our approach offers an interpretable representation
of the constraints, a vital feature in safety-critical environments. To
validate the effectiveness of our proposed method, we conduct experiments in
synthetic benchmark domains and a realistic driving environment.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08839" title="Abstract">arXiv:2312.08839</a> [<a href="/pdf/2312.08839" title="Download PDF">pdf</a>, <a href="/format/2312.08839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration of visual prompt in Grounded pre-trained open-set detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Weizhong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengdi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Li Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaozheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text prompts are crucial for generalizing pre-trained open-set object
detection models to new categories. However, current methods for text prompts
are limited as they require manual feedback when generalizing to new
categories, which restricts their ability to model complex scenes, often
leading to incorrect detection results. To address this limitation, we propose
a novel visual prompt method that learns new category knowledge from a few
labeled images, which generalizes the pre-trained detection model to the new
category. To allow visual prompts to represent new categories adequately, we
propose a statistical-based prompt construction module that is not limited by
predefined vocabulary lengths, thus allowing more vectors to be used when
representing categories. We further utilize the category dictionaries in the
pre-training dataset to design task-specific similarity dictionaries, which
make visual prompts more discriminative. We evaluate the method on the ODinW
dataset and show that it outperforms existing prompt learning methods and
performs more consistently in combinatorial inference.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08843" title="Abstract">arXiv:2312.08843</a> [<a href="/pdf/2312.08843" title="Download PDF">pdf</a>, <a href="/format/2312.08843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-C: Unveiling the Generative Challenges of Diffusion Models  through Corrupted Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Keywoong Bae</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wookey Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In our contemporary academic inquiry, we present "Diffusion-C," a
foundational methodology to analyze the generative restrictions of Diffusion
Models, particularly those akin to GANs, DDPM, and DDIM. By employing input
visual data that has been subjected to a myriad of corruption modalities and
intensities, we elucidate the performance characteristics of those Diffusion
Models. The noise component takes center stage in our analysis, hypothesized to
be a pivotal element influencing the mechanics of deep learning systems. In our
rigorous expedition utilizing Diffusion-C, we have discerned the following
critical observations: (I) Within the milieu of generative models under the
Diffusion taxonomy, DDPM emerges as a paragon, consistently exhibiting superior
performance metrics. (II) Within the vast spectrum of corruption frameworks,
the fog and fractal corruptions notably undermine the functional robustness of
both DDPM and DDIM. (III) The vulnerability of Diffusion Models to these
particular corruptions is significantly influenced by topological and
statistical similarities, particularly concerning the alignment between mean
and variance. This scholarly work highlights Diffusion-C's core understandings
regarding the impacts of various corruptions, setting the stage for future
research endeavors in the realm of generative models.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08846" title="Abstract">arXiv:2312.08846</a> [<a href="/pdf/2312.08846" title="Download PDF">pdf</a>, <a href="/format/2312.08846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiMix: Text-aware Image Mixing for Effective Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaoya Jiang</a>, 
<a href="/search/cs?searchtype=author&query=ye%2C+W">Wei ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Self-supervised Multi-modal Contrastive Learning (SMCL) remarkably advances
modern Vision-Language Pre-training (VLP) models by aligning visual and
linguistic modalities. Due to noises in web-harvested text-image pairs,
however, scaling up training data volume in SMCL presents considerable
obstacles in terms of computational cost and data inefficiency. To improve data
efficiency in VLP, we propose Text-aware Image Mixing (TiMix), which integrates
mix-based data augmentation techniques into SMCL, yielding significant
performance improvements without significantly increasing computational
overhead. We provide a theoretical analysis of TiMixfrom a mutual information
(MI) perspective, showing that mixed data samples for cross-modal contrastive
learning implicitly serve as a regularizer for the contrastive loss. The
experimental results demonstrate that TiMix exhibits a comparable performance
on downstream tasks, even with a reduced amount of training data and shorter
training time, when benchmarked against existing methods. This work empirically
and theoretically demonstrates the potential of data mixing for data-efficient
and computationally viable VLP, benefiting broader VLP model adoption in
practical scenarios.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08847" title="Abstract">arXiv:2312.08847</a> [<a href="/pdf/2312.08847" title="Download PDF">pdf</a>, <a href="/format/2312.08847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Driven Modulation of Neural Networks with Attention Mechanism  for Next Activity Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadello%2C+I">Ivan Donadello</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Jonghyeon Ko</a>, 
<a href="/search/cs?searchtype=author&query=Maggi%2C+F+M">Fabrizio Maria Maggi</a>, 
<a href="/search/cs?searchtype=author&query=Mendling%2C+J">Jan Mendling</a>, 
<a href="/search/cs?searchtype=author&query=Riva%2C+F">Francesco Riva</a>, 
<a href="/search/cs?searchtype=author&query=Weidlich%2C+M">Matthias Weidlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Predictive Process Monitoring (PPM) aims at leveraging historic process
execution data to predict how ongoing executions will continue up to their
completion. In recent years, PPM techniques for the prediction of the next
activities have matured significantly, mainly thanks to the use of Neural
Networks (NNs) as a predictor. While their performance is difficult to beat in
the general case, there are specific situations where background process
knowledge can be helpful. Such knowledge can be leveraged for improving the
quality of predictions for exceptional process executions or when the process
changes due to a concept drift. In this paper, we present a Symbolic[Neuro]
system that leverages background knowledge expressed in terms of a procedural
process model to offset the under-sampling in the training data. More
specifically, we make predictions using NNs with attention mechanism, an
emerging technology in the NN field. The system has been tested on several
real-life logs showing an improvement in the performance of the prediction
task.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08850" title="Abstract">arXiv:2312.08850</a> [<a href="/pdf/2312.08850" title="Download PDF">pdf</a>, <a href="/format/2312.08850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hourglass-AVSR: Down-Up Sampling-based Computational Efficiency Model  for Audio-Visual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently audio-visual speech recognition (AVSR), which better leverages video
modality as additional information to extend automatic speech recognition
(ASR), has shown promising results in complex acoustic environments. However,
there is still substantial space to improve as complex computation of visual
modules and ineffective fusion of audio-visual modalities. To eliminate these
drawbacks, we propose a down-up sampling-based AVSR model (Hourglass-AVSR) to
enjoy high efficiency and performance, whose time length is scaled during the
intermediate processing, resembling an hourglass. Firstly, we propose a context
and residual aware video upsampling approach to improve the recognition
performance, which utilizes contextual information from visual representations
and captures residual information between adjacent video frames. Secondly, we
introduce a visual-audio alignment approach during the upsampling by explicitly
incorporating boundary constraint loss. Besides, we propose a cross-layer
attention fusion to capture the modality dependencies within each visual
encoder layer. Experiments conducted on the MISP-AVSR dataset reveal that our
proposed Hourglass-AVSR model outperforms ASR model by 12.9% and 20.8% relative
concatenated minimum permutation character error rate (cpCER) reduction on
far-field and middle-field test sets, respectively. Moreover, compared to other
state-of-the-art AVSR models, our model exhibits the highest improvement in
cpCER for the visual module. Furthermore, on the benefit of our down-up
sampling approach, Hourglass-AVSR model reduces 54.2% overall computation costs
with minor performance degradation.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08851" title="Abstract">arXiv:2312.08851</a> [<a href="/pdf/2312.08851" title="Download PDF">pdf</a>, <a href="/format/2312.08851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achelous++: Power-Oriented Water-Surface Panoptic Perception Framework  on Edge Devices based on Vision-Radar Fusion and Pruning of Heterogeneous  Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Runwei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haocheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanliang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+K+L">Ka Lok Man</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaohui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Limin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jeremy Smith</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E+G">Eng Gee Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yutao Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE); Robotics (cs.RO)

</div>
<p class="mathjax">Urban water-surface robust perception serves as the foundation for
intelligent monitoring of aquatic environments and the autonomous navigation
and operation of unmanned vessels, especially in the context of waterway
safety. It is worth noting that current multi-sensor fusion and multi-task
learning models consume substantial power and heavily rely on high-power GPUs
for inference. This contributes to increased carbon emissions, a concern that
runs counter to the prevailing emphasis on environmental preservation and the
pursuit of sustainable, low-carbon urban environments. In light of these
concerns, this paper concentrates on low-power, lightweight, multi-task
panoptic perception through the fusion of visual and 4D radar data, which is
seen as a promising low-cost perception method. We propose a framework named
Achelous++ that facilitates the development and comprehensive evaluation of
multi-task water-surface panoptic perception models. Achelous++ can
simultaneously execute five perception tasks with high speed and low power
consumption, including object detection, object semantic segmentation,
drivable-area segmentation, waterline segmentation, and radar point cloud
semantic segmentation. Furthermore, to meet the demand for developers to
customize models for real-time inference on low-performance devices, a novel
multi-modal pruning strategy known as Heterogeneous-Aware SynFlow (HA-SynFlow)
is proposed. Besides, Achelous++ also supports random pruning at initialization
with different layer-wise sparsity, such as Uniform and Erdos-Renyi-Kernel
(ERK). Overall, our Achelous++ framework achieves state-of-the-art performance
on the WaterScenes benchmark, excelling in both accuracy and power efficiency
compared to other single-task and multi-task models. We release and maintain
the code at https://github.com/GuanRunwei/Achelous.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08852" title="Abstract">arXiv:2312.08852</a> [<a href="/pdf/2312.08852" title="Download PDF">pdf</a>, <a href="/format/2312.08852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ERASE: Error-Resilient Representation Learning on Graphs for Label Noise  Tolerance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling-Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanshuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taohua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Liangcai Su</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zeyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 14 figures, 15 tables and a project page at <a href="https://eraseai.github.io/ERASE-page">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning has achieved remarkable success in graph-related tasks, yet
this accomplishment heavily relies on large-scale high-quality annotated
datasets. However, acquiring such datasets can be cost-prohibitive, leading to
the practical use of labels obtained from economically efficient sources such
as web searches and user tags. Unfortunately, these labels often come with
noise, compromising the generalization performance of deep networks. To tackle
this challenge and enhance the robustness of deep learning models against label
noise in graph-based tasks, we propose a method called ERASE (Error-Resilient
representation learning on graphs for lAbel noiSe tolerancE). The core idea of
ERASE is to learn representations with error tolerance by maximizing coding
rate reduction. Particularly, we introduce a decoupled label propagation method
for learning representations. Before training, noisy labels are pre-corrected
through structural denoising. During training, ERASE combines prototype
pseudo-labels with propagated denoised labels and updates representations with
error resilience, which significantly improves the generalization performance
in node classification. The proposed method allows us to more effectively
withstand errors caused by mislabeled nodes, thereby strengthening the
robustness of deep networks in handling noisy graph data. Extensive
experimental results show that our method can outperform multiple baselines
with clear margins in broad noise levels and enjoy great scalability. Codes are
released at https://github.com/eraseai/erase.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08853" title="Abstract">arXiv:2312.08853</a> [<a href="/pdf/2312.08853" title="Download PDF">pdf</a>, <a href="/format/2312.08853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Image Restoration via Simultaneous Feature and Image Guided  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jie Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Hui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Guided image restoration (GIR), such as guided depth map super-resolution and
pan-sharpening, aims to enhance a target image using guidance information from
another image of the same scene. Currently, joint image filtering-inspired deep
learning-based methods represent the state-of-the-art for GIR tasks. Those
methods either deal with GIR in an end-to-end way by elaborately designing
filtering-oriented deep neural network (DNN) modules, focusing on the
feature-level fusion of inputs; or explicitly making use of the traditional
joint filtering mechanism by parameterizing filtering coefficients with DNNs,
working on image-level fusion. The former ones are good at recovering
contextual information but tend to lose fine-grained details, while the latter
ones can better retain textual information but might lead to content
distortions. In this work, to inherit the advantages of both methodologies
while mitigating their limitations, we proposed a Simultaneous Feature and
Image Guided Fusion (SFIGF) network, that simultaneously considers feature and
image-level guided fusion following the guided filter (GF) mechanism. In the
feature domain, we connect the cross-attention (CA) with GF, and propose a
GF-inspired CA module for better feature-level fusion; in the image domain, we
fully explore the GF mechanism and design GF-like structure for better
image-level fusion. Since guided fusion is implemented in both feature and
image domains, the proposed SFIGF is expected to faithfully reconstruct both
contextual and textual information from sources and thus lead to better GIR
results. We apply SFIGF to 4 typical GIR tasks, and experimental results on
these tasks demonstrate its effectiveness and general availability.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08855" title="Abstract">arXiv:2312.08855</a> [<a href="/pdf/2312.08855" title="Download PDF">pdf</a>, <a href="/format/2312.08855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A rational Krylov subspace based projection method for solving  large-scale algebraic Riccati equations via low-rank approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertram%2C+C">Christian Bertram</a>, 
<a href="/search/math?searchtype=author&query=Fa%C3%9Fbender%2C+H">Heike Fa&#xdf;bender</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A class of (block) rational Krylov subspace based projection method for
solving large-scale continuous-time algebraic Riccati equation (CARE) $0 =
\mathcal{R}(X) := A^HX + XA + C^HC - XBB^HX$ with a large, sparse $A$ and $B$
and $C$ of full low rank is proposed. The CARE is projected onto a block
rational Krylov subspace $\mathcal{K}_j$ spanned by blocks of the form $(A^H+
s_kI)C^H$ for some shifts $s_k, k = 1, \ldots, j.$ The considered projections
do not need to be orthogonal and are built from the matrices appearing in the
block rational Arnoldi decomposition associated to $\mathcal{K}_j.$ The
resulting projected Riccati equation is solved for the small square Hermitian
$Y_j.$ Then the Hermitian low-rank approximation $X_j = Z_jY_jZ_j^H$ to $X$ is
set up where the columns of $Z_j$ span $\mathcal{K}_j.$ The residual norm
$\|R(X_j )\|_F$ can be computed efficiently via the norm of a readily available
$2p \times 2p$ matrix. We suggest to reduce the rank of the approximate
solution $X_j$ even further by truncating small eigenvalues from $X_j.$ This
truncated approximate solution can be interpreted as the solution of the
Riccati residual projected to a subspace of $\mathcal{K}_j.$ This gives us a
way to efficiently evaluate the norm of the resulting residual. Numerical
examples are presented.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08859" title="Abstract">arXiv:2312.08859</a> [<a href="/pdf/2312.08859" title="Download PDF">pdf</a>, <a href="/format/2312.08859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BVI-Artefact: An Artefact Detection Benchmark Dataset for Streamed  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages and 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Professionally generated content (PGC) streamed online can contain visual
artefacts that degrade the quality of user experience. These artefacts arise
from different stages of the streaming pipeline, including acquisition,
post-production, compression, and transmission. To better guide streaming
experience enhancement, it is important to detect specific artefacts at the
user end in the absence of a pristine reference. In this work, we address the
lack of a comprehensive benchmark for artefact detection within streamed PGC,
via the creation and validation of a large database, BVI-Artefact. Considering
the ten most relevant artefact types encountered in video streaming, we
collected and generated 480 video sequences, each containing various artefacts
with associated binary artefact labels. Based on this new database, existing
artefact detection methods are benchmarked, with results showing the
challenging nature of this tasks and indicating the requirement of more
reliable artefact detection methods. To facilitate further research in this
area, we have made BVI-Artifact publicly available at
https://chenfeng-bristol.github.io/BVI-Artefact/
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08862" title="Abstract">arXiv:2312.08862</a> [<a href="/pdf/2312.08862" title="Download PDF">pdf</a>, <a href="/format/2312.08862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-Division Duplexing: A Novel Full-Duplex Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+K">Kai Niu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zijian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jincheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Z">Zhongwei Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, submitted to IEEE Wireless Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In-band full-duplex (IBFD) is a theoretically effective solution to increase
the overall throughput for the future wireless communications system by
enabling transmission and reception over the same time-frequency resources.
However, reliable source reconstruction remains a great challenge in the
practical IBFD systems due to the non-ideal elimination of the
self-interference and the inherent limitations of the separate source and
channel coding methods. On the other hand, artificial intelligence-enabled
semantic communication can provide a viable direction for the optimization of
the IBFD system. This article introduces a novel IBFD paradigm with the
guidance of semantic communication called semantics-division duplexing (SDD).
It utilizes semantic domain processing to further suppress self-interference,
distinguish the expected semantic information, and recover the desired sources.
Further integration of the digital and semantic domain processing can be
implemented so as to achieve intelligent and concise communications. We present
the advantages of the SDD paradigm with theoretical explanations and provide
some visualized results to verify its effectiveness.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08863" title="Abstract">arXiv:2312.08863</a> [<a href="/pdf/2312.08863" title="Download PDF">pdf</a>, <a href="/format/2312.08863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeadRecon: High-Fidelity 3D Head Reconstruction from Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juyong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the reconstruction of high-fidelity 3D head models from static
portrait image has made great progress. However, most methods require
multi-view or multi-illumination information, which therefore put forward high
requirements for data acquisition. In this paper, we study the reconstruction
of high-fidelity 3D head models from arbitrary monocular videos. Non-rigid
structure from motion (NRSFM) methods have been widely used to solve such
problems according to the two-dimensional correspondence between different
frames. However, the inaccurate correspondence caused by high-complex hair
structures and various facial expression changes would heavily influence the
reconstruction accuracy. To tackle these problems, we propose a prior-guided
dynamic implicit neural network. Specifically, we design a two-part dynamic
deformation field to transform the current frame space to the canonical one. We
further model the head geometry in the canonical space with a learnable signed
distance field (SDF) and optimize it using the volumetric rendering with the
guidance of two-main head priors to improve the reconstruction accuracy and
robustness. Extensive ablation studies and comparisons with state-of-the-art
methods demonstrate the effectiveness and robustness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08865" title="Abstract">arXiv:2312.08865</a> [<a href="/pdf/2312.08865" title="Download PDF">pdf</a>, <a href="/format/2312.08865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Cross-modal Alignment with Synthetic Pairs for Text-only Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fanrong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Although image captioning models have made significant advancements in recent
years, the majority of them heavily depend on high-quality datasets containing
paired images and texts which are costly to acquire. Previous works leverage
the CLIP's cross-modal association ability for image captioning, relying solely
on textual information under unsupervised settings. However, not only does a
modality gap exist between CLIP text and image features, but a discrepancy also
arises between training and inference due to the unavailability of real-world
images, which hinders the cross-modal alignment in text-only captioning. This
paper proposes a novel method to address these issues by incorporating
synthetic image-text pairs. A pre-trained text-to-image model is deployed to
obtain images that correspond to textual data, and the pseudo features of
generated images are optimized toward the real ones in the CLIP embedding
space. Furthermore, textual information is gathered to represent image
features, resulting in the image features with various semantics and the
bridged modality gap. To unify training and inference, synthetic image features
would serve as the training prefix for the language decoder, while real images
are used for inference. Additionally, salient objects in images are detected as
assistance to enhance the learning of modality alignment. Experimental results
demonstrate that our method obtains the state-of-the-art performance on
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08869" title="Abstract">arXiv:2312.08869</a> [<a href="/pdf/2312.08869" title="Download PDF">pdf</a>, <a href="/format/2312.08869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I&#x27;M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chengfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiashen Du</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Z">Ziwei Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures, project page: <a href="https://afterjourney00.github.io/IM-HOI.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We are living in a world surrounded by diverse and "smart" devices with rich
modalities of sensing ability. Conveniently capturing the interactions between
us humans and these objects remains far-reaching. In this paper, we present
I'm-HOI, a monocular scheme to faithfully capture the 3D motions of both the
human and object in a novel setting: using a minimal amount of RGB camera and
object-mounted Inertial Measurement Unit (IMU). It combines general motion
inference and category-aware refinement. For the former, we introduce a
holistic human-object tracking method to fuse the IMU signals and the RGB
stream and progressively recover the human motions and subsequently the
companion object motions. For the latter, we tailor a category-aware motion
diffusion model, which is conditioned on both the raw IMU observations and the
results from the previous stage under over-parameterization representation. It
significantly refines the initial results and generates vivid body, hand, and
object motions. Moreover, we contribute a large dataset with ground truth human
and object motions, dense RGB inputs, and rich object-mounted IMU measurements.
Extensive experiments demonstrate the effectiveness of I'm-HOI under a hybrid
capture setting. Our dataset and code will be released to the community.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08870" title="Abstract">arXiv:2312.08870</a> [<a href="/pdf/2312.08870" title="Download PDF">pdf</a>, <a href="/format/2312.08870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vista-LLaMA: Reliable Video Narrator via Equal Distance to Visual Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaojie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yuchen Xian</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in large video-language models have displayed promising
outcomes in video comprehension. Current approaches straightforwardly convert
video into language tokens and employ large language models for multi-modal
tasks. However, this method often leads to the generation of irrelevant
content, commonly known as "hallucination", as the length of the text increases
and the impact of the video diminishes. To address this problem, we propose
Vista-LLaMA, a novel framework that maintains the consistent distance between
all visual tokens and any language tokens, irrespective of the generated text
length. Vista-LLaMA omits relative position encoding when determining attention
weights between visual and text tokens, retaining the position encoding for
text and text tokens. This amplifies the effect of visual tokens on text
generation, especially when the relative distance is longer between visual and
text tokens. The proposed attention mechanism significantly reduces the chance
of producing irrelevant text related to the video content. Furthermore, we
present a sequential visual projector that projects the current video frame
into tokens of language space with the assistance of the previous frame. This
approach not only captures the temporal relationship within the video, but also
allows less visual tokens to encompass the entire video. Our approach
significantly outperforms various previous methods (e.g., Video-ChatGPT,
MovieChat) on four challenging open-ended video question answering benchmarks.
We reach an accuracy of 60.7 on the zero-shot NExT-QA and 60.5 on the zero-shot
MSRVTT-QA, setting a new state-of-the-art performance. This project is
available at https://jinxxian.github.io/Vista-LLaMA.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08871" title="Abstract">arXiv:2312.08871</a> [<a href="/pdf/2312.08871" title="Download PDF">pdf</a>, <a href="/format/2312.08871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxelKP: A Voxel-based Network Architecture for Human Keypoint  Estimation in LiDAR Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present \textit{VoxelKP}, a novel fully sparse network architecture
tailored for human keypoint estimation in LiDAR data. The key challenge is that
objects are distributed sparsely in 3D space, while human keypoint detection
requires detailed local information wherever humans are present. We propose
four novel ideas in this paper. First, we propose sparse selective kernels to
capture multi-scale context. Second, we introduce sparse box-attention to focus
on learning spatial correlations between keypoints within each human instance.
Third, we incorporate a spatial encoding to leverage absolute 3D coordinates
when projecting 3D voxels to a 2D grid encoding a bird's eye view. Finally, we
propose hybrid feature learning to combine the processing of per-voxel features
with sparse convolution. We evaluate our method on the Waymo dataset and
achieve an improvement of $27\%$ on the MPJPE metric compared to the
state-of-the-art, \textit{HUM3DIL}, trained on the same data, and $12\%$
against the state-of-the-art, \textit{GC-KPL}, pretrained on a $25\times$
larger dataset. To the best of our knowledge, \textit{VoxelKP} is the first
single-staged, fully sparse network that is specifically designed for
addressing the challenging task of 3D keypoint estimation from LiDAR data,
achieving state-of-the-art performances. Our code is available at
\url{https://github.com/shijianjian/VoxelKP}.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08872" title="Abstract">arXiv:2312.08872</a> [<a href="/pdf/2312.08872" title="Download PDF">pdf</a>, <a href="/format/2312.08872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Driven Initial Image Construction for Guided Image Synthesis in  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiafeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The initial noise image has demonstrated a significant influence on image
generation, and manipulating the initial noise image can effectively increase
control over the generation. All of the current generation is based only on a
single initial noise drawn from a normal distribution, which may not be suited
to the desired content specified by the prompt. In this research, we propose a
novel approach using pre-collected, semantically-informed pixel blocks from
multiple initial noises for the initial image construction to enhance control
over the image generation. The inherent tendencies of these pixel blocks can
easily generate specific content, thus effectively guiding the generation
process towards the desired content. The pursuit of tailored initial image
construction inevitably leads to deviations from the normal distribution, and
our experimental results show that the diffusion model exhibits a certain
degree of tolerance towards the distribution of initial images. Our approach
achieves state-of-the-art performance in the training-free layout-to-image
synthesis task, demonstrating the adaptability of the initial image
construction in guiding the content of the generated image. Our code will be
made publicly available.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08873" title="Abstract">arXiv:2312.08873</a> [<a href="/pdf/2312.08873" title="Download PDF">pdf</a>, <a href="/format/2312.08873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Cocktail: Fused Generation from Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanhe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongyi Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models excel at generating high-quality images and are easy to
extend, making them extremely popular among active users who have created an
extensive collection of diffusion models with various styles by fine-tuning
base models such as Stable Diffusion. Recent work has focused on uncovering
semantic and visual information encoded in various components of a diffusion
model, enabling better generation quality and more fine-grained control.
However, those methods target improving a single model and overlook the vastly
available collection of fine-tuned diffusion models. In this work, we study the
combinations of diffusion models. We propose Diffusion Cocktail (Ditail), a
training-free method that can accurately transfer content information between
two diffusion models. This allows us to perform diverse generations using a set
of diffusion models, resulting in novel images that are unlikely to be obtained
by a single model alone. We also explore utilizing Ditail for style transfer,
with the target style set by a diffusion model instead of an image. Ditail
offers a more detailed manipulation of the diffusion generation, thereby
enabling the vast community to integrate various styles and contents seamlessly
and generate any content of any style.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08874" title="Abstract">arXiv:2312.08874</a> [<a href="/pdf/2312.08874" title="Download PDF">pdf</a>, <a href="/format/2312.08874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Attention: On the Integration of Softmax and Linear Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tianzhu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yizeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The attention module is the key component in Transformers. While the global
attention mechanism offers high expressiveness, its excessive computational
cost restricts its applicability in various scenarios. In this paper, we
propose a novel attention paradigm, Agent Attention, to strike a favorable
balance between computational efficiency and representation power.
Specifically, the Agent Attention, denoted as a quadruple $(Q, A, K, V)$,
introduces an additional set of agent tokens $A$ into the conventional
attention module. The agent tokens first act as the agent for the query tokens
$Q$ to aggregate information from $K$ and $V$, and then broadcast the
information back to $Q$. Given the number of agent tokens can be designed to be
much smaller than the number of query tokens, the agent attention is
significantly more efficient than the widely adopted Softmax attention, while
preserving global context modelling capability. Interestingly, we show that the
proposed agent attention is equivalent to a generalized form of linear
attention. Therefore, agent attention seamlessly integrates the powerful
Softmax attention and the highly efficient linear attention. Extensive
experiments demonstrate the effectiveness of agent attention with various
vision Transformers and across diverse vision tasks, including image
classification, object detection, semantic segmentation and image generation.
Notably, agent attention has shown remarkable performance in high-resolution
scenarios, owning to its linear attention nature. For instance, when applied to
Stable Diffusion, our agent attention accelerates generation and substantially
enhances image generation quality without any additional training. Code is
available at https://github.com/LeapLabTHU/Agent-Attention.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08875" title="Abstract">arXiv:2312.08875</a> [<a href="/pdf/2312.08875" title="Download PDF">pdf</a>, <a href="/format/2312.08875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What, How, and When Should Object Detectors Update in Continually  Changing Test Domains?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jayeon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongkwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+I">Inseop Chung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It is a well-known fact that the performance of deep learning models
deteriorates when they encounter a distribution shift at test time. Test-time
adaptation (TTA) algorithms have been proposed to adapt the model online while
inferring test data. However, existing research predominantly focuses on
classification tasks through the optimization of batch normalization layers or
classification heads, but this approach limits its applicability to various
model architectures like Transformers and makes it challenging to apply to
other tasks, such as object detection. In this paper, we propose a novel online
adaption approach for object detection in continually changing test domains,
considering which part of the model to update, how to update it, and when to
perform the update. By introducing architecture-agnostic and lightweight
adaptor modules and only updating these while leaving the pre-trained backbone
unchanged, we can rapidly adapt to new test domains in an efficient way and
prevent catastrophic forgetting. Furthermore, we present a practical and
straightforward class-wise feature aligning method for object detection to
resolve domain shifts. Additionally, we enhance efficiency by determining when
the model is sufficiently adapted or when additional adaptation is needed due
to changes in the test distribution. Our approach surpasses baselines on widely
used benchmarks, achieving improvements of up to 4.9\%p and 7.9\%p in mAP for
COCO $\rightarrow$ COCO-corrupted and SHIFT, respectively, while maintaining
about 20 FPS or higher.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08876" title="Abstract">arXiv:2312.08876</a> [<a href="/pdf/2312.08876" title="Download PDF">pdf</a>, <a href="/format/2312.08876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenSight: A Simple Open-Vocabulary Framework for LiDAR-Based Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaicheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional LiDAR-based object detection research primarily focuses on
closed-set scenarios, which falls short in complex real-world applications.
Directly transferring existing 2D open-vocabulary models with some known LiDAR
classes for open-vocabulary ability, however, tends to suffer from over-fitting
problems: The obtained model will detect the known objects, even presented with
a novel category. In this paper, we propose OpenSight, a more advanced 2D-3D
modeling framework for LiDAR-based open-vocabulary detection. OpenSight
utilizes 2D-3D geometric priors for the initial discernment and localization of
generic objects, followed by a more specific semantic interpretation of the
detected objects. The process begins by generating 2D boxes for generic objects
from the accompanying camera images of LiDAR. These 2D boxes, together with
LiDAR points, are then lifted back into the LiDAR space to estimate
corresponding 3D boxes. For better generic object perception, our framework
integrates both temporal and spatial-aware constraints. Temporal awareness
correlates the predicted 3D boxes across consecutive timestamps, recalibrating
the missed or inaccurate boxes. The spatial awareness randomly places some
``precisely'' estimated 3D boxes at varying distances, increasing the
visibility of generic objects. To interpret the specific semantics of detected
objects, we develop a cross-modal alignment and fusion module to first align 3D
features with 2D image embeddings and then fuse the aligned 3D-2D features for
semantic decoding. Our experiments indicate that our method establishes
state-of-the-art open-vocabulary performance on widely used 3D detection
benchmarks and effectively identifies objects for new categories of interest.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08877" title="Abstract">arXiv:2312.08877</a> [<a href="/pdf/2312.08877" title="Download PDF">pdf</a>, <a href="/format/2312.08877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> May the Noise be with you: Adversarial Training without Adversarial  Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arous%2C+A">Ayoub Arous</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Lopera%2C+A+F">Andres F Lopez-Lopera</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>, 
<a href="/search/cs?searchtype=author&query=Alouani%2C+I">Ihsen Alouani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we investigate the following question: Can we obtain
adversarially-trained models without training on adversarial examples? Our
intuition is that training a model with inherent stochasticity, i.e.,
optimizing the parameters by minimizing a stochastic loss function, yields a
robust expectation function that is non-stochastic. In contrast to related
methods that introduce noise at the input level, our proposed approach
incorporates inherent stochasticity by embedding Gaussian noise within the
layers of the NN model at training time. We model the propagation of noise
through the layers, introducing a closed-form stochastic loss function that
encapsulates a noise variance parameter. Additionally, we contribute a
formalized noise-aware gradient, enabling the optimization of model parameters
while accounting for stochasticity. Our experimental results confirm that the
expectation model of a stochastic architecture trained on benign distribution
is adversarially robust. Interestingly, we find that the impact of the applied
Gaussian noise's standard deviation on both robustness and baseline accuracy
closely mirrors the impact of the noise magnitude employed in adversarial
training. Our work contributes adversarially trained networks using a
completely different approach, with empirically similar robustness to
adversarial training.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08878" title="Abstract">arXiv:2312.08878</a> [<a href="/pdf/2312.08878" title="Download PDF">pdf</a>, <a href="/format/2312.08878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Prompt Learning with Quaternion Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Prompt learning has emerged as an effective and data-efficient technique in
large Vision-Language Models (VLMs). However, when adapting VLMs to specialized
domains such as remote sensing and medical imaging, domain prompt learning
remains underexplored. While large-scale domain-specific foundation models can
help tackle this challenge, their concentration on a single vision level makes
it challenging to prompt both vision and language modalities. To overcome this,
we propose to leverage domain-specific knowledge from domain-specific
foundation models to transfer the robust recognition ability of VLMs from
generalized to specialized domains, using quaternion networks. Specifically,
the proposed method involves using domain-specific vision features from
domain-specific foundation models to guide the transformation of generalized
contextual embeddings from the language branch into a specialized space within
the quaternion networks. Moreover, we present a hierarchical approach that
generates vision prompt features by analyzing intermodal relationships between
hierarchical language prompt features and domain-specific vision features. In
this way, quaternion networks can effectively mine the intermodal relationships
in the specific domain, facilitating domain-specific vision-language
contrastive learning. Extensive experiments on domain-specific datasets show
that our proposed method achieves new state-of-the-art results in prompt
learning.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08879" title="Abstract">arXiv:2312.08879</a> [<a href="/pdf/2312.08879" title="Download PDF">pdf</a>, <a href="/format/2312.08879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularizing Self-supervised 3D Scene Flows with Surface Awareness and  Cyclic Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vacek%2C+P">Patrik Vacek</a>, 
<a href="/search/cs?searchtype=author&query=Hurych%2C+D">David Hurych</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+K">Karel Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+P">Patrick Perez</a>, 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+T">Tomas Svoboda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning without supervision how to predict 3D scene flows from point clouds
is central to many vision systems. We propose a novel learning framework for
this task which improves the necessary regularization. Relying on the
assumption that scene elements are mostly rigid, current smoothness losses are
built on the definition of ``rigid clusters" in the input point clouds. The
definition of these clusters is challenging and has a major impact on the
quality of predicted flows. We introduce two new consistency losses that
enlarge clusters while preventing them from spreading over distinct objects. In
particular, we enforce \emph{temporal} consistency with a forward-backward
cyclic loss and \emph{spatial} consistency by considering surface orientation
similarity in addition to spatial proximity. The proposed losses are
model-independent and can thus be used in a plug-and-play fashion to
significantly improve the performance of existing models, as demonstrated on
two top-performing ones. We also showcase the effectiveness and generalization
capability of our framework on four standard sensor-unique driving datasets,
achieving state-of-the-art performance in 3D scene flow estimation. Our codes
are available anonymously on \url{https://github.com/vacany/sac-flow}.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08880" title="Abstract">arXiv:2312.08880</a> [<a href="/pdf/2312.08880" title="Download PDF">pdf</a>, <a href="/format/2312.08880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenDet: Towards Good Generalizations for AI-Generated Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingjian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mouxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hailin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The misuse of AI imagery can have harmful societal effects, prompting the
creation of detectors to combat issues like the spread of fake news. Existing
methods can effectively detect images generated by seen generators, but it is
challenging to detect those generated by unseen generators. They do not
concentrate on amplifying the output discrepancy when detectors process real
versus fake images. This results in a close output distribution of real and
fake samples, increasing classification difficulty in detecting unseen
generators. This paper addresses the unseen-generator detection problem by
considering this task from the perspective of anomaly detection and proposes an
adversarial teacher-student discrepancy-aware framework. Our method encourages
smaller output discrepancies between the student and the teacher models for
real images while aiming for larger discrepancies for fake images. We employ
adversarial learning to train a feature augmenter, which promotes smaller
discrepancies between teacher and student networks when the inputs are fake
images. Our method has achieved state-of-the-art on public benchmarks, and the
visualization results show that a large output discrepancy is maintained when
faced with various types of generators.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08881" title="Abstract">arXiv:2312.08881</a> [<a href="/pdf/2312.08881" title="Download PDF">pdf</a>, <a href="/format/2312.08881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaptIR: Parameter Efficient Multi-task Adaptation for Pre-trained Image  Restoration Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuanchao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zexuan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training has shown promising results on various image restoration tasks,
which is usually followed by full fine-tuning for each specific downstream task
(e.g., image denoising). However, such full fine-tuning usually suffers from
the problems of heavy computational cost in practice, due to the massive
parameters of pre-trained restoration models, thus limiting its real-world
applications. Recently, Parameter Efficient Transfer Learning (PETL) offers an
efficient alternative solution to full fine-tuning, yet still faces great
challenges for pre-trained image restoration models, due to the diversity of
different degradations. To address these issues, we propose AdaptIR, a novel
parameter efficient transfer learning method for adapting pre-trained
restoration models. Specifically, the proposed method consists of a
multi-branch inception structure to orthogonally capture local spatial, global
spatial, and channel interactions. In this way, it allows powerful
representations under a very low parameter budget. Extensive experiments
demonstrate that the proposed method can achieve comparable or even better
performance than full fine-tuning, while only using 0.6% parameters. Code is
available at https://github.com/csguoh/AdaptIR.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08882" title="Abstract">arXiv:2312.08882</a> [<a href="/pdf/2312.08882" title="Download PDF">pdf</a>, <a href="/format/2312.08882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Video Fields Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuzhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chong Mou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have revolutionized text-driven video editing. However,
applying these methods to real-world editing encounters two significant
challenges: (1) the rapid increase in graphics memory demand as the number of
frames grows, and (2) the inter-frame inconsistency in edited videos. To this
end, we propose NVEdit, a novel text-driven video editing framework designed to
mitigate memory overhead and improve consistent editing for real-world long
videos. Specifically, we construct a neural video field, powered by tri-plane
and sparse grid, to enable encoding long videos with hundreds of frames in a
memory-efficient manner. Next, we update the video field through off-the-shelf
Text-to-Image (T2I) models to impart text-driven editing effects. A progressive
optimization strategy is developed to preserve original temporal priors.
Importantly, both the neural video field and T2I model are adaptable and
replaceable, thus inspiring future research. Experiments demonstrate that our
approach successfully edits hundreds of frames with impressive inter-frame
consistency.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08883" title="Abstract">arXiv:2312.08883</a> [<a href="/pdf/2312.08883" title="Download PDF">pdf</a>, <a href="/format/2312.08883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EditGuard: Versatile Image Watermarking for Tamper Localization and  Copyright Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Youmin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AIGC image watermarking, tamper localization and copyright protection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the era where AI-generated content (AIGC) models can produce stunning and
lifelike images, the lingering shadow of unauthorized reproductions and
malicious tampering poses imminent threats to copyright integrity and
information security. Current image watermarking methods, while widely accepted
for safeguarding visual content, can only protect copyright and ensure
traceability. They fall short in localizing increasingly realistic image
tampering, potentially leading to trust crises, privacy violations, and legal
disputes. To solve this challenge, we propose an innovative proactive forensics
framework EditGuard, to unify copyright protection and tamper-agnostic
localization, especially for AIGC-based editing methods. It can offer a
meticulous embedding of imperceptible watermarks and precise decoding of
tampered areas and copyright information. Leveraging our observed fragility and
locality of image-into-image steganography, the realization of EditGuard can be
converted into a united image-bit steganography issue, thus completely
decoupling the training process from the tampering types. Extensive experiments
demonstrate that our EditGuard balances the tamper localization accuracy,
copyright recovery precision, and generalizability to various AIGC-based
tampering methods, especially for image forgery that is difficult for the naked
eye to detect. The project page is available at
https://xuanyuzhang21.github.io/project/editguard/.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08884" title="Abstract">arXiv:2312.08884</a> [<a href="/pdf/2312.08884" title="Download PDF">pdf</a>, <a href="/format/2312.08884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Rewards in Multi-Agent Deep Reinforcement Learning for Autonomous  Mobility on Demand Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+H">Heiko Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Enders%2C+T">Tobias Enders</a>, 
<a href="/search/cs?searchtype=author&query=Cappart%2C+Q">Quentin Cappart</a>, 
<a href="/search/cs?searchtype=author&query=Schiffer%2C+M">Maximilian Schiffer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">We study vehicle dispatching in autonomous mobility on demand (AMoD) systems,
where a central operator assigns vehicles to customer requests or rejects these
with the aim of maximizing its total profit. Recent approaches use multi-agent
deep reinforcement learning (MADRL) to realize scalable yet performant
algorithms, but train agents based on local rewards, which distorts the reward
signal with respect to the system-wide profit, leading to lower performance. We
therefore propose a novel global-rewards-based MADRL algorithm for vehicle
dispatching in AMoD systems, which resolves so far existing goal conflicts
between the trained agents and the operator by assigning rewards to agents
leveraging a counterfactual baseline. Our algorithm shows statistically
significant improvements across various settings on real-world data compared to
state-of-the-art MADRL algorithms with local rewards. We further provide a
structural analysis which shows that the utilization of global rewards can
improve implicit vehicle balancing and demand forecasting abilities. Our code
is available at https://github.com/tumBAIS/GR-MADRL-AMoD.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08885" title="Abstract">arXiv:2312.08885</a> [<a href="/pdf/2312.08885" title="Download PDF">pdf</a>, <a href="/format/2312.08885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneWiz3D: Towards Text-guided 3D Scene Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+P">Peiye Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://zqh0253.github.io/SceneWiz3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We are witnessing significant breakthroughs in the technology for generating
3D objects from text. Existing approaches either leverage large text-to-image
models to optimize a 3D representation or train 3D generators on object-centric
datasets. Generating entire scenes, however, remains very challenging as a
scene contains multiple 3D objects, diverse and scattered. In this work, we
introduce SceneWiz3D, a novel approach to synthesize high-fidelity 3D scenes
from text. We marry the locality of objects with globality of scenes by
introducing a hybrid 3D representation: explicit for objects and implicit for
scenes. Remarkably, an object, being represented explicitly, can be either
generated from text using conventional text-to-3D approaches, or provided by
users. To configure the layout of the scene and automatically place objects, we
apply the Particle Swarm Optimization technique during the optimization
process. Furthermore, it is difficult for certain parts of the scene (e.g.,
corners, occlusion) to receive multi-view supervision, leading to inferior
geometry. We incorporate an RGBD panorama diffusion model to mitigate it,
resulting in high-quality geometry. Extensive evaluation supports that our
approach achieves superior quality over previous approaches, enabling the
generation of detailed and view-consistent 3D scenes.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08886" title="Abstract">arXiv:2312.08886</a> [<a href="/pdf/2312.08886" title="Download PDF">pdf</a>, <a href="/format/2312.08886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Blind Text Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhouxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Luwei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongqing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+L">Liheng Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recovering degraded low-resolution text images is challenging, especially for
Chinese text images with complex strokes and severe degradation in real-world
scenarios. Ensuring both text fidelity and style realness is crucial for
high-quality text image super-resolution. Recently, diffusion models have
achieved great success in natural image synthesis and restoration due to their
powerful data distribution modeling abilities and data generation capabilities.
In this work, we propose an Image Diffusion Model (IDM) to restore text images
with realistic styles. For diffusion models, they are not only suitable for
modeling realistic image distribution but also appropriate for learning text
distribution. Since text prior is important to guarantee the correctness of the
restored text structure according to existing arts, we also propose a Text
Diffusion Model (TDM) for text recognition which can guide IDM to generate text
images with correct structures. We further propose a Mixture of Multi-modality
module (MoM) to make these two diffusion models cooperate with each other in
all the diffusion steps. Extensive experiments on synthetic and real-world
datasets demonstrate that our Diffusion-based Blind Text Image Super-Resolution
(DiffTSR) can restore text images with more accurate text structures as well as
more realistic appearances simultaneously.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08887" title="Abstract">arXiv:2312.08887</a> [<a href="/pdf/2312.08887" title="Download PDF">pdf</a>, <a href="/format/2312.08887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Weilong Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">DanDan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiajiong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenguang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image diffusion models (SD) exhibit significant advancements while
requiring extensive computational resources. Though many acceleration methods
have been proposed, they suffer from generation quality degradation or extra
training cost generalizing to new fine-tuned models. To address these
limitations, we propose a novel and universal Stable-Diffusion (SD)
acceleration module called SpeedUpNet(SUN). SUN can be directly plugged into
various fine-tuned SD models without extra training. This technique utilizes
cross-attention layers to learn the relative offsets in the generated image
results between negative and positive prompts achieving classifier-free
guidance distillation with negative prompts controllable, and introduces a
Multi-Step Consistency (MSC) loss to ensure a harmonious balance between
reducing inference steps and maintaining consistency in the generated output.
Consequently, SUN significantly reduces the number of inference steps to just 4
steps and eliminates the need for classifier-free guidance. It leads to an
overall speedup of more than 10 times for SD models compared to the
state-of-the-art 25-step DPM-solver++, and offers two extra advantages: (1)
classifier-free guidance distillation with controllable negative prompts and
(2) seamless integration into various fine-tuned Stable-Diffusion models
without training. The effectiveness of the SUN has been verified through
extensive experimentation. Project Page:
https://williechai.github.io/speedup-plugin-for-stable-diffusions.github.io
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08888" title="Abstract">arXiv:2312.08888</a> [<a href="/pdf/2312.08888" title="Download PDF">pdf</a>, <a href="/format/2312.08888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Read Between the Layers: Leveraging Intra-Layer Representations for  Rehearsal-Free Continual Learning with Pre-Trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahrens%2C+K">Kyra Ahrens</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+H+H">Hans Hergen Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jae Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We address the Continual Learning (CL) problem, where a model has to learn a
sequence of tasks from non-stationary distributions while preserving prior
knowledge as it encounters new experiences. With the advancement of foundation
models, CL research has shifted focus from the initial learning-from-scratch
paradigm to the use of generic features from large-scale pre-training. However,
existing approaches to CL with pre-trained models only focus on separating the
class-specific features from the final representation layer and neglect the
power of intermediate representations that capture low- and mid-level features
naturally more invariant to domain shifts. In this work, we propose LayUP, a
new class-prototype-based approach to continual learning that leverages
second-order feature statistics from multiple intermediate layers of a
pre-trained network. Our method is conceptually simple, does not require any
replay buffer, and works out of the box with any foundation model. LayUP
improves over the state-of-the-art on four of the seven class-incremental
learning settings at a considerably reduced memory and computational footprint
compared with the next best baseline. Our results demonstrate that fully
exhausting the representational capacities of pre-trained models in CL goes far
beyond their final embeddings.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08889" title="Abstract">arXiv:2312.08889</a> [<a href="/pdf/2312.08889" title="Download PDF">pdf</a>, <a href="/format/2312.08889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained  Geometry and Appearance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanyou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Powered by large-scale text-to-image generation models, text-to-3D avatar
generation has made promising progress. However, most methods fail to produce
photorealistic results, limited by imprecise geometry and low-quality
appearance. Towards more practical avatar generation, we present SEEAvatar, a
method for generating photorealistic 3D avatars from text with SElf-Evolving
constraints for decoupled geometry and appearance. For geometry, we propose to
constrain the optimized avatar in a decent global shape with a template avatar.
The template avatar is initialized with human prior and can be updated by the
optimized avatar periodically as an evolving template, which enables more
flexible shape generation. Besides, the geometry is also constrained by the
static human prior in local parts like face and hands to maintain the delicate
structures. For appearance generation, we use diffusion model enhanced by
prompt engineering to guide a physically based rendering pipeline to generate
realistic textures. The lightness constraint is applied on the albedo texture
to suppress incorrect lighting effect. Experiments show that our method
outperforms previous methods on both global and local geometry and appearance
quality by a large margin. Since our method can produce high-quality meshes and
textures, such assets can be directly applied in classic graphics pipeline for
realistic rendering under any lighting condition. Project page at:
https://seeavatar3d.github.io.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08890" title="Abstract">arXiv:2312.08890</a> [<a href="/pdf/2312.08890" title="Download PDF">pdf</a>, <a href="/format/2312.08890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defenses in Adversarial Machine Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shaokui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingli Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meixi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Danni Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingshan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures, 2 tables, 237 reference papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adversarial phenomenon has been widely observed in machine learning (ML)
systems, especially in those using deep neural networks, describing that ML
systems may produce inconsistent and incomprehensible predictions with humans
at some particular cases. This phenomenon poses a serious security threat to
the practical application of ML systems, and several advanced attack paradigms
have been developed to explore it, mainly including backdoor attacks, weight
attacks, and adversarial examples. For each individual attack paradigm, various
defense paradigms have been developed to improve the model robustness against
the corresponding attack paradigm. However, due to the independence and
diversity of these defense paradigms, it is difficult to examine the overall
robustness of an ML system against different kinds of attacks.This survey aims
to build a systematic review of all existing defense paradigms from a unified
perspective. Specifically, from the life-cycle perspective, we factorize a
complete machine learning system into five stages, including pre-training,
training, post-training, deployment, and inference stages, respectively. Then,
we present a clear taxonomy to categorize and review representative defense
methods at each individual stage. The unified perspective and presented
taxonomies not only facilitate the analysis of the mechanism of each defense
paradigm but also help us to understand connections and differences among
different defense paradigms, which may inspire future research to develop more
advanced, comprehensive defenses.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08891" title="Abstract">arXiv:2312.08891</a> [<a href="/pdf/2312.08891" title="Download PDF">pdf</a>, <a href="/format/2312.08891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Dimensional Bayesian Optimisation with Large-Scale Constraints --  An Application to Aeroelastic Tailoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maathuis%2C+H">Hauke Maathuis</a>, 
<a href="/search/cs?searchtype=author&query=De+Breuker%2C+R">Roeland De Breuker</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+S+G+P">Saullo G. P. Castro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper submitted to AIAA Scitech 2024 Forum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Design optimisation potentially leads to lightweight aircraft structures with
lower environmental impact. Due to the high number of design variables and
constraints, these problems are ordinarily solved using gradient-based
optimisation methods, leading to a local solution in the design space while the
global space is neglected. Bayesian Optimisation is a promising path towards
sample-efficient, global optimisation based on probabilistic surrogate models.
While Bayesian optimisation methods have demonstrated their strength for
problems with a low number of design variables, the scalability to
high-dimensional problems while incorporating large-scale constraints is still
lacking. Especially in aeroelastic tailoring where directional stiffness
properties are embodied into the structural design of aircraft, to control
aeroelastic deformations and to increase the aerodynamic and structural
performance, the safe operation of the system needs to be ensured by involving
constraints resulting from different analysis disciplines. Hence, a global
design space search becomes even more challenging. The present study attempts
to tackle the problem by using high-dimensional Bayesian Optimisation in
combination with a dimensionality reduction approach to solve the optimisation
problem occurring in aeroelastic tailoring, presenting a novel approach for
high-dimensional problems with large-scale constraints. Experiments on
well-known benchmark cases with black-box constraints show that the proposed
approach can incorporate large-scale constraints.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08892" title="Abstract">arXiv:2312.08892</a> [<a href="/pdf/2312.08892" title="Download PDF">pdf</a>, <a href="/format/2312.08892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VaLID: Variable-Length Input Diffusion for Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Zanjani%2C+F+G">Farhad G. Zanjani</a>, 
<a href="/search/cs?searchtype=author&query=Yahia%2C+H+B">Haitam Ben Yahia</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>, 
<a href="/search/cs?searchtype=author&query=Habibian%2C+A">Amirhossein Habibian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper and supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel View Synthesis (NVS), which tries to produce a realistic image at the
target view given source view images and their corresponding poses, is a
fundamental problem in 3D Vision. As this task is heavily under-constrained,
some recent work, like Zero123, tries to solve this problem with generative
modeling, specifically using pre-trained diffusion models. Although this
strategy generalizes well to new scenes, compared to neural radiance
field-based methods, it offers low levels of flexibility. For example, it can
only accept a single-view image as input, despite realistic applications often
offering multiple input images. This is because the source-view images and
corresponding poses are processed separately and injected into the model at
different stages. Thus it is not trivial to generalize the model into
multi-view source images, once they are available. To solve this issue, we try
to process each pose image pair separately and then fuse them as a unified
visual representation which will be injected into the model to guide image
synthesis at the target-views. However, inconsistency and computation costs
increase as the number of input source-view images increases. To solve these
issues, the Multi-view Cross Former module is proposed which maps
variable-length input data to fix-size output data. A two-stage training
strategy is introduced to further improve the efficiency during training time.
Qualitative and quantitative evaluation over multiple datasets demonstrates the
effectiveness of the proposed method against previous approaches. The code will
be released according to the acceptance.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08893" title="Abstract">arXiv:2312.08893</a> [<a href="/pdf/2312.08893" title="Download PDF">pdf</a>, <a href="/ps/2312.08893" title="Download PostScript">ps</a>, <a href="/format/2312.08893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Dense Linear Systems Faster than via Preconditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derezi%C5%84ski%2C+M">Micha&#x142; Derezi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaming Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">We give a stochastic optimization algorithm that solves a dense $n\times n$
real-valued linear system $Ax=b$, returning $\tilde x$ such that $\|A\tilde
x-b\|\leq \epsilon\|b\|$ in time: $$\tilde
O((n^2+nk^{\omega-1})\log1/\epsilon),$$ where $k$ is the number of singular
values of $A$ larger than $O(1)$ times its smallest positive singular value,
$\omega &lt; 2.372$ is the matrix multiplication exponent, and $\tilde O$ hides a
poly-logarithmic in $n$ factor. When $k=O(n^{1-\theta})$ (namely, $A$ has a
flat-tailed spectrum, e.g., due to noisy data or regularization), this improves
on both the cost of solving the system directly, as well as on the cost of
preconditioning an iterative method such as conjugate gradient. In particular,
our algorithm has an $\tilde O(n^2)$ runtime when $k=O(n^{0.729})$. We further
adapt this result to sparse positive semidefinite matrices and least squares
regression.
<br />Our main algorithm can be viewed as a randomized block coordinate descent
method, where the key challenge is simultaneously ensuring good convergence and
fast per-iteration time. In our analysis, we use theory of majorization for
elementary symmetric polynomials to establish a sharp convergence guarantee
when coordinate blocks are sampled using a determinantal point process. We then
use a Markov chain coupling argument to show that similar convergence can be
attained with a cheaper sampling scheme, and accelerate the block coordinate
descent update via matrix sketching.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08894" title="Abstract">arXiv:2312.08894</a> [<a href="/pdf/2312.08894" title="Download PDF">pdf</a>, <a href="/format/2312.08894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAROOD: Human Activity Classification and Out-of-Distribution Detection  with Short-Range FMCW Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahya%2C+S+M">Sabri Mustafa Kahya</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+M+S">Muhammet Sami Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Steinbach%2C+E">Eckehard Steinbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose HAROOD as a short-range FMCW radar-based human activity classifier
and out-of-distribution (OOD) detector. It aims to classify human sitting,
standing, and walking activities and to detect any other moving or stationary
object as OOD. We introduce a two-stage network. The first stage is trained
with a novel loss function that includes intermediate reconstruction loss,
intermediate contrastive loss, and triplet loss. The second stage uses the
first stage's output as its input and is trained with cross-entropy loss. It
creates a simple classifier that performs the activity classification. On our
dataset collected by 60 GHz short-range FMCW radar, we achieve an average
classification accuracy of 96.51%. Also, we achieve an average AUROC of 95.04%
as an OOD detector. Additionally, our extensive evaluations demonstrate the
superiority of HAROOD over the state-of-the-art OOD detection methods in terms
of standard OOD detection metrics.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08895" title="Abstract">arXiv:2312.08895</a> [<a href="/pdf/2312.08895" title="Download PDF">pdf</a>, <a href="/format/2312.08895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Flow Matching for Human Motion Synthesis and Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenzhe Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunlu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+B">Basura Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M Asano</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>, 
<a href="/search/cs?searchtype=author&query=Ommer%2C+B">Bjorn Ommer</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human motion synthesis is a fundamental task in computer animation. Recent
methods based on diffusion models or GPT structure demonstrate commendable
performance but exhibit drawbacks in terms of slow sampling speeds and error
accumulation. In this paper, we propose \emph{Motion Flow Matching}, a novel
generative model designed for human motion generation featuring efficient
sampling and effectiveness in motion editing applications. Our method reduces
the sampling complexity from thousand steps in previous diffusion models to
just ten steps, while achieving comparable performance in text-to-motion and
action-to-motion generation benchmarks. Noticeably, our approach establishes a
new state-of-the-art Fr\'echet Inception Distance on the KIT-ML dataset. What
is more, we tailor a straightforward motion editing paradigm named
\emph{sampling trajectory rewriting} leveraging the ODE-style generative models
and apply it to various editing scenarios including motion prediction, motion
in-between prediction, motion interpolation, and upper-body editing. Our code
will be released.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08897" title="Abstract">arXiv:2312.08897</a> [<a href="/pdf/2312.08897" title="Download PDF">pdf</a>, <a href="/ps/2312.08897" title="Download PostScript">ps</a>, <a href="/format/2312.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax Monads for the Working Formal Metatheorist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunn%2C+L">Lawrence Dunn</a> (University of Pennsylvania), 
<a href="/search/cs?searchtype=author&query=Tannen%2C+V">Val Tannen</a> (University of Pennsylvania), 
<a href="/search/cs?searchtype=author&query=Zdancewic%2C+S">Steve Zdancewic</a> (University of Pennsylvania)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 98-117
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Formally verifying the properties of formal systems using a proof assistant
requires justifying numerous minor lemmas about capture-avoiding substitution.
Despite work on category-theoretic accounts of syntax and variable binding,
raw, first-order representations of syntax, the kind considered by many
practitioners and compiler frontends, have received relatively little
attention. Therefore applications miss out on the benefits of category theory,
most notably the promise of reusing formalized infrastructural lemmas between
implementations of different systems. Our Coq framework Tealeaves provides
libraries of reusable infrastructure for a raw, locally nameless representation
and can be extended to other representations in a modular fashion. In this
paper we give a string-diagrammatic account of decorated traversable monads
(DTMs), the key abstraction implemented by Tealeaves. We define DTMs as monoids
of structured endofunctors before proving a representation theorem a la
Kleisli, yielding a recursion combinator for finitary tree-like datatypes.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08898" title="Abstract">arXiv:2312.08898</a> [<a href="/pdf/2312.08898" title="Download PDF">pdf</a>, <a href="/format/2312.08898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Defense of Unlearnable Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lijia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiao-Shan Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Privacy preserving has become increasingly critical with the emergence of
social media. Unlearnable examples have been proposed to avoid leaking personal
information on the Internet by degrading generalization abilities of deep
learning models. However, our study reveals that unlearnable examples are
easily detectable. We provide theoretical results on linear separability of
certain unlearnable poisoned dataset and simple network based detection methods
that can identify all existing unlearnable examples, as demonstrated by
extensive experiments. Detectability of unlearnable examples with simple
networks motivates us to design a novel defense method. We propose using
stronger data augmentations coupled with adversarial noises generated by simple
networks, to degrade the detectability and thus provide effective defense
against unlearnable examples with a lower cost. Adversarial training with large
budgets is a widely-used defense method on unlearnable examples. We establish
quantitative criteria between the poison and adversarial budgets which
determine the existence of robust unlearnable examples or the failure of the
adversarial defense.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08899" title="Abstract">arXiv:2312.08899</a> [<a href="/pdf/2312.08899" title="Download PDF">pdf</a>, <a href="/ps/2312.08899" title="Download PostScript">ps</a>, <a href="/format/2312.08899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbiotic Blockchain Consensus: Cognitive Backscatter  Communications-enabled Wireless Blockchain Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haoxiang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.16692">arXiv:2309.16692</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The wireless blockchain network (WBN) concept, born from the blockchain
deployed in wireless networks, has appealed to many network scenarios.
Blockchain consensus mechanisms (CMs) are key to enabling nodes in a wireless
network to achieve consistency without any trusted entity. However, consensus
reliability will be seriously affected by the instability of communication
links in wireless networks. Meanwhile, it is difficult for nodes in wireless
scenarios to obtain a timely energy supply. Energy-intensive blockchain
functions can quickly drain the power of nodes, thus degrading consensus
performance. Fortunately, a symbiotic radio (SR) system enabled by cognitive
backscatter communications can solve the above problems. In SR, the secondary
transmitter (STx) transmits messages over the radio frequency (RF) signal
emitted from a primary transmitter (PTx) with extremely low energy consumption,
and the STx can provide multipath gain to the PTx in return. Such an approach
is useful for almost all vote-based CMs, such as the Practical Byzantine
Fault-tolerant (PBFT)-like and the RAFT-like CMs. This paper proposes symbiotic
blockchain consensus (SBC) by transforming 6 PBFT-like and 4 RAFT-like
state-of-the-art (SOTA) CMs to demonstrate universality. These new CMs will
benefit from mutualistic transmission relationships in SR, making full use of
the limited spectrum resources in WBN. Simulation results show that SBC can
increase the consensus success rate of PBFT-like and RAFT-like by 54.1% and
5.8%, respectively, and reduce energy consumption by 9.2% and 23.7%,
respectively.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08900" title="Abstract">arXiv:2312.08900</a> [<a href="/pdf/2312.08900" title="Download PDF">pdf</a>, <a href="/format/2312.08900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-PEFT: Efficient Multi-Modal, Multi-Task Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hadji-Kyriacou%2C+A+A">Avelina Asada Hadji-Kyriacou</a>, 
<a href="/search/cs?searchtype=author&query=Arandjelovic%2C+O">Ognjen Arandjelovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper introduces a novel Parameter-Efficient Fine-Tuning (PEFT)
framework for multi-modal, multi-task transfer learning with pre-trained
language models. PEFT techniques such as LoRA, BitFit and IA3 have demonstrated
comparable performance to full fine-tuning of pre-trained models for specific
downstream tasks, all while demanding significantly fewer trainable parameters
and reduced GPU memory consumption. However, in the context of multi-modal
fine-tuning, the need for architectural modifications or full fine-tuning often
becomes apparent. To address this we propose Context-PEFT, which learns
different groups of adaptor parameters based on the token's domain. This
approach enables LoRA-like weight injection without requiring additional
architectural changes. Our method is evaluated on the COCO captioning task,
where it outperforms full fine-tuning under similar data constraints while
simultaneously offering a substantially more parameter-efficient and
computationally economical solution.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08901" title="Abstract">arXiv:2312.08901</a> [<a href="/pdf/2312.08901" title="Download PDF">pdf</a>, <a href="/format/2312.08901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting LLM Reasoning: Push the Limits of Few-shot Learning with  Reinforced In-Context Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+L">Li Lyna Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive capabilities in various
tasks, yet they still struggle with math reasoning. Despite efforts to optimize
Chain-of-Thoughts (CoT) prompts and fine-tune LLMs, the potential of few-shot
learning remains unexplored. In this work, we propose CoT-Max, a novel approach
pushing the boundaries of few-shot CoT learning to improve LLM math reasoning
capabilities. CoT-Max addresses the challenges of the selection of useful
examples and limited number of examples due to restricted context window
length. Inspired by our observation that natural language inputs contain many
redundancy, we propose a coarse-to-fine pruner as a plug-and-play module for
LLMs, which first identifies crucial CoT examples from a large batch and then
further prunes unimportant tokens. To train the pruner, we collect a math
reasoning dataset with diverse difficulty and steps, introduce a reward to
measure both the input's effectiveness for math reasoning and token length
constraints, and propose a novel training approach with reinforcement learning.
As a result, CoT-Max significantly outperforms CoT and few-shot prompting
baselines across various LLMs (LLaMA2-7B, 13B, 70B) and 5 mathematical
datasets, achieving up to 4.55% absolute improvements. Remarkably, without any
fine-tuning, LLaMA2-70B with CoT-Max surpasses GPT-3.5 and a wide range of
larger LLMs (PaLM, Minerva, etc.) on the GSM8K.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08903" title="Abstract">arXiv:2312.08903</a> [<a href="/pdf/2312.08903" title="Download PDF">pdf</a>, <a href="/format/2312.08903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attestation with Constrained Relying Party
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moustafa%2C+M">Mariam Moustafa</a>, 
<a href="/search/cs?searchtype=author&query=Niemi%2C+A">Arto Niemi</a>, 
<a href="/search/cs?searchtype=author&query=Ginzboorg%2C+P">Philip Ginzboorg</a>, 
<a href="/search/cs?searchtype=author&query=Ekberg%2C+J">Jan-Erik Ekberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Allowing a compromised device to receive privacy-sensitive sensor readings,
or to operate a safety-critical actuator, carries significant risk. Usually,
such risks are mitigated by validating the device's security state with remote
attestation, but current remote attestation protocols are not suitable when the
beneficiary of attestation, the relying party, is a constrained device such as
a small sensor or actuator. These devices typically lack the power and memory
to operate public-key cryptography needed by such protocols, and may only be
able to communicate with devices in their physical proximity, such as with the
controller whose security state they wish to evaluate. In this paper, we
present a remote platform attestation protocol suitable for relying parties
that are limited to symmetric-key cryptography and a single communication
channel. We show that our protocol, including the needed cryptography and
message processing, can be implemented with a code size of 6 KB and validate
its security via model checking with the ProVerif tool.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08906" title="Abstract">arXiv:2312.08906</a> [<a href="/pdf/2312.08906" title="Download PDF">pdf</a>, <a href="/format/2312.08906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using eye tracking to investigate what native Chinese speakers notice  about linguistic landscape images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zichao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yewei Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Linguistic landscape is an important field in sociolinguistic research. Eye
tracking technology is a common technology in psychological research. There are
few cases of using eye movement to study linguistic landscape. This paper uses
eye tracking technology to study the actual fixation of the linguistic
landscape and finds that in the two dimensions of fixation time and fixation
times, the fixation of native Chinese speakers to the linguistic landscape is
higher than that of the general landscape. This paper argues that this
phenomenon is due to the higher information density of linguistic landscapes.
At the same time, the article also discusses other possible reasons for this
phenomenon.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08912" title="Abstract">arXiv:2312.08912</a> [<a href="/pdf/2312.08912" title="Download PDF">pdf</a>, <a href="/format/2312.08912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Distillation via Adversarial Prediction Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junda Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Minhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dataset distillation is the technique of synthesizing smaller condensed
datasets from large original datasets while retaining necessary information to
persist the effect. In this paper, we approach the dataset distillation problem
from a novel perspective: we regard minimizing the prediction discrepancy on
the real data distribution between models, which are respectively trained on
the large original dataset and on the small distilled dataset, as a conduit for
condensing information from the raw data into the distilled version. An
adversarial framework is proposed to solve the problem efficiently. In contrast
to existing distillation methods involving nested optimization or long-range
gradient unrolling, our approach hinges on single-level optimization. This
ensures the memory efficiency of our method and provides a flexible tradeoff
between time and memory budgets, allowing us to distil ImageNet-1K using a
minimum of only 6.5GB of GPU memory. Under the optimal tradeoff strategy, it
requires only 2.5$\times$ less memory and 5$\times$ less runtime compared to
the state-of-the-art. Empirically, our method can produce synthetic datasets
just 10% the size of the original, yet achieve, on average, 94% of the test
accuracy of models trained on the full original datasets including ImageNet-1K,
significantly surpassing state-of-the-art. Additionally, extensive tests reveal
that our distilled datasets excel in cross-architecture generalization
capabilities.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08914" title="Abstract">arXiv:2312.08914</a> [<a href="/pdf/2312.08914" title="Download PDF">pdf</a>, <a href="/format/2312.08914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogAgent: A Visual Language Model for GUI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+W">Wenyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qingsong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiazheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenmeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junhui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">People are spending an enormous amount of time on digital devices through
graphical user interfaces (GUIs), e.g., computer or smartphone screens. Large
language models (LLMs) such as ChatGPT can assist people in tasks like writing
emails, but struggle to understand and interact with GUIs, thus limiting their
potential to increase automation levels. In this paper, we introduce CogAgent,
an 18-billion-parameter visual language model (VLM) specializing in GUI
understanding and navigation. By utilizing both low-resolution and
high-resolution image encoders, CogAgent supports input at a resolution of
1120*1120, enabling it to recognize tiny page elements and text. As a
generalist visual language model, CogAgent achieves the state of the art on
five text-rich and four general VQA benchmarks, including VQAv2, OK-VQA,
Text-VQA, ST-VQA, ChartQA, infoVQA, DocVQA, MM-Vet, and POPE. CogAgent, using
only screenshots as input, outperforms LLM-based methods that consume extracted
HTML text on both PC and Android GUI navigation tasks -- Mind2Web and AITW,
advancing the state of the art. The model and codes are available at
\url{https://github.com/THUDM/CogVLM}.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08916" title="Abstract">arXiv:2312.08916</a> [<a href="/pdf/2312.08916" title="Download PDF">pdf</a>, <a href="/format/2312.08916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Uncertain Feature Self-reinforcement for Weakly Supervised  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chaowei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zunlei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tingting Mu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Compared to conventional semantic segmentation with pixel-level supervision,
Weakly Supervised Semantic Segmentation (WSSS) with image-level labels poses
the challenge that it always focuses on the most discriminative regions,
resulting in a disparity between fully supervised conditions. A typical
manifestation is the diminished precision on the object boundaries, leading to
a deteriorated accuracy of WSSS. To alleviate this issue, we propose to
adaptively partition the image content into deterministic regions (e.g.,
confident foreground and background) and uncertain regions (e.g., object
boundaries and misclassified categories) for separate processing. For uncertain
cues, we employ an activation-based masking strategy and seek to recover the
local information with self-distilled knowledge. We further assume that the
unmasked confident regions should be robust enough to preserve the global
semantics. Building upon this, we introduce a complementary self-enhancement
method that constrains the semantic consistency between these confident regions
and an augmented image with the same class labels. Extensive experiments
conducted on PASCAL VOC 2012 and MS COCO 2014 demonstrate that our proposed
single-stage approach for WSSS not only outperforms state-of-the-art benchmarks
remarkably but also surpasses multi-stage methodologies that trade complexity
for accuracy. The code can be found at
https://github.com/Jessie459/feature-self-reinforcement.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08917" title="Abstract">arXiv:2312.08917</a> [<a href="/pdf/2312.08917" title="Download PDF">pdf</a>, <a href="/format/2312.08917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Incremental Unified Framework for Small Defect Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruizheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sixing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T+W">Tsz Wa Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+M">Ming Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tsung%2C+F">Fugee Tsung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence (AI)-driven defect inspection is pivotal in
industrial manufacturing. Yet, many methods, tailored to specific pipelines,
grapple with diverse product portfolios and evolving processes. Addressing
this, we present the Incremental Unified Framework (IUF) that can reduce the
feature conflict problem when continuously integrating new objects in the
pipeline, making it advantageous in object-incremental learning scenarios.
Employing a state-of-the-art transformer, we introduce Object-Aware
Self-Attention (OASA) to delineate distinct semantic boundaries. Semantic
Compression Loss (SCL) is integrated to optimize non-primary semantic space,
enhancing network adaptability for novel objects. Additionally, we prioritize
retaining the features of established objects during weight updates.
Demonstrating prowess in both image and pixel-level defect inspection, our
approach achieves state-of-the-art performance, proving indispensable for
dynamic and scalable industrial inspections. Our code will be released at
https://github.com/jqtangust/IUF.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08924" title="Abstract">arXiv:2312.08924</a> [<a href="/pdf/2312.08924" title="Download PDF">pdf</a>, <a href="/format/2312.08924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-free Zero-shot Composed Image Retrieval with Local Concept  Reranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fanghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Composed image retrieval attempts to retrieve an image of interest from
gallery images through a composed query of a reference image and its
corresponding modified text. It has recently attracted attention due to the
collaboration of information-rich images and concise language to precisely
express the requirements of target images. Most of the existing composed image
retrieval methods follow a supervised learning paradigm to perform training on
a costly triplet dataset composed of a reference image, modified text, and a
corresponding target image. To alleviate the demand for difficult-to-obtain
labeled triplet data, recent methods have introduced zero-shot composed image
retrieval (ZS-CIR), which aims to retrieve the target image without the
supervision of human-labeled triplets but instead relies on image-text pairs or
self-generated triplets. However, these methods are less computationally
efficient due to the requirement of training and also less understandable,
assuming that the interaction between image and text is conducted with implicit
query embedding. In this work, we present a new Training-Free zero-shot
Composed Image Retrieval (TFCIR) method which translates the query into
explicit human-understandable text. This helps improve computation efficiency
while maintaining the generalization of foundation models. Further, we
introduce a Local Concept Reranking (LCR) mechanism to focus on discriminative
local information extracted from the modified instruction. Extensive
experiments on three ZS-CIR benchmarks show that the proposed approach can
achieve comparable performances with state-of-the-art methods and significantly
outperforms other training-free methods on the open domain datasets, CIRR and
CIRCO, as well as the fashion domain dataset, FashionIQ.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08926" title="Abstract">arXiv:2312.08926</a> [<a href="/pdf/2312.08926" title="Download PDF">pdf</a>, <a href="/format/2312.08926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Complex Mathematical Reasoning via Large Language Model based  MathAgent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haoran Liao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qinyi Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shaohua Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jidong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) face challenges in solving complex mathematical
problems that require comprehensive capacities to parse the statements,
associate domain knowledge, perform compound logical reasoning, and integrate
the intermediate rationales. Tackling all these problems once could be arduous
for LLMs, thus leading to confusion in generation. In this work, we explore the
potential of enhancing LLMs with agents by meticulous decomposition and
modeling of mathematical reasoning process. Specifically, we propose a formal
description of the mathematical solving and extend LLMs with an agent-based
zero-shot framework named
$\bf{P}$lanner-$\bf{R}$easoner-$\bf{E}$xecutor-$\bf{R}$eflector (PRER). We
further provide and implement two MathAgents that define the logical forms and
inherent relations via a pool of actions in different grains and orientations:
MathAgent-M adapts its actions to LLMs, while MathAgent-H aligns with
humankind. Experiments on miniF2F and MATH have demonstrated the effectiveness
of PRER and proposed MathAgents, achieving an increase of
$12.3\%$($53.9\%\xrightarrow{}66.2\%$) on the MiniF2F, $9.2\%$
($49.8\%\xrightarrow{}59.0\%$) on MATH, and
$13.2\%$($23.2\%\xrightarrow{}35.4\%$) for level-5 problems of MATH against
GPT-4. Further analytical results provide more insightful perspectives on
exploiting the behaviors of LLMs as agents.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08931" title="Abstract">arXiv:2312.08931</a> [<a href="/pdf/2312.08931" title="Download PDF">pdf</a>, <a href="/format/2312.08931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> N-Gram Unsupervised Compoundation and Feature Injection for Better  Symbolic Music Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinhao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiajia Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, aaai2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The first step to apply deep learning techniques for symbolic music
understanding is to transform musical pieces (mainly in MIDI format) into
sequences of predefined tokens like note pitch, note velocity, and chords.
Subsequently, the sequences are fed into a neural sequence model to accomplish
specific tasks. Music sequences exhibit strong correlations between adjacent
elements, making them prime candidates for N-gram techniques from Natural
Language Processing (NLP). Consider classical piano music: specific melodies
might recur throughout a piece, with subtle variations each time. In this
paper, we propose a novel method, NG-Midiformer, for understanding symbolic
music sequences that leverages the N-gram approach. Our method involves first
processing music pieces into word-like sequences with our proposed unsupervised
compoundation, followed by using our N-gram Transformer encoder, which can
effectively incorporate N-gram information to enhance the primary encoder part
for better understanding of music sequences. The pre-training process on
large-scale music datasets enables the model to thoroughly learn the N-gram
information contained within music sequences, and subsequently apply this
information for making inferences during the fine-tuning stage. Experiment on
various datasets demonstrate the effectiveness of our method and achieved
state-of-the-art performance on a series of music understanding downstream
tasks. The code and model weights will be released at
https://github.com/WouuYoauin/NG-Midiformer.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08932" title="Abstract">arXiv:2312.08932</a> [<a href="/pdf/2312.08932" title="Download PDF">pdf</a>, <a href="/format/2312.08932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence of Prompting Strategies on Segment Anything Model (SAM) for  Short-axis Cardiac MRI segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Josh Stein</a>, 
<a href="/search/cs?searchtype=author&query=Di+Folco%2C+M">Maxime Di Folco</a>, 
<a href="/search/cs?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Segment Anything Model (SAM) has recently emerged as a significant
breakthrough in foundation models, demonstrating remarkable zero-shot
performance in object segmentation tasks. While SAM is designed for
generalization, it exhibits limitations in handling specific medical imaging
tasks that require fine-structure segmentation or precise boundaries. In this
paper, we focus on the task of cardiac magnetic resonance imaging (cMRI)
short-axis view segmentation using the SAM foundation model. We conduct a
comprehensive investigation of the impact of different prompting strategies
(including bounding boxes, positive points, negative points, and their
combinations) on segmentation performance. We evaluate on two public datasets
using the baseline model and models fine-tuned with varying amounts of
annotated data, ranging from a limited number of volumes to a fully annotated
dataset. Our findings indicate that prompting strategies significantly
influence segmentation performance. Combining positive points with either
bounding boxes or negative points shows substantial benefits, but little to no
benefit when combined simultaneously. We further observe that fine-tuning SAM
with a few annotated volumes improves segmentation performance when properly
prompted. Specifically, fine-tuning with bounding boxes has a positive impact,
while fine-tuning without bounding boxes leads to worse results compared to
baseline.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08933" title="Abstract">arXiv:2312.08933</a> [<a href="/pdf/2312.08933" title="Download PDF">pdf</a>, <a href="/format/2312.08933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Learning-based Reconstruction of High-Resolution Spatial  Wind Speed Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zambra%2C+M">Matteo Zambra</a>, 
<a href="/search/cs?searchtype=author&query=Farrugia%2C+N">Nicolas Farrugia</a>, 
<a href="/search/cs?searchtype=author&query=Cazau%2C+D">Dorian Cazau</a>, 
<a href="/search/cs?searchtype=author&query=Gensse%2C+A">Alexandre Gensse</a>, 
<a href="/search/cs?searchtype=author&query=Fablet%2C+R">Ronan Fablet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures. This work is to be submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Wind speed at sea surface is a key quantity for a variety of scientific
applications and human activities. Due to the non-linearity of the phenomenon,
a complete description of such variable is made infeasible on both the small
scale and large spatial extents. Methods relying on Data Assimilation
techniques, despite being the state-of-the-art for Numerical Weather
Prediction, can not provide the reconstructions with a spatial resolution that
can compete with satellite imagery. In this work we propose a framework based
on Variational Data Assimilation and Deep Learning concepts. This framework is
applied to recover rich-in-time, high-resolution information on sea surface
wind speed. We design our experiments using synthetic wind data and different
sampling schemes for high-resolution and low-resolution versions of original
data to emulate the real-world scenario of spatio-temporally heterogeneous
observations. Extensive numerical experiments are performed to assess
systematically the impact of low and high-resolution wind fields and in-situ
observations on the model reconstruction performance. We show that in-situ
observations with richer temporal resolution represent an added value in terms
of the model reconstruction performance. We show how a multi-modal approach,
that explicitly informs the model about the heterogeneity of the available
observations, can improve the reconstruction task by exploiting the
complementary information in spatial and local point-wise data. To conclude, we
propose an analysis to test the robustness of the chosen framework against
phase delay and amplitude biases in low-resolution data and against
interruptions of in-situ observations supply at evaluation time
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08935" title="Abstract">arXiv:2312.08935</a> [<a href="/pdf/2312.08935" title="Download PDF">pdf</a>, <a href="/format/2312.08935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in  Mathematical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhihong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R+X">R.X. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Damai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Y.Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Large Language Models; Mathematical Reasoning; Process Reward Models; Automatic Process Supervision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks. However, even the most advanced open-source LLMs, such
as the LLaMA family models, still face challenges when it comes to accurately
solving complex multi-step mathematical problems. In this paper, we present an
innovative process-oriented math verifier called \textbf{Math-Shepherd}, which
assigns a reward score to each step of the LLM's outputs on math problems. The
training of Math-Shepherd is achieved using automatically constructed
process-wise supervision data, breaking the bottleneck of heavy reliance on
manual annotation in existing work. With the guidance of Math-Shepherd, a
series of open-source LLMs demonstrate exceptional performance. Among them,
DeepSeek 67B \citep{DeepSeek-llm} stands out by achieving accuracy rates of
93.3\% on the GSM8K dataset and 48.1\% on the MATH dataset, without external
enhancement such as tool usage. Our Math-Shepherd also outperforms the
self-consistency method and other existing verification models. We believe that
automatic process supervision holds significant potential for the future
evolution of LLMs.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08937" title="Abstract">arXiv:2312.08937</a> [<a href="/pdf/2312.08937" title="Download PDF">pdf</a>, <a href="/format/2312.08937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiPFT: Binary Pre-trained Foundation Transformer with Low-rank  Estimation of Binarization Residual Polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianlin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pretrained foundation models offer substantial benefits for a wide range of
downstream tasks, which can be one of the most potential techniques to access
artificial general intelligence. However, scaling up foundation transformers
for maximal task-agnostic knowledge has brought about computational challenges,
especially on resource-limited devices such as mobiles. This work proposes the
first Binary Pretrained Foundation Transformer (BiPFT) for natural language
understanding (NLU) tasks, which remarkably saves 56 times operations and 28
times memory. In contrast to previous task-specific binary transformers, BiPFT
exhibits a substantial enhancement in the learning capabilities of binary
neural networks (BNNs), promoting BNNs into the era of pre-training. Benefiting
from extensive pretraining data, we further propose a data-driven binarization
method. Specifically, we first analyze the binarization error in self-attention
operations and derive the polynomials of binarization error. To simulate
full-precision self-attention, we define binarization error as binarization
residual polynomials, and then introduce low-rank estimators to model these
polynomials. Extensive experiments validate the effectiveness of BiPFTs,
surpassing task-specific baseline by 15.4% average performance on the GLUE
benchmark. BiPFT also demonstrates improved robustness to hyperparameter
changes, improved optimization efficiency, and reduced reliance on downstream
distillation, which consequently generalize on various NLU tasks and simplify
the downstream pipeline of BNNs. Our code and pretrained models are publicly
available at https://github.com/Xingrun-Xing/BiPFT.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08939" title="Abstract">arXiv:2312.08939</a> [<a href="/pdf/2312.08939" title="Download PDF">pdf</a>, <a href="/format/2312.08939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAT: Towards Long-Tailed Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo-Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min-Ling Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite recent advancements in out-of-distribution (OOD) detection, most
current studies assume a class-balanced in-distribution training dataset, which
is rarely the case in real-world scenarios. This paper addresses the
challenging task of long-tailed OOD detection, where the in-distribution data
follows a long-tailed class distribution. The main difficulty lies in
distinguishing OOD data from samples belonging to the tail classes, as the
ability of a classifier to detect OOD instances is not strongly correlated with
its accuracy on the in-distribution classes. To overcome this issue, we propose
two simple ideas: (1) Expanding the in-distribution class space by introducing
multiple abstention classes. This approach allows us to build a detector with
clear decision boundaries by training on OOD data using virtual labels. (2)
Augmenting the context-limited tail classes by overlaying images onto the
context-rich OOD data. This technique encourages the model to pay more
attention to the discriminative features of the tail classes. We provide a clue
for separating in-distribution and OOD data by analyzing gradient noise.
Through extensive experiments, we demonstrate that our method outperforms the
current state-of-the-art on various benchmark datasets. Moreover, our method
can be used as an add-on for existing long-tail learning approaches,
significantly enhancing their OOD detection performance. Code is available at:
https://github.com/Stomach-ache/Long-Tailed-OOD-Detection .
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08944" title="Abstract">arXiv:2312.08944</a> [<a href="/pdf/2312.08944" title="Download PDF">pdf</a>, <a href="/format/2312.08944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s Next? Predicting Hamiltonian Dynamics from Discrete Observations  of a Vector Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoo%2C+Z">Zi-Yu Khoo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Delong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bressan%2C+S">St&#xe9;phane Bressan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> longer version of the submitted and accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">We present several methods for predicting the dynamics of Hamiltonian systems
from discrete observations of their vector field. Each method is either
informed or uninformed of the Hamiltonian property. We empirically and
comparatively evaluate the methods and observe that information that the system
is Hamiltonian can be effectively informed, and that different methods strike
different trade-offs between efficiency and effectiveness for different
dynamical systems.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08945" title="Abstract">arXiv:2312.08945</a> [<a href="/pdf/2312.08945" title="Download PDF">pdf</a>, <a href="/format/2312.08945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gas Cost Analysis of Proxy and Diamond Patterns: Towards Trusted Smart  Contract Engineering in EVM Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anto%2C+B">Benedetti Anto</a>, 
<a href="/search/cs?searchtype=author&query=Tiphaine%2C+H">Henry Tiphaine</a>, 
<a href="/search/cs?searchtype=author&query=Sara%2C+T">Tucci-Piergiovanni Sara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Blockchain applications are witnessing rapid evolution, necessitating the
integration of upgradeable smart contracts. Software patterns have been
proposed to summarize upgradeable smart contract best practices. However,
research is missing on the comparison of these upgradeable smart contract
patterns, especially regarding gas costs related to deployment and execution.
This study aims to provide an in-depth analysis of gas costs associated with
two prevalent upgradeable smart contract patterns: the Proxy and diamond
patterns. The Proxy pattern utilizes a Proxy pointing to a logic contract,
while the diamond pattern enables a Proxy to point to multiple logic contracts.
We conduct a comparative analysis of gas costs for both patterns in contrast to
a traditional non-upgradeable smart contract. We derive from this analysis a
theoretical contribution in the form of two consolidated blockchain patterns
and a corresponding decision model. By so doing we hope to contribute to the
broader understanding of upgradeable smart contract patterns.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08948" title="Abstract">arXiv:2312.08948</a> [<a href="/pdf/2312.08948" title="Download PDF">pdf</a>, <a href="/ps/2312.08948" title="Download PostScript">ps</a>, <a href="/format/2312.08948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSTM Network Analysis of Vehicle-Type Fatalities on Great Britain&#x27;s  Roads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>, 
<a href="/search/cs?searchtype=author&query=Hanify%2C+J">James Hanify</a>, 
<a href="/search/cs?searchtype=author&query=Heffron-Smith%2C+S">Salter Heffron-Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">This study harnesses the predictive capabilities of Long Short-Term Memory
(LSTM) networks to analyse and predict road traffic accidents in Great Britain.
It addresses the challenge of traffic accident forecasting, which is paramount
for devising effective preventive measures. We utilised an extensive dataset
encompassing reported collisions, casualties, and vehicles involvements from
1926 to 2022, provided by the Department for Transport (DfT). The data
underwent stringent processing to rectify missing values and normalise
features, ensuring robust LSTM network input.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08950" title="Abstract">arXiv:2312.08950</a> [<a href="/pdf/2312.08950" title="Download PDF">pdf</a>, <a href="/format/2312.08950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Active Attacks in Over-the-Air Computation using Dummy Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nordlund%2C+D">David Nordlund</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, presented at 57:th Annual Asilomar Conference on Signals, Systems, and Computers, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Over-the-Air (OtA) computation is a newly emerged concept for computing
functions of data from distributed nodes by taking advantage of the wave
superposition property of wireless channels. Despite its advantage in
communication efficiency, OtA computation is associated with significant
security and privacy concerns that have so far not been thoroughly
investigated, especially in the case of active attacks. In this paper, we
propose and evaluate a detection scheme against active attacks in OtA
computation systems. More explicitly, we consider an active attacker which is
an external node sending random or misleading data to alter the aggregated data
received by the server. To detect the presence of the attacker, in every
communication period, legitimate users send some dummy samples in addition to
the real data. We propose a detector design that relies on the existence of a
shared secret only known by the legitimate users and the server, that can be
used to hide the transmitted signal in a secret subspace. After the server
projects the received vector back to the original subspace, the dummy samples
can be used to detect active attacks. We show that this design achieves good
detection performance for a small cost in terms of channel resources.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08951" title="Abstract">arXiv:2312.08951</a> [<a href="/pdf/2312.08951" title="Download PDF">pdf</a>, <a href="/format/2312.08951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scene Generalized Trajectory Global Graph Solver with Composite  Nodes for Multiple Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haojun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The global multi-object tracking (MOT) system can consider interaction,
occlusion, and other ``visual blur'' scenarios to ensure effective object
tracking in long videos. Among them, graph-based tracking-by-detection
paradigms achieve surprising performance. However, their fully-connected nature
poses storage space requirements that challenge algorithm handling long videos.
Currently, commonly used methods are still generated trajectories by building
one-forward associations across frames. Such matches produced under the
guidance of first-order similarity information may not be optimal from a
longer-time perspective. Moreover, they often lack an end-to-end scheme for
correcting mismatches. This paper proposes the Composite Node Message Passing
Network (CoNo-Link), a multi-scene generalized framework for modeling
ultra-long frames information for association. CoNo-Link's solution is a
low-storage overhead method for building constrained connected graphs. In
addition to the previous method of treating objects as nodes, the network
innovatively treats object trajectories as nodes for information interaction,
improving the graph neural network's feature representation capability.
Specifically, we formulate the graph-building problem as a top-k selection task
for some reliable objects or trajectories. Our model can learn better
predictions on longer-time scales by adding composite nodes. As a result, our
method outperforms the state-of-the-art in several commonly used datasets.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08952" title="Abstract">arXiv:2312.08952</a> [<a href="/pdf/2312.08952" title="Download PDF">pdf</a>, <a href="/format/2312.08952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCMCTrack: Multi-Object Tracking with Uniform Camera Motion Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kefu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+K">Kai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaolei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiangui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rongdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Wei Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-object tracking (MOT) in video sequences remains a challenging task,
especially in scenarios with significant camera movements. This is because
targets can drift considerably on the image plane, leading to erroneous
tracking outcomes. Addressing such challenges typically requires supplementary
appearance cues or Camera Motion Compensation (CMC). While these strategies are
effective, they also introduce a considerable computational burden, posing
challenges for real-time MOT. In response to this, we introduce UCMCTrack, a
novel motion model-based tracker robust to camera movements. Unlike
conventional CMC that computes compensation parameters frame-by-frame,
UCMCTrack consistently applies the same compensation parameters throughout a
video sequence. It employs a Kalman filter on the ground plane and introduces
the Mapped Mahalanobis Distance (MMD) as an alternative to the traditional
Intersection over Union (IoU) distance measure. By leveraging projected
probability distributions on the ground plane, our approach efficiently
captures motion patterns and adeptly manages uncertainties introduced by
homography projections. Remarkably, UCMCTrack, relying solely on motion cues,
achieves state-of-the-art performance across a variety of challenging datasets,
including MOT17, MOT20, DanceTrack and KITTI, with an exceptional speed of over
1000 FPS on a single CPU. More details and code are available at
https://github.com/corfyi/UCMCTrack
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08953" title="Abstract">arXiv:2312.08953</a> [<a href="/pdf/2312.08953" title="Download PDF">pdf</a>, <a href="/format/2312.08953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single and Multi-Objective Benchmark Problems Focusing on Human-Powered  Aircraft Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namura%2C+N">Nobuo Namura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper introduces a novel set of benchmark problems aimed at advancing
research in both single and multi-objective optimization, with a specific focus
on the design of human-powered aircraft (HPA). These benchmark problems are
unique in that they incorporate real-world design considerations such as fluid
dynamics and material mechanics, providing a more realistic simulation of
engineering design optimization. We propose three difficulty levels and a wing
segmentation parameter in these problems, allowing for scalable complexity to
suit various research needs. The problems are designed to be computationally
reasonable, ensuring short evaluation times, while still capturing the moderate
multimodality of engineering design problems. Our extensive experiments using
popular evolutionary algorithms for multi-objective problems demonstrate that
the proposed benchmarks effectively replicate the diverse Pareto front shapes
observed in real-world problems, including convex, linear, concave, and
degenerated forms. The benchmarks and their Python source codes are made
publicly available for broader use in the optimization research community.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08957" title="Abstract">arXiv:2312.08957</a> [<a href="/pdf/2312.08957" title="Download PDF">pdf</a>, <a href="/format/2312.08957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceptance and Trust: Drivers&#x27; First Contact with Released Automated  Vehicles in Naturalistic Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwindt-Drews%2C+S">Sarah Schwindt-Drews</a>, 
<a href="/search/cs?searchtype=author&query=Storms%2C+K">Kai Storms</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+S">Steven Peters</a>, 
<a href="/search/cs?searchtype=author&query=Abendroth%2C+B">Bettina Abendroth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This study investigates the impact of initial contact of drivers with an SAE
Level 3 Automated Driving System (ADS) under real traffic conditions, focusing
on the Mercedes-Benz Drive Pilot in the EQS. It examines Acceptance, Trust,
Usability, and User Experience. Although previous studies in simulated
environments provided insights into human-automation interaction, real-world
experiences can differ significantly. The research was conducted on a segment
of German interstate with 30 participants lacking familiarity with Level 3 ADS.
Pre- and post-driving questionnaires were used to assess changes in acceptance
and confidence. Supplementary metrics included post-driving ratings for
usability and user experience. Findings reveal a significant increase in
acceptance and trust following the first contact, confirming results from prior
simulator studies. Factors such as Performance Expectancy, Effort Expectancy,
Facilitating Condition, Self-Efficacy, and Behavioral Intention to use the
vehicle were rated higher after initial contact with the ADS. However,
inadequate communication from the ADS to the human driver was detected,
highlighting the need for improved communication to prevent misuse or confusion
about the operating mode. Contrary to prior research, we found no significant
impact of general attitudes towards technological innovation on acceptance and
trust. However, it's worth noting that most participants already had a high
affinity for technology. Although overall reception was positive and showed an
upward trend post first contact, the ADS was also perceived as demanding as
manual driving. Future research should focus on a more diverse participant
sample and include longer or multiple real-traffic trips to understand
behavioral adaptations over time.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08958" title="Abstract">arXiv:2312.08958</a> [<a href="/pdf/2312.08958" title="Download PDF">pdf</a>, <a href="/format/2312.08958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiFT: Unsupervised Reinforcement Learning with Foundation Models as  Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+T">Taewook Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juyong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jesse Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+J">Joseph J. Lim</a>, 
<a href="/search/cs?searchtype=author&query=Pertsch%2C+K">Karl Pertsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2nd Workshop on Agent Learning in Open-Endedness (ALOE) at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We propose a framework that leverages foundation models as teachers, guiding
a reinforcement learning agent to acquire semantically meaningful behavior
without human feedback. In our framework, the agent receives task instructions
grounded in a training environment from large language models. Then, a
vision-language model guides the agent in learning the multi-task
language-conditioned policy by providing reward feedback. We demonstrate that
our method can learn semantically meaningful skills in a challenging open-ended
MineDojo environment while prior unsupervised skill discovery methods struggle.
Additionally, we discuss observed challenges of using off-the-shelf foundation
models as teachers and our efforts to address them.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08960" title="Abstract">arXiv:2312.08960</a> [<a href="/pdf/2312.08960" title="Download PDF">pdf</a>, <a href="/format/2312.08960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DenRAM: Neuromorphic Dendritic Architecture with RRAM for Efficient  Temporal Processing with Delays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DAgostino%2C+S">Simone DAgostino</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+F">Filippo Moro</a>, 
<a href="/search/cs?searchtype=author&query=Torchet%2C+T">Tristan Torchet</a>, 
<a href="/search/cs?searchtype=author&query=Demirag%2C+Y">Yigit Demirag</a>, 
<a href="/search/cs?searchtype=author&query=Grenouillet%2C+L">Laurent Grenouillet</a>, 
<a href="/search/cs?searchtype=author&query=Indiveri%2C+G">Giacomo Indiveri</a>, 
<a href="/search/cs?searchtype=author&query=Vianello%2C+E">Elisa Vianello</a>, 
<a href="/search/cs?searchtype=author&query=Payvand%2C+M">Melika Payvand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">An increasing number of neuroscience studies are highlighting the importance
of spatial dendritic branching in pyramidal neurons in the brain for supporting
non-linear computation through localized synaptic integration. In particular,
dendritic branches play a key role in temporal signal processing and feature
detection, using coincidence detection (CD) mechanisms, made possible by the
presence of synaptic delays that align temporally disparate inputs for
effective integration. Computational studies on spiking neural networks further
highlight the significance of delays for CD operations, enabling
spatio-temporal pattern recognition within feed-forward neural networks without
the need for recurrent architectures. In this work, we present DenRAM, the
first realization of a spiking neural network with analog dendritic circuits,
integrated into a 130nm technology node coupled with resistive memory (RRAM)
technology. DenRAM's dendritic circuits use the RRAM devices to implement both
delays and synaptic weights in the network. By configuring the RRAM devices to
reproduce bio-realistic timescales, and through exploiting their heterogeneity,
we experimentally demonstrate DenRAM's capability to replicate synaptic delay
profiles, and efficiently implement CD for spatio-temporal pattern recognition.
To validate the architecture, we conduct comprehensive system-level simulations
on two representative temporal benchmarks, highlighting DenRAM's resilience to
analog hardware noise, and its superior accuracy compared to recurrent
architectures with an equivalent number of parameters. DenRAM not only brings
rich temporal processing capabilities to neuromorphic architectures, but also
reduces the memory footprint of edge devices, provides high accuracy on
temporal benchmarks, and represents a significant step-forward in low-power
real-time signal processing technologies.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08961" title="Abstract">arXiv:2312.08961</a> [<a href="/pdf/2312.08961" title="Download PDF">pdf</a>, <a href="/format/2312.08961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contact-Implicit MPC: Controlling Diverse Quadruped Motions Without  Pre-Planned Contact Modes or Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gijeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joon-Ha Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seungwoo Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hae-Won Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 19 figures, submitted to International Journal of Robotics Research (IJRR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a contact-implicit model predictive control (MPC)
framework for the real-time discovery of multi-contact motions, without
predefined contact mode sequences or foothold positions. This approach utilizes
the contact-implicit differential dynamic programming (DDP) framework, merging
the hard contact model with a linear complementarity constraint. We propose the
analytical gradient of the contact impulse based on relaxed complementarity
constraints to further the exploration of a variety of contact modes. By
leveraging a hard contact model-based simulation and computation of search
direction through a smooth gradient, our methodology identifies dynamically
feasible state trajectories, control inputs, and contact forces while
simultaneously unveiling new contact mode sequences. However, the broadened
scope of contact modes does not always ensure real-world applicability.
Recognizing this, we implemented differentiable cost terms to guide foot
trajectories and make gait patterns. Furthermore, to address the challenge of
unstable initial roll-outs in an MPC setting, we employ the multiple shooting
variant of DDP. The efficacy of the proposed framework is validated through
simulations and real-world demonstrations using a 45 kg HOUND quadruped robot,
performing various tasks in simulation and showcasing actual experiments
involving a forward trot and a front-leg rearing motion.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08962" title="Abstract">arXiv:2312.08962</a> [<a href="/pdf/2312.08962" title="Download PDF">pdf</a>, <a href="/format/2312.08962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depicting Beyond Scores: Advancing Image Quality Assessment through  Multi-modal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Z">Zhiyuan You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a Depicted image Quality Assessment method (DepictQA),
overcoming the constraints of traditional score-based approaches. DepictQA
leverages Multi-modal Large Language Models (MLLMs), allowing for detailed,
language-based, human-like evaluation of image quality. Unlike conventional
Image Quality Assessment (IQA) methods relying on scores, DepictQA interprets
image content and distortions descriptively and comparatively, aligning closely
with humans' reasoning process. To build the DepictQA model, we establish a
hierarchical task framework, and collect a multi-modal IQA training dataset,
named M-BAPPS. To navigate the challenges in limited training data and
processing multiple images, we propose to use multi-source training data and
specialized image tags. Our DepictQA demonstrates a better performance than
score-based methods on the BAPPS benchmark. Moreover, compared with general
MLLMs, our DepictQA can generate more accurate reasoning descriptive languages.
Our research indicates that language-based IQA methods have the potential to be
customized for individual preferences. Datasets and codes will be released
publicly.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08963" title="Abstract">arXiv:2312.08963</a> [<a href="/pdf/2312.08963" title="Download PDF">pdf</a>, <a href="/format/2312.08963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEMON: Learning 3D Human-Object Interaction Relation from 2D Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+W">Wei Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hongchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning 3D human-object interaction relation is pivotal to embodied AI and
interaction modeling. Most existing methods approach the goal by learning to
predict isolated interaction elements, e.g., human contact, object affordance,
and human-object spatial relation, primarily from the perspective of either the
human or the object. Which underexploit certain correlations between the
interaction counterparts (human and object), and struggle to address the
uncertainty in interactions. Actually, objects' functionalities potentially
affect humans' interaction intentions, which reveals what the interaction is.
Meanwhile, the interacting humans and objects exhibit matching geometric
structures, which presents how to interact. In light of this, we propose
harnessing these inherent correlations between interaction counterparts to
mitigate the uncertainty and jointly anticipate the above interaction elements
in 3D space. To achieve this, we present LEMON (LEarning 3D huMan-Object
iNteraction relation), a unified model that mines interaction intentions of the
counterparts and employs curvatures to guide the extraction of geometric
correlations, combining them to anticipate the interaction elements. Besides,
the 3D Interaction Relation dataset (3DIR) is collected to serve as the test
bed for training and evaluation. Extensive experiments demonstrate the
superiority of LEMON over methods estimating each element in isolation.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08968" title="Abstract">arXiv:2312.08968</a> [<a href="/pdf/2312.08968" title="Download PDF">pdf</a>, <a href="/ps/2312.08968" title="Download PostScript">ps</a>, <a href="/format/2312.08968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting value-expressive text posts in Russian social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milkova%2C+M">Maria Milkova</a>, 
<a href="/search/cs?searchtype=author&query=Rudnev%2C+M">Maksim Rudnev</a>, 
<a href="/search/cs?searchtype=author&query=Okolskaya%2C+L">Lidia Okolskaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Basic values are concepts or beliefs which pertain to desirable end-states
and transcend specific situations. Studying personal values in social media can
illuminate how and why societal values evolve especially when the stimuli-based
methods, such as surveys, are inefficient, for instance, in hard-to-reach
populations. On the other hand, user-generated content is driven by the massive
use of stereotyped, culturally defined speech constructions rather than
authentic expressions of personal values. We aimed to find a model that can
accurately detect value-expressive posts in Russian social media VKontakte. A
training dataset of 5,035 posts was annotated by three experts, 304
crowd-workers and ChatGPT. Crowd-workers and experts showed only moderate
agreement in categorizing posts. ChatGPT was more consistent but struggled with
spam detection. We applied an ensemble of human- and AI-assisted annotation
involving active learning approach, subsequently trained several LLMs and
selected a model based on embeddings from pre-trained fine-tuned rubert-tiny2,
and reached a high quality of value detection with F1 = 0.75 (F1-macro = 0.80).
This model provides a crucial step to a study of values within and between
Russian social media users.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08975" title="Abstract">arXiv:2312.08975</a> [<a href="/pdf/2312.08975" title="Download PDF">pdf</a>, <a href="/format/2312.08975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Mask-based Image Set Desensitization with Recognition Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qilong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Applied Intelligence (APIN), 1-26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In recent years, Deep Neural Networks (DNN) have emerged as a practical
method for image recognition. The raw data, which contain sensitive
information, are generally exploited within the training process. However, when
the training process is outsourced to a third-party organization, the raw data
should be desensitized before being transferred to protect sensitive
information. Although masks are widely applied to hide important sensitive
information, preventing inpainting masked images is critical, which may restore
the sensitive information. The corresponding models should be adjusted for the
masked images to reduce the degradation of the performance for recognition or
classification tasks due to the desensitization of images. In this paper, we
propose a mask-based image desensitization approach while supporting
recognition. This approach consists of a mask generation algorithm and a model
adjustment method. We propose exploiting an interpretation algorithm to
maintain critical information for the recognition task in the mask generation
algorithm. In addition, we propose a feature selection masknet as the model
adjustment method to improve the performance based on the masked images.
Extensive experimentation results based on multiple image datasets reveal
significant advantages (up to 9.34% in terms of accuracy) of our approach for
image desensitization while supporting recognition.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08976" title="Abstract">arXiv:2312.08976</a> [<a href="/pdf/2312.08976" title="Download PDF">pdf</a>, <a href="/format/2312.08976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entity-Augmented Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapkin%2C+A">Anton Shapkin</a>, 
<a href="/search/cs?searchtype=author&query=Litvinov%2C+D">Denis Litvinov</a>, 
<a href="/search/cs?searchtype=author&query=Bryksin%2C+T">Timofey Bryksin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The current state-of-the-art large language models (LLMs) are effective in
generating high-quality text and encapsulating a broad spectrum of world
knowledge. However, these models often hallucinate during generation and are
not designed to utilize external information sources. To enable requests to the
external knowledge bases, also called knowledge grounding, retrieval-augmented
LLMs were introduced. For now, their applications have largely involved Open
Domain Question Answering, Abstractive Question Answering, and such. In this
paper, we broaden the scope of retrieval-augmented LLMs by venturing into a new
task - code generation using external entities. For this task, we collect and
publish a new dataset for project-level code generation, where the model should
reuse functions defined in the project during generation. As we show, existing
retrieval-augmented LLMs fail to assign relevance scores between similar entity
names, and to mitigate it, they expand entity names with description context
and append it to the input. In practice, due to the limited context size they
can not accommodate the indefinitely large context of the whole project. To
solve this issue, we propose a novel end-to-end trainable architecture with an
scalable entity retriever injected directly into the LLM decoder. We
demonstrate that our model can outperform common baselines in several
scenarios, including project-level code generation, as well as Bash and SQL
scripting.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08977" title="Abstract">arXiv:2312.08977</a> [<a href="/pdf/2312.08977" title="Download PDF">pdf</a>, <a href="/format/2312.08977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Ensemble Models Are Strong Continual Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marouf%2C+I+E">Imad Eddine Marouf</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhankar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>, 
<a href="/search/cs?searchtype=author&query=Lathuili%C3%A8re%2C+S">St&#xe9;phane Lathuili&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/IemProg/CoFiMA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, we study the problem of continual learning (CL) where the goal
is to learn a model on a sequence of tasks, such that the data from the
previous tasks becomes unavailable while learning on the current task data. CL
is essentially a balancing act between being able to learn on the new task
(i.e., plasticity) and maintaining the performance on the previously learned
concepts (i.e., stability). With an aim to address the stability-plasticity
trade-off, we propose to perform weight-ensembling of the model parameters of
the previous and current task. This weight-ensembled model, which we call
Continual Model Averaging (or CoMA), attains high accuracy on the current task
by leveraging plasticity, while not deviating too far from the previous weight
configuration, ensuring stability. We also propose an improved variant of CoMA,
named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively
weighs each parameter in the weight ensemble by leveraging the Fisher
information of the weights of the model. Both the variants are conceptually
simple, easy to implement, and effective in attaining state-of-the-art
performance on several standard CL benchmarks.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08978" title="Abstract">arXiv:2312.08978</a> [<a href="/pdf/2312.08978" title="Download PDF">pdf</a>, <a href="/format/2312.08978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Uplink and Downlink EMF Exposure and Coverage in Dense Cellular  Networks: A Stochastic Geometry Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gontier%2C+Q">Quentin Gontier</a>, 
<a href="/search/cs?searchtype=author&query=Wiame%2C+C">Charles Wiame</a>, 
<a href="/search/cs?searchtype=author&query=Wiart%2C+J">Joe Wiart</a>, 
<a href="/search/cs?searchtype=author&query=Horlin%2C+F">Fran&#xe7;ois Horlin</a>, 
<a href="/search/cs?searchtype=author&query=Tsigros%2C+C">Christo Tsigros</a>, 
<a href="/search/cs?searchtype=author&query=Oestges%2C+C">Claude Oestges</a>, 
<a href="/search/cs?searchtype=author&query=De+Doncker%2C+P">Philippe De Doncker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT); Other Statistics (stat.OT)

</div>
<p class="mathjax">Existing studies analyzing electromagnetic field (EMF) exposure in wireless
networks have primarily considered downlink (DL) communications. In the uplink
(UL), the EMF exposure caused by the user's smartphone is usually the only
considered source of radiation, thereby ignoring contributions caused by other
active neighboring devices. In addition, the network coverage and EMF exposure
are typically analyzed independently for both the UL and DL, while a joint
analysis would be necessary to fully understand the network performance. This
paper aims at bridging the resulting gaps by presenting a comprehensive
stochastic geometry framework including the above aspects. The proposed
topology features base stations (BS) modeled via a homogeneous Poisson point
process as well as a user process of type II (with users uniformly distributed
in the Voronoi cell of each BS). In addition to the UL to DL exposure ratio, we
derive joint probability metrics considering the UL and DL coverage and EMF
exposure. These metrics are evaluated in two scenarios considering BS and/or
user densifications. Our numerical results highlight the existence of optimal
node densities maximizing these joint probabilities.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08979" title="Abstract">arXiv:2312.08979</a> [<a href="/pdf/2312.08979" title="Download PDF">pdf</a>, <a href="/ps/2312.08979" title="Download PostScript">ps</a>, <a href="/format/2312.08979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-CMGAN+/+: Leveraging Multi-Objective Speech Quality Metric  Prediction for Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Close%2C+G">George Close</a>, 
<a href="/search/cs?searchtype=author&query=Ravenscroft%2C+W">William Ravenscroft</a>, 
<a href="/search/cs?searchtype=author&query=Hain%2C+T">Thomas Hain</a>, 
<a href="/search/cs?searchtype=author&query=Goetze%2C+S">Stefan Goetze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted @ ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Neural network based approaches to speech enhancement have shown to be
particularly powerful, being able to leverage a data-driven approach to result
in a significant performance gain versus other approaches. Such approaches are
reliant on artificially created labelled training data such that the neural
model can be trained using intrusive loss functions which compare the output of
the model with clean reference speech. Performance of such systems when
enhancing real-world audio often suffers relative to their performance on
simulated test data. In this work, a non-intrusive multi-metric prediction
approach is introduced, wherein a model trained on artificial labelled data
using inference of an adversarially trained metric prediction neural network.
The proposed approach shows improved performance versus state-of-the-art
systems on the recent CHiME-7 challenge \ac{UDASE} task evaluation sets.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08981" title="Abstract">arXiv:2312.08981</a> [<a href="/pdf/2312.08981" title="Download PDF">pdf</a>, <a href="/format/2312.08981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Noisy Keys for Obfuscation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dickens%2C+C">Charlie Dickens</a>, 
<a href="/search/cs?searchtype=author&query=Bax%2C+E">Eric Bax</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Data sketching has emerged as a key infrastructure for large-scale data
analysis on streaming and distributed data. Merging sketches enables efficient
estimation of cardinalities and frequency histograms over distributed data.
However, merging sketches can require that each sketch stores hash codes for
identifiers in different data sets or partitions, in order to perform effective
matching. This can reveal identifiers during merging or across different data
set or partition owners. This paper presents a framework to use noisy hash
codes, with the noise level selected to obfuscate identifiers while allowing
matching, with high probability. We give probabilistic error bounds on
simultaneous obfuscation and matching, concluding that this is a viable
approach.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08983" title="Abstract">arXiv:2312.08983</a> [<a href="/pdf/2312.08983" title="Download PDF">pdf</a>, <a href="/format/2312.08983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Humanoid: Online Full-Body Motion Reaction Synthesis with  Social Affordance Canonicalization and Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We focus on the human-humanoid interaction task optionally with an object. We
propose a new task named online full-body motion reaction synthesis, which
generates humanoid reactions based on the human actor's motions. The previous
work only focuses on human interaction without objects and generates body
reactions without hand. Besides, they also do not consider the task as an
online setting, which means the inability to observe information beyond the
current moment in practical situations. To support this task, we construct two
datasets named HHI and CoChair and propose a unified method. Specifically, we
propose to construct a social affordance representation. We first select a
social affordance carrier and use SE(3)-Equivariant Neural Networks to learn
the local frame for the carrier, then we canonicalize the social affordance.
Besides, we propose a social affordance forecasting scheme to enable the
reactor to predict based on the imagined future. Experiments demonstrate that
our approach can effectively generate high-quality reactions on HHI and
CoChair. Furthermore, we also validate our method on existing human interaction
datasets Interhuman and Chi3D.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08984" title="Abstract">arXiv:2312.08984</a> [<a href="/pdf/2312.08984" title="Download PDF">pdf</a>, <a href="/format/2312.08984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CL2CM: Improving Cross-Lingual Cross-Modal Retrieval via Cross-Lingual  Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Cross-lingual cross-modal retrieval has garnered increasing attention
recently, which aims to achieve the alignment between vision and target
language (V-T) without using any annotated V-T data pairs. Current methods
employ machine translation (MT) to construct pseudo-parallel data pairs, which
are then used to learn a multi-lingual and multi-modal embedding space that
aligns visual and target-language representations. However, the large
heterogeneous gap between vision and text, along with the noise present in
target language translations, poses significant challenges in effectively
aligning their representations. To address these challenges, we propose a
general framework, Cross-Lingual to Cross-Modal (CL2CM), which improves the
alignment between vision and target language using cross-lingual transfer. This
approach allows us to fully leverage the merits of multi-lingual pre-trained
models (e.g., mBERT) and the benefits of the same modality structure, i.e.,
smaller gap, to provide reliable and comprehensive semantic correspondence
(knowledge) for the cross-modal network. We evaluate our proposed approach on
two multilingual image-text datasets, Multi30K and MSCOCO, and one video-text
dataset, VATEX. The results clearly demonstrate the effectiveness of our
proposed method and its high potential for large-scale retrieval.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08985" title="Abstract">arXiv:2312.08985</a> [<a href="/pdf/2312.08985" title="Download PDF">pdf</a>, <a href="/format/2312.08985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OMG: Towards Open-vocabulary Motion Generation via Mixture of  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Han Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jiacheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sihan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuecheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We have recently seen tremendous progress in realistic text-to-motion
generation. Yet, the existing methods often fail or produce implausible motions
with unseen text inputs, which limits the applications. In this paper, we
present OMG, a novel framework, which enables compelling motion generation from
zero-shot open-vocabulary text prompts. Our key idea is to carefully tailor the
pretrain-then-finetune paradigm into the text-to-motion generation. At the
pre-training stage, our model improves the generation ability by learning the
rich out-of-domain inherent motion traits. To this end, we scale up a large
unconditional diffusion model up to 1B parameters, so as to utilize the massive
unlabeled motion data up to over 20M motion instances. At the subsequent
fine-tuning stage, we introduce motion ControlNet, which incorporates text
prompts as conditioning information, through a trainable copy of the
pre-trained model and the proposed novel Mixture-of-Controllers (MoC) block.
MoC block adaptively recognizes various ranges of the sub-motions with a
cross-attention mechanism and processes them separately with the
text-token-specific experts. Such a design effectively aligns the CLIP token
embeddings of text prompts to various ranges of compact and expressive motion
features. Extensive experiments demonstrate that our OMG achieves significant
improvements over the state-of-the-art methods on zero-shot text-to-motion
generation. Project page: https://tr3e.github.io/omg-page.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08987" title="Abstract">arXiv:2312.08987</a> [<a href="/pdf/2312.08987" title="Download PDF">pdf</a>, <a href="/format/2312.08987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased organism-agnostic and highly sensitive signal peptide predictor  with deep protein language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junbo Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinze Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shenyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qingxiong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages 5 figures. Nat Comput Sci (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Signal peptide (SP) is a short peptide located in the N-terminus of proteins.
It is essential to target and transfer transmembrane and secreted proteins to
correct positions. Compared with traditional experimental methods to identify
signal peptides, computational methods are faster and more efficient, which are
more practical for analyzing thousands or even millions of protein sequences,
especially for metagenomic data. Here we present Unbiased Organism-agnostic
Signal Peptide Network (USPNet), a signal peptide classification and cleavage
site prediction deep learning method that takes advantage of protein language
models. We propose to apply label distribution-aware margin loss to handle data
imbalance problems and use evolutionary information of protein to enrich
representation and overcome species information dependence.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08990" title="Abstract">arXiv:2312.08990</a> [<a href="/pdf/2312.08990" title="Download PDF">pdf</a>, <a href="/ps/2312.08990" title="Download PostScript">ps</a>, <a href="/format/2312.08990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving Conjectures Acquired by Composing Multiple Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheukam-Ngouonou%2C+J">Jovial Cheukam-Ngouonou</a>, 
<a href="/search/cs?searchtype=author&query=Gindullin%2C+R">Ramiz Gindullin</a>, 
<a href="/search/cs?searchtype=author&query=Beldiceanu%2C+N">Nicolas Beldiceanu</a>, 
<a href="/search/cs?searchtype=author&query=Douence%2C+R">R&#xe9;mi Douence</a>, 
<a href="/search/cs?searchtype=author&query=Quimper%2C+C">Claude-Guy Quimper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We present the proofs of the conjectures mentioned in the paper published in
the proceedings of the 2024 AAAI conference [1], and discovered by the
decomposition methods presented in the same paper.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08991" title="Abstract">arXiv:2312.08991</a> [<a href="/pdf/2312.08991" title="Download PDF">pdf</a>, <a href="/format/2312.08991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sim-to-Real Deep Learning-based Framework for Autonomous Nano-drone  Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamberti%2C+L">Lorenzo Lamberti</a>, 
<a href="/search/cs?searchtype=author&query=Cereda%2C+E">Elia Cereda</a>, 
<a href="/search/cs?searchtype=author&query=Abbate%2C+G">Gabriele Abbate</a>, 
<a href="/search/cs?searchtype=author&query=Bellone%2C+L">Lorenzo Bellone</a>, 
<a href="/search/cs?searchtype=author&query=Morinigo%2C+V+J+K">Victor Javier Kartsch Morinigo</a>, 
<a href="/search/cs?searchtype=author&query=Barcis%2C+M">Micha&#x142; Barcis</a>, 
<a href="/search/cs?searchtype=author&query=Barcis%2C+A">Agata Barcis</a>, 
<a href="/search/cs?searchtype=author&query=Giusti%2C+A">Alessandro Giusti</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Palossi%2C+D">Daniele Palossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 Figures, 3 Tables, This paper has been accepted for publication in the IEEE Robotics and Automation Letters (RAL). Copyright 2023 IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Autonomous drone racing competitions are a proxy to improve unmanned aerial
vehicles' perception, planning, and control skills. The recent emergence of
autonomous nano-sized drone racing imposes new challenges, as their ~10cm form
factor heavily restricts the resources available onboard, including memory,
computation, and sensors. This paper describes the methodology and technical
implementation of the system winning the first autonomous nano-drone racing
international competition: the IMAV 2022 Nanocopter AI Challenge. We developed
a fully onboard deep learning approach for visual navigation trained only on
simulation images to achieve this goal. Our approach includes a convolutional
neural network for obstacle avoidance, a sim-to-real dataset collection
procedure, and a navigation policy that we selected, characterized, and adapted
through simulation and actual in-field experiments. Our system ranked 1st among
seven competing teams at the competition. In our best attempt, we scored 115m
of traveled distance in the allotted 5-minute flight, never crashing while
dodging static and dynamic obstacles. Sharing our knowledge with the research
community, we aim to provide a solid groundwork to foster future development in
this field.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08992" title="Abstract">arXiv:2312.08992</a> [<a href="/pdf/2312.08992" title="Download PDF">pdf</a>, <a href="/format/2312.08992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QQESPM: A Quantitative and Qualitative Spatial Pattern Matching  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minervino%2C+C">Carlos Minervino</a>, 
<a href="/search/cs?searchtype=author&query=Campelo%2C+C">Claudio Campelo</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M">Maxwell Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+S">Salatiel Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The Spatial Pattern Matching (SPM) query allows for the retrieval of Points
of Interest (POIs) based on spatial patterns defined by keywords and distance
criteria. However, it does not consider the connectivity between POIs. In this
study, we introduce the Qualitative and Quantitative Spatial Pattern Matching
(QQ-SPM) query, an extension of the SPM query that incorporates qualitative
connectivity constraints. To answer the proposed query type, we propose the
QQESPM algorithm, which adapts the state-of-the-art ESPM algorithm to handle
connectivity constraints. Performance tests comparing QQESPM to a baseline
approach demonstrate QQESPM's superiority in addressing the proposed query
type.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08994" title="Abstract">arXiv:2312.08994</a> [<a href="/pdf/2312.08994" title="Download PDF">pdf</a>, <a href="/format/2312.08994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PANDA: Architecture-Level Power Evaluation by Unifying Analytical and  Machine Learning Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guanglei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jingyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chen-Chia Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiyao Xie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Power efficiency is a critical design objective in modern microprocessor
design. To evaluate the impact of architectural-level design decisions, an
accurate yet efficient architecture-level power model is desired. However,
widely adopted data-independent analytical power models like McPAT and Wattch
have been criticized for their unreliable accuracy. While some machine learning
(ML) methods have been proposed for architecture-level power modeling, they
rely on sufficient known designs for training and perform poorly when the
number of available designs is limited, which is typically the case in
realistic scenarios.
<br />In this work, we derive a general formulation that unifies existing
architecture-level power models. Based on the formulation, we propose PANDA, an
innovative architecture-level solution that combines the advantages of
analytical and ML power models. It achieves unprecedented high accuracy on
unknown new designs even when there are very limited designs for training,
which is a common challenge in practice. Besides being an excellent power
model, it can predict area, performance, and energy accurately. PANDA further
supports power prediction for unknown new technology nodes. In our experiments,
besides validating the superior performance and the wide range of
functionalities of PANDA, we also propose an application scenario, where PANDA
proves to identify high-performance design configurations given a power
constraint.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08995" title="Abstract">arXiv:2312.08995</a> [<a href="/pdf/2312.08995" title="Download PDF">pdf</a>, <a href="/format/2312.08995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FrameFinder: Explorative Multi-Perspective Framing Extraction from News  Headlines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reiter-Haas%2C+M">Markus Reiter-Haas</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%B6sch%2C+B">Beate Kl&#xf6;sch</a>, 
<a href="/search/cs?searchtype=author&query=Hadler%2C+M">Markus Hadler</a>, 
<a href="/search/cs?searchtype=author&query=Lex%2C+E">Elisabeth Lex</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at CHIIR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Revealing the framing of news articles is an important yet neglected task in
information seeking and retrieval. In the present work, we present FrameFinder,
an open tool for extracting and analyzing frames in textual data. FrameFinder
visually represents the frames of text from three perspectives, i.e., (i) frame
labels, (ii) frame dimensions, and (iii) frame structure. By analyzing the
well-established gun violence frame corpus, we demonstrate the merits of our
proposed solution to support social science research and call for subsequent
integration into information interactions.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08996" title="Abstract">arXiv:2312.08996</a> [<a href="/pdf/2312.08996" title="Download PDF">pdf</a>, <a href="/ps/2312.08996" title="Download PostScript">ps</a>, <a href="/format/2312.08996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decremental Matching in General Weighted Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dudeja%2C+A">Aditi Dudeja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.00927">arXiv:2207.00927</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In this paper, we consider the problem of maintaining a
$(1-\varepsilon)$-approximate maximum weight matching in a dynamic graph $G$,
while the adversary makes changes to the edges of the graph. In the fully
dynamic setting, where both edge insertions and deletions are allowed, Gupta
and Peng gave an algorithm for this problem with an update time of
$\tilde{O}_{\varepsilon}(\sqrt{m})$. We study a natural relaxation of this
problem, namely the decremental model, where the adversary is only allowed to
delete edges. For the cardinality version of this problem in general (possibly,
non-bipartite) graphs, Assadi, Bernstein, and Dudeja gave a decremental
algorithm with update time $O_{\varepsilon}(\text{poly}(\log n))$. However,
beating $\tilde{O}_{\varepsilon}(\sqrt{m})$ update time remained an open
problem for the \emph{weighted} version in \emph{general graphs}. In this
paper, we bridge the gap between unweighted and weighted general graphs for the
decremental setting. We give a $O_{\varepsilon}(\text{poly}(\log n))$ update
time algorithm that maintains a $(1-\varepsilon)$-approximate maximum weight
matching under adversarial deletions. Like the decremental algorithm of Assadi,
Bernstein, and Dudeja, our algorithm is randomized, but works against an
adaptive adversary. It also matches the time bound for the cardinality version
upto dependencies on $\varepsilon$ and a $\log R$ factor, where $R$ is the
ratio between the maximum and minimum edge weight in $G$.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08999" title="Abstract">arXiv:2312.08999</a> [<a href="/pdf/2312.08999" title="Download PDF">pdf</a>, <a href="/format/2312.08999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformalised data synthesis with statistical quality guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meister%2C+J+A">Julia A. Meister</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K+A">Khuong An Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Machine Learning journal special issue "Conformal Prediction and Distribution-Free Uncertainty Quantification"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">With the proliferation of ever more complicated Deep Learning architectures,
data synthesis is a highly promising technique to address the demand of
data-hungry models. However, reliably assessing the quality of a 'synthesiser'
model's output is an open research question with significant associated risks
for high-stake domains. To address this challenge, we have designed a unique
confident data synthesis algorithm that introduces statistical confidence
guarantees through a novel extension of the Conformal Prediction framework. We
support our proposed algorithm with theoretical proofs and an extensive
empirical evaluation of five benchmark datasets. To show our approach's
versatility on ubiquitous real-world challenges, the datasets were carefully
selected for their variety of difficult characteristics: low sample count,
class imbalance and non-separability, and privacy-sensitive data. In all
trials, training sets extended with our confident synthesised data performed at
least as well as the original, and frequently significantly improved Deep
Learning performance by up to +65% F1-score.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09000" title="Abstract">arXiv:2312.09000</a> [<a href="/pdf/2312.09000" title="Download PDF">pdf</a>, <a href="/ps/2312.09000" title="Download PostScript">ps</a>, <a href="/format/2312.09000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComOM at VLSP 2023: A Dual-Stage Framework with BERTology and Unified  Multi-Task Instruction Tuning Model for Vietnamese Comparative Opinion Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Thin%2C+D">Dang Van Thin</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+D+N">Duong Ngoc Hao</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+L">Ngan Luu-Thuy Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted manuscript at VLSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The ComOM shared task aims to extract comparative opinions from product
reviews in Vietnamese language. There are two sub-tasks, including (1)
Comparative Sentence Identification (CSI) and (2) Comparative Element
Extraction (CEE). The first task is to identify whether the input is a
comparative review, and the purpose of the second task is to extract the
quintuplets mentioned in the comparative review. To address this task, our team
proposes a two-stage system based on fine-tuning a BERTology model for the CSI
task and unified multi-task instruction tuning for the CEE task. Besides, we
apply the simple data augmentation technique to increase the size of the
dataset for training our model in the second stage. Experimental results show
that our approach outperforms the other competitors and has achieved the top
score on the official private test.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09002" title="Abstract">arXiv:2312.09002</a> [<a href="/pdf/2312.09002" title="Download PDF">pdf</a>, <a href="/format/2312.09002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization with Reconfigurable Intelligent Surface: An Active Sensing  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Wireless Communications. arXiv admin note: substantial text overlap with <a href="/abs/2310.13160">arXiv:2310.13160</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper addresses an uplink localization problem in which a base station
(BS) aims to locate a remote user with the help of reconfigurable intelligent
surfaces (RISs). We propose a strategy in which the user transmits pilots
sequentially and the BS adaptively adjusts the sensing vectors, including the
BS beamforming vector and multiple RIS reflection coefficients based on the
observations already made, to eventually produce an estimated user position.
This is a challenging active sensing problem for which finding an optimal
solution involves searching through a complicated functional space whose
dimension increases with the number of measurements. We show that the long
short-term memory (LSTM) network can be used to exploit the latent temporal
correlation between measurements to automatically construct scalable state
vectors. Subsequently, the state vector is mapped to the sensing vectors for
the next time frame via a deep neural network (DNN). A final DNN is used to map
the state vector to the estimated user position. Numerical result illustrates
the advantage of the active sensing design as compared to non-active sensing
methods. The proposed solution produces interpretable results and is
generalizable in the number of sensing stages. Remarkably, we show that a
network with one BS and multiple RISs can outperform a comparable setting with
multiple BSs.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09005" title="Abstract">arXiv:2312.09005</a> [<a href="/pdf/2312.09005" title="Download PDF">pdf</a>, <a href="/format/2312.09005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene 3-D Reconstruction System in Scattering Medium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuoyifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoming Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The research on neural radiance fields for new view synthesis has experienced
explosive growth with the development of new models and extensions. The NERF
algorithm, suitable for underwater scenes or scattering media, is also
evolving. Existing underwater 3D reconstruction systems still face challenges
such as extensive training time and low rendering efficiency. This paper
proposes an improved underwater 3D reconstruction system to address these
issues and achieve rapid, high-quality 3D reconstruction.To begin with, we
enhance underwater videos captured by a monocular camera to correct the poor
image quality caused by the physical properties of the water medium while
ensuring consistency in enhancement across adjacent frames. Subsequently, we
perform keyframe selection on the video frames to optimize resource utilization
and eliminate the impact of dynamic objects on the reconstruction results. The
selected keyframes, after pose estimation using COLMAP, undergo a
three-dimensional reconstruction improvement process using neural radiance
fields based on multi-resolution hash coding for model construction and
rendering.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09006" title="Abstract">arXiv:2312.09006</a> [<a href="/pdf/2312.09006" title="Download PDF">pdf</a>, <a href="/format/2312.09006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSSA: Semantic Similarity-based Aggregation for Efficient  Model-Heterogeneous Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Liping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoguang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.06879">arXiv:2311.06879</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) is a privacy-preserving collaboratively machine
learning paradigm. Traditional FL requires all data owners (a.k.a. FL clients)
to train the same local model. This design is not well-suited for scenarios
involving data and/or system heterogeneity. Model-Heterogeneous Personalized FL
(MHPFL) has emerged to address this challenge. Existing MHPFL approaches often
rely on having a public dataset with the same nature of the learning task, or
incur high computation and communication costs. To address these limitations,
we propose the Federated Semantic Similarity Aggregation (FedSSA) approach,
which splits each client's model into a heterogeneous (structure-different)
feature extractor and a homogeneous (structure-same) classification header. It
performs local-to-global knowledge transfer via semantic similarity-based
header parameter aggregation. In addition, global-to-local knowledge transfer
is achieved via an adaptive parameter stabilization strategy which fuses the
seen-class parameters of historical local headers with that of the latest
global header for each client. In this way, FedSSA does not rely on public
datasets, while only requiring partial header parameter transmission (thereby
saving costs). Theoretical analysis proves the convergence of FedSSA. Extensive
experiments demonstrate that FedSSA achieves up to $3.62 \times\%$ higher
accuracy, $15.54$ times higher communication efficiency, and $15.52 \times$
higher computational efficiency compared to 7 state-of-the-art MHPFL baselines.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09007" title="Abstract">arXiv:2312.09007</a> [<a href="/pdf/2312.09007" title="Download PDF">pdf</a>, <a href="/format/2312.09007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hongwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yulin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+S+C">Soung Chang Liew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this article, we introduce LLMind, an innovative AI framework that
utilizes large language models (LLMs) as a central orchestrator. The framework
integrates LLMs with domain-specific AI modules, enabling IoT devices to
collaborate effectively in executing complex tasks. The LLM performs planning
and generates control scripts using a reliable and precise language-code
transformation approach based on finite state machines (FSMs). The LLM engages
in natural conversations with users, employing role-playing techniques to
generate contextually appropriate responses. Additionally, users can interact
easily with the AI agent via a user-friendly social media platform. The
framework also incorporates semantic analysis and response optimization
techniques to enhance speed and effectiveness. Ultimately, this framework is
designed not only to innovate IoT device control and enrich user experiences
but also to foster an intelligent and integrated IoT device ecosystem that
evolves and becomes more sophisticated through continuing user and machine
interactions.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09008" title="Abstract">arXiv:2312.09008</a> [<a href="/pdf/2312.09008" title="Download PDF">pdf</a>, <a href="/format/2312.09008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Injection in Diffusion: A Training-free Approach for Adapting  Large-scale Diffusion Models for Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiwoo Chung</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+S">Sangeek Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the impressive generative capabilities of diffusion models, existing
diffusion model-based style transfer methods require inference-stage
optimization (e.g. fine-tuning or textual inversion of style) which is
time-consuming, or fails to leverage the generative ability of large-scale
diffusion models. To address these issues, we introduce a novel artistic style
transfer method based on a pre-trained large-scale diffusion model without any
optimization. Specifically, we manipulate the features of self-attention layers
as the way the cross-attention mechanism works; in the generation process,
substituting the key and value of content with those of style image. This
approach provides several desirable characteristics for style transfer
including 1) preservation of content by transferring similar styles into
similar image patches and 2) transfer of style based on similarity of local
texture (e.g. edge) between content and style images. Furthermore, we introduce
query preservation and attention temperature scaling to mitigate the issue of
disruption of original content, and initial latent Adaptive Instance
Normalization (AdaIN) to deal with the disharmonious color (failure to transfer
the colors of style). Our experimental results demonstrate that our proposed
method surpasses state-of-the-art methods in both conventional and
diffusion-based style transfer baselines.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09009" title="Abstract">arXiv:2312.09009</a> [<a href="/pdf/2312.09009" title="Download PDF">pdf</a>, <a href="/format/2312.09009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive parameter sharing for multi-agent reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+N">Na Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, accepted for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Parameter sharing, as an important technique in multi-agent systems, can
effectively solve the scalability issue in large-scale agent problems. However,
the effectiveness of parameter sharing largely depends on the environment
setting. When agents have different identities or tasks, naive parameter
sharing makes it difficult to generate sufficiently differentiated strategies
for agents. Inspired by research pertaining to the brain in biology, we propose
a novel parameter sharing method. It maps each type of agent to different
regions within a shared network based on their identity, resulting in distinct
subnetworks. Therefore, our method can increase the diversity of strategies
among different agents without introducing additional training parameters.
Through experiments conducted in multiple environments, our method has shown
better performance than other parameter sharing methods.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09015" title="Abstract">arXiv:2312.09015</a> [<a href="/pdf/2312.09015" title="Download PDF">pdf</a>, <a href="/ps/2312.09015" title="Download PostScript">ps</a>, <a href="/format/2312.09015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty in GNN Learning Evaluations: A Comparison Between Measures  for Quantifying Randomness in GNN Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leeney%2C+W">William Leeney</a>, 
<a href="/search/cs?searchtype=author&query=McConville%2C+R">Ryan McConville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, contribution from COMPLEX NETWORKS 2023 selected for a possible publication in the special issue of the journal Entropy dedicated to the conference. arXiv admin note: substantial text overlap with <a href="/abs/2305.06026">arXiv:2305.06026</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">(1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised
community detection of clustered nodes is attributed to their capacity to
encode both the connectivity and feature information spaces of graphs. The
identification of latent communities holds practical significance in various
domains, from social networks to genomics. Current real-world performance
benchmarks are perplexing due to the multitude of decisions influencing GNN
evaluations for this task. (2) Three metrics are compared to assess the
consistency of algorithm rankings in the presence of randomness. The
consistency and quality of performance between the results under a
hyperparameter optimisation with the default hyperparameters is evaluated. (3)
The results compare hyperparameter optimisation with default hyperparameters,
revealing a significant performance loss when neglecting hyperparameter
investigation. A comparison of metrics indicates that ties in ranks can
substantially alter the quantification of randomness. (4) Ensuring adherence to
the same evaluation criteria may result in notable differences in the reported
performance of methods for this task. The $W$ Randomness coefficient, based on
the Wasserstein distance, is identified as providing the most robust assessment
of randomness.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09016" title="Abstract">arXiv:2312.09016</a> [<a href="/pdf/2312.09016" title="Download PDF">pdf</a>, <a href="/ps/2312.09016" title="Download PostScript">ps</a>, <a href="/format/2312.09016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry Breaking and Equivariant Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaba%2C+S">S&#xe9;kou-Oumar Kaba</a>, 
<a href="/search/cs?searchtype=author&query=Ravanbakhsh%2C+S">Siamak Ravanbakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Symmetry and Geometry in Neural Representations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Using symmetry as an inductive bias in deep learning has been proven to be a
principled approach for sample-efficient model design. However, the
relationship between symmetry and the imperative for equivariance in neural
networks is not always obvious. Here, we analyze a key limitation that arises
in equivariant functions: their incapacity to break symmetry at the level of
individual data samples. In response, we introduce a novel notion of 'relaxed
equivariance' that circumvents this limitation. We further demonstrate how to
incorporate this relaxation into equivariant multilayer perceptrons (E-MLPs),
offering an alternative to the noise-injection method. The relevance of
symmetry breaking is then discussed in various application domains: physics,
graph representation learning, combinatorial optimization and equivariant
decoding.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09018" title="Abstract">arXiv:2312.09018</a> [<a href="/pdf/2312.09018" title="Download PDF">pdf</a>, <a href="/ps/2312.09018" title="Download PostScript">ps</a>, <a href="/format/2312.09018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Diagnosis and Prognosis Capabilities for Wind Turbine Hydraulic  Pitch Systems: An Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dallabona%2C+A">Alessio Dallabona</a>, 
<a href="/search/eess?searchtype=author&query=Blanke%2C+M">Mogens Blanke</a>, 
<a href="/search/eess?searchtype=author&query=Pedersen%2C+H+C">Henrik C. Pedersen</a>, 
<a href="/search/eess?searchtype=author&query=Papageorgiou%2C+D">Dimitrios Papageorgiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Wind energy is the leading non-hydro renewable technology. Increasing
reliability is a key factor in reducing the downtime of high-power wind
turbines installed in remote off-shore places, where maintenance is costly and
less reactive. Defects in the pitch system are responsible for up to $20\%$ of
a wind turbine downtime. Thus, prognosis and condition monitoring of such
defects are essential for avoiding downtime. This paper presents a generic
assessment of diagnosis capabilities in hydraulic pitch systems characterizing
high-power wind turbines. A mathematical model of the non-linear system
dynamics is presented along with a description of the most frequent faults that
can affect it. Structural analysis is employed to assess the diagnosis and
prognosis capabilities of defects in the pitch system. The structural
properties are furthermore explored to investigate possible sensor reduction
without compromising fault diagnosis capabilities.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09020" title="Abstract">arXiv:2312.09020</a> [<a href="/pdf/2312.09020" title="Download PDF">pdf</a>, <a href="/format/2312.09020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Transferability for Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Stephen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training foundation models on extensive datasets and then finetuning them on
specific tasks has emerged as the mainstream approach in artificial
intelligence. However, the model robustness, which is a critical aspect for
safety, is often optimized for each specific task rather than at the
pretraining stage. In this paper, we propose a method for pretraining
certifiably robust models that can be readily finetuned for adaptation to a
particular task. A key challenge is dealing with the compromise between
semantic learning and robustness. We address this with a simple yet highly
effective strategy based on significantly broadening the pretraining data
distribution, which is shown to greatly benefit finetuning for downstream
tasks. Through pretraining on a mixture of clean and various noisy images, we
find that surprisingly strong certified accuracy can be achieved even when
finetuning on only clean images. Furthermore, this strategy requires just a
single model to deal with various noise levels, thus substantially reducing
computational costs in relation to previous works that employ multiple models.
Despite using just one model, our method can still yield results that are on
par with, or even superior to, existing multi-model methods.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09023" title="Abstract">arXiv:2312.09023</a> [<a href="/pdf/2312.09023" title="Download PDF">pdf</a>, <a href="/ps/2312.09023" title="Download PostScript">ps</a>, <a href="/format/2312.09023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Exploring Federated Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leeney%2C+W">William Leeney</a>, 
<a href="/search/cs?searchtype=author&query=McConville%2C+R">Ryan McConville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, Accepted at Association for the Advancement of Artificial Intelligence (AAAI) 2024 - 4th Workshop on Graphs and more Complex structures for Learning and Reasoning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Federated Learning is machine learning in the context of a network of clients
whilst maintaining data residency and/or privacy constraints. Community
detection is the unsupervised discovery of clusters of nodes within
graph-structured data. The intersection of these two fields uncovers much
opportunity, but also challenge. For example, it adds complexity due to missing
connectivity information between privately held graphs. In this work, we
explore the potential of federated community detection by conducting initial
experiments across a range of existing datasets that showcase the gap in
performance introduced by the distributed data. We demonstrate that isolated
models would benefit from collaboration establishing a framework for
investigating challenges within this domain. The intricacies of these research
frontiers are discussed alongside proposed solutions to these issues.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09024" title="Abstract">arXiv:2312.09024</a> [<a href="/pdf/2312.09024" title="Download PDF">pdf</a>, <a href="/format/2312.09024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes Net based highbrid Monte Carlo Optimization for Redundant  Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yichang%2C+F">Feng Yichang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Haiyun%2C+Z">Zhang Haiyun</a>, 
<a href="/search/cs?searchtype=author&query=Guodong%2C+L">Lu Guodong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a Bayes Net based Monte Carlo optimization for motion
planning (BN-MCO). Primarily, we adjust the potential fields determined by goal
and start constraints to progressively guide the sampled clusters toward the
goal and start points. Then, we utilize the Gaussian mixed modal (GMM) to
perform the Monte Carlo optimization, confronting these two non-convex
potential fields. Moreover, KL divergence measures the bias between the true
distribution determined by the fields and the proposed GMM, whose parameters
are learned incrementally according to the manifold information of the bias. In
this way, the Bayesian network consisting of sequential updated GMMs expands
until the constraints are satisfied and the shortest path method can find a
feasible path. Finally, we tune the key parameters and benchmark BN-MCO against
the other 5 planners on LBR-iiwa in a bookshelf. The result shows the highest
success rate and moderate solving efficiency of BN-MCO.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09025" title="Abstract">arXiv:2312.09025</a> [<a href="/pdf/2312.09025" title="Download PDF">pdf</a>, <a href="/format/2312.09025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Simultaneous Geometric Embedding for Edge-Disjoint  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BCnzel%2C+B">Benedikt K&#xfc;nzel</a>, 
<a href="/search/cs?searchtype=author&query=Rollin%2C+J">Jonathan Rollin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Simultaneous Geometric Embedding (SGE) asks whether, for a given collection
of graphs on the same vertex set V, there is an embedding of V in the plane
that admits a crossing-free drawing with straightline edges for each of the
given graphs. It is known that SGE is $\exists\mathbb{R}$-complete, that is,
the problem is polynomially equivalent to deciding whether a system of
polynomial equations and inequalities with integer coefficients has a real
solution. We prove that SGE remains $\exists\mathbb{R}$-complete for
edge-disjoint input graphs, that is, for collections of graphs without
so-called public edges.
<br />As an intermediate result, we prove that it is $\exists\mathbb{R}$-complete
to decide whether a directional walk without repeating edges is realizable.
Here, a directional walk consists of a sequence of not-necessarily distinct
vertices (a walk) and a function prescribing for each inner position whether
the walk shall turn left or shall turn right. A directional walk is realizable,
if there is an embedding of its vertices in the plane such that the embedded
walk turns according to the given directions. Previously it was known that
realization is $\exists\mathbb{R}$-complete to decide for directional walks
repeating each edge at most 336 times.
<br />This answers two questions posed by Schaefer ["On the Complexity of Some
Geometric Problems With Fixed Parameters", JGAA 2021].
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09027" title="Abstract">arXiv:2312.09027</a> [<a href="/pdf/2312.09027" title="Download PDF">pdf</a>, <a href="/format/2312.09027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAM-Locker: A General-Purpose DRAM Protection Mechanism against  Adversarial DNN Weight Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ranyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sabbir Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Roohi%2C+A">Arman Roohi</a>, 
<a href="/search/cs?searchtype=author&query=Rakin%2C+A+S">Adnan Siraj Rakin</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages. arXiv admin note: text overlap with <a href="/abs/2305.08034">arXiv:2305.08034</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In this work, we propose DRAM-Locker as a robust general-purpose defense
mechanism that can protect DRAM against various adversarial Deep Neural Network
(DNN) weight attacks affecting data or page tables. DRAM-Locker harnesses the
capabilities of in-DRAM swapping combined with a lock-table to prevent
attackers from singling out specific DRAM rows to safeguard DNN's weight
parameters. Our results indicate that DRAM-Locker can deliver a high level of
protection downgrading the performance of targeted weight attacks to a random
attack level. Furthermore, the proposed defense mechanism demonstrates no
reduction in accuracy when applied to CIFAR-10 and CIFAR-100. Importantly,
DRAM-Locker does not necessitate any software retraining or result in extra
hardware burden.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09028" title="Abstract">arXiv:2312.09028</a> [<a href="/pdf/2312.09028" title="Download PDF">pdf</a>, <a href="/format/2312.09028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Space Exploration of Low-Bit Quantized Neural Networks for Visual  Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grainge%2C+O">Oliver Grainge</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=Bodala%2C+I">Indu Bodala</a>, 
<a href="/search/cs?searchtype=author&query=Ramchurn%2C+S+D">Sarvapali D. Ramchurn</a>, 
<a href="/search/cs?searchtype=author&query=Ehsan%2C+S">Shoaib Ehsan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Place Recognition (VPR) is a critical task for performing global
re-localization in visual perception systems. It requires the ability to
accurately recognize a previously visited location under variations such as
illumination, occlusion, appearance and viewpoint. In the case of robotic
systems and augmented reality, the target devices for deployment are battery
powered edge devices. Therefore whilst the accuracy of VPR methods is important
so too is memory consumption and latency. Recently new works have focused on
the recall@1 metric as a performance measure with limited focus on resource
utilization. This has resulted in methods that use deep learning models too
large to deploy on low powered edge devices. We hypothesize that these large
models are highly over-parameterized and can be optimized to satisfy the
constraints of a low powered embedded system whilst maintaining high recall
performance. Our work studies the impact of compact convolutional network
architecture design in combination with full-precision and mixed-precision
post-training quantization on VPR performance. Importantly we not only measure
performance via the recall@1 score but also measure memory consumption and
latency. We characterize the design implications on memory, latency and recall
scores and provide a number of design recommendations for VPR systems under
these resource limitations.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09030" title="Abstract">arXiv:2312.09030</a> [<a href="/pdf/2312.09030" title="Download PDF">pdf</a>, <a href="/format/2312.09030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Branch Network Towards Accurate Printed Mathematical Expression  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Z">Zhenyu Weng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhaokun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuaijian Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhongjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuesheng Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICANN 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past years, Printed Mathematical Expression Recognition (PMER) has
progressed rapidly. However, due to the insufficient context information
captured by Convolutional Neural Networks, some mathematical symbols might be
incorrectly recognized or missed. To tackle this problem, in this paper, a Dual
Branch transformer-based Network (DBN) is proposed to learn both local and
global context information for accurate PMER. In our DBN, local and global
features are extracted simultaneously, and a Context Coupling Module (CCM) is
developed to complement the features between the global and local contexts. CCM
adopts an interactive manner so that the coupled context clues are highly
correlated to each expression symbol. Additionally, we design a Dynamic Soft
Target (DST) strategy to utilize the similarities among symbol categories for
reasonable label generation. Our experimental results have demonstrated that
DBN can accurately recognize mathematical expressions and has achieved
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09031" title="Abstract">arXiv:2312.09031</a> [<a href="/pdf/2312.09031" title="Download PDF">pdf</a>, <a href="/format/2312.09031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iComMa: Inverting 3D Gaussians Splatting for Camera Pose Estimation via  Comparing and Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunfan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Caigui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a method named iComMa to address the 6D pose estimation problem in
computer vision. The conventional pose estimation methods typically rely on the
target's CAD model or necessitate specific network training tailored to
particular object classes. Some existing methods address mesh-free 6D pose
estimation by employing the inversion of a Neural Radiance Field (NeRF), aiming
to overcome the aforementioned constraints. However, it still suffers from
adverse initializations. By contrast, we model the pose estimation as the
problem of inverting the 3D Gaussian Splatting (3DGS) with both the comparing
and matching loss. In detail, a render-and-compare strategy is adopted for the
precise estimation of poses. Additionally, a matching module is designed to
enhance the model's robustness against adverse initializations by minimizing
the distances between 2D keypoints. This framework systematically incorporates
the distinctive characteristics and inherent rationale of render-and-compare
and matching-based approaches. This comprehensive consideration equips the
framework to effectively address a broader range of intricate and challenging
scenarios, including instances with substantial angular deviations, all while
maintaining a high level of prediction accuracy. Experimental results
demonstrate the superior precision and robustness of our proposed jointly
optimized framework when evaluated on synthetic and complex real-world data in
challenging scenarios.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09033" title="Abstract">arXiv:2312.09033</a> [<a href="/pdf/2312.09033" title="Download PDF">pdf</a>, <a href="/format/2312.09033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Surprise Index for Competency Assessment in Autonomous  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratheesh%2C+A">Akash Ratheesh</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+O">Ofer Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+R">Nisar R. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Bosanac%2C+N">Natasha Bosanac</a>, 
<a href="/search/cs?searchtype=author&query=McMahon%2C+J">Jay McMahon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, to be presented at AIAA SciTech 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper considers the problem of evaluating an autonomous system's
competency in performing a task, particularly when working in dynamic and
uncertain environments. The inherent opacity of machine learning models, from
the perspective of the user, often described as a `black box', poses a
challenge. To overcome this, we propose using a measure called the Surprise
index, which leverages available measurement data to quantify whether the
dynamic system performs as expected. We show that the surprise index can be
computed in closed form for dynamic systems when observed evidence in a
probabilistic model if the joint distribution for that evidence follows a
multivariate Gaussian marginal distribution. We then apply it to a nonlinear
spacecraft maneuver problem, where actions are chosen by a reinforcement
learning agent and show it can indicate how well the trajectory follows the
required orbit.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09037" title="Abstract">arXiv:2312.09037</a> [<a href="/pdf/2312.09037" title="Download PDF">pdf</a>, <a href="/format/2312.09037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Ground Truth Quality on Handwriting Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jungo%2C+M">Michael Jungo</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6gtlin%2C+L">Lars V&#xf6;gtlin</a>, 
<a href="/search/cs?searchtype=author&query=Fakhari%2C+A">Atefeh Fakhari</a>, 
<a href="/search/cs?searchtype=author&query=Wegmann%2C+N">Nathan Wegmann</a>, 
<a href="/search/cs?searchtype=author&query=Ingold%2C+R">Rolf Ingold</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+A">Andreas Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Scius-Bertrand%2C+A">Anna Scius-Bertrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOICT 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SOICT 2023: The 12th International Symposium on Information and
  Communication Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Handwriting recognition is a key technology for accessing the content of old
manuscripts, helping to preserve cultural heritage. Deep learning shows an
impressive performance in solving this task. However, to achieve its full
potential, it requires a large amount of labeled data, which is difficult to
obtain for ancient languages and scripts. Often, a trade-off has to be made
between ground truth quantity and quality, as is the case for the recently
introduced Bullinger database. It contains an impressive amount of over a
hundred thousand labeled text line images of mostly premodern German and Latin
texts that were obtained by automatically aligning existing page-level
transcriptions with text line images. However, the alignment process introduces
systematic errors, such as wrongly hyphenated words. In this paper, we
investigate the impact of such errors on training and evaluation and suggest
means to detect and correct typical alignment errors.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09038" title="Abstract">arXiv:2312.09038</a> [<a href="/pdf/2312.09038" title="Download PDF">pdf</a>, <a href="/format/2312.09038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Recognition from Scientific Document based on Compartment  Refinement Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinghong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Wen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+K">Koichi Ota</a>, 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+S">Shinobu Hasegawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.17401">arXiv:2305.17401</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rapid development of the internet in the past decade, it has become
increasingly important to extract valuable information from vast resources
efficiently, which is crucial for establishing a comprehensive digital
ecosystem, particularly in the context of research surveys and comprehension.
The foundation of these tasks focuses on accurate extraction and deep mining of
data from scientific documents, which are essential for building a robust data
infrastructure. However, parsing raw data or extracting data from complex
scientific documents have been ongoing challenges. Current data extraction
methods for scientific documents typically use rule-based (RB) or machine
learning (ML) approaches. However, using rule-based methods can incur high
coding costs for articles with intricate typesetting. Conversely, relying
solely on machine learning methods necessitates annotation work for complex
content types within the scientific document, which can be costly.
Additionally, few studies have thoroughly defined and explored the hierarchical
layout within scientific documents. The lack of a comprehensive definition of
the internal structure and elements of the documents indirectly impacts the
accuracy of text classification and object recognition tasks. From the
perspective of analyzing the standard layout and typesetting used in the
specified publication, we propose a new document layout analysis framework
called CTBR(Compartment &amp; Text Blocks Refinement). Firstly, we define
scientific documents into hierarchical divisions: base domain, compartment, and
text blocks. Next, we conduct an in-depth exploration and classification of the
meanings of text blocks. Finally, we utilize the results of text block
classification to implement object recognition within scientific documents
based on rule-based compartment segmentation.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09039" title="Abstract">arXiv:2312.09039</a> [<a href="/pdf/2312.09039" title="Download PDF">pdf</a>, <a href="/format/2312.09039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAP4LLM: Table Provider on Sampling, Augmenting, and Packing  Semi-structured Data for Large Language Model Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yuan Sui</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jiaru Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinyi He</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.08674">arXiv:2307.08674</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Table reasoning has shown remarkable progress in a wide range of table-based
tasks. These challenging tasks require reasoning over both free-form natural
language (NL) questions and semi-structured tabular data. However, previous
table reasoning solutions suffer from significant performance degradation on
"huge" tables. In addition, most existing methods struggle to reason over
complex questions since they lack essential information or they are scattered
in different places. To alleviate these challenges, we exploit a table
provider, namely TAP4LLM, on versatile sampling, augmentation, and packing
methods to achieve effective semi-structured data reasoning using large
language models (LLMs), which 1) decompose raw tables into sub-tables with
specific rows or columns based on the rules or semantic similarity; 2) augment
table information by extracting semantic and statistical metadata from raw
tables while retrieving relevant knowledge from trustworthy knowledge sources
(e.g., Wolfram Alpha, Wikipedia); 3) pack sampled tables with augmented
knowledge into sequence prompts for LLMs reasoning while balancing the token
allocation trade-off. We show that TAP4LLM allows for different components as
plug-ins, enhancing LLMs' understanding of structured data in diverse tabular
tasks.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09040" title="Abstract">arXiv:2312.09040</a> [<a href="/pdf/2312.09040" title="Download PDF">pdf</a>, <a href="/format/2312.09040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STaR: Distilling Speech Temporal Relation for Lightweight Speech  Self-Supervised Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+K">Kangwook Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungnyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoirin Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Albeit great performance of Transformer-based speech selfsupervised learning
(SSL) models, their large parameter size and computational cost make them
unfavorable to utilize. In this study, we propose to compress the speech SSL
models by distilling speech temporal relation (STaR). Unlike previous works
that directly match the representation for each speech frame, STaR distillation
transfers temporal relation between speech frames, which is more suitable for
lightweight student with limited capacity. We explore three STaR distillation
objectives and select the best combination as the final STaR loss. Our model
distilled from HuBERT BASE achieves an overall score of 79.8 on SUPERB
benchmark, the best performance among models with up to 27 million parameters.
We show that our method is applicable across different speech SSL models and
maintains robust performance with further reduced parameters.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09041" title="Abstract">arXiv:2312.09041</a> [<a href="/pdf/2312.09041" title="Download PDF">pdf</a>, <a href="/format/2312.09041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks with Diverse Spectral Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings of the ACM Web Conference 2023 (WWW '23)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM Web Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Spectral Graph Neural Networks (GNNs) have achieved tremendous success in
graph machine learning, with polynomial filters applied for graph convolutions,
where all nodes share the identical filter weights to mine their local
contexts. Despite the success, existing spectral GNNs usually fail to deal with
complex networks (e.g., WWW) due to such homogeneous spectral filtering setting
that ignores the regional heterogeneity as typically seen in real-world
networks. To tackle this issue, we propose a novel diverse spectral filtering
(DSF) framework, which automatically learns node-specific filter weights to
exploit the varying local structure properly. Particularly, the diverse filter
weights consist of two components -- A global one shared among all nodes, and a
local one that varies along network edges to reflect node difference arising
from distinct graph parts -- to balance between local and global information.
As such, not only can the global graph characteristics be captured, but also
the diverse local patterns can be mined with awareness of different node
positions. Interestingly, we formulate a novel optimization problem to assist
in learning diverse filters, which also enables us to enhance any spectral GNNs
with our DSF framework. We showcase the proposed framework on three
state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive
experiments over 10 benchmark datasets demonstrate that our framework can
consistently boost model performance by up to 4.92% in node classification
tasks, producing diverse filters with enhanced interpretability. Code is
available at \url{https://github.com/jingweio/DSF}.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09043" title="Abstract">arXiv:2312.09043</a> [<a href="/pdf/2312.09043" title="Download PDF">pdf</a>, <a href="/format/2312.09043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic Bias in Emotion Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wegge%2C+M">Maximilian Wegge</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Emotion corpora are typically sampled based on keyword/hashtag search or by
asking study participants to generate textual instances. In any case, these
corpora are not uniform samples representing the entirety of a domain. We
hypothesize that this practice of data acquisition leads to unrealistic
correlations between overrepresented topics in these corpora that harm the
generalizability of models. Such topic bias could lead to wrong predictions for
instances like "I organized the service for my aunt's funeral." when funeral
events are over-represented for instances labeled with sadness, despite the
emotion of pride being more appropriate here. In this paper, we study this
topic bias both from the data and the modeling perspective. We first label a
set of emotion corpora automatically via topic modeling and show that emotions
in fact correlate with specific topics. Further, we see that emotion
classifiers are confounded by such topics. Finally, we show that the
established debiasing method of adversarial correction via gradient reversal
mitigates the issue. Our work points out issues with existing emotion corpora
and that more representative resources are required for fair evaluation of
models predicting affective concepts from text.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09048" title="Abstract">arXiv:2312.09048</a> [<a href="/pdf/2312.09048" title="Download PDF">pdf</a>, <a href="/format/2312.09048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Expressivity of Recurrent Neural Cascades
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knorozova%2C+N+A">Nadezda Alexandrovna Knorozova</a>, 
<a href="/search/cs?searchtype=author&query=Ronca%2C+A">Alessandro Ronca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version with appendix of a paper with the same title that will appear in the proceedings of AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Formal Languages and Automata Theory (cs.FL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recurrent Neural Cascades (RNCs) are the recurrent neural networks with no
cyclic dependencies among recurrent neurons. This class of recurrent networks
has received a lot of attention in practice. Besides training methods for a
fixed architecture such as backpropagation, the cascade architecture naturally
allows for constructive learning methods, where recurrent nodes are added
incrementally one at a time, often yielding smaller networks. Furthermore,
acyclicity amounts to a structural prior that even for the same number of
neurons yields a more favourable sample complexity compared to a
fully-connected architecture. A central question is whether the advantages of
the cascade architecture come at the cost of a reduced expressivity. We provide
new insights into this question. We show that the regular languages captured by
RNCs with sign and tanh activation with positive recurrent weights are the
star-free regular languages. In order to establish our results we developed a
novel framework where capabilities of RNCs are accessed by analysing which
semigroups and groups a single neuron is able to implement. A notable
implication of our framework is that RNCs can achieve the expressivity of all
regular languages by introducing neurons that can implement groups.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09050" title="Abstract">arXiv:2312.09050</a> [<a href="/pdf/2312.09050" title="Download PDF">pdf</a>, <a href="/format/2312.09050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sparse Cross Attention-based Graph Convolution Network with Auxiliary  Information Awareness for Traffic Flow Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinglin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengchu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+C">Chenglong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yiming Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep graph convolution networks (GCNs) have recently shown excellent
performance in traffic prediction tasks. However, they face some challenges.
First, few existing models consider the influence of auxiliary information,
i.e., weather and holidays, which may result in a poor grasp of
spatial-temporal dynamics of traffic data. Second, both the construction of a
dynamic adjacent matrix and regular graph convolution operations have quadratic
computation complexity, which restricts the scalability of GCN-based models. To
address such challenges, this work proposes a deep encoder-decoder model
entitled AIMSAN. It contains an auxiliary information-aware module (AIM) and
sparse cross attention-based graph convolution network (SAN). The former learns
multi-attribute auxiliary information and obtains its embedded presentation of
different time-window sizes. The latter uses a cross-attention mechanism to
construct dynamic adjacent matrices by fusing traffic data and embedded
auxiliary data. Then, SAN applies diffusion GCN on traffic data to mine rich
spatial-temporal dynamics. Furthermore, AIMSAN considers and uses the spatial
sparseness of traffic nodes to reduce the quadratic computation complexity.
Experimental results on three public traffic datasets demonstrate that the
proposed method outperforms other counterparts in terms of various performance
indices. Specifically, the proposed method has competitive performance with the
state-of-the-art algorithms but saves 35.74% of GPU memory usage, 42.25% of
training time, and 45.51% of validation time on average.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09053" title="Abstract">arXiv:2312.09053</a> [<a href="/pdf/2312.09053" title="Download PDF">pdf</a>, <a href="/format/2312.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Green Computing in Video Games: The Dawn of Green Video  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+C">Carlos P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Marc%C3%A9n%2C+A+C">Ana C. Marc&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Ver%C3%B3n%2C+J">Javier Ver&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Cetina%2C+C">Carlos Cetina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Today, the large number of players and the high computational requirements of
video games have motivated research on Green Video Games. We present a survey
that provides an overview of this recent research area. A total of 2,637 papers
were reviewed, selecting 69 papers as primary studies for further analysis.
Through a detailed analysis of the results, we propose a new way to define the
Green Video Game issues based on motivation, device, and layer of the primary
studies. Then, we analyze the different applied techniques, the limitations and
levels of evidence, and specific aspects of video games.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09056" title="Abstract">arXiv:2312.09056</a> [<a href="/pdf/2312.09056" title="Download PDF">pdf</a>, <a href="/format/2312.09056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReCoRe: Regularized Contrastive Representation Learning of World Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poudel%2C+R+P+K">Rudra P.K. Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+H">Harit Pandya</a>, 
<a href="/search/cs?searchtype=author&query=Liwicki%2C+S">Stephan Liwicki</a>, 
<a href="/search/cs?searchtype=author&query=Cipolla%2C+R">Roberto Cipolla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2209.14932">arXiv:2209.14932</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
<p class="mathjax">While recent model-free Reinforcement Learning (RL) methods have demonstrated
human-level effectiveness in gaming environments, their success in everyday
tasks like visual navigation has been limited, particularly under significant
appearance variations. This limitation arises from (i) poor sample efficiency
and (ii) over-fitting to training scenarios. To address these challenges, we
present a world model that learns invariant features using (i) contrastive
unsupervised learning and (ii) an intervention-invariant regularizer. Learning
an explicit representation of the world dynamics i.e. a world model, improves
sample efficiency while contrastive learning implicitly enforces learning of
invariant features, which improves generalization. However, the naive
integration of contrastive loss to world models fails due to a lack of
supervisory signals to the visual encoder, as world-model-based RL methods
independently optimize representation learning and agent policy. To overcome
this issue, we propose an intervention-invariant regularizer in the form of an
auxiliary task such as depth prediction, image denoising, etc., that explicitly
enforces invariance to style-interventions. Our method outperforms current
state-of-the-art model-based and model-free RL methods and significantly on
out-of-distribution point navigation task evaluated on the iGibson benchmark.
We further demonstrate that our approach, with only visual observations,
outperforms recent language-guided foundation models for point navigation,
which is essential for deployment on robots with limited computation
capabilities. Finally, we demonstrate that our proposed model excels at the
sim-to-real transfer of its perception module on Gibson benchmark.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09057" title="Abstract">arXiv:2312.09057</a> [<a href="/pdf/2312.09057" title="Download PDF">pdf</a>, <a href="/format/2312.09057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Difficulty of Defending Contrastive Learning against Backdoor  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+R">Ren Pang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bochuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhaohan Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> USENIX Security 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent studies have shown that contrastive learning, like supervised
learning, is highly vulnerable to backdoor attacks wherein malicious functions
are injected into target models, only to be activated by specific triggers.
However, thus far it remains under-explored how contrastive backdoor attacks
fundamentally differ from their supervised counterparts, which impedes the
development of effective defenses against the emerging threat.
<br />This work represents a solid step toward answering this critical question.
Specifically, we define TRL, a unified framework that encompasses both
supervised and contrastive backdoor attacks. Through the lens of TRL, we
uncover that the two types of attacks operate through distinctive mechanisms:
in supervised attacks, the learning of benign and backdoor tasks tends to occur
independently, while in contrastive attacks, the two tasks are deeply
intertwined both in their representations and throughout their learning
processes. This distinction leads to the disparate learning dynamics and
feature distributions of supervised and contrastive attacks. More importantly,
we reveal that the specificities of contrastive backdoor attacks entail
important implications from a defense perspective: existing defenses for
supervised attacks are often inadequate and not easily retrofitted to
contrastive attacks. We also explore several alternative defenses and discuss
their potential challenges. Our findings highlight the need for defenses
tailored to the specificities of contrastive backdoor attacks, pointing to
promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09058" title="Abstract">arXiv:2312.09058</a> [<a href="/pdf/2312.09058" title="Download PDF">pdf</a>, <a href="/format/2312.09058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Coalition Structures with Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y+E">Yixuan Even Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 3 tables, aaai 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Coalitions naturally exist in many real-world systems involving multiple
decision makers such as ridesharing, security, and online ad auctions, but the
coalition structure among the agents is often unknown. We propose and study an
important yet previously overseen problem -- Coalition Structure Learning
(CSL), where we aim to carefully design a series of games for the agents and
infer the underlying coalition structure by observing their interactions in
those games. We establish a lower bound on the sample complexity -- defined as
the number of games needed to learn the structure -- of any algorithms for CSL
and propose the Iterative Grouping (IG) algorithm for designing normal-form
games to achieve the lower bound. We show that IG can be extended to other
succinct games such as congestion games and graphical games. Moreover, we solve
CSL in a more restrictive and practical setting: auctions. We show a variant of
IG to solve CSL in the auction setting even if we cannot design the bidder
valuations. Finally, we conduct experiments to evaluate IG in the auction
setting and the results align with our theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09059" title="Abstract">arXiv:2312.09059</a> [<a href="/pdf/2312.09059" title="Download PDF">pdf</a>, <a href="/format/2312.09059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Prox: Training-Free Vision Transformer Architecture Search via  Automatic Proxy Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zimian Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peijie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Z">Zheng Hui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anggeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Menglong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hengyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepetd by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The substantial success of Vision Transformer (ViT) in computer vision tasks
is largely attributed to the architecture design. This underscores the
necessity of efficient architecture search for designing better ViTs
automatically. As training-based architecture search methods are
computationally intensive, there is a growing interest in training-free methods
that use zero-cost proxies to score ViTs. However, existing training-free
approaches require expert knowledge to manually design specific zero-cost
proxies. Moreover, these zero-cost proxies exhibit limitations to generalize
across diverse domains. In this paper, we introduce Auto-Prox, an automatic
proxy discovery framework, to address the problem. First, we build the
ViT-Bench-101, which involves different ViT candidates and their actual
performance on multiple datasets. Utilizing ViT-Bench-101, we can evaluate
zero-cost proxies based on their score-accuracy correlation. Then, we represent
zero-cost proxies with computation graphs and organize the zero-cost proxy
search space with ViT statistics and primitive operations. To discover generic
zero-cost proxies, we propose a joint correlation metric to evolve and mutate
different zero-cost proxy candidates. We introduce an elitism-preserve strategy
for search efficiency to achieve a better trade-off between exploitation and
exploration. Based on the discovered zero-cost proxy, we conduct a ViT
architecture search in a training-free manner. Extensive experiments
demonstrate that our method generalizes well to different datasets and achieves
state-of-the-art results both in ranking correlation and final accuracy. Codes
can be found at https://github.com/lilujunai/Auto-Prox-AAAI24.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09066" title="Abstract">arXiv:2312.09066</a> [<a href="/pdf/2312.09066" title="Download PDF">pdf</a>, <a href="/format/2312.09066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset  with High-Quality Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chi-hsuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shih-yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Minciullo%2C+L">Luca Minciullo</a>, 
<a href="/search/cs?searchtype=author&query=Yiu%2C+W+K">Wong Kai Yiu</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+K">Kenny Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Online learning is a rapidly growing industry due to its convenience.
However, a major challenge in online learning is whether students are as
engaged as they are in face-to-face classes. An engagement recognition system
can significantly improve the learning experience in online classes. Current
challenges in engagement detection involve poor label quality in the dataset,
intra-class variation, and extreme data imbalance. To address these problems,
we present the CMOSE dataset, which contains a large number of data in
different engagement levels and high-quality labels generated according to the
psychological advice. We demonstrate the advantage of transferability by
analyzing the model performance on other engagement datasets. We also developed
a training mechanism, MocoRank, to handle the intra-class variation, the
ordinal relationship between different classes, and the data imbalance problem.
MocoRank outperforms prior engagement detection losses, achieving a 1.32%
enhancement in overall accuracy and 5.05% improvement in average accuracy. We
further demonstrate the effectiveness of multi-modality by conducting ablation
studies on features such as pre-trained video features, high-level facial
features, and audio features.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09067" title="Abstract">arXiv:2312.09067</a> [<a href="/pdf/2312.09067" title="Download PDF">pdf</a>, <a href="/format/2312.09067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holodeck: Language Guided Generation of 3D Embodied AI Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fan-Yun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Weihs%2C+L">Luca Weihs</a>, 
<a href="/search/cs?searchtype=author&query=VanderBilt%2C+E">Eli VanderBilt</a>, 
<a href="/search/cs?searchtype=author&query=Herrasti%2C+A">Alvaro Herrasti</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Winson Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+N">Nick Haber</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>, 
<a href="/search/cs?searchtype=author&query=Yatskar%2C+M">Mark Yatskar</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+C">Christopher Clark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 24 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">3D simulated environments play a critical role in Embodied AI, but their
creation requires expertise and extensive manual effort, restricting their
diversity and scope. To mitigate this limitation, we present Holodeck, a system
that generates 3D environments to match a user-supplied prompt fully
automatedly. Holodeck can generate diverse scenes, e.g., arcades, spas, and
museums, adjust the designs for styles, and can capture the semantics of
complex queries such as "apartment for a researcher with a cat" and "office of
a professor who is a fan of Star Wars". Holodeck leverages a large language
model (GPT-4) for common sense knowledge about what the scene might look like
and uses a large collection of 3D assets from Objaverse to populate the scene
with diverse objects. To address the challenge of positioning objects
correctly, we prompt GPT-4 to generate spatial relational constraints between
objects and then optimize the layout to satisfy those constraints. Our
large-scale human evaluation shows that annotators prefer Holodeck over
manually designed procedural baselines in residential scenes and that Holodeck
can produce high-quality outputs for diverse scene types. We also demonstrate
an exciting application of Holodeck in Embodied AI, training agents to navigate
in novel scenes like music rooms and daycares without human-constructed data,
which is a significant step forward in developing general-purpose embodied
agents.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09069" title="Abstract">arXiv:2312.09069</a> [<a href="/pdf/2312.09069" title="Download PDF">pdf</a>, <a href="/format/2312.09069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying-Tian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Guan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Heyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce PI3D, a novel and efficient framework that
utilizes the pre-trained text-to-image diffusion models to generate
high-quality 3D shapes in minutes. On the one hand, it fine-tunes a pre-trained
2D diffusion model into a 3D diffusion model, enabling both 3D generative
capabilities and generalization derived from the 2D model. On the other, it
utilizes score distillation sampling of 2D diffusion models to quickly improve
the quality of the sampled 3D shapes. PI3D enables the migration of knowledge
from image to triplane generation by treating it as a set of pseudo-images. We
adapt the modules in the pre-training model to enable hybrid training using
pseudo and real images, which has proved to be a well-established strategy for
improving generalizability. The efficiency of PI3D is highlighted by its
ability to sample diverse 3D models in seconds and refine them in minutes. The
experimental results confirm the advantages of PI3D over existing methods based
on either 3D diffusion models or lifting 2D diffusion models in terms of fast
generation of 3D consistent and high-quality models. The proposed PI3D stands
as a promising advancement in the field of text-to-3D generation, and we hope
it will inspire more research into 3D generation leveraging the knowledge in
both 2D and 3D data.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09073" title="Abstract">arXiv:2312.09073</a> [<a href="/pdf/2312.09073" title="Download PDF">pdf</a>, <a href="/format/2312.09073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Motion Planning using Finite Fourier Series in a Learning-based  Collision Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yichang%2C+F">Feng Yichang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guodong%2C+L">Lu Guodong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper utilizes finite Fourier series to represent a time-continuous
motion and proposes a novel planning method that adjusts the motion harmonics
of each manipulator joint. Primarily, we sum the potential energy for collision
detection and the kinetic energy up to calculate the Hamiltonian of the
manipulator motion harmonics. Though the adaptive interior-point method is
designed to modify the harmonics in its finite frequency domain, we still
encounter the local minima due to the non-convexity of the collision field. In
this way, we learn the collision field through a support vector machine with a
Gaussian kernel, which is highly convex. The learning-based collision field is
applied for Hamiltonian, and the experiment results show our method's high
reliability and efficiency.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09075" title="Abstract">arXiv:2312.09075</a> [<a href="/pdf/2312.09075" title="Download PDF">pdf</a>, <a href="/format/2312.09075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Verifiable Text Generation with Evolving Memory and  Self-Reflection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yingyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaochi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) face several challenges, including the tendency
to produce incorrect outputs, known as hallucination. An effective solution is
verifiable text generation, which prompts LLMs to generate content with
citations for accuracy verification. However, verifiable text generation is
non-trivial due to the focus-shifting phenomenon, the dilemma between the
precision and scope in document retrieval, and the intricate reasoning required
to discern the relationship between the claim and citations. In this paper, we
present VTG, an innovative approach for Verifiable Text Generation with
evolving memory and self-reflection. VTG maintains evolving long short-term
memory to retain both valuable documents and up-to-date documents. Active
retrieval and diverse query generation are utilized to enhance both the
precision and scope of the retrieved documents. Furthermore, VTG features a
two-tier verifier and an evidence finder, enabling rethinking and reflection on
the relationship between the claim and citations. We conduct extensive
experiments on five datasets across three knowledge-intensive tasks and the
results reveal that VTG significantly outperforms existing baselines.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09076" title="Abstract">arXiv:2312.09076</a> [<a href="/pdf/2312.09076" title="Download PDF">pdf</a>, <a href="/format/2312.09076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProSGNeRF: Progressive Dynamic Neural Scene Graph with Frequency  Modulated Auto-Encoder in Urban Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+T">Tianchen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yejia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weidong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2011.10379">arXiv:2011.10379</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implicit neural representation has demonstrated promising results in view
synthesis for large and complex scenes. However, existing approaches either
fail to capture the fast-moving objects or need to build the scene graph
without camera ego-motions, leading to low-quality synthesized views of the
scene. We aim to jointly solve the view synthesis problem of large-scale urban
scenes and fast-moving vehicles, which is more practical and challenging. To
this end, we first leverage a graph structure to learn the local scene
representations of dynamic objects and the background. Then, we design a
progressive scheme that dynamically allocates a new local scene graph trained
with frames within a temporal window, allowing us to scale up the
representation to an arbitrarily large scene. Besides, the training views of
urban scenes are relatively sparse, which leads to a significant decline in
reconstruction accuracy for dynamic objects. Therefore, we design a frequency
auto-encoder network to encode the latent code and regularize the frequency
range of objects, which can enhance the representation of dynamic objects and
address the issue of sparse image inputs. Additionally, we employ lidar point
projection to maintain geometry consistency in large-scale urban scenes.
Experimental results demonstrate that our method achieves state-of-the-art view
synthesis accuracy, object manipulation, and scene roaming ability. The code
will be open-sourced upon paper acceptance.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09077" title="Abstract">arXiv:2312.09077</a> [<a href="/pdf/2312.09077" title="Download PDF">pdf</a>, <a href="/format/2312.09077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy Regularization and Faster Decremental Matching in General Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+T">Ta-Wei Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We provide an algorithm that maintains, against an adaptive adversary, a
$(1-\varepsilon)$-approximate maximum matching in $n$-node $m$-edge general
(not necessarily bipartite) undirected graph undergoing edge deletions with
high probability with (amortized) $O(\mathrm{poly}(\varepsilon^{-1}, \log n))$
time per update. We also obtain the same update time for maintaining a
fractional approximate weighted matching (and hence an approximation to the
value of the maximum weight matching) and an integral approximate weighted
matching in dense graphs. Our unweighted result improves upon the prior
state-of-the-art which includes a $\mathrm{poly}(\log{n}) \cdot
2^{O(1/\varepsilon^2)}$ update time [Assadi-Bernstein-Dudeja 2022] and an
$O(\sqrt{m} \varepsilon^{-2})$ update time [Gupta-Peng 2013], and our weighted
result improves upon the $O(\sqrt{m}\varepsilon^{-O(1/\varepsilon)}\log{n})$
update time due to [Gupta-Peng 2013].
<br />To obtain our results, we generalize a recent optimization approach to
dynamic algorithms from [Jambulapati-Jin-Sidford-Tian 2022]. We show that
repeatedly solving entropy-regularized optimization problems yields a lazy
updating scheme for fractional decremental problems with a near-optimal number
of updates. To apply this framework we develop optimization methods compatible
with it and new dynamic rounding algorithms for the matching polytope.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09078" title="Abstract">arXiv:2312.09078</a> [<a href="/pdf/2312.09078" title="Download PDF">pdf</a>, <a href="/format/2312.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coevolutionary Algorithm for Building Robust Decision Trees under  Minimax Regret
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%BBychowski%2C+A">Adam &#x17b;ychowski</a>, 
<a href="/search/cs?searchtype=author&query=Perrault%2C+A">Andrew Perrault</a>, 
<a href="/search/cs?searchtype=author&query=Ma%C5%84dziuk%2C+J">Jacek Ma&#x144;dziuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In recent years, there has been growing interest in developing robust machine
learning (ML) models that can withstand adversarial attacks, including one of
the most widely adopted, efficient, and interpretable ML algorithms-decision
trees (DTs). This paper proposes a novel coevolutionary algorithm (CoEvoRDT)
designed to create robust DTs capable of handling noisy high-dimensional data
in adversarial contexts. Motivated by the limitations of traditional DT
algorithms, we leverage adaptive coevolution to allow DTs to evolve and learn
from interactions with perturbed input data. CoEvoRDT alternately evolves
competing populations of DTs and perturbed features, enabling construction of
DTs with desired properties. CoEvoRDT is easily adaptable to various target
metrics, allowing the use of tailored robustness criteria such as minimax
regret. Furthermore, CoEvoRDT has potential to improve the results of other
state-of-the-art methods by incorporating their outcomes (DTs they produce)
into the initial population and optimize them in the process of coevolution.
Inspired by the game theory, CoEvoRDT utilizes mixed Nash equilibrium to
enhance convergence. The method is tested on 20 popular datasets and shows
superior performance compared to 4 state-of-the-art algorithms. It outperformed
all competing methods on 13 datasets with adversarial accuracy metrics, and on
all 20 considered datasets with minimax regret. Strong experimental results and
flexibility in choosing the error measure make CoEvoRDT a promising approach
for constructing robust DTs in real-world applications.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09080" title="Abstract">arXiv:2312.09080</a> [<a href="/pdf/2312.09080" title="Download PDF">pdf</a>, <a href="/format/2312.09080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Differential Sweeping Method for Ultrasound Waves with Fractional  Attenuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Acosta%2C+S">Sebastian Acosta</a>, 
<a href="/search/math?searchtype=author&query=Chan%2C+J">Jesse Chan</a>, 
<a href="/search/math?searchtype=author&query=Johnson%2C+R">Raven Johnson</a>, 
<a href="/search/math?searchtype=author&query=Palacios%2C+B">Benjamin Palacios</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We derive a pseudo-differential factorization of the wave operator with
fractional attenuation. This factorization allows us to approximately solve the
Helmholtz equation via a two-way (transmission and reflection) sweeping scheme
tailored to high-frequency wave fields. We provide explicitly the three highest
order terms of the pseudo-differential expansion to incorporate the well-known
square-root first order symbol for wave propagation, the zeroth order symbol
for amplitude modulation due to changes in wave speed and damping, and the next
symbol to model fractional attenuation. We also propose wide-angle Pad\'e
approximations for the pseudo-differential operators corresponding to these
three highest order symbols. Our analysis provides insights regarding the role
played by the frequency and the Pad\'e approximations in the estimation of
error bounds. We also provide a proof-of-concept numerical implementation of
the proposed method and test the error estimates numerically.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09082" title="Abstract">arXiv:2312.09082</a> [<a href="/pdf/2312.09082" title="Download PDF">pdf</a>, <a href="/format/2312.09082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Fusion: 3D Object Detection using Calibration-Free Transformer  Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%BCrst%2C+M">Michael F&#xfc;rst</a>, 
<a href="/search/cs?searchtype=author&query=Jakkamsetty%2C+R">Rahul Jakkamsetty</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+R">Ren&#xe9; Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The state of the art in 3D object detection using sensor fusion heavily
relies on calibration quality, which is difficult to maintain in large scale
deployment outside a lab environment. We present the first calibration-free
approach for 3D object detection. Thus, eliminating the need for complex and
costly calibration procedures. Our approach uses transformers to map the
features between multiple views of different sensors at multiple abstraction
levels. In an extensive evaluation for object detection, we not only show that
our approach outperforms single modal setups by 14.1% in BEV mAP, but also that
the transformer indeed learns mapping. By showing calibration is not necessary
for sensor fusion, we hope to motivate other researchers following the
direction of calibration-free fusion. Additionally, resulting approaches have a
substantial resilience against rotation and translation changes.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09084" title="Abstract">arXiv:2312.09084</a> [<a href="/pdf/2312.09084" title="Download PDF">pdf</a>, <a href="/format/2312.09084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Modeling on a SpiNNaker 2 Neuromorphic Chip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazeer%2C+K+K">Khaleelulla Khan Nazeer</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ne%2C+M">Mark Sch&#xf6;ne</a>, 
<a href="/search/cs?searchtype=author&query=Mukherji%2C+R">Rishav Mukherji</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+C">Christian Mayr</a>, 
<a href="/search/cs?searchtype=author&query=Kappel%2C+D">David Kappel</a>, 
<a href="/search/cs?searchtype=author&query=Subramoney%2C+A">Anand Subramoney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computation and Language (cs.CL); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models continue to scale in size rapidly, so too does the
computational power required to run them. Event-based networks on neuromorphic
devices offer a potential way to reduce energy consumption for inference
significantly. However, to date, most event-based networks that can run on
neuromorphic hardware, including spiking neural networks (SNNs), have not
achieved task performance even on par with LSTM models for language modeling.
As a result, language modeling on neuromorphic devices has seemed a distant
prospect. In this work, we demonstrate the first-ever implementation of a
language model on a neuromorphic device - specifically the SpiNNaker 2 chip -
based on a recently published event-based architecture called the EGRU.
SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale
asynchronous processing, while the EGRU is architected to leverage such
hardware efficiently while maintaining competitive task performance. This
implementation marks the first time a neuromorphic language model matches
LSTMs, setting the stage for taking task performance to the level of large
language models. We also demonstrate results on a gesture recognition task
based on inputs from a DVS camera. Overall, our results showcase the
feasibility of this neuro-inspired neural network in hardware, highlighting
significant gains versus conventional hardware in energy efficiency for the
common use case of single batch inference.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09085" title="Abstract">arXiv:2312.09085</a> [<a href="/pdf/2312.09085" title="Download PDF">pdf</a>, <a href="/format/2312.09085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Earth is Flat because...: Investigating LLMs&#x27; Belief towards  Misinformation via Persuasive Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+S">Brian S. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shujian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiyan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhixuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large Language Models (LLMs) encapsulate vast amounts of knowledge but still
remain vulnerable to external misinformation. Existing research mainly studied
this susceptibility behavior in a single-turn setting. However, belief can
change during a multi-turn conversation, especially a persuasive one.
Therefore, in this study, we delve into LLMs' susceptibility to persuasive
conversations, particularly on factual questions that they can answer
correctly. We first curate the Farm (i.e., Fact to Misinform) dataset, which
contains factual questions paired with systematically generated persuasive
misinformation. Then, we develop a testing framework to track LLMs' belief
changes in a persuasive dialogue. Through extensive experiments, we find that
LLMs' correct beliefs on factual knowledge can be easily manipulated by various
persuasive strategies.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09086" title="Abstract">arXiv:2312.09086</a> [<a href="/pdf/2312.09086" title="Download PDF">pdf</a>, <a href="/format/2312.09086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMBHelper: A Neural Approach to Reduce Search Space for Graph  Combinatorial Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Medya%2C+S">Sourav Medya</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Combinatorial Optimization (CO) problems over graphs appear routinely in many
applications such as in optimizing traffic, viral marketing in social networks,
and matching for job allocation. Due to their combinatorial nature, these
problems are often NP-hard. Existing approximation algorithms and heuristics
rely on the search space to find the solutions and become time-consuming when
this space is large. In this paper, we design a neural method called COMBHelper
to reduce this space and thus improve the efficiency of the traditional CO
algorithms based on node selection. Specifically, it employs a Graph Neural
Network (GNN) to identify promising nodes for the solution set. This pruned
search space is then fed to the traditional CO algorithms. COMBHelper also uses
a Knowledge Distillation (KD) module and a problem-specific boosting module to
bring further efficiency and efficacy. Our extensive experiments show that the
traditional CO algorithms with COMBHelper are at least 2 times faster than
their original versions.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09087" title="Abstract">arXiv:2312.09087</a> [<a href="/pdf/2312.09087" title="Download PDF">pdf</a>, <a href="/format/2312.09087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Trusted Runtime for WebAssembly with Intel SGX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A9n%C3%A9trey%2C+J">J&#xe4;mes M&#xe9;n&#xe9;trey</a>, 
<a href="/search/cs?searchtype=author&query=Pasin%2C+M">Marcelo Pasin</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+P">Pascal Felber</a>, 
<a href="/search/cs?searchtype=author&query=Schiavoni%2C+V">Valerio Schiavoni</a>, 
<a href="/search/cs?searchtype=author&query=Mazzeo%2C+G">Giovanni Mazzeo</a>, 
<a href="/search/cs?searchtype=author&query=Hollum%2C+A">Arne Hollum</a>, 
<a href="/search/cs?searchtype=author&query=Vaydia%2C+D">Darshan Vaydia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197. arXiv admin note: text overlap with <a href="/abs/2103.15860">arXiv:2103.15860</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TDSC: IEEE Transactions on Dependable and Secure Computing,
  November, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Performance (cs.PF); Programming Languages (cs.PL)

</div>
<p class="mathjax">In real-world scenarios, trusted execution environments (TEEs) frequently
host applications that lack the trust of the infrastructure provider, as well
as data owners who have specifically outsourced their data for remote
processing. We present Twine, a trusted runtime for running
WebAssembly-compiled applications within TEEs, establishing a two-way sandbox.
Twine leverages memory safety guarantees of WebAssembly (Wasm) and abstracts
the complexity of TEEs, empowering the execution of legacy and
language-agnostic applications. It extends the standard WebAssembly system
interface (WASI), providing controlled OS services, focusing on I/O.
Additionally, through built-in TEE mechanisms, Twine delivers attestation
capabilities to ensure the integrity of the runtime and the OS services
supplied to the application. We evaluate its performance using general-purpose
benchmarks and real-world applications, showing it compares on par with
state-of-the-art solutions. A case study involving fintech company Credora
reveals that Twine can be deployed in production with reasonable performance
trade-offs, ranging from a 0.7x slowdown to a 1.17x speedup compared to native
run time. Finally, we identify performance improvement through library
optimisation, showcasing one such adjustment that leads up to 4.1x speedup.
Twine is open-source and has been upstreamed into the original Wasm runtime,
WAMR.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09093" title="Abstract">arXiv:2312.09093</a> [<a href="/pdf/2312.09093" title="Download PDF">pdf</a>, <a href="/format/2312.09093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aleth-NeRF: Illumination Adaptive NeRF with Concealing Field Assumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Ziteng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+L">Lin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianzheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, code available at <a href="https://github.com/cuiziteng/Aleth-NeRF.">this https URL</a> Modified version of previous paper <a href="/abs/2303.05807">arXiv:2303.05807</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The standard Neural Radiance Fields (NeRF) paradigm employs a viewer-centered
methodology, entangling the aspects of illumination and material reflectance
into emission solely from 3D points. This simplified rendering approach
presents challenges in accurately modeling images captured under adverse
lighting conditions, such as low light or over-exposure. Motivated by the
ancient Greek emission theory that posits visual perception as a result of rays
emanating from the eyes, we slightly refine the conventional NeRF framework to
train NeRF under challenging light conditions and generate normal-light
condition novel views unsupervised. We introduce the concept of a "Concealing
Field," which assigns transmittance values to the surrounding air to account
for illumination effects. In dark scenarios, we assume that object emissions
maintain a standard lighting level but are attenuated as they traverse the air
during the rendering process. Concealing Field thus compel NeRF to learn
reasonable density and colour estimations for objects even in dimly lit
situations. Similarly, the Concealing Field can mitigate over-exposed emissions
during the rendering stage. Furthermore, we present a comprehensive multi-view
dataset captured under challenging illumination conditions for evaluation. Our
code and dataset available at https://github.com/cuiziteng/Aleth-NeRF
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09094" title="Abstract">arXiv:2312.09094</a> [<a href="/pdf/2312.09094" title="Download PDF">pdf</a>, <a href="/format/2312.09094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hopf Arborescent Links, Minor Theory, and Decidability of the Genus  Defect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehornoy%2C+P">Pierre Dehornoy</a>, 
<a href="/search/cs?searchtype=author&query=Lunel%2C+C">Corentin Lunel</a>, 
<a href="/search/cs?searchtype=author&query=de+Mesmay%2C+A">Arnaud de Mesmay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Geometric Topology (math.GT)

</div>
<p class="mathjax">While the problem of computing the genus of a knot is now fairly well
understood, no algorithm is known for its four-dimensional variants, both in
the smooth and in the topological locally flat category. In this article, we
investigate a class of knots and links called Hopf arborescent links, which are
obtained as the boundaries of some iterated plumbings of Hopf bands. We show
that for such links, computing the genus defects, which measure how much the
four-dimensional genera differ from the classical genus, is decidable. Our
proof is non-constructive, and is obtained by proving that Seifert surfaces of
Hopf arborescent links under a relation of minors defined by containment of
their Seifert surfaces form a well-quasi-order.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09095" title="Abstract">arXiv:2312.09095</a> [<a href="/pdf/2312.09095" title="Download PDF">pdf</a>, <a href="/format/2312.09095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ColNeRF: Collaboration for Generalizable Sparse Input Neural Radiance  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhangkai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peiqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kwong%2C+S">Sam Kwong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have demonstrated impressive potential in
synthesizing novel views from dense input, however, their effectiveness is
challenged when dealing with sparse input. Existing approaches that incorporate
additional depth or semantic supervision can alleviate this issue to an extent.
However, the process of supervision collection is not only costly but also
potentially inaccurate, leading to poor performance and generalization ability
in diverse scenarios. In our work, we introduce a novel model: the
Collaborative Neural Radiance Fields (ColNeRF) designed to work with sparse
input. The collaboration in ColNeRF includes both the cooperation between
sparse input images and the cooperation between the output of the neural
radiation field. Through this, we construct a novel collaborative module that
aligns information from various views and meanwhile imposes self-supervised
constraints to ensure multi-view consistency in both geometry and appearance. A
Collaborative Cross-View Volume Integration module (CCVI) is proposed to
capture complex occlusions and implicitly infer the spatial location of
objects. Moreover, we introduce self-supervision of target rays projected in
multiple directions to ensure geometric and color consistency in adjacent
regions. Benefiting from the collaboration at the input and output ends,
ColNeRF is capable of capturing richer and more generalized scene
representation, thereby facilitating higher-quality results of the novel view
synthesis. Extensive experiments demonstrate that ColNeRF outperforms
state-of-the-art sparse input generalizable NeRF methods. Furthermore, our
approach exhibits superiority in fine-tuning towards adapting to new scenes,
achieving competitive performance compared to per-scene optimized NeRF-based
methods while significantly reducing computational costs. Our code is available
at: https://github.com/eezkni/ColNeRF.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09098" title="Abstract">arXiv:2312.09098</a> [<a href="/pdf/2312.09098" title="Download PDF">pdf</a>, <a href="/format/2312.09098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A variant of the Raviart-Thomas method to handle smooth domains using  straight-edged triangles. Part II -- Approximation results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Formerly appeared in <a href="/abs/2307.03503">arXiv:2307.03503v2</a>, now split into two parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In <a href="/abs/2307.03503">arXiv:2307.03503</a> [math.NA] we commenced to study a variant of the
Raviart-Thomas mixed finite element method for triangles, to solve second order
elliptic equations in a curved domain with Neumann or mixed boundary
conditions. It is well known that in such a case the normal component of the
flux variable should not take up values at nodes shifted to the boundary of the
approximating polytope in the corresponding normal direction. This is because
the method's accuracy downgrades, which was shown in previous work by the first
author et al. An order-preserving technique was studied therein, based on a
parametric version of these elements with curved simplexes. Our variant is an
alternative to the approach advocated in those articles, allowing to achieve
the same effect with straight-edged triangles. The key point of this method is
a Petrov-Galerkin formulation of the mixed problem, in which the test-flux
space is a little different from the shape-flux space. In this paper we first
recall the description of this method, together with underlying uniform
stability results given in <a href="/abs/2307.03503">arXiv:2307.03503</a> [math.NA]. Then we show that it
gives rise to optimal-order interpolation in the space H(div). Accordingly a
priori error estimates are obtained for the Poisson equation taken as a model.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09107" title="Abstract">arXiv:2312.09107</a> [<a href="/pdf/2312.09107" title="Download PDF">pdf</a>, <a href="/ps/2312.09107" title="Download PostScript">ps</a>, <a href="/format/2312.09107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Approach to Ensuring Quality in Spreadsheet-Based  Metadata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+M+J">Martin J. O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Romero%2C+M">Marcos Mart&#xed;nez-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Akdogan%2C+M+U">Mete Ugur Akdogan</a>, 
<a href="/search/cs?searchtype=author&query=Hardi%2C+J">Josef Hardi</a>, 
<a href="/search/cs?searchtype=author&query=Musen%2C+M+A">Mark A. Musen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">While scientists increasingly recognize the importance of metadata in
describing their data, spreadsheets remain the preferred tool for supplying
this information despite their limitations in ensuring compliance and quality.
Various tools have been developed to address these limitations, but they suffer
from their own shortcomings, such as steep learning curves and limited
customization. In this paper, we describe an end-to-end approach that supports
spreadsheet-based entry of metadata while providing rigorous compliance and
quality control. Our approach employs several key strategies, including
customizable templates for defining metadata, integral support for the use of
controlled terminologies when defining these templates, and an interactive
Web-based tool that allows users to rapidly identify and fix errors in the
spreadsheet-based metadata they supply. We demonstrate how this approach is
being deployed in a biomedical consortium to define and collect metadata about
scientific experiments.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09108" title="Abstract">arXiv:2312.09108</a> [<a href="/pdf/2312.09108" title="Download PDF">pdf</a>, <a href="/format/2312.09108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Shapley Client Selection for Communication-Efficient Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+P">Pranava Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Communication Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The standard client selection algorithms for Federated Learning (FL) are
often unbiased and involve uniform random sampling of clients. This has been
proven sub-optimal for fast convergence under practical settings characterized
by significant heterogeneity in data distribution and computing and
communication resources across clients. For applications having timing
constraints due to limited communication opportunities, the client selection
strategy is critical to complete model training within the fixed budget of
communication rounds. To address this, we develop a biased client selection
strategy, GreedyFed that identifies and greedily selects the most contributing
clients in each communication round. This method builds on a fast approximation
algorithm for the Shapley Value at the parameter server (PS), making the
computation tractable for real-world applications with many clients. Compared
to various client selection strategies on several real-world datasets,
GreedyFed demonstrates fast and stable convergence with high accuracy under
timing constraints and a higher degree of heterogeneity in data distribution,
systems constraints, and privacy requirements.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09109" title="Abstract">arXiv:2312.09109</a> [<a href="/pdf/2312.09109" title="Download PDF">pdf</a>, <a href="/format/2312.09109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoLCM: Video Latent Consistency Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Consistency models have demonstrated powerful capability in efficient image
generation and allowed synthesis within a few sampling steps, alleviating the
high computational cost in diffusion models. However, the consistency model in
the more challenging and resource-consuming video generation is still less
explored. In this report, we present the VideoLCM framework to fill this gap,
which leverages the concept of consistency models from image generation to
efficiently synthesize videos with minimal steps while maintaining high
quality. VideoLCM builds upon existing latent video diffusion models and
incorporates consistency distillation techniques for training the latent
consistency model. Experimental results reveal the effectiveness of our
VideoLCM in terms of computational efficiency, fidelity and temporal
consistency. Notably, VideoLCM achieves high-fidelity and smooth video
synthesis with only four sampling steps, showcasing the potential for real-time
synthesis. We hope that VideoLCM can serve as a simple yet effective baseline
for subsequent research. The source code and models will be publicly available.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09116" title="Abstract">arXiv:2312.09116</a> [<a href="/pdf/2312.09116" title="Download PDF">pdf</a>, <a href="/format/2312.09116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Computation of Non-Equilateral Quantum Graph Spectra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dr%C3%B6ge%2C+C">Chong-Son Dr&#xf6;ge</a>, 
<a href="/search/math?searchtype=author&query=Weller%2C+A">Anna Weller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In the broad range of studies related to quantum graphs, quantum graph
spectra appear as a topic of special interest. They are important in the
context of diffusion type problems posed on metric graphs. Theoretical findings
suggest that quantum graph eigenvalues can be found as the solutions of a
nonlinear eigenvalue problem, and in the special case of equilateral graphs,
even as the solutions of a linear eigenvalue problem on the underlying
combinatorial graph. The latter, remarkable relation to combinatorial graph
spectra will be exploited to derive a solver for the general, non-equilateral
case. Eigenvalue estimates from equilateral approximations will be applied as
initial guesses in a Newton-trace iteration to solve the nonlinear eigenvalue
problem.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09118" title="Abstract">arXiv:2312.09118</a> [<a href="/pdf/2312.09118" title="Download PDF">pdf</a>, <a href="/format/2312.09118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LayerZero
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarick%2C+R">Ryan Zarick</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrino%2C+B">Bryan Pellegrino</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+I">Isaac Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Thomas Kim</a>, 
<a href="/search/cs?searchtype=author&query=Banister%2C+C">Caleb Banister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this paper, we present the first instrinsically secure and semantically
universal omnichain interoperability protocol: LayerZero. Utilizing an
immutable endpoint, append-only verification modules, and fully-configurable
verification infrastructure, LayerZero provides the security, configurability,
and extensibility necessary to achieve omnichain interoperability. LayerZero
enforces strict application-exclusive ownership of protocol security and cost
through its novel trust-minimized modular security framework which is designed
to universally support all blockchains and use cases. Omnichain applications
(OApps) built on the LayerZero protocol achieve frictionless
blockchain-agnostic interoperation through LayerZero's universal network
semantics.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09119" title="Abstract">arXiv:2312.09119</a> [<a href="/pdf/2312.09119" title="Download PDF">pdf</a>, <a href="/ps/2312.09119" title="Download PostScript">ps</a>, <a href="/format/2312.09119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability in Online Coalition Formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+M">Martin Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Romen%2C+R">Ren&#xe9; Romen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Coalition formation is concerned with the question of how to partition a set
of agents into disjoint coalitions according to their preferences. Deviating
from most of the previous work, we consider an online variant of the problem,
where agents arrive in sequence and whenever an agent arrives, they have to be
assigned to a coalition immediately and irrevocably. The scarce existing
literature on online coalition formation has focused on the objective of
maximizing social welfare, a demanding requirement, even in the offline
setting. Instead, we seek to achieve stable coalition structures in an online
setting, and focus on stability concepts based on deviations by single agents.
We present a comprehensive picture in additively separable hedonic games,
leading to dichotomies, where positive results are obtained by deterministic
algorithms and negative results even hold for randomized algorithms.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09120" title="Abstract">arXiv:2312.09120</a> [<a href="/pdf/2312.09120" title="Download PDF">pdf</a>, <a href="/format/2312.09120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is more -- the Dispatcher/ Executor principle for multi-task  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Hertweck%2C+T">Tim Hertweck</a>, 
<a href="/search/cs?searchtype=author&query=Hafner%2C+R">Roland Hafner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures. Videos showing the results can be found at <a href="https://sites.google.com/view/dispatcher-executor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Humans instinctively know how to neglect details when it comes to solve
complex decision making problems in environments with unforeseeable variations.
This abstraction process seems to be a vital property for most biological
systems and helps to 'abstract away' unnecessary details and boost
generalisation. In this work we introduce the dispatcher/ executor principle
for the design of multi-task Reinforcement Learning controllers. It suggests to
partition the controller in two entities, one that understands the task (the
dispatcher) and one that computes the controls for the specific device (the
executor) - and to connect these two by a strongly regularizing communication
channel. The core rationale behind this position paper is that changes in
structure and design principles can improve generalisation properties and
drastically enforce data-efficiency. It is in some sense a 'yes, and ...'
response to the current trend of using large neural networks trained on vast
amounts of data and bet on emerging generalisation properties. While we agree
on the power of scaling - in the sense of Sutton's 'bitter lesson' - we will
give some evidence, that considering structure and adding design principles can
be a valuable and critical component in particular when data is not abundant
and infinite, but is a precious resource.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09123" title="Abstract">arXiv:2312.09123</a> [<a href="/pdf/2312.09123" title="Download PDF">pdf</a>, <a href="/format/2312.09123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRL-PoS: A Multi-agent Reinforcement Learning based Proof of Stake  Consensus Algorithm for Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+T">Tariqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Bappy%2C+F+H">Faisal Haque Bappy</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+T+S">Tarannum Shaila Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Sajid%2C+M+S+I">Md Sajidul Islam Sajid</a>, 
<a href="/search/cs?searchtype=author&query=Pritom%2C+M+M+A">Mir Mehedi Ahsan Pritom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The core of a blockchain network is its consensus algorithm. Starting with
the Proof-of-Work, there have been various versions of consensus algorithms,
such as Proof-of-Stake (PoS), Proof-of-Authority (PoA), and Practical Byzantine
Fault Tolerance (PBFT). Each of these algorithms focuses on different aspects
to ensure efficient and reliable processing of transactions. Blockchain
operates in a decentralized manner where there is no central authority and the
network is composed of diverse users. This openness creates the potential for
malicious nodes to disrupt the network in various ways. Therefore, it is
crucial to embed a mechanism within the blockchain network to constantly
monitor, identify, and eliminate these malicious nodes. However, there is no
one-size-fits-all mechanism to identify all malicious nodes. Hence, the dynamic
adaptability of the blockchain network is important to maintain security and
reliability at all times. This paper introduces MRL-PoS, a Proof-of-Stake
consensus algorithm based on multi-agent reinforcement learning. MRL-PoS
employs reinforcement learning for dynamically adjusting to the behavior of all
users. It incorporates a system of rewards and penalties to eliminate malicious
nodes and incentivize honest ones. Additionally, MRL-PoS has the capability to
learn and respond to new malicious tactics by continually training its agents.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09125" title="Abstract">arXiv:2312.09125</a> [<a href="/pdf/2312.09125" title="Download PDF">pdf</a>, <a href="/format/2312.09125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Puppy: A Publicly Verifiable Watermarking Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%B0%C5%9Fler%2C+D">Devri&#x15f; &#x130;&#x15f;ler</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seoyeon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Nakatsuka%2C+Y">Yoshimichi Nakatsuka</a>, 
<a href="/search/cs?searchtype=author&query=Laoutaris%2C+N">Nikolaos Laoutaris</a>, 
<a href="/search/cs?searchtype=author&query=Tsudik%2C+G">Gene Tsudik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In this paper, we propose Puppy, the first formally defined framework for
converting any symmetric watermarking into a publicly verifiable one. Puppy
allows anyone to verify a watermark any number of times with the help of an
untrusted third party, without requiring owner presence during detection. We
formally define and prove security of Puppy using the ideal/real-world
simulation paradigm and construct two practical and secure instances: (1)
Puppy-TEE that uses Trusted Execution Environments (TEEs), and (2) Puppy-2PC
that relies on two-party computation (2PC) based on garbled circuits. We then
convert four current symmetric watermarking schemes into publicly verifiable
ones and run extensive experiments using Puppy-TEE and Puppy-2PC. Evaluation
results show that, while Puppy-TEE incurs some overhead, its total latency is
on the order of milliseconds for three out of four watermarking schemes.
Although the overhead of Puppy-2PC is higher (on the order of seconds), it is
viable for settings that lack a TEE or where strong trust assumptions about a
TEE need to be avoided. We further optimize the solution to increase its
scalability and resilience to denial of service attacks via memoization.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09126" title="Abstract">arXiv:2312.09126</a> [<a href="/pdf/2312.09126" title="Download PDF">pdf</a>, <a href="/format/2312.09126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Trustworthy AI Software Development Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maninger%2C+D">Daniel Maninger</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Krishna Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Mezini%2C+M">Mira Mezini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure; to be published in ICSE-NIER '24: Proceedings of the 46th International Conference on Software Engineering: New Ideas and Emerging Results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">It is expected that in the near future, AI software development assistants
will play an important role in the software industry. However, current software
development assistants tend to be unreliable, often producing incorrect,
unsafe, or low-quality code. We seek to resolve these issues by introducing a
holistic architecture for constructing, training, and using trustworthy AI
software development assistants. In the center of the architecture, there is a
foundational LLM trained on datasets representative of real-world coding
scenarios and complex software architectures, and fine-tuned on code quality
criteria beyond correctness. The LLM will make use of graph-based code
representations for advanced semantic comprehension. We envision a knowledge
graph integrated into the system to provide up-to-date background knowledge and
to enable the assistant to provide appropriate explanations. Finally, a modular
framework for constrained decoding will ensure that certain guarantees (e.g.,
for correctness and security) hold for the generated code.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09128" title="Abstract">arXiv:2312.09128</a> [<a href="/pdf/2312.09128" title="Download PDF">pdf</a>, <a href="/format/2312.09128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tokenize Anything via Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+T">Ting Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lulu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code, model, and demo: <a href="https://github.com/baaivision/tokenize-anything">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a unified, promptable model capable of simultaneously segmenting,
recognizing, and captioning anything. Unlike SAM, we aim to build a versatile
region representation in the wild via visual prompting. To achieve this, we
train a generalizable model with massive segmentation masks, e.g., SA-1B masks,
and semantic priors from a pre-trained CLIP model with 5 billion parameters.
Specifically, we construct a promptable image decoder by adding a semantic
token to each mask token. The semantic token is responsible for learning the
semantic priors in a predefined concept space. Through joint optimization of
segmentation on mask tokens and concept prediction on semantic tokens, our
model exhibits strong regional recognition and localization capabilities. For
example, an additional 38M-parameter causal text decoder trained from scratch
sets a new record with a CIDEr score of 150.7 on the Visual Genome region
captioning task. We believe this model can be a versatile region-level image
tokenizer, capable of encoding general-purpose region context for a broad range
of perception tasks. Code and models are available at
https://github.com/baaivision/tokenize-anything.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09138" title="Abstract">arXiv:2312.09138</a> [<a href="/pdf/2312.09138" title="Download PDF">pdf</a>, <a href="/format/2312.09138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Living Scenes: Multi-object Relocalization and Reconstruction in  Changing 3D Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Armeni%2C+I">Iro Armeni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Research into dynamic 3D scene understanding has primarily focused on
short-term change tracking from dense observations, while little attention has
been paid to long-term changes with sparse observations. We address this gap
with MoRE, a novel approach for multi-object relocalization and reconstruction
in evolving environments. We view these environments as "living scenes" and
consider the problem of transforming scans taken at different points in time
into a 3D reconstruction of the object instances, whose accuracy and
completeness increase over time. At the core of our method lies an
SE(3)-equivariant representation in a single encoder-decoder network, trained
on synthetic data. This representation enables us to seamlessly tackle instance
matching, registration, and reconstruction. We also introduce a joint
optimization algorithm that facilitates the accumulation of point clouds
originating from the same instance across multiple scans taken at different
points in time. We validate our method on synthetic and real-world data and
demonstrate state-of-the-art performance in both end-to-end performance and
individual subtasks.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09139" title="Abstract">arXiv:2312.09139</a> [<a href="/pdf/2312.09139" title="Download PDF">pdf</a>, <a href="/format/2312.09139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Wise Buffer Management for Incremental Object Detection: An  Effective Buffer Training Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sumin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Tiruneh%2C+Y+Y">Yihalem Yimolal Tiruneh</a>, 
<a href="/search/cs?searchtype=author&query=On%2C+J">Jeongwan On</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jihyun Song</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sunhwa Choi</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungryul Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class incremental learning aims to solve a problem that arises when
continuously adding unseen class instances to an existing model This approach
has been extensively studied in the context of image classification; however
its applicability to object detection is not well established yet. Existing
frameworks using replay methods mainly collect replay data without considering
the model being trained and tend to rely on randomness or the number of labels
of each sample. Also, despite the effectiveness of the replay, it was not yet
optimized for the object detection task. In this paper, we introduce an
effective buffer training strategy (eBTS) that creates the optimized replay
buffer on object detection. Our approach incorporates guarantee minimum and
hierarchical sampling to establish the buffer customized to the trained model.
%These methods can facilitate effective retrieval of prior knowledge.
Furthermore, we use the circular experience replay training to optimally
utilize the accumulated buffer data. Experiments on the MS COCO dataset
demonstrate that our eBTS achieves state-of-the-art performance compared to the
existing replay schemes.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09143" title="Abstract">arXiv:2312.09143</a> [<a href="/pdf/2312.09143" title="Download PDF">pdf</a>, <a href="/format/2312.09143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> F1-EV Score: Measuring the Likelihood of Estimating a Good Decision  Threshold for Semi-Supervised Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkinghoff%2C+K">Kevin Wilkinghoff</a>, 
<a href="/search/cs?searchtype=author&query=Imoto%2C+K">Keisuke Imoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Anomalous sound detection (ASD) systems are usually compared by using
threshold-independent performance measures such as AUC-ROC. However, for
practical applications a decision threshold is needed to decide whether a given
test sample is normal or anomalous. Estimating such a threshold is highly
non-trivial in a semi-supervised setting where only normal training samples are
available. In this work, F1-EV a novel threshold-independent performance
measure for ASD systems that also includes the likelihood of estimating a good
decision threshold is proposed and motivated using specific toy examples. In
experimental evaluations, multiple performance measures are evaluated for all
systems submitted to the ASD task of the DCASE Challenge 2023. It is shown that
F1-EV is strongly correlated with AUC-ROC while having a significantly stronger
correlation with the F1-score obtained with estimated and optimal decision
thresholds than AUC-ROC.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09147" title="Abstract">arXiv:2312.09147</a> [<a href="/pdf/2312.09147" title="Download PDF">pdf</a>, <a href="/format/2312.09147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D  Reconstruction with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zi-Xin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhipeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Ding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in 3D reconstruction from single images have been driven
by the evolution of generative models. Prominent among these are methods based
on Score Distillation Sampling (SDS) and the adaptation of diffusion models in
the 3D domain. Despite their progress, these techniques often face limitations
due to slow optimization or rendering processes, leading to extensive training
and optimization times. In this paper, we introduce a novel approach for
single-view reconstruction that efficiently generates a 3D model from a single
image via feed-forward inference. Our method utilizes two transformer-based
networks, namely a point decoder and a triplane decoder, to reconstruct 3D
objects using a hybrid Triplane-Gaussian intermediate representation. This
hybrid representation strikes a balance, achieving a faster rendering speed
compared to implicit representations while simultaneously delivering superior
rendering quality than explicit representations. The point decoder is designed
for generating point clouds from single images, offering an explicit
representation which is then utilized by the triplane decoder to query Gaussian
features for each point. This design choice addresses the challenges associated
with directly regressing explicit 3D Gaussian attributes characterized by their
non-structural nature. Subsequently, the 3D Gaussians are decoded by an MLP to
enable rapid rendering through splatting. Both decoders are built upon a
scalable, transformer-based architecture and have been efficiently trained on
large-scale 3D datasets. The evaluations conducted on both synthetic datasets
and real-world images demonstrate that our method not only achieves higher
quality but also ensures a faster runtime in comparison to previous
state-of-the-art techniques. Please see our project page at
https://zouzx.github.io/TriplaneGaussian/.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09148" title="Abstract">arXiv:2312.09148</a> [<a href="/pdf/2312.09148" title="Download PDF">pdf</a>, <a href="/format/2312.09148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model  Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anthony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huanrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yulu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Gudovskiy%2C+D+A">Denis A Gudovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Okuno%2C+T">Tomoyuki Okuno</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+Y">Yohei Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes will be publicly available at <a href="https://antonioo-c.github.io/projects/split-ensemble">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Uncertainty estimation is crucial for machine learning models to detect
out-of-distribution (OOD) inputs. However, the conventional discriminative deep
learning classifiers produce uncalibrated closed-set predictions for OOD data.
A more robust classifiers with the uncertainty estimation typically require a
potentially unavailable OOD dataset for outlier exposure training, or a
considerable amount of additional memory and compute to build ensemble models.
In this work, we improve on uncertainty estimation without extra OOD data or
additional inference costs using an alternative Split-Ensemble method.
Specifically, we propose a novel subtask-splitting ensemble training objective,
where a common multiclass classification task is split into several
complementary subtasks. Then, each subtask's training data can be considered as
OOD to the other subtasks. Diverse submodels can therefore be trained on each
subtask with OOD-aware objectives. The subtask-splitting objective enables us
to share low-level features across submodels to avoid parameter and
computational overheads. In particular, we build a tree-like Split-Ensemble
architecture by performing iterative splitting and pruning from a shared
backbone model, where each branch serves as a submodel corresponding to a
subtask. This leads to improved accuracy and uncertainty estimation across
submodels under a fixed ensemble computation budget. Empirical study with
ResNet-18 backbone shows Split-Ensemble, without additional computation cost,
improves accuracy over a single model by 0.8%, 1.8%, and 25.5% on CIFAR-10,
CIFAR-100, and Tiny-ImageNet, respectively. OOD detection for the same backbone
and in-distribution datasets surpasses a single model baseline by,
correspondingly, 2.2%, 8.1%, and 29.6% mean AUROC. Codes will be publicly
available at https://antonioo-c.github.io/projects/split-ensemble
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09150" title="Abstract">arXiv:2312.09150</a> [<a href="/pdf/2312.09150" title="Download PDF">pdf</a>, <a href="/format/2312.09150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPR Emergency Assistance Through Mixed Reality Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rebol%2C+M">Manuel Rebol</a>, 
<a href="/search/cs?searchtype=author&query=Steinmaurer%2C+A">Alexander Steinmaurer</a>, 
<a href="/search/cs?searchtype=author&query=Gamillscheg%2C+F">Florian Gamillscheg</a>, 
<a href="/search/cs?searchtype=author&query=Pietroszek%2C+K">Krzysztof Pietroszek</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCtl%2C+C">Christian G&#xfc;tl</a>, 
<a href="/search/cs?searchtype=author&query=Ranniger%2C+C">Claudia Ranniger</a>, 
<a href="/search/cs?searchtype=author&query=Hood%2C+C">Colton Hood</a>, 
<a href="/search/cs?searchtype=author&query=Rutenberg%2C+A">Adam Rutenberg</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+N">Neal Sikka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://doi.org/10.1007/978-3-031-32883-1_38">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Augmented Intelligence and Intelligent Tutoring Systems. ITS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We design and evaluate a mixed reality real-time communication system for
remote assistance during CPR emergencies. Our system allows an expert to guide
a first responder, remotely, on how to give first aid. RGBD cameras capture a
volumetric view of the local scene including the patient, the first responder,
and the environment. The volumetric capture is augmented onto the remote
expert's view to spatially guide the first responder using visual and verbal
instructions. We evaluate the mixed reality communication system in a research
study in which participants face a simulated emergency. The first responder
moves the patient to the recovery position and performs chest compressions as
well as mouth-to-mask ventilation. Our study compares mixed reality against
videoconferencing-based assistance using CPR performance measures, cognitive
workload surveys, and semi-structured interviews. We find that more visual
communication including gestures and objects is used by the remote expert when
assisting in mixed reality compared to videoconferencing. Moreover, the
performance and the workload of the first responder during simulation do not
differ significantly between the two technologies.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09152" title="Abstract">arXiv:2312.09152</a> [<a href="/pdf/2312.09152" title="Download PDF">pdf</a>, <a href="/format/2312.09152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Augmented Reality Communication: How Can We Teach Procedural  Skill in AR?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rebol%2C+M">Manuel Rebol</a>, 
<a href="/search/cs?searchtype=author&query=Pietroszek%2C+K">Krzysztof Pietroszek</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+N">Neal Sikka</a>, 
<a href="/search/cs?searchtype=author&query=Ranniger%2C+C">Claudia Ranniger</a>, 
<a href="/search/cs?searchtype=author&query=Hood%2C+C">Colton Hood</a>, 
<a href="/search/cs?searchtype=author&query=Rutenberg%2C+A">Adam Rutenberg</a>, 
<a href="/search/cs?searchtype=author&query=Sasankan%2C+P">Puja Sasankan</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCtl%2C+C">Christian G&#xfc;tl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://doi.org/10.1145/3611659.3615685">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 29th ACM Symposium on Virtual Reality Software
  and Technology (VRST 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Augmented reality (AR) has great potential for use in healthcare
applications, especially remote medical training and supervision. In this
paper, we analyze the usage of an AR communication system to teach a medical
procedure, the placement of a central venous catheter (CVC) under ultrasound
guidance. We examine various AR communication and collaboration components,
including gestural communication, volumetric information, annotations,
augmented objects, and augmented screens. We compare how teaching in AR differs
from teaching through videoconferencing-based communication. Our results
include a detailed medical training steps analysis in which we compare how
verbal and visual communication differs between video and AR training. We
identify procedural steps in which medical experts give visual instructions
utilizing AR components. We examine the change in AR usage and interaction over
time and recognize patterns between users. Moreover, AR design recommendations
are given based on post-training interviews.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09154" title="Abstract">arXiv:2312.09154</a> [<a href="/pdf/2312.09154" title="Download PDF">pdf</a>, <a href="/format/2312.09154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal  Distance and Multi-scale Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingrui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+W">Weize Quan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaohong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Dong-Ming Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents an accurate and robust method for estimating normals from
point clouds. In contrast to predecessor approaches that minimize the
deviations between the annotated and the predicted normals directly, leading to
direction inconsistency, we first propose a new metric termed Chamfer Normal
Distance to address this issue. This not only mitigates the challenge but also
facilitates network training and substantially enhances the network robustness
against noise. Subsequently, we devise an innovative architecture that
encompasses Multi-scale Local Feature Aggregation and Hierarchical Geometric
Information Fusion. This design empowers the network to capture intricate
geometric details more effectively and alleviate the ambiguity in scale
selection. Extensive experiments demonstrate that our method achieves the
state-of-the-art performance on both synthetic and real-world datasets,
particularly in scenarios contaminated by noise. Our implementation is
available at https://github.com/YingruiWoo/CMG-Net_Pytorch.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09158" title="Abstract">arXiv:2312.09158</a> [<a href="/pdf/2312.09158" title="Download PDF">pdf</a>, <a href="/format/2312.09158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Object Foundation Model for Images and Videos at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zehuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project homepage: <a href="https://glee-vision.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present GLEE in this work, an object-level foundation model for locating
and identifying objects in images and videos. Through a unified framework, GLEE
accomplishes detection, segmentation, tracking, grounding, and identification
of arbitrary objects in the open world scenario for various object perception
tasks. Adopting a cohesive learning strategy, GLEE acquires knowledge from
diverse data sources with varying supervision levels to formulate general
object representations, excelling in zero-shot transfer to new data and tasks.
Specifically, we employ an image encoder, text encoder, and visual prompter to
handle multi-modal inputs, enabling to simultaneously solve various
object-centric downstream tasks while maintaining state-of-the-art performance.
Demonstrated through extensive training on over five million images from
diverse benchmarks, GLEE exhibits remarkable versatility and improved
generalization performance, efficiently tackling downstream tasks without the
need for task-specific adaptation. By integrating large volumes of
automatically labeled data, we further enhance its zero-shot generalization
capabilities. Additionally, GLEE is capable of being integrated into Large
Language Models, serving as a foundational model to provide universal
object-level information for multi-modal tasks. We hope that the versatility
and universality of our method will mark a significant step in the development
of efficient visual foundation models for AGI systems. The model and code will
be released at https://glee-vision.github.io .
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09159" title="Abstract">arXiv:2312.09159</a> [<a href="/pdf/2312.09159" title="Download PDF">pdf</a>, <a href="/format/2312.09159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WIT-UAS: A Wildland-fire Infrared Thermal Dataset to Detect Crew Assets  From Aerial Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jong%2C+A">Andrew Jong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mukai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dhrafani%2C+D">Devansh Dhrafani</a>, 
<a href="/search/cs?searchtype=author&query=Kailas%2C+S">Siva Kailas</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+B">Brady Moon</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present the Wildland-fire Infrared Thermal (WIT-UAS) dataset for long-wave
infrared sensing of crew and vehicle assets amidst prescribed wildland fire
environments. While such a dataset is crucial for safety monitoring in wildland
fire applications, to the authors' awareness, no such dataset focusing on
assets near fire is publicly available. Presumably, this is due to the barrier
to entry of collaborating with fire management personnel. We present two
related data subsets: WIT-UAS-ROS consists of full ROS bag files containing
sensor and robot data of UAS flight over the fire, and WIT-UAS-Image contains
hand-labeled long-wave infrared (LWIR) images extracted from WIT-UAS-ROS. Our
dataset is the first to focus on asset detection in a wildland fire
environment. We show that thermal detection models trained without fire data
frequently detect false positives by classifying fire as people. By adding our
dataset to training, we show that the false positive rate is reduced
significantly. Yet asset detection in wildland fire environments is still
significantly more challenging than detection in urban environments, due to
dense obscuring trees, greater heat variation, and overbearing thermal signal
of the fire. We publicize this dataset to encourage the community to study more
advanced models to tackle this challenging environment. The dataset, code and
pretrained models are available at
\url{https://github.com/castacks/WIT-UAS-Dataset}.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09160" title="Abstract">arXiv:2312.09160</a> [<a href="/pdf/2312.09160" title="Download PDF">pdf</a>, <a href="/format/2312.09160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecture Singularity Distance Computations for Linear Pentapods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapilavai%2C+A">Aditya Kapilavai</a>, 
<a href="/search/cs?searchtype=author&query=Nawratil%2C+G">Georg Nawratil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Mathematical Software (cs.MS); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">The kinematic/robotic community is not only interested in measuring the
closeness of a given robot configuration to its next singular one but also in a
geometric meaningful index evaluating how far the robot design is away from
being architecturally singular. Such an architecture singularity distance,
which can be used by engineers as a criterion within the design process, is
presented for a certain class of parallel manipulators of Stewart-Gough type;
namely so-called linear pentapods. Geometrically the architecture singular
designs are well-understood and can be subclassified into several cases, which
allows to solve the optimization problem of computing the closest architecture
singular design to a given linear pentapod with algorithms from numerical
algebraic geometry.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09162" title="Abstract">arXiv:2312.09162</a> [<a href="/pdf/2312.09162" title="Download PDF">pdf</a>, <a href="/format/2312.09162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation Algorithms for Preference Aggregation Using CP-Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+M+H">Abu Mohammmad Hammad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zilles%2C+S">Sandra Zilles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, main body and appendix. Full version of a paper accepted at the 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper studies the design and analysis of approximation algorithms for
aggregating preferences over combinatorial domains, represented using
Conditional Preference Networks (CP-nets). Its focus is on aggregating
preferences over so-called \emph{swaps}, for which optimal solutions in general
are already known to be of exponential size. We first analyze a trivial
2-approximation algorithm that simply outputs the best of the given input
preferences, and establish a structural condition under which the approximation
ratio of this algorithm is improved to $4/3$. We then propose a polynomial-time
approximation algorithm whose outputs are provably no worse than those of the
trivial algorithm, but often substantially better. A family of problem
instances is presented for which our improved algorithm produces optimal
solutions, while, for any $\varepsilon$, the trivial algorithm can\emph{not}\/
attain a $(2-\varepsilon)$-approximation. These results may lead to the first
polynomial-time approximation algorithm that solves the CP-net aggregation
problem for swaps with an approximation ratio substantially better than $2$.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09167" title="Abstract">arXiv:2312.09167</a> [<a href="/pdf/2312.09167" title="Download PDF">pdf</a>, <a href="/format/2312.09167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Nash Social Welfare under Two-Sided Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Pallavi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Vaish%2C+R">Rohit Vaish</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The maximum Nash social welfare (NSW) -- which maximizes the geometric mean
of agents' utilities -- is a fundamental solution concept with remarkable
fairness and efficiency guarantees. The computational aspects of NSW have been
extensively studied for one-sided preferences where a set of agents have
preferences over a set of resources. Our work deviates from this trend and
studies NSW maximization for two-sided preferences, wherein a set of workers
and firms, each having a cardinal valuation function, are matched with each
other. We provide a systematic study of the computational complexity of
maximizing NSW for many-to-one matchings under two-sided preferences. Our main
negative result is that maximizing NSW is NP-hard even in a highly restricted
setting where each firm has capacity 2, all valuations are in the range
{0,1,2}, and each agent positively values at most three other agents. In search
of positive results, we develop approximation algorithms as well as
parameterized algorithms in terms of natural parameters such as the number of
workers, the number of firms, and the firms' capacities. We also provide
algorithms for restricted domains such as symmetric binary valuations and
bounded degree instances.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09168" title="Abstract">arXiv:2312.09168</a> [<a href="/pdf/2312.09168" title="Download PDF">pdf</a>, <a href="/format/2312.09168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionLight: Light Probes for Free by Painting a Chrome Ball
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phongthawee%2C+P">Pakkapon Phongthawee</a>, 
<a href="/search/cs?searchtype=author&query=Chinchuthakun%2C+W">Worameth Chinchuthakun</a>, 
<a href="/search/cs?searchtype=author&query=Sinsunthithet%2C+N">Nontaphat Sinsunthithet</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Amit Raj</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Khungurn%2C+P">Pramook Khungurn</a>, 
<a href="/search/cs?searchtype=author&query=Suwajanakorn%2C+S">Supasorn Suwajanakorn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For more info and code, please visit our website <a href="https://diffusionlight.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a simple yet effective technique to estimate lighting in a single
input image. Current techniques rely heavily on HDR panorama datasets to train
neural networks to regress an input with limited field-of-view to a full
environment map. However, these approaches often struggle with real-world,
uncontrolled settings due to the limited diversity and size of their datasets.
To address this problem, we leverage diffusion models trained on billions of
standard images to render a chrome ball into the input image. Despite its
simplicity, this task remains challenging: the diffusion models often insert
incorrect or inconsistent objects and cannot readily generate images in HDR
format. Our research uncovers a surprising relationship between the appearance
of chrome balls and the initial diffusion noise map, which we utilize to
consistently generate high-quality chrome balls. We further fine-tune an LDR
difusion model (Stable Diffusion XL) with LoRA, enabling it to perform exposure
bracketing for HDR light estimation. Our method produces convincing light
estimates across diverse settings and demonstrates superior generalization to
in-the-wild scenarios.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09173" title="Abstract">arXiv:2312.09173</a> [<a href="/pdf/2312.09173" title="Download PDF">pdf</a>, <a href="/format/2312.09173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Motion Planning for Quadruped Robots Using Density Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S+S+K+S">Sriram S.K.S Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+A">Andrew Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+U">Umesh Vaidya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.15830">arXiv:2306.15830</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a motion planning algorithm for quadruped locomotion
based on density functions. We decompose the locomotion problem into a
high-level density planner and a model predictive controller (MPC). Due to
density functions having a physical interpretation through the notion of
occupancy, it is intuitive to represent the environment with safety
constraints. Hence, there is an ease of use to constructing the planning
problem with density. The proposed method uses a simplified model of the robot
into an integrator system, where the high-level plan is in a feedback form
formulated through an analytically constructed density function. We then use
the MPC to optimize the reference trajectory, in which a low-level PID
controller is used to obtain the torque level control. The overall framework is
implemented in simulation, demonstrating our feedback density planner for
legged locomotion. The implementation of work is available at
\url{https://github.com/AndrewZheng-1011/legged_planner}
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09181" title="Abstract">arXiv:2312.09181</a> [<a href="/pdf/2312.09181" title="Download PDF">pdf</a>, <a href="/format/2312.09181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Efficiency of Diffusion Models via Multi-Stage Framework and  Tailored Multi-Decoder Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huijie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Alkhouri%2C+I">Ismail Alkhouri</a>, 
<a href="/search/cs?searchtype=author&query=Ravishankar%2C+S">Saiprasad Ravishankar</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dogyoon Song</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models, emerging as powerful deep generative tools, excel in
various applications. They operate through a two-steps process: introducing
noise into training samples and then employing a model to convert random noise
into new samples (e.g., images). However, their remarkable generative
performance is hindered by slow training and sampling. This is due to the
necessity of tracking extensive forward and reverse diffusion trajectories, and
employing a large model with numerous parameters across multiple timesteps
(i.e., noise levels). To tackle these challenges, we present a multi-stage
framework inspired by our empirical findings. These observations indicate the
advantages of employing distinct parameters tailored to each timestep while
retaining universal parameters shared across all time steps. Our approach
involves segmenting the time interval into multiple stages where we employ
custom multi-decoder U-net architecture that blends time-dependent models with
a universally shared encoder. Our framework enables the efficient distribution
of computational resources and mitigates inter-stage interference, which
substantially improves training efficiency. Extensive numerical experiments
affirm the effectiveness of our framework, showcasing significant training and
sampling efficiency enhancements on three state-of-the-art diffusion models,
including large-scale latent diffusion models. Furthermore, our ablation
studies illustrate the impact of two important components in our framework: (i)
a novel timestep clustering algorithm for stage division, and (ii) an
innovative multi-decoder U-net architecture, seamlessly integrating universal
and customized hyperparameters.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09187" title="Abstract">arXiv:2312.09187</a> [<a href="/pdf/2312.09187" title="Download PDF">pdf</a>, <a href="/format/2312.09187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Models as a Source of Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumli%2C+K">Kate Baumli</a>, 
<a href="/search/cs?searchtype=author&query=Baveja%2C+S">Satinder Baveja</a>, 
<a href="/search/cs?searchtype=author&query=Behbahani%2C+F">Feryal Behbahani</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+H">Harris Chan</a>, 
<a href="/search/cs?searchtype=author&query=Comanici%2C+G">Gheorghe Comanici</a>, 
<a href="/search/cs?searchtype=author&query=Flennerhag%2C+S">Sebastian Flennerhag</a>, 
<a href="/search/cs?searchtype=author&query=Gazeau%2C+M">Maxime Gazeau</a>, 
<a href="/search/cs?searchtype=author&query=Holsheimer%2C+K">Kristian Holsheimer</a>, 
<a href="/search/cs?searchtype=author&query=Horgan%2C+D">Dan Horgan</a>, 
<a href="/search/cs?searchtype=author&query=Laskin%2C+M">Michael Laskin</a>, 
<a href="/search/cs?searchtype=author&query=Lyle%2C+C">Clare Lyle</a>, 
<a href="/search/cs?searchtype=author&query=Masoom%2C+H">Hussain Masoom</a>, 
<a href="/search/cs?searchtype=author&query=McKinney%2C+K">Kay McKinney</a>, 
<a href="/search/cs?searchtype=author&query=Mnih%2C+V">Volodymyr Mnih</a>, 
<a href="/search/cs?searchtype=author&query=Neitz%2C+A">Alexander Neitz</a>, 
<a href="/search/cs?searchtype=author&query=Pardo%2C+F">Fabio Pardo</a>, 
<a href="/search/cs?searchtype=author&query=Parker-Holder%2C+J">Jack Parker-Holder</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+J">John Quan</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>, 
<a href="/search/cs?searchtype=author&query=Sahni%2C+H">Himanshu Sahni</a>, 
<a href="/search/cs?searchtype=author&query=Schaul%2C+T">Tom Schaul</a>, 
<a href="/search/cs?searchtype=author&query=Schroecker%2C+Y">Yannick Schroecker</a>, 
<a href="/search/cs?searchtype=author&query=Spencer%2C+S">Stephen Spencer</a>, 
<a href="/search/cs?searchtype=author&query=Steigerwald%2C+R">Richie Steigerwald</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Building generalist agents that can accomplish many goals in rich open-ended
environments is one of the research frontiers for reinforcement learning. A key
limiting factor for building generalist agents with RL has been the need for a
large number of reward functions for achieving different goals. We investigate
the feasibility of using off-the-shelf vision-language models, or VLMs, as
sources of rewards for reinforcement learning agents. We show how rewards for
visual achievement of a variety of language goals can be derived from the CLIP
family of models, and used to train RL agents that can achieve a variety of
language goals. We showcase this approach in two distinct visual domains and
present a scaling trend showing how larger VLMs lead to more accurate rewards
for visual goal achievement, which in turn produces more capable RL agents.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09190" title="Abstract">arXiv:2312.09190</a> [<a href="/pdf/2312.09190" title="Download PDF">pdf</a>, <a href="/format/2312.09190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Online Learning of Contact Force Models for Connector  Insertion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tracy%2C+K">Kevin Tracy</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+Z">Zachary Manchester</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ajinkya Jain</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+K">Keegan Go</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>, 
<a href="/search/cs?searchtype=author&query=Erez%2C+T">Tom Erez</a>, 
<a href="/search/cs?searchtype=author&query=Tassa%2C+Y">Yuval Tassa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Contact-rich manipulation tasks with stiff frictional elements like connector
insertion are difficult to model with rigid-body simulators. In this work, we
propose a new approach for modeling these environments by learning a
quasi-static contact force model instead of a full simulator. Using a feature
vector that contains information about the configuration and control, we find a
linear mapping adequately captures the relationship between this feature vector
and the sensed contact forces. A novel Linear Model Learning (LML) algorithm is
used to solve for the globally optimal mapping in real time without any matrix
inversions, resulting in an algorithm that runs in nearly constant time on a
GPU as the model size increases. We validate the proposed approach for
connector insertion both in simulation and hardware experiments, where the
learned model is combined with an optimization-based controller to achieve
smooth insertions in the presence of misalignments and uncertainty. Our website
featuring videos, code, and more materials is available at
https://model-based-plugging.github.io/.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09193" title="Abstract">arXiv:2312.09193</a> [<a href="/pdf/2312.09193" title="Download PDF">pdf</a>, <a href="/format/2312.09193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Sampling via De-randomization for Discrete Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huizhuo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Y">Yiwen Kou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 7 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion models have emerged as powerful tools for high-quality data
generation, such as image generation. Despite its success in continuous spaces,
discrete diffusion models, which apply to domains such as texts and natural
languages, remain under-studied and often suffer from slow generation speed. In
this paper, we propose a novel de-randomized diffusion process, which leads to
an accelerated algorithm for discrete diffusion models. Our technique
significantly reduces the number of function evaluations (i.e., calls to the
neural network), making the sampling process much faster. Furthermore, we
introduce a continuous-time (i.e., infinite-step) sampling algorithm that can
provide even better sample qualities than its discrete-time (finite-step)
counterpart. Extensive experiments on natural language generation and machine
translation tasks demonstrate the superior performance of our method in terms
of both generation speed and sample quality over existing methods for discrete
diffusion models.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09196" title="Abstract">arXiv:2312.09196</a> [<a href="/pdf/2312.09196" title="Download PDF">pdf</a>, <a href="/format/2312.09196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIRECT: Deep Active Learning under Imbalance and Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nuggehalli%2C+S">Shyam Nuggehalli</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+L">Lalit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R">Robert Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Class imbalance is a prevalent issue in real world machine learning
applications, often leading to poor performance in rare and minority classes.
With an abundance of wild unlabeled data, active learning is perhaps the most
effective technique in solving the problem at its root -- collecting a more
balanced and informative set of labeled examples during annotation. In this
work, we propose a novel algorithm that first identifies the class separation
threshold and then annotate the most uncertain examples from the minority
classes, close to the separation threshold. Through a novel reduction to
one-dimensional active learning, our algorithm DIRECT is able to leverage the
classic active learning literature to address issues such as batch labeling and
tolerance towards label noise. Compared to existing algorithms, our algorithm
saves more than 15\% of the annotation budget compared to state-of-art active
learning algorithm and more than 90\% of annotation budget compared to random
sampling.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09197" title="Abstract">arXiv:2312.09197</a> [<a href="/pdf/2312.09197" title="Download PDF">pdf</a>, <a href="/format/2312.09197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Change Point Detection for Mixing Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Shroff%2C+N">Ness Shroff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper considers the change point detection problem under dependent
samples. In particular, we provide performance guarantees for the MMD-CUSUM
test under $\alpha$, $\beta$, and $\phi$-mixing processes, which significantly
expands its utility beyond the i.i.d. and Markovian cases used in previous
studies. We obtain lower bounds for average-run-length (ARL) and upper bounds
for average-detection-delay (ADD) in terms of the threshold parameter. We show
that the MMD-CUSUM test enjoys the same level of performance as the i.i.d. case
under $\phi$-mixing processes. The MMD-CUSUM test also achieves strong
performance under $\alpha$/$\beta$-mixing processes, which are significantly
more relaxed than existing results. The MMD-CUSUM test statistic adapts to
different settings without modifications, rendering it a completely
data-driven, dependence-agnostic change point detection scheme. Numerical
simulations are provided at the end to evaluate our findings.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09198" title="Abstract">arXiv:2312.09198</a> [<a href="/pdf/2312.09198" title="Download PDF">pdf</a>, <a href="/format/2312.09198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weaving Pathways for Justice with GPT: LLM-driven automated drafting of  interactive legal applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steenhuis%2C+Q">Quinten Steenhuis</a>, 
<a href="/search/cs?searchtype=author&query=Colarusso%2C+D">David Colarusso</a>, 
<a href="/search/cs?searchtype=author&query=Willey%2C+B">Bryce Willey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Can generative AI help us speed up the authoring of tools to help
self-represented litigants?
<br />In this paper, we describe 3 approaches to automating the completion of court
forms: a generative AI approach that uses GPT-3 to iteratively prompt the user
to answer questions, a constrained template-driven approach that uses
GPT-4-turbo to generate a draft of questions that are subject to human review,
and a hybrid method. We use the open source Docassemble platform in all 3
experiments, together with a tool created at Suffolk University Law School
called the Assembly Line Weaver. We conclude that the hybrid model of
constrained automated drafting with human review is best suited to the task of
authoring guided interviews.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09203" title="Abstract">arXiv:2312.09203</a> [<a href="/pdf/2312.09203" title="Download PDF">pdf</a>, <a href="/format/2312.09203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measurement in the Age of LLMs: An Application to Ideological Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Hagan%2C+S">Sean O&#x27;Hagan</a>, 
<a href="/search/cs?searchtype=author&query=Schein%2C+A">Aaron Schein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 4th International Conference of Social Computing in Beijing, China, September 2023, the New Directions in Analyzing Text as Data (TADA) meeting in Amherst, MA, USA, November 2023, and the NeurIPS workshop titled "I Can't Believe It's Not Better!'' Failure Modes in the Age of Foundation Models in New Orleans, LA, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Much of social science is centered around terms like ``ideology'' or
``power'', which generally elude precise definition, and whose contextual
meanings are trapped in surrounding language. This paper explores the use of
large language models (LLMs) to flexibly navigate the conceptual clutter
inherent to social scientific measurement tasks. We rely on LLMs' remarkable
linguistic fluency to elicit ideological scales of both legislators and text,
which accord closely to established methods and our own judgement. A key aspect
of our approach is that we elicit such scores directly, instructing the LLM to
furnish numeric scores itself. This approach affords a great deal of
flexibility, which we showcase through a variety of different case studies. Our
results suggest that LLMs can be used to characterize highly subtle and diffuse
manifestations of political ideology in text.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09207" title="Abstract">arXiv:2312.09207</a> [<a href="/pdf/2312.09207" title="Download PDF">pdf</a>, <a href="/format/2312.09207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WikiMuTe: A web-sourced dataset of semantic descriptions for music audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weck%2C+B">Benno Weck</a>, 
<a href="/search/cs?searchtype=author&query=Kirchhoff%2C+H">Holger Kirchhoff</a>, 
<a href="/search/cs?searchtype=author&query=Grosche%2C+P">Peter Grosche</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 30th International Conference on MultiMedia Modeling (MMM2024). This preprint has not undergone peer review or any post-submission improvements or corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multi-modal deep learning techniques for matching free-form text with music
have shown promising results in the field of Music Information Retrieval (MIR).
Prior work is often based on large proprietary data while publicly available
datasets are few and small in size. In this study, we present WikiMuTe, a new
and open dataset containing rich semantic descriptions of music. The data is
sourced from Wikipedia's rich catalogue of articles covering musical works.
Using a dedicated text-mining pipeline, we extract both long and short-form
descriptions covering a wide range of topics related to music content such as
genre, style, mood, instrumentation, and tempo. To show the use of this data,
we train a model that jointly learns text and audio representations and
performs cross-modal retrieval. The model is evaluated on two tasks: tag-based
music retrieval and music auto-tagging. The results show that while our
approach has state-of-the-art performance on multiple tasks, but still observe
a difference in performance depending on the data used for training.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09211" title="Abstract">arXiv:2312.09211</a> [<a href="/pdf/2312.09211" title="Download PDF">pdf</a>, <a href="/format/2312.09211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+A">Alireza Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Justin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nejad%2C+M+G">Mahsa Ghazvini Nejad</a>, 
<a href="/search/cs?searchtype=author&query=Asgharian%2C+M">Masoud Asgharian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nia%2C+V+P">Vahid Partovi Nia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Low-precision fine-tuning of language models has gained prominence as a
cost-effective and energy-efficient approach to deploying large-scale models in
various applications. However, this approach is susceptible to the existence of
outlier values in activation. The outlier values in the activation can
negatively affect the performance of fine-tuning language models in the
low-precision regime since they affect the scaling factor and thus make
representing smaller values harder. This paper investigates techniques for
mitigating outlier activation in low-precision integer fine-tuning of the
language models. Our proposed novel approach enables us to represent the
outlier activation values in 8-bit integers instead of floating-point (FP16)
values. The benefit of using integers for outlier values is that it enables us
to use operator tiling to avoid performing 16-bit integer matrix multiplication
to address this problem effectively. We provide theoretical analysis and
supporting experiments to demonstrate the effectiveness of our approach in
improving the robustness and performance of low-precision fine-tuned language
models.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09219" title="Abstract">arXiv:2312.09219</a> [<a href="/pdf/2312.09219" title="Download PDF">pdf</a>, <a href="/format/2312.09219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NestE: Modeling Nested Relational Structures for Knowledge Graph  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Bo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Nayyeri%2C+M">Mojtaba Nayyeri</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Reasoning with knowledge graphs (KGs) has primarily focused on triple-shaped
facts. Recent advancements have been explored to enhance the semantics of these
facts by incorporating more potent representations, such as hyper-relational
facts. However, these approaches are limited to \emph{atomic facts}, which
describe a single piece of information. This paper extends beyond \emph{atomic
facts} and delves into \emph{nested facts}, represented by quoted triples where
subjects and objects are triples themselves (e.g., ((\emph{BarackObama},
\emph{holds\_position}, \emph{President}), \emph{succeed\_by},
(\emph{DonaldTrump}, \emph{holds\_position}, \emph{President}))). These nested
facts enable the expression of complex semantics like \emph{situations} over
time and \emph{logical patterns} over entities and relations. In response, we
introduce NestE, a novel KG embedding approach that captures the semantics of
both atomic and nested factual knowledge. NestE represents each atomic fact as
a $1\times3$ matrix, and each nested relation is modeled as a $3\times3$ matrix
that rotates the $1\times3$ atomic fact matrix through matrix multiplication.
Each element of the matrix is represented as a complex number in the
generalized 4D hypercomplex space, including (spherical) quaternions,
hyperbolic quaternions, and split-quaternions. Through thorough analysis, we
demonstrate the embedding's efficacy in capturing diverse logical patterns over
nested facts, surpassing the confines of first-order logic-like expressions.
Our experimental results showcase NestE's significant performance gains over
current baselines in triple prediction and conditional link prediction. The
code and pre-trained models are open available at
https://github.com/xiongbo010/NestE.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09222" title="Abstract">arXiv:2312.09222</a> [<a href="/pdf/2312.09222" title="Download PDF">pdf</a>, <a href="/format/2312.09222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mosaic-SDF for 3D Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yariv%2C+L">Lior Yariv</a>, 
<a href="/search/cs?searchtype=author&query=Puny%2C+O">Omri Puny</a>, 
<a href="/search/cs?searchtype=author&query=Neverova%2C+N">Natalia Neverova</a>, 
<a href="/search/cs?searchtype=author&query=Gafni%2C+O">Oran Gafni</a>, 
<a href="/search/cs?searchtype=author&query=Lipman%2C+Y">Yaron Lipman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More results and details can be found at <a href="https://lioryariv.github.io/msdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Current diffusion or flow-based generative models for 3D shapes divide to
two: distilling pre-trained 2D image diffusion models, and training directly on
3D shapes. When training a diffusion or flow models on 3D shapes a crucial
design choice is the shape representation. An effective shape representation
needs to adhere three design principles: it should allow an efficient
conversion of large 3D datasets to the representation form; it should provide a
good tradeoff of approximation power versus number of parameters; and it should
have a simple tensorial form that is compatible with existing powerful neural
architectures. While standard 3D shape representations such as volumetric grids
and point clouds do not adhere to all these principles simultaneously, we
advocate in this paper a new representation that does. We introduce Mosaic-SDF
(M-SDF): a simple 3D shape representation that approximates the Signed Distance
Function (SDF) of a given shape by using a set of local grids spread near the
shape's boundary. The M-SDF representation is fast to compute for each shape
individually making it readily parallelizable; it is parameter efficient as it
only covers the space around the shape's boundary; and it has a simple matrix
form, compatible with Transformer-based architectures. We demonstrate the
efficacy of the M-SDF representation by using it to train a 3D generative flow
model including class-conditioned generation with the 3D Warehouse dataset, and
text-to-3D generation using a dataset of about 600k caption-shape pairs.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09225" title="Abstract">arXiv:2312.09225</a> [<a href="/pdf/2312.09225" title="Download PDF">pdf</a>, <a href="/ps/2312.09225" title="Download PostScript">ps</a>, <a href="/format/2312.09225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process Regression under Computational and Epistemic  Misspecification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sanz-Alonso%2C+D">Daniel Sanz-Alonso</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+R">Ruiyi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gaussian process regression is a classical kernel method for function
estimation and data interpolation. In large data applications, computational
costs can be reduced using low-rank or sparse approximations of the kernel.
This paper investigates the effect of such kernel approximations on the
interpolation error. We introduce a unified framework to analyze Gaussian
process regression under important classes of computational misspecification:
Karhunen-Lo\`eve expansions that result in low-rank kernel approximations,
multiscale wavelet expansions that induce sparsity in the covariance matrix,
and finite element representations that induce sparsity in the precision
matrix. Our theory also accounts for epistemic misspecification in the choice
of kernel parameters.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09228" title="Abstract">arXiv:2312.09228</a> [<a href="/pdf/2312.09228" title="Download PDF">pdf</a>, <a href="/format/2312.09228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhiyin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mihajlovic%2C+M">Marko Mihajlovic</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce an approach that creates animatable human avatars from monocular
videos using 3D Gaussian Splatting (3DGS). Existing methods based on neural
radiance fields (NeRFs) achieve high-quality novel-view/novel-pose image
synthesis but often require days of training, and are extremely slow at
inference time. Recently, the community has explored fast grid structures for
efficient training of clothed avatars. Albeit being extremely fast at training,
these methods can barely achieve an interactive rendering frame rate with
around 15 FPS. In this paper, we use 3D Gaussian Splatting and learn a
non-rigid deformation network to reconstruct animatable clothed human avatars
that can be trained within 30 minutes and rendered at real-time frame rates
(50+ FPS). Given the explicit nature of our representation, we further
introduce as-isometric-as-possible regularizations on both the Gaussian mean
vectors and the covariance matrices, enhancing the generalization of our model
on highly articulated unseen poses. Experimental results show that our method
achieves comparable and even better performance compared to state-of-the-art
approaches on animatable avatar creation from a monocular input, while being
400x and 250x faster in training and inference, respectively.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09230" title="Abstract">arXiv:2312.09230</a> [<a href="/pdf/2312.09230" title="Download PDF">pdf</a>, <a href="/format/2312.09230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successor Heads: Recurring, Interpretable Attention Heads In The Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gould%2C+R">Rhys Gould</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+E">Euan Ong</a>, 
<a href="/search/cs?searchtype=author&query=Ogden%2C+G">George Ogden</a>, 
<a href="/search/cs?searchtype=author&query=Conmy%2C+A">Arthur Conmy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 main text pages, with appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this work we present successor heads: attention heads that increment
tokens with a natural ordering, such as numbers, months, and days. For example,
successor heads increment 'Monday' into 'Tuesday'. We explain the successor
head behavior with an approach rooted in mechanistic interpretability, the
field that aims to explain how models complete tasks in human-understandable
terms. Existing research in this area has found interpretable language model
components in small toy models. However, results in toy models have not yet led
to insights that explain the internals of frontier models and little is
currently understood about the internal operations of large language models. In
this paper, we analyze the behavior of successor heads in large language models
(LLMs) and find that they implement abstract representations that are common to
different architectures. They form in LLMs with as few as 31 million
parameters, and at least as many as 12 billion parameters, such as GPT-2,
Pythia, and Llama-2. We find a set of 'mod-10 features' that underlie how
successor heads increment in LLMs across different architectures and sizes. We
perform vector arithmetic with these features to edit head behavior and provide
insights into numeric representations within LLMs. Additionally, we study the
behavior of successor heads on natural language data, identifying interpretable
polysemanticity in a Pythia successor head.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09231" title="Abstract">arXiv:2312.09231</a> [<a href="/pdf/2312.09231" title="Download PDF">pdf</a>, <a href="/format/2312.09231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability in Semantic Segmentation: Can We Use Synthetic Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loiseau%2C+T">Thibaut Loiseau</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Hung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mickael Chen</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://valeoai.github.io/blog/publications/GenVal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Assessing the reliability of perception models to covariate shifts and
out-of-distribution (OOD) detection is crucial for safety-critical applications
such as autonomous vehicles. By nature of the task, however, the relevant data
is difficult to collect and annotate. In this paper, we challenge cutting-edge
generative models to automatically synthesize data for assessing reliability in
semantic segmentation. By fine-tuning Stable Diffusion, we perform zero-shot
generation of synthetic data in OOD domains or inpainted with OOD objects.
Synthetic data is employed to provide an initial assessment of pretrained
segmenters, thereby offering insights into their performance when confronted
with real edge cases. Through extensive experiments, we demonstrate a high
correlation between the performance on synthetic data and the performance on
real OOD data, showing the validity approach. Furthermore, we illustrate how
synthetic data can be utilized to enhance the calibration and OOD detection
capabilities of segmenters.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09232" title="Abstract">arXiv:2312.09232</a> [<a href="/pdf/2312.09232" title="Download PDF">pdf</a>, <a href="/format/2312.09232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVQI: A Multi-task, Hardware-integrated Artificial Intelligence System  for Automated Visual Inspection in Electronics Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+A">Audrey Chung</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Francis Li</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+J">Jeremy Ward</a>, 
<a href="/search/cs?searchtype=author&query=Hryniowski%2C+A">Andrew Hryniowski</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As electronics manufacturers continue to face pressure to increase production
efficiency amid difficulties with supply chains and labour shortages, many
printed circuit board assembly (PCBA) manufacturers have begun to invest in
automation and technological innovations to remain competitive. One such method
is to leverage artificial intelligence (AI) to greatly augment existing
manufacturing processes. In this paper, we present the DarwinAI Visual Quality
Inspection (DVQI) system, a hardware-integration artificial intelligence system
for the automated inspection of printed circuit board assembly defects in an
electronics manufacturing environment. The DVQI system enables multi-task
inspection via minimal programming and setup for manufacturing engineers while
improving cycle time relative to manual inspection. We also present a case
study of the deployed DVQI system's performance and impact for a top
electronics manufacturer.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09234" title="Abstract">arXiv:2312.09234</a> [<a href="/pdf/2312.09234" title="Download PDF">pdf</a>, <a href="/format/2312.09234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s do the time-warp-attend: Learning topological invariants of  dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moriel%2C+N">Noa Moriel</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+M">Matthew Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Nitzan%2C+M">Mor Nitzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Dynamical systems across the sciences, from electrical circuits to ecological
networks, undergo qualitative and often catastrophic changes in behavior,
called bifurcations, when their underlying parameters cross a threshold.
Existing methods predict oncoming catastrophes in individual systems but are
primarily time-series-based and struggle both to categorize qualitative
dynamical regimes across diverse systems and to generalize to real data. To
address this challenge, we propose a data-driven, physically-informed
deep-learning framework for classifying dynamical regimes and characterizing
bifurcation boundaries based on the extraction of topologically invariant
features. We focus on the paradigmatic case of the supercritical Hopf
bifurcation, which is used to model periodic dynamics across a wide range of
applications. Our convolutional attention method is trained with data
augmentations that encourage the learning of topological invariants which can
be used to detect bifurcation boundaries in unseen systems and to design models
of biological systems like oscillatory gene regulatory networks. We further
demonstrate our method's use in analyzing real data by recovering distinct
proliferation and differentiation dynamics along pancreatic endocrinogenesis
trajectory in gene expression space based on single-cell data. Our method
provides valuable insights into the qualitative, long-term behavior of a wide
range of dynamical systems, and can detect bifurcations or catastrophic
transitions in large-scale physical and biological systems.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09236" title="Abstract">arXiv:2312.09236</a> [<a href="/pdf/2312.09236" title="Download PDF">pdf</a>, <a href="/format/2312.09236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A framework for conditional diffusion modelling with applications in  motif scaffolding for protein design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Didi%2C+K">Kieran Didi</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+F">Francisco Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Mathis%2C+S+V">Simon V Mathis</a>, 
<a href="/search/cs?searchtype=author&query=Dutordoir%2C+V">Vincent Dutordoir</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Komorowska%2C+U+J">Urszula J Komorowska</a>, 
<a href="/search/cs?searchtype=author&query=Lio%2C+P">Pietro Lio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Many protein design applications, such as binder or enzyme design, require
scaffolding a structural motif with high precision. Generative modelling
paradigms based on denoising diffusion processes emerged as a leading candidate
to address this motif scaffolding problem and have shown early experimental
success in some cases. In the diffusion paradigm, motif scaffolding is treated
as a conditional generation task, and several conditional generation protocols
were proposed or imported from the Computer Vision literature. However, most of
these protocols are motivated heuristically, e.g. via analogies to Langevin
dynamics, and lack a unifying framework, obscuring connections between the
different approaches. In this work, we unify conditional training and
conditional sampling procedures under one common framework based on the
mathematically well-understood Doob's h-transform. This new perspective allows
us to draw connections between existing methods and propose a new variation on
existing conditional training protocols. We illustrate the effectiveness of
this new protocol in both, image outpainting and motif scaffolding and find
that it outperforms standard methods.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09237" title="Abstract">arXiv:2312.09237</a> [<a href="/pdf/2312.09237" title="Download PDF">pdf</a>, <a href="/format/2312.09237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel Aligned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiarui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Arnab%2C+A">Anurag Arnab</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jerryxu.net/PixelLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models have achieved great success in recent years, so as
their variants in vision. Existing vision-language models can describe images
in natural languages, answer visual-related questions, or perform complex
reasoning about the image. However, it is yet unclear how localization tasks,
such as word grounding or referring localization, can be performed using large
language models. In this work, we aim to develop a vision-language model that
can take locations, for example, a set of points or boxes, as either inputs or
outputs. When taking locations as inputs, the model performs
location-conditioned captioning, which generates captions for the indicated
object or region. When generating locations as outputs, our model regresses
pixel coordinates for each output word generated by the language model, and
thus performs dense word grounding. Our model is pre-trained on the Localized
Narrative dataset, which contains pixel-word-aligned captioning from human
attention. We show our model can be applied to various location-aware
vision-language tasks, including referring localization, location-conditioned
captioning, and dense object captioning, archiving state-of-the-art performance
on RefCOCO and Visual Genome. Project page: https://jerryxu.net/PixelLLM .
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09238" title="Abstract">arXiv:2312.09238</a> [<a href="/pdf/2312.09238" title="Download PDF">pdf</a>, <a href="/format/2312.09238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto MC-Reward: Automated Dense Reward Design with Large Language Models  for Minecraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaokai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditional reinforcement-learning-based agents rely on sparse rewards that
often only use binary values to indicate task completion or failure. The
challenge in exploration efficiency makes it difficult to effectively learn
complex tasks in Minecraft. To address this, this paper introduces an advanced
learning system, named Auto MC-Reward, that leverages Large Language Models
(LLMs) to automatically design dense reward functions, thereby enhancing the
learning efficiency. Auto MC-Reward consists of three important components:
Reward Designer, Reward Critic, and Trajectory Analyzer. Given the environment
information and task descriptions, the Reward Designer first design the reward
function by coding an executable Python function with predefined observation
inputs. Then, our Reward Critic will be responsible for verifying the code,
checking whether the code is self-consistent and free of syntax and semantic
errors. Further, the Trajectory Analyzer summarizes possible failure causes and
provides refinement suggestions according to collected trajectories. In the
next round, Reward Designer will take further refine and iterate the dense
reward function based on feedback. Experiments demonstrate a significant
improvement in the success rate and learning efficiency of our agents in
complex tasks in Minecraft, such as obtaining diamond with the efficient
ability to avoid lava, and efficiently explore trees and animals that are
sparse on the plains biome.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09241" title="Abstract">arXiv:2312.09241</a> [<a href="/pdf/2312.09241" title="Download PDF">pdf</a>, <a href="/format/2312.09241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyGSM: achieving &gt;80% on GSM8k with small language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bubeck%2C+S">Sebastien Bubeck</a>, 
<a href="/search/cs?searchtype=author&query=Eldan%2C+R">Ronen Eldan</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+J">Janardhan Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+R">Rachel Ward</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Small-scale models offer various computational advantages, and yet to which
extent size is critical for problem-solving abilities remains an open question.
Specifically for solving grade school math, the smallest model size so far
required to break the 80\% barrier on the GSM8K benchmark remains to be 34B.
Our work studies how high-quality datasets may be the key for small language
models to acquire mathematical reasoning. We introduce \texttt{TinyGSM}, a
synthetic dataset of 12.3M grade school math problems paired with Python
solutions, generated fully by GPT-3.5. After finetuning on \texttt{TinyGSM}, we
find that a duo of a 1.3B generation model and a 1.3B verifier model can
achieve 81.5\% accuracy, outperforming existing models that are orders of
magnitude larger. This also rivals the performance of the GPT-3.5 ``teacher''
model (77.4\%), from which our model's training data is generated. Our approach
is simple and has two key components: 1) the high-quality dataset
\texttt{TinyGSM}, 2) the use of a verifier, which selects the final outputs
from multiple candidate generations.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09242" title="Abstract">arXiv:2312.09242</a> [<a href="/pdf/2312.09242" title="Download PDF">pdf</a>, <a href="/format/2312.09242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Immersion: Generative Immersive Scene with 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+H">Hao Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Heal%2C+K">Kathryn Heal</a>, 
<a href="/search/cs?searchtype=author&query=Lombardi%2C+S">Stephen Lombardi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tiancheng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ken-ouyang.github.io/text2immersion/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce Text2Immersion, an elegant method for producing high-quality 3D
immersive scenes from text prompts. Our proposed pipeline initiates by
progressively generating a Gaussian cloud using pre-trained 2D diffusion and
depth estimation models. This is followed by a refining stage on the Gaussian
cloud, interpolating and refining it to enhance the details of the generated
scene. Distinct from prevalent methods that focus on single object or indoor
scenes, or employ zoom-out trajectories, our approach generates diverse scenes
with various objects, even extending to the creation of imaginary scenes.
Consequently, Text2Immersion can have wide-ranging implications for various
applications such as virtual reality, game development, and automated content
creation. Extensive evaluations demonstrate that our system surpasses other
methods in rendering quality and diversity, further progressing towards
text-driven 3D scene generation. We will make the source code publicly
accessible at the project page.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09243" title="Abstract">arXiv:2312.09243</a> [<a href="/pdf/2312.09243" title="Download PDF">pdf</a>, <a href="/format/2312.09243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural  Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chubin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Juncheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yueqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/LinShan-Bin/OccNeRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As a fundamental task of vision-based perception, 3D occupancy prediction
reconstructs 3D structures of surrounding environments. It provides detailed
information for autonomous driving planning and navigation. However, most
existing methods heavily rely on the LiDAR point clouds to generate occupancy
ground truth, which is not available in the vision-based system. In this paper,
we propose an OccNeRF method for self-supervised multi-camera occupancy
prediction. Different from bounded 3D occupancy labels, we need to consider
unbounded scenes with raw image supervision. To solve the issue, we
parameterize the reconstructed occupancy fields and reorganize the sampling
strategy. The neural rendering is adopted to convert occupancy fields to
multi-camera depth maps, supervised by multi-frame photometric consistency.
Moreover, for semantic occupancy prediction, we design several strategies to
polish the prompts and filter the outputs of a pretrained open-vocabulary 2D
segmentation model. Extensive experiments for both self-supervised depth
estimation and semantic occupancy prediction tasks on nuScenes dataset
demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09244" title="Abstract">arXiv:2312.09244</a> [<a href="/pdf/2312.09244" title="Download PDF">pdf</a>, <a href="/format/2312.09244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate  Reward Hacking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eisenstein%2C+J">Jacob Eisenstein</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+C">Chirag Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Alekh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amour%2C+A">Alex D&#x27;Amour</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+D">DJ Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Fisch%2C+A">Adam Fisch</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>, 
<a href="/search/cs?searchtype=author&query=Pfohl%2C+S">Stephen Pfohl</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+D">Deepak Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+P">Peter Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reward models play a key role in aligning language model applications towards
human preferences. However, this setup creates an incentive for the language
model to exploit errors in the reward model to achieve high estimated reward, a
phenomenon often termed \emph{reward hacking}. A natural mitigation is to train
an ensemble of reward models, aggregating over model outputs to obtain a more
robust reward estimate. We explore the application of reward ensembles to
alignment at both training time (through reinforcement learning) and inference
time (through reranking). First, we show that reward models are
\emph{underspecified}: reward models that perform similarly in-distribution can
yield very different rewards when used in alignment, due to distribution shift.
Second, underspecification results in overoptimization, where alignment to one
reward model does not improve reward as measured by another reward model
trained on the same data. Third, overoptimization is mitigated by the use of
reward ensembles, and ensembles that vary by their \emph{pretraining} seeds
lead to better generalization than ensembles that differ only by their
\emph{fine-tuning} seeds, with both outperforming individual reward models.
However, even pretrain reward ensembles do not eliminate reward hacking: we
show several qualitative reward hacking phenomena that are not mitigated by
ensembling because all reward models in the ensemble exhibit similar error
patterns.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09245" title="Abstract">arXiv:2312.09245</a> [<a href="/pdf/2312.09245" title="Download PDF">pdf</a>, <a href="/format/2312.09245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral  Planning States for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiangwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">ChuanYang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Haoming Zou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wenwen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Silei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hanming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have opened up new possibilities for intelligent
agents, endowing them with human-like thinking and cognitive abilities. In this
work, we delve into the potential of large language models (LLMs) in autonomous
driving (AD). We introduce DriveMLM, an LLM-based AD framework that can perform
close-loop autonomous driving in realistic simulators. To this end, (1) we
bridge the gap between the language decisions and the vehicle control commands
by standardizing the decision states according to the off-the-shelf motion
planning module. (2) We employ a multi-modal LLM (MLLM) to model the behavior
planning module of a module AD system, which uses driving rules, user commands,
and inputs from various sensors (e.g., camera, lidar) as input and makes
driving decisions and provide explanations; This model can plug-and-play in
existing AD systems such as Apollo for close-loop driving. (3) We design an
effective data engine to collect a dataset that includes decision state and
corresponding explanation annotation for model training and evaluation. We
conduct extensive experiments and show that our model achieves 76.1 driving
score on the CARLA Town05 Long, and surpasses the Apollo baseline by 4.7 points
under the same settings, demonstrating the effectiveness of our model. We hope
this work can serve as a baseline for autonomous driving with LLMs. Code and
models shall be released at https://github.com/OpenGVLab/DriveMLM.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09246" title="Abstract">arXiv:2312.09246</a> [<a href="/pdf/2312.09246" title="Download PDF">pdf</a>, <a href="/format/2312.09246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHAP-EDITOR: Instruction-guided Latent 3D Editing in Seconds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Junyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://silent-chen.github.io/Shap-Editor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel feed-forward 3D editing framework called Shap-Editor.
Prior research on editing 3D objects primarily concentrated on editing
individual objects by leveraging off-the-shelf 2D image editing networks. This
is achieved via a process called distillation, which transfers knowledge from
the 2D network to 3D assets. Distillation necessitates at least tens of minutes
per asset to attain satisfactory editing results, and is thus not very
practical. In contrast, we ask whether 3D editing can be carried out directly
by a feed-forward network, eschewing test-time optimisation. In particular, we
hypothesise that editing can be greatly simplified by first encoding 3D objects
in a suitable latent space. We validate this hypothesis by building upon the
latent space of Shap-E. We demonstrate that direct 3D editing in this space is
possible and efficient by building a feed-forward editor network that only
requires approximately one second per edit. Our experiments show that
Shap-Editor generalises well to both in-distribution and out-of-distribution 3D
assets with different prompts, exhibiting comparable performance with methods
that carry out test-time optimisation for each edited instance.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09249" title="Abstract">arXiv:2312.09249</a> [<a href="/pdf/2312.09249" title="Download PDF">pdf</a>, <a href="/format/2312.09249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroRF: Fast Sparse View 360&#xb0; Reconstruction with Zero Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruoxi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinyue Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sarahweiii.github.io/zerorf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present ZeroRF, a novel per-scene optimization method addressing the
challenge of sparse view 360{\deg} reconstruction in neural field
representations. Current breakthroughs like Neural Radiance Fields (NeRF) have
demonstrated high-fidelity image synthesis but struggle with sparse input
views. Existing methods, such as Generalizable NeRFs and per-scene optimization
approaches, face limitations in data dependency, computational cost, and
generalization across diverse scenarios. To overcome these challenges, we
propose ZeroRF, whose key idea is to integrate a tailored Deep Image Prior into
a factorized NeRF representation. Unlike traditional methods, ZeroRF
parametrizes feature grids with a neural network generator, enabling efficient
sparse view 360{\deg} reconstruction without any pretraining or additional
regularization. Extensive experiments showcase ZeroRF's versatility and
superiority in terms of both quality and speed, achieving state-of-the-art
results on benchmark datasets. ZeroRF's significance extends to applications in
3D content generation and editing. Project page:
https://sarahweiii.github.io/zerorf/
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09250" title="Abstract">arXiv:2312.09250</a> [<a href="/pdf/2312.09250" title="Download PDF">pdf</a>, <a href="/format/2312.09250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Mesh Diffusion Models with Field Latents for Texture Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitchel%2C+T+W">Thomas W. Mitchel</a>, 
<a href="/search/cs?searchtype=author&query=Esteves%2C+C">Carlos Esteves</a>, 
<a href="/search/cs?searchtype=author&query=Makadia%2C+A">Ameesh Makadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a framework for intrinsic latent diffusion models operating
directly on the surfaces of 3D shapes, with the goal of synthesizing
high-quality textures. Our approach is underpinned by two contributions: field
latents, a latent representation encoding textures as discrete vector fields on
the mesh vertices, and field latent diffusion models, which learn to denoise a
diffusion process in the learned latent space on the surface. We consider a
single-textured-mesh paradigm, where our models are trained to generate
variations of a given texture on a mesh. We show the synthesized textures are
of superior fidelity compared those from existing single-textured-mesh
generative models. Our models can also be adapted for user-controlled editing
tasks such as inpainting and label-guided generation. The efficacy of our
approach is due in part to the equivariance of our proposed framework under
isometries, allowing our models to seamlessly reproduce details across locally
similar regions and opening the door to a notion of generative texture
transfer.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09251" title="Abstract">arXiv:2312.09251</a> [<a href="/pdf/2312.09251" title="Download PDF">pdf</a>, <a href="/format/2312.09251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VL-GPT: A Generative Pre-trained Transformer for Vision and Language  Understanding and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinguo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuying Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we introduce Vision-Language Generative Pre-trained Transformer
(VL-GPT), a transformer model proficient at concurrently perceiving and
generating visual and linguistic data. VL-GPT achieves a unified pre-training
approach for both image and text modalities by employing a straightforward
auto-regressive objective, thereby enabling the model to process image and text
as seamlessly as a language model processes text. To accomplish this, we
initially propose a novel image tokenizer-detokenizer framework for visual
data, specifically designed to transform raw images into a sequence of
continuous embeddings and reconstruct them accordingly. In combination with the
existing text tokenizer and detokenizer, this framework allows for the encoding
of interleaved image-text data into a multimodal sequence, which can
subsequently be fed into the transformer model. Consequently, VL-GPT can
perform large-scale pre-training on multimodal corpora utilizing a unified
auto-regressive objective (i.e., next-token prediction). Upon completion of
pre-training, VL-GPT exhibits remarkable zero-shot and few-shot performance
across a diverse range of vision and language understanding and generation
tasks, including image captioning, visual question answering, text-to-image
generation, and more. Additionally, the pre-trained model retrains in-context
learning capabilities when provided with multimodal prompts. We further conduct
instruction tuning on our VL-GPT, highlighting its exceptional potential for
multimodal assistance. The source code and model weights shall be released.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09252" title="Abstract">arXiv:2312.09252</a> [<a href="/pdf/2312.09252" title="Download PDF">pdf</a>, <a href="/format/2312.09252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineControlNet: Fine-level Text Control for Image Generation with  Spatially Aligned Text Control Injection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hongsuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kasahara%2C+I">Isaac Kasahara</a>, 
<a href="/search/cs?searchtype=author&query=Engin%2C+S">Selim Engin</a>, 
<a href="/search/cs?searchtype=author&query=Graule%2C+M">Moritz Graule</a>, 
<a href="/search/cs?searchtype=author&query=Chavan-Dafle%2C+N">Nikhil Chavan-Dafle</a>, 
<a href="/search/cs?searchtype=author&query=Isler%2C+V">Volkan Isler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Hongsuk Choi and Isaac Kasahara have eqaul contributions. 19 pages, 15 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently introduced ControlNet has the ability to steer the text-driven image
generation process with geometric input such as human 2D pose, or edge
features. While ControlNet provides control over the geometric form of the
instances in the generated image, it lacks the capability to dictate the visual
appearance of each instance. We present FineControlNet to provide fine control
over each instance's appearance while maintaining the precise pose control
capability. Specifically, we develop and demonstrate FineControlNet with
geometric control via human pose images and appearance control via
instance-level text prompts. The spatial alignment of instance-specific text
prompts and 2D poses in latent space enables the fine control capabilities of
FineControlNet. We evaluate the performance of FineControlNet with rigorous
comparison against state-of-the-art pose-conditioned text-to-image diffusion
models. FineControlNet achieves superior performance in generating images that
follow the user-provided instance-specific text prompts and poses compared with
existing methods. Project webpage:
https://samsunglabs.github.io/FineControlNet-project-page
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09254" title="Abstract">arXiv:2312.09254</a> [<a href="/pdf/2312.09254" title="Download PDF">pdf</a>, <a href="/format/2312.09254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Depth Completion from a Stereo Matching Perspective for  Cross-domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartolomei%2C+L">Luca Bartolomei</a>, 
<a href="/search/cs?searchtype=author&query=Poggi%2C+M">Matteo Poggi</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+A">Andrea Conti</a>, 
<a href="/search/cs?searchtype=author&query=Tosi%2C+F">Fabio Tosi</a>, 
<a href="/search/cs?searchtype=author&query=Mattoccia%2C+S">Stefano Mattoccia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3DV 2024. Code: <a href="https://github.com/bartn8/vppdc">this https URL</a> - Project page: <a href="https://vppdc.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a new framework for depth completion robust against
domain-shifting issues. It exploits the generalization capability of modern
stereo networks to face depth completion, by processing fictitious stereo pairs
obtained through a virtual pattern projection paradigm. Any stereo network or
traditional stereo matcher can be seamlessly plugged into our framework,
allowing for the deployment of a virtual stereo setup that is future-proof
against advancement in the stereo field. Exhaustive experiments on cross-domain
generalization support our claims. Hence, we argue that our framework can help
depth completion to reach new deployment scenarios.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09256" title="Abstract">arXiv:2312.09256</a> [<a href="/pdf/2312.09256" title="Download PDF">pdf</a>, <a href="/format/2312.09256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIME: Localized Image Editing via Attention Regularization in Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simsar%2C+E">Enis Simsar</a>, 
<a href="/search/cs?searchtype=author&query=Tonioni%2C+A">Alessio Tonioni</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yongqin Xian</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models (DMs) have gained prominence due to their ability to
generate high-quality, varied images, with recent advancements in text-to-image
generation. The research focus is now shifting towards the controllability of
DMs. A significant challenge within this domain is localized editing, where
specific areas of an image are modified without affecting the rest of the
content. This paper introduces LIME for localized image editing in diffusion
models that do not require user-specified regions of interest (RoI) or
additional text input. Our method employs features from pre-trained methods and
a simple clustering technique to obtain precise semantic segmentation maps.
Then, by leveraging cross-attention maps, it refines these segments for
localized edits. Finally, we propose a novel cross-attention regularization
technique that penalizes unrelated cross-attention scores in the RoI during the
denoising steps, ensuring localized edits. Our approach, without re-training
and fine-tuning, consistently improves the performance of existing methods in
various editing benchmarks.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 15 Dec 23</h3>
<dl>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02675" title="Abstract">arXiv:2305.02675</a> (cross-list from math.CT) [<a href="/pdf/2305.02675" title="Download PDF">pdf</a>, <a href="/format/2305.02675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collages of String Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Braithwaite%2C+D">Dylan Braithwaite</a> (University of Strathclyde), 
<a href="/search/math?searchtype=author&query=Rom%C3%A1n%2C+M">Mario Rom&#xe1;n</a> (Tallinn University of Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>. 15 pages, 10 figures, shorter version for ACT2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 39-53
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We introduce collages of string diagrams as a diagrammatic syntax for glueing
multiple monoidal categories. Collages of string diagrams are interpreted as
pointed bimodular profunctors. As the main examples of this technique, we
introduce string diagrams for bimodular categories, string diagrams for functor
boxes, and string diagrams for internal diagrams.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11637" title="Abstract">arXiv:2305.11637</a> (cross-list from math.CT) [<a href="/pdf/2305.11637" title="Download PDF">pdf</a>, <a href="/ps/2305.11637" title="Download PostScript">ps</a>, <a href="/format/2305.11637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posetal Diagrams for Logically-Structured Semistrict Higher Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sarti%2C+C">Chiara Sarti</a> (Department of Computer Science, University of Cambridge), 
<a href="/search/math?searchtype=author&query=Vicary%2C+J">Jamie Vicary</a> (Department of Computer Science, University of Cambridge)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>. Reformatted paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 246-259
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We now have a wide range of proof assistants available for compositional
reasoning in monoidal or higher categories which are free on some generating
signature. However, none of these allow us to represent categorical operations
such as products, equalizers, and similar logical techniques. Here we show how
the foundational mathematical formalism of one such proof assistant can be
generalized, replacing the conventional notion of string diagram as a
geometrical entity living inside an n-cube with a posetal variant that allows
exotic branching structure. We show that these generalized diagrams have richer
behaviour with respect to categorical limits, and give an algorithm for
computing limits in this setting, with a view towards future application in
proof assistants.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08470" title="Abstract">arXiv:2312.08470</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.08470" title="Download PDF">pdf</a>, <a href="/ps/2312.08470" title="Download PostScript">ps</a>, <a href="/format/2312.08470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best practices for machine learning in antibody discovery and  development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wossnig%2C+L">Leonard Wossnig</a>, 
<a href="/search/q-bio?searchtype=author&query=Furtmann%2C+N">Norbert Furtmann</a>, 
<a href="/search/q-bio?searchtype=author&query=Buchanan%2C+A">Andrew Buchanan</a>, 
<a href="/search/q-bio?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>, 
<a href="/search/q-bio?searchtype=author&query=Greiff%2C+V">Victor Greiff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past 40 years, the discovery and development of therapeutic
antibodies to treat disease has become common practice. However, as therapeutic
antibody constructs are becoming more sophisticated (e.g., multi-specifics),
conventional approaches to optimisation are increasingly inefficient. Machine
learning (ML) promises to open up an in silico route to antibody discovery and
help accelerate the development of drug products using a reduced number of
experiments and hence cost. Over the past few years, we have observed rapid
developments in the field of ML-guided antibody discovery and development
(D&amp;D). However, many of the results are difficult to compare or hard to assess
for utility by other experts in the field due to the high diversity in the
datasets and evaluation techniques and metrics that are across industry and
academia. This limitation of the literature curtails the broad adoption of ML
across the industry and slows down overall progress in the field, highlighting
the need to develop standards and guidelines that may help improve the
reproducibility of ML models across different research groups. To address these
challenges, we set out in this perspective to critically review current
practices, explain common pitfalls, and clearly define a set of method
development and evaluation guidelines that can be applied to different types of
ML-based techniques for therapeutic antibody D&amp;D. Specifically, we address in
an end-to-end analysis, challenges associated with all aspects of the ML
process and recommend a set of best practices for each stage.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08493" title="Abstract">arXiv:2312.08493</a> (cross-list from stat.ML) [<a href="/pdf/2312.08493" title="Download PDF">pdf</a>, <a href="/format/2312.08493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning-based estimation of time-dependent parameters in Markov  models with application to nonlinear regression and SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ka%C5%82u%C5%BCa%2C+A">Andrzej Ka&#x142;u&#x17c;a</a>, 
<a href="/search/stat?searchtype=author&query=Morkisz%2C+P+M">Pawe&#x142; M. Morkisz</a>, 
<a href="/search/stat?searchtype=author&query=Mulewicz%2C+B">Bart&#x142;omiej Mulewicz</a>, 
<a href="/search/stat?searchtype=author&query=Przyby%C5%82owicz%2C+P">Pawe&#x142; Przyby&#x142;owicz</a>, 
<a href="/search/stat?searchtype=author&query=Wi%C4%85cek%2C+M">Martyna Wi&#x105;cek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present a novel deep learning method for estimating time-dependent
parameters in Markov processes through discrete sampling. Departing from
conventional machine learning, our approach reframes parameter approximation as
an optimization problem using the maximum likelihood approach. Experimental
validation focuses on parameter estimation in multivariate regression and
stochastic differential equations (SDEs). Theoretical results show that the
real solution is close to SDE with parameters approximated using our neural
network-derived under specific conditions. Our work contributes to SDE-based
model parameter estimation, offering a versatile tool for diverse fields.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08496" title="Abstract">arXiv:2312.08496</a> (cross-list from eess.AS) [<a href="/pdf/2312.08496" title="Download PDF">pdf</a>, <a href="/ps/2312.08496" title="Download PostScript">ps</a>, <a href="/format/2312.08496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metrological support of acoustic measuring installations mid-frequency  devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grekov%2C+A+N">A.N. Grekov</a>, 
<a href="/search/eess?searchtype=author&query=Grekov%2C+N+A">N.A. Grekov</a>, 
<a href="/search/eess?searchtype=author&query=Sychev%2C+E+N">E.N. Sychev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Environmental control systems. 2023. Issue. 2 (40). pp. 117-126
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The article discusses methods for measuring the speed of sound, scattering,
attenuation and absorption of sound in liquids, on the basis of which the
structural diagrams of modern devices have been developed. In real conditions,
acoustic measurement schemes are not ideal and depending on specific structure
may give different results. The technical and metrological characteristics of
the measuring channels of modern acoustic devices are presented.
Recommendations are given for the use of GOST in acoustic measurements and it
is stated that the metrological characteristics of newly created measuring
instruments operating in in situ conditions are at the level of State primary
standards.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08512" title="Abstract">arXiv:2312.08512</a> (cross-list from math.OC) [<a href="/pdf/2312.08512" title="Download PDF">pdf</a>, <a href="/format/2312.08512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Triggered Extremum Seeking Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rodrigues%2C+V+H+P">Victor Hugo Pereira Rodrigues</a>, 
<a href="/search/math?searchtype=author&query=Oliveira%2C+T+R">Tiago Roux Oliveira</a>, 
<a href="/search/math?searchtype=author&query=Hsu%2C+L">Liu Hsu</a>, 
<a href="/search/math?searchtype=author&query=Diagne%2C+M">Mamadou Diagne</a>, 
<a href="/search/math?searchtype=author&query=Krstic%2C+M">Miroslav Krstic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes an event-triggered control scheme for multivariable
extremum seeking of static maps. Both static and dynamic triggering conditions
are developed. Integrating Lyapunov and averaging theories for discontinuous
systems, a systematic design procedure and stability analysis are developed.
Both event-based methods enable one to achieve an asymptotic stability result.
Ultimately, the resulting closed-loop dynamics demonstrates the advantages of
combining both approaches, namely, event-triggered control and extremum
seeking. Although we keep the presentation using the classical event-triggered
method, the extension of the results for the periodic event-triggered approach
is also indicated. An illustration of the benefits of the new control method is
presented using consistent simulation results, which compare the static and the
dynamic triggering approaches.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08519" title="Abstract">arXiv:2312.08519</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.08519" title="Download PDF">pdf</a>, <a href="/ps/2312.08519" title="Download PostScript">ps</a>, <a href="/format/2312.08519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a More Biologically Plausible Neural Network Model of Latent  Cause Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+Q">Qihong Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Nguyen%2C+T+T">Tan T. Nguyen</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Q">Qiong Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Hasson%2C+U">Uri Hasson</a>, 
<a href="/search/q-bio?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/q-bio?searchtype=author&query=Zacks%2C+J+M">Jeffrey M. Zacks</a>, 
<a href="/search/q-bio?searchtype=author&query=Gershman%2C+S+J">Samuel J. Gershman</a>, 
<a href="/search/q-bio?searchtype=author&query=Norman%2C+K+A">Kenneth A. Norman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans spontaneously perceive a continuous stream of experience as discrete
events. It has been hypothesized that this ability is supported by latent cause
inference (LCI). We implemented this hypothesis using Latent Cause Network
(LCNet), a neural network model of LCI. LCNet interacts with a Bayesian LCI
mechanism that activates a unique context vector for each inferred latent
cause. This architecture makes LCNet more biologically plausible than existing
models of LCI and supports extraction of shared structure across latent causes.
Across three simulations, we found that LCNet could 1) extract shared structure
across latent causes in a function-learning task while avoiding catastrophic
interference, 2) capture human data on curriculum effects in schema learning,
and 3) infer the underlying event structure when processing naturalistic videos
of daily activities. Our work provides a biologically plausible computational
model that can operate in both laboratory experiment settings and naturalistic
settings, opening up the possibility of providing a unified model of event
cognition.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08524" title="Abstract">arXiv:2312.08524</a> (cross-list from eess.IV) [<a href="/pdf/2312.08524" title="Download PDF">pdf</a>, <a href="/format/2312.08524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A FUNQUE Approach to the Quality Assessment of Compressed HDR Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Venkataramanan%2C+A+K">Abhinau K. Venkataramanan</a>, 
<a href="/search/eess?searchtype=author&query=Stejerean%2C+C">Cosmin Stejerean</a>, 
<a href="/search/eess?searchtype=author&query=Katsavounidis%2C+I">Ioannis Katsavounidis</a>, 
<a href="/search/eess?searchtype=author&query=Bovik%2C+A+C">Alan C. Bovik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent years have seen steady growth in the popularity and availability of
High Dynamic Range (HDR) content, particularly videos, streamed over the
internet. As a result, assessing the subjective quality of HDR videos, which
are generally subjected to compression, is of increasing importance. In
particular, we target the task of full-reference quality assessment of
compressed HDR videos. The state-of-the-art (SOTA) approach HDRMAX involves
augmenting off-the-shelf video quality models, such as VMAF, with features
computed on non-linearly transformed video frames. However, HDRMAX increases
the computational complexity of models like VMAF. Here, we show that an
efficient class of video quality prediction models named FUNQUE+ achieves SOTA
accuracy. This shows that the FUNQUE+ models are flexible alternatives to VMAF
that achieve higher HDR video quality prediction accuracy at lower
computational cost.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08553" title="Abstract">arXiv:2312.08553</a> (cross-list from eess.AS) [<a href="/pdf/2312.08553" title="Download PDF">pdf</a>, <a href="/format/2312.08553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USM-Lite: Quantization and Sparsity Aware Fine-tuning for Speech  Recognition with Universal Speech Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ding%2C+S">Shaojin Ding</a>, 
<a href="/search/eess?searchtype=author&query=David%2C+Q">Qiu David</a>, 
<a href="/search/eess?searchtype=author&query=Rim%2C+D">David Rim</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yanzhang He</a>, 
<a href="/search/eess?searchtype=author&query=Rybakov%2C+O">Oleg Rybakov</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/eess?searchtype=author&query=Prabhavalkar%2C+R">Rohit Prabhavalkar</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/eess?searchtype=author&query=Sainath%2C+T+N">Tara N. Sainath</a>, 
<a href="/search/eess?searchtype=author&query=Agrawal%2C+S">Shivani Agrawal</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zhonglin Han</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/eess?searchtype=author&query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024. Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">End-to-end automatic speech recognition (ASR) models have seen revolutionary
quality gains with the recent development of large-scale universal speech
models (USM). However, deploying these massive USMs is extremely expensive due
to the enormous memory usage and computational cost. Therefore, model
compression is an important research topic to fit USM-based ASR under budget in
real-world scenarios. In this study, we propose a USM fine-tuning approach for
ASR, with a low-bit quantization and N:M structured sparsity aware paradigm on
the model weights, reducing the model complexity from parameter precision and
matrix topology perspectives. We conducted extensive experiments with a
2-billion parameter USM on a large-scale voice search dataset to evaluate our
proposed method. A series of ablation studies validate the effectiveness of up
to int4 quantization and 2:4 sparsity. However, a single compression technique
fails to recover the performance well under extreme setups including int2
quantization and 1:4 sparsity. By contrast, our proposed method can compress
the model to have 9.4% of the size, at the cost of only 7.3% relative word
error rate (WER) regressions. We also provided in-depth analyses on the results
and discussions on the limitations and potential solutions, which would be
valuable for future studies.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08555" title="Abstract">arXiv:2312.08555</a> (cross-list from eess.IV) [<a href="/pdf/2312.08555" title="Download PDF">pdf</a>, <a href="/format/2312.08555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KDAS3: Knowledge distillation via Attention Supervision, and Symmetrical  structure guiding for Polyp Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Polyp segmentation, a contentious issue in medical imaging, has seen numerous
proposed methods aimed at improving the quality of segmented masks. Currently,
state-of-the-art techniques yield impressive results. However, the sheer size
of these models poses challenges for practical industry applications. To
address this, we present a Knowledge Distillation framework, incorporating
attention supervision and the symmetrical guiding method. This framework is
designed to facilitate knowledge transfer from a teacher model to a more
compact student model with fewer parameters. Our experimental evaluation of the
framework assesses its effectiveness in enabling the student model to acquire
knowledge from the teacher efficiently. Additionally, our method serves to
prevent the student model from incorporating redundant features that could lead
to inaccurate predictions. Consequently, our method, boasting approximately 5
million parameters, achieves competitive results comparable to the
state-of-the-art approaches. The implementation can be found at:
https://github.com/huyquoctrinh/KDAS3
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08567" title="Abstract">arXiv:2312.08567</a> (cross-list from eess.IV) [<a href="/pdf/2312.08567" title="Download PDF">pdf</a>, <a href="/format/2312.08567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConFormer: A Novel Collection of Deep Learning Models to Assist  Cardiologists in the Assessment of Cardiac Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Thomas%2C+E">Ethan Thomas</a>, 
<a href="/search/eess?searchtype=author&query=Aslam%2C+S">Salman Aslam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cardiovascular diseases, particularly heart failure, are a leading cause of
death globally. The early detection of heart failure through routine
echocardiogram screenings is often impeded by the high cost and labor-intensive
nature of these procedures, a barrier that can mean the difference between life
and death. This paper presents ConFormer, a novel deep learning model designed
to automate the estimation of Ejection Fraction (EF) and Left Ventricular Wall
Thickness from echocardiograms. The implementation of ConFormer has the
potential to enhance preventative cardiology by enabling cost-effective,
accessible, and comprehensive heart health monitoring, thereby saving countless
lives. The source code is available at https://github.com/Aether111/ConFormer.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08573" title="Abstract">arXiv:2312.08573</a> (cross-list from math.OC) [<a href="/pdf/2312.08573" title="Download PDF">pdf</a>, <a href="/ps/2312.08573" title="Download PostScript">ps</a>, <a href="/format/2312.08573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probably approximately correct stability of allocations in uncertain  coalitional games with private sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pantazis%2C+G">George Pantazis</a>, 
<a href="/search/math?searchtype=author&query=Fele%2C+F">Filiberto Fele</a>, 
<a href="/search/math?searchtype=author&query=Fabiani%2C+F">Filippo Fabiani</a>, 
<a href="/search/math?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>, 
<a href="/search/math?searchtype=author&query=Margellos%2C+K">Kostas Margellos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY)

</div>
<p class="mathjax">We study coalitional games with exogenous uncertainty in the coalition value,
in which each agent is allowed to have private samples of the uncertainty. As a
consequence, the agents may have a different perception of stability of the
grand coalition. In this context, we propose a novel methodology to study the
out-of-sample coalitional rationality of allocations in the set of stable
allocations (i.e., the core). Our analysis builds on the framework of probably
approximately correct learning. Initially, we state a priori and a posteriori
guarantees for the entire core. Furthermore, we provide a distributed algorithm
to compute a compression set that determines the generalization properties of
the a posteriori statements. We then refine our probabilistic robustness bounds
by specialising the analysis to a single payoff allocation, taking, also in
this case, both a priori and a posteriori approaches. Finally, we consider a
relaxed $\zeta$-core to include nearby allocations and also address the case of
empty core. For this case, probabilistic statements are given on the eventual
stability of allocations in the $\zeta$-core.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08603" title="Abstract">arXiv:2312.08603</a> (cross-list from eess.AS) [<a href="/pdf/2312.08603" title="Download PDF">pdf</a>, <a href="/format/2312.08603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeXt-TDNN: Modernizing Multi-Scale Temporal Convolution Backbone for  Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Heo%2C+H">Hyun-Jun Heo</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+U">Ui-Hyeop Shin</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+R">Ran Lee</a>, 
<a href="/search/eess?searchtype=author&query=Cheon%2C+Y">YoungJu Cheon</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+H">Hyung-Min Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In speaker verification, ECAPA-TDNN has shown remarkable improvement by
utilizing one-dimensional(1D) Res2Net block and squeeze-and-excitation(SE)
module, along with multi-layer feature aggregation (MFA). Meanwhile, in vision
tasks, ConvNet structures have been modernized by referring to Transformer,
resulting in improved performance. In this paper, we present an improved block
design for TDNN in speaker verification. Inspired by recent ConvNet structures,
we replace the SE-Res2Net block in ECAPA-TDNN with a novel 1D two-step
multi-scale ConvNeXt block, which we call \textit{TS-ConvNeXt}. The TS-ConvNeXt
block is constructed using two separated sub-modules: a temporal multi-scale
convolution (MSC) and a frame-wise feed-forward network (FFN). This two-step
design allows for flexible capturing of inter-frame and intra-frame contexts.
Additionally, we introduce global response normalization (GRN) for the FFN
modules to enable more selective feature propagation, similar to the SE module
in ECAPA-TDNN. Experimental results demonstrate that NeXt-TDNN, with a
modernized backbone block, significantly improved performance in speaker
verification tasks while reducing parameter size and inference time. We have
released our code for future studies.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08610" title="Abstract">arXiv:2312.08610</a> (cross-list from eess.AS) [<a href="/pdf/2312.08610" title="Download PDF">pdf</a>, <a href="/format/2312.08610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A computationally efficient semi-blind source separation based approach  for nonlinear echo cancellation based on an element-wise iterative source  steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+K">Kunxing Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xianrui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ueda%2C+T">Tetsuya Ueda</a>, 
<a href="/search/eess?searchtype=author&query=Makino%2C+S">Shoji Makino</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">While the semi-blind source separation-based acoustic echo cancellation
(SBSS-AEC) has received much research attention due to its promising
performance during double-talk compared to the traditional adaptive algorithms,
it suffers from system latency and nonlinear distortions. To circumvent these
drawbacks, the recently developed ideas on convolutive transfer function (CTF)
approximation and nonlinear expansion have been used in the iterative
projection (IP)-based semi-blind source separation (SBSS) algorithm. However,
because of the introduction of CTF approximation and nonlinear expansion, this
algorithm becomes computationally very expensive, which makes it difficult to
implement in embedded systems. Thus, we attempt in this paper to improve this
IP-based algorithm, thereby developing an element-wise iterative source
steering (EISS) algorithm. In comparison with the IP-based SBSS algorithm, the
proposed algorithm is computationally much more efficient, especially when the
nonlinear expansion order is high and the length of the CTF filter is long.
Meanwhile, its AEC performance is as good as that of IP-based SBSS.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08622" title="Abstract">arXiv:2312.08622</a> (cross-list from eess.AS) [<a href="/pdf/2312.08622" title="Download PDF">pdf</a>, <a href="/format/2312.08622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Ensemble-based Detection Method against Adversarial Attacks for  speaker verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Haibin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Kuo%2C+H">Heng-Cheng Kuo</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Automatic speaker verification (ASV) is highly susceptible to adversarial
attacks. Purification modules are usually adopted as a pre-processing to
mitigate adversarial noise. However, they are commonly implemented across
diverse experimental settings, rendering direct comparisons challenging. This
paper comprehensively compares mainstream purification techniques in a unified
framework. We find these methods often face a trade-off between user experience
and security, as they struggle to simultaneously maintain genuine sample
performance and reduce adversarial perturbations. To address this challenge,
some efforts have extended purification modules to encompass detection
capabilities, aiming to alleviate the trade-off. However, advanced purification
modules will always come into the stage to surpass previous detection method.
As a result, we further propose an easy-to-follow ensemble approach that
integrates advanced purification modules for detection, achieving
state-of-the-art (SOTA) performance in countering adversarial noise. Our
ensemble method has great potential due to its compatibility with future
advanced purification techniques.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08625" title="Abstract">arXiv:2312.08625</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.08625" title="Download PDF">pdf</a>, <a href="/format/2312.08625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Network Surrogate Model for Subsurface Flow Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tang%2C+H">Haoyu Tang</a>, 
<a href="/search/physics?searchtype=author&query=Durlofsky%2C+L+J">Louis J. Durlofsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The optimization of well locations and controls is an important step in the
design of subsurface flow operations such as oil production or geological CO2
storage. These optimization problems can be computationally expensive, however,
as many potential candidate solutions must be evaluated. In this study, we
propose a graph network surrogate model (GNSM) for optimizing well placement
and controls. The GNSM transforms the flow model into a computational graph
that involves an encoding-processing-decoding architecture. Separate networks
are constructed to provide global predictions for the pressure and saturation
state variables. Model performance is enhanced through the inclusion of the
single-phase steady-state pressure solution as a feature. A multistage
multistep strategy is used for training. The trained GNSM is applied to predict
flow responses in a 2D unstructured model of a channelized reservoir. Results
are presented for a large set of test cases, in which five injection wells and
five production wells are placed randomly throughout the model, with a random
control variable (bottom-hole pressure) assigned to each well. Median relative
error in pressure and saturation for 300 such test cases is 1-2%. The ability
of the trained GNSM to provide accurate predictions for a new (geologically
similar) permeability realization is demonstrated. Finally, the trained GNSM is
used to optimize well locations and controls with a differential evolution
algorithm. GNSM-based optimization results are comparable to those from
simulation-based optimization, with a runtime speedup of a factor of 36. Much
larger speedups are expected if the method is used for robust optimization, in
which each candidate solution is evaluated on multiple geological models.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08641" title="Abstract">arXiv:2312.08641</a> (cross-list from eess.AS) [<a href="/pdf/2312.08641" title="Download PDF">pdf</a>, <a href="/format/2312.08641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Data Augmentation for Disordered Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+X">Xurong Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianzi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+J">Jiajun Deng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Guinan Li</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shujie Hu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xunying Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Automatic recognition of disordered speech remains a highly challenging task
to date due to data scarcity. This paper presents a reinforcement learning (RL)
based on-the-fly data augmentation approach for training state-of-the-art
PyChain TDNN and end-to-end Conformer ASR systems on such data. The handcrafted
temporal and spectral mask operations in the standard SpecAugment method that
are task and system dependent, together with additionally introduced minimum
and maximum cut-offs of these time-frequency masks, are now automatically
learned using an RNN-based policy controller and tightly integrated with ASR
system training. Experiments on the UASpeech corpus suggest the proposed
RL-based data augmentation approach consistently produced performance superior
or comparable that obtained using expert or handcrafted SpecAugment policies.
Our RL auto-augmented PyChain TDNN system produced an overall WER of 28.79% on
the UASpeech test set of 16 dysarthric speakers.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08658" title="Abstract">arXiv:2312.08658</a> (cross-list from cond-mat.soft) [<a href="/pdf/2312.08658" title="Download PDF">pdf</a>, <a href="/ps/2312.08658" title="Download PostScript">ps</a>, <a href="/format/2312.08658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Autonomous Control of a Continuous Macroscopic Process as  Demonstrated by Plastic Forming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Muroga%2C+S">Shun Muroga</a>, 
<a href="/search/cond-mat?searchtype=author&query=Honda%2C+T">Takashi Honda</a>, 
<a href="/search/cond-mat?searchtype=author&query=Miki%2C+Y">Yasuaki Miki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nakajima%2C+H">Hideaki Nakajima</a>, 
<a href="/search/cond-mat?searchtype=author&query=Futaba%2C+D+N">Don N. Futaba</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hata%2C+K">Kenji Hata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18pages, 7figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">To meet the demands for more adaptable and expedient approaches to augment
both research and manufacturing, we report an autonomous system using real-time
in-situ characterization and an autonomous, decision-making processer based on
an active learning algorithm. This system was applied to a plastic film forming
system to highlight its efficiency and accuracy in determining the process
conditions for specified target film dimensions, importantly, without any human
intervention. Application of this system towards nine distinct film dimensions
demonstrated the system ability to quickly determine the appropriate and stable
process conditions (average 11 characterization-adjustment iterations, 19
minutes) and the ability to avoid traps, such as repetitive over-correction.
Furthermore, comparison of the achieved film dimensions to the target values
showed a high accuracy (R2 = 0.87, 0.90) for film width and thickness,
respectively. In addition, the use of an active learning algorithm afforded our
system to proceed optimization with zero initial training data, which was
unavailable due to the complex relationships between the control factors
(material supply rate, applied force, material viscosity) within the plastic
forming process. As our system is intrinsically general and can be applied to
any most material processes, these results have significant implications in
accelerating both research and industrial processes.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08670" title="Abstract">arXiv:2312.08670</a> (cross-list from stat.ME) [<a href="/pdf/2312.08670" title="Download PDF">pdf</a>, <a href="/format/2312.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-Spatial Entropy Balancing for Causal Continuous  Treatment-Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Honglong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zeng%2C+F">Fan Zeng</a>, 
<a href="/search/stat?searchtype=author&query=Du%2C+M">Min Du</a>, 
<a href="/search/stat?searchtype=author&query=Du%2C+X">XiangKun Du</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+Y">Yue Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mengran Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+D">Dan Yang</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+J">Jihao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of intracity freight transportation, changes in order volume are
significantly influenced by temporal and spatial factors. When building subsidy
and pricing strategies, predicting the causal effects of these strategies on
order volume is crucial. In the process of calculating causal effects,
confounding variables can have an impact. Traditional methods to control
confounding variables handle data from a holistic perspective, which cannot
ensure the precision of causal effects in specific temporal and spatial
dimensions. However, temporal and spatial dimensions are extremely critical in
the logistics field, and this limitation may directly affect the precision of
subsidy and pricing strategies. To address these issues, this study proposes a
technique based on flexible temporal-spatial grid partitioning. Furthermore,
based on the flexible grid partitioning technique, we further propose a
continuous entropy balancing method in the temporal-spatial domain, which named
TS-EBCT (Temporal-Spatial Entropy Balancing for Causal Continue Treatments).
The method proposed in this paper has been tested on two simulation datasets
and two real datasets, all of which have achieved excellent performance. In
fact, after applying the TS-EBCT method to the intracity freight transportation
field, the prediction accuracy of the causal effect has been significantly
improved. It brings good business benefits to the company's subsidy and pricing
strategies.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08766" title="Abstract">arXiv:2312.08766</a> (cross-list from eess.IV) [<a href="/pdf/2312.08766" title="Download PDF">pdf</a>, <a href="/format/2312.08766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual Convolutional Neural Network Pipeline for Melanoma Diagnostics  and Prognostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=B%C3%B8-Sande%2C+M">Marie B&#xf8;-Sande</a>, 
<a href="/search/eess?searchtype=author&query=Benjaminsen%2C+E">Edvin Benjaminsen</a>, 
<a href="/search/eess?searchtype=author&query=Kanwal%2C+N">Neel Kanwal</a>, 
<a href="/search/eess?searchtype=author&query=Fuster%2C+S">Saul Fuster</a>, 
<a href="/search/eess?searchtype=author&query=Hardardottir%2C+H">Helga Hardardottir</a>, 
<a href="/search/eess?searchtype=author&query=Lundal%2C+I">Ingrid Lundal</a>, 
<a href="/search/eess?searchtype=author&query=Janssen%2C+E+A+M">Emiel A.M. Janssen</a>, 
<a href="/search/eess?searchtype=author&query=Engan%2C+K">Kjersti Engan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NLDL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Melanoma is a type of cancer that begins in the cells controlling the pigment
of the skin, and it is often referred to as the most dangerous skin cancer.
Diagnosing melanoma can be time-consuming, and a recent increase in melanoma
incidents indicates a growing demand for a more efficient diagnostic process.
This paper presents a pipeline for melanoma diagnostics, leveraging two
convolutional neural networks, a diagnosis, and a prognosis model. The
diagnostic model is responsible for localizing malignant patches across whole
slide images and delivering a patient-level diagnosis as malignant or benign.
Further, the prognosis model utilizes the diagnostic model's output to provide
a patient-level prognosis as good or bad. The full pipeline has an F1 score of
0.79 when tested on data from the same distribution as it was trained on.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08809" title="Abstract">arXiv:2312.08809</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.08809" title="Download PDF">pdf</a>, <a href="/ps/2312.08809" title="Download PostScript">ps</a>, <a href="/format/2312.08809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance evaluation of matrix factorization for fMRI data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Endo%2C+Y">Yusuke Endo</a>, 
<a href="/search/q-bio?searchtype=author&query=Takeda%2C+K">Koujin Takeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computation (2024) 36 (1) 128-150
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the study of the brain, there is a hypothesis that sparse coding is
realized in information representation of external stimuli, which is
experimentally confirmed for visual stimulus recently. However, unlike the
specific functional region in the brain, sparse coding in information
processing in the whole brain has not been clarified sufficiently. In this
study, we investigate the validity of sparse coding in the whole human brain by
applying various matrix factorization methods to functional magnetic resonance
imaging data of neural activities in the whole human brain. The result suggests
sparse coding hypothesis in information representation in the whole human
brain, because extracted features from sparse MF method, SparsePCA or MOD under
high sparsity setting, or approximate sparse MF method, FastICA, can classify
external visual stimuli more accurately than non-sparse MF method or sparse MF
method under low sparsity setting.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08821" title="Abstract">arXiv:2312.08821</a> (cross-list from eess.AS) [<a href="/pdf/2312.08821" title="Download PDF">pdf</a>, <a href="/format/2312.08821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of Sound Field through Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Miotello%2C+F">Federico Miotello</a>, 
<a href="/search/eess?searchtype=author&query=Comanducci%2C+L">Luca Comanducci</a>, 
<a href="/search/eess?searchtype=author&query=Pezzoli%2C+M">Mirco Pezzoli</a>, 
<a href="/search/eess?searchtype=author&query=Bernardini%2C+A">Alberto Bernardini</a>, 
<a href="/search/eess?searchtype=author&query=Antonacci%2C+F">Fabio Antonacci</a>, 
<a href="/search/eess?searchtype=author&query=Sarti%2C+A">Augusto Sarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconstructing the sound field in a room is an important task for several
applications, such as sound control and augmented (AR) or virtual reality (VR).
In this paper, we propose a data-driven generative model for reconstructing the
magnitude of acoustic fields in rooms with a focus on the modal frequency
range. We introduce, for the first time, the use of a conditional Denoising
Diffusion Probabilistic Model (DDPM) trained in order to reconstruct the sound
field (SF-Diff) over an extended domain. The architecture is devised in order
to be conditioned on a set of limited available measurements at different
frequencies and generate the sound field in target, unknown, locations. The
results show that SF-Diff is able to provide accurate reconstructions,
outperforming a state-of-the-art baseline based on kernel interpolation.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08823" title="Abstract">arXiv:2312.08823</a> (cross-list from stat.CO) [<a href="/pdf/2312.08823" title="Download PDF">pdf</a>, <a href="/format/2312.08823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast sampling from constrained spaces using the Metropolis-adjusted  Mirror Langevin Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Srinivasan%2C+V">Vishwak Srinivasan</a>, 
<a href="/search/stat?searchtype=author&query=Wibisono%2C+A">Andre Wibisono</a>, 
<a href="/search/stat?searchtype=author&query=Wilson%2C+A">Ashia Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a new method called the Metropolis-adjusted Mirror Langevin
algorithm for approximate sampling from distributions whose support is a
compact and convex set. This algorithm adds an accept-reject filter to the
Markov chain induced by a single step of the mirror Langevin algorithm (Zhang
et al., 2020), which is a basic discretisation of the mirror Langevin dynamics.
Due to the inclusion of this filter, our method is unbiased relative to the
target, while known discretisations of the mirror Langevin dynamics including
the mirror Langevin algorithm have an asymptotic bias. We give upper bounds for
the mixing time of the proposed algorithm when the potential is relatively
smooth, convex, and Lipschitz with respect to a self-concordant mirror
function. As a consequence of the reversibility of the Markov chain induced by
the algorithm, we obtain an exponentially better dependence on the error
tolerance for approximate sampling. We also present numerical experiments that
corroborate our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08829" title="Abstract">arXiv:2312.08829</a> (cross-list from math.OC) [<a href="/pdf/2312.08829" title="Download PDF">pdf</a>, <a href="/ps/2312.08829" title="Download PostScript">ps</a>, <a href="/format/2312.08829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When are selector control strategies optimal for constrained monotone  systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taghavian%2C+H">Hamed Taghavian</a>, 
<a href="/search/math?searchtype=author&query=Drummond%2C+R">Ross Drummond</a>, 
<a href="/search/math?searchtype=author&query=Johansson%2C+M">Mikael Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper considers optimal control problems defined by a monotone dynamical
system, a monotone cost, and monotone constraints. We identify families of such
problems for which the optimal solution is bang-ride, i.e., always operates on
the constraint boundaries, and prove that the optimal policy switches between a
finite number of state feedback controllers. This motivates the use of simpler
policies, such as selector control, that can be designed without perfect models
and full state measurements. The approach is successfully applied to several
variations of the health-aware fast charging problem for lithium-ion batteries.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08831" title="Abstract">arXiv:2312.08831</a> (cross-list from math.OC) [<a href="/pdf/2312.08831" title="Download PDF">pdf</a>, <a href="/format/2312.08831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proper Lumping for Positive Bilinear Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jim%C3%A9nez-Pastor%2C+A">Antonio Jim&#xe9;nez-Pastor</a>, 
<a href="/search/math?searchtype=author&query=Toller%2C+D">Daniele Toller</a>, 
<a href="/search/math?searchtype=author&query=Tribastone%2C+M">Mirco Tribastone</a>, 
<a href="/search/math?searchtype=author&query=Tschaikowski%2C+M">Max Tschaikowski</a>, 
<a href="/search/math?searchtype=author&query=Vandin%2C+A">Andrea Vandin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Positive systems naturally arise in situations where the model tracks
physical quantities. Although the linear case is well understood, analysis and
controller design for nonlinear positive systems remain challenging. Model
reduction methods can help tame this problem. Here we propose a notion of model
reduction for a class of positive bilinear systems with (bounded) matrix and
exogenous controls. Our reduction, called proper positive lumping, aggregates
the original system such that states of the corresponding reduced model
represent non-negative linear combinations of original state variables. We
prove a characterization result showing that the reductions by proper positive
lumping are exactly those preserving the optimality of a suitable class of
value functions. Moreover, we provide an efficient polynomial-time algorithm
for the computation of the minimal lumping. We numerically evaluate our
approach by applying it to a number of benchmark case studies.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08834" title="Abstract">arXiv:2312.08834</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.08834" title="Download PDF">pdf</a>, <a href="/format/2312.08834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up Photoacoustic Imaging using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Loc%2C+I">Irem Loc</a>, 
<a href="/search/physics?searchtype=author&query=Unlu%2C+M+B">Mehmet Burcin Unlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Background: Photoacoustic Microscopy (PAM) integrates optical and acoustic
imaging, offering enhanced penetration depth for detecting optical-absorbing
components in tissues. Nonetheless, challenges arise in scanning large areas
with high spatial resolution. With speed limitations imposed by laser pulse
repetition rates, the potential role of computational methods is highlighted in
accelerating PAM imaging. Purpose: We are proposing a novel and highly
adaptable DiffPam algorithm that utilizes diffusion models for speeding up the
photoacoustic imaging process. Method: We leveraged a diffusion model trained
exclusively on natural images, comparing its performance with an in-domain
trained U-Net model using a dataset focused on PAM images of mice brain
microvasculature. Results: Our findings indicate that DiffPam achieves
comparable performance to a dedicated U-Net model, without the need for a large
dataset or training a deep learning model. The study also introduces the
efficacy of shortened diffusion processes for reducing computing time without
compromising accuracy. Conclusion: This study underscores the significance of
DiffPam as a practical algorithm for reconstructing undersampled PAM images,
particularly for researchers with limited AI expertise and computational
resources.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08856" title="Abstract">arXiv:2312.08856</a> (cross-list from eess.AS) [<a href="/pdf/2312.08856" title="Download PDF">pdf</a>, <a href="/format/2312.08856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Guided Adaptation for Code-Switching Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aditya%2C+B">Bobbi Aditya</a>, 
<a href="/search/eess?searchtype=author&query=Rohmatillah%2C+M">Mahdin Rohmatillah</a>, 
<a href="/search/eess?searchtype=author&query=Tai%2C+L">Liang-Hsuan Tai</a>, 
<a href="/search/eess?searchtype=author&query=Chien%2C+J">Jen-Tzung Chien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The prevalence of the powerful multilingual models, such as Whisper, has
significantly advanced the researches on speech recognition. However, these
models often struggle with handling the code-switching setting, which is
essential in multilingual speech recognition. Recent studies have attempted to
address this setting by separating the modules for different languages to
ensure distinct latent representations for languages. Some other methods
considered the switching mechanism based on language identification. In this
study, a new attention-guided adaptation is proposed to conduct
parameter-efficient learning for bilingual ASR. This method selects those
attention heads in a model which closely express language identities and then
guided those heads to be correctly attended with their corresponding languages.
The experiments on the Mandarin-English code-switching speech corpus show that
the proposed approach achieves a 14.2% mixed error rate, surpassing
state-of-the-art method, where only 5.6% additional parameters over Whisper are
trained.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08864" title="Abstract">arXiv:2312.08864</a> (cross-list from eess.IV) [<a href="/pdf/2312.08864" title="Download PDF">pdf</a>, <a href="/format/2312.08864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankDVQA-mini: Knowledge Distillation-Driven Deep Video Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/eess?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages and 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning-based video quality assessment (deep VQA) has demonstrated
significant potential in surpassing conventional metrics, with promising
improvements in terms of correlation with human perception. However, the
practical deployment of such deep VQA models is often limited due to their high
computational complexity and large memory requirements. To address this issue,
we aim to significantly reduce the model size and runtime of one of the
state-of-the-art deep VQA methods, RankDVQA, by employing a two-phase workflow
that integrates pruning-driven model compression with multi-level knowledge
distillation. The resulting lightweight quality metric, RankDVQA-mini, requires
less than 10% of the model parameters compared to its full version (14% in
terms of FLOPs), while still retaining a quality prediction performance that is
superior to most existing deep VQA methods. The source code of the
RankDVQA-mini has been released at
https://chenfeng-bristol.github.io/RankDVQA-mini/ for public evaluation.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08866" title="Abstract">arXiv:2312.08866</a> (cross-list from eess.IV) [<a href="/pdf/2312.08866" title="Download PDF">pdf</a>, <a href="/format/2312.08866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+H">Hao Shao</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Q">Quansheng Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jufeng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Efficiently capturing multi-scale information and building long-range
dependencies among pixels are essential for medical image segmentation because
of the various sizes and shapes of the lesion regions or organs. In this paper,
we present Multi-scale Cross-axis Attention (MCA) to solve the above
challenging issues based on the efficient axial attention. Instead of simply
connecting axial attention along the horizontal and vertical directions
sequentially, we propose to calculate dual cross attentions between two
parallel axial attentions to capture global information better. To process the
significant variations of lesion regions or organs in individual sizes and
shapes, we also use multiple convolutions of strip-shape kernels with different
kernel sizes in each axial attention path to improve the efficiency of the
proposed MCA in encoding spatial information. We build the proposed MCA upon
the MSCAN backbone, yielding our network, termed MCANet. Our MCANet with only
4M+ parameters performs even better than most previous works with heavy
backbones (e.g., Swin Transformer) on four challenging tasks, including skin
lesion segmentation, nuclei segmentation, abdominal multi-organ segmentation,
and polyp segmentation. Code is available at https:// github.com/ haoshao-nku/
medical seg.git.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08867" title="Abstract">arXiv:2312.08867</a> (cross-list from quant-ph) [<a href="/pdf/2312.08867" title="Download PDF">pdf</a>, <a href="/format/2312.08867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Digital Quantum Simulations in the Low-Energy Subspace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gong%2C+W">Weiyuan Gong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+S">Shuo Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+T">Tongyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures, github repo: <a href="https://github.com/Qubit-Fernand/Digital-Quantum-Simulation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Digital quantum simulation has broad applications in approximating unitary
evolutions of Hamiltonians. In practice, many simulation tasks for quantum
systems focus on quantum states in the low-energy subspace instead of the
entire Hilbert space. In this paper, we systematically investigate the
complexity of digital quantum simulation based on product formulas in the
low-energy subspace. We show that the simulation error depends on the effective
low-energy norm of the Hamiltonian for a variety of digital quantum simulation
algorithms and quantum systems, allowing improvements over the previous
complexities for full unitary simulations even for imperfect state
preparations. In particular, for simulating spin models in the low-energy
subspace, we prove that randomized product formulas such as qDRIFT and random
permutation require smaller step complexities. This improvement also persists
in symmetry-protected digital quantum simulations. We prove a similar
improvement in simulating the dynamics of power-law quantum interactions. We
also provide a query lower bound for general digital quantum simulations in the
low-energy subspace.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08911" title="Abstract">arXiv:2312.08911</a> (cross-list from math.CO) [<a href="/pdf/2312.08911" title="Download PDF">pdf</a>, <a href="/format/2312.08911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contributions to the Domino Problem: Seeding, Recurrence and  Satisfiability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bitar%2C+N">Nicol&#xe1;s Bitar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, Accepted to STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Dynamical Systems (math.DS); Group Theory (math.GR)

</div>
<p class="mathjax">We study the seeded domino problem, the recurring domino problem and the
$k$-SAT problem on finitely generated groups. These problems are generalization
of their original versions on $\mathbb{Z}^2$ that were shown to be undecidable
using the domino problem. We show that the seeded and recurring domino problems
on a group are invariant under changes in the generating set, are many-one
reduced from the respective problems on subgroups, and are positive equivalent
to the problems on finite index subgroups. This leads to showing that the
recurring domino problem is decidable for free groups. Coupled with the
invariance properties, we conjecture that the only groups in which the seeded
and recurring domino problems are decidable are virtually free groups. In the
case of the $k$-SAT problem, we introduce a new generalization that is
compatible with decision problems on finitely generated groups. We show that
the subgroup membership problem many-one reduces to the $2$-SAT problem, that
in certain cases the $k$-SAT problem many one reduces to the domino problem,
and finally that the domino problem reduces to $3$-SAT for the class of
scalable groups.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08915" title="Abstract">arXiv:2312.08915</a> (cross-list from eess.IV) [<a href="/pdf/2312.08915" title="Download PDF">pdf</a>, <a href="/format/2312.08915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Regularized Soft Introspective Variational Autoencoder for  Interpretable Cardiac Disease Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Folco%2C+M">Maxime Di Folco</a>, 
<a href="/search/eess?searchtype=author&query=Bercea%2C+C+I">Cosmin I. Bercea</a>, 
<a href="/search/eess?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Interpretability is essential in medical imaging to ensure that clinicians
can comprehend and trust artificial intelligence models. In this paper, we
propose a novel interpretable approach that combines attribute regularization
of the latent space within the framework of an adversarially trained
variational autoencoder. Comparative experiments on a cardiac MRI dataset
demonstrate the ability of the proposed method to address blurry reconstruction
issues of variational autoencoder methods and improve latent space
interpretability. Additionally, our analysis of a downstream task reveals that
the classification of cardiac disease using the regularized latent space
heavily relies on attribute regularized dimensions, demonstrating great
interpretability by connecting the used attributes for prediction with clinical
observations.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08927" title="Abstract">arXiv:2312.08927</a> (cross-list from q-fin.TR) [<a href="/pdf/2312.08927" title="Download PDF">pdf</a>, <a href="/format/2312.08927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limit Order Book Dynamics and Order Size Modelling Using Compound Hawkes  Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Jain%2C+K">Konark Jain</a>, 
<a href="/search/q-fin?searchtype=author&query=Firoozye%2C+N">Nick Firoozye</a>, 
<a href="/search/q-fin?searchtype=author&query=Kochems%2C+J">Jonathan Kochems</a>, 
<a href="/search/q-fin?searchtype=author&query=Treleaven%2C+P">Philip Treleaven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended abstract for the poster presented at the Market Microstructure workshop. The full paper will follow in the future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP); Applications (stat.AP)

</div>
<p class="mathjax">Hawkes Process has been used to model Limit Order Book (LOB) dynamics in
several ways in the literature however the focus has been limited to capturing
the inter-event times while the order size is usually assumed to be constant.
We propose a novel methodology of using Compound Hawkes Process for the LOB
where each event has an order size sampled from a calibrated distribution. The
process is formulated in a novel way such that the spread of the process always
remains positive. Further, we condition the model parameters on time of day to
support empirical observations. We make use of an enhanced non-parametric
method to calibrate the Hawkes kernels and allow for inhibitory
cross-excitation kernels. We showcase the results and quality of fits for an
equity stock's LOB in the NASDAQ exchange.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08940" title="Abstract">arXiv:2312.08940</a> (cross-list from math.OC) [<a href="/pdf/2312.08940" title="Download PDF">pdf</a>, <a href="/format/2312.08940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Decomposition Method for the Hybrid Quantum-Classical Solution of the  Number Partitioning Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zongji Li</a>, 
<a href="/search/math?searchtype=author&query=Seidel%2C+T">Tobias Seidel</a>, 
<a href="/search/math?searchtype=author&query=Bortz%2C+M">Michael Bortz</a>, 
<a href="/search/math?searchtype=author&query=Heese%2C+R">Raoul Heese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Current quantum computers can only solve optimization problems of a very
limited size. For larger problems, decomposition methods are required in which
the original problem is broken down into several smaller sub-problems. These
are then solved on the quantum computer and their solutions are merged into a
final solution for the original problem. Often, these decomposition methods do
not take the specific problem structure into account. In this paper, we present
a tailored method using a divide-and-conquer strategy to solve the number
partitioning problem (NPP) with a large number of variables. The idea is to
perform a specialized decomposition into smaller NPPs, which can be solved on a
quantum computer, and then recombine the results into another small auxiliary
NPP. Solving this auxiliary problem yields an approximate solution of the
original larger problem. We experimentally verify that our method allows to
solve NPPs with over a thousand variables using a D-Wave quantum annealer.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08998" title="Abstract">arXiv:2312.08998</a> (cross-list from eess.AS) [<a href="/pdf/2312.08998" title="Download PDF">pdf</a>, <a href="/ps/2312.08998" title="Download PostScript">ps</a>, <a href="/format/2312.08998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design, construction and evaluation of emotional multimodal pathological  speech database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+S">Shufei Duan</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+H">Huizhi Liang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">The lack of an available emotion pathology database is one of the key
obstacles in studying the emotion expression status of patients with
dysarthria. The first Chinese multimodal emotional pathological speech database
containing multi-perspective information is constructed in this paper. It
includes 29 controls and 39 patients with different degrees of motor
dysarthria, expressing happy, sad, angry and neutral emotions. All emotional
speech was labeled for intelligibility, types and discrete dimensional emotions
by developed WeChat mini-program. The subjective analysis justifies from
emotion discrimination accuracy, speech intelligibility, valence-arousal
spatial distribution, and correlation between SCL-90 and disease severity. The
automatic recognition tested on speech and glottal data, with average accuracy
of 78% for controls and 60% for patients in audio, while 51% for controls and
38% for patients in glottal data, indicating an influence of the disease on
emotional expression.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09004" title="Abstract">arXiv:2312.09004</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.09004" title="Download PDF">pdf</a>, <a href="/format/2312.09004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic chemical evaluation reveals pitfalls in reaction prediction  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gil%2C+V+S">Victor Sabanza Gil</a>, 
<a href="/search/physics?searchtype=author&query=Bran%2C+A+M">Andres M. Bran</a>, 
<a href="/search/physics?searchtype=author&query=Franke%2C+M">Malte Franke</a>, 
<a href="/search/physics?searchtype=author&query=Schlama%2C+R">Remi Schlama</a>, 
<a href="/search/physics?searchtype=author&query=Luterbacher%2C+J+S">Jeremy S. Luterbacher</a>, 
<a href="/search/physics?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The prediction of chemical reactions has gained significant interest within
the machine learning community in recent years, owing to its complexity and
crucial applications in chemistry. However, model evaluation for this task has
been mostly limited to simple metrics like top-k accuracy, which obfuscates
fine details of a model's limitations. Inspired by progress in other fields, we
propose a new assessment scheme that builds on top of current approaches,
steering towards a more holistic evaluation. We introduce the following key
components for this goal: CHORISO, a curated dataset along with multiple
tailored splits to recreate chemically relevant scenarios, and a collection of
metrics that provide a holistic view of a model's advantages and limitations.
Application of this method to state-of-the-art models reveals important
differences on sensitive fronts, especially stereoselectivity and chemical
out-of-distribution generalization. Our work paves the way towards robust
prediction models that can ultimately accelerate chemical discovery.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09022" title="Abstract">arXiv:2312.09022</a> (cross-list from eess.IV) [<a href="/pdf/2312.09022" title="Download PDF">pdf</a>, <a href="/format/2312.09022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Diffuser with Hierarchical Transformer for MCI Causality Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zuo%2C+Q">Qiankun Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Effective connectivity estimation plays a crucial role in understanding the
interactions and information flow between different brain regions. However, the
functional time series used for estimating effective connentivity is derived
from certain software, which may lead to large computing errors because of
different parameter settings and degrade the ability to model complex causal
relationships between brain regions. In this paper, a brain diffuser with
hierarchical transformer (BDHT) is proposed to estimate effective connectivity
for mild cognitive impairment (MCI) analysis. To our best knowledge, the
proposed brain diffuer is the first generative model to apply diffusion models
in the application of generating and analyzing multimodal brain networks.
Specifically, the BDHT leverages the structural connectivity to guide the
reverse processes in an efficient way. It makes the denoising process more
reliable and guarantees effective connectivity estimation accuracy. To improve
denoising quality, the hierarchical denoising transformer is designed to learn
multi-scale features in topological space. Furthermore, the GraphConFormer
block can concentrate on both global and adjacent connectivity information. By
stacking the multi-head attention and graph convolutional network, the proposed
model enhances structure-function complementarity and improves the ability in
noise estimation. Experimental evaluations of the denoising diffusion model
demonstrate its effectiveness in estimating effective connectivity. The method
achieves superior performance in terms of accuracy and robustness compared to
existing approaches. It can captures both unidirectal and bidirectional
interactions between brain regions, providing a comprehensive understanding of
the brain's information processing mechanisms.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09029" title="Abstract">arXiv:2312.09029</a> (cross-list from math.FA) [<a href="/pdf/2312.09029" title="Download PDF">pdf</a>, <a href="/ps/2312.09029" title="Download PostScript">ps</a>, <a href="/format/2312.09029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some points of view on Grothendieck&#x27;s inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christensen%2C+E">Erik Christensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Operator Algebras (math.OA)

</div>
<p class="mathjax">Haagerup's proof of the non commutative little Grothendieck inequality raises
some questions on the commutative little inequality, and it offers a new result
on scalar matrices with non negative entries. The theory of completely bounded
maps implies that the commutative Grothendieck inequality follows from the
little commutative inequality, and that this passage may be given a geometric
form as a relation between a pair of compact convex sets of positive matrices,
which, in turn, characterizes the little constant in the complex case.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09034" title="Abstract">arXiv:2312.09034</a> (cross-list from eess.AS) [<a href="/pdf/2312.09034" title="Download PDF">pdf</a>, <a href="/format/2312.09034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion of Audio and Visual Embeddings for Sound Event Localization and  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Berghi%2C+D">Davide Berghi</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+P">Peipei Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Jinzheng Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jackson%2C+P+J+B">Philip J. B. Jackson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Sound event localization and detection (SELD) combines two subtasks: sound
event detection (SED) and direction of arrival (DOA) estimation. SELD is
usually tackled as an audio-only problem, but visual information has been
recently included. Few audio-visual (AV)-SELD works have been published and
most employ vision via face/object bounding boxes, or human pose keypoints. In
contrast, we explore the integration of audio and visual feature embeddings
extracted with pre-trained deep networks. For the visual modality, we tested
ResNet50 and Inflated 3D ConvNet (I3D). Our comparison of AV fusion methods
includes the AV-Conformer and Cross-Modal Attentive Fusion (CMAF) model. Our
best models outperform the DCASE 2023 Task3 audio-only and AV baselines by a
wide margin on the development set of the STARSS23 dataset, making them
competitive amongst state-of-the-art results of the AV challenge, without model
ensembling, heavy data augmentation, or prediction post-processing. Such
techniques and further pre-training could be applied as next steps to improve
performance.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09061" title="Abstract">arXiv:2312.09061</a> (cross-list from stat.ML) [<a href="/pdf/2312.09061" title="Download PDF">pdf</a>, <a href="/format/2312.09061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Clustering: A Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bayer%2C+F">Fritz Bayer</a>, 
<a href="/search/stat?searchtype=author&query=Plecko%2C+D">Drago Plecko</a>, 
<a href="/search/stat?searchtype=author&query=Beerenwinkel%2C+N">Niko Beerenwinkel</a>, 
<a href="/search/stat?searchtype=author&query=Kuipers%2C+J">Jack Kuipers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Clustering algorithms may unintentionally propagate or intensify existing
disparities, leading to unfair representations or biased decision-making.
Current fair clustering methods rely on notions of fairness that do not capture
any information on the underlying causal mechanisms. We show that optimising
for non-causal fairness notions can paradoxically induce direct discriminatory
effects from a causal standpoint. We present a clustering approach that
incorporates causal fairness metrics to provide a more nuanced approach to
fairness in unsupervised learning. Our approach enables the specification of
the causal fairness metrics that should be minimised. We demonstrate the
efficacy of our methodology using datasets known to harbour unfair biases.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09063" title="Abstract">arXiv:2312.09063</a> (cross-list from eess.IV) [<a href="/pdf/2312.09063" title="Download PDF">pdf</a>, <a href="/format/2312.09063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Demoireing in RAW and sRGB Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+S">Shuning Xu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+B">Binbin Song</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Moir\'e patterns frequently appear when capturing screens with smartphones or
cameras, potentially compromising image quality. Previous studies suggest that
moir\'e pattern elimination in the RAW domain offers greater efficiency
compared to demoir\'eing in the sRGB domain. Nevertheless, relying solely on
raw data for image demoir\'eing is insufficient in mitigating color cast due to
the absence of essential information required for color correction by the Image
Signal Processor (ISP). In this paper, we propose perform Image Demoir\'eing
concurrently utilizing both RAW and sRGB data (RRID), which is readily
accessible in both smartphones and digital cameras. We develop
Skip-Connection-based Demoir\'eing Module (SCDM) with specific modules embeded
in skip-connections for the efficient and effective demoir\'eing of RAW and
sRGB features, respectively. Subsequently, we propose RGB Guided Image Signal
Processor (RGISP) to incorporate color information from coarsely demoir\'ed
sRGB features during the ISP stage, assisting the process of color recovery.
Extensive experiments demonstrate that our RRID outperforms state-of-the-art
approaches by 0.62dB in PSNR and 0.003 in SSIM, exhibiting superior performance
both in moir\'e pattern removal and color cast correction.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09072" title="Abstract">arXiv:2312.09072</a> (cross-list from quant-ph) [<a href="/pdf/2312.09072" title="Download PDF">pdf</a>, <a href="/format/2312.09072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On variants of multivariate quantum signal processing and their  characterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=N%C3%A9meth%2C+B">Bal&#xe1;zs N&#xe9;meth</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6v%C3%A9r%2C+B">Blanka K&#xf6;v&#xe9;r</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kulcs%C3%A1r%2C+B">Bogl&#xe1;rka Kulcs&#xe1;r</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mikl%C3%B3si%2C+R+B">Roland Botond Mikl&#xf3;si</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gily%C3%A9n%2C+A">Andr&#xe1;s Gily&#xe9;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY); Algebraic Geometry (math.AG); Complex Variables (math.CV)

</div>
<p class="mathjax">Quantum signal processing (QSP) is a highly successful algorithmic primitive
in quantum computing which leads to conceptually simple and efficient quantum
algorithms using the block-encoding framework of quantum linear algebra.
Multivariate variants of quantum signal processing (MQSP) could be a valuable
tool in extending earlier results via implementing multivariate (matrix)
polynomials. However, MQSP remains much less understood than its single-variate
version lacking a clear characterization of "achievable" multivariate
polynomials. We show that Haah's characterization of general univariate QSP can
be extended to homogeneous bivariate (commuting) quantum signal processing. We
also show a similar result for an alternative inhomogeneous variant when the
degree in one of the variables is at most 1, but construct a counterexample
where both variables have degree 2, which in turn refutes an earlier
characterization proposed / conjectured by Rossi and Chuang for a related
restricted class of MQSP. Finally, we describe homogeneous multivariate
(non-commuting) QSP variants that break away from the earlier two-dimensional
treatment limited by its reliance on Jordan-like decompositions, and might
ultimately lead to the development of novel quantum algorithms.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09083" title="Abstract">arXiv:2312.09083</a> (cross-list from math.OC) [<a href="/pdf/2312.09083" title="Download PDF">pdf</a>, <a href="/ps/2312.09083" title="Download PostScript">ps</a>, <a href="/format/2312.09083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Linear Ensemble Systems and Structural Averaged Controllability:  Single-input Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+X">Xudong Chen</a>, 
<a href="/search/math?searchtype=author&query=Gharesifard%2C+B">Bahman Gharesifard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider continuum ensembles of linear time-invariant control systems with
single inputs. A sparsity pattern is said to be structurally averaged
controllability if it admits an averaged controllable linear ensemble system.
We provide a necessary and sufficient condition for a sparsity pattern to be
structurally averaged controllable.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09100" title="Abstract">arXiv:2312.09100</a> (cross-list from eess.AS) [<a href="/pdf/2312.09100" title="Download PDF">pdf</a>, <a href="/format/2312.09100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastInject: Injecting Unpaired Text Data into CTC-based ASR training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+K">Keqi Deng</a>, 
<a href="/search/eess?searchtype=author&query=Woodland%2C+P+C">Philip C. Woodland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Recently, connectionist temporal classification (CTC)-based end-to-end (E2E)
automatic speech recognition (ASR) models have achieved impressive results,
especially with the development of self-supervised learning. However, E2E ASR
models trained on paired speech-text data often suffer from domain shifts from
training to testing. To alleviate this issue, this paper proposes a flat-start
joint training method, named FastInject, which efficiently injects multi-domain
unpaired text data into CTC-based ASR training. To maintain training
efficiency, text units are pre-upsampled, and their representations are fed
into the CTC model along with speech features. To bridge the modality gap
between speech and text, an attention-based modality matching mechanism (AM3)
is proposed, which retains the E2E flat-start training. Experiments show that
the proposed FastInject gave a 22\% relative WER reduction (WERR) for
intra-domain Librispeech-100h data and 20\% relative WERR on out-of-domain test
sets.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09121" title="Abstract">arXiv:2312.09121</a> (cross-list from quant-ph) [<a href="/pdf/2312.09121" title="Download PDF">pdf</a>, <a href="/format/2312.09121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does provable absence of barren plateaus imply classical simulability?  Or, why we need to rethink variational quantum computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cerezo%2C+M">M. Cerezo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Larocca%2C+M">Martin Larocca</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa-Mart%C3%ADn%2C+D">Diego Garc&#xed;a-Mart&#xed;n</a>, 
<a href="/search/quant-ph?searchtype=author&query=Diaz%2C+N+L">N. L. Diaz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Braccia%2C+P">Paolo Braccia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fontana%2C+E">Enrico Fontana</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rudolph%2C+M+S">Manuel S. Rudolph</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bermejo%2C+P">Pablo Bermejo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ijaz%2C+A">Aroosa Ijaz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thanasilp%2C+S">Supanut Thanasilp</a>, 
<a href="/search/quant-ph?searchtype=author&query=Anschuetz%2C+E+R">Eric R. Anschuetz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Holmes%2C+Z">Zo&#xeb; Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14+15 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">A large amount of effort has recently been put into understanding the barren
plateau phenomenon. In this perspective article, we face the increasingly loud
elephant in the room and ask a question that has been hinted at by many but not
explicitly addressed: Can the structure that allows one to avoid barren
plateaus also be leveraged to efficiently simulate the loss classically? We
present strong evidence that commonly used models with provable absence of
barren plateaus are also classically simulable, provided that one can collect
some classical data from quantum devices during an initial data acquisition
phase. This follows from the observation that barren plateaus result from a
curse of dimensionality, and that current approaches for solving them end up
encoding the problem into some small, classically simulable, subspaces. This
sheds serious doubt on the non-classicality of the information processing
capabilities of parametrized quantum circuits for barren plateau-free
landscapes and on the possibility of superpolynomial advantages from running
them on quantum hardware. We end by discussing caveats in our arguments, the
role of smart initializations, and by highlighting new opportunities that our
perspective raises.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09131" title="Abstract">arXiv:2312.09131</a> (cross-list from math.OC) [<a href="/pdf/2312.09131" title="Download PDF">pdf</a>, <a href="/format/2312.09131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Network Lyapunov Functions: PDE  Characterization, Learning, and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+Y">Yiming Meng</a>, 
<a href="/search/math?searchtype=author&query=Fitzsimmons%2C+M">Maxwell Fitzsimmons</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+R">Ruikun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We provide a systematic investigation of using physics-informed neural
networks to compute Lyapunov functions. We encode Lyapunov conditions as a
partial differential equation (PDE) and use this for training neural network
Lyapunov functions. We analyze the analytical properties of the solutions to
the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov
equation in training neural Lyapunov functions can lead to approximate regions
of attraction close to the true domain of attraction. We then provide
sufficient conditions for the learned neural Lyapunov functions that can be
readily verified by satisfiability modulo theories (SMT) solvers, enabling
formal verification of both local stability analysis and region-of-attraction
estimates in the large. Through a number of nonlinear examples, ranging from
low to high dimensions, we demonstrate that the proposed framework can
outperform traditional sums-of-squares (SOS) Lyapunov functions obtained using
semidefinite programming (SDP).
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09174" title="Abstract">arXiv:2312.09174</a> (cross-list from quant-ph) [<a href="/pdf/2312.09174" title="Download PDF">pdf</a>, <a href="/format/2312.09174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Quantum Anomaly Detection: One-Class SVMs using  Variable Subsampling and Randomized Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ahouzi%2C+A">Afrae Ahouzi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Debus%2C+P">Pascal Debus</a>, 
<a href="/search/quant-ph?searchtype=author&query=M%C3%BCller%2C+R">Robert M&#xfc;ller</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schuman%2C+D">Danielle Schuman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing, with its potential to enhance various machine learning
tasks, allows significant advancements in kernel calculation and model
precision. Utilizing the one-class Support Vector Machine alongside a quantum
kernel, known for its classically challenging representational capacity,
notable improvements in average precision compared to classical counterparts
were observed in previous studies. Conventional calculations of these kernels,
however, present a quadratic time complexity concerning data size, posing
challenges in practical applications. To mitigate this, we explore two distinct
approaches: utilizing randomized measurements to evaluate the quantum kernel
and implementing the variable subsampling ensemble method, both targeting
linear time complexity. Experimental results demonstrate a substantial
reduction in training and inference times by up to 95\% and 25\% respectively,
employing these methods. Although unstable, the average precision of randomized
measurements discernibly surpasses that of the classical Radial Basis Function
kernel, suggesting a promising direction for further research in scalable,
efficient quantum computing applications in machine learning.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09176" title="Abstract">arXiv:2312.09176</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.09176" title="Download PDF">pdf</a>, <a href="/format/2312.09176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of Fields from Sparse Sensing: Differentiable Sensor  Placement Enhances Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Marcato%2C+A">Agnese Marcato</a>, 
<a href="/search/physics?searchtype=author&query=O%27Malley%2C+D">Daniel O&#x27;Malley</a>, 
<a href="/search/physics?searchtype=author&query=Viswanathan%2C+H">Hari Viswanathan</a>, 
<a href="/search/physics?searchtype=author&query=Guiltinan%2C+E">Eric Guiltinan</a>, 
<a href="/search/physics?searchtype=author&query=Santos%2C+J+E">Javier E. Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recreating complex, high-dimensional global fields from limited data points
is a grand challenge across various scientific and industrial domains. Given
the prohibitive costs of specialized sensors and the frequent inaccessibility
of certain regions of the domain, achieving full field coverage is typically
not feasible. Therefore, the development of algorithms that intelligently
improve sensor placement is of significant value. In this study, we introduce a
general approach that employs differentiable programming to exploit sensor
placement within the training of a neural network model in order to improve
field reconstruction. We evaluated our method using two distinct datasets; the
results show that our approach improved test scores. Ultimately, our method of
differentiable placement strategies has the potential to significantly increase
data collection efficiency, enable more thorough area coverage, and reduce
redundancy in sensor deployment.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09206" title="Abstract">arXiv:2312.09206</a> (cross-list from quant-ph) [<a href="/pdf/2312.09206" title="Download PDF">pdf</a>, <a href="/ps/2312.09206" title="Download PostScript">ps</a>, <a href="/format/2312.09206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandomness from Subset States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Giurgica-Tiron%2C+T">Tudor Giurgica-Tiron</a> (Stanford University), 
<a href="/search/quant-ph?searchtype=author&query=Bouland%2C+A">Adam Bouland</a> (Stanford University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We show it is possible to obtain quantum pseudorandomness and
pseudoentanglement from random subset states -- i.e. quantum states which are
equal superpositions over (pseudo)random subsets of strings. This answers an
open question of Aaronson et al. [<a href="/abs/2211.00747">arXiv:2211.00747</a>], who devised a similar
construction augmented by pseudorandom phases. Our result follows from a direct
calculation of the trace distance between $t$ copies of random subset states
and the Haar measure, via the representation theory of the symmetric group. We
show that the trace distance is negligibly small, as long as the subsets are of
an appropriate size which is neither too big nor too small. In particular, we
analyze the action of basis permutations on the symmetric subspace, and show
that the largest component is described by the Johnson scheme: the
double-cosets of the symmetric group $\mathbb{S}_N$ by the subgroup
$\mathbb{S}_t \times \mathbb{S}_{N-t}$. The Gelfand pair property of this
setting implies that the matrix eigenbasis coincides with the symmetric group
irreducible blocks, with the largest eigenblock asymptotically approaching the
Haar average. An immediate corollary of our result is that quantum pseudorandom
and pseudoentangled state ensembles do not require relative phases.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09209" title="Abstract">arXiv:2312.09209</a> (cross-list from quant-ph) [<a href="/pdf/2312.09209" title="Download PDF">pdf</a>, <a href="/format/2312.09209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A colossal advantage: 3D-local noisy shallow quantum circuits defeat  unbounded fan-in classical circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Caha%2C+L">Libor Caha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Coiteux-Roy%2C+X">Xavier Coiteux-Roy</a>, 
<a href="/search/quant-ph?searchtype=author&query=Koenig%2C+R">Robert Koenig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We present a computational problem with the following properties: (i) Every
instance can be solved with near-certainty by a constant-depth quantum circuit
using only nearest-neighbor gates in 3D even when its implementation is
corrupted by noise. (ii) Any constant-depth classical circuit composed of
unbounded fan-in AND, OR, as well as NOT gates, i.e., an AC0-circuit, of size
smaller than a certain subexponential, fails to solve a uniformly random
instance with probability greater than a certain constant. Such an advantage
against unbounded fan-in classical circuits was previously only known in the
noise-free case or without locality constraints. We overcome these limitations,
proposing a quantum advantage demonstration amenable to experimental
realizations. Subexponential circuit-complexity lower bounds have traditionally
been referred to as exponential. We use the term colossal since our
fault-tolerant 3D architecture resembles a certain Roman monument.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09215" title="Abstract">arXiv:2312.09215</a> (cross-list from quant-ph) [<a href="/pdf/2312.09215" title="Download PDF">pdf</a>, <a href="/format/2312.09215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Quantum Machine Learning for Solving Partial  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Setty%2C+A">Abhishek Setty</a>, 
<a href="/search/quant-ph?searchtype=author&query=Abdusalamov%2C+R">Rasul Abdusalamov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Itskov%2C+M">Mikhail Itskov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we solve differential equations using quantum Chebyshev feature
maps. We propose a tensor product over a summation of Pauli-Z operators as a
change in the measurement observables resulting in improved accuracy and
reduced computation time for initial value problems processed by floating
boundary handling. This idea has been tested on solving the complex dynamics of
a Riccati equation as well as on a system of differential equations.
Furthermore, a second-order differential equation is investigated in which we
propose adding entangling layers to improve accuracy without increasing the
variational parameters. Additionally, a modified self-adaptivity approach of
physics-informed neural networks is incorporated to balance the multi-objective
loss function. Finally, a new quantum circuit structure is proposed to
approximate multivariable functions, tested on solving a 2D Poisson's equation.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09224" title="Abstract">arXiv:2312.09224</a> (cross-list from math.CO) [<a href="/pdf/2312.09224" title="Download PDF">pdf</a>, <a href="/format/2312.09224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shannon capacity, Lov&#xe1;sz theta number and the Mycielski construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Csonka%2C+B">Bence Csonka</a>, 
<a href="/search/math?searchtype=author&query=Simonyi%2C+G">G&#xe1;bor Simonyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages plus appendices, one figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We investigate the effect of the well-known Mycielski construction on the
Shannon capacity of graphs and on one of its most prominent upper bounds, the
(complementary) Lov\'asz theta number. We prove that if the Shannon capacity of
a graph, the distinguishability graph of a noisy channel, is attained by some
finite power, then its Mycielskian has strictly larger Shannon capacity than
the graph itself. For the complementary Lov\'asz theta function we show that
its value on the Mycielskian of a graph is completely determined by its value
on the original graph, a phenomenon similar to the one discovered for the
fractional chromatic number by Larsen, Propp and Ullman. We also consider the
possibility of generalizing our results on the Sperner capacity of directed
graphs and on the generalized Mycielsky construction. Possible connections with
what Zuiddam calls the asymptotic spectrum of graphs are discussed as well.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 15 Dec 23</h3>
<dl>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.14159" title="Abstract">arXiv:2011.14159</a> (replaced) [<a href="/pdf/2011.14159" title="Download PDF">pdf</a>, <a href="/format/2011.14159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adamastor: a New Low Latency and Scalable Decentralized Anonymous  Payment System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morais%2C+R">Rui Morais</a>, 
<a href="/search/cs?searchtype=author&query=Crocker%2C+P">Paul Crocker</a>, 
<a href="/search/cs?searchtype=author&query=de+Sousa%2C+S+M">Simao Melo de Sousa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.02312" title="Abstract">arXiv:2101.02312</a> (replaced) [<a href="/pdf/2101.02312" title="Download PDF">pdf</a>, <a href="/format/2101.02312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4 vs 7 sparse undirected unweighted Diameter is SETH-hard at time  $n^{4/3}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+%C3%89">&#xc9;douard Bonnet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.00640" title="Abstract">arXiv:2104.00640</a> (replaced) [<a href="/pdf/2104.00640" title="Download PDF">pdf</a>, <a href="/format/2104.00640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmbiFC: Fact-Checking Ambiguous Claims with Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glockner%2C+M">Max Glockner</a>, 
<a href="/search/cs?searchtype=author&query=Stali%C5%ABnait%C4%97%2C+I">Ieva Stali&#x16b;nait&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Thorne%2C+J">James Thorne</a>, 
<a href="/search/cs?searchtype=author&query=Vallejo%2C+G">Gisela Vallejo</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TACL; pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.11893" title="Abstract">arXiv:2104.11893</a> (replaced) [<a href="/pdf/2104.11893" title="Download PDF">pdf</a>, <a href="/format/2104.11893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LGD-GCN: Local and Global Disentangled Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> add additinal code and paper links
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.05300" title="Abstract">arXiv:2109.05300</a> (replaced) [<a href="/pdf/2109.05300" title="Download PDF">pdf</a>, <a href="/ps/2109.05300" title="Download PostScript">ps</a>, <a href="/format/2109.05300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On syntactically similar logic programs and sequential decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antic%2C+C">Christian Antic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1809.09938">arXiv:1809.09938</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.00944" title="Abstract">arXiv:2111.00944</a> (replaced) [<a href="/pdf/2111.00944" title="Download PDF">pdf</a>, <a href="/format/2111.00944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piezoelectric Soft Robot Inchworm Motion by Tuning Ground Friction  through Robot Shape: Quasi-Static Modeling and Experimental Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhiwu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Prakhar Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yenan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hsin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S">Sigurd Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+N">Naveen Verma</a>, 
<a href="/search/cs?searchtype=author&query=Sturm%2C+J+C">James C. Sturm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.04720" title="Abstract">arXiv:2112.04720</a> (replaced) [<a href="/pdf/2112.04720" title="Download PDF">pdf</a>, <a href="/format/2112.04720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amicable Aid: Perturbing Images to Improve Classification Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juyeop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jun-Ho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+S">Soobeom Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-Seok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.04678" title="Abstract">arXiv:2201.04678</a> (replaced) [<a href="/pdf/2201.04678" title="Download PDF">pdf</a>, <a href="/ps/2201.04678" title="Download PostScript">ps</a>, <a href="/format/2201.04678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Turing Compressions for Some Graph Problems Parameterized by  Modular-Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weidong Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.13108" title="Abstract">arXiv:2201.13108</a> (replaced) [<a href="/pdf/2201.13108" title="Download PDF">pdf</a>, <a href="/format/2201.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDS multi-twisted Reed-Solomon codes with small dimensional hull
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harshdeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Meena%2C+K+C">Kapish Chand Meena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in Cryptography and Communications (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01793" title="Abstract">arXiv:2204.01793</a> (replaced) [<a href="/pdf/2204.01793" title="Download PDF">pdf</a>, <a href="/ps/2204.01793" title="Download PostScript">ps</a>, <a href="/format/2204.01793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using random graphs to sample repulsive Gibbs point processes with  arbitrary-range potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+T">Tobias Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6bel%2C+A">Andreas G&#xf6;bel</a>, 
<a href="/search/cs?searchtype=author&query=Katzmann%2C+M">Maximilian Katzmann</a>, 
<a href="/search/cs?searchtype=author&query=Krejca%2C+M">Martin Krejca</a>, 
<a href="/search/cs?searchtype=author&query=Pappik%2C+M">Marcus Pappik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10789" title="Abstract">arXiv:2204.10789</a> (replaced) [<a href="/pdf/2204.10789" title="Download PDF">pdf</a>, <a href="/ps/2204.10789" title="Download PostScript">ps</a>, <a href="/format/2204.10789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Locally Tight Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fandinno%2C+J">Jorge Fandinno</a>, 
<a href="/search/cs?searchtype=author&query=Lifschitz%2C+V">Vladimir Lifschitz</a>, 
<a href="/search/cs?searchtype=author&query=Temple%2C+N">Nathan Temple</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration for publication in Theory and Practice of Logic Programming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10083" title="Abstract">arXiv:2205.10083</a> (replaced) [<a href="/pdf/2205.10083" title="Download PDF">pdf</a>, <a href="/format/2205.10083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Experiment Design Approach for Cyclic and Acyclic Causal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mokhtarian%2C+E">Ehsan Mokhtarian</a>, 
<a href="/search/cs?searchtype=author&query=Salehkaleybar%2C+S">Saber Salehkaleybar</a>, 
<a href="/search/cs?searchtype=author&query=Ghassami%2C+A">AmirEmad Ghassami</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 6 figures, 1 table, accepted in JMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10347" title="Abstract">arXiv:2205.10347</a> (replaced) [<a href="/pdf/2205.10347" title="Download PDF">pdf</a>, <a href="/format/2205.10347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse super-resolution with pretrained deep hiererarchical VAEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prost%2C+J">Jean Prost</a>, 
<a href="/search/cs?searchtype=author&query=Houdard%2C+A">Antoine Houdard</a>, 
<a href="/search/cs?searchtype=author&query=Almansa%2C+A">Andr&#xe9;s Almansa</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+N">Nicolas Papadakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages , 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14683" title="Abstract">arXiv:2205.14683</a> (replaced) [<a href="/pdf/2205.14683" title="Download PDF">pdf</a>, <a href="/format/2205.14683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact of memory on learning sequence-to-sequence tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seif%2C+A">Alireza Seif</a>, 
<a href="/search/cs?searchtype=author&query=Loos%2C+S+A+M">Sarah A.M. Loos</a>, 
<a href="/search/cs?searchtype=author&query=Tucci%2C+G">Gennaro Tucci</a>, 
<a href="/search/cs?searchtype=author&query=Rold%C3%A1n%2C+%C3%89">&#xc9;dgar Rold&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Goldt%2C+S">Sebastian Goldt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code to reproduce our experiments available at <a href="https://github.com/alirezaseif/nonmarkovian_learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00560" title="Abstract">arXiv:2206.00560</a> (replaced) [<a href="/pdf/2206.00560" title="Download PDF">pdf</a>, <a href="/format/2206.00560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning common structures in a collection of networks. An application  to food webs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chabert-Liddell%2C+S">Saint-Clair Chabert-Liddell</a>, 
<a href="/search/stat?searchtype=author&query=Barbillon%2C+P">Pierre Barbillon</a>, 
<a href="/search/stat?searchtype=author&query=Donnet%2C+S">Sophie Donnet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Annals of Applied Statistics (2023-09-28)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Social and Information Networks (cs.SI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03538" title="Abstract">arXiv:2206.03538</a> (replaced) [<a href="/pdf/2206.03538" title="Download PDF">pdf</a>, <a href="/format/2206.03538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WIDESim: A toolkit for simulating resource management techniques of  scientific Workflows In Distributed Environments with graph topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rayej%2C+M+A">Mohammad Amin Rayej</a>, 
<a href="/search/cs?searchtype=author&query=Siar%2C+H">Hajar Siar</a>, 
<a href="/search/cs?searchtype=author&query=Hamzei%2C+A">Ahmadreza Hamzei</a>, 
<a href="/search/cs?searchtype=author&query=Yazdi%2C+M+S+M">Mohammad Sadegh Majidi Yazdi</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadian%2C+P">Parsa Mohammadian</a>, 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Mohammad Izadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05575" title="Abstract">arXiv:2206.05575</a> (replaced) [<a href="/pdf/2206.05575" title="Download PDF">pdf</a>, <a href="/ps/2206.05575" title="Download PostScript">ps</a>, <a href="/format/2206.05575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MammoFL: Mammographic Breast Density Estimation using Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muthukrishnan%2C+R">Ramya Muthukrishnan</a>, 
<a href="/search/eess?searchtype=author&query=Heyler%2C+A">Angelina Heyler</a>, 
<a href="/search/eess?searchtype=author&query=Katti%2C+K">Keshava Katti</a>, 
<a href="/search/eess?searchtype=author&query=Pati%2C+S">Sarthak Pati</a>, 
<a href="/search/eess?searchtype=author&query=Mankowski%2C+W">Walter Mankowski</a>, 
<a href="/search/eess?searchtype=author&query=Alahari%2C+A">Aprupa Alahari</a>, 
<a href="/search/eess?searchtype=author&query=Sanborn%2C+M">Michael Sanborn</a>, 
<a href="/search/eess?searchtype=author&query=Conant%2C+E+F">Emily F. Conant</a>, 
<a href="/search/eess?searchtype=author&query=Scott%2C+C">Christopher Scott</a>, 
<a href="/search/eess?searchtype=author&query=Winham%2C+S">Stacey Winham</a>, 
<a href="/search/eess?searchtype=author&query=Vachon%2C+C">Celine Vachon</a>, 
<a href="/search/eess?searchtype=author&query=Chaudhari%2C+P">Pratik Chaudhari</a>, 
<a href="/search/eess?searchtype=author&query=Kontos%2C+D">Despina Kontos</a>, 
<a href="/search/eess?searchtype=author&query=Bakas%2C+S">Spyridon Bakas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Deep learning, federated learning, mammography, breast density, risk assessment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07207" title="Abstract">arXiv:2206.07207</a> (replaced) [<a href="/pdf/2206.07207" title="Download PDF">pdf</a>, <a href="/format/2206.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Grounding: Extracting Fine-Grained Event Hierarchies Across  Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayyubi%2C+H+A">Hammad A. Ayyubi</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C">Christopher Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Chum%2C+L">Lovish Chum</a>, 
<a href="/search/cs?searchtype=author&query=Lokesh%2C+R">Rahul Lokesh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yulei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xuande Feng</a>, 
<a href="/search/cs?searchtype=author&query=Koo%2C+J">Jaywon Koo</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+S">Sounak Ray</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09753" title="Abstract">arXiv:2206.09753</a> (replaced) [<a href="/pdf/2206.09753" title="Download PDF">pdf</a>, <a href="/format/2206.09753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing and Understanding Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sammani%2C+F">Fawaz Sammani</a>, 
<a href="/search/cs?searchtype=author&query=Joukovsky%2C+B">Boris Joukovsky</a>, 
<a href="/search/cs?searchtype=author&query=Deligiannis%2C+N">Nikos Deligiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Image Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11792" title="Abstract">arXiv:2206.11792</a> (replaced) [<a href="/pdf/2206.11792" title="Download PDF">pdf</a>, <a href="/format/2206.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nucl-ex?searchtype=author&query=Dembski%2C+C">Cade Dembski</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Kuchera%2C+M+P">Michelle P. Kuchera</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Liddick%2C+S">Sean Liddick</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Ramanujan%2C+R">Raghu Ramanujan</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Spyrou%2C+A">Artemis Spyrou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Nuclear Experiment (nucl-ex)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13444" title="Abstract">arXiv:2206.13444</a> (replaced) [<a href="/pdf/2206.13444" title="Download PDF">pdf</a>, <a href="/format/2206.13444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zenix: Efficient Execution of Bulky Serverless Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhiyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+Z">Zachary Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinmou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zerui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bili Dong</a>, 
<a href="/search/cs?searchtype=author&query=Pota%2C+I">Ishaan Pota</a>, 
<a href="/search/cs?searchtype=author&query=Shahrad%2C+M">Mohammad Shahrad</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Harry Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiying Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01795" title="Abstract">arXiv:2208.01795</a> (replaced) [<a href="/pdf/2208.01795" title="Download PDF">pdf</a>, <a href="/format/2208.01795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Modeling of Branched Robots using Modular Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+F+F+A">Frederico Fernandes Afonso Silva</a>, 
<a href="/search/cs?searchtype=author&query=Adorno%2C+B+V">Bruno Vilhena Adorno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 5 tables. Under Review for the IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02529" title="Abstract">arXiv:2208.02529</a> (replaced) [<a href="/pdf/2208.02529" title="Download PDF">pdf</a>, <a href="/format/2208.02529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metadata-enhanced contrastive learning from retinal optical coherence  tomography images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holland%2C+R">Robbie Holland</a>, 
<a href="/search/cs?searchtype=author&query=Leingang%2C+O">Oliver Leingang</a>, 
<a href="/search/cs?searchtype=author&query=Bogunovi%C4%87%2C+H">Hrvoje Bogunovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+S">Sophie Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Fritsche%2C+L">Lars Fritsche</a>, 
<a href="/search/cs?searchtype=author&query=Prevost%2C+T">Toby Prevost</a>, 
<a href="/search/cs?searchtype=author&query=Scholl%2C+H+P+N">Hendrik P. N. Scholl</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Erfurth%2C+U">Ursula Schmidt-Erfurth</a>, 
<a href="/search/cs?searchtype=author&query=Sivaprasad%2C+S">Sobha Sivaprasad</a>, 
<a href="/search/cs?searchtype=author&query=Lotery%2C+A+J">Andrew J. Lotery</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Menten%2C+M+J">Martin J. Menten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05788" title="Abstract">arXiv:2208.05788</a> (replaced) [<a href="/pdf/2208.05788" title="Download PDF">pdf</a>, <a href="/format/2208.05788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Self-adaptation: Enhancing Generalization with a Single Sample
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+S">Sherwin Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+O">Oliver Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Zamfir%2C+E">Eduard Zamfir</a>, 
<a href="/search/cs?searchtype=author&query=Araslanov%2C+N">Nikita Araslanov</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+S">Stefan Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR (July 2023) | OpenReview: <a href="https://openreview.net/forum?id=ILNqQhGbLx">this https URL</a> | Code: <a href="https://github.com/visinf/self-adaptive">this https URL</a> | Video: <a href="https://youtu.be/s4DG65ic0EA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05724" title="Abstract">arXiv:2209.05724</a> (replaced) [<a href="/pdf/2209.05724" title="Download PDF">pdf</a>, <a href="/format/2209.05724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concealing Sensitive Samples against Gradient Leakage in Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+M">Munawar Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Defence against model inversion attack in federated learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03394" title="Abstract">arXiv:2210.03394</a> (replaced) [<a href="/pdf/2210.03394" title="Download PDF">pdf</a>, <a href="/ps/2210.03394" title="Download PostScript">ps</a>, <a href="/format/2210.03394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Wayness in Quantum Cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Morimae%2C+T">Tomoyuki Morimae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04723" title="Abstract">arXiv:2210.04723</a> (replaced) [<a href="/pdf/2210.04723" title="Download PDF">pdf</a>, <a href="/format/2210.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiential Explanations for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabdulkarim%2C+A">Amal Alabdulkarim</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Madhuri Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mansi%2C+G">Gennie Mansi</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+K">Kaely Hall</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M+O">Mark O. Riedl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05742" title="Abstract">arXiv:2210.05742</a> (replaced) [<a href="/pdf/2210.05742" title="Download PDF">pdf</a>, <a href="/format/2210.05742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curved Representation Space of Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juyeop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junha Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Songkuk Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-Seok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11194" title="Abstract">arXiv:2210.11194</a> (replaced) [<a href="/pdf/2210.11194" title="Download PDF">pdf</a>, <a href="/format/2210.11194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controller-Guided Partial Label Consistency Regularization with  Unlabeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian-Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bowen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingyan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zimo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15609" title="Abstract">arXiv:2210.15609</a> (replaced) [<a href="/pdf/2210.15609" title="Download PDF">pdf</a>, <a href="/ps/2210.15609" title="Download PostScript">ps</a>, <a href="/format/2210.15609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The formal verification of the ctm approach to forcing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gunther%2C+E">Emmanuel Gunther</a>, 
<a href="/search/math?searchtype=author&query=Pagano%2C+M">Miguel Pagano</a>, 
<a href="/search/math?searchtype=author&query=Terraf%2C+P+S">Pedro S&#xe1;nchez Terraf</a>, 
<a href="/search/math?searchtype=author&query=Steinberg%2C+M">Mat&#xed;as Steinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20pp + 14pp in bibliography &amp; appendices, 2 tables. v2: Added details to Delta System Lemma appendix, updated acknowledgments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17178" title="Abstract">arXiv:2210.17178</a> (replaced) [<a href="/pdf/2210.17178" title="Download PDF">pdf</a>, <a href="/format/2210.17178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Optimize Permutation Flow Shop Scheduling via Graph-based  Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longkang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chris Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hongyuan Zha</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures, 11 tables, AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03733" title="Abstract">arXiv:2211.03733</a> (replaced) [<a href="/pdf/2211.03733" title="Download PDF">pdf</a>, <a href="/format/2211.03733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Iterative Bidirectional Gradient Boosting Approach for CVR Baseline  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+H+P">Han Pyo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiyan Li</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+L">Lidong Song</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Ning Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07066" title="Abstract">arXiv:2211.07066</a> (replaced) [<a href="/pdf/2211.07066" title="Download PDF">pdf</a>, <a href="/format/2211.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Citation Sentence Generation with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Nianlong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hahnloser%2C+R+H+R">Richard H.R. Hahnloser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08622" title="Abstract">arXiv:2211.08622</a> (replaced) [<a href="/pdf/2211.08622" title="Download PDF">pdf</a>, <a href="/format/2211.08622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Redundancy on Resilience in Distributed Optimization and  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nirupam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+N+H">Nitin H. Vaidya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 2 figures, 2 tables. Updated with the full version of the paper, updated results in Section 4 and Appendix C, and other minor fixings. arXiv admin note: substantial text overlap with <a href="/abs/2110.10858">arXiv:2110.10858</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12986" title="Abstract">arXiv:2211.12986</a> (replaced) [<a href="/pdf/2211.12986" title="Download PDF">pdf</a>, <a href="/ps/2211.12986" title="Download PostScript">ps</a>, <a href="/format/2211.12986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural networks for pathloss prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Limmer%2C+S">Steffen Limmer</a>, 
<a href="/search/stat?searchtype=author&query=Alba%2C+A+M">Alberto Martinez Alba</a>, 
<a href="/search/stat?searchtype=author&query=Michailow%2C+N">Nicola Michailow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, accepted at MLSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14158" title="Abstract">arXiv:2211.14158</a> (replaced) [<a href="/pdf/2211.14158" title="Download PDF">pdf</a>, <a href="/format/2211.14158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Isolation-Aware Online Virtual Network Embedding via Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohar%2C+A">Ali Gohar</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+C">Chunming Rong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghwan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures, 3 tables, 2 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01196" title="Abstract">arXiv:2212.01196</a> (replaced) [<a href="/pdf/2212.01196" title="Download PDF">pdf</a>, <a href="/format/2212.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Symbolic Finite State Machines in Attractor Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotteret%2C+M">Madison Cotteret</a>, 
<a href="/search/cs?searchtype=author&query=Greatorex%2C+H">Hugh Greatorex</a>, 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+M">Martin Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Chicca%2C+E">Elisabetta Chicca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 13 figures. This is the authors' final version before publication in Neural Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02997" title="Abstract">arXiv:2212.02997</a> (replaced) [<a href="/pdf/2212.02997" title="Download PDF">pdf</a>, <a href="/format/2212.02997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGazeNet: Generalizing Gaze Estimation with Weak-Supervision from  Synthetic Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ververas%2C+E">Evangelos Ververas</a>, 
<a href="/search/cs?searchtype=author&query=Gkagkos%2C+P">Polydefkis Gkagkos</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Doukas%2C+M+C">Michail Christos Doukas</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04246" title="Abstract">arXiv:2212.04246</a> (replaced) [<a href="/pdf/2212.04246" title="Download PDF">pdf</a>, <a href="/format/2212.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViTPose++: Vision Transformer for Generic Body Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yufei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of ViTPose paper, accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06244" title="Abstract">arXiv:2212.06244</a> (replaced) [<a href="/pdf/2212.06244" title="Download PDF">pdf</a>, <a href="/format/2212.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathFusion: Path-consistent Lidar-Camera Deep Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lemeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06605" title="Abstract">arXiv:2212.06605</a> (replaced) [<a href="/pdf/2212.06605" title="Download PDF">pdf</a>, <a href="/format/2212.06605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionality reduction on complex vector spaces for Euclidean distance  with dynamic weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pellizzoni%2C+P">Paolo Pellizzoni</a>, 
<a href="/search/cs?searchtype=author&query=Moretti%2C+S">Simone Moretti</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Francesco Silvestri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08949" title="Abstract">arXiv:2212.08949</a> (replaced) [<a href="/pdf/2212.08949" title="Download PDF">pdf</a>, <a href="/format/2212.08949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Temporal Resolution in Continuous Value Estimation: A  Fundamental Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kirschner%2C+J">Johannes Kirschner</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zanini%2C+F">Francesco Zanini</a>, 
<a href="/search/cs?searchtype=author&query=Ayoub%2C+A">Alex Ayoub</a>, 
<a href="/search/cs?searchtype=author&query=Dehghan%2C+M">Masood Dehghan</a>, 
<a href="/search/cs?searchtype=author&query=Schuurmans%2C+D">Dale Schuurmans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13120" title="Abstract">arXiv:2212.13120</a> (replaced) [<a href="/pdf/2212.13120" title="Download PDF">pdf</a>, <a href="/format/2212.13120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Structure Fields with Application to Crystal Structure  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cond-mat?searchtype=author&query=Suzuki%2C+Y">Yuta Suzuki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Taniai%2C+T">Tatsunori Taniai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Igarashi%2C+R">Ryo Igarashi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cond-mat?searchtype=author&query=Saito%2C+K">Kotaro Saito</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ono%2C+K">Kanta Ono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages , 7 figures, 4 tables. 15 pages Supplementary Information
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Communications Materials (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02281" title="Abstract">arXiv:2301.02281</a> (replaced) [<a href="/pdf/2301.02281" title="Download PDF">pdf</a>, <a href="/format/2301.02281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A compositional game to fairly divide homogeneous cake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansma%2C+A">Abel Jansma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 5 diagrams
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06145" title="Abstract">arXiv:2301.06145</a> (replaced) [<a href="/pdf/2301.06145" title="Download PDF">pdf</a>, <a href="/format/2301.06145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dyck Words, Pattern Avoidance, and Automatic Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mol%2C+L">Lucas Mol</a>, 
<a href="/search/cs?searchtype=author&query=Rampersad%2C+N">Narad Rampersad</a>, 
<a href="/search/cs?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a paper appearing in the conference proceedings of WORDS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Formal Languages and Automata Theory (cs.FL); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09083" title="Abstract">arXiv:2301.09083</a> (replaced) [<a href="/pdf/2301.09083" title="Download PDF">pdf</a>, <a href="/format/2301.09083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the determination of Lagrange Multipliers for a weighted LASSO  problem using geometric and convex analysis techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Giacchi%2C+G">Gianluca Giacchi</a>, 
<a href="/search/math?searchtype=author&query=Milani%2C+B">Bastien Milani</a>, 
<a href="/search/math?searchtype=author&query=Franchieschiello%2C+B">Benedetta Franchieschiello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12562" title="Abstract">arXiv:2301.12562</a> (replaced) [<a href="/pdf/2301.12562" title="Download PDF">pdf</a>, <a href="/format/2301.12562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Subgraph Representation Learning for Scalable Link  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louis%2C+P">Paul Louis</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+S+A">Shweta Ann Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Salehi-Abari%2C+A">Amirali Salehi-Abari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12677" title="Abstract">arXiv:2301.12677</a> (replaced) [<a href="/pdf/2301.12677" title="Download PDF">pdf</a>, <a href="/format/2301.12677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Stochastic Optimization under a General Variance Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+K">Kun Huang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/math?searchtype=author&query=Pu%2C+S">Shi Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13319" title="Abstract">arXiv:2301.13319</a> (replaced) [<a href="/pdf/2301.13319" title="Download PDF">pdf</a>, <a href="/format/2301.13319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation  Solution for Individual Particle Characterization from Micro CT Images in  Mineral Processing and Recycling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gotkowski%2C+K">Karol Gotkowski</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shuvam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Godinho%2C+J+R+A">Jose R. A. Godinho</a>, 
<a href="/search/cs?searchtype=author&query=Tochtrop%2C+C+G+S">Camila G. S. Tochtrop</a>, 
<a href="/search/cs?searchtype=author&query=Maier-Hein%2C+K+H">Klaus H. Maier-Hein</a>, 
<a href="/search/cs?searchtype=author&query=Isensee%2C+F">Fabian Isensee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00919" title="Abstract">arXiv:2302.00919</a> (replaced) [<a href="/pdf/2302.00919" title="Download PDF">pdf</a>, <a href="/format/2302.00919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based  Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+X">Xiangming Meng</a>, 
<a href="/search/eess?searchtype=author&query=Kabashima%2C+Y">Yoshiyuki Kabashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 with appendix. 23 pages, 17 figures, code available at <a href="https://github.com/mengxiangming/QCS-SGM-plus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06228" title="Abstract">arXiv:2302.06228</a> (replaced) [<a href="/pdf/2302.06228" title="Download PDF">pdf</a>, <a href="/ps/2302.06228" title="Download PostScript">ps</a>, <a href="/format/2302.06228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Detection of Behavioural Drifts with Dynamic Clustering and  Trajectory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prenkaj%2C+B">Bardh Prenkaj</a>, 
<a href="/search/cs?searchtype=author&query=Velardi%2C+P">Paola Velardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TKDE
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09639" title="Abstract">arXiv:2302.09639</a> (replaced) [<a href="/pdf/2302.09639" title="Download PDF">pdf</a>, <a href="/format/2302.09639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An overview of differentiable particle filters for data-adaptive  sequential Bayesian inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, accepted for publication by AIMS Foundation of Data Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13020" title="Abstract">arXiv:2302.13020</a> (replaced) [<a href="/pdf/2302.13020" title="Download PDF">pdf</a>, <a href="/format/2302.13020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCLP: Neural Architecture Predictor with Curriculum Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shenghe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tianyu Mu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01141" title="Abstract">arXiv:2303.01141</a> (replaced) [<a href="/pdf/2303.01141" title="Download PDF">pdf</a>, <a href="/format/2303.01141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint  Satisfaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+K">Kshitij Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Dumancic%2C+S">Sebastijan Dumancic</a>, 
<a href="/search/cs?searchtype=author&query=Blockeel%2C+H">Hendrik Blockeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01903" title="Abstract">arXiv:2303.01903</a> (replaced) [<a href="/pdf/2303.01903" title="Download PDF">pdf</a>, <a href="/format/2303.01903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prophet: Prompting Large Language Models with Complementary Answer  Heuristics for Knowledge-based Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+X">Xuecheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhenwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended jounral version of our CVPR 2023 paper. The conference version can be referred to the last arxiv version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02904" title="Abstract">arXiv:2303.02904</a> (replaced) [<a href="/pdf/2303.02904" title="Download PDF">pdf</a>, <a href="/format/2303.02904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Cue Detection and Analysis Using Transfer Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Croft%2C+E+A">Elizabeth A. Croft</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+M+G">Michael G. Burke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. Preprint. To be published in Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24), March 11--14, 2024, Boulder, CO, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03381" title="Abstract">arXiv:2303.03381</a> (replaced) [<a href="/pdf/2303.03381" title="Download PDF">pdf</a>, <a href="/format/2303.03381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Humanoid Locomotion with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tete Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Sreenath%2C+K">Koushil Sreenath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://learning-humanoid-locomotion.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03865" title="Abstract">arXiv:2303.03865</a> (replaced) [<a href="/pdf/2303.03865" title="Download PDF">pdf</a>, <a href="/format/2303.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bicategories of Automata, Automata in Bicategories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boccali%2C+G">Guido Boccali</a> (University of Torino), 
<a href="/search/math?searchtype=author&query=Laretto%2C+A">Andrea Laretto</a> (Tallinn University of Technology), 
<a href="/search/math?searchtype=author&query=Loregian%2C+F">Fosco Loregian</a> (Tallinn University of Technology), 
<a href="/search/math?searchtype=author&query=Luneia%2C+S">Stefano Luneia</a> (University of Bologna)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 1-19
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03919" title="Abstract">arXiv:2303.03919</a> (replaced) [<a href="/pdf/2303.03919" title="Download PDF">pdf</a>, <a href="/format/2303.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Portraits: Recording Foundation Model Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marone%2C+M">Marc Marone</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04416" title="Abstract">arXiv:2303.04416</a> (replaced) [<a href="/pdf/2303.04416" title="Download PDF">pdf</a>, <a href="/format/2303.04416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference on Optimal Dynamic Policies via Softmax Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Chen%2C+Q">Qizhao Chen</a>, 
<a href="/search/econ?searchtype=author&query=Austern%2C+M">Morgane Austern</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05115" title="Abstract">arXiv:2303.05115</a> (replaced) [<a href="/pdf/2303.05115" title="Download PDF">pdf</a>, <a href="/format/2303.05115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal smoothing and dynamics of different electricity  flexibility options for highly renewable energy systems -- Case study for  Norway
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grochowicz%2C+A">Aleksander Grochowicz</a>, 
<a href="/search/math?searchtype=author&query=Benth%2C+F+E">Fred Espen Benth</a>, 
<a href="/search/math?searchtype=author&query=Zeyringer%2C+M">Marianne Zeyringer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Energy 356:122338. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05164" title="Abstract">arXiv:2303.05164</a> (replaced) [<a href="/pdf/2303.05164" title="Download PDF">pdf</a>, <a href="/format/2303.05164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability-Adaptive Consistency Regularization for Weakly-Supervised  Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yicheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10981" title="Abstract">arXiv:2303.10981</a> (replaced) [<a href="/pdf/2303.10981" title="Download PDF">pdf</a>, <a href="/format/2303.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passivity-Preserving Safety-Critical Control using Control Barrier  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Califano%2C+F">Federico Califano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13056" title="Abstract">arXiv:2303.13056</a> (replaced) [<a href="/pdf/2303.13056" title="Download PDF">pdf</a>, <a href="/format/2303.13056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the Initial Conditions of the Universe using a Deterministic  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Jindal%2C+V">Vaibhav Jindal</a>, 
<a href="/search/astro-ph?searchtype=author&query=Liang%2C+A">Albert Liang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Singh%2C+A">Aarti Singh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ho%2C+S">Shirley Ho</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jamieson%2C+D">Drew Jamieson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version for NeurIPS 2023 AI for Science workshop <a href="https://ai4sciencecommunity.github.io/neurips23.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13630" title="Abstract">arXiv:2303.13630</a> (replaced) [<a href="/pdf/2303.13630" title="Download PDF">pdf</a>, <a href="/format/2303.13630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Critical Coordination for Cooperative Legged Locomotion via  Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023). 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02878" title="Abstract">arXiv:2304.02878</a> (replaced) [<a href="/pdf/2304.02878" title="Download PDF">pdf</a>, <a href="/format/2304.02878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Stabilization of Unknown Linear Time-Varying Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+J">Jing Yu</a>, 
<a href="/search/math?searchtype=author&query=Gupta%2C+V">Varun Gupta</a>, 
<a href="/search/math?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07235" title="Abstract">arXiv:2304.07235</a> (replaced) [<a href="/pdf/2304.07235" title="Download PDF">pdf</a>, <a href="/format/2304.07235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What does self-attention learn from Masked Language Modelling?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Rende%2C+R">Riccardo Rende</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gerace%2C+F">Federica Gerace</a>, 
<a href="/search/cond-mat?searchtype=author&query=Laio%2C+A">Alessandro Laio</a>, 
<a href="/search/cond-mat?searchtype=author&query=Goldt%2C+S">Sebastian Goldt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10337" title="Abstract">arXiv:2304.10337</a> (replaced) [<a href="/pdf/2304.10337" title="Download PDF">pdf</a>, <a href="/format/2304.10337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of the evolution of the nuclear reactor core parameters using  artificial neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palmi%2C+K">Krzysztof Palmi</a>, 
<a href="/search/cs?searchtype=author&query=Kubinski%2C+W">Wojciech Kubinski</a>, 
<a href="/search/cs?searchtype=author&query=Darnowski%2C+P">Piotr Darnowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02506" title="Abstract">arXiv:2305.02506</a> (replaced) [<a href="/pdf/2305.02506" title="Download PDF">pdf</a>, <a href="/ps/2305.02506" title="Download PostScript">ps</a>, <a href="/format/2305.02506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> String Diagrams with Factorized Densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sennesh%2C+E">Eli Sennesh</a> (Northeastern University), 
<a href="/search/cs?searchtype=author&query=van+de+Meent%2C+J">Jan-Willem van de Meent</a> (University of Amsterdam)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 260-278
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Category Theory (math.CT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02906" title="Abstract">arXiv:2305.02906</a> (replaced) [<a href="/pdf/2305.02906" title="Download PDF">pdf</a>, <a href="/format/2305.02906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optics for Premonoidal Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hefford%2C+J">James Hefford</a> (University of Oxford), 
<a href="/search/math?searchtype=author&query=Rom%C3%A1n%2C+M">Mario Rom&#xe1;n</a> (Tallinn University of Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 152-171
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05451" title="Abstract">arXiv:2305.05451</a> (replaced) [<a href="/pdf/2305.05451" title="Download PDF">pdf</a>, <a href="/format/2305.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Augmented Normalizing Flows for Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Windsheimer%2C+M">Marc Windsheimer</a>, 
<a href="/search/eess?searchtype=author&query=Brand%2C+F">Fabian Brand</a>, 
<a href="/search/eess?searchtype=author&query=Kaup%2C+A">Andr&#xe9; Kaup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06941" title="Abstract">arXiv:2305.06941</a> (replaced) [<a href="/pdf/2305.06941" title="Download PDF">pdf</a>, <a href="/format/2305.06941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dendritic Computation through Exploiting Resistive Memory as both Delays  and Weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Payvand%2C+M">Melika Payvand</a>, 
<a href="/search/cs?searchtype=author&query=D%27Agostino%2C+S">Simone D&#x27;Agostino</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+F">Filippo Moro</a>, 
<a href="/search/cs?searchtype=author&query=Demirag%2C+Y">Yigit Demirag</a>, 
<a href="/search/cs?searchtype=author&query=Indiveri%2C+G">Giacomo Indiveri</a>, 
<a href="/search/cs?searchtype=author&query=Vianello%2C+E">Elisa Vianello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07439" title="Abstract">arXiv:2305.07439</a> (replaced) [<a href="/pdf/2305.07439" title="Download PDF">pdf</a>, <a href="/ps/2305.07439" title="Download PostScript">ps</a>, <a href="/format/2305.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension Results for Extremal-Generic Polynomial Systems over Complete  Toric Varieties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bender%2C+M">Mat&#xed;as Bender</a>, 
<a href="/search/cs?searchtype=author&query=Spaenlehauer%2C+P">Pierre-Jean Spaenlehauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07525" title="Abstract">arXiv:2305.07525</a> (replaced) [<a href="/pdf/2305.07525" title="Download PDF">pdf</a>, <a href="/ps/2305.07525" title="Download PostScript">ps</a>, <a href="/format/2305.07525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truthful Two-Facility Location with Candidate Locations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+P">Panagiotis Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+A+A">Alexandros A. Voudouris</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A previous version claimed an upper bound of 3 for social cost and general preferences which was incorrect; this has now been removed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10547" title="Abstract">arXiv:2305.10547</a> (replaced) [<a href="/pdf/2305.10547" title="Download PDF">pdf</a>, <a href="/format/2305.10547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Multimodal Content Moderation from an Asymmetric Angle with  Mixed-modality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jialin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Ye Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+G">Gaurav Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+M">Matthew Hall</a>, 
<a href="/search/cs?searchtype=author&query=Sajeev%2C+S">Sandra Sajeev</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10816" title="Abstract">arXiv:2305.10816</a> (replaced) [<a href="/pdf/2305.10816" title="Download PDF">pdf</a>, <a href="/format/2305.10816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACos: Learning Temporally Structured Embeddings for Few-Shot Keyword  Spotting with Dynamic Time Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wilkinghoff%2C+K">Kevin Wilkinghoff</a>, 
<a href="/search/eess?searchtype=author&query=Cornaggia-Urrigshardt%2C+A">Alessia Cornaggia-Urrigshardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10847" title="Abstract">arXiv:2305.10847</a> (replaced) [<a href="/pdf/2305.10847" title="Download PDF">pdf</a>, <a href="/format/2305.10847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models can be Guided to Evade AI-Generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Ning Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Rui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13721" title="Abstract">arXiv:2305.13721</a> (replaced) [<a href="/pdf/2305.13721" title="Download PDF">pdf</a>, <a href="/format/2305.13721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Dialogue State Tracking via Example-Guided Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hyundong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Madotto%2C+A">Andrea Madotto</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhaojiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Kottur%2C+S">Satwik Kottur</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=May%2C+J">Jonathan May</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+C">Chinnadhurai Sankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13921" title="Abstract">arXiv:2305.13921</a> (replaced) [<a href="/pdf/2305.13921" title="Download PDF">pdf</a>, <a href="/format/2305.13921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Text-to-Image Synthesis with Attention Map Control of  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zekang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accept by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14141" title="Abstract">arXiv:2305.14141</a> (replaced) [<a href="/pdf/2305.14141" title="Download PDF">pdf</a>, <a href="/format/2305.14141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Remote Sensing Object Detection with Single Point Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shitian He</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Huanxin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+N">Ning Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TGRS; 16 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14973" title="Abstract">arXiv:2305.14973</a> (replaced) [<a href="/pdf/2305.14973" title="Download PDF">pdf</a>, <a href="/format/2305.14973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OverPrompt: Enhancing ChatGPT through Efficient In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiazheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Runcong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+L">Lin Gui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 R0-FoMo Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16321" title="Abstract">arXiv:2305.16321</a> (replaced) [<a href="/pdf/2305.16321" title="Download PDF">pdf</a>, <a href="/format/2305.16321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eclipse: Disambiguating Illumination and Materials using Unintended  Shadows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>, 
<a href="/search/cs?searchtype=author&query=Hedman%2C+P">Peter Hedman</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Zickler%2C+T">Todd Zickler</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P+P">Pratul P. Srinivasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://dorverbin.github.io/eclipse/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16846" title="Abstract">arXiv:2305.16846</a> (replaced) [<a href="/pdf/2305.16846" title="Download PDF">pdf</a>, <a href="/format/2305.16846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lagrangian Flow Networks for Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torres%2C+F+A">F. Arend Torres</a>, 
<a href="/search/cs?searchtype=author&query=Negri%2C+M+M">Marcello Massimo Negri</a>, 
<a href="/search/cs?searchtype=author&query=Inversi%2C+M">Marco Inversi</a>, 
<a href="/search/cs?searchtype=author&query=Aellen%2C+J">Jonathan Aellen</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+V">Volker Roth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an); Fluid Dynamics (physics.flu-dyn); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01952" title="Abstract">arXiv:2306.01952</a> (replaced) [<a href="/pdf/2306.01952" title="Download PDF">pdf</a>, <a href="/format/2306.01952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in Domain Randomization via Continuous Time Non-Stochastic  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jingwei Li</a>, 
<a href="/search/math?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/math?searchtype=author&query=Chang%2C+C">Can Chang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Baoxiang Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jingzhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03480" title="Abstract">arXiv:2306.03480</a> (replaced) [<a href="/pdf/2306.03480" title="Download PDF">pdf</a>, <a href="/format/2306.03480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSHOT: Few-shot Generative Modeling of Labeled Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manchanda%2C+S">Sahil Manchanda</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shubham Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ranu%2C+S">Sayan Ranu</a>, 
<a href="/search/cs?searchtype=author&query=Bedathur%2C+S">Srikanta Bedathur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Learning on Graph Conference (LOG,2023),<a href="https://openreview.net/forum?id=Hy9K2WiVwW">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04389" title="Abstract">arXiv:2306.04389</a> (replaced) [<a href="/pdf/2306.04389" title="Download PDF">pdf</a>, <a href="/format/2306.04389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symplectic multirate generalized additive Runge-Kutta methods for  Hamiltonian systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sch%C3%A4fers%2C+K">Kevin Sch&#xe4;fers</a>, 
<a href="/search/math?searchtype=author&query=G%C3%BCnther%2C+M">Michael G&#xfc;nther</a>, 
<a href="/search/math?searchtype=author&query=Sandu%2C+A">Adrian Sandu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06388" title="Abstract">arXiv:2306.06388</a> (replaced) [<a href="/pdf/2306.06388" title="Download PDF">pdf</a>, <a href="/format/2306.06388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From NeRFLiX to NeRFLiX++: A General NeRF-Agnostic Restorer Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nianjuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiangbo Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figures. To appear in TPAMI2023. Project Page: <a href="https://redrock303.github.io/nerflix_plus/.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2303.06919">arXiv:2303.06919</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06963" title="Abstract">arXiv:2306.06963</a> (replaced) [<a href="/pdf/2306.06963" title="Download PDF">pdf</a>, <a href="/format/2306.06963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Fusion from Head to Tail for Long-Tailed Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengke Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhikai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+W">Weichao Lan</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y">Yiu-ming Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI24, similar to the conference version. Add the supplementry
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07562" title="Abstract">arXiv:2306.07562</a> (replaced) [<a href="/pdf/2306.07562" title="Download PDF">pdf</a>, <a href="/format/2306.07562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Beamformer Exploiting Non-stationarity and Sparsity with  Spatially Constrained ICA for Robust Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shin%2C+U">Ui-Hyeop Shin</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+H">Hyung-Min Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08053" title="Abstract">arXiv:2306.08053</a> (replaced) [<a href="/pdf/2306.08053" title="Download PDF">pdf</a>, <a href="/format/2306.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Spatial Audio Quality Impairment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Watcharasupat%2C+K+N">Karn N. Watcharasupat</a>, 
<a href="/search/eess?searchtype=author&query=Lerch%2C+A">Alexander Lerch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09202" title="Abstract">arXiv:2306.09202</a> (replaced) [<a href="/pdf/2306.09202" title="Download PDF">pdf</a>, <a href="/format/2306.09202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Optimal Algorithm for the Real-Valued Combinatorial Pure Exploration  of Multi-Armed Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Shintaro Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10007" title="Abstract">arXiv:2306.10007</a> (replaced) [<a href="/pdf/2306.10007" title="Download PDF">pdf</a>, <a href="/format/2306.10007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Learning with Sensorimotor Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Baifeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Letian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Ken Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023; Project page: <a href="https://robotic-pretrained-transformer.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10311" title="Abstract">arXiv:2306.10311</a> (replaced) [<a href="/pdf/2306.10311" title="Download PDF">pdf</a>, <a href="/format/2306.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Denoising and Fusion with Short- and Long-exposure Raw Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qihua Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14408" title="Abstract">arXiv:2306.14408</a> (replaced) [<a href="/pdf/2306.14408" title="Download PDF">pdf</a>, <a href="/format/2306.14408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decompose and Realign: Tackling Condition Misalignment in Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luozhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guibao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Wenhang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-cong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00293" title="Abstract">arXiv:2307.00293</a> (replaced) [<a href="/pdf/2307.00293" title="Download PDF">pdf</a>, <a href="/format/2307.00293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoST: Training-free Neural Architecture Search for Spiking  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qidong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jinku Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01146" title="Abstract">arXiv:2307.01146</a> (replaced) [<a href="/pdf/2307.01146" title="Download PDF">pdf</a>, <a href="/format/2307.01146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVSegFormer: Audio-Visual Segmentation with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shengyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01200" title="Abstract">arXiv:2307.01200</a> (replaced) [<a href="/pdf/2307.01200" title="Download PDF">pdf</a>, <a href="/format/2307.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProxyCap: Real-time Monocular Full-body Capture in World Space via  Human-Centric Proxy-to-Motion Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liangxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03223" title="Abstract">arXiv:2307.03223</a> (replaced) [<a href="/pdf/2307.03223" title="Download PDF">pdf</a>, <a href="/ps/2307.03223" title="Download PostScript">ps</a>, <a href="/format/2307.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Field Theories: Non-Gaussianity, Actions, and Locality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-th?searchtype=author&query=Demirtas%2C+M">Mehmet Demirtas</a>, 
<a href="/search/hep-th?searchtype=author&query=Halverson%2C+J">James Halverson</a>, 
<a href="/search/hep-th?searchtype=author&query=Maiti%2C+A">Anindita Maiti</a>, 
<a href="/search/hep-th?searchtype=author&query=Schwartz%2C+M+D">Matthew D. Schwartz</a>, 
<a href="/search/hep-th?searchtype=author&query=Stoner%2C+K">Keegan Stoner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, plus references and appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Theory (hep-th)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03503" title="Abstract">arXiv:2307.03503</a> (replaced) [<a href="/pdf/2307.03503" title="Download PDF">pdf</a>, <a href="/format/2307.03503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A variant of the Raviart-Thomas method to handle smooth domains with  straight-edged triangles. Part I -- Well-posedness results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Splitting <a href="/abs/2307.03503">arXiv:2307.03503v2</a> into two parts. This is the first part thereof, which first appeared as <a href="/abs/2307.03503">arXiv:2307.03503v3</a> without this comment. The second and last part is already the object of another submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06009" title="Abstract">arXiv:2307.06009</a> (replaced) [<a href="/pdf/2307.06009" title="Download PDF">pdf</a>, <a href="/format/2307.06009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Linear Algebraic Framework for Dynamic Scheduling Over Memory-Equipped  Quantum Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fittipaldi%2C+P">Paolo Fittipaldi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Giovanidis%2C+A">Anastasios Giovanidis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grosshans%2C+F">Fr&#xe9;d&#xe9;ric Grosshans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures. Accepted for publication in "IEEE Transactions on Quantum Engineering"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06643" title="Abstract">arXiv:2307.06643</a> (replaced) [<a href="/pdf/2307.06643" title="Download PDF">pdf</a>, <a href="/format/2307.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nowcasting Temporal Trends Using Indirect Surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+J+M">Juan Marcos Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Aranda%2C+S">Sergio D&#xed;az-Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Aguilar%2C+J">Jose Aguilar</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+A">Antonio Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Anta%2C+A+F">Antonio Fern&#xe1;ndez Anta</a>, 
<a href="/search/cs?searchtype=author&query=Lillo%2C+R+E">Rosa Elvira Lillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07462" title="Abstract">arXiv:2307.07462</a> (replaced) [<a href="/pdf/2307.07462" title="Download PDF">pdf</a>, <a href="/format/2307.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Zigzag Vineyard Efficiently Including Expansions and  Contractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+T+K">Tamal K. Dey</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tao Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12618" title="Abstract">arXiv:2307.12618</a> (replaced) [<a href="/e-print/2307.12618" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Regularized Soft Introspective VAE: Towards Cardiac Attribute  Regularization Through MRI Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Folco%2C+M">Maxime Di Folco</a>, 
<a href="/search/eess?searchtype=author&query=Bercea%2C+C">Cosmin Bercea</a>, 
<a href="/search/eess?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Not accepted and outdated results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12971" title="Abstract">arXiv:2307.12971</a> (replaced) [<a href="/pdf/2307.12971" title="Download PDF">pdf</a>, <a href="/format/2307.12971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big Data - Supply Chain Management Framework for Forecasting: Data  Preprocessing and Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Shovon%2C+M+S+H">Md Sakib Hossain Shovon</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jungpil Shin</a>, 
<a href="/search/cs?searchtype=author&query=Ridoy%2C+I+A">Istiyaque Ahmed Ridoy</a>, 
<a href="/search/cs?searchtype=author&query=Tomioka%2C+Y">Yoichi Tomioka</a>, 
<a href="/search/cs?searchtype=author&query=Mridha%2C+M+F">M. F. Mridha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14461" title="Abstract">arXiv:2307.14461</a> (replaced) [<a href="/pdf/2307.14461" title="Download PDF">pdf</a>, <a href="/ps/2307.14461" title="Download PostScript">ps</a>, <a href="/format/2307.14461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obstructions to Compositionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Puca%2C+C">Caterina Puca</a>, 
<a href="/search/math?searchtype=author&query=Hadzihasanovic%2C+A">Amar Hadzihasanovic</a>, 
<a href="/search/math?searchtype=author&query=Genovese%2C+F">Fabrizio Genovese</a>, 
<a href="/search/math?searchtype=author&query=Coecke%2C+B">Bob Coecke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 226-245
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16506" title="Abstract">arXiv:2307.16506</a> (replaced) [<a href="/pdf/2307.16506" title="Download PDF">pdf</a>, <a href="/format/2307.16506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Equivariant Neural Networks for Particle Physics: PELICAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Bogatskiy%2C+A">Alexander Bogatskiy</a>, 
<a href="/search/hep-ph?searchtype=author&query=Hoffman%2C+T">Timothy Hoffman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Miller%2C+D+W">David W. Miller</a>, 
<a href="/search/hep-ph?searchtype=author&query=Offermann%2C+J+T">Jan T. Offermann</a>, 
<a href="/search/hep-ph?searchtype=author&query=Liu%2C+X">Xiaoyang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 34 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01890" title="Abstract">arXiv:2308.01890</a> (replaced) [<a href="/pdf/2308.01890" title="Download PDF">pdf</a>, <a href="/format/2308.01890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition  with Limited Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Ping Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Ximeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sclaroff%2C+S">Stan Sclaroff</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TPAMI. arXiv admin note: substantial text overlap with <a href="/abs/2206.09541">arXiv:2206.09541</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02668" title="Abstract">arXiv:2308.02668</a> (replaced) [<a href="/pdf/2308.02668" title="Download PDF">pdf</a>, <a href="/format/2308.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Distillation for Semi-Supervised Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrada%2C+T">Tariq Berrada</a>, 
<a href="/search/cs?searchtype=author&query=Couprie%2C+C">Camille Couprie</a>, 
<a href="/search/cs?searchtype=author&query=Alahari%2C+K">Karteek Alahari</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+J">Jakob Verbeek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03358" title="Abstract">arXiv:2308.03358</a> (replaced) [<a href="/pdf/2308.03358" title="Download PDF">pdf</a>, <a href="/format/2308.03358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGMComm: Return Gap Minimization Via Discrete Communications In  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03443" title="Abstract">arXiv:2308.03443</a> (replaced) [<a href="/pdf/2308.03443" title="Download PDF">pdf</a>, <a href="/format/2308.03443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Robust Estimator for Off-Policy Evaluation with Large Action  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shimizu%2C+T">Tatsuhiro Shimizu</a>, 
<a href="/search/stat?searchtype=author&query=Forastiere%2C+L">Laura Forastiere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03669" title="Abstract">arXiv:2308.03669</a> (replaced) [<a href="/pdf/2308.03669" title="Download PDF">pdf</a>, <a href="/format/2308.03669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model in Causal Inference with Unmeasured Confounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimizu%2C+T">Tatsuhiro Shimizu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03793" title="Abstract">arXiv:2308.03793</a> (replaced) [<a href="/pdf/2308.03793" title="Download PDF">pdf</a>, <a href="/format/2308.03793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free  Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuefeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Albert Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiajia Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuyin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ken Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+N">Nan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+C">Cheng-Hao Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+R">Ram Nevatia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Oral Paper by 2024 IEEE CVF Winter Conference on Applications of Computer Vision (WACV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05890" title="Abstract">arXiv:2308.05890</a> (replaced) [<a href="/pdf/2308.05890" title="Download PDF">pdf</a>, <a href="/format/2308.05890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of the Landscape of Privacy Policies of Smart Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamid%2C+A">Aamir Hamid</a>, 
<a href="/search/cs?searchtype=author&query=Samidi%2C+H+R">Hemanth Reddy Samidi</a>, 
<a href="/search/cs?searchtype=author&query=Finin%2C+T">Tim Finin</a>, 
<a href="/search/cs?searchtype=author&query=Pappachan%2C+P">Primal Pappachan</a>, 
<a href="/search/cs?searchtype=author&query=Yus%2C+R">Roberto Yus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06221" title="Abstract">arXiv:2308.06221</a> (replaced) [<a href="/e-print/2308.06221" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Sizing and Training of Efficient Deep Autoencoders using  Second Order Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+K">Kanishka Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Rane%2C+C">Chinmay Rane</a>, 
<a href="/search/cs?searchtype=author&query=Manry%2C+M">Michael Manry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the paper need heavy editing incuding some changes in the results that needs to be updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06385" title="Abstract">arXiv:2308.06385</a> (replaced) [<a href="/pdf/2308.06385" title="Download PDF">pdf</a>, <a href="/format/2308.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZYN: Zero-Shot Reward Models with Yes-No Questions for RLAIF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallego%2C+V">Victor Gallego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pre-print, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08539" title="Abstract">arXiv:2308.08539</a> (replaced) [<a href="/pdf/2308.08539" title="Download PDF">pdf</a>, <a href="/format/2308.08539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant-depth circuits for Uniformly Controlled Gates and Boolean  functions with application to quantum memory circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Allcock%2C+J">Jonathan Allcock</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bao%2C+J">Jinge Bao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Doriguello%2C+J+F">Jo&#xe3;o F. Doriguello</a>, 
<a href="/search/quant-ph?searchtype=author&query=Luongo%2C+A">Alessandro Luongo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Santha%2C+M">Miklos Santha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 11 figures. v2: corrected typos, added one figure and references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09300" title="Abstract">arXiv:2308.09300</a> (replaced) [<a href="/pdf/2308.09300" title="Download PDF">pdf</a>, <a href="/format/2308.09300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by  Connecting Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pascual%2C+S">Santiago Pascual</a>, 
<a href="/search/cs?searchtype=author&query=Cartwright%2C+R">Richard Cartwright</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Demo page: <a href="https://v2a-mapper.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09591" title="Abstract">arXiv:2308.09591</a> (replaced) [<a href="/pdf/2308.09591" title="Download PDF">pdf</a>, <a href="/format/2308.09591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene  with a Pre-trained 2D Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yubin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Sheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Matthieu Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuze He</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yu-Hui Wen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10273" title="Abstract">arXiv:2308.10273</a> (replaced) [<a href="/pdf/2308.10273" title="Download PDF">pdf</a>, <a href="/format/2308.10273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zuheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10597" title="Abstract">arXiv:2308.10597</a> (replaced) [<a href="/pdf/2308.10597" title="Download PDF">pdf</a>, <a href="/format/2308.10597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppler-aware Odometry from FMCW Scanning Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rennie%2C+F">Fraser Rennie</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+D">David Williams</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>, 
<a href="/search/cs?searchtype=author&query=De+Martini%2C+D">Daniele De Martini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11561" title="Abstract">arXiv:2308.11561</a> (replaced) [<a href="/pdf/2308.11561" title="Download PDF">pdf</a>, <a href="/format/2308.11561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Grounded Graph-Aware Transformer for Aerial Vision-and-Dialog  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yifei Su</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+D">Dong An</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kehan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st Place Solution for the AVDN Challenge in ICCV CLVL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11918" title="Abstract">arXiv:2308.11918</a> (replaced) [<a href="/pdf/2308.11918" title="Download PDF">pdf</a>, <a href="/format/2308.11918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-Man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">ChunLe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11932" title="Abstract">arXiv:2308.11932</a> (replaced) [<a href="/pdf/2308.11932" title="Download PDF">pdf</a>, <a href="/format/2308.11932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Multiscale Detail Refinement via Intrinsic Supervision for  Underwater Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">ChunLe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12423" title="Abstract">arXiv:2308.12423</a> (replaced) [<a href="/pdf/2308.12423" title="Download PDF">pdf</a>, <a href="/format/2308.12423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and execution of quantum circuits using tens of superconducting  qubits and thousands of gates for dense Ising optimization problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Maciejewski%2C+F+B">Filip B. Maciejewski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hadfield%2C+S">Stuart Hadfield</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hall%2C+B">Benjamin Hall</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hodson%2C+M">Mark Hodson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dupont%2C+M">Maxime Dupont</a>, 
<a href="/search/quant-ph?searchtype=author&query=Evert%2C+B">Bram Evert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sud%2C+J">James Sud</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alam%2C+M+S">M. Sohaib Alam</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Z">Zhihui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jeffrey%2C+S">Stephen Jeffrey</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sundar%2C+B">Bhuvanesh Sundar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lott%2C+P+A">P. Aaron Lott</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grabbe%2C+S">Shon Grabbe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rieffel%2C+E+G">Eleanor G. Rieffel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Reagor%2C+M+J">Matthew J. Reagor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Venturelli%2C+D">Davide Venturelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: extended experimental results, updated references, fixed typos; 14+5 pages; 3+3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12608" title="Abstract">arXiv:2308.12608</a> (replaced) [<a href="/pdf/2308.12608" title="Download PDF">pdf</a>, <a href="/format/2308.12608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HR-Pro: Point-supervised Temporal Action Localization via Hierarchical  Reliability Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhiwu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13388" title="Abstract">arXiv:2308.13388</a> (replaced) [<a href="/pdf/2308.13388" title="Download PDF">pdf</a>, <a href="/format/2308.13388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direction-aware Video Demoireing with Temporal-guided Bilateral Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuning Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Binbin Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13772" title="Abstract">arXiv:2308.13772</a> (replaced) [<a href="/pdf/2308.13772" title="Download PDF">pdf</a>, <a href="/format/2308.13772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Residual Networks with Group Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shengji Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baopu Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weihao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14015" title="Abstract">arXiv:2308.14015</a> (replaced) [<a href="/pdf/2308.14015" title="Download PDF">pdf</a>, <a href="/format/2308.14015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yi-Feng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+R">Rui-Yao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+D">Dai-Bao Hou</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+H">Hai-Zhong Weng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bo-Wen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Ke-Jie Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xing Lin</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen-Hui Li</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+C">Chao-Yuan Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14256" title="Abstract">arXiv:2308.14256</a> (replaced) [<a href="/pdf/2308.14256" title="Download PDF">pdf</a>, <a href="/format/2308.14256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceChain: A Playground for Human-centric Artificial Intelligence  Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lei Shang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongyi He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuze Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenmeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baigui Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an ongoing work that will be consistently refined and improved upon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15799" title="Abstract">arXiv:2308.15799</a> (replaced) [<a href="/pdf/2308.15799" title="Download PDF">pdf</a>, <a href="/format/2308.15799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6G Localization and Sensing in the Near Field: Features, Opportunities,  and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Keskin%2C+M+F">Musa Furkan Keskin</a>, 
<a href="/search/cs?searchtype=author&query=Sakhnini%2C+A">Adham Sakhnini</a>, 
<a href="/search/cs?searchtype=author&query=Decarli%2C+N">Nicol&#xf3; Decarli</a>, 
<a href="/search/cs?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>, 
<a href="/search/cs?searchtype=author&query=Dardari%2C+D">Davide Dardari</a>, 
<a href="/search/cs?searchtype=author&query=Wymeersch%2C+H">Henk Wymeersch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01141" title="Abstract">arXiv:2309.01141</a> (replaced) [<a href="/pdf/2309.01141" title="Download PDF">pdf</a>, <a href="/format/2309.01141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual  Grounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yachen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honggang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02004" title="Abstract">arXiv:2309.02004</a> (replaced) [<a href="/pdf/2309.02004" title="Download PDF">pdf</a>, <a href="/format/2309.02004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reduced Magnetic Vector Potential Formulation for the Magnetic  Field Simulation of Accelerator Magnets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+L+A+M">Laura A. M. D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Moll%2C+D">Dominik Moll</a>, 
<a href="/search/cs?searchtype=author&query=Vitrano%2C+A">Andrea Vitrano</a>, 
<a href="/search/cs?searchtype=author&query=Marsic%2C+N">Nicolas Marsic</a>, 
<a href="/search/cs?searchtype=author&query=Schnaubelt%2C+E">Erik Schnaubelt</a>, 
<a href="/search/cs?searchtype=author&query=Wozniak%2C+M">Mariusz Wozniak</a>, 
<a href="/search/cs?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>, 
<a href="/search/cs?searchtype=author&query=Auchmann%2C+B">Bernhard Auchmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 13 figures, to be published in IEEE Transactions on Magnetics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03559" title="Abstract">arXiv:2309.03559</a> (replaced) [<a href="/pdf/2309.03559" title="Download PDF">pdf</a>, <a href="/format/2309.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Anchor Learning Approach for Citation Field Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zilin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Borun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yimeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03661" title="Abstract">arXiv:2309.03661</a> (replaced) [<a href="/pdf/2309.03661" title="Download PDF">pdf</a>, <a href="/format/2309.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based Context- and Domain-aware Pretraining for Vision and  Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05395" title="Abstract">arXiv:2309.05395</a> (replaced) [<a href="/pdf/2309.05395" title="Download PDF">pdf</a>, <a href="/format/2309.05395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SABLE: Secure And Byzantine robust LEarning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choffrut%2C+A">Antoine Choffrut</a>, 
<a href="/search/cs?searchtype=author&query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="/search/cs?searchtype=author&query=Pinot%2C+R">Rafael Pinot</a>, 
<a href="/search/cs?searchtype=author&query=Sirdey%2C+R">Renaud Sirdey</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+J">John Stephan</a>, 
<a href="/search/cs?searchtype=author&query=Zuber%2C+M">Martin Zuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06157" title="Abstract">arXiv:2309.06157</a> (replaced) [<a href="/pdf/2309.06157" title="Download PDF">pdf</a>, <a href="/format/2309.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for  Remaining Useful Life Prediction and Operational Condition Identification of  Rotating Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+K">Khoa Tran</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+H">Hai-Canh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Lam Pham</a>, 
<a href="/search/cs?searchtype=author&query=Boudaoud%2C+N">Nassim Boudaoud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06869" title="Abstract">arXiv:2309.06869</a> (replaced) [<a href="/pdf/2309.06869" title="Download PDF">pdf</a>, <a href="/format/2309.06869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic control of self-assembly of quasicrystalline structures through  reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lieu%2C+U+T">Uyen Tu Lieu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yoshinaga%2C+N">Natsuhiko Yoshinaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures. For Supplementary Information, please download file listed under "Ancillary files"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07377" title="Abstract">arXiv:2309.07377</a> (replaced) [<a href="/pdf/2309.07377" title="Download PDF">pdf</a>, <a href="/format/2309.07377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07579" title="Abstract">arXiv:2309.07579</a> (replaced) [<a href="/pdf/2309.07579" title="Download PDF">pdf</a>, <a href="/format/2309.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Transformers for Sequences of SPD Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seraphim%2C+M">Mathieu Seraphim</a>, 
<a href="/search/cs?searchtype=author&query=Lechervy%2C+A">Alexis Lechervy</a>, 
<a href="/search/cs?searchtype=author&query=Yger%2C+F">Florian Yger</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+L">Luc Brun</a>, 
<a href="/search/cs?searchtype=author&query=Etard%2C+O">Olivier Etard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Removed copyright header present in previous version (no longer relevant)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08628" title="Abstract">arXiv:2309.08628</a> (replaced) [<a href="/pdf/2309.08628" title="Download PDF">pdf</a>, <a href="/format/2309.08628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering from Privacy-Preserving Masking with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+A">Arpita Vats</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Peng Su</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Debjyoti Paul</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yutong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Z">Zeeshan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11599" title="Abstract">arXiv:2309.11599</a> (replaced) [<a href="/pdf/2309.11599" title="Download PDF">pdf</a>, <a href="/format/2309.11599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadoma%2C+K">Kowe Kadoma</a>, 
<a href="/search/cs?searchtype=author&query=Quere%2C+M+A+L">Marianne Aubin Le Quere</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jenny Fu</a>, 
<a href="/search/cs?searchtype=author&query=Munsch%2C+C">Christin Munsch</a>, 
<a href="/search/cs?searchtype=author&query=Metaxa%2C+D">Danae Metaxa</a>, 
<a href="/search/cs?searchtype=author&query=Naaman%2C+M">Mor Naaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11814" title="Abstract">arXiv:2309.11814</a> (replaced) [<a href="/pdf/2309.11814" title="Download PDF">pdf</a>, <a href="/format/2309.11814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Micromechanics-Informed Parametric Deep Material Network for Physics  Behavior Prediction of Heterogeneous Materials with a Varying Morphology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyi Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering 419 (2024)
  116687
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13672" title="Abstract">arXiv:2309.13672</a> (replaced) [<a href="/pdf/2309.13672" title="Download PDF">pdf</a>, <a href="/format/2309.13672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Image-to-Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chengming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14780" title="Abstract">arXiv:2309.14780</a> (replaced) [<a href="/pdf/2309.14780" title="Download PDF">pdf</a>, <a href="/ps/2309.14780" title="Download PostScript">ps</a>, <a href="/format/2309.14780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring climate change knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Immorlano%2C+F">Francesco Immorlano</a>, 
<a href="/search/physics?searchtype=author&query=Eyring%2C+V">Veronika Eyring</a>, 
<a href="/search/physics?searchtype=author&query=de+Gouville%2C+T+l+M">Thomas le Monnier de Gouville</a>, 
<a href="/search/physics?searchtype=author&query=Accarino%2C+G">Gabriele Accarino</a>, 
<a href="/search/physics?searchtype=author&query=Elia%2C+D">Donatello Elia</a>, 
<a href="/search/physics?searchtype=author&query=Aloisio%2C+G">Giovanni Aloisio</a>, 
<a href="/search/physics?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15112" title="Abstract">arXiv:2309.15112</a> (replaced) [<a href="/pdf/2309.15112" title="Download PDF">pdf</a>, <a href="/format/2309.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternLM-XComposer: A Vision-Language Large Model for Advanced  Text-image Comprehension and Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haodong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuangrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models are available at <a href="https://github.com/InternLM/InternLM-XComposer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00268" title="Abstract">arXiv:2310.00268</a> (replaced) [<a href="/pdf/2310.00268" title="Download PDF">pdf</a>, <a href="/format/2310.00268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unravel Anomalies: An End-to-end Seasonal-Trend Decomposition Approach  for Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ran Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuantao Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 14-19 April 2024 in Seoul, Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01794" title="Abstract">arXiv:2310.01794</a> (replaced) [<a href="/pdf/2310.01794" title="Download PDF">pdf</a>, <a href="/format/2310.01794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers  through In-depth Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosan%2C+M">Mert Kosan</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Samidha Verma</a>, 
<a href="/search/cs?searchtype=author&query=Armgaan%2C+B">Burouj Armgaan</a>, 
<a href="/search/cs?searchtype=author&query=Pahwa%2C+K">Khushbu Pahwa</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ambuj Singh</a>, 
<a href="/search/cs?searchtype=author&query=Medya%2C+S">Sourav Medya</a>, 
<a href="/search/cs?searchtype=author&query=Ranu%2C+S">Sayan Ranu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02207" title="Abstract">arXiv:2310.02207</a> (replaced) [<a href="/pdf/2310.02207" title="Download PDF">pdf</a>, <a href="/format/2310.02207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models Represent Space and Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurnee%2C+W">Wes Gurnee</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02299" title="Abstract">arXiv:2310.02299</a> (replaced) [<a href="/pdf/2310.02299" title="Download PDF">pdf</a>, <a href="/format/2310.02299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Symmetry Breaking in Physical Systems with Relaxed Group  Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Han Gao</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Smidt%2C+T+E">Tess E.Smidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03175" title="Abstract">arXiv:2310.03175</a> (replaced) [<a href="/pdf/2310.03175" title="Download PDF">pdf</a>, <a href="/format/2310.03175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impedance Leakage Vulnerability and its Utilization in  Reverse-engineering Embedded Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Awal%2C+M+S">Md Sadik Awal</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+T">Md Tauhidur Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04086" title="Abstract">arXiv:2310.04086</a> (replaced) [<a href="/pdf/2310.04086" title="Download PDF">pdf</a>, <a href="/format/2310.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Chess Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masouris%2C+A">Athanasios Masouris</a>, 
<a href="/search/cs?searchtype=author&query=van+Gemert%2C+J">Jan van Gemert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04723" title="Abstract">arXiv:2310.04723</a> (replaced) [<a href="/pdf/2310.04723" title="Download PDF">pdf</a>, <a href="/format/2310.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace Identification for Multi-Source Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruichu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Boyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05804" title="Abstract">arXiv:2310.05804</a> (replaced) [<a href="/pdf/2310.05804" title="Download PDF">pdf</a>, <a href="/format/2310.05804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Language-guided Adaptive Hyper-modality Representation for  Multimodal Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+G">Guanghao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kejun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianshu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in EMNLP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 Conference on Empirical Methods in Natural
  Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06372" title="Abstract">arXiv:2310.06372</a> (replaced) [<a href="/pdf/2310.06372" title="Download PDF">pdf</a>, <a href="/format/2310.06372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Diffusion-Based Image Variations for Robust Training on  Poisoned Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="/search/cs?searchtype=author&query=Hentschel%2C+M+B">Martin B. Hentschel</a>, 
<a href="/search/cs?searchtype=author&query=Poth%2C+C">Clifton Poth</a>, 
<a href="/search/cs?searchtype=author&query=Hintersdorf%2C+D">Dominik Hintersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06470" title="Abstract">arXiv:2310.06470</a> (replaced) [<a href="/pdf/2310.06470" title="Download PDF">pdf</a>, <a href="/format/2310.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Local Regions for Query-based Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yamei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bo Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08349" title="Abstract">arXiv:2310.08349</a> (replaced) [<a href="/pdf/2310.08349" title="Download PDF">pdf</a>, <a href="/format/2310.08349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performativity and Prospective Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zezulka%2C+S">Sebastian Zezulka</a>, 
<a href="/search/cs?searchtype=author&query=Genin%2C+K">Konstantin Genin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08820" title="Abstract">arXiv:2310.08820</a> (replaced) [<a href="/pdf/2310.08820" title="Download PDF">pdf</a>, <a href="/format/2310.08820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Adapt SAM for Segmenting Cross-domain Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xidong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+F">Feng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09693" title="Abstract">arXiv:2310.09693</a> (replaced) [<a href="/pdf/2310.09693" title="Download PDF">pdf</a>, <a href="/ps/2310.09693" title="Download PostScript">ps</a>, <a href="/format/2310.09693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence of Acceleration and Deceleration Capability on Machine Tool  Feed System Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Dongsheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10158" title="Abstract">arXiv:2310.10158</a> (replaced) [<a href="/pdf/2310.10158" title="Download PDF">pdf</a>, <a href="/format/2310.10158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character-LLM: A Trainable Agent for Role-Playing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunfan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Junqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP 2023; Repo at <a href="https://github.com/choosewhatulike/trainable-agents">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10605" title="Abstract">arXiv:2310.10605</a> (replaced) [<a href="/pdf/2310.10605" title="Download PDF">pdf</a>, <a href="/ps/2310.10605" title="Download PostScript">ps</a>, <a href="/format/2310.10605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ForceGen: End-to-end de novo protein generation based on nonlinear  mechanical unfolding responses using a language diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ni%2C+B">Bo Ni</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kaplan%2C+D+L">David L. Kaplan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Buehler%2C+M+J">Markus J. Buehler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Computation and Language (cs.CL); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11234" title="Abstract">arXiv:2310.11234</a> (replaced) [<a href="/pdf/2310.11234" title="Download PDF">pdf</a>, <a href="/format/2310.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging of nonlinear materials via the Monotonicity Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mottola%2C+V">Vincenzo Mottola</a>, 
<a href="/search/math?searchtype=author&query=Esposito%2C+A+C">Antonio Corbo Esposito</a>, 
<a href="/search/math?searchtype=author&query=Piscitelli%2C+G">Gianpaolo Piscitelli</a>, 
<a href="/search/math?searchtype=author&query=Tamburrino%2C+A">Antonello Tamburrino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11648" title="Abstract">arXiv:2310.11648</a> (replaced) [<a href="/pdf/2310.11648" title="Download PDF">pdf</a>, <a href="/format/2310.11648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Faithfulness Evaluation for Text Summarization with Foundation  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12103" title="Abstract">arXiv:2310.12103</a> (replaced) [<a href="/pdf/2310.12103" title="Download PDF">pdf</a>, <a href="/format/2310.12103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality Diversity through Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jenny Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Clune%2C+J">Jeff Clune</a>, 
<a href="/search/cs?searchtype=author&query=Spector%2C+L">Lee Spector</a>, 
<a href="/search/cs?searchtype=author&query=Lehman%2C+J">Joel Lehman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023: ALOE Workshop (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13637" title="Abstract">arXiv:2310.13637</a> (replaced) [<a href="/pdf/2310.13637" title="Download PDF">pdf</a>, <a href="/ps/2310.13637" title="Download PostScript">ps</a>, <a href="/format/2310.13637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application Performance Benchmarks for Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurowski%2C+K">Krzysztof Kurowski</a>, 
<a href="/search/cs?searchtype=author&query=Rydlichowski%2C+P">Piotr Rydlichowski</a>, 
<a href="/search/cs?searchtype=author&query=Wojciechowski%2C+K">Konrad Wojciechowski</a>, 
<a href="/search/cs?searchtype=author&query=Pecyna%2C+T">Tomasz Pecyna</a>, 
<a href="/search/cs?searchtype=author&query=Slysz%2C+M">Mateusz Slysz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15140" title="Abstract">arXiv:2310.15140</a> (replaced) [<a href="/pdf/2310.15140" title="Download PDF">pdf</a>, <a href="/format/2310.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Sicheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bang An</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Barrow%2C+J">Joe Barrow</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nenkova%2C+A">Ani Nenkova</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2 updates: Added comparison of three more evaluation methods and their reliability check using human labeling. Added results for jailbreaking Llama2 (individual behavior) and included complexity and hyperparameter analysis. Revised objectives for prompt leaking. Other minor changes made
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15517" title="Abstract">arXiv:2310.15517</a> (replaced) [<a href="/pdf/2310.15517" title="Download PDF">pdf</a>, <a href="/format/2310.15517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MarkQA: A large scale KBQA dataset with numerical reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sitao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yuheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shanshan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuzhong Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 main conference. Code: <a href="https://github.com/cdhx/MarkQA">this https URL</a> Homepage: <a href="http://ws.nju.edu.cn/MarkQA">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16121" title="Abstract">arXiv:2310.16121</a> (replaced) [<a href="/pdf/2310.16121" title="Download PDF">pdf</a>, <a href="/format/2310.16121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Bogatskiy%2C+A">Alexander Bogatskiy</a>, 
<a href="/search/hep-ph?searchtype=author&query=Hoffman%2C+T">Timothy Hoffman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Offermann%2C+J+T">Jan T. Offermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to the "Machine Learning and the Physical Sciences" NeurIPS 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18168" title="Abstract">arXiv:2310.18168</a> (replaced) [<a href="/pdf/2310.18168" title="Download PDF">pdf</a>, <a href="/format/2310.18168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personas as a Way to Model Truthfulness in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+N">Nitish Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Rando%2C+J">Javier Rando</a>, 
<a href="/search/cs?searchtype=author&query=Saparov%2C+A">Abulhair Saparov</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Najoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18893" title="Abstract">arXiv:2310.18893</a> (replaced) [<a href="/pdf/2310.18893" title="Download PDF">pdf</a>, <a href="/format/2310.18893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ever Evolving Evaluator (EV3): Towards Flexible and Reliable  Meta-Optimization for Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zoghi%2C+M">Masrour Zoghi</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+G">Guy Tennenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Karimzadehgan%2C+M">Maryam Karimzadehgan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World (RealML)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19704" title="Abstract">arXiv:2310.19704</a> (replaced) [<a href="/pdf/2310.19704" title="Download PDF">pdf</a>, <a href="/format/2310.19704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Knowledge Editing of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazzia%2C+V">Vittorio Mazzia</a>, 
<a href="/search/cs?searchtype=author&query=Pedrani%2C+A">Alessandro Pedrani</a>, 
<a href="/search/cs?searchtype=author&query=Caciolai%2C+A">Andrea Caciolai</a>, 
<a href="/search/cs?searchtype=author&query=Rottmann%2C+K">Kay Rottmann</a>, 
<a href="/search/cs?searchtype=author&query=Bernardi%2C+D">Davide Bernardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20092" title="Abstract">arXiv:2310.20092</a> (replaced) [<a href="/pdf/2310.20092" title="Download PDF">pdf</a>, <a href="/format/2310.20092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond U: Making Diffusion Models Faster &amp; Lighter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calvo-Ordonez%2C+S">Sergio Calvo-Ordonez</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lipei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Schonlieb%2C+C">Carola-Bibiane Schonlieb</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I Aviles-Rivero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, Neural Information Processing Systems (NeurIPS) 2023 Workshop on Diffusion Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00961" title="Abstract">arXiv:2311.00961</a> (replaced) [<a href="/pdf/2311.00961" title="Download PDF">pdf</a>, <a href="/format/2311.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concatenated Masked Autoencoders as Spatial-Temporal Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhouqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhaofeng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangshun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/minhoooo1/CatMAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01683" title="Abstract">arXiv:2311.01683</a> (replaced) [<a href="/pdf/2311.01683" title="Download PDF">pdf</a>, <a href="/ps/2311.01683" title="Download PostScript">ps</a>, <a href="/format/2311.01683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amide Proton Transfer (APT) imaging in tumor with a machine learning  approach using partially synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Viswanathan%2C+M">Malvika Viswanathan</a>, 
<a href="/search/physics?searchtype=author&query=Yin%2C+L">Leqi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Kurmi%2C+Y">Yashwant Kurmi</a>, 
<a href="/search/physics?searchtype=author&query=Zu%2C+Z">Zhongliang Zu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated Supporting Information typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02558" title="Abstract">arXiv:2311.02558</a> (replaced) [<a href="/pdf/2311.02558" title="Download PDF">pdf</a>, <a href="/format/2311.02558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity  with Free-Flying Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+H">Holly Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J">Jamie Santos</a>, 
<a href="/search/cs?searchtype=author&query=Albee%2C+K">Keenan Albee</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+P">Paulo Borges</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+M">Marina Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+O">Oleg Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Coltin%2C+B">Brian Coltin</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+T">Trey Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, Manuscript presented at the 74th International Astronautical Congress, IAC 2023, Baku, Azerbaijan, 2 - 6 October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03424" title="Abstract">arXiv:2311.03424</a> (replaced) [<a href="/pdf/2311.03424" title="Download PDF">pdf</a>, <a href="/ps/2311.03424" title="Download PostScript">ps</a>, <a href="/format/2311.03424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Symmetries to Lift Satisfiability Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carbonnelle%2C+P">Pierre Carbonnelle</a>, 
<a href="/search/cs?searchtype=author&query=Schenner%2C+G">Gottfried Schenner</a>, 
<a href="/search/cs?searchtype=author&query=Bruynooghe%2C+M">Maurice Bruynooghe</a>, 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Denecker%2C+M">Marc Denecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03731" title="Abstract">arXiv:2311.03731</a> (replaced) [<a href="/pdf/2311.03731" title="Download PDF">pdf</a>, <a href="/format/2311.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zetian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinshuo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Aiguo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03828" title="Abstract">arXiv:2311.03828</a> (replaced) [<a href="/pdf/2311.03828" title="Download PDF">pdf</a>, <a href="/format/2311.03828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Information Integration and Propagation for Occluded Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Information Fusion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04915" title="Abstract">arXiv:2311.04915</a> (replaced) [<a href="/pdf/2311.04915" title="Download PDF">pdf</a>, <a href="/ps/2311.04915" title="Download PostScript">ps</a>, <a href="/format/2311.04915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Empathy: Enhancing Empathetic Response of Large Language Models  Based on Psychotherapy Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+K">Yoon Kyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Inju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Minjung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Seoyeon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+S">Sowon Hahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06497" title="Abstract">arXiv:2311.06497</a> (replaced) [<a href="/pdf/2311.06497" title="Download PDF">pdf</a>, <a href="/format/2311.06497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRUformer: Enhancing the driving scene Important object detection with  driving relationship self-understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yingjie Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Ohtani%2C+K">Kento Ohtani</a>, 
<a href="/search/cs?searchtype=author&query=Carballo%2C+A">Alexander Carballo</a>, 
<a href="/search/cs?searchtype=author&query=Takeda%2C+K">Kazuya Takeda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08141" title="Abstract">arXiv:2311.08141</a> (replaced) [<a href="/pdf/2311.08141" title="Download PDF">pdf</a>, <a href="/format/2311.08141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMTR: Graph Matching Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08945" title="Abstract">arXiv:2311.08945</a> (replaced) [<a href="/pdf/2311.08945" title="Download PDF">pdf</a>, <a href="/format/2311.08945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Single-Loop Algorithm for Decentralized Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+Y">Youran Dong</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Shiqian Ma</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Junfeng Yang</a>, 
<a href="/search/math?searchtype=author&query=Yin%2C+C">Chao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09118" title="Abstract">arXiv:2311.09118</a> (replaced) [<a href="/pdf/2311.09118" title="Download PDF">pdf</a>, <a href="/format/2311.09118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WildlifeDatasets: An open-source toolkit for animal re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%8Cerm%C3%A1k%2C+V">Vojt&#x11b;ch &#x10c;erm&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+L">Lukas Picek</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+L">Luk&#xe1;&#x161; Adam</a>, 
<a href="/search/cs?searchtype=author&query=Papafitsoros%2C+K">Kostas Papafitsoros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11473" title="Abstract">arXiv:2311.11473</a> (replaced) [<a href="/e-print/2311.11473" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zongsheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For the privacy issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12133" title="Abstract">arXiv:2311.12133</a> (replaced) [<a href="/pdf/2311.12133" title="Download PDF">pdf</a>, <a href="/format/2311.12133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-performance Effective Scientific Error-bounded Lossy Compression  with Auto-tuned Multi-component Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+Z">Zizhe Jian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiajun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shixun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Engineering, Finance, and Science (cs.CE); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12304" title="Abstract">arXiv:2311.12304</a> (replaced) [<a href="/pdf/2311.12304" title="Download PDF">pdf</a>, <a href="/format/2311.12304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Effective Policies for Land-Use Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miikkulainen%2C+R">Risto Miikkulainen</a>, 
<a href="/search/cs?searchtype=author&query=Francon%2C+O">Olivier Francon</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+D">Daniel Young</a>, 
<a href="/search/cs?searchtype=author&query=Meyerson%2C+E">Elliot Meyerson</a>, 
<a href="/search/cs?searchtype=author&query=Bieker%2C+J">Jacob Bieker</a>, 
<a href="/search/cs?searchtype=author&query=Cunha%2C+H">Hugo Cunha</a>, 
<a href="/search/cs?searchtype=author&query=Hodjat%2C+B">Babak Hodjat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12342" title="Abstract">arXiv:2311.12342</a> (replaced) [<a href="/pdf/2311.12342" title="Download PDF">pdf</a>, <a href="/format/2311.12342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruiyang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://peiang-zhao.tech/LoCo/">this https URL</a> ;10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12733" title="Abstract">arXiv:2311.12733</a> (replaced) [<a href="/pdf/2311.12733" title="Download PDF">pdf</a>, <a href="/format/2311.12733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not Just Training, Also Testing: High School Youths&#x27; Perspective-Taking  through Peer Testing Machine Learning-Powered Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morales-Navarro%2C+L">L. Morales-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">M. Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kafai%2C+Y+B">Y. B. Kafai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13018" title="Abstract">arXiv:2311.13018</a> (replaced) [<a href="/pdf/2311.13018" title="Download PDF">pdf</a>, <a href="/format/2311.13018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoLocator: a location-integrated large multimodal model for inferring  geo-privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuju Sun</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Junhong Duan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junzhou He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14294" title="Abstract">arXiv:2311.14294</a> (replaced) [<a href="/pdf/2311.14294" title="Download PDF">pdf</a>, <a href="/format/2311.14294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decouple Content and Motion for Conditional Image-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cuifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yulu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiongwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lele Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tingting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinzhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14388" title="Abstract">arXiv:2311.14388</a> (replaced) [<a href="/pdf/2311.14388" title="Download PDF">pdf</a>, <a href="/format/2311.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parameterized Generative Adversarial Network Using Cyclic Projection  for Explainable Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiangyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+C">Chan-Tong Lam</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+T">Tong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qinquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures. This work has been submitted to the IEEE ICASSP for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14483" title="Abstract">arXiv:2311.14483</a> (replaced) [<a href="/pdf/2311.14483" title="Download PDF">pdf</a>, <a href="/format/2311.14483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SER_AMPEL: a multi-source dataset for speech emotion recognition of  Italian older adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grossi%2C+A">Alessandra Grossi</a>, 
<a href="/search/eess?searchtype=author&query=Gasparini%2C+F">Francesca Gasparini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 Figure, 7 Tables, submitted to ForItAAL 2023 (12{\deg} Forum Italiano Ambient Assisted Living)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15939" title="Abstract">arXiv:2311.15939</a> (replaced) [<a href="/pdf/2311.15939" title="Download PDF">pdf</a>, <a href="/format/2311.15939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Prompt-driven Nucleus Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shui%2C+Z">Zhongyi Shui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16045" title="Abstract">arXiv:2311.16045</a> (replaced) [<a href="/pdf/2311.16045" title="Download PDF">pdf</a>, <a href="/format/2311.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal Lie-Poisson discretization for incompressible  magnetohydrodynamics on the sphere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Modin%2C+K">Klas Modin</a>, 
<a href="/search/math?searchtype=author&query=Roop%2C+M">Michael Roop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, figures and typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16146" title="Abstract">arXiv:2311.16146</a> (replaced) [<a href="/pdf/2311.16146" title="Download PDF">pdf</a>, <a href="/ps/2311.16146" title="Download PostScript">ps</a>, <a href="/format/2311.16146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emulators in JINSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+L">Lv Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16516" title="Abstract">arXiv:2311.16516</a> (replaced) [<a href="/pdf/2311.16516" title="Download PDF">pdf</a>, <a href="/format/2311.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Every Out-of-Distribution Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17135" title="Abstract">arXiv:2311.17135</a> (replaced) [<a href="/pdf/2311.17135" title="Download PDF">pdf</a>, <a href="/format/2311.17135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLControl: Trajectory and Language Control for Human Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+D">Dinesh Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17516" title="Abstract">arXiv:2311.17516</a> (replaced) [<a href="/pdf/2311.17516" title="Download PDF">pdf</a>, <a href="/format/2311.17516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMA-Diffusion: MultiModal Attack on Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17559" title="Abstract">arXiv:2311.17559</a> (replaced) [<a href="/pdf/2311.17559" title="Download PDF">pdf</a>, <a href="/ps/2311.17559" title="Download PostScript">ps</a>, <a href="/format/2311.17559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizations of Weighted Generalized Inverses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sitha%2C+B">Bibekananda Sitha</a>, 
<a href="/search/math?searchtype=author&query=Behera%2C+R">Ratikanta Behera</a>, 
<a href="/search/math?searchtype=author&query=Sahoo%2C+J+K">Jajati Keshari Sahoo</a>, 
<a href="/search/math?searchtype=author&query=Mohapatra%2C+R+N">R. N. Mohapatra</a>, 
<a href="/search/math?searchtype=author&query=Stanimirovic%2C+P">Predrag Stanimirovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17804" title="Abstract">arXiv:2311.17804</a> (replaced) [<a href="/pdf/2311.17804" title="Download PDF">pdf</a>, <a href="/format/2311.17804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregation Model Hyperparameters Matter in Digital Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bredell%2C+G">Gustav Bredell</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marcel Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Szostak%2C+P">Przemyslaw Szostak</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi-Sureshjani%2C+S">Samaneh Abbasi-Sureshjani</a>, 
<a href="/search/cs?searchtype=author&query=Gomariz%2C+A">Alvaro Gomariz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18044" title="Abstract">arXiv:2311.18044</a> (replaced) [<a href="/pdf/2311.18044" title="Download PDF">pdf</a>, <a href="/format/2311.18044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning in Robotics: An Upcoming Breakthrough? A Review of  Promises and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaquier%2C+N">No&#xe9;mie Jaquier</a>, 
<a href="/search/cs?searchtype=author&query=Welle%2C+M+C">Michael C. Welle</a>, 
<a href="/search/cs?searchtype=author&query=Gams%2C+A">Andrej Gams</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kunpeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Fichera%2C+B">Bernardo Fichera</a>, 
<a href="/search/cs?searchtype=author&query=Billard%2C+A">Aude Billard</a>, 
<a href="/search/cs?searchtype=author&query=Ude%2C+A">Ale&#x161; Ude</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18126" title="Abstract">arXiv:2311.18126</a> (replaced) [<a href="/pdf/2311.18126" title="Download PDF">pdf</a>, <a href="/format/2311.18126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisMech: A Discrete Differential Geometry-based Physical Simulator for  Soft Robots and Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+A">Andrew Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+R">Ran Jing</a>, 
<a href="/search/cs?searchtype=author&query=Sabelhaus%2C+A">Andrew Sabelhaus</a>, 
<a href="/search/cs?searchtype=author&query=Jawed%2C+M+K">Mohammad Khalid Jawed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18259" title="Abstract">arXiv:2311.18259</a> (replaced) [<a href="/pdf/2311.18259" title="Download PDF">pdf</a>, <a href="/format/2311.18259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ego-Exo4D: Understanding Skilled Human Activity from First- and  Third-Person Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>, 
<a href="/search/cs?searchtype=author&query=Westbury%2C+A">Andrew Westbury</a>, 
<a href="/search/cs?searchtype=author&query=Torresani%2C+L">Lorenzo Torresani</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Afouras%2C+T">Triantafyllos Afouras</a>, 
<a href="/search/cs?searchtype=author&query=Ashutosh%2C+K">Kumar Ashutosh</a>, 
<a href="/search/cs?searchtype=author&query=Baiyya%2C+V">Vijay Baiyya</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Siddhant Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Boote%2C+B">Bikram Boote</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+E">Eugene Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Chavis%2C+Z">Zach Chavis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Joya Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Feng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+F">Fu-Jen Chu</a>, 
<a href="/search/cs?searchtype=author&query=Crane%2C+S">Sean Crane</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+A">Avijit Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Escobar%2C+M">Maria Escobar</a>, 
<a href="/search/cs?searchtype=author&query=Forigua%2C+C">Cristhian Forigua</a>, 
<a href="/search/cs?searchtype=author&query=Gebreselasie%2C+A">Abrham Gebreselasie</a>, 
<a href="/search/cs?searchtype=author&query=Haresh%2C+S">Sanjay Haresh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Suyog Jain</a>, 
<a href="/search/cs?searchtype=author&query=Khirodkar%2C+R">Rawal Khirodkar</a>, 
<a href="/search/cs?searchtype=author&query=Kukreja%2C+D">Devansh Kukreja</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K+J">Kevin J Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+S">Sagnik Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongsen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Miguel Martin</a>, 
<a href="/search/cs?searchtype=author&query=Mavroudi%2C+E">Effrosyni Mavroudi</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Ragusa%2C+F">Francesco Ragusa</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+S+K">Santhosh Kumar Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Seminara%2C+L">Luigi Seminara</a>, 
<a href="/search/cs?searchtype=author&query=Somayazulu%2C+A">Arjun Somayazulu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yale Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shan Su</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zihui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Edward Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+A">Angela Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinzhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+R">Ryosuke Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C">Cristina Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Prince Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiabo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Khoo%2C+W">Weslie Khoo</a>,  et al. (48 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated baseline results to match the released data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18274" title="Abstract">arXiv:2311.18274</a> (replaced) [<a href="/pdf/2311.18274" title="Download PDF">pdf</a>, <a href="/format/2311.18274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiparametric Efficient Inference in Adaptive Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cook%2C+T">Thomas Cook</a>, 
<a href="/search/stat?searchtype=author&query=Mishler%2C+A">Alan Mishler</a>, 
<a href="/search/stat?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00265" title="Abstract">arXiv:2312.00265</a> (replaced) [<a href="/pdf/2312.00265" title="Download PDF">pdf</a>, <a href="/format/2312.00265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboSync: Efficient Real-Time Operating System for Social Robots with  Customizable Behaviour
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Cheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yijing Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00856" title="Abstract">arXiv:2312.00856</a> (replaced) [<a href="/pdf/2312.00856" title="Download PDF">pdf</a>, <a href="/format/2312.00856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAFE-Net: Quality Assessment of Facial Expressions with Landmark  Heatmaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shuchao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Dadashzadeh%2C+A">Amirhossein Dadashzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Whone%2C+A">Alan Whone</a>, 
<a href="/search/cs?searchtype=author&query=Mirmehdi%2C+M">Majid Mirmehdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ELFA workshop at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00878" title="Abstract">arXiv:2312.00878</a> (replaced) [<a href="/pdf/2312.00878" title="Download PDF">pdf</a>, <a href="/format/2312.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Everything: Emerging Localization Properties in  Vision-Language Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousselham%2C+W">Walid Bousselham</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+F">Felix Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Vittorio Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/WalBouss/GEM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01397" title="Abstract">arXiv:2312.01397</a> (replaced) [<a href="/pdf/2312.01397" title="Download PDF">pdf</a>, <a href="/format/2312.01397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Prompting Upgrades Neural Network Sparsification: A Data-Model  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Can Jin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01878" title="Abstract">arXiv:2312.01878</a> (replaced) [<a href="/pdf/2312.01878" title="Download PDF">pdf</a>, <a href="/format/2312.01878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02027" title="Abstract">arXiv:2312.02027</a> (replaced) [<a href="/pdf/2312.02027" title="Download PDF">pdf</a>, <a href="/format/2312.02027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Optimal Control Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Domingo-Enrich%2C+C">Carles Domingo-Enrich</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+J">Jiequn Han</a>, 
<a href="/search/math?searchtype=author&query=Amos%2C+B">Brandon Amos</a>, 
<a href="/search/math?searchtype=author&query=Bruna%2C+J">Joan Bruna</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02252" title="Abstract">arXiv:2312.02252</a> (replaced) [<a href="/pdf/2312.02252" title="Download PDF">pdf</a>, <a href="/format/2312.02252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StoryGPT-V: Large Language Models as Consistent Story Visualizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoqian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://xiaoqian-shen.github.io/StoryGPT-V">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03404" title="Abstract">arXiv:2312.03404</a> (replaced) [<a href="/pdf/2312.03404" title="Download PDF">pdf</a>, <a href="/format/2312.03404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyclical Route Linking Fundamental Mechanism and AI Algorithm: An  Example from Poisson&#x27;s Ratio in Amorphous Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zhu%2C+C">Changliang Zhu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fang%2C+C">Chenchao Fang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jin%2C+Z">Zhipeng Jin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+B">Baowen Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+X">Xiangying Shen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+L">Lei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03664" title="Abstract">arXiv:2312.03664</a> (replaced) [<a href="/pdf/2312.03664" title="Download PDF">pdf</a>, <a href="/format/2312.03664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative agent-based modeling with actions grounded in physical,  social, or digital space using Concordia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vezhnevets%2C+A+S">Alexander Sasha Vezhnevets</a>, 
<a href="/search/cs?searchtype=author&query=Agapiou%2C+J+P">John P. Agapiou</a>, 
<a href="/search/cs?searchtype=author&query=Aharon%2C+A">Avia Aharon</a>, 
<a href="/search/cs?searchtype=author&query=Ziv%2C+R">Ron Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Matyas%2C+J">Jayd Matyas</a>, 
<a href="/search/cs?searchtype=author&query=Du%C3%A9%C3%B1ez-Guzm%C3%A1n%2C+E+A">Edgar A. Du&#xe9;&#xf1;ez-Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+W+A">William A. Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Osindero%2C+S">Simon Osindero</a>, 
<a href="/search/cs?searchtype=author&query=Karmon%2C+D">Danny Karmon</a>, 
<a href="/search/cs?searchtype=author&query=Leibo%2C+J+Z">Joel Z. Leibo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03731" title="Abstract">arXiv:2312.03731</a> (replaced) [<a href="/pdf/2312.03731" title="Download PDF">pdf</a>, <a href="/format/2312.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03818" title="Abstract">arXiv:2312.03818</a> (replaced) [<a href="/pdf/2312.03818" title="Download PDF">pdf</a>, <a href="/format/2312.03818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alpha-CLIP: A CLIP Model Focusing on Wherever You Want
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Ye Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yuhang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuanjun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://aleafy.github.io/alpha-clip">this https URL</a> code: <a href="https://github.com/SunzeY/AlphaCLIP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04070" title="Abstract">arXiv:2312.04070</a> (replaced) [<a href="/pdf/2312.04070" title="Download PDF">pdf</a>, <a href="/format/2312.04070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transformer Model for Symbolic Regression towards Scientific Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalande%2C+F">Florian Lalande</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Taniai%2C+T">Tatsunori Taniai</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+R">Ryo Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at NeurIPS2023 AI4Science Workshop. OpenReview: <a href="https://openreview.net/forum?id=AIfqWNHKjo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04265" title="Abstract">arXiv:2312.04265</a> (replaced) [<a href="/pdf/2312.04265" title="Download PDF">pdf</a>, <a href="/format/2312.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for  Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianle Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pengyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinjin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04333" title="Abstract">arXiv:2312.04333</a> (replaced) [<a href="/pdf/2312.04333" title="Download PDF">pdf</a>, <a href="/format/2312.04333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Surface: Probing LLaMA Across Scales and Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shining Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04386" title="Abstract">arXiv:2312.04386</a> (replaced) [<a href="/pdf/2312.04386" title="Download PDF">pdf</a>, <a href="/format/2312.04386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Epistemic Variance of Values for Risk-Aware Policy  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luis%2C+C+E">Carlos E. Luis</a>, 
<a href="/search/cs?searchtype=author&query=Bottero%2C+A+G">Alessandro G. Bottero</a>, 
<a href="/search/cs?searchtype=author&query=Vinogradska%2C+J">Julia Vinogradska</a>, 
<a href="/search/cs?searchtype=author&query=Berkenkamp%2C+F">Felix Berkenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12526">arXiv:2302.12526</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04956" title="Abstract">arXiv:2312.04956</a> (replaced) [<a href="/pdf/2312.04956" title="Download PDF">pdf</a>, <a href="/format/2312.04956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stacked ensemble learning IDS model for Software-defined VANET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+S+I">Shakil Ibne Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=Legg%2C+P">Phil Legg</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S+M+I">S M Iftekharul Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05284" title="Abstract">arXiv:2312.05284</a> (replaced) [<a href="/pdf/2312.05284" title="Download PDF">pdf</a>, <a href="/format/2312.05284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 0.1% Data Makes Segment Anything Slim
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zigeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Code reposity: url{<a href="http://github.com/czg1225/SlimSAM">this http URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05476" title="Abstract">arXiv:2312.05476</a> (replaced) [<a href="/pdf/2312.05476" title="Download PDF">pdf</a>, <a href="/format/2312.05476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Naturalness of AI-Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05497" title="Abstract">arXiv:2312.05497</a> (replaced) [<a href="/pdf/2312.05497" title="Download PDF">pdf</a>, <a href="/format/2312.05497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History Matters: Temporal Knowledge Editing in Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunjian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05955" title="Abstract">arXiv:2312.05955</a> (replaced) [<a href="/pdf/2312.05955" title="Download PDF">pdf</a>, <a href="/format/2312.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Differentiable Particle Filter on the Fly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06036" title="Abstract">arXiv:2312.06036</a> (replaced) [<a href="/pdf/2312.06036" title="Download PDF">pdf</a>, <a href="/format/2312.06036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks: towards impactful challenges with  post-challenge papers, benchmarks and other dissemination actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marot%2C+A">Antoine Marot</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+D">David Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhen Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5th chapter of book "AI Competitions and Benchmarks: the science behind the contests" see: <a href="https://sites.google.com/chalearn.org/book/home">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06528" title="Abstract">arXiv:2312.06528</a> (replaced) [<a href="/pdf/2312.06528" title="Download PDF">pdf</a>, <a href="/format/2312.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers Implement Functional Gradient Descent to Learn Non-Linear  Functions In Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sra%2C+S">Suvrit Sra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06720" title="Abstract">arXiv:2312.06720</a> (replaced) [<a href="/pdf/2312.06720" title="Download PDF">pdf</a>, <a href="/format/2312.06720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual LLM for Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Fangxun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06723" title="Abstract">arXiv:2312.06723</a> (replaced) [<a href="/pdf/2312.06723" title="Download PDF">pdf</a>, <a href="/format/2312.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to See Low-Light Images via Feature Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06726" title="Abstract">arXiv:2312.06726</a> (replaced) [<a href="/pdf/2312.06726" title="Download PDF">pdf</a>, <a href="/format/2312.06726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compress &amp; Align: Curating Image-Text Data with Human Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Fangxun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sucheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06733" title="Abstract">arXiv:2312.06733</a> (replaced) [<a href="/pdf/2312.06733" title="Download PDF">pdf</a>, <a href="/format/2312.06733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TULIP: Transformer for Upsampling of LiDAR Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pfreundschuh%2C+P">Patrick Pfreundschuh</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+V">Vaishakh Patil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06887" title="Abstract">arXiv:2312.06887</a> (replaced) [<a href="/pdf/2312.06887" title="Download PDF">pdf</a>, <a href="/format/2312.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Leveraging the Learning Phases of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Johannes Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Prabhushankar%2C+M">Mohit Prabhushankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. This is the extended version with all proofs and additional experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06937" title="Abstract">arXiv:2312.06937</a> (replaced) [<a href="/pdf/2312.06937" title="Download PDF">pdf</a>, <a href="/ps/2312.06937" title="Download PostScript">ps</a>, <a href="/format/2312.06937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can a Transformer Represent a Kalman Filter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+G">Gautam Goel</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+P">Peter Bartlett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06988" title="Abstract">arXiv:2312.06988</a> (replaced) [<a href="/pdf/2312.06988" title="Download PDF">pdf</a>, <a href="/format/2312.06988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box  Annotations for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangfeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pai Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07062" title="Abstract">arXiv:2312.07062</a> (replaced) [<a href="/pdf/2312.07062" title="Download PDF">pdf</a>, <a href="/format/2312.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ThinkBot: Embodied Instruction Following with Thought Chain Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guanxing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07180" title="Abstract">arXiv:2312.07180</a> (replaced) [<a href="/pdf/2312.07180" title="Download PDF">pdf</a>, <a href="/format/2312.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Iteration Policy Network for Efficient Optical Flow  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ri Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024, Association for the Advancement of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07353" title="Abstract">arXiv:2312.07353</a> (replaced) [<a href="/pdf/2312.07353" title="Download PDF">pdf</a>, <a href="/format/2312.07353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP in Medical Imaging: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+L">Lin Teng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Disheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page available at <a href="https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07374" title="Abstract">arXiv:2312.07374</a> (replaced) [<a href="/pdf/2312.07374" title="Download PDF">pdf</a>, <a href="/format/2312.07374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relax Image-Specific Prompt Requirement in SAM: A Single Generic Prompt  for Segmenting Camouflaged Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weitong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07492" title="Abstract">arXiv:2312.07492</a> (replaced) [<a href="/pdf/2312.07492" title="Download PDF">pdf</a>, <a href="/format/2312.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagireddy%2C+M">Manish Nagireddy</a>, 
<a href="/search/cs?searchtype=author&query=Chiazor%2C+L">Lamogha Chiazor</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Moninder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+I">Ioana Baldini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07533" title="Abstract">arXiv:2312.07533</a> (replaced) [<a href="/pdf/2312.07533" title="Download PDF">pdf</a>, <a href="/format/2312.07533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VILA: On Pre-training for Visual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Ji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+A">Andrew Tao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Huizi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07622" title="Abstract">arXiv:2312.07622</a> (replaced) [<a href="/pdf/2312.07622" title="Download PDF">pdf</a>, <a href="/format/2312.07622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanglei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuyang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jiayi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mengliang He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1705.04146">arXiv:1705.04146</a>, <a href="/abs/2304.10977">arXiv:2304.10977</a>, <a href="/abs/2112.00114">arXiv:2112.00114</a>, <a href="/abs/1905.13319">arXiv:1905.13319</a>, <a href="/abs/2304.12244">arXiv:2304.12244</a>, <a href="/abs/2206.01347">arXiv:2206.01347</a>, <a href="/abs/2006.09265">arXiv:2006.09265</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07851" title="Abstract">arXiv:2312.07851</a> (replaced) [<a href="/pdf/2312.07851" title="Download PDF">pdf</a>, <a href="/ps/2312.07851" title="Download PostScript">ps</a>, <a href="/format/2312.07851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise in the reverse process improves the approximation capabilities of  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elamvazhuthi%2C+K">Karthik Elamvazhuthi</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/cs?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended preprint for submission to Learning for Dynamics &amp; Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07853" title="Abstract">arXiv:2312.07853</a> (replaced) [<a href="/pdf/2312.07853" title="Download PDF">pdf</a>, <a href="/format/2312.07853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Structure Based Middle-Feature Learning for Visible-Infrared  Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Liuxiang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Si Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jing-Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Da-Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shunzhi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07871" title="Abstract">arXiv:2312.07871</a> (replaced) [<a href="/pdf/2312.07871" title="Download PDF">pdf</a>, <a href="/format/2312.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLNet: Mutual Learning Network with Neighborhood Invariance for  Universal Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanzuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A+J">Andy J Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07898" title="Abstract">arXiv:2312.07898</a> (replaced) [<a href="/pdf/2312.07898" title="Download PDF">pdf</a>, <a href="/format/2312.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensuring End-to-End Security with Fine-grained Access Control for  Connected and Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Donghyun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+R">Ruei-Hau Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jemin Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07953" title="Abstract">arXiv:2312.07953</a> (replaced) [<a href="/pdf/2312.07953" title="Download PDF">pdf</a>, <a href="/format/2312.07953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robotic Navigation: An Evaluation of Single and  Multi-Objective Reinforcement Learning Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Young%2C+V">Vicki Young</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+J">Jumman Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nirmalya Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> REU program project (work in progress)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07976" title="Abstract">arXiv:2312.07976</a> (replaced) [<a href="/pdf/2312.07976" title="Download PDF">pdf</a>, <a href="/ps/2312.07976" title="Download PostScript">ps</a>, <a href="/format/2312.07976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges of YOLO Series for Object Detection in Extremely Heavy Rain:  CALRA Simulator based Synthetic Evaluation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">T. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">H. Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Y. Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07987" title="Abstract">arXiv:2312.07987</a> (replaced) [<a href="/pdf/2312.07987" title="Download PDF">pdf</a>, <a href="/format/2312.07987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csord%C3%A1s%2C+R">R&#xf3;bert Csord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Pi%C4%99kos%2C+P">Piotr Pi&#x119;kos</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+K">Kazuki Irie</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08009" title="Abstract">arXiv:2312.08009</a> (replaced) [<a href="/pdf/2312.08009" title="Download PDF">pdf</a>, <a href="/format/2312.08009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Class-Agnostic Motion Prediction with Pseudo Label  Regeneration and BEVMix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kewei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yizheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+K">Ke Xian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08048" title="Abstract">arXiv:2312.08048</a> (replaced) [<a href="/pdf/2312.08048" title="Download PDF">pdf</a>, <a href="/format/2312.08048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Inversion for Stable Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiao-Yong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jin-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tian-Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08078" title="Abstract">arXiv:2312.08078</a> (replaced) [<a href="/pdf/2312.08078" title="Download PDF">pdf</a>, <a href="/format/2312.08078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic  Image-Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08140" title="Abstract">arXiv:2312.08140</a> (replaced) [<a href="/pdf/2312.08140" title="Download PDF">pdf</a>, <a href="/format/2312.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection  in Shared Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 1 table. arXiv admin note: text overlap with <a href="/abs/2312.04876">arXiv:2312.04876</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08221" title="Abstract">arXiv:2312.08221</a> (replaced) [<a href="/pdf/2312.08221" title="Download PDF">pdf</a>, <a href="/format/2312.08221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-Enhanced Residual Soft An-Isotropic Normalization for  Over-smoothness in Deep GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qirong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuling Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longkun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang-Geng Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08245" title="Abstract">arXiv:2312.08245</a> (replaced) [<a href="/pdf/2312.08245" title="Download PDF">pdf</a>, <a href="/ps/2312.08245" title="Download PostScript">ps</a>, <a href="/format/2312.08245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Stationary Prophet Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+N">Neel Patel</a>, 
<a href="/search/cs?searchtype=author&query=Wajc%2C+D">David Wajc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08274" title="Abstract">arXiv:2312.08274</a> (replaced) [<a href="/pdf/2312.08274" title="Download PDF">pdf</a>, <a href="/format/2312.08274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-throughput Biomedical Relation Extraction for Semi-Structured Web  Articles Empowered by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Songchi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item404">Cross-lists</a></li>
<li><a href="#item456">Replacements</a></li>
</ul>
<small>[ total of 708 entries:  <b>1-708</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
