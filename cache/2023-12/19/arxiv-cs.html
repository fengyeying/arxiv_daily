<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 15 Dec 23  to  Mon 18 Dec 23, announced Tue, 19 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item672">Cross-lists</a></li>
<li><a href="#item742">Replacements</a></li>
</ul>
<small>[ total of 1154 entries:  <b>1-1154</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 19 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10039" title="Abstract">arXiv:2312.10039</a> [<a href="/pdf/2312.10039" title="Download PDF">pdf</a>, <a href="/ps/2312.10039" title="Download PostScript">ps</a>, <a href="/format/2312.10039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Silos A Roadblock for AIOps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Subhadip Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Using artificial intelligence to manage IT operations, also known as AIOps,
is a trend that has attracted a lot of interest and anticipation in recent
years. The challenge in IT operations is to run steady-state operations without
disruption as well as support agility" can be rephrased as "IT operations face
the challenge of maintaining steady-state operations while also supporting
agility [11]. AIOps assists in bridging the gap between the demand for IT
operations and the ability of humans to meet that demand. However, it is not
easy to apply AIOps in current organizational settings. Data Centralization is
a major obstacle for adopting AIOps, according to a recent survey by Cisco [1].
The survey, which involved 8,161 senior business leaders from organizations
with more than 500 employees, found that 81% of them acknowledged that their
data was scattered across different silos within their organizations. This
paper illustrates the topic of data silos, their causes, consequences, and
solutions.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10041" title="Abstract">arXiv:2312.10041</a> [<a href="/pdf/2312.10041" title="Download PDF">pdf</a>, <a href="/ps/2312.10041" title="Download PostScript">ps</a>, <a href="/format/2312.10041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin Technology Enabled Proactive Safety Application for  Vulnerable Road Users: A Real-World Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rua%2C+E">Erik Rua</a>, 
<a href="/search/cs?searchtype=author&query=Shakib%2C+K+H">Kazi Hasan Shakib</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+S">Sagar Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+S">Steven Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures, submitted to the Transportation Research Board 2024 TRB Annual Meeting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While measures, such as traffic calming and advance driver assistance
systems, can improve safety for Vulnerable Road Users (VRUs), their
effectiveness ultimately relies on the responsible behavior of drivers and
pedestrians who must adhere to traffic rules or take appropriate actions.
However, these measures offer no solution in scenarios where a collision
becomes imminent, leaving no time for warning or corrective actions. Recently,
connected vehicle technology has introduced warning services that can alert
drivers and VRUs about potential collisions. Nevertheless, there is still a
significant gap in the system's ability to predict collisions in advance. The
objective of this study is to utilize Digital Twin (DT) technology to enable a
proactive safety alert system for VRUs. A pedestrian-vehicle trajectory
prediction model has been developed using the Encoder-Decoder Long Short-Term
Memory (LSTM) architecture to predict future trajectories of pedestrians and
vehicles. Subsequently, parallel evaluation of all potential future
safety-critical scenarios is carried out. Three Encoder-Decoder LSTM models,
namely pedestrian-LSTM, vehicle-through-LSTM, and vehicle-left-turn-LSTM, are
trained and validated using field-collected data, achieving corresponding root
mean square errors (RMSE) of 0.049, 1.175, and 0.355 meters, respectively. A
real-world case study has been conducted where a pedestrian crosses a road, and
vehicles have the option to proceed through or left-turn, to evaluate the
efficacy of DT-enabled proactive safety alert systems. Experimental results
confirm that DT-enabled safety alert systems were succesfully able to detect
potential crashes and proactively generate safety alerts to reduce potential
crash risk.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10042" title="Abstract">arXiv:2312.10042</a> [<a href="/pdf/2312.10042" title="Download PDF">pdf</a>, <a href="/ps/2312.10042" title="Download PostScript">ps</a>, <a href="/format/2312.10042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generic Stochastic Hybrid Car-following Model Based on Approximate  Bayesian Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiwan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Soyoung Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Car following (CF) models are fundamental to describing traffic dynamics.
However, the CF behavior of human drivers is highly stochastic and nonlinear.
As a result, identifying the best CF model has been challenging and
controversial despite decades of research. Introduction of automated vehicles
has further complicated this matter as their CF controllers remain proprietary,
though their behavior appears different than human drivers. This paper develops
a stochastic learning approach to integrate multiple CF models, rather than
relying on a single model. The framework is based on approximate Bayesian
computation that probabilistically concatenates a pool of CF models based on
their relative likelihood of describing observed behavior. The approach, while
data-driven, retains physical tractability and interpretability. Evaluation
results using two datasets show that the proposed approach can better reproduce
vehicle trajectories for both human driven and automated vehicles than any
single CF model considered.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10045" title="Abstract">arXiv:2312.10045</a> [<a href="/pdf/2312.10045" title="Download PDF">pdf</a>, <a href="/format/2312.10045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Knowledge Tracing via Response Influence-based  Counterfactual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiajun Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Minghe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version of the paper accepted to appear in ICDE'24. Source code at <a href="https://github.com/JJCui96/RCKT.">this https URL</a> Keywords: knowledge tracing, interpretable machine learning, counterfactual reasoning, artificial intelligence for education
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge tracing (KT) plays a crucial role in computer-aided education and
intelligent tutoring systems, aiming to assess students' knowledge proficiency
by predicting their future performance on new questions based on their past
response records. While existing deep learning knowledge tracing (DLKT) methods
have significantly improved prediction accuracy and achieved state-of-the-art
results, they often suffer from a lack of interpretability. To address this
limitation, current approaches have explored incorporating psychological
influences to achieve more explainable predictions, but they tend to overlook
the potential influences of historical responses. In fact, understanding how
models make predictions based on response influences can enhance the
transparency and trustworthiness of the knowledge tracing process, presenting
an opportunity for a new paradigm of interpretable KT. However, measuring
unobservable response influences is challenging. In this paper, we resort to
counterfactual reasoning that intervenes in each response to answer
\textit{what if a student had answered a question incorrectly that he/she
actually answered correctly, and vice versa}. Based on this, we propose RCKT, a
novel response influence-based counterfactual knowledge tracing framework. RCKT
generates response influences by comparing prediction outcomes from factual
sequences and constructed counterfactual sequences after interventions.
Additionally, we introduce maximization and inference techniques to leverage
accumulated influences from different past responses, further improving the
model's performance and credibility. Extensive experimental results demonstrate
that our RCKT method outperforms state-of-the-art knowledge tracing methods on
four datasets against six baselines, and provides credible interpretations of
response influences.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10046" title="Abstract">arXiv:2312.10046</a> [<a href="/pdf/2312.10046" title="Download PDF">pdf</a>, <a href="/format/2312.10046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Metric Learning for Computer Vision: A Brief Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohan%2C+D+D">Deen Dayal Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Jawade%2C+B">Bhavin Jawade</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+S">Srirangaraj Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Govindaraj%2C+V">Venu Govindaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Book Chapter Published In Handbook of Statistics, Special Issue - Deep Learning 48, 59
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Objective functions that optimize deep neural networks play a vital role in
creating an enhanced feature representation of the input data. Although
cross-entropy-based loss formulations have been extensively used in a variety
of supervised deep-learning applications, these methods tend to be less
adequate when there is large intra-class variance and low inter-class variance
in input data distribution. Deep Metric Learning seeks to develop methods that
aim to measure the similarity between data samples by learning a representation
function that maps these data samples into a representative embedding space. It
leverages carefully designed sampling strategies and loss functions that aid in
optimizing the generation of a discriminative embedding space even for
distributions having low inter-class and high intra-class variances. In this
chapter, we will provide an overview of recent progress in this area and
discuss state-of-the-art Deep Metric Learning approaches.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10047" title="Abstract">arXiv:2312.10047</a> [<a href="/pdf/2312.10047" title="Download PDF">pdf</a>, <a href="/ps/2312.10047" title="Download PostScript">ps</a>, <a href="/format/2312.10047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering Students According to their Academic Achievement Using Fuzzy  Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balovsyak%2C+S">Serhiy Balovsyak</a>, 
<a href="/search/cs?searchtype=author&query=Derevyanchuk%2C+O">Oleksandr Derevyanchuk</a>, 
<a href="/search/cs?searchtype=author&query=Kravchenko%2C+H">Hanna Kravchenko</a>, 
<a href="/search/cs?searchtype=author&query=Ushenko%2C+Y">Yuriy Ushenko</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengbing Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,9 figures,ijmecs
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Modern Education and Computer
  Science(IJMECS), Vol.15, No.6, pp. 31-43, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The software for clustering students according to their educational
achievements using fuzzy logic was developed in Python using the Google Colab
cloud service. In the process of analyzing educational data, the problems of
Data Mining are solved, since only some characteristics of the educational
process are obtained from a large sample of data. Data clustering was performed
using the classic K-Means method, which is characterized by simplicity and high
speed. Cluster analysis was performed in the space of two features using the
machine learning library scikit-learn (Python). The obtained clusters are
described by fuzzy triangular membership functions, which allowed to correctly
determine the membership of each student to a certain cluster. Creation of
fuzzy membership functions is done using the scikit-fuzzy library. The
development of fuzzy functions of objects belonging to clusters is also useful
for educational purposes, as it allows a better understanding of the principles
of using fuzzy logic. As a result of processing test educational data using the
developed software, correct results were obtained. It is shown that the use of
fuzzy membership functions makes it possible to correctly determine the
belonging of students to certain clusters, even if such clusters are not
clearly separated. Due to this, it is possible to more accurately determine the
recommended level of difficulty of tasks for each student, depending on his
previous evaluations.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10048" title="Abstract">arXiv:2312.10048</a> [<a href="/pdf/2312.10048" title="Download PDF">pdf</a>, <a href="/ps/2312.10048" title="Download PostScript">ps</a>, <a href="/format/2312.10048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspect-Level Sentiment Analysis Based on Knowledge Graph and Recurrent  Attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+K">Kavita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Ritu Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+S">Sunita Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we propose a novel method to enhance sentiment analysis by
addressing the challenge of context-specific word meanings. It combines the
advantages of a bidirectional long short-term memory network (Bi-LSTM) with a
knowledge graph's synonym data. This synergy leverages a dynamic attention
mechanism to develop a knowledge-driven state vector. For classifying
sentiments linked to specific aspects, the approach constructs a memory bank
integrating positional data. This data is then analyzed using a multi-layer
gated recurrent unit (GRU) to pinpoint sentiment characteristics related to
specific aspect terms. Tests on three widely available datasets demonstrate
this method's superior performance in sentiment classification.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10049" title="Abstract">arXiv:2312.10049</a> [<a href="/pdf/2312.10049" title="Download PDF">pdf</a>, <a href="/ps/2312.10049" title="Download PostScript">ps</a>, <a href="/format/2312.10049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Reasoning Based on Attention GCN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Meera Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+R">Ravi Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+D">Divya Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+N">Nandini Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">We propose a novel technique to enhance Knowledge Graph Reasoning by
combining Graph Convolution Neural Network (GCN) with the Attention Mechanism.
This approach utilizes the Attention Mechanism to examine the relationships
between entities and their neighboring nodes, which helps to develop detailed
feature vectors for each entity. The GCN uses shared parameters to effectively
represent the characteristics of adjacent entities. By integrating the
attributes of the entities and their interactions, this method generates
extensive implicit feature vectors for each entity, improving performance in
tasks including entity classification and link prediction, outperforming
traditional neural network models. To conclude, this work provides crucial
methodological support for a range of applications, such as search engines,
question-answering systems, recommendation systems, and data integration tasks.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10053" title="Abstract">arXiv:2312.10053</a> [<a href="/pdf/2312.10053" title="Download PDF">pdf</a>, <a href="/format/2312.10053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Goal-oriented Intelligent Tutoring Systems in Online Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zifeng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">An Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Interactive Intelligent Tutoring Systems (ITSs) enhance traditional ITSs by
promoting effective learning through interactions and problem resolution in
online education. Yet, proactive engagement, prioritizing resource optimization
with planning and assessment capabilities, is often overlooked in current ITS
designs. In this work, we investigate a new task, named Goal-oriented
Intelligent Tutoring Systems (GITS), which aims to enable the student's mastery
of a designated concept by strategically planning a customized sequence of
exercises and assessment. To address the problem of goal-oriented policy
learning in GITS, we propose a novel graph-based reinforcement learning
framework, named Planning-Assessment-Interaction (PAI). Specifically, we first
leverage cognitive structure information to improve state representation
learning and action selection for planning the next action, which can be either
to tutor an exercise or to assess the target concept. Further, we use a
dynamically updated cognitive diagnosis model to simulate student responses to
exercises and concepts. Three benchmark datasets across different subjects are
constructed for enabling offline academic research on GITS. Experimental
results demonstrate the effectiveness and efficiency of PAI and extensive
analyses of various types of students are conducted to showcase the challenges
in this task.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10055" title="Abstract">arXiv:2312.10055</a> [<a href="/pdf/2312.10055" title="Download PDF">pdf</a>, <a href="/format/2312.10055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next-Step Hint Generation for Introductory Programming Using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roest%2C+L">Lianne Roest</a>, 
<a href="/search/cs?searchtype=author&query=Keuning%2C+H">Hieke Keuning</a>, 
<a href="/search/cs?searchtype=author&query=Jeuring%2C+J">Johan Jeuring</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large Language Models possess skills such as answering questions, writing
essays or solving programming exercises. Since these models are easily
accessible, researchers have investigated their capabilities and risks for
programming education. This work explores how LLMs can contribute to
programming education by supporting students with automated next-step hints. We
investigate prompt practices that lead to effective next-step hints and use
these insights to build our StAP-tutor. We evaluate this tutor by conducting an
experiment with students, and performing expert assessments. Our findings show
that most LLM-generated feedback messages describe one specific next step and
are personalised to the student's code and approach. However, the hints may
contain misleading information and lack sufficient detail when students
approach the end of the assignment. This work demonstrates the potential for
LLM-generated feedback, but further research is required to explore its
practical implementation.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10057" title="Abstract">arXiv:2312.10057</a> [<a href="/pdf/2312.10057" title="Download PDF">pdf</a>, <a href="/format/2312.10057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI in Writing Research Papers: A New Type of Algorithmic Bias  and Uncertainty in Scholarly Work
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rishab Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aditya Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The use of artificial intelligence (AI) in research across all disciplines is
becoming ubiquitous. However, this ubiquity is largely driven by hyperspecific
AI models developed during scientific studies for accomplishing a well-defined,
data-dense task. These AI models introduce apparent, human-recognizable biases
because they are trained with finite, specific data sets and parameters.
However, the efficacy of using large language models (LLMs) -- and LLM-powered
generative AI tools, such as ChatGPT -- to assist the research process is
currently indeterminate. These generative AI tools, trained on general and
imperceptibly large datasets along with human feedback, present challenges in
identifying and addressing biases. Furthermore, these models are susceptible to
goal misgeneralization, hallucinations, and adversarial attacks such as red
teaming prompts -- which can be unintentionally performed by human researchers,
resulting in harmful outputs. These outputs are reinforced in research -- where
an increasing number of individuals have begun to use generative AI to compose
manuscripts. Efforts into AI interpretability lag behind development, and the
implicit variations that occur when prompting and providing context to a
chatbot introduce uncertainty and irreproducibility. We thereby find that
incorporating generative AI in the process of writing research manuscripts
introduces a new type of context-induced algorithmic bias and has unintended
side effects that are largely detrimental to academia, knowledge production,
and communicating research.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10059" title="Abstract">arXiv:2312.10059</a> [<a href="/pdf/2312.10059" title="Download PDF">pdf</a>, <a href="/format/2312.10059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A collection of principles for guiding and evaluating large language  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hebenstreit%2C+K">Konstantin Hebenstreit</a>, 
<a href="/search/cs?searchtype=author&query=Praas%2C+R">Robert Praas</a>, 
<a href="/search/cs?searchtype=author&query=Samwald%2C+M">Matthias Samwald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Socially Responsible Language Modelling Research (SoLaR) workshop, NeurIPS 2023 (<a href="https://openreview.net/forum?id=8iXdNXW34d">this https URL</a>). Based on previous manuscript version: doi:10.2139/ssrn.4446991
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Large language models (LLMs) demonstrate outstanding capabilities, but
challenges remain regarding their ability to solve complex reasoning tasks, as
well as their transparency, robustness, truthfulness, and ethical alignment. In
this preliminary study, we compile a set of core principles for steering and
evaluating the reasoning of LLMs by curating literature from several relevant
strands of work: structured reasoning in LLMs, self-evaluation/self-reflection,
explainability, AI system safety/security, guidelines for human critical
thinking, and ethical/regulatory guidelines for AI. We identify and curate a
list of 220 principles from literature, and derive a set of 37 core principles
organized into seven categories: assumptions and perspectives, reasoning,
information and evidence, robustness and security, ethics, utility, and
implications. We conduct a small-scale expert survey, eliciting the subjective
importance experts assign to different principles and lay out avenues for
future work beyond our preliminary results. We envision that the development of
a shared model of principles can serve multiple purposes: monitoring and
steering models at inference time, improving model behavior during training,
and guiding human evaluation of model reasoning.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10061" title="Abstract">arXiv:2312.10061</a> [<a href="/pdf/2312.10061" title="Download PDF">pdf</a>, <a href="/ps/2312.10061" title="Download PostScript">ps</a>, <a href="/format/2312.10061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restivo Salemi property for $&#x3b1;$-power free languages with  $&#x3b1;\geq 5$ and $k\geq 3$ letters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rukavicka%2C+J">Josef Rukavicka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2202.12038">arXiv:2202.12038</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In 2009, Shur published the following conjecture: Let $L$ be a power-free
language and let $e(L)\subseteq L$ be the set of words of $L$ that can be
extended to a bi-infinite word respecting the given power-freeness. If $u, v
\in e(L)$ then $uwv \in e(L)$ for some word $w$. Let $L_{k,\alpha}$ denote an
$\alpha$-power free language over an alphabet with $k$ letters, where $\alpha$
is a positive rational number and $k$ is positive integer. We prove the
conjecture for the languages $L_{k,\alpha}$, where $\alpha\geq 5$ and $k\geq
3$.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10064" title="Abstract">arXiv:2312.10064</a> [<a href="/pdf/2312.10064" title="Download PDF">pdf</a>, <a href="/format/2312.10064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Collaborative Filtering for Matrix- and Tensor-based Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saiapin%2C+A">Albert Saiapin</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+E">Evgeny Frolov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In production applications of recommender systems, a continuous data flow is
employed to update models in real-time. Many recommender models often require
complete retraining to adapt to new data. In this work, we introduce a novel
collaborative filtering model for sequential problems known as Tucker
Integrator Recommender - TIRecA. TIRecA efficiently updates its parameters
using only the new data segment, allowing incremental addition of new users and
items to the recommender system. To demonstrate the effectiveness of the
proposed model, we conducted experiments on four publicly available datasets:
MovieLens 20M, Amazon Beauty, Amazon Toys and Games, and Steam. Our comparison
with general matrix and tensor-based baselines in terms of prediction quality
and computational time reveals that TIRecA achieves comparable quality to the
baseline methods, while being 10-20 times faster in training time.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10065" title="Abstract">arXiv:2312.10065</a> [<a href="/pdf/2312.10065" title="Download PDF">pdf</a>, <a href="/format/2312.10065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Social Bias in Downstream Applications of Text-to-Image  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saravanan%2C+A+P">Adhithya Prakash Saravanan</a>, 
<a href="/search/cs?searchtype=author&query=Kocielnik%2C+R">Rafal Kocielnik</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Roy Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengrui Han</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-image diffusion models have been adopted into key commercial
workflows, such as art generation and image editing. Characterising the
implicit social biases they exhibit, such as gender and racial stereotypes, is
a necessary first step in avoiding discriminatory outcomes. While existing
studies on social bias focus on image generation, the biases exhibited in
alternate applications of diffusion-based foundation models remain
under-explored. We propose methods that use synthetic images to probe two
applications of diffusion models, image editing and classification, for social
bias. Using our methodology, we uncover meaningful and significant
inter-sectional social biases in \textit{Stable Diffusion}, a state-of-the-art
open-source text-to-image model. Our findings caution against the uninformed
adoption of text-to-image foundation models for downstream tasks and services.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10067" title="Abstract">arXiv:2312.10067</a> [<a href="/pdf/2312.10067" title="Download PDF">pdf</a>, <a href="/format/2312.10067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teenagers and Artificial Intelligence: Bootcamp Experience and Lessons  Learned
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macar%2C+U">Uzay Macar</a>, 
<a href="/search/cs?searchtype=author&query=Castleman%2C+B">Blake Castleman</a>, 
<a href="/search/cs?searchtype=author&query=Mauchly%2C+N">Noah Mauchly</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Michael Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Aouissi%2C+A">Asma Aouissi</a>, 
<a href="/search/cs?searchtype=author&query=Aouissi%2C+S">Salma Aouissi</a>, 
<a href="/search/cs?searchtype=author&query=Maayah%2C+X">Xena Maayah</a>, 
<a href="/search/cs?searchtype=author&query=Erdem%2C+K">Kaan Erdem</a>, 
<a href="/search/cs?searchtype=author&query=Ravindranath%2C+R">Rohith Ravindranath</a>, 
<a href="/search/cs?searchtype=author&query=Clark-Sevilla%2C+A">Andrea Clark-Sevilla</a>, 
<a href="/search/cs?searchtype=author&query=Salleb-Aouissi%2C+A">Ansaf Salleb-Aouissi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 12 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) stands out as a game-changer in today's
technology landscape. However, the integration of AI education in classroom
curricula currently lags behind, leaving teenagers inadequately prepared for an
imminent AI-driven future.
<br />In this pilot study, we designed a three-day bootcamp offered in the summer
of 2023 to a cohort of 60 high school students. The curriculum was delivered in
person through animated video content, easy-to-follow slides, interactive
playgrounds, and quizzes. These were packaged in the early version of an online
learning platform we are developing. Results from the post-bootcamp survey
conveyed a 91.4% overall satisfaction. Despite the short bootcamp duration,
88.5% and 71.4% of teenagers responded that they had an improved understanding
of AI concepts and programming, respectively.
<br />Overall, we found that employing diverse modalities effectively engaged
students, and building foundational modules proved beneficial for introducing
more complex topics. Furthermore, using Google Colab notebooks for coding
assignments proved challenging to most students. Students' activity on the
platform and their answers to quizzes showed proficient engagement and a grasp
of the material.
<br />Our results strongly highlight the need for compelling and accessible AI
education methods for the next generation and the potential for informal
learning to fill the gap of providing early AI education to teenagers.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10069" title="Abstract">arXiv:2312.10069</a> [<a href="/pdf/2312.10069" title="Download PDF">pdf</a>, <a href="/format/2312.10069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Representations Pretrained with Auxiliary Losses for  Embodied Agent Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Weihs%2C+L">Luca Weihs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pretrained representations from large-scale vision models have boosted the
performance of downstream embodied policy learning. We look to understand
whether additional self-supervised pretraining on exploration trajectories can
build on these general-purpose visual representations to better support
embodied planning in realistic environments. We evaluated four common auxiliary
losses in embodied AI, two hindsight-based losses, and a standard imitation
learning loss, by pretraining the agent's visual compression module and state
belief representations with each objective and using CLIP as a representative
visual backbone. The learned representations are then frozen for downstream
multi-step evaluation on two goal-directed tasks. Surprisingly, we find that
imitation learning on these exploration trajectories out-performs all other
auxiliary losses even despite the exploration trajectories being dissimilar
from the downstream tasks. This suggests that imitation of exploration may be
''all you need'' for building powerful planning representations. Additionally,
we find that popular auxiliary losses can benefit from simple modifications to
improve their support for downstream planning ability.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10070" title="Abstract">arXiv:2312.10070</a> [<a href="/pdf/2312.10070" title="Download PDF">pdf</a>, <a href="/format/2312.10070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yugay%2C+V">Vladimir Yugay</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present a new dense simultaneous localization and mapping (SLAM) method
that uses Gaussian splats as a scene representation. The new representation
enables interactive-time reconstruction and photo-realistic rendering of
real-world and synthetic scenes. We propose novel strategies for seeding and
optimizing Gaussian splats to extend their use from multiview offline scenarios
to sequential monocular RGBD input data setups. In addition, we extend Gaussian
splats to encode geometry and experiment with tracking against this scene
representation. Our method achieves state-of-the-art rendering quality on both
real-world and synthetic datasets while being competitive in reconstruction
performance and runtime.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10072" title="Abstract">arXiv:2312.10072</a> [<a href="/pdf/2312.10072" title="Download PDF">pdf</a>, <a href="/format/2312.10072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Usability of GutGPT: A Simulation Study of an AI Clinical  Decision Support System for Gastrointestinal Bleeding Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Colleen Chan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+K">Kisung You</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Sunny Chung</a>, 
<a href="/search/cs?searchtype=author&query=Giuffr%C3%A8%2C+M">Mauro Giuffr&#xe8;</a>, 
<a href="/search/cs?searchtype=author&query=Saarinen%2C+T">Theo Saarinen</a>, 
<a href="/search/cs?searchtype=author&query=Rajashekar%2C+N">Niroop Rajashekar</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y+E">Yeo Eun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+L">Loren Laine</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Ambrose Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kizilcec%2C+R">Ren&#xe9; Kizilcec</a>, 
<a href="/search/cs?searchtype=author&query=Sekhon%2C+J">Jasjeet Sekhon</a>, 
<a href="/search/cs?searchtype=author&query=Shung%2C+D">Dennis Shung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10, 2023, New Orleans, United States, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Applications of large language models (LLMs) like ChatGPT have potential to
enhance clinical decision support through conversational interfaces. However,
challenges of human-algorithmic interaction and clinician trust are poorly
understood. GutGPT, a LLM for gastrointestinal (GI) bleeding risk prediction
and management guidance, was deployed in clinical simulation scenarios
alongside the electronic health record (EHR) with emergency medicine
physicians, internal medicine physicians, and medical students to evaluate its
effect on physician acceptance and trust in AI clinical decision support
systems (AI-CDSS). GutGPT provides risk predictions from a validated machine
learning model and evidence-based answers by querying extracted clinical
guidelines. Participants were randomized to GutGPT and an interactive
dashboard, or the interactive dashboard and a search engine. Surveys and
educational assessments taken before and after measured technology acceptance
and content mastery. Preliminary results showed mixed effects on acceptance
after using GutGPT compared to the dashboard or search engine but appeared to
improve content mastery based on simulation performance. Overall, this study
demonstrates LLMs like GutGPT could enhance effective AI-CDSS if implemented
optimally and paired with interactive interfaces.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10073" title="Abstract">arXiv:2312.10073</a> [<a href="/pdf/2312.10073" title="Download PDF">pdf</a>, <a href="/format/2312.10073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Scarcity in Recommendation Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaixia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Recommender Systems, 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prevalence of online content has led to the widespread adoption of
recommendation systems (RSs), which serve diverse purposes such as news,
advertisements, and e-commerce recommendations. Despite their significance,
data scarcity issues have significantly impaired the effectiveness of existing
RS models and hindered their progress. To address this challenge, the concept
of knowledge transfer, particularly from external sources like pre-trained
language models, emerges as a potential solution to alleviate data scarcity and
enhance RS development. However, the practice of knowledge transfer in RSs is
intricate. Transferring knowledge between domains introduces data disparities,
and the application of knowledge transfer in complex RS scenarios can yield
negative consequences if not carefully designed. Therefore, this article
contributes to this discourse by addressing the implications of data scarcity
on RSs and introducing various strategies, such as data augmentation,
self-supervised learning, transfer learning, broad learning, and knowledge
graph utilization, to mitigate this challenge. Furthermore, it delves into the
challenges and future direction within the RS domain, offering insights that
are poised to facilitate the development and implementation of robust RSs,
particularly when confronted with data scarcity. We aim to provide valuable
guidance and inspiration for researchers and practitioners, ultimately driving
advancements in the field of RS.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10074" title="Abstract">arXiv:2312.10074</a> [<a href="/pdf/2312.10074" title="Download PDF">pdf</a>, <a href="/ps/2312.10074" title="Download PostScript">ps</a>, <a href="/format/2312.10074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAGER checklist: Standardized Testing and Assessment Guidelines for  Evaluating Generative AI Reliability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+W">Weiming Mou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zaoqu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Quan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A">Anqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Peng Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 0 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative Artificial Intelligence (AI) holds immense potential in medical
applications. Numerous studies have explored the efficacy of various generative
AI models within healthcare contexts, but there is a lack of a comprehensive
and systematic evaluation framework. Given that some studies evaluating the
ability of generative AI for medical applications have deficiencies in their
methodological design, standardized guidelines for their evaluation are also
currently lacking. In response, our objective is to devise standardized
assessment guidelines tailored for evaluating the performance of generative AI
systems in medical contexts. To this end, we conducted a thorough literature
review using the PubMed and Google Scholar databases, focusing on research that
tests generative AI capabilities in medicine. Our multidisciplinary team,
comprising experts in life sciences, clinical medicine, medical engineering,
and generative AI users, conducted several discussion sessions and developed a
checklist of 23 items. The checklist is designed to encompass the critical
evaluation aspects of generative AI in medical applications comprehensively.
This checklist, and the broader assessment framework it anchors, address
several key dimensions, including question collection, querying methodologies,
and assessment techniques. We aim to provide a holistic evaluation of AI
systems. The checklist delineates a clear pathway from question gathering to
result assessment, offering researchers guidance through potential challenges
and pitfalls. Our framework furnishes a standardized, systematic approach for
research involving the testing of generative AI's applicability in medicine. It
enhances the quality of research reporting and aids in the evolution of
generative AI in medicine and life sciences.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10075" title="Abstract">arXiv:2312.10075</a> [<a href="/pdf/2312.10075" title="Download PDF">pdf</a>, <a href="/format/2312.10075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing LLMs for Moral Value Pluralism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benkler%2C+N">Noam Benkler</a>, 
<a href="/search/cs?searchtype=author&query=Mosaphir%2C+D">Drisana Mosaphir</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+S">Scott Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Smart%2C+A">Andrew Smart</a>, 
<a href="/search/cs?searchtype=author&query=Schmer-Galunder%2C+S">Sonja Schmer-Galunder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper to workshop on "AI meets Moral Philosophy and Moral Psychology: An Interdisciplinary Dialogue about Computational Ethics" at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The fields of AI current lacks methods to quantitatively assess and
potentially alter the moral values inherent in the output of large language
models (LLMs). However, decades of social science research has developed and
refined widely-accepted moral value surveys, such as the World Values Survey
(WVS), eliciting value judgments from direct questions in various geographies.
We have turned those questions into value statements and use NLP to compute to
how well popular LLMs are aligned with moral values for various demographics
and cultures. While the WVS is accepted as an explicit assessment of values, we
lack methods for assessing implicit moral and cultural values in media, e.g.,
encountered in social media, political rhetoric, narratives, and generated by
AI systems such as LLMs that are increasingly present in our daily lives. As we
consume online content and utilize LLM outputs, we might ask, which moral
values are being implicitly promoted or undercut, or -- in the case of LLMs --
if they are intending to represent a cultural identity, are they doing so
consistently? In this paper we utilize a Recognizing Value Resonance (RVR) NLP
model to identify WVS values that resonate and conflict with a given passage of
output text. We apply RVR to the text generated by LLMs to characterize
implicit moral values, allowing us to quantify the moral/cultural distance
between LLMs and various demographics that have been surveyed using the WVS. In
line with other work we find that LLMs exhibit several Western-centric value
biases; they overestimate how conservative people in non-Western countries are,
they are less accurate in representing gender for non-Western countries, and
portray older populations as having more traditional values. Our results
highlight value misalignment and age groups, and a need for social science
informed technological solutions addressing value plurality in LLMs.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10076" title="Abstract">arXiv:2312.10076</a> [<a href="/pdf/2312.10076" title="Download PDF">pdf</a>, <a href="/ps/2312.10076" title="Download PostScript">ps</a>, <a href="/format/2312.10076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Exploring the Consequences of AI-Mediated Enterprise  Knowledge Access and Identifying Risks to Workers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gausen%2C+A">Anna Gausen</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+B">Bhaskar Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+S">Si&#xe2;n Lindley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Organisations generate vast amounts of information, which has resulted in a
long-term research effort into knowledge access systems for enterprise
settings. Recent developments in artificial intelligence, in relation to large
language models, are poised to have significant impact on knowledge access.
This has the potential to shape the workplace and knowledge in new and
unanticipated ways. Many risks can arise from the deployment of these types of
AI systems, due to interactions between the technical system and organisational
power dynamics.
<br />This paper presents the Consequence-Mechanism-Risk framework to identify
risks to workers from AI-mediated enterprise knowledge access systems. We have
drawn on wide-ranging literature detailing risks to workers, and categorised
risks as being to worker value, power, and wellbeing. The contribution of our
framework is to additionally consider (i) the consequences of these systems
that are of moral import: commodification, appropriation, concentration of
power, and marginalisation, and (ii) the mechanisms, which represent how these
consequences may take effect in the system. The mechanisms are a means of
contextualising risk within specific system processes, which is critical for
mitigation. This framework is aimed at helping practitioners involved in the
design and deployment of AI-mediated knowledge access systems to consider the
risks introduced to workers, identify the precise system mechanisms that
introduce those risks and begin to approach mitigation. Future work could apply
this framework to other technological systems to promote the protection of
workers and other groups.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10077" title="Abstract">arXiv:2312.10077</a> [<a href="/pdf/2312.10077" title="Download PDF">pdf</a>, <a href="/ps/2312.10077" title="Download PostScript">ps</a>, <a href="/format/2312.10077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial intelligence in social science: A study based on  bibliometrics analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prieto-Gutierrez%2C+J">Juan-Jose Prieto-Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Segado-Boj%2C+F">Francisco Segado-Boj</a>, 
<a href="/search/cs?searchtype=author&query=Da+Silva+Fran%C3%A7a%2C+F">Fabiana Da Silva Fran&#xe7;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Artificial intelligence (AI) is gradually changing the planet. Data
digitisation, computing infrastructure and machine learning are helping AI
tools to spread across all sectors of society. This article presents the
results of a bibliometric analysis of AI-related publications in the social
sciences over the last ten years (2013-2022). Most of the historical
publications are taken into consideration with the aim of identifying research
relevance and trends in this field. The results indicate that more than 19,408
articles have been published, 85% from 2008 to 2022, showing that research in
this field is increasing significantly year on year. Clear domains or
disciplines of research related to AI within the social sciences can be grouped
into sub-areas such as law and legal reasoning, education, economics, and
ethics. The United States is the country that publishes the most (20%),
followed by China (13%). The influence of AI on society is inevitable and the
advances can generate great opportunities for innovation and new jobs, but in
the medium term it is necessary to adequately face this transition, setting
regulations and reviewing the challenges of ethics and responsibility.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10078" title="Abstract">arXiv:2312.10078</a> [<a href="/pdf/2312.10078" title="Download PDF">pdf</a>, <a href="/format/2312.10078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early ChatGPT User Portrait through the Lens of Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuyang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Ni Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, 2023 IEEE International Conference on Big Data (BigData), to be published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Since its launch, ChatGPT has achieved remarkable success as a versatile
conversational AI platform, drawing millions of users worldwide and garnering
widespread recognition across academic, industrial, and general communities.
This paper aims to point a portrait of early GPT users and understand how they
evolved. Specific questions include their topics of interest and their
potential careers; and how this changes over time. We conduct a detailed
analysis of real-world ChatGPT datasets with multi-turn conversations between
users and ChatGPT. Through a multi-pronged approach, we quantify conversation
dynamics by examining the number of turns, then gauge sentiment to understand
user sentiment variations, and finally employ Latent Dirichlet Allocation (LDA)
to discern overarching topics within the conversation. By understanding shifts
in user demographics and interests, we aim to shed light on the changing nature
of human-AI interaction and anticipate future trends in user engagement with
language models.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10079" title="Abstract">arXiv:2312.10079</a> [<a href="/pdf/2312.10079" title="Download PDF">pdf</a>, <a href="/ps/2312.10079" title="Download PostScript">ps</a>, <a href="/format/2312.10079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Music Recommendation on Spotify using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+C">Chhavi Maheshwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 images, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Hosting about 50 million songs and 4 billion playlists, there is an enormous
amount of data generated at Spotify every single day - upwards of 600 gigabytes
of data (harvard.edu). Since the algorithms that Spotify uses in recommendation
systems is proprietary and confidential, code for big data analytics and
recommendation can only be speculated. However, it is widely theorized that
Spotify uses two main strategies to target users' playlists and personalized
mixes that are infamous for their retention - exploration and exploitation
(kaggle.com). This paper aims to appropriate filtering using the approach of
deep learning for maximum user likeability. The architecture achieves 98.57%
and 80% training and validation accuracy respectively.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10080" title="Abstract">arXiv:2312.10080</a> [<a href="/pdf/2312.10080" title="Download PDF">pdf</a>, <a href="/ps/2312.10080" title="Download PostScript">ps</a>, <a href="/format/2312.10080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No prejudice! Fair Federated Graph Neural Networks for Personalized  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+N">Nimesh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+A+K">Anuj Kumar Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=Jayadeva">Jayadeva</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear as a full paper in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Ensuring fairness in Recommendation Systems (RSs) across demographic groups
is critical due to the increased integration of RSs in applications such as
personalized healthcare, finance, and e-commerce. Graph-based RSs play a
crucial role in capturing intricate higher-order interactions among entities.
However, integrating these graph models into the Federated Learning (FL)
paradigm with fairness constraints poses formidable challenges as this requires
access to the entire interaction graph and sensitive user information (such as
gender, age, etc.) at the central server. This paper addresses the pervasive
issue of inherent bias within RSs for different demographic groups without
compromising the privacy of sensitive user attributes in FL environment with
the graph-based model. To address the group bias, we propose F2PGNN (Fair
Federated Personalized Graph Neural Network), a novel framework that leverages
the power of Personalized Graph Neural Network (GNN) coupled with fairness
considerations. Additionally, we use differential privacy techniques to fortify
privacy protection. Experimental evaluation on three publicly available
datasets showcases the efficacy of F2PGNN in mitigating group unfairness by 47%
- 99% compared to the state-of-the-art while preserving privacy and maintaining
the utility. The results validate the significance of our framework in
achieving equitable and personalized recommendations using GNN within the FL
landscape.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10082" title="Abstract">arXiv:2312.10082</a> [<a href="/pdf/2312.10082" title="Download PDF">pdf</a>, <a href="/format/2312.10082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Paths for Explainable MOOC Recommendation: A Learner Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frej%2C+J">Jibril Frej</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Neel Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kne%C5%BEevi%C4%87%2C+M">Marta Kne&#x17e;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Nazaretsky%2C+T">Tanya Nazaretsky</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ser%2C+T">Tanja K&#xe4;ser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing availability of Massive Open Online Courses (MOOCs) has
created a necessity for personalized course recommendation systems. These
systems often combine neural networks with Knowledge Graphs (KGs) to achieve
richer representations of learners and courses. While these enriched
representations allow more accurate and personalized recommendations,
explainability remains a significant challenge which is especially problematic
for certain domains with significant impact such as education and online
learning. Recently, a novel class of recommender systems that uses
reinforcement learning and graph reasoning over KGs has been proposed to
generate explainable recommendations in the form of paths over a KG. Despite
their accuracy and interpretability on e-commerce datasets, these approaches
have scarcely been applied to the educational domain and their use in practice
has not been studied. In this work, we propose an explainable recommendation
system for MOOCs that uses graph reasoning. To validate the practical
implications of our approach, we conducted a user study examining user
perceptions of our new explainable recommendations. We demonstrate the
generalizability of our approach by conducting experiments on two educational
datasets: COCO and Xuetang.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10083" title="Abstract">arXiv:2312.10083</a> [<a href="/pdf/2312.10083" title="Download PDF">pdf</a>, <a href="/ps/2312.10083" title="Download PostScript">ps</a>, <a href="/format/2312.10083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limits of Fair Medical Imaging AI In The Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gichoya%2C+J+W">Judy W Gichoya</a>, 
<a href="/search/cs?searchtype=author&query=Katabi%2C+D">Dina Katabi</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data are available at <a href="https://github.com/YyzHarry/shortcut-ood-fairness">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">As artificial intelligence (AI) rapidly approaches human-level performance in
medical imaging, it is crucial that it does not exacerbate or propagate
healthcare disparities. Prior research has established AI's capacity to infer
demographic data from chest X-rays, leading to a key concern: do models using
demographic shortcuts have unfair predictions across subpopulations? In this
study, we conduct a thorough investigation into the extent to which medical AI
utilizes demographic encodings, focusing on potential fairness discrepancies
within both in-distribution training sets and external test sets. Our analysis
covers three key medical imaging disciplines: radiology, dermatology, and
ophthalmology, and incorporates data from six global chest X-ray datasets. We
confirm that medical imaging AI leverages demographic shortcuts in disease
classification. While correcting shortcuts algorithmically effectively
addresses fairness gaps to create "locally optimal" models within the original
data distribution, this optimality is not true in new test settings.
Surprisingly, we find that models with less encoding of demographic attributes
are often most "globally optimal", exhibiting better fairness during model
evaluation in new test environments. Our work establishes best practices for
medical imaging models which maintain their performance and fairness in
deployments beyond their initial training contexts, underscoring critical
considerations for AI clinical deployments across populations and sites.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10089" title="Abstract">arXiv:2312.10089</a> [<a href="/pdf/2312.10089" title="Download PDF">pdf</a>, <a href="/ps/2312.10089" title="Download PostScript">ps</a>, <a href="/format/2312.10089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Content-Based Image Retrieval: A Comprehensive Survey of  Relevance Feedback Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qazanfari%2C+H">Hamed Qazanfari</a>, 
<a href="/search/cs?searchtype=author&query=AlyanNezhadi%2C+M+M">Mohammad M. AlyanNezhadi</a>, 
<a href="/search/cs?searchtype=author&query=Khoshdaregi%2C+Z+N">Zohreh Nozari Khoshdaregi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Content-based image retrieval (CBIR) systems have emerged as crucial tools in
the field of computer vision, allowing for image search based on visual content
rather than relying solely on metadata. This survey paper presents a
comprehensive overview of CBIR, emphasizing its role in object detection and
its potential to identify and retrieve visually similar images based on content
features. Challenges faced by CBIR systems, including the semantic gap and
scalability, are discussed, along with potential solutions. It elaborates on
the semantic gap, which arises from the disparity between low-level features
and high-level semantic concepts, and explores approaches to bridge this gap.
One notable solution is the integration of relevance feedback (RF), empowering
users to provide feedback on retrieved images and refine search results
iteratively. The survey encompasses long-term and short-term learning
approaches that leverage RF for enhanced CBIR accuracy and relevance. These
methods focus on weight optimization and the utilization of active learning
algorithms to select samples for training classifiers. Furthermore, the paper
investigates machine learning techniques and the utilization of deep learning
and convolutional neural networks to enhance CBIR performance. This survey
paper plays a significant role in advancing the understanding of CBIR and RF
techniques. It guides researchers and practitioners in comprehending existing
methodologies, challenges, and potential solutions while fostering knowledge
dissemination and identifying research gaps. By addressing future research
directions, it sets the stage for advancements in CBIR that will enhance
retrieval accuracy, usability, and effectiveness in various application
domains.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10091" title="Abstract">arXiv:2312.10091</a> [<a href="/pdf/2312.10091" title="Download PDF">pdf</a>, <a href="/format/2312.10091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: A Universal Emergent Decomposition of Retrieval  Tasks in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Variengien%2C+A">Alexandre Variengien</a>, 
<a href="/search/cs?searchtype=author&query=Winsor%2C+E">Eric Winsor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">When solving challenging problems, language models (LMs) are able to identify
relevant information from long and complicated contexts. To study how LMs solve
retrieval tasks in diverse situations, we introduce ORION, a collection of
structured retrieval tasks spanning six domains, from text understanding to
coding. Each task in ORION can be represented abstractly by a request (e.g. a
question) that retrieves an attribute (e.g. the character name) from a context
(e.g. a story). We apply causal analysis on 18 open-source language models with
sizes ranging from 125 million to 70 billion parameters. We find that LMs
internally decompose retrieval tasks in a modular way: middle layers at the
last token position process the request, while late layers retrieve the correct
entity from the context. After causally enforcing this decomposition, models
are still able to solve the original task, preserving 70% of the original
correct token probability in 98 of the 106 studied model-task pairs. We connect
our macroscopic decomposition with a microscopic description by performing a
fine-grained case study of a question-answering task on Pythia-2.8b. Building
on our high-level understanding, we demonstrate a proof of concept application
for scalable internal oversight of LMs to mitigate prompt-injection while
requiring human supervision on only a single input. Our solution improves
accuracy drastically (from 15.5% to 97.5% on Pythia-12b). This work presents
evidence of a universal emergent modular processing of tasks across varied
domains and models and is a pioneering effort in applying interpretability for
scalable internal oversight of LMs.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10092" title="Abstract">arXiv:2312.10092</a> [<a href="/pdf/2312.10092" title="Download PDF">pdf</a>, <a href="/format/2312.10092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introspecting the Happiness amongst University Students using Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+S">Sakshi Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Priyadarshini%2C+P">Pooja Priyadarshini</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Subhankar Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Figures, 10 tables, 12 pages. Accepted at Happiness Meet IIT Kharagpur-2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Happiness underlines the intuitive constructs of a specified population based
on positive psychological outcomes. It is the cornerstone of the cognitive
skills and exploring university student's happiness has been the essence of the
researchers lately. In this study, we have analyzed the university student's
happiness and its facets using statistical distribution charts; designing
research questions. Furthermore, regression analysis, machine learning, and
clustering algorithms were applied on the world happiness dataset and
university student's dataset for training and testing respectively. Philosophy
was the happiest department while Sociology the saddest; average happiness
score being 2.8 and 2.44 respectively. Pearson coefficient of correlation was
0.74 for Health. Predicted happiness score was 5.2 and the goodness of model
fit was 51%. train and test error being 0.52, 0.47 respectively. On a
Confidence Interval(CI) of 5% p-value was least for Campus Environment(CE) and
University Reputation(UR) and maximum for Extra-curricular Activities(ECA) and
Work Balance(WB) (i.e. 0.184 and 0.228 respectively). RF with Clustering got
the highest accuracy(89%) and F score(0.98) and the least error(17.91%), hence
turned out to be best for our study
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10093" title="Abstract">arXiv:2312.10093</a> [<a href="/pdf/2312.10093" title="Download PDF">pdf</a>, <a href="/ps/2312.10093" title="Download PostScript">ps</a>, <a href="/format/2312.10093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verbesserung des Record Linkage f&#xfc;r die Gesundheitsforschung in  Deutschland
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Intemann%2C+T">Timm Intemann</a>, 
<a href="/search/cs?searchtype=author&query=Kaulke%2C+K">Knut Kaulke</a>, 
<a href="/search/cs?searchtype=author&query=Kipker%2C+D">Dennis-Kenji Kipker</a>, 
<a href="/search/cs?searchtype=author&query=Lettieri%2C+V">Vanessa Lettieri</a>, 
<a href="/search/cs?searchtype=author&query=Stallmann%2C+C">Christoph Stallmann</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C+O">Carsten O. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Geidel%2C+L">Lars Geidel</a>, 
<a href="/search/cs?searchtype=author&query=Bialke%2C+M">Martin Bialke</a>, 
<a href="/search/cs?searchtype=author&query=Hampf%2C+C">Christopher Hampf</a>, 
<a href="/search/cs?searchtype=author&query=Stahl%2C+D">Dana Stahl</a>, 
<a href="/search/cs?searchtype=author&query=Lablans%2C+M">Martin Lablans</a>, 
<a href="/search/cs?searchtype=author&query=Rohde%2C+F">Florens Rohde</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+M">Martin Franke</a>, 
<a href="/search/cs?searchtype=author&query=Kraywinkel%2C+K">Klaus Kraywinkel</a>, 
<a href="/search/cs?searchtype=author&query=Kieschke%2C+J">Joachim Kieschke</a>, 
<a href="/search/cs?searchtype=author&query=Bartholom%C3%A4us%2C+S">Sebastian Bartholom&#xe4;us</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%A4her%2C+A">Anatol-Fiete N&#xe4;her</a>, 
<a href="/search/cs?searchtype=author&query=Tremper%2C+G">Galina Tremper</a>, 
<a href="/search/cs?searchtype=author&query=Lambarki%2C+M">Mohamed Lambarki</a>, 
<a href="/search/cs?searchtype=author&query=March%2C+S">Stefanie March</a>, 
<a href="/search/cs?searchtype=author&query=Prasser%2C+F">Fabian Prasser</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+A+C">Anna Christine Haber</a>, 
<a href="/search/cs?searchtype=author&query=Drepper%2C+J">Johannes Drepper</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%BCnder%2C+I">Irene Schl&#xfc;nder</a>, 
<a href="/search/cs?searchtype=author&query=Kirsten%2C+T">Toralf Kirsten</a>, 
<a href="/search/cs?searchtype=author&query=Pigeot%2C+I">Iris Pigeot</a>, 
<a href="/search/cs?searchtype=author&query=Sax%2C+U">Ulrich Sax</a>, 
<a href="/search/cs?searchtype=author&query=Buchner%2C+B">Benedikt Buchner</a>, 
<a href="/search/cs?searchtype=author&query=Ahrens%2C+W">Wolfgang Ahrens</a>, 
<a href="/search/cs?searchtype=author&query=Semler%2C+S+C">Sebastian C. Semler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in German language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">Record linkage means linking data from multiple sources. This approach
enables the answering of scientific questions that cannot be addressed using
single data sources due to limited variables. The potential of linked data for
health research is enormous, as it can enhance prevention, treatment, and
population health policies. Due the sensitivity of health data, there are
strict legal requirements to prevent potential misuse. However, these
requirements also limit the use of health data for research, thereby hindering
innovations in prevention and care. Also, comprehensive Record linkage in
Germany is often challenging due to lacking unique personal identifiers or
interoperable solutions. Rather, the need to protect data is often weighed
against the importance of research aiming at healthcare enhancements: for
instance, data protection officers may demand the informed consent of
individual study participants for data linkage, even when this is not
mandatory. Furthermore, legal frameworks may be interpreted differently on
varying occasions. Given both, technical and legal challenges, record linkage
for health research in Germany falls behind the standards of other European
countries. To ensure successful record linkage, case-specific solutions must be
developed, tested, and modified as necessary before implementation. This paper
discusses limitations and possibilities of various data linkage approaches
tailored to different use cases in compliance with the European General Data
Protection Regulation. It further describes requirements for achieving a more
research-friendly approach to linking health data records in Germany.
Additionally, it provides recommendations to legislators. The objective of this
work is to improve record linkage for health research in Germany.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10094" title="Abstract">arXiv:2312.10094</a> [<a href="/pdf/2312.10094" title="Download PDF">pdf</a>, <a href="/format/2312.10094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluative Item-Contrastive Explanations in Rankings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castelnovo%2C+A">Alessandro Castelnovo</a>, 
<a href="/search/cs?searchtype=author&query=Crupi%2C+R">Riccardo Crupi</a>, 
<a href="/search/cs?searchtype=author&query=Mombelli%2C+N">Nicol&#xf2; Mombelli</a>, 
<a href="/search/cs?searchtype=author&query=Nanino%2C+G">Gabriele Nanino</a>, 
<a href="/search/cs?searchtype=author&query=Regoli%2C+D">Daniele Regoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The remarkable success of Artificial Intelligence in advancing automated
decision-making is evident both in academia and industry. Within the plethora
of applications, ranking systems hold significant importance in various
domains. This paper advocates for the application of a specific form of
Explainable AI -- namely, contrastive explanations -- as particularly
well-suited for addressing ranking problems. This approach is especially potent
when combined with an Evaluative AI methodology, which conscientiously
evaluates both positive and negative aspects influencing a potential ranking.
Therefore, the present work introduces Evaluative Item-Contrastive Explanations
tailored for ranking systems and illustrates its application and
characteristics through an experiment conducted on publicly available data.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10095" title="Abstract">arXiv:2312.10095</a> [<a href="/pdf/2312.10095" title="Download PDF">pdf</a>, <a href="/ps/2312.10095" title="Download PostScript">ps</a>, <a href="/format/2312.10095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Casual Social Media Use among the Youth: Effects on Online and Offline  Political Participation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barati%2C+M">Mehdi Barati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Background: Previous studies suggest that social media use among the youth is
correlated with online and offline political participation. There is also a
mixed and inconclusive debate on whether more online political participation in
the youth increases their offline political participation. Methods: This study
uses three models of OLS, two-way fixed effects, and an instrumental variable
approach to make causal inferences about social media use, online, and offline
political participation of the youth. Findings: The analyses provide evidence
of a large effect of casual social media use on online political participation,
and no effect or negligible effect on offline political participation and
voting behavior. The results from fixed effects and instrumental variable
models provide strong evidence of elasticity between online and offline
political participation in young individuals. On average, a one percent
increase in online political participation increases the offline political
activity index by 0.12 percent.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10096" title="Abstract">arXiv:2312.10096</a> [<a href="/pdf/2312.10096" title="Download PDF">pdf</a>, <a href="/ps/2312.10096" title="Download PostScript">ps</a>, <a href="/format/2312.10096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Government Data Programs and Information Privacy Concerns: A  Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barati%2C+M">Mehdi Barati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
<p class="mathjax">This study presents a narrative review of the literature on privacy concerns
of Open Government Data (OGD) programs and identifies suggested technical,
procedural, and legal remedies. Peer-reviewed articles were identified and
analysed from major bibliographic databases, including Web of Science, Digital
ACM Library, IEEE Explore Digital Library and Science Direct. Included articles
focus on identifying individual information privacy concerns from the viewpoint
of OGD stakeholders or providing solutions for mitigating concerns and risks.
Papers that discussed and focused on general privacy issues or privacy concerns
of open data in general or open science privacy concerns were excluded. Three
streams of research were identified: 1) exploring privacy concerns and balance
with OGD value propositions, 2) proposing solutions for mitigating privacy
concerns, and 3) developing risk-based frameworks for the OGD program at
different governmental levels. Findings suggest that contradictions with Fair
Information Practices, reidentification risks, conflicts with OGD value
propositions, and smart city data practices are significant privacy concerns in
the literature. Proposed solutions include technical, legal, and procedural
measures to mitigate privacy concerns. Building on the findings, practical
implications and suggested future research directions are provided.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10097" title="Abstract">arXiv:2312.10097</a> [<a href="/pdf/2312.10097" title="Download PDF">pdf</a>, <a href="/ps/2312.10097" title="Download PostScript">ps</a>, <a href="/format/2312.10097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetics-Based Decomposition of Numeral Words -- Arithmetic  Conditions give the Unpacking Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maier%2C+I+K">Isidor Konrad Maier</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+M">Matthias Wolff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we present a novel numeral decomposer that is designed to
revert Hurford's Packing Strategy. The Packing Strategy is a model on how
numeral words are formed out of smaller numeral words by recursion. The
decomposer does not simply check decimal digits but it also works for numerals
formed on base 20 or any other base or even combinations of different bases.
All assumptions that we use are justified with Hurford's Packing Strategy. The
decomposer reads through the numeral. When it finds a sub-numeral, it checks
arithmetic conditions to decide whether or not to unpack the sub-numeral. The
goal is to unpack those numerals that can sensibly be substituted by similar
numerals. E.g., in 'twenty-seven thousand and two hundred and six' it should
unpack 'twenty-seven' and 'two hundred and six', as those could each be
sensibly replaced by any numeral from 1 to 999. Our most used condition is: If
S is a substitutable sub-numeral of a numeral N, then 2*value(S) &lt; value(N). We
have tested the decomposer on numeral systems in 254 different natural
languages. We also developed a reinforcement learning algorithm based on the
decomposer. Both algorithms' code and the results are open source on GitHub.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10099" title="Abstract">arXiv:2312.10099</a> [<a href="/pdf/2312.10099" title="Download PDF">pdf</a>, <a href="/format/2312.10099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADA-YOLO: Dynamic Fusion of YOLOv8 and Adaptive Heads for Precise Image  Detection and Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruocheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+T+T">Teik Toe Teoh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection and localization are crucial tasks for biomedical image
analysis, particularly in the field of hematology where the detection and
recognition of blood cells are essential for diagnosis and treatment decisions.
While attention-based methods have shown significant progress in object
detection in various domains, their application in medical object detection has
been limited due to the unique challenges posed by medical imaging datasets. To
address this issue, we propose ADA-YOLO, a light-weight yet effective method
for medical object detection that integrates attention-based mechanisms with
the YOLOv8 architecture. Our proposed method leverages the dynamic feature
localisation and parallel regression for computer vision tasks through
\textit{adaptive head} module. Empirical experiments were conducted on the
Blood Cell Count and Detection (BCCD) dataset to evaluate the effectiveness of
ADA-YOLO. The results showed that ADA-YOLO outperforms the YOLOv8 model in mAP
(mean average precision) on the BCCD dataset by using more than 3 times less
space than YOLOv8. This indicates that our proposed method is effective.
Moreover, the light-weight nature of our proposed method makes it suitable for
deployment in resource-constrained environments such as mobile devices or edge
computing systems. which could ultimately lead to improved diagnosis and
treatment outcomes in the field of hematology.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10100" title="Abstract">arXiv:2312.10100</a> [<a href="/pdf/2312.10100" title="Download PDF">pdf</a>, <a href="/format/2312.10100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Adaptive Dimensional Analysis for Accurate Interpolation and  Extrapolation in Computer Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez-Arelis%2C+G+A">G. Alexi Rodriguez-Arelis</a>, 
<a href="/search/cs?searchtype=author&query=Welch%2C+W+J">William J. Welch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
<p class="mathjax">Dimensional analysis (DA) pays attention to fundamental physical dimensions
such as length and mass when modelling scientific and engineering systems. It
goes back at least a century to Buckingham's Pi theorem, which characterizes a
scientifically meaningful model in terms of a limited number of dimensionless
variables. The methodology has only been exploited relatively recently by
statisticians for design and analysis of experiments, however, and computer
experiments in particular. The basic idea is to build models in terms of new
dimensionless quantities derived from the original input and output variables.
A scientifically valid formulation has the potential for improved prediction
accuracy in principle, but the implementation of DA is far from
straightforward. There can be a combinatorial number of possible models
satisfying the conditions of the theory. Empirical approaches for finding
effective derived variables will be described, and improvements in prediction
accuracy will be demonstrated. As DA's dimensionless quantities for a
statistical model typically compare the original variables rather than use
their absolute magnitudes, DA is less dependent on the choice of experimental
ranges in the training data. Hence, we are also able to illustrate sustained
accuracy gains even when extrapolating substantially outside the training data.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10101" title="Abstract">arXiv:2312.10101</a> [<a href="/pdf/2312.10101" title="Download PDF">pdf</a>, <a href="/format/2312.10101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Repository Level Prompting for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schonholtz%2C+D">Douglas Schonholtz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 figures/charts, 7 pages, Submitted as an NLP project at Northeastern. Focuses on comparing two papers, there are many more papers that could be included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">As coding challenges become more complex, recent advancements in Large
Language Models (LLMs) have led to notable successes, such as achieving a
94.6\% solve rate on the HumanEval benchmark. Concurrently, there is an
increasing commercial push for repository-level inline code completion tools,
such as GitHub Copilot and Tab Nine, aimed at enhancing developer productivity.
This paper delves into the transition from individual coding problems to
repository-scale solutions, presenting a thorough review of the current
literature on effective LLM prompting for code generation at the repository
level. We examine approaches that will work with black-box LLMs such that they
will be useful and applicable to commercial use cases, and their applicability
in interpreting code at a repository scale. We juxtapose the Repository-Level
Prompt Generation technique with RepoCoder, an iterative retrieval and
generation method, to highlight the trade-offs inherent in each approach and to
establish best practices for their application in cutting-edge coding
benchmarks. The interplay between iterative refinement of prompts and the
development of advanced retrieval systems forms the core of our discussion,
offering a pathway to significantly improve LLM performance in code generation
tasks. Insights from this study not only guide the application of these methods
but also chart a course for future research to integrate such techniques into
broader software engineering contexts.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10103" title="Abstract">arXiv:2312.10103</a> [<a href="/pdf/2312.10103" title="Download PDF">pdf</a>, <a href="/format/2312.10103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSVA: Generalized Segmentation via Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yizeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuran Pan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalized Referring Expression Segmentation (GRES) extends the scope of
classic RES to referring to multiple objects in one expression or identifying
the empty targets absent in the image. GRES poses challenges in modeling the
complex spatial relationships of the instances in the image and identifying
non-existing referents. Recently, Multimodal Large Language Models (MLLMs) have
shown tremendous progress in these complicated vision-language tasks.
Connecting Large Language Models (LLMs) and vision models, MLLMs are proficient
in understanding contexts with visual inputs. Among them, LISA, as a
representative, adopts a special [SEG] token to prompt a segmentation mask
decoder, e.g., SAM, to enable MLLMs in the RES task. However, existing
solutions to of GRES remain unsatisfactory since current segmentation MLLMs
cannot properly handle the cases where users might reference multiple subjects
in a singular prompt or provide descriptions incongruent with any image target.
In this paper, we propose Generalized Segmentation Vision Assistant (GSVA) to
address this gap. Specifically, GSVA reuses the [SEG] token to prompt the
segmentation model towards supporting multiple mask references simultaneously
and innovatively learns to generate a [REJ] token to reject the null targets
explicitly. Experiments validate GSVA's efficacy in resolving the GRES issue,
marking a notable enhancement and setting a new record on the GRES benchmark
gRefCOCO dataset. GSVA also proves effective across various classic referring
expression segmentation and comprehension tasks.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10104" title="Abstract">arXiv:2312.10104</a> [<a href="/pdf/2312.10104" title="Download PDF">pdf</a>, <a href="/format/2312.10104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICD-LM: Configuring Vision-Language In-Context Demonstrations by  Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yingzhe Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies how to configure powerful In-Context Demonstration (ICD)
sequences for a Large Vision-Language Model (LVLM) to solve Vision-Language
tasks through In-Context Learning (ICL). After observing that configuring an
ICD sequence is a mirror process of composing a sentence, i.e., just as a
sentence can be composed word by word via a Language Model, an ICD sequence can
also be configured one by one. Consequently, we introduce an ICD Language Model
(ICD-LM) specifically designed to generate effective ICD sequences. This
involves creating a dataset of hand-crafted ICD sequences for various query
samples and using it to train the ICD-LM. Our approach, diverging from
traditional methods in NLP that select and order ICDs separately, enables to
simultaneously learn how to select and order ICDs, enhancing the effect of the
sequences. Moreover, during data construction, we use the LVLM intended for ICL
implementation to validate the strength of each ICD sequence, resulting in a
model-specific dataset and the ICD-LM trained by this dataset is also
model-specific. We validate our methodology through experiments in Visual
Question Answering and Image Captioning, confirming the viability of using a
Language Model for ICD configuration. Our comprehensive ablation studies
further explore the impact of various dataset construction and ICD-LM
development settings on the outcomes. The code is given in
https://github.com/ForJadeForest/ICD-LM.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10105" title="Abstract">arXiv:2312.10105</a> [<a href="/pdf/2312.10105" title="Download PDF">pdf</a>, <a href="/format/2312.10105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forging Tokens for Improved Storage-efficient Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Song Park</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+B">Byeongho Heo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongyoon Han</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in Deep Neural Network (DNN) models have significantly
improved performance across computer vision tasks. However, achieving highly
generalizable and high-performing vision models requires extensive datasets,
leading to large storage requirements. This storage challenge poses a critical
bottleneck for scaling up vision models. Motivated by the success of discrete
representations, SeiT proposes to use Vector-Quantized (VQ) feature vectors
(i.e., tokens) as network inputs for vision classification. However, applying
traditional data augmentations to tokens faces challenges due to input domain
shift. To address this issue, we introduce TokenAdapt and ColorAdapt, simple
yet effective token-based augmentation strategies. TokenAdapt realigns token
embedding space for compatibility with spatial augmentations, preserving the
model's efficiency without requiring fine-tuning. Additionally, ColorAdapt
addresses color-based augmentations for tokens inspired by Adaptive Instance
Normalization (AdaIN). We evaluate our approach across various scenarios,
including storage-efficient ImageNet-1k classification, fine-grained
classification, robustness benchmarks, and ADE-20k semantic segmentation.
Experimental results demonstrate consistent performance improvement in diverse
experiments. Code is available at https://github.com/naver-ai/tokenadapt.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10106" title="Abstract">arXiv:2312.10106</a> [<a href="/pdf/2312.10106" title="Download PDF">pdf</a>, <a href="/format/2312.10106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-domain Gaussian Process Models for $H_\infty$ Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Devonport%2C+A">Alex Devonport</a>, 
<a href="/search/eess?searchtype=author&query=Seiler%2C+P">Peter Seiler</a>, 
<a href="/search/eess?searchtype=author&query=Arcak%2C+M">Murat Arcak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures. Submission to SICON. arXiv admin note: substantial text overlap with <a href="/abs/2211.15923">arXiv:2211.15923</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Complex-valued Gaussian processes are commonly used in Bayesian
frequency-domain system identification as prior models for regression. If each
realization of such a process were an $H_\infty$ function with probability one,
then the same model could be used for probabilistic robust control, allowing
for robustly safe learning. We investigate sufficient conditions for a general
complex-domain Gaussian process to have this property. For the special case of
processes whose Hermitian covariance is stationary, we provide an explicit
parameterization of the covariance structure in terms of a summable sequence of
nonnegative numbers. We then establish how an $H_\infty$ Gaussian process can
serve as a prior for Bayesian system identification and as a probabilistic
uncertainty model for probabilistic robust control. In particular, we compute
formulas for refining the uncertainty model by conditioning on frequency-domain
data and for upper-bounding the probability that the realizations of the
process satisfy a given integral quadratic constraint.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10107" title="Abstract">arXiv:2312.10107</a> [<a href="/pdf/2312.10107" title="Download PDF">pdf</a>, <a href="/format/2312.10107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Context-Aware Domain Generalization: Representing Environments  with Permutation-Invariant Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Jens M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChmichel%2C+L">Lars K&#xfc;hmichel</a>, 
<a href="/search/cs?searchtype=author&query=Rohbeck%2C+M">Martin Rohbeck</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+S+T">Stefan T. Radev</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we show that information about the context of an input $X$ can
improve the predictions of deep learning models when applied in new domains or
production environments. We formalize the notion of context as a
permutation-invariant representation of a set of data points that originate
from the same environment/domain as the input itself. These representations are
jointly learned with a standard supervised learning objective, providing
incremental information about the unknown outcome. Furthermore, we offer a
theoretical analysis of the conditions under which our approach can, in
principle, yield benefits, and formulate two necessary criteria that can be
easily verified in practice. Additionally, we contribute insights into the kind
of distribution shifts for which our approach promises robustness. Our
empirical evaluation demonstrates the effectiveness of our approach for both
low-dimensional and high-dimensional data sets. Finally, we demonstrate that we
can reliably detect scenarios where a model is tasked with unwarranted
extrapolation in out-of-distribution (OOD) domains, identifying potential
failure cases. Consequently, we showcase a method to select between the most
predictive and the most robust model, circumventing the well-known trade-off
between predictive performance and robustness.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10108" title="Abstract">arXiv:2312.10108</a> [<a href="/pdf/2312.10108" title="Download PDF">pdf</a>, <a href="/format/2312.10108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Document Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tito%2C+R">Rub&#xe8;n Tito</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tobaben%2C+M">Marlon Tobaben</a>, 
<a href="/search/cs?searchtype=author&query=Kerkouche%2C+R">Raouf Kerkouche</a>, 
<a href="/search/cs?searchtype=author&query=Souibgui%2C+M+A">Mohamed Ali Souibgui</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kangsoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+L">Lei Kang</a>, 
<a href="/search/cs?searchtype=author&query=Valveny%2C+E">Ernest Valveny</a>, 
<a href="/search/cs?searchtype=author&query=Honkela%2C+A">Antti Honkela</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Document Visual Question Answering (DocVQA) is a fast growing branch of
document understanding. Despite the fact that documents contain sensitive or
copyrighted information, none of the current DocVQA methods offers strong
privacy guarantees.
<br />In this work, we explore privacy in the domain of DocVQA for the first time.
We highlight privacy issues in state of the art multi-modal LLM models used for
DocVQA, and explore possible solutions.
<br />Specifically, we focus on the invoice processing use case as a realistic,
widely used scenario for document understanding, and propose a large scale
DocVQA dataset comprising invoice documents and associated questions and
answers. We employ a federated learning scheme, that reflects the real-life
distribution of documents in different businesses, and we explore the use case
where the ID of the invoice issuer is the sensitive information to be
protected.
<br />We demonstrate that non-private models tend to memorise, behaviour that can
lead to exposing private information. We then evaluate baseline training
schemes employing federated learning and differential privacy in this
multi-modal scenario, where the sensitive information might be exposed through
any of the two input modalities: vision (document image) or language (OCR
tokens).
<br />Finally, we design an attack exploiting the memorisation effect of the model,
and demonstrate its effectiveness in probing different DocVQA models.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10109" title="Abstract">arXiv:2312.10109</a> [<a href="/pdf/2312.10109" title="Download PDF">pdf</a>, <a href="/format/2312.10109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enlighten-Your-Voice: When Multimodal Meets Zero-shot Low-light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zishan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chaochen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shanying Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+X">Xinping Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.10286">arXiv:2306.10286</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Low-light image enhancement is a crucial visual task, and many unsupervised
methods tend to overlook the degradation of visible information in low-light
scenes, which adversely affects the fusion of complementary information and
hinders the generation of satisfactory results. To address this, our study
introduces ``Enlighten-Your-Voice'', a multimodal enhancement framework that
innovatively enriches user interaction through voice and textual commands. This
approach does not merely signify a technical leap but also represents a
paradigm shift in user engagement. Our model is equipped with a Dual
Collaborative Attention Module (DCAM) that meticulously caters to distinct
content and color discrepancies, thereby facilitating nuanced enhancements.
Complementarily, we introduce a Semantic Feature Fusion (SFM) plug-and-play
module that synergizes semantic context with low-light enhancement operations,
sharpening the algorithm's efficacy. Crucially, ``Enlighten-Your-Voice''
showcases remarkable generalization in unsupervised zero-shot scenarios. The
source code can be accessed from
https://github.com/zhangbaijin/Enlighten-Your-Voice
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10110" title="Abstract">arXiv:2312.10110</a> [<a href="/pdf/2312.10110" title="Download PDF">pdf</a>, <a href="/format/2312.10110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Cognitive Diagnosis using Un-interacted Exercises: A  Collaboration-aware Mixed Sampling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haiping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shangshang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, accepted by AAAI-24 (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cognitive diagnosis is a crucial task in computational education, aimed at
evaluating students' proficiency levels across various knowledge concepts
through exercises. Current models, however, primarily rely on students'
answered exercises, neglecting the complex and rich information contained in
un-interacted exercises. While recent research has attempted to leverage the
data within un-interacted exercises linked to interacted knowledge concepts,
aiming to address the long-tail issue, these studies fail to fully explore the
informative, un-interacted exercises related to broader knowledge concepts.
This oversight results in diminished performance when these models are applied
to comprehensive datasets. In response to this gap, we present the
Collaborative-aware Mixed Exercise Sampling (CMES) framework, which can
effectively exploit the information present in un-interacted exercises linked
to un-interacted knowledge concepts. Specifically, we introduce a novel
universal sampling module where the training samples comprise not merely raw
data slices, but enhanced samples generated by combining weight-enhanced
attention mixture techniques. Given the necessity of real response labels in
cognitive diagnosis, we also propose a ranking-based pseudo feedback module to
regulate students' responses on generated exercises. The versatility of the
CMES framework bolsters existing models and improves their adaptability.
Finally, we demonstrate the effectiveness and interpretability of our framework
through comprehensive experiments on real-world datasets.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10111" title="Abstract">arXiv:2312.10111</a> [<a href="/pdf/2312.10111" title="Download PDF">pdf</a>, <a href="/format/2312.10111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plasticine3D: Non-rigid 3D editting with text guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yige Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Ang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the help of Score Distillation Sampling(SDS) and the rapid development
of various trainable 3D representations, Text-to-Image(T2I) diffusion models
have been applied to 3D generation tasks and achieved considerable results.
There are also some attempts toward the task of editing 3D objects leveraging
this Text-to-3D pipeline. However, most methods currently focus on adding
additional geometries, overwriting textures or both. But few of them can
perform non-rigid transformation of 3D objects. For those who can perform
non-rigid editing, on the other hand, suffer from low-resolution, lack of
fidelity and poor flexibility. In order to address these issues, we present:
Plasticine3D, a general, high-fidelity, photo-realistic and controllable
non-rigid editing pipeline. Firstly, our work divides the editing process into
a geometry editing stage and a texture editing stage to achieve more detailed
and photo-realistic results ; Secondly, in order to perform non-rigid
transformation with controllable results while maintain the fidelity towards
original 3D models in the same time, we propose a multi-view-embedding(MVE)
optimization strategy to ensure that the diffusion model learns the overall
features of the original object and an embedding-fusion(EF) to control the
degree of editing by adjusting the value of the fusing rate. We also design a
geometry processing step before optimizing on the base geometry to cope with
different needs of various editing tasks. Further more, to fully leverage the
geometric prior from the original 3D object, we provide an optional replacement
of score distillation sampling named score projection sampling(SPS) which
enables us to directly perform optimization from the origin 3D mesh in most
common median non-rigid editing scenarios. We demonstrate the effectiveness of
our method on both the non-rigid 3D editing task and general 3D editing task.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10112" title="Abstract">arXiv:2312.10112</a> [<a href="/pdf/2312.10112" title="Download PDF">pdf</a>, <a href="/format/2312.10112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NM-FlowGAN: Modeling sRGB Noise with a Hybrid Approach based on  Normalizing Flows and Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y+J">Young Joo Han</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Ha-Jin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Modeling and synthesizing real sRGB noise is crucial for various low-level
vision tasks. The distribution of real sRGB noise is highly complex and
affected by a multitude of factors, making its accurate modeling extremely
challenging. Therefore, recent studies have proposed methods that employ
data-driven generative models, such as generative adversarial networks (GAN)
and Normalizing Flows. These studies achieve more accurate modeling of sRGB
noise compared to traditional noise modeling methods. However, there are
performance limitations due to the inherent characteristics of each generative
model. To address this issue, we propose NM-FlowGAN, a hybrid approach that
exploits the strengths of both GAN and Normalizing Flows. We simultaneously
employ a pixel-wise noise modeling network based on Normalizing Flows, and
spatial correlation modeling networks based on GAN. In our experiments, our
NM-FlowGAN outperforms other baselines on the sRGB noise synthesis task.
Moreover, the denoising neural network, trained with synthesized image pairs
from our model, also shows superior performance compared to other baselines.
Our code is available at: https://github.com/YoungJooHan/NM-FlowGAN
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10113" title="Abstract">arXiv:2312.10113</a> [<a href="/pdf/2312.10113" title="Download PDF">pdf</a>, <a href="/format/2312.10113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Your Instruction: Fine-grained and Multi-instruction Image  Editing by Attention Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianwei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, diffusion-based methods, like InstructPix2Pix (IP2P), have achieved
effective instruction-based image editing, requiring only natural language
instructions from the user. However, these methods often inadvertently alter
unintended areas and struggle with multi-instruction editing, resulting in
compromised outcomes. To address these issues, we introduce the Focus on Your
Instruction (FoI), a method designed to ensure precise and harmonious editing
across multiple instructions without extra training or test-time optimization.
In the FoI, we primarily emphasize two aspects: (1) precisely extracting
regions of interest for each instruction and (2) guiding the denoising process
to concentrate within these regions of interest. For the first objective, we
identify the implicit grounding capability of IP2P from the cross-attention
between instruction and image, then develop an effective mask extraction
method. For the second objective, we introduce a cross attention modulation
module for rough isolation of target editing regions and unrelated regions.
Additionally, we introduce a mask-guided disentangle sampling strategy to
further ensure clear region isolation. Experimental results demonstrate that
FoI surpasses existing methods in both quantitative and qualitative
evaluations, especially excelling in multi-instruction editing task.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10114" title="Abstract">arXiv:2312.10114</a> [<a href="/pdf/2312.10114" title="Download PDF">pdf</a>, <a href="/format/2312.10114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoMo-Bench: a multi-modal, multi-scale and multi-task Forest Monitoring  Benchmark for remote sensing foundation models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bountos%2C+N+I">Nikolaos Ioannis Bountos</a>, 
<a href="/search/cs?searchtype=author&query=Ouaknine%2C+A">Arthur Ouaknine</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Forests are an essential part of Earth's ecosystems and natural systems, as
well as providing services on which humanity depends, yet they are rapidly
changing as a result of land use decisions and climate change. Understanding
and mitigating negative effects requires parsing data on forests at global
scale from a broad array of sensory modalities, and recently many such problems
have been approached using machine learning algorithms for remote sensing. To
date, forest-monitoring problems have largely been approached in isolation.
Inspired by the rise of foundation models for computer vision and remote
sensing, we here present the first unified Forest Monitoring Benchmark
(FoMo-Bench). FoMo-Bench consists of 15 diverse datasets encompassing
satellite, aerial, and inventory data, covering a variety of geographical
regions, and including multispectral, red-green-blue, synthetic aperture radar
(SAR) and LiDAR data with various temporal, spatial and spectral resolutions.
FoMo-Bench includes multiple types of forest-monitoring tasks, spanning
classification, segmentation, and object detection. To further enhance the
diversity of tasks and geographies represented in FoMo-Bench, we introduce a
novel global dataset, TalloS, combining satellite imagery with ground-based
annotations for tree species classification, spanning 1,000+ hierarchical
taxonomic levels (species, genus, family). Finally, we propose FoMo-Net, a
foundation model baseline designed for forest monitoring with the flexibility
to process any combination of commonly used sensors in remote sensing. This
work aims to inspire research collaborations between machine learning and
forest biology researchers in exploring scalable multi-modal and multi-task
models for forest monitoring. All code and data will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10115" title="Abstract">arXiv:2312.10115</a> [<a href="/pdf/2312.10115" title="Download PDF">pdf</a>, <a href="/format/2312.10115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkySense: A Multi-Modal Remote Sensing Foundation Model Towards  Universal Interpretation for Earth Observation Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+J">Jiangwei Lao</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+B">Bo Dang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ru%2C+L">Lixiang Ru</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Liheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dingxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Huimei He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yansheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prior studies on Remote Sensing Foundation Model (RSFM) reveal immense
potential towards a generic model for Earth Observation. Nevertheless, these
works primarily focus on a single modality without temporal and geo-context
modeling, hampering their capabilities for diverse tasks. In this study, we
present SkySense, a generic billion-scale model, pre-trained on a curated
multi-modal Remote Sensing Imagery (RSI) dataset with 21.5 million temporal
sequences. SkySense incorporates a factorized multi-modal spatiotemporal
encoder taking temporal sequences of optical and Synthetic Aperture Radar (SAR)
data as input. This encoder is pre-trained by our proposed Multi-Granularity
Contrastive Learning to learn representations across different modal and
spatial granularities. To further enhance the RSI representations by the
geo-context clue, we introduce Geo-Context Prototype Learning to learn
region-aware prototypes upon RSI's multi-modal spatiotemporal features. To our
best knowledge, SkySense is the largest Multi-Modal RSFM to date, whose modules
can be flexibly combined or used individually to accommodate various tasks. It
demonstrates remarkable generalization capabilities on a thorough evaluation
encompassing 16 datasets over 7 tasks, from single- to multi-modal, static to
temporal, and classification to localization. SkySense surpasses 18 recent
RSFMs in all test scenarios. Specifically, it outperforms the latest models
such as GFM, SatLas and Scale-MAE by a large margin, i.e., 2.76%, 3.67% and
3.61% on average respectively. We will release the pre-trained weights to
facilitate future research and Earth Observation applications.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10116" title="Abstract">arXiv:2312.10116</a> [<a href="/pdf/2312.10116" title="Download PDF">pdf</a>, <a href="/format/2312.10116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Estimate of Mean Proper Scores for Diversity-Enhanced Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lan Du</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, TPAMI. arXiv admin note: text overlap with <a href="/abs/2110.14171">arXiv:2110.14171</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TPAMI, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The effectiveness of active learning largely depends on the sampling
efficiency of the acquisition function. Expected Loss Reduction (ELR) focuses
on a Bayesian estimate of the reduction in classification error, and more
general costs fit in the same framework. We propose Bayesian Estimate of Mean
Proper Scores (BEMPS) to estimate the increase in strictly proper scores such
as log probability or negative mean square error within this framework. We also
prove convergence results for this general class of costs. To facilitate better
experimentation with the new acquisition functions, we develop a complementary
batch AL algorithm that encourages diversity in the vector of expected changes
in scores for unlabeled data. To allow high-performance classifiers, we combine
deep ensembles, and dynamic validation set construction on pretrained models,
and further speed up the ensemble process with the idea of Monte Carlo Dropout.
Extensive experiments on both texts and images show that the use of mean square
error and log probability with BEMPS yields robust acquisition functions and
well-calibrated classifiers, and consistently outperforms the others tested.
The advantages of BEMPS over the others are further supported by a set of
qualitative analyses, where we visualise their sampling behaviour using data
maps and t-SNE plots.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10118" title="Abstract">arXiv:2312.10118</a> [<a href="/pdf/2312.10118" title="Download PDF">pdf</a>, <a href="/format/2312.10118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From-Ground-To-Objects: Coarse-to-Fine Self-supervised Monocular Depth  Estimation of Dynamic Objects with Ground Contact Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+J">Jaeho Moon</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+J+L+G">Juan Luis Gonzalez Bello</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B">Byeongjun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Munchurl Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised monocular depth estimation (DE) is an approach to learning
depth without costly depth ground truths. However, it often struggles with
moving objects that violate the static scene assumption during training. To
address this issue, we introduce a coarse-to-fine training strategy leveraging
the ground contacting prior based on the observation that most moving objects
in outdoor scenes contact the ground. In the coarse training stage, we exclude
the objects in dynamic classes from the reprojection loss calculation to avoid
inaccurate depth learning. To provide precise supervision on the depth of the
objects, we present a novel Ground-contacting-prior Disparity Smoothness Loss
(GDS-Loss) that encourages a DE network to align the depth of the objects with
their ground-contacting points. Subsequently, in the fine training stage, we
refine the DE network to learn the detailed depth of the objects from the
reprojection loss, while ensuring accurate DE on the moving object regions by
employing our regularization loss with a cost-volume-based weighting factor.
Our overall coarse-to-fine training strategy can easily be integrated with
existing DE methods without any modifications, significantly enhancing DE
performance on challenging Cityscapes and KITTI datasets, especially in the
moving object regions.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10120" title="Abstract">arXiv:2312.10120</a> [<a href="/pdf/2312.10120" title="Download PDF">pdf</a>, <a href="/format/2312.10120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVHuman: Tailoring 2D Diffusion with Multi-view Sampling For Realistic  3D Human Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Suyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haimin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoran Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent months have witnessed rapid progress in 3D generation based on
diffusion models. Most advances require fine-tuning existing 2D Stable
Diffsuions into multi-view settings or tedious distilling operations and hence
fall short of 3D human generation due to the lack of diverse 3D human datasets.
We present an alternative scheme named MVHuman to generate human radiance
fields from text guidance, with consistent multi-view images directly sampled
from pre-trained Stable Diffsuions without any fine-tuning or distilling. Our
core is a multi-view sampling strategy to tailor the denoising processes of the
pre-trained network for generating consistent multi-view images. It encompasses
view-consistent conditioning, replacing the original noises with
``consistency-guided noises'', optimizing latent codes, as well as utilizing
cross-view attention layers. With the multi-view images through the sampling
process, we adopt geometry refinement and 3D radiance field generation followed
by a subsequent neural blending scheme for free-view rendering. Extensive
experiments demonstrate the efficacy of our method, as well as its superiority
to state-of-the-art 3D human generation methods.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10123" title="Abstract">arXiv:2312.10123</a> [<a href="/pdf/2312.10123" title="Download PDF">pdf</a>, <a href="/format/2312.10123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Soft Actor-Critic Policy Collaboration via  Regulated Segment Mixture in Internet of Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaoxue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chengchao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning (MARL) has emerged as a foundational
approach for addressing diverse, intelligent control tasks, notably in
autonomous driving within the Internet of Vehicles (IoV) domain. However, the
widely assumed existence of a central node for centralized, federated
learning-assisted MARL might be impractical in highly dynamic environments.
This can lead to excessive communication overhead, potentially overwhelming the
IoV system. To address these challenges, we design a novel
communication-efficient and policy collaboration algorithm for MARL under the
frameworks of Soft Actor-Critic (SAC) and Decentralized Federated Learning
(DFL), named RSM-MASAC, within a fully distributed architecture. In particular,
RSM-MASAC enhances multi-agent collaboration and prioritizes higher
communication efficiency in dynamic IoV system by incorporating the concept of
segmented aggregation in DFL and augmenting multiple model replicas from
received neighboring policy segments, which are subsequently employed as
reconstructed referential policies for mixing. Distinctively diverging from
traditional RL approaches, with derived new bounds under Maximum Entropy
Reinforcement Learning (MERL), RSM-MASAC adopts a theory-guided mixture metric
to regulate the selection of contributive referential policies to guarantee the
soft policy improvement during communication phase. Finally, the extensive
simulations in mixed-autonomy traffic control scenarios verify the
effectiveness and superiority of our algorithm.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10126" title="Abstract">arXiv:2312.10126</a> [<a href="/pdf/2312.10126" title="Download PDF">pdf</a>, <a href="/format/2312.10126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Text Simplification Systems Preserve Meaning? A Human Evaluation via  Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Sweta Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TACL (a pre-MIT Press publication version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic text simplification (TS) aims to automate the process of rewriting
text to make it easier for people to read. A pre-requisite for TS to be useful
is that it should convey information that is consistent with the meaning of the
original text. However, current TS evaluation protocols assess system outputs
for simplicity and meaning preservation without regard for the document context
in which output sentences occur and for how people understand them. In this
work, we introduce a human evaluation framework to assess whether simplified
texts preserve meaning using reading comprehension questions. With this
framework, we conduct a thorough human evaluation of texts by humans and by
nine automatic systems. Supervised systems that leverage pre-training knowledge
achieve the highest scores on the reading comprehension (RC) tasks amongst the
automatic controllable TS systems. However, even the best-performing supervised
system struggles with at least 14% of the questions, marking them as
"unanswerable'' based on simplified content. We further investigate how
existing TS evaluation metrics and automatic question-answering systems
approximate the human judgments we obtained.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10127" title="Abstract">arXiv:2312.10127</a> [<a href="/pdf/2312.10127" title="Download PDF">pdf</a>, <a href="/format/2312.10127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Does It Function? Characterizing Long-term Trends in Production  Serverless Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joosen%2C+A">Artjom Joosen</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A">Ahmed Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Asenov%2C+M">Martin Asenov</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rajkarn Singh</a>, 
<a href="/search/cs?searchtype=author&query=Darlow%2C+L">Luke Darlow</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+A">Adam Barker</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SoCC '23: Proceedings of the 2023 ACM Symposium on Cloud
  Computing, October 2023, Pages 443-458
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper releases and analyzes two new Huawei cloud serverless traces. The
traces span a period of over 7 months with over 1.4 trillion function
invocations combined. The first trace is derived from Huawei's internal
workloads and contains detailed per-second statistics for 200 functions running
across multiple Huawei cloud data centers. The second trace is a representative
workload from Huawei's public FaaS platform. This trace contains per-minute
arrival rates for over 5000 functions running in a single Huawei data center.
We present the internals of a production FaaS platform by characterizing
resource consumption, cold-start times, programming languages used,
periodicity, per-second versus per-minute burstiness, correlations, and
popularity. Our findings show that there is considerable diversity in how
serverless functions behave: requests vary by up to 9 orders of magnitude
across functions, with some functions executed over 1 billion times per day;
scheduling time, execution time and cold-start distributions vary across 2 to 4
orders of magnitude and have very long tails; and function invocation counts
demonstrate strong periodicity for many individual functions and on an
aggregate level. Our analysis also highlights the need for further research in
estimating resource reservations and time-series prediction to account for the
huge diversity in how serverless functions behave.
<br />Datasets and code available at https://github.com/sir-lab/data-release
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10128" title="Abstract">arXiv:2312.10128</a> [<a href="/pdf/2312.10128" title="Download PDF">pdf</a>, <a href="/ps/2312.10128" title="Download PostScript">ps</a>, <a href="/format/2312.10128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Information-Flow Perspective on Algorithmic Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teuber%2C+S">Samuel Teuber</a>, 
<a href="/search/cs?searchtype=author&query=Beckert%2C+B">Bernhard Beckert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; extended version of paper to appear at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This work presents insights gained by investigating the relationship between
algorithmic fairness and the concept of secure information flow. The problem of
enforcing secure information flow is well-studied in the context of information
security: If secret information may "flow" through an algorithm or program in
such a way that it can influence the program's output, then that is considered
insecure information flow as attackers could potentially observe (parts of) the
secret.
<br />There is a strong correspondence between secure information flow and
algorithmic fairness: if protected attributes such as race, gender, or age are
treated as secret program inputs, then secure information flow means that these
``secret'' attributes cannot influence the result of a program. While most
research in algorithmic fairness evaluation concentrates on studying the impact
of algorithms (often treating the algorithm as a black-box), the concepts
derived from information flow can be used both for the analysis of disparate
treatment as well as disparate impact w.r.t. a structural causal model.
<br />In this paper, we examine the relationship between quantitative as well as
qualitative information-flow properties and fairness. Moreover, based on this
duality, we derive a new quantitative notion of fairness called fairness
spread, which can be easily analyzed using quantitative information flow and
which strongly relates to counterfactual fairness. We demonstrate that
off-the-shelf tools for information-flow properties can be used in order to
formally analyze a program's algorithmic fairness properties, including the new
notion of fairness spread as well as established notions such as demographic
parity.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10132" title="Abstract">arXiv:2312.10132</a> [<a href="/pdf/2312.10132" title="Download PDF">pdf</a>, <a href="/format/2312.10132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs Against  Query-Based Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+P">Pascal Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Andreina%2C+S">S&#xe9;bastien Andreina</a>, 
<a href="/search/cs?searchtype=author&query=Marson%2C+G+A">Giorgia Azzurra Marson</a>, 
<a href="/search/cs?searchtype=author&query=Karame%2C+G">Ghassan Karame</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although promising, existing defenses against query-based attacks share a
common limitation: they offer increased robustness against attacks at the price
of a considerable accuracy drop on clean samples. In this work, we show how to
efficiently establish, at test-time, a solid tradeoff between robustness and
accuracy when mitigating query-based attacks. Given that these attacks
necessarily explore low-confidence regions, our insight is that activating
dedicated defenses, such as RND (Qin et al., NeuRIPS 2021) and Random Image
Transformations (Xie et al., ICLR 2018), only for low-confidence inputs is
sufficient to prevent them. Our approach is independent of training and
supported by theory. We verify the effectiveness of our approach for various
existing defenses by conducting extensive experiments on CIFAR-10, CIFAR-100,
and ImageNet. Our results confirm that our proposal can indeed enhance these
defenses by providing better tradeoffs between robustness and accuracy when
compared to state-of-the-art approaches while being completely training-free.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10136" title="Abstract">arXiv:2312.10136</a> [<a href="/pdf/2312.10136" title="Download PDF">pdf</a>, <a href="/format/2312.10136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-based Parameter Selection for Efficient Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zijun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shutova%2C+E">Ekaterina Shutova</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shiji Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the growing size of pre-trained models, full fine-tuning and storing all
the parameters for various downstream tasks is costly and infeasible. In this
paper, we propose a new parameter-efficient fine-tuning method, Gradient-based
Parameter Selection (GPS), demonstrating that only tuning a few selected
parameters from the pre-trained model while keeping the remainder of the model
frozen can generate similar or better performance compared with the full model
fine-tuning method. Different from the existing popular and state-of-the-art
parameter-efficient fine-tuning approaches, our method does not introduce any
additional parameters and computational costs during both the training and
inference stages. Another advantage is the model-agnostic and non-destructive
property, which eliminates the need for any other design specific to a
particular model. Compared with the full fine-tuning, GPS achieves 3.33%
(91.78% vs. 88.45%, FGVC) and 9.61% (73.1% vs. 65.57%, VTAB) improvement of the
accuracy with tuning only 0.36% parameters of the pre-trained model on average
over 24 image classification tasks; it also demonstrates a significant
improvement of 17% and 16.8% in mDice and mIoU, respectively, on medical image
segmentation task. Moreover, GPS achieves state-of-the-art performance compared
with existing PEFT methods.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10144" title="Abstract">arXiv:2312.10144</a> [<a href="/pdf/2312.10144" title="Download PDF">pdf</a>, <a href="/format/2312.10144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Efficient Multimodal Fusion on a Single GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vouitsis%2C+N">No&#xeb;l Vouitsis</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gorti%2C+S+K">Satya Krishna Gorti</a>, 
<a href="/search/cs?searchtype=author&query=Villecroze%2C+V">Valentin Villecroze</a>, 
<a href="/search/cs?searchtype=author&query=Cresswell%2C+J+C">Jesse C. Cresswell</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Loaiza-Ganem%2C+G">Gabriel Loaiza-Ganem</a>, 
<a href="/search/cs?searchtype=author&query=Volkovs%2C+M">Maksims Volkovs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The goal of multimodal alignment is to learn a single latent space that is
shared between multimodal inputs. The most powerful models in this space have
been trained using massive datasets of paired inputs and large-scale
computational resources, making them prohibitively expensive to train in many
practical scenarios. We surmise that existing unimodal encoders pre-trained on
large amounts of unimodal data should provide an effective bootstrap to create
multimodal models from unimodal ones at much lower costs. We therefore propose
FuseMix, a multimodal augmentation scheme that operates on the latent spaces of
arbitrary pre-trained unimodal encoders. Using FuseMix for multimodal
alignment, we achieve competitive performance -- and in certain cases
outperform state-of-the art methods -- in both image-text and audio-text
retrieval, with orders of magnitude less compute and data: for example, we
outperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \!
600\times$ fewer GPU days and $\sim \! 80\times$ fewer image-text pairs.
Additionally, we show how our method can be applied to convert pre-trained
text-to-image generative models into audio-to-image ones. Code is available at:
https://github.com/layer6ai-labs/fusemix.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10153" title="Abstract">arXiv:2312.10153</a> [<a href="/pdf/2312.10153" title="Download PDF">pdf</a>, <a href="/format/2312.10153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Metaplasticity from Synaptic Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+D">Djohan Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Hirtzlin%2C+T">Tifenn Hirtzlin</a>, 
<a href="/search/cs?searchtype=author&query=Januel%2C+T">Tarcisius Januel</a>, 
<a href="/search/cs?searchtype=author&query=Dalgaty%2C+T">Thomas Dalgaty</a>, 
<a href="/search/cs?searchtype=author&query=Querlioz%2C+D">Damien Querlioz</a>, 
<a href="/search/cs?searchtype=author&query=Vianello%2C+E">Elisa Vianello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Catastrophic forgetting remains a challenge for neural networks, especially
in lifelong learning scenarios. In this study, we introduce MEtaplasticity from
Synaptic Uncertainty (MESU), inspired by metaplasticity and Bayesian inference
principles. MESU harnesses synaptic uncertainty to retain information over
time, with its update rule closely approximating the diagonal Newton's method
for synaptic updates. Through continual learning experiments on permuted MNIST
tasks, we demonstrate MESU's remarkable capability to maintain learning
performance across 100 tasks without the need of explicit task boundaries.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10155" title="Abstract">arXiv:2312.10155</a> [<a href="/pdf/2312.10155" title="Download PDF">pdf</a>, <a href="/ps/2312.10155" title="Download PostScript">ps</a>, <a href="/format/2312.10155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process-Based Learning Control of Underactuated Balance Robots  with an External and Internal Convertible Modeling Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feng Han</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">External and internal convertible (EIC) form-based motion control is one of
the effective designs of simultaneously trajectory tracking and balance for
underactuated balance robots. Under certain conditions, the EIC-based control
design however leads to uncontrolled robot motion. We present a Gaussian
process (GP)-based data-driven learning control for underactuated balance
robots with the EIC modeling structure. Two GP-based learning controllers are
presented by using the EIC structure property. The partial EIC (PEIC)-based
control design partitions the robotic dynamics into a fully actuated subsystem
and one reduced-order underactuated system. The null-space EIC (NEIC)-based
control compensates for the uncontrolled motion in a subspace, while the other
closed-loop dynamics are not affected. Under the PEIC- and NEIC-based, the
tracking and balance tasks are guaranteed and convergence rate and bounded
errors are achieved without causing any uncontrolled motion by the original
EIC-based control. We validate the results and demonstrate the GP-based
learning control design performance using two inverted pendulum platforms.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10160" title="Abstract">arXiv:2312.10160</a> [<a href="/pdf/2312.10160" title="Download PDF">pdf</a>, <a href="/format/2312.10160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in  Chart Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kung-Hsiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+H+P">Hou Pong Chan</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+Y+R">Yi R. Fung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenhailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in large vision-language models (LVLMs) have led to
significant progress in generating natural language descriptions for visual
content and thus enhancing various applications. One issue with these powerful
models is that they sometimes produce texts that are factually inconsistent
with the visual input. While there has been some effort to mitigate such
inconsistencies in natural image captioning, the factuality of generated
captions for structured document images, such as charts, has not received as
much scrutiny, posing a potential threat to information reliability in critical
applications. This work delves into the factuality aspect by introducing a
comprehensive typology of factual errors in generated chart captions. A
large-scale human annotation effort provides insight into the error patterns
and frequencies in captions crafted by various chart captioning models,
ultimately forming the foundation of a novel dataset, CHOCOLATE. Our analysis
reveals that even state-of-the-art models, including GPT-4V, frequently produce
captions laced with factual inaccuracies. In response to this challenge, we
establish the new task of Chart Caption Factual Error Correction and introduce
CHARTVE, a model for visual entailment that outperforms proprietary and
open-source LVLMs in evaluating factual consistency. Furthermore, we propose
C2TFEC, an interpretable two-stage framework that excels at correcting factual
errors. This work inaugurates a new domain in factual error correction for
chart captions, presenting a novel evaluation mechanism, and demonstrating an
effective approach to ensuring the factuality of generated chart captions.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10163" title="Abstract">arXiv:2312.10163</a> [<a href="/pdf/2312.10163" title="Download PDF">pdf</a>, <a href="/format/2312.10163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Unification of Generative and Discriminative Visual  Foundation Model: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qinjingwen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weizhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yonghuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junjun He</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yiqing Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of foundation models, which are pre-trained on vast datasets, has
ushered in a new era of computer vision, characterized by their robustness and
remarkable zero-shot generalization capabilities. Mirroring the transformative
impact of foundation models like large language models (LLMs) in natural
language processing, visual foundation models (VFMs) have become a catalyst for
groundbreaking developments in computer vision. This review paper delineates
the pivotal trajectories of VFMs, emphasizing their scalability and proficiency
in generative tasks such as text-to-image synthesis, as well as their adeptness
in discriminative tasks including image segmentation. While generative and
discriminative models have historically charted distinct paths, we undertake a
comprehensive examination of the recent strides made by VFMs in both domains,
elucidating their origins, seminal breakthroughs, and pivotal methodologies.
Additionally, we collate and discuss the extensive resources that facilitate
the development of VFMs and address the challenges that pave the way for future
research endeavors. A crucial direction for forthcoming innovation is the
amalgamation of generative and discriminative paradigms. The nascent
application of generative models within discriminative contexts signifies the
early stages of this confluence. This survey aspires to be a contemporary
compendium for scholars and practitioners alike, charting the course of VFMs
and illuminating their multifaceted landscape.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10165" title="Abstract">arXiv:2312.10165</a> [<a href="/pdf/2312.10165" title="Download PDF">pdf</a>, <a href="/format/2312.10165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Domain Adaptation by Learning Domain-Aware Batch Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Z">Zhixiang Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Songhe Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAA2024, see this https URL: <a href="https://github.com/ynanwu/MABN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Test-time domain adaptation aims to adapt the model trained on source domains
to unseen target domains using a few unlabeled images. Emerging research has
shown that the label and domain information is separately embedded in the
weight matrix and batch normalization (BN) layer. Previous works normally
update the whole network naively without explicitly decoupling the knowledge
between label and domain. As a result, it leads to knowledge interference and
defective distribution adaptation. In this work, we propose to reduce such
learning interference and elevate the domain knowledge learning by only
manipulating the BN layer. However, the normalization step in BN is
intrinsically unstable when the statistics are re-estimated from a few samples.
We find that ambiguities can be greatly reduced when only updating the two
affine parameters in BN while keeping the source domain statistics. To further
enhance the domain knowledge extraction from unlabeled data, we construct an
auxiliary branch with label-independent self-supervised learning (SSL) to
provide supervision. Moreover, we propose a bi-level optimization based on
meta-learning to enforce the alignment of two learning objectives of auxiliary
and main branches. The goal is to use the auxiliary branch to adapt the domain
and benefit main task for subsequent inference. Our method keeps the same
computational cost at inference as the auxiliary branch can be thoroughly
discarded after adaptation. Extensive experiments show that our method
outperforms the prior works on five WILDS real-world domain shift datasets. Our
method can also be integrated with methods with label-dependent optimization to
further push the performance boundary. Our code is available at
https://github.com/ynanwu/MABN.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10169" title="Abstract">arXiv:2312.10169</a> [<a href="/pdf/2312.10169" title="Download PDF">pdf</a>, <a href="/format/2312.10169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of Unsupervised POS Tagging and Its Implications on Language  Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dickson%2C+N">Niels Dickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">An ability that underlies human syntactic knowledge is determining which
words can appear in the similar structures (i.e. grouping words by their
syntactic categories). These groupings enable humans to combine structures in
order to communicate complex meanings. A foundational question is how do
children acquire this ability underlying syntactic knowledge. In exploring this
process, we will review various engineering approaches whose goal is similar to
that of a child's -- without prior syntactic knowledge, correctly identify the
parts of speech (POS) of the words in a sample of text. In reviewing these
unsupervised tagging efforts, we will discuss common themes that support the
advances in the models and their relevance for language acquisition. For
example, we discuss how each model judges success (evaluation metrics), the
"additional information" that constrains the POS learning (such as orthographic
information), and the context used to determine POS (only previous word, words
before and after the target, etc). The identified themes pave the way for
future investigations into the cognitive processes that underpin the
acquisition of syntactic categories and provide a useful layout of current
state of the art unsupervised POS tagging models.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10170" title="Abstract">arXiv:2312.10170</a> [<a href="/pdf/2312.10170" title="Download PDF">pdf</a>, <a href="/format/2312.10170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UINav: A maker of UI automation agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+F">Fu-Lin Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Bishop%2C+W">Will Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Campbell-Ajala%2C+F">Folawiyo Campbell-Ajala</a>, 
<a href="/search/cs?searchtype=author&query=Riva%2C+O">Oriana Riva</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Max Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An automation system that can execute natural language instructions by
driving the user interface (UI) of an application can benefit users, especially
when situationally or permanently impaired. Traditional automation systems
(manual scripting, programming by demonstration tools, etc.) do not produce
generalizable models that can tolerate changes in the UI or task workflow.
Machine-learned automation agents generalize better, but either work only in
simple, hand-crafted applications or rely on large pre-trained models, which
may be too computationally expensive to run on mobile devices. In this paper,
we propose \emph{UINav}, a demonstration-based agent maker system. UINav agents
are lightweight enough to run on mobile devices, yet they achieve high success
rates with a modest number of task demonstrations. To minimize the number of
task demonstrations, UINav includes a referee model that allows users to
receive immediate feedback on tasks where the agent is failing to best guide
efforts to collect additional demonstrations. Further, UINav adopts macro
actions to reduce an agent's state space, and augments human demonstrations to
increase the diversity of training data. Our evaluation demonstrates that with
an average of 10 demonstrations per task UINav can achieve an accuracy of 70\%
or higher, and that with enough demonstrations it can achieve near-perfect
success rates on 40+ different tasks.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10171" title="Abstract">arXiv:2312.10171</a> [<a href="/pdf/2312.10171" title="Download PDF">pdf</a>, <a href="/format/2312.10171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pipeline and Dataset Generation for Automated Fact-checking in Almost  Any Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drchal%2C+J">Jan Drchal</a>, 
<a href="/search/cs?searchtype=author&query=Ullrich%2C+H">Herbert Ullrich</a>, 
<a href="/search/cs?searchtype=author&query=Mlyn%C3%A1%C5%99%2C+T">Tom&#xe1;&#x161; Mlyn&#xe1;&#x159;</a>, 
<a href="/search/cs?searchtype=author&query=Moravec%2C+V">V&#xe1;clav Moravec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to NCAA journal for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This article presents a pipeline for automated fact-checking leveraging
publicly available Language Models and data. The objective is to assess the
accuracy of textual claims using evidence from a ground-truth evidence corpus.
The pipeline consists of two main modules -- the evidence retrieval and the
claim veracity evaluation. Our primary focus is on the ease of deployment in
various languages that remain unexplored in the field of automated
fact-checking. Unlike most similar pipelines, which work with evidence
sentences, our pipeline processes data on a paragraph level, simplifying the
overall architecture and data requirements. Given the high cost of annotating
language-specific fact-checking training data, our solution builds on the
Question Answering for Claim Generation (QACG) method, which we adapt and use
to generate the data for all models of the pipeline. Our strategy enables the
introduction of new languages through machine translation of only two fixed
datasets of moderate size. Subsequently, any number of training samples can be
generated based on an evidence corpus in the target language. We provide open
access to all data and fine-tuned models for Czech, English, Polish, and Slovak
pipelines, as well as to our codebase that may be used to reproduce the
results.We comprehensively evaluate the pipelines for all four languages,
including human annotations and per-sample difficulty assessment using
Pointwise V-information. The presented experiments are based on full Wikipedia
snapshots to promote reproducibility. To facilitate implementation and user
interaction, we develop the FactSearch application featuring the proposed
pipeline and the preliminary feedback on its performance.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10172" title="Abstract">arXiv:2312.10172</a> [<a href="/pdf/2312.10172" title="Download PDF">pdf</a>, <a href="/format/2312.10172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Load is not what you should balance: Introducing Prequal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wydrowski%2C+B">Bartek Wydrowski</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+R">Robert Kleinberg</a>, 
<a href="/search/cs?searchtype=author&query=Rumble%2C+S+M">Stephen M. Rumble</a>, 
<a href="/search/cs?searchtype=author&query=Archer%2C+A">Aaron Archer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to USENIX NSDI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We present Prequal (Probing to Reduce Queuing and Latency), a load balancer
for distributed multi-tenant systems. Prequal aims to minimize real-time
request latency in the presence of heterogeneous server capacities and
non-uniform, time-varying antagonist load. It actively probes server load to
leverage the power-of-d-choices paradigm, extending it with asynchronous and
reusable probes. Cutting against received wisdom, Prequal does not balance CPU
load, but instead selects servers according to estimated latency and active
requests-in-flight (RIF). We explore its major design features on a testbed
system and evaluate it on YouTube, where it has been deployed for more than two
years. Prequal has dramatically decreased tail latency, error rates, and
resource use, enabling YouTube and other production systems at Google to run at
much higher utilization.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10175" title="Abstract">arXiv:2312.10175</a> [<a href="/pdf/2312.10175" title="Download PDF">pdf</a>, <a href="/format/2312.10175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniAR: Unifying Human Attention and Response Prediction on Visual  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizhao Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+R">Rachit Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaolei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Valliappan%2C+N">Nachiappan Valliappan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongxiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+V">Venky Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+G">Golnaz Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kohlhoff%2C+K+J">Kai J Kohlhoff</a>, 
<a href="/search/cs?searchtype=author&query=Navalpakkam%2C+V">Vidhya Navalpakkam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Progress in human behavior modeling involves understanding both implicit,
early-stage perceptual behavior such as human attention and explicit,
later-stage behavior such as subjective ratings/preferences. Yet, most prior
research has focused on modeling implicit and explicit human behavior in
isolation. Can we build a unified model of human attention and preference
behavior that reliably works across diverse types of visual content? Such a
model would enable predicting subjective feedback such as overall satisfaction
or aesthetic quality ratings, along with the underlying human attention or
interaction heatmaps and viewing order, enabling designers and content-creation
models to optimize their creation for human-centric improvements. In this
paper, we propose UniAR -- a unified model that predicts both implicit and
explicit human behavior across different types of visual content. UniAR
leverages a multimodal transformer, featuring distinct prediction heads for
each facet, and predicts attention heatmap, scanpath or viewing order, and
subjective rating/preference. We train UniAR on diverse public datasets
spanning natural images, web pages and graphic designs, and achieve leading
performance on multiple benchmarks across different image domains and various
behavior modeling tasks. Potential applications include providing instant
feedback on the effectiveness of UIs/digital designs/images, and serving as a
reward model to further optimize design/image creation.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10179" title="Abstract">arXiv:2312.10179</a> [<a href="/pdf/2312.10179" title="Download PDF">pdf</a>, <a href="/format/2312.10179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3FM: Multi-modal Meta-learning for Federated Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Roochi Shah</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zejun Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a novel approach in the domain of federated learning (FL),
particularly focusing on addressing the challenges posed by modality
heterogeneity, variability in modality availability across clients, and the
prevalent issue of missing data. We introduce a meta-learning framework
specifically designed for multimodal federated tasks. Our approach is motivated
by the need to enable federated models to robustly adapt when exposed to new
modalities, a common scenario in FL where clients often differ in the number of
available modalities. The effectiveness of our proposed framework is
demonstrated through extensive experimentation on an augmented MNIST dataset,
enriched with audio and sign language data. We demonstrate that the proposed
algorithm achieves better performance than the baseline on a subset of missing
modality scenarios with careful tuning of the meta-learning rates. This is a
shortened report, and our work will be extended and updated soon.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10181" title="Abstract">arXiv:2312.10181</a> [<a href="/pdf/2312.10181" title="Download PDF">pdf</a>, <a href="/format/2312.10181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupling Fairness and Pruning in a Single Run: a Bi-level Optimization  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yucong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Feng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaolong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Deep neural networks have demonstrated remarkable performance in various
tasks. With a growing need for sparse deep learning, model compression
techniques, especially pruning, have gained significant attention. However,
conventional pruning techniques can inadvertently exacerbate algorithmic bias,
resulting in unequal predictions. To address this, we define a fair pruning
task where a sparse model is derived subject to fairness requirements. In
particular, we propose a framework to jointly optimize the pruning mask and
weight update processes with fairness constraints. This framework is engineered
to compress models that maintain performance while ensuring fairness in a
single execution. To this end, we formulate the fair pruning problem as a novel
constrained bi-level optimization task and derive efficient and effective
solving strategies. We design experiments spanning various datasets and
settings to validate our proposed method. Our empirical analysis contrasts our
framework with several mainstream pruning strategies, emphasizing our method's
superiority in maintaining model fairness, performance, and efficiency.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10185" title="Abstract">arXiv:2312.10185</a> [<a href="/pdf/2312.10185" title="Download PDF">pdf</a>, <a href="/format/2312.10185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student as an Inherent Denoiser of Noisy Teacher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Third NeurIPS Workshop on Efficient Natural Language and Speech Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Knowledge distillation (KD) has been widely employed to transfer knowledge
from a large language model (LLM) to a specialized model in low-data regimes
through pseudo label learning. However, pseudo labels generated by teacher
models are usually noisy and may influence KD performance. This study delves
into KD with noisy teachers and uncovers that the student model can already
generate more accurate predictions than the teacher labels used to train it
during KD, indicating its inherent ability to denoise noisy teacher labels.
Motivated by this finding, we propose Peer-Advised KD to improve vanilla KD
from noisy teachers. Experiments show that Peer-Advised KD can outperform LLM
by approximately 5% with 50 human-labeled data, and even competitive to
standard supervised finetuning with 750 human-labeled data.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10188" title="Abstract">arXiv:2312.10188</a> [<a href="/pdf/2312.10188" title="Download PDF">pdf</a>, <a href="/format/2312.10188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WordScape: a Pipeline to extract multilingual, visually rich Documents  with Layout Annotations from Web Crawl Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Maurice Weber</a>, 
<a href="/search/cs?searchtype=author&query=Siebenschuh%2C+C">Carlo Siebenschuh</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+R">Rory Butler</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+A">Anton Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Thanner%2C+V">Valdemar Thanner</a>, 
<a href="/search/cs?searchtype=author&query=Tsolakis%2C+G">Georgios Tsolakis</a>, 
<a href="/search/cs?searchtype=author&query=Jabbar%2C+H">Haris Jabbar</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+R">Rick Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce WordScape, a novel pipeline for the creation of
cross-disciplinary, multilingual corpora comprising millions of pages with
annotations for document layout detection. Relating visual and textual items on
document pages has gained further significance with the advent of multimodal
models. Various approaches proved effective for visual question answering or
layout segmentation. However, the interplay of text, tables, and visuals
remains challenging for a variety of document understanding tasks. In
particular, many models fail to generalize well to diverse domains and new
languages due to insufficient availability of training data. WordScape
addresses these limitations. Our automatic annotation pipeline parses the Open
XML structure of Word documents obtained from the web, jointly providing
layout-annotated document images and their textual representations. In turn,
WordScape offers unique properties as it (1) leverages the ubiquity of the Word
file format on the internet, (2) is readily accessible through the Common Crawl
web corpus, (3) is adaptive to domain-specific documents, and (4) offers
culturally and linguistically diverse document pages with natural semantic
structure and high-quality text. Together with the pipeline, we will
additionally release 9.5M urls to word documents which can be processed using
WordScape to create a dataset of over 40M pages. Finally, we investigate the
quality of text and layout annotations extracted by WordScape, assess the
impact on document understanding benchmarks, and demonstrate that manual
labeling costs can be substantially reduced.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10191" title="Abstract">arXiv:2312.10191</a> [<a href="/pdf/2312.10191" title="Download PDF">pdf</a>, <a href="/format/2312.10191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell Me What You See: Text-Guided Real-World Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yosef%2C+E">Erez Yosef</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image reconstruction in low-light conditions is a challenging problem. Many
solutions have been proposed for it, where the main approach is trying to learn
a good prior of natural images along with modeling the true statistics of the
noise in the scene. In the presence of very low lighting conditions, such
approaches are usually not enough, and additional information is required,
e.g., in the form of using multiple captures. In this work, we suggest as an
alternative to add a description of the scene as prior, which can be easily
done by the photographer who is capturing the scene. Using a text-conditioned
diffusion model, we show that adding image caption information improves
significantly the image reconstruction in low-light conditions on both
synthetic and real-world images.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10193" title="Abstract">arXiv:2312.10193</a> [<a href="/pdf/2312.10193" title="Download PDF">pdf</a>, <a href="/format/2312.10193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Computation Modules: Granular Conditional Computation For  Efficient Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%B3jcik%2C+B">Bartosz W&#xf3;jcik</a>, 
<a href="/search/cs?searchtype=author&query=Devoto%2C+A">Alessio Devoto</a>, 
<a href="/search/cs?searchtype=author&query=Pustelnik%2C+K">Karol Pustelnik</a>, 
<a href="/search/cs?searchtype=author&query=Minervini%2C+P">Pasquale Minervini</a>, 
<a href="/search/cs?searchtype=author&query=Scardapane%2C+S">Simone Scardapane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The computational cost of transformer models makes them inefficient in
low-latency or low-power applications. While techniques such as quantization or
linear attention can reduce the computational load, they may incur a reduction
in accuracy. In addition, globally reducing the cost for all inputs may be
sub-optimal. We observe that for each layer, the full width of the layer may be
needed only for a small subset of tokens inside a batch and that the
"effective" width needed to process a token can vary from layer to layer.
Motivated by this observation, we introduce the Adaptive Computation Module
(ACM), a generic module that dynamically adapts its computational load to match
the estimated difficulty of the input on a per-token basis. An ACM consists of
a sequence of learners that progressively refine the output of their preceding
counterparts. An additional gating mechanism determines the optimal number of
learners to execute for each token. We also describe a distillation technique
to replace any pre-trained model with an "ACMized" variant. The distillation
phase is designed to be highly parallelizable across layers while being simple
to plug-and-play into existing networks. Our evaluation of transformer models
in computer vision and speech recognition demonstrates that substituting layers
with ACMs significantly reduces inference costs without degrading the
downstream accuracy for a wide interval of user-defined budgets.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10194" title="Abstract">arXiv:2312.10194</a> [<a href="/pdf/2312.10194" title="Download PDF">pdf</a>, <a href="/format/2312.10194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto Envelope Augmented with Reinforcement Learning: Multi-objective  reinforcement learning-based approach for Large-Scale Constrained Pressurized  Water Reactor optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seurin%2C+P">Paul Seurin</a>, 
<a href="/search/cs?searchtype=author&query=Seurin%2C+K">Koroush Seurin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">A novel method, the Pareto Envelope Augmented with Reinforcement Learning
(PEARL), has been developed to address the challenges posed by multi-objective
problems, particularly in the field of engineering where the evaluation of
candidate solutions can be time-consuming. PEARL distinguishes itself from
traditional policy-based multi-objective Reinforcement Learning methods by
learning a single policy, eliminating the need for multiple neural networks to
independently solve simpler sub-problems. Several versions inspired from deep
learning and evolutionary techniques have been crafted, catering to both
unconstrained and constrained problem domains. Curriculum Learning is harnessed
to effectively manage constraints in these versions. PEARL's performance is
first evaluated on classical multi-objective benchmarks. Additionally, it is
tested on two practical PWR core Loading Pattern optimization problems to
showcase its real-world applicability. The first problem involves optimizing
the Cycle length and the rod-integrated peaking factor as the primary
objectives, while the second problem incorporates the mean average enrichment
as an additional objective. Furthermore, PEARL addresses three types of
constraints related to boron concentration, peak pin burnup, and peak pin
power. The results are systematically compared against a conventional approach,
the Non-dominated Sorting Genetic Algorithm. Notably, PEARL, specifically the
PEARL-NdS variant, efficiently uncovers a Pareto front without necessitating
additional efforts from the algorithm designer, as opposed to a single
optimization with scaled objectives. It also outperforms the classical approach
across multiple performance metrics, including the Hyper-volume.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10195" title="Abstract">arXiv:2312.10195</a> [<a href="/pdf/2312.10195" title="Download PDF">pdf</a>, <a href="/format/2312.10195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+D+C">David C. Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Salazar%2C+S">Saunder Salazar</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jessie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kitts%2C+C+A">Christopher A. Kitts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While recent two-stage many-to-one deep learning models have demonstrated
great success in 3D human pose estimation, such models are inefficient ways to
detect 3D key points in a sequential video relative to one-shot and
many-to-many models. Another key drawback of two-stage and many-to-one models
is that errors in the first stage will be passed onto the second stage. In this
paper, we introduce SoloPose, a novel one-shot, many-to-many spatio-temporal
transformer model for kinematic 3D human pose estimation of video. SoloPose is
further fortified by HeatPose, a 3D heatmap based on Gaussian Mixture Model
distributions that factors target key points as well as kinematically adjacent
key points. Finally, we address data diversity constraints with the 3D
AugMotion Toolkit, a methodology to augment existing 3D human pose datasets,
specifically by projecting four top public 3D human pose datasets (Humans3.6M,
MADS, AIST Dance++, MPI INF 3DHP) into a novel dataset (Humans7.1M) with a
universal coordinate system. Extensive experiments are conducted on Human3.6M
as well as the augmented Humans7.1M dataset, and SoloPose demonstrates superior
results relative to the state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10196" title="Abstract">arXiv:2312.10196</a> [<a href="/pdf/2312.10196" title="Download PDF">pdf</a>, <a href="/format/2312.10196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Prior Knowledge Help Detect Collisions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ben-Eliezer%2C+O">Omri Ben-Eliezer</a>, 
<a href="/search/cs?searchtype=author&query=Grossman%2C+T">Tomer Grossman</a>, 
<a href="/search/cs?searchtype=author&query=Naor%2C+M">Moni Naor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Suppose you are given a function $f\colon [n] \to [n]$ via (black-box) query
access to the function. You are looking to find something local, like a
collision (a pair $x \neq y$ s.t.\ $f(x)=f(y)$). The question is whether
knowing the `shape' of the function helps you or not (by shape we mean that
some permutation of the function is known). Our goal in this work is to
characterize all local properties for which knowing the shape may help,
compared to an algorithm that does not know the shape.
<br />Formally, we investigate the instance optimality of fundamental substructure
detection problems in graphs and functions. Here, a problem is considered
instance optimal (IO) if there exists an algorithm $A$ for solving the problem
which satisfies that for any possible input, the (randomized) query complexity
of $A$ is at most a multiplicative constant larger than the query complexity of
any algorithm $A'$ for solving the same problem which also holds an unlabeled
copy of the input graph or function.
<br />We provide a complete characterization of those constant-size substructure
detection problems that are IO. Interestingly, our results imply that collision
detection is not IO, showing that in some cases an algorithm holding an
unlabeled certificate requires a factor of $\Theta(\log n)$ fewer queries than
any algorithm without a certificate. We conjecture that this separation result
is tight, which would make collision detection an ``almost instance optimal''
problem. In contrast, for all other non-trivial substructures, such as finding
a fixed point, we show that the separation is polynomial in $n$.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10198" title="Abstract">arXiv:2312.10198</a> [<a href="/pdf/2312.10198" title="Download PDF">pdf</a>, <a href="/ps/2312.10198" title="Download PostScript">ps</a>, <a href="/format/2312.10198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expert-Level Annotation Quality Achieved by Gamified Crowdsourcing for  B-line Segmentation in Lung Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mike Jin</a>, 
<a href="/search/cs?searchtype=author&query=Duggan%2C+N+M">Nicole M Duggan</a>, 
<a href="/search/cs?searchtype=author&query=Bashyakarla%2C+V">Varoon Bashyakarla</a>, 
<a href="/search/cs?searchtype=author&query=Mendicuti%2C+M+A+D">Maria Alejandra Duran Mendicuti</a>, 
<a href="/search/cs?searchtype=author&query=Hallisey%2C+S">Stephen Hallisey</a>, 
<a href="/search/cs?searchtype=author&query=Bernier%2C+D">Denie Bernier</a>, 
<a href="/search/cs?searchtype=author&query=Stegeman%2C+J">Joseph Stegeman</a>, 
<a href="/search/cs?searchtype=author&query=Duhaime%2C+E">Erik Duhaime</a>, 
<a href="/search/cs?searchtype=author&query=Kapur%2C+T">Tina Kapur</a>, 
<a href="/search/cs?searchtype=author&query=Goldsmith%2C+A+J">Andrew J Goldsmith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Accurate and scalable annotation of medical data is critical for the
development of medical AI, but obtaining time for annotation from medical
experts is challenging. Gamified crowdsourcing has demonstrated potential for
obtaining highly accurate annotations for medical data at scale, and we
demonstrate the same in this study for the segmentation of B-lines, an
indicator of pulmonary congestion, on still frames within point-of-care lung
ultrasound clips. We collected 21,154 annotations from 214 annotators over 2.5
days, and we demonstrated that the concordance of crowd consensus segmentations
with reference standards exceeds that of individual experts with the same
reference standards, both in terms of B-line count (mean squared error 0.239
vs. 0.308, p&lt;0.05) as well as the spatial precision of B-line annotations (mean
Dice-H score 0.755 vs. 0.643, p&lt;0.05). These results suggest that
expert-quality segmentations can be achieved using gamified crowdsourcing.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10199" title="Abstract">arXiv:2312.10199</a> [<a href="/pdf/2312.10199" title="Download PDF">pdf</a>, <a href="/format/2312.10199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic nonlinear MPC approximation with closed-loop guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tokmak%2C+A">Abdullah Tokmak</a>, 
<a href="/search/eess?searchtype=author&query=Fiedler%2C+C">Christian Fiedler</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>, 
<a href="/search/eess?searchtype=author&query=Trimpe%2C+S">Sebastian Trimpe</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we address the problem of automatically approximating
nonlinear model predictive control (MPC) schemes with closed-loop guarantees.
First, we discuss how this problem can be reduced to a function approximation
problem, which we then tackle by proposing ALKIA-X, the Adaptive and Localized
Kernel Interpolation Algorithm with eXtrapolated reproducing kernel Hilbert
space norm. ALKIA-X is a non-iterative algorithm that ensures numerically
well-conditioned computations, a fast-to-evaluate approximating function, and
the guaranteed satisfaction of any desired bound on the approximation error.
Hence, ALKIA-X automatically computes an explicit function that approximates
the MPC, yielding a controller suitable for safety-critical systems and high
sampling rates. In a numerical experiment, we apply ALKIA-X to a nonlinear MPC
scheme, demonstrating reduced offline computation and online evaluation time
compared to a state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10200" title="Abstract">arXiv:2312.10200</a> [<a href="/pdf/2312.10200" title="Download PDF">pdf</a>, <a href="/format/2312.10200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Active Perception for Object Detection using Navigation Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ginargiros%2C+S">Stefanos Ginargiros</a>, 
<a href="/search/cs?searchtype=author&query=Passalis%2C+N">Nikolaos Passalis</a>, 
<a href="/search/cs?searchtype=author&query=Tefas%2C+A">Anastasios Tefas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, 2023 IEEE Symposium Series on Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Learning (DL) has brought significant advances to robotics vision tasks.
However, most existing DL methods have a major shortcoming, they rely on a
static inference paradigm inherent in traditional computer vision pipelines. On
the other hand, recent studies have found that active perception improves the
perception abilities of various models by going beyond these static paradigms.
Despite the significant potential of active perception, it poses several
challenges, primarily involving significant changes in training pipelines for
deep learning models. To overcome these limitations, in this work, we propose a
generic supervised active perception pipeline for object detection that can be
trained using existing off-the-shelf object detectors, while also leveraging
advances in simulation environments. To this end, the proposed method employs
an additional neural network architecture that estimates better viewpoints in
cases where the object detector confidence is insufficient. The proposed method
was evaluated on synthetic datasets, constructed within the Webots robotics
simulator, showcasing its effectiveness in two object detection cases.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10201" title="Abstract">arXiv:2312.10201</a> [<a href="/pdf/2312.10201" title="Download PDF">pdf</a>, <a href="/format/2312.10201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARAT: Contrastive Feature Reconstruction and Aggregation for  Multi-modal Multi-label Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Lidan Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-modal multi-label emotion recognition (MMER) aims to identify relevant
emotions from multiple modalities. The challenge of MMER is how to effectively
capture discriminative features for multiple labels from heterogeneous data.
Recent studies are mainly devoted to exploring various fusion strategies to
integrate multi-modal information into a unified representation for all labels.
However, such a learning scheme not only overlooks the specificity of each
modality but also fails to capture individual discriminative features for
different labels. Moreover, dependencies of labels and modalities cannot be
effectively modeled. To address these issues, this paper presents ContrAstive
feature Reconstruction and AggregaTion (CARAT) for the MMER task. Specifically,
we devise a reconstruction-based fusion mechanism to better model fine-grained
modality-to-label dependencies by contrastively learning modal-separated and
label-specific features. To further exploit the modality complementarity, we
introduce a shuffle-based aggregation strategy to enrich co-occurrence
collaboration among labels. Experiments on two benchmark datasets CMU-MOSEI and
M3ED demonstrate the effectiveness of CARAT over state-of-the-art methods. Code
is available at https://github.com/chengzju/CARAT.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10202" title="Abstract">arXiv:2312.10202</a> [<a href="/pdf/2312.10202" title="Download PDF">pdf</a>, <a href="/format/2312.10202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-resource classification of mobility functioning information in  clinical sentences using large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T+D">Tuan Dung Le</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+T">Thanh Duong</a>, 
<a href="/search/cs?searchtype=author&query=Thieu%2C+T">Thanh Thieu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Objective: Function is increasingly recognized as an important indicator of
whole-person health. This study evaluates the ability of publicly available
large language models (LLMs) to accurately identify the presence of functioning
information from clinical notes. We explore various strategies to improve the
performance on this task. Materials and Methods: We collect a balanced binary
classification dataset of 1000 sentences from the Mobility NER dataset, which
was curated from n2c2 clinical notes. For evaluation, we construct zero-shot
and few-shot prompts to query the LLMs whether a given sentence contains
mobility functioning information. Two sampling techniques, random sampling and
k-nearest neighbor (kNN)-based sampling, are used to select the few-shot
examples. Furthermore, we apply a parameter-efficient prompt-based fine-tuning
method to the LLMs and evaluate their performance under various training
settings. Results: Flan-T5-xxl outperforms all other models in both zero-shot
and few-shot settings, achieving a F1 score of 0.865 with a single
demonstrative example selected by kNN sampling. In prompt-based fine-tuning
experiments, this foundation model also demonstrates superior performance
across all low-resource settings, particularly achieving an impressive F1 score
of 0.922 using the full training dataset. The smaller model, Flan-T5-xl,
requires fine-tuning with only 2.3M additional parameters to achieve comparable
performance to the fully fine-tuned Gatortron-base model, both surpassing 0.9
F1 score. Conclusion: Open-source instruction-tuned LLMs demonstrate impressive
in-context learning capability in the mobility functioning classification task.
The performance of these models can be further improved by continuing
fine-tuning on a task-specific dataset.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10205" title="Abstract">arXiv:2312.10205</a> [<a href="/pdf/2312.10205" title="Download PDF">pdf</a>, <a href="/format/2312.10205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pay to (Not) Play: Monetizing Impatience in Mobile Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lundy%2C+T">Taylor Lundy</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+N">Narun Raman</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Leyton-Brown%2C+K">Kevin Leyton-Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Mobile gaming is a rapidly growing and incredibly profitable sector; having
grown seven-fold over the past 10 years, it now grosses over $100 billion
annually. This growth was due in large part to a shift in monetization
strategies: rather than charging players an upfront cost ("pay-to-play"), games
often request optional microtransactions throughout gameplay ("free-to-play").
We focus on a common scenario in which games include wait times -- gating
either items or game progression -- that players can pay to skip. Game
designers typically say that they optimize for player happiness rather than
revenue; however, prices for skips are typically set at levels that few players
are willing to pay, leading to low purchase rates. Under a traditional
analysis, it would seem that game designers fail at their stated goal if few
players buy what they are selling. We argue that an alternate model can better
explain this dynamic: players value tasks more highly as they are perceived to
be more difficult. While skips can increase players' utilities by providing
instant gratification, pricing skips too cheaply can lower players' utilities
by decreasing the perceived amount of work needed to complete a task. We show
that high revenue, high player utility, and low purchase rates can all coexist
under this model, particularly under a realistic distribution of players having
few buyers but a few big-spending "whales." We also investigate how a game
designer should optimize prices under our model.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10208" title="Abstract">arXiv:2312.10208</a> [<a href="/pdf/2312.10208" title="Download PDF">pdf</a>, <a href="/format/2312.10208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-based Surgical Skill Assessment using Tree-based Gaussian Process  Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+A">Arefeh Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M+J">Mohammad Javad Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Molaei%2C+A">Amir Molaei</a>, 
<a href="/search/cs?searchtype=author&query=Taghirad%2C+H+D">Hamid. D. Taghirad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> e.g: 11 pages, 2 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">assessment using video data and to showcase the effectiveness of the proposed
approach in evaluating surgeon proficiency, its potential for targeted training
interventions, and quality assurance in surgical departments. The pipeline
incorporates a representation flow convolutional neural network and a novel
tree-based Gaussian process classifier, which is robust to noise, while being
computationally efficient. Additionally, new kernels are introduced to enhance
accuracy. The performance of the pipeline is evaluated using the JIGSAWS
dataset. Comparative analysis with existing literature reveals significant
improvement in accuracy and betterment in computation cost. The proposed
pipeline contributes to computational efficiency and accuracy improvement in
surgical skill assessment using video data. Results of our study based on
comments of our colleague surgeons show that the proposed method has the
potential to facilitate skill improvement among surgery fellows and enhance
patient safety through targeted training interventions and quality assurance in
surgical departments.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10209" title="Abstract">arXiv:2312.10209</a> [<a href="/pdf/2312.10209" title="Download PDF">pdf</a>, <a href="/format/2312.10209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Empirical Windowing: An Attention-Based Approach for Trust  Prediction in Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+M">Minxue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhaobo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Akash%2C+K">Kumar Akash</a>, 
<a href="/search/cs?searchtype=author&query=Misu%2C+T">Teruhisa Misu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans' internal states play a key role in human-machine interaction, leading
to the rise of human state estimation as a prominent field. Compared to swift
state changes such as surprise and irritation, modeling gradual states like
trust and satisfaction are further challenged by label sparsity: long
time-series signals are usually associated with a single label, making it
difficult to identify the critical span of state shifts. Windowing has been one
widely-used technique to enable localized analysis of long time-series data.
However, the performance of downstream models can be sensitive to the window
size, and determining the optimal window size demands domain expertise and
extensive search. To address this challenge, we propose a Selective Windowing
Attention Network (SWAN), which employs window prompts and masked attention
transformation to enable the selection of attended intervals with flexible
lengths. We evaluate SWAN on the task of trust prediction on a new multimodal
driving simulation dataset. Experiments show that SWAN significantly
outperforms an existing empirical window selection baseline and neural network
baselines including CNN-LSTM and Transformer. Furthermore, it shows robustness
across a wide span of windowing ranges, compared to the traditional windowing
approach.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10210" title="Abstract">arXiv:2312.10210</a> [<a href="/pdf/2312.10210" title="Download PDF">pdf</a>, <a href="/format/2312.10210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VK-G2T: Vision and Context Knowledge enhanced Gloss2Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuemeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+X">Xinxing Zu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Na Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongzhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing sign language translation methods follow a two-stage pipeline: first
converting the sign language video to a gloss sequence (i.e. Sign2Gloss) and
then translating the generated gloss sequence into a spoken language sentence
(i.e. Gloss2Text). While previous studies have focused on boosting the
performance of the Sign2Gloss stage, we emphasize the optimization of the
Gloss2Text stage. However, this task is non-trivial due to two distinct
features of Gloss2Text: (1) isolated gloss input and (2) low-capacity gloss
vocabulary. To address these issues, we propose a vision and context knowledge
enhanced Gloss2Text model, named VK-G2T, which leverages the visual content of
the sign language video to learn the properties of the target sentence and
exploit the context knowledge to facilitate the adaptive translation of gloss
words. Extensive experiments conducted on a Chinese benchmark validate the
superiority of our model.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10212" title="Abstract">arXiv:2312.10212</a> [<a href="/pdf/2312.10212" title="Download PDF">pdf</a>, <a href="/format/2312.10212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Remark on Concept Drift for Dependent Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hinder%2C+F">Fabian Hinder</a>, 
<a href="/search/cs?searchtype=author&query=Vaquet%2C+V">Valerie Vaquet</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Concept drift, i.e., the change of the data generating distribution, can
render machine learning models inaccurate. Several works address the phenomenon
of concept drift in the streaming context usually assuming that consecutive
data points are independent of each other. To generalize to dependent data,
many authors link the notion of concept drift to time series. In this work, we
show that the temporal dependencies are strongly influencing the sampling
process. Thus, the used definitions need major modifications. In particular, we
show that the notion of stationarity is not suited for this setup and discuss
alternatives. We demonstrate that these alternative formal notions describe the
observable learning behavior in numerical experiments.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10214" title="Abstract">arXiv:2312.10214</a> [<a href="/pdf/2312.10214" title="Download PDF">pdf</a>, <a href="/format/2312.10214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Healthcare Policy Compliance: A Blockchain Smart Contract-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amin%2C+M+A">Md Al Amin</a>, 
<a href="/search/cs?searchtype=author&query=Tummala%2C+H">Hemanth Tummala</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+S">Seshamalini Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+I">Indrajit Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper addresses the critical challenge of ensuring healthcare policy
compliance in the context of Electronic Health Records (EHRs). Despite
stringent regulations like HIPAA, significant gaps in policy compliance often
remain undetected until a data breach occurs. To bridge this gap, we propose a
novel blockchain-powered, smart contract-based access control model. This model
is specifically designed to enforce patient-provider agreements (PPAs) and
other relevant policies, thereby ensuring both policy compliance and
provenance. Our approach integrates components of informed consent into PPAs,
employing blockchain smart contracts to automate and secure policy enforcement.
The authorization module utilizes these contracts to make informed access
decisions, recording all actions in a transparent, immutable blockchain ledger.
This system not only ensures that policies are rigorously applied but also
maintains a verifiable record of all actions taken, thus facilitating an easy
audit and proving compliance. We implement this model in a private Ethereum
blockchain setup, focusing on maintaining the integrity and lineage of policies
and ensuring that audit trails are accurately and securely recorded. The Proof
of Compliance (PoC) consensus mechanism enables decentralized, independent
auditor nodes to verify compliance status based on the audit trails recorded.
Experimental evaluation demonstrates the effectiveness of the proposed model in
a simulated healthcare environment. The results show that our approach not only
strengthens policy compliance and provenance but also enhances the transparency
and accountability of the entire process. In summary, this paper presents a
comprehensive, blockchain-based solution to a longstanding problem in
healthcare data management, offering a robust framework for ensuring policy
compliance and provenance through smart contracts and blockchain technology.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10217" title="Abstract">arXiv:2312.10217</a> [<a href="/pdf/2312.10217" title="Download PDF">pdf</a>, <a href="/format/2312.10217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-MAE: Temporal Masked Autoencoders for Point Cloud Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Weijie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Nejadasl%2C+F+K">Fatemeh Karimi Nejadasl</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The scarcity of annotated data in outdoor point cloud segmentation poses a
significant obstacle in harnessing the modeling capabilities of advanced
networks like transformers. Consequently, scholars have been actively
investigating efficacious self-supervised pre-training strategies, e.g.
contrasting learning and reconstruction-based pretext tasks. Nevertheless,
temporal information, which is inherent in the LiDAR point cloud sequence, is
consistently disregarded. To better utilize this property, we propose an
effective pre-training strategy, namely Temporal Masked AutoEncoders (T-MAE),
which takes as input temporally adjacent frames and learns temporal dependency.
A SiamWCA backbone, containing a Siamese encoder and a window-based
cross-attention (WCA) module, is established for the two-frame input. Taking
into account that the motion of an ego-vehicle alters the illumination angles
of the same instance, temporal modeling also serves as a robust and natural
data augmentation, enhancing the comprehension of target objects. Moreover,
instead of utilizing consecutive frames, it is more cost-effective and powerful
by using distant historical frames. SiamWCA is a powerful architecture but
heavily relies on annotated data. With our T-MAE pre-training strategy, we
achieve the best performance on the Waymo dataset among self-supervised
learning methods. Comprehensive experiments are conducted to validate all
components of our proposal. Upon acceptance, the source code will be made
accessible.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10219" title="Abstract">arXiv:2312.10219</a> [<a href="/pdf/2312.10219" title="Download PDF">pdf</a>, <a href="/format/2312.10219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Optimizing Atomic Congestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+C">Cornelius Brand</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Kalyanasundaram%2C+S">Subrahmanyam Kalyanasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Inerney%2C+F+M">Fionn Mc Inerney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
<p class="mathjax">Atomic congestion games are a classic topic in network design, routing, and
algorithmic game theory, and are capable of modeling congestion and flow
optimization tasks in various application areas. While both the price of
anarchy for such games as well as the computational complexity of computing
their Nash equilibria are by now well-understood, the computational complexity
of computing a system-optimal set of strategies -- that is, a centrally planned
routing that minimizes the average cost of agents -- is severely understudied
in the literature. We close this gap by identifying the exact boundaries of
tractability for the problem through the lens of the parameterized complexity
paradigm. After showing that the problem remains highly intractable even on
extremely simple networks, we obtain a set of results which demonstrate that
the structural parameters which control the computational (in)tractability of
the problem are not vertex-separator based in nature (such as, e.g.,
treewidth), but rather based on edge separators. We conclude by extending our
analysis towards the (even more challenging) min-max variant of the problem.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10225" title="Abstract">arXiv:2312.10225</a> [<a href="/pdf/2312.10225" title="Download PDF">pdf</a>, <a href="/format/2312.10225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-doctor: Customizing Large Language Models for Medical Consultation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianshu Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The advent of Large Language Models (LLMs) has ushered in a new era for
design science in Information Systems, demanding a paradigm shift in tailoring
LLMs design for business contexts. This paper proposes a novel framework to
customize LLMs for general business contexts that aims to achieve three
fundamental objectives simultaneously: (1) aligning conversational patterns,
(2) integrating in-depth domain knowledge, and (3) embodying the soft skills
and core principles. We design methodologies to combine domain-specific theory
with Supervised Fine Tuning (SFT) in LLMs. We instantiate our proposed
framework in the context of medical consultation, creating a GPT-doctor model.
Specifically, we construct a comprehensive dataset for SFT by collecting large
volume of real doctors consultation records from a leading online medical
consultation platform and medical knowledge from professional databases.
Additionally, drawing on medical theory, we identify three soft skills and core
principles of human doctors including professionalism, explainability, and
emotional support, and design approaches to integrate these skills into LLMs.
We demonstrate the feasibility and performance of our proposed framework using
online experiments with real patients as well as evaluation by domain experts
and real consumers. Results demonstrate that fine-tuned GPT-doctor performs on
par with human doctors across multiple metrics including medical expertise and
consumer preference. Finally, we unravel the black box and examine the sources
of model performance improvement from the perspectives of horizontal
conversation pattern alignment and vertical medical knowledge evolution. Our
proposed framework offers step-by-step principles and guidance for customizing
LLMs for real-world business problems.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10230" title="Abstract">arXiv:2312.10230</a> [<a href="/pdf/2312.10230" title="Download PDF">pdf</a>, <a href="/format/2312.10230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Meta-Reinforcement Learning for Adaptable Safety Guarantee  with Differentiable Convex Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minjae Cho</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chuangchuang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite remarkable achievements in artificial intelligence, the deployability
of learning-enabled systems in high-stakes real-world environments still faces
persistent challenges. For example, in safety-critical domains like autonomous
driving, robotic manipulation, and healthcare, it is crucial not only to
achieve high performance but also to comply with given constraints.
Furthermore, adaptability becomes paramount in non-stationary domains, where
environmental parameters are subject to change. While safety and adaptability
are recognized as key qualities for the new generation of AI, current
approaches have not demonstrated effective adaptable performance in constrained
settings. Hence, this paper breaks new ground by studying the unique challenges
of ensuring safety in non-stationary environments by solving constrained
problems through the lens of the meta-learning approach (learning-to-learn).
While unconstrained meta-learning al-ready encounters complexities in
end-to-end differentiation of the loss due to the bi-level nature, its
constrained counterpart introduces an additional layer of difficulty, since the
constraints imposed on task-level updates complicate the differentiation
process. To address the issue, we first employ successive convex-constrained
policy updates across multiple tasks with differentiable convexprogramming,
which allows meta-learning in constrained scenarios by enabling end-to-end
differentiation. This approach empowers the agent to rapidly adapt to new tasks
under non-stationarity while ensuring compliance with safety constraints.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10235" title="Abstract">arXiv:2312.10235</a> [<a href="/pdf/2312.10235" title="Download PDF">pdf</a>, <a href="/format/2312.10235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building symmetries into data-driven manifold dynamics models for  complex flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Jes%C3%BAs%2C+C+E+P">Carlos E. P&#xe9;rez De Jes&#xfa;s</a>, 
<a href="/search/cs?searchtype=author&query=Linot%2C+A+J">Alec J. Linot</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+M+D">Michael D. Graham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Symmetries in a dynamical system provide an opportunity to dramatically
improve the performance of data-driven models. For fluid flows, such models are
needed for tasks related to design, understanding, prediction, and control. In
this work we exploit the symmetries of the Navier-Stokes equations (NSE) and
use simulation data to find the manifold where the long-time dynamics live,
which has many fewer degrees of freedom than the full state representation, and
the evolution equation for the dynamics on that manifold. We call this method
''symmetry charting''. The first step is to map to a ''fundamental chart'',
which is a region in the state space of the flow to which all other regions can
be mapped by a symmetry operation. To map to the fundamental chart we identify
a set of indicators from the Fourier transform that uniquely identify the
symmetries of the system. We then find a low-dimensional coordinate
representation of the data in the fundamental chart with the use of an
autoencoder. We use a variation called an implicit rank minimizing autoencoder
with weight decay, which in addition to compressing the dimension of the data,
also gives estimates of how many dimensions are needed to represent the data:
i.e. the dimension of the invariant manifold of the long-time dynamics.
Finally, we learn dynamics on this manifold with the use of neural ordinary
differential equations. We apply symmetry charting to two-dimensional
Kolmogorov flow in a chaotic bursting regime. This system has a continuous
translation symmetry, and discrete rotation and shift-reflect symmetries. With
this framework we observe that less data is needed to learn accurate
data-driven models, more robust estimates of the manifold dimension are
obtained, equivariance of the NSE is satisfied, better short-time tracking with
respect to the true data is observed, and long-time statistics are correctly
captured.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10237" title="Abstract">arXiv:2312.10237</a> [<a href="/pdf/2312.10237" title="Download PDF">pdf</a>, <a href="/format/2312.10237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Federated Alzheimer&#x27;s Detection on Multimodal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+P+K">Paul K. Mandal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the era of rapidly advancing medical technologies, the segmentation of
medical data has become inevitable, necessitating the development of privacy
preserving machine learning algorithms that can train on distributed data.
Consolidating sensitive medical data is not always an option particularly due
to the stringent privacy regulations imposed by the Health Insurance
Portability and Accountability Act (HIPAA). In this paper, we introduce a HIPAA
compliant framework that can train from distributed data. We then propose a
multimodal vertical federated model for Alzheimer's Disease (AD) detection, a
serious neurodegenerative condition that can cause dementia, severely impairing
brain function and hindering simple tasks, especially without preventative
care. This vertical federated model offers a distributed architecture that
enables collaborative learning across diverse sources of medical data while
respecting privacy constraints imposed by HIPAA. It is also able to leverage
multiple modalities of data, enhancing the robustness and accuracy of AD
detection. Our proposed model not only contributes to the advancement of
federated learning techniques but also holds promise for overcoming the hurdles
posed by data segmentation in medical research. By using vertical federated
learning, this research strives to provide a framework that enables healthcare
institutions to harness the collective intelligence embedded in their
distributed datasets without compromising patient privacy.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10238" title="Abstract">arXiv:2312.10238</a> [<a href="/pdf/2312.10238" title="Download PDF">pdf</a>, <a href="/format/2312.10238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypothesis Testing for Class-Conditional Noise Using Local Maximum  Likelihood
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weisong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Poyiadzi%2C+R">Rafael Poyiadzi</a>, 
<a href="/search/cs?searchtype=author&query=Twomey%2C+N">Niall Twomey</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+R+S">Raul Santos Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In supervised learning, automatically assessing the quality of the labels
before any learning takes place remains an open research question. In certain
particular cases, hypothesis testing procedures have been proposed to assess
whether a given instance-label dataset is contaminated with class-conditional
label noise, as opposed to uniform label noise. The existing theory builds on
the asymptotic properties of the Maximum Likelihood Estimate for parametric
logistic regression. However, the parametric assumptions on top of which these
approaches are constructed are often too strong and unrealistic in practice. To
alleviate this problem, in this paper we propose an alternative path by showing
how similar procedures can be followed when the underlying model is a product
of Local Maximum Likelihood Estimation that leads to more flexible
nonparametric logistic regression models, which in turn are less susceptible to
model misspecification. This different view allows for wider applicability of
the tests by offering users access to a richer model class. Similarly to
existing works, we assume we have access to anchor points which are provided by
the users. We introduce the necessary ingredients for the adaptation of the
hypothesis tests to the case of nonparametric logistic regression and
empirically compare against the parametric approach presenting both synthetic
and real-world case studies and discussing the advantages and limitations of
the proposed approach.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10239" title="Abstract">arXiv:2312.10239</a> [<a href="/pdf/2312.10239" title="Download PDF">pdf</a>, <a href="/format/2312.10239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Hierarchical Decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joyce%2C+I+S">Ian Stewart Joyce</a>, 
<a href="/search/cs?searchtype=author&query=Erdmann%2C+G">Grant Erdmann</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+K+P">Kirk P. Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+R">Ryan Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Siegrist%2C+K">Kyle Siegrist</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">Topological data analysis is an emerging field that applies the study of
topological invariants to data. Perhaps the simplest of these invariants is the
number of connected components or clusters. In this work, we explore a
topological framework for cluster analysis and show how it can be used as a
basis for explainability in unsupervised data analysis. Our main object of
study will be hierarchical data structures referred to as Topological
Hierarchical Decompositions (THDs). We give a number of examples of how
traditional clustering algorithms can be topologized, and provide preliminary
results on the THDs associated with Reeb graphs and the mapper algorithm. In
particular, we give a generalized construction of the mapper functor as a
pixelization of a cosheaf in order to generalize multiscale mapper.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10240" title="Abstract">arXiv:2312.10240</a> [<a href="/pdf/2312.10240" title="Download PDF">pdf</a>, <a href="/format/2312.10240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rich Human Feedback for Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Klimovskiy%2C+A">Arseniy Klimovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Carolan%2C+N">Nicholas Carolan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pont-Tuset%2C+J">Jordi Pont-Tuset</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+S">Sarah Young</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Feng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Junjie Ke</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+K+D">Krishnamurthy Dj Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+K">Katie Collins</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yiwen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kohlhoff%2C+K+J">Kai J Kohlhoff</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+D">Deepak Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Navalpakkam%2C+V">Vidhya Navalpakkam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent Text-to-Image (T2I) generation models such as Stable Diffusion and
Imagen have made significant progress in generating high-resolution images
based on text descriptions. However, many generated images still suffer from
issues such as artifacts/implausibility, misalignment with text descriptions,
and low aesthetic quality. Inspired by the success of Reinforcement Learning
with Human Feedback (RLHF) for large language models, prior works collected
human-provided scores as feedback on generated images and trained a reward
model to improve the T2I generation. In this paper, we enrich the feedback
signal by (i) marking image regions that are implausible or misaligned with the
text, and (ii) annotating which words in the text prompt are misrepresented or
missing on the image. We collect such rich human feedback on 18K generated
images and train a multimodal transformer to predict the rich feedback
automatically. We show that the predicted rich human feedback can be leveraged
to improve image generation, for example, by selecting high-quality training
data to finetune and improve the generative models, or by creating masks with
predicted heatmaps to inpaint the problematic regions. Notably, the
improvements generalize to models (Muse) beyond those used to generate the
images on which human feedback data were collected (Stable Diffusion variants).
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10244" title="Abstract">arXiv:2312.10244</a> [<a href="/pdf/2312.10244" title="Download PDF">pdf</a>, <a href="/format/2312.10244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Muchisim: A Simulation Framework for Design Exploration of Multi-Chip  Manycore Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orenes-Vera%2C+M">Marcelo Orenes-Vera</a>, 
<a href="/search/cs?searchtype=author&query=Tureci%2C+E">Esin Tureci</a>, 
<a href="/search/cs?searchtype=author&query=Martonosi%2C+M">Margaret Martonosi</a>, 
<a href="/search/cs?searchtype=author&query=Wentzlaff%2C+D">David Wentzlaff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Current design-space exploration tools cannot accurately evaluate
communication-intensive applications whose execution is data-dependent (e.g.,
graph analytics and sparse linear algebra) on scale-out manycore systems, due
to either lack of scalability or lack of detail in modeling the network. This
paper presents Muchisim, a novel parallel simulator designed to address the
challenges in exploring the design space of distributed multi-chiplet manycore
architectures for communication-intensive applications. We evaluate Muchisim at
simulating systems with up to a million interconnected processing elements
(PEs) while modeling data movement and communication in a cycle-accurate
manner. In addition to performance, Muchisim reports the energy, area, and cost
of the simulated system, and it comes with a benchmark application suite and
two data visualization tools.
<br />Muchisim supports various parallelization strategies and communication
primitives such as task-based parallelization and message passing, making it
highly relevant for architectures with software-managed coherence and
distributed memory. Via a case study, we show that Muchisim helps users explore
the balance between memory and computation units and the constraints related to
chiplet integration and inter-chip communication. Muchisim enables scaling up
the systems in which new techniques or design parameters are evaluated, opening
the gate for further research in this area.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10245" title="Abstract">arXiv:2312.10245</a> [<a href="/pdf/2312.10245" title="Download PDF">pdf</a>, <a href="/format/2312.10245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On selecting a fraction of leaves with disjoint neighborhoods in a plane  tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junginger%2C+K">Kolja Junginger</a>, 
<a href="/search/cs?searchtype=author&query=Mantas%2C+I">Ioannis Mantas</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulou%2C+E">Evanthia Papadopoulou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Applied Mathematics, 319:141-148, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We present a generalization of a combinatorial result by Aggarwal, Guibas,
Saxe and Shor [Discrete &amp; Computational Geometry, 1989] on a linear-time
algorithm that selects a constant fraction of leaves, with pairwise disjoint
neighborhoods, from a binary tree embedded in the plane. This result of
Aggarwal et al. is essential to the linear-time framework, which they also
introduced, that computes certain Voronoi diagrams of points with a tree
structure in linear time. An example is the diagram computed while updating the
Voronoi diagram of points after deletion of one site. Our generalization allows
that only a fraction of the tree leaves is considered, and it is motivated by
linear-time Voronoi constructions for non-point sites. We are given a plane
tree $T$ of $n$ leaves, $m$ of which have been marked, and each marked leaf is
associated with a neighborhood (a subtree of $T$) such that any two
topologically consecutive marked leaves have disjoint neighborhoods. We show
how to select in linear time a constant fraction of the marked leaves having
pairwise disjoint neighborhoods.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10246" title="Abstract">arXiv:2312.10246</a> [<a href="/pdf/2312.10246" title="Download PDF">pdf</a>, <a href="/format/2312.10246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Modeling of Non-rigid Objects with Cross-Category Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Planche%2C+B">Benjamin Planche</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhongpai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sibut-Bourde%2C+P">Pierre Sibut-Bourde</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Terrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. Paper + supplementary material
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  38(1), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep implicit functions (DIFs) have emerged as a potent and articulate means
of representing 3D shapes. However, methods modeling object categories or
non-rigid entities have mainly focused on single-object scenarios. In this
work, we propose MODIF, a multi-object deep implicit function that jointly
learns the deformation fields and instance-specific latent codes for multiple
objects at once. Our emphasis is on non-rigid, non-interpenetrating entities
such as organs. To effectively capture the interrelation between these entities
and ensure precise, collision-free representations, our approach facilitates
signaling between category-specific fields to adequately rectify shapes. We
also introduce novel inter-object supervision: an attraction-repulsion loss is
formulated to refine contact regions between objects. Our approach is
demonstrated on various medical benchmarks, involving modeling different groups
of intricate anatomical entities. Experimental results illustrate that our
model can proficiently learn the shape representation of each organ and their
relations to others, to the point that shapes missing from unseen instances can
be consistently recovered by our method. Finally, MODIF can also propagate
semantic information throughout the population via accurate point
correspondences
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10247" title="Abstract">arXiv:2312.10247</a> [<a href="/pdf/2312.10247" title="Download PDF">pdf</a>, <a href="/format/2312.10247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Accurate Summation of Many Floating-Point Numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blanton%2C+M">Marina Blanton</a>, 
<a href="/search/cs?searchtype=author&query=Goodrich%2C+M+T">Michael T. Goodrich</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chen Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected version of the paper published at PETS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings on Privacy Enhancing Technologies (PoPETs), Vol. 2023,
  No. 3, pp. 432-445, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Motivated by the importance of floating-point computations, we study the
problem of securely and accurately summing many floating-point numbers. Prior
work has focused on security absent accuracy or accuracy absent security,
whereas our approach achieves both of them. Specifically, we show how to
implement floating-point superaccumulators using secure multi-party computation
techniques, so that a number of participants holding secret shares of
floating-point numbers can accurately compute their sum while keeping the
individual values private.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10250" title="Abstract">arXiv:2312.10250</a> [<a href="/pdf/2312.10250" title="Download PDF">pdf</a>, <a href="/format/2312.10250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report: Unresolved Challenges and Potential Features in EATXT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Holtmann%2C+J">J&#xf6;rg Holtmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We developed a textual concrete syntax and a textual editor that supports it
for the domain-specific language EAST-ADL, which we named EATXT. This document
is a technical report that describes potential advanced features that could be
added to EATXT that have not yet been implemented. The purpose of this report
is to share our understanding of the relevant technical challenges and to
assist potentially interested peers.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10251" title="Abstract">arXiv:2312.10251</a> [<a href="/pdf/2312.10251" title="Download PDF">pdf</a>, <a href="/format/2312.10251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Surgical VQA with Scene Graph Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kattel%2C+M">Manasi Kattel</a>, 
<a href="/search/cs?searchtype=author&query=Lavanchy%2C+J+L">Joel L. Lavanchy</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Vinkle Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditional Accept by IPCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern operating room is becoming increasingly complex, requiring innovative
intra-operative support systems. While the focus of surgical data science has
largely been on video analysis, integrating surgical computer vision with
language capabilities is emerging as a necessity. Our work aims to advance
Visual Question Answering (VQA) in the surgical context with scene graph
knowledge, addressing two main challenges in the current surgical VQA systems:
removing question-condition bias in the surgical VQA dataset and incorporating
scene-aware reasoning in the surgical VQA model design. First, we propose a
Surgical Scene Graph-based dataset, SSG-QA, generated by employing segmentation
and detection models on publicly available datasets. We build surgical scene
graphs using spatial and action information of instruments and anatomies. These
graphs are fed into a question engine, generating diverse QA pairs. Our SSG-QA
dataset provides a more complex, diverse, geometrically grounded, unbiased, and
surgical action-oriented dataset compared to existing surgical VQA datasets. We
then propose SSG-QA-Net, a novel surgical VQA model incorporating a lightweight
Scene-embedded Interaction Module (SIM), which integrates geometric scene
knowledge in the VQA model design by employing cross-attention between the
textual and the scene features. Our comprehensive analysis of the SSG-QA
dataset shows that SSG-QA-Net outperforms existing methods across different
question types and complexities. We highlight that the primary limitation in
the current surgical VQA systems is the lack of scene knowledge to answer
complex queries. We present a novel surgical VQA dataset and model and show
that results can be significantly improved by incorporating geometric scene
features in the VQA model design. The source code and the dataset will be made
publicly available at: https://github.com/CAMMA-public/SSG-QA
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10253" title="Abstract">arXiv:2312.10253</a> [<a href="/pdf/2312.10253" title="Download PDF">pdf</a>, <a href="/format/2312.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catwalk: A Unified Language Model Evaluation Framework for Many Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Awadalla%2C+A">Anas Awadalla</a>, 
<a href="/search/cs?searchtype=author&query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+P">Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The success of large language models has shifted the evaluation paradigms in
natural language processing (NLP). The community's interest has drifted towards
comparing NLP models across many tasks, domains, and datasets, often at an
extreme scale. This imposes new engineering challenges: efforts in constructing
datasets and models have been fragmented, and their formats and interfaces are
incompatible. As a result, it often takes extensive (re)implementation efforts
to make fair and controlled comparisons at scale.
<br />Catwalk aims to address these issues. Catwalk provides a unified interface to
a broad range of existing NLP datasets and models, ranging from both canonical
supervised training and fine-tuning, to more modern paradigms like in-context
learning. Its carefully-designed abstractions allow for easy extensions to many
others. Catwalk substantially lowers the barriers to conducting controlled
experiments at scale. For example, we finetuned and evaluated over 64 models on
over 86 datasets with a single command, without writing any code. Maintained by
the AllenNLP team at the Allen Institute for Artificial Intelligence (AI2),
Catwalk is an ongoing open-source effort: https://github.com/allenai/catwalk.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10256" title="Abstract">arXiv:2312.10256</a> [<a href="/pdf/2312.10256" title="Download PDF">pdf</a>, <a href="/format/2312.10256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent Reinforcement Learning: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huh%2C+D">Dom Huh</a>, 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+P">Prasant Mohapatra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The prevalence of multi-agent applications pervades various interconnected
systems in our everyday lives. Despite their ubiquity, the integration and
development of intelligent decision-making agents in a shared environment pose
challenges to their effective implementation. This survey delves into the
domain of multi-agent systems (MAS), placing a specific emphasis on unraveling
the intricacies of learning optimal control within the MAS framework, commonly
known as multi-agent reinforcement learning (MARL). The objective of this
survey is to provide comprehensive insights into various dimensions of MAS,
shedding light on myriad opportunities while highlighting the inherent
challenges that accompany multi-agent applications. We hope not only to
contribute to a deeper understanding of the MAS landscape but also to provide
valuable perspectives for both researchers and practitioners. By doing so, we
aim to facilitate informed exploration and foster development within the
dynamic realm of MAS, recognizing the need for adaptive strategies and
continuous evolution in addressing emerging complexities in MARL.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10257" title="Abstract">arXiv:2312.10257</a> [<a href="/pdf/2312.10257" title="Download PDF">pdf</a>, <a href="/format/2312.10257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Physics-Informed Neural Network Gravity Model: Generation III
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martin%2C+J">John Martin</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+H">Hanspeter Schaub</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 14 figures, submitted to The Journal of Astronautical Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Scientific machine learning and the advent of the Physics-Informed Neural
Network (PINN) show considerable potential in their capacity to identify
solutions to complex differential equations. Over the past two years, much work
has gone into the development of PINNs capable of solving the gravity field
modeling problem -- i.e.\ learning a differentiable form of the gravitational
potential from position and acceleration estimates. While the past PINN gravity
models (PINN-GMs) have demonstrated advantages in model compactness, robustness
to noise, and sample efficiency; there remain key modeling challenges which
this paper aims to address. Specifically, this paper introduces the third
generation of the Physics-Informed Neural Network Gravity Model (PINN-GM-III)
which solves the problems of extrapolation error, bias towards low-altitude
samples, numerical instability at high-altitudes, and compliant boundary
conditions through numerous modifications to the model's design. The
PINN-GM-III is tested by modeling a known heterogeneous density asteroid, and
its performance is evaluated using seven core metrics which showcases its
strengths against its predecessors and other analytic and numerical gravity
models.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10259" title="Abstract">arXiv:2312.10259</a> [<a href="/pdf/2312.10259" title="Download PDF">pdf</a>, <a href="/format/2312.10259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRNNet: Copy Recurrent Neural Network Structure Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaofan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.13250">arXiv:2305.13250</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The target of Electronic Health Record (EHR) coding is to find the diagnostic
codes according to the EHRs. In previous research, researchers have preferred
to do multi-classification on the EHR coding task; most of them encode the EHR
first and then process it to get the probability of each code based on the EHR
representation. However, the question of complicating diseases is neglected
among all these methods. In this paper, we propose a novel EHR coding
framework, which is the first attempt at detecting complicating diseases,
called Copy Recurrent Neural Network Structure Network (CRNNet). This method
refers to the idea of adversarial learning; a Path Generator and a Path
Discriminator are designed to more efficiently finish the task of EHR coding.
We propose a copy module to detect complicating diseases; by the proposed copy
module and the adversarial learning strategy, we identify complicating diseases
efficiently. Extensive experiments show that our method achieves a 57.30\%
ratio of complicating diseases in predictions, demonstrating the effectiveness
of our proposed model. According to the ablation study, the proposed copy
mechanism plays a crucial role in detecting complicating diseases.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10260" title="Abstract">arXiv:2312.10260</a> [<a href="/pdf/2312.10260" title="Download PDF">pdf</a>, <a href="/format/2312.10260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QR-based Parallel Set-Valued Approximation with Rational Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dirckx%2C+S">Simon Dirckx</a>, 
<a href="/search/math?searchtype=author&query=Meerbergen%2C+K">Karl Meerbergen</a>, 
<a href="/search/math?searchtype=author&query=Huybrechs%2C+D">Daan Huybrechs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article a fast and parallelizable algorithm for rational
approximation is presented. The method, called (P)QR-AAA, is a set valued
variant of the Adaptive Antoulas Anderson (AAA) algorithm. It builds on the
Set-Valued AAA framework from [16], accelerating it by using an approximate
orthogonal basis obtained from a truncated QR decomposition. We demonstrate
both theoretically and numerically this method's robustness. We show how it can
be parallelized while maintaining the desired accuracy, with minimal
communication cost.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10263" title="Abstract">arXiv:2312.10263</a> [<a href="/pdf/2312.10263" title="Download PDF">pdf</a>, <a href="/format/2312.10263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Painterly Image Harmonization by Learning from Painterly Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given a composite image with photographic object and painterly background,
painterly image harmonization targets at stylizing the composite object to be
compatible with the background. Despite the competitive performance of existing
painterly harmonization works, they did not fully leverage the painterly
objects in artistic paintings. In this work, we explore learning from painterly
objects for painterly image harmonization. In particular, we learn a mapping
from background style and object information to object style based on painterly
objects in artistic paintings. With the learnt mapping, we can hallucinate the
target style of composite object, which is used to harmonize encoder feature
maps to produce the harmonized image. Extensive experiments on the benchmark
dataset demonstrate the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10264" title="Abstract">arXiv:2312.10264</a> [<a href="/pdf/2312.10264" title="Download PDF">pdf</a>, <a href="/format/2312.10264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Painterly Image Harmonization from Low-level Styles to  High-level Styles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Painterly image harmonization aims to harmonize a photographic foreground
object on the painterly background. Different from previous auto-encoder based
harmonization networks, we develop a progressive multi-stage harmonization
network, which harmonizes the composite foreground from low-level styles (e.g.,
color, simple texture) to high-level styles (e.g., complex texture). Our
network has better interpretability and harmonization performance. Moreover, we
design an early-exit strategy to automatically decide the proper stage to exit,
which can skip the unnecessary and even harmful late stages. Extensive
experiments on the benchmark dataset demonstrate the effectiveness of our
progressive harmonization network.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10265" title="Abstract">arXiv:2312.10265</a> [<a href="/pdf/2312.10265" title="Download PDF">pdf</a>, <a href="/format/2312.10265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoCopilot: Voice-Activated Tracking of Everyday Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goh%2C+S+A">Sheen An Goh</a>, 
<a href="/search/cs?searchtype=author&query=Gulati%2C+M">Manoj Gulati</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+A">Ambuj Varshney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Voice plays an important role in our lives by facilitating communication,
conveying emotions, and indicating health. Therefore, tracking vocal
interactions can provide valuable insight into many aspects of our lives. This
paper presents our ongoing efforts to design a new vocal tracking system we
call VoCopilot. VoCopilot is an end-to-end system centered around an
energy-efficient acoustic hardware and firmware combined with advanced machine
learning models. As a result, VoCopilot is able to continuously track
conversations, record them, transcribe them, and then extract useful insights
from them. By utilizing large language models, VoCopilot ensures the user can
extract useful insights from recorded interactions without having to learn
complex machine learning techniques. In order to protect the privacy of end
users, VoCopilot uses a novel wake-up mechanism that only records conversations
of end users. Additionally, all the rest of pipeline can be run on a commodity
computer (Mac Mini M2). In this work, we show the effectiveness of VoCopilot in
real-world environment for two use cases.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10266" title="Abstract">arXiv:2312.10266</a> [<a href="/pdf/2312.10266" title="Download PDF">pdf</a>, <a href="/ps/2312.10266" title="Download PostScript">ps</a>, <a href="/format/2312.10266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asset Ownership Identification: Using machine learning to predict  enterprise asset ownership
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobik%2C+C">Craig Jacobik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Asset owner identification is an important first step for any information
security organization, allowing organizations the ability to identify and
detect data breaches and losses, vulnerabilities, possible attack surfaces, and
define effective countermeasures. Using existing asset ownership data, the
research utilized an assortment of machine learning algorithms to determine the
best classification model to predict an asset's owner. The research ran
separate analyses for each enumerated team, then ran a 100 iteration Monte
Carlo Cross Validation across Adaboost, Logistic Regression, Naive Bayes,
Classification and Regression Trees, and Random Forests. Finally, a
visualization dashboard was created to help users understand the asset
inventory through interactive exploratory data analysis as well as the ability
to understand model evaluation metrics including accuracy, sensitivity, and
specificity for each model. Overall, Adaboost performed the best across all
owners with low testing errors below 5% while Naive Bayes performed the worst.
The remaining models performed similarly. The fully qualified domain name
(FQDN), Classless Inter-Domain Routing (CIDR) CIDR/16, and location were among
the most important features.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10269" title="Abstract">arXiv:2312.10269</a> [<a href="/pdf/2312.10269" title="Download PDF">pdf</a>, <a href="/format/2312.10269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The DSA Transparency Database: Auditing Self-reported Moderation Actions  by Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trujillo%2C+A">Amaury Trujillo</a>, 
<a href="/search/cs?searchtype=author&query=Fagni%2C+T">Tiziano Fagni</a>, 
<a href="/search/cs?searchtype=author&query=Cresci%2C+S">Stefano Cresci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Since September 2023, the Digital Services Act (DSA) obliges large online
platforms to submit detailed data on each moderation action they take within
the European Union (EU) to the DSA Transparency Database. From its inception,
this centralized database has sparked scholarly interest as an unprecedented
and potentially unique trove of data on real-world online moderation. Here, we
thoroughly analyze all 195.61M records submitted by the eight largest social
media platforms in the EU during the first 60 days of the database.
Specifically, we conduct a platform-wise comparative study of their: volume of
moderation actions, grounds for decision, types of applied restrictions, types
of moderated content, timeliness in undertaking and submitting moderation
actions, and use of automation. Furthermore, we systematically cross-check the
contents of the database with the platforms' own transparency reports. Our
analyses reveal that (i) the platforms adhered only in part to the philosophy
and structure of the database, (ii) the structure of the database is partially
inadequate for the platforms' reporting needs, (iii) the platforms exhibited
substantial differences in their moderation actions, (iv) a remarkable fraction
of the database data is inconsistent, (v) the platform X (formerly Twitter)
presents the most inconsistencies. Our findings have far-reaching implications
for policymakers and scholars across diverse disciplines. They offer guidance
for future regulations that cater to the reporting needs of online platforms in
general, but also highlight opportunities to improve and refine the database
itself.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10273" title="Abstract">arXiv:2312.10273</a> [<a href="/pdf/2312.10273" title="Download PDF">pdf</a>, <a href="/format/2312.10273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Authentication and Identity Inconsistency Detection via  Mouse-trajectory Similarity Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Completely Automated Public Turing Test To Tell Computers and Humans Apart
(CAPTCHA) is a type of challenge-response test widely used in authentication
systems. A well-known challenge it faces is the CAPTCHA farm, where workers are
hired to solve CAPTCHAs manually. In this work, we propose to tackle this
challenge from a novel perspective, converting CAPTCHA farm detection to
identity inconsistency detection, which essentially becomes an authentication
process. Specifically, we develop a novel embedding model, which measures the
similarity between mouse trajectories collected during the session and when
registering/solving CAPTCHA, to authenticate and detect identity inconsistency.
Moreover, unlike most existing works that employ a separate mouse movement
classifier for each individual user, which brings in considerable costs when
serving a large number of users, our model performs detection tasks using only
one classifier for all users, significantly reducing the cost. Experiment
results validate the superiority of our method over the state-of-the-art time
series classification methods, achieving 94.3% and 97.7% of AUC in identity and
authentication inconsistency detection, respectively.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10274" title="Abstract">arXiv:2312.10274</a> [<a href="/pdf/2312.10274" title="Download PDF">pdf</a>, <a href="/format/2312.10274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operator-learning-inspired Modeling of Neural Ordinary Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+W">Woojin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Seunghyeon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hyundong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jinsung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sanghyun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural ordinary differential equations (NODEs), one of the most influential
works of the differential equation-based deep learning, are to continuously
generalize residual networks and opened a new field. They are currently
utilized for various downstream tasks, e.g., image classification, time series
classification, image generation, etc. Its key part is how to model the
time-derivative of the hidden state, denoted dh(t)/dt. People have habitually
used conventional neural network architectures, e.g., fully-connected layers
followed by non-linear activations. In this paper, however, we present a neural
operator-based method to define the time-derivative term. Neural operators were
initially proposed to model the differential operator of partial differential
equations (PDEs). Since the time-derivative of NODEs can be understood as a
special type of the differential operator, our proposed method, called branched
Fourier neural operator (BFNO), makes sense. In our experiments with general
downstream tasks, our method significantly outperforms existing methods.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10275" title="Abstract">arXiv:2312.10275</a> [<a href="/pdf/2312.10275" title="Download PDF">pdf</a>, <a href="/format/2312.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable Data Management: Indefinite Static Data at Rest with  Machine-Readable Printed Optical Data Sheets (MRPODS)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doll%2C+A">Artem Doll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">In an era where both commercial and private sectors place a premium on the
longevity of digital data storage, the imperative to bolster resilience of
digital information while simultaneously curbing costs and reducing failure
rates becomes paramount. This study delves into the unique attributes of
optical encoding methodologies, which are poised to offer enduring stability
for digital data. Despite their promising potential, there remains a notable
dearth of comprehensive analyses comparing various optical encoding techniques
in terms of their durability. This research is thus dedicated to exploring the
financial and environmental implications of employing technology to transcribe
digital data into a machine-readable optical format, assessing both the
advantages and limitations inherent in this approach. Our empirical findings
reveal a marked increase in the efficiency of machine-readable optical encoding
over conventional digital storage methods, particularly as the volume of data
diminishes and the expected lifespan of storage extends indefinitely. This
paper aims to illuminate key aspects of long-term digital data storage within
business contexts, focusing on aspects such as cost, dependability, legibility,
and confidentiality of optically encoded digital information.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10276" title="Abstract">arXiv:2312.10276</a> [<a href="/pdf/2312.10276" title="Download PDF">pdf</a>, <a href="/format/2312.10276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Norms to Approximate the Minimum Action Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steccanella%2C+L">Lorenzo Steccanella</a>, 
<a href="/search/cs?searchtype=author&query=Jonsson%2C+A">Anders Jonsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents a state representation for reward-free Markov decision
processes. The idea is to learn, in a self-supervised manner, an embedding
space where distances between pairs of embedded states correspond to the
minimum number of actions needed to transition between them. Unlike previous
methods, our approach incorporates an asymmetric norm parametrization, enabling
accurate approximations of minimum action distances in environments with
inherent asymmetry. We show how this representation can be leveraged to learn
goal-conditioned policies, providing a notion of similarity between states and
goals and a useful heuristic distance to guide planning. To validate our
approach, we conduct empirical experiments on both symmetric and asymmetric
environments. Our results show that our asymmetric norm parametrization
performs comparably to symmetric norms in symmetric environments and surpasses
symmetric norms in asymmetric environments.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10279" title="Abstract">arXiv:2312.10279</a> [<a href="/pdf/2312.10279" title="Download PDF">pdf</a>, <a href="/ps/2312.10279" title="Download PostScript">ps</a>, <a href="/format/2312.10279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A charge-preserving method for solving graph neural diffusion networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aceto%2C+L">Lidia Aceto</a>, 
<a href="/search/math?searchtype=author&query=Grassi%2C+P+A">Pietro Antonio Grassi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph)

</div>
<p class="mathjax">The aim of this paper is to give a systematic mathematical interpretation of
the diffusion problem on which Graph Neural Networks (GNNs) models are based.
The starting point of our approach is a dissipative functional leading to
dynamical equations which allows us to study the symmetries of the model. We
discuss the conserved charges and provide a charge-preserving numerical method
for solving the dynamical equations. In any dynamical system and also in GRAph
Neural Diffusion (GRAND), knowing the charge values and their conservation
along the evolution flow could provide a way to understand how GNNs and other
networks work with their learning capabilities.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10282" title="Abstract">arXiv:2312.10282</a> [<a href="/pdf/2312.10282" title="Download PDF">pdf</a>, <a href="/format/2312.10282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetailKLIP : Finetuning OpenCLIP backbone using metric learning on a  single GPU for Zero-shot retail product image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M+M">Muktabh Mayank Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Retail product or packaged grocery goods images need to classified in various
computer vision applications like self checkout stores, supply chain automation
and retail execution evaluation. Previous works explore ways to finetune deep
models for this purpose. But because of the fact that finetuning a large model
or even linear layer for a pretrained backbone requires to run at least a few
epochs of gradient descent for every new retail product added in classification
range, frequent retrainings are needed in a real world scenario. In this work,
we propose finetuning the vision encoder of a CLIP model in a way that its
embeddings can be easily used for nearest neighbor based classification, while
also getting accuracy close to or exceeding full finetuning. A nearest neighbor
based classifier needs no incremental training for new products, thus saving
resources and wait time.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10289" title="Abstract">arXiv:2312.10289</a> [<a href="/pdf/2312.10289" title="Download PDF">pdf</a>, <a href="/format/2312.10289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Reinforcement Learning for Robust Building Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+D">Doseok Jang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Larry Yan</a>, 
<a href="/search/cs?searchtype=author&query=Spangher%2C+L">Lucas Spangher</a>, 
<a href="/search/cs?searchtype=author&query=Spanos%2C+C">Costas Spanos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning (RL) is a powerful tool for optimal control that has
found great success in Atari games, the game of Go, robotic control, and
building optimization. RL is also very brittle; agents often overfit to their
training environment and fail to generalize to new settings. Unsupervised
environment design (UED) has been proposed as a solution to this problem, in
which the agent trains in environments that have been specially selected to
help it learn. Previous UED algorithms focus on trying to train an RL agent
that generalizes across a large distribution of environments. This is not
necessarily desirable when we wish to prioritize performance in one environment
over others. In this work, we will be examining the setting of robust RL
building control, where we wish to train an RL agent that prioritizes
performing well in normal weather while still being robust to extreme weather
conditions. We demonstrate a novel UED algorithm, ActivePLR, that uses
uncertainty-aware neural network architectures to generate new training
environments at the limit of the RL agent's ability while being able to
prioritize performance in a desired base environment. We show that ActivePLR is
able to outperform state-of-the-art UED algorithms in minimizing energy usage
while maximizing occupant comfort in the setting of building control.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10290" title="Abstract">arXiv:2312.10290</a> [<a href="/pdf/2312.10290" title="Download PDF">pdf</a>, <a href="/ps/2312.10290" title="Download PostScript">ps</a>, <a href="/format/2312.10290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Analysis of the SMS-EMOA for Many-Objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a paper accepted in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The widely used multiobjective optimizer NSGA-II was recently proven to have
considerable difficulties in many-objective optimization. In contrast,
experimental results in the literature show a good performance of the SMS-EMOA,
which can be seen as a steady-state NSGA-II that uses the hypervolume
contribution instead of the crowding distance as the second selection
criterion.
<br />This paper conducts the first rigorous runtime analysis of the SMS-EMOA for
many-objective optimization. To this aim, we first propose a many-objective
counterpart, the m-objective mOJZJ problem, of the bi-objective OJZJ benchmark,
which is the first many-objective multimodal benchmark used in a mathematical
runtime analysis. We prove that SMS-EMOA computes the full Pareto front of this
benchmark in an expected number of $O(M^2 n^k)$ iterations, where $n$ denotes
the problem size (length of the bit-string representation), $k$ the gap size (a
difficulty parameter of the problem), and $M=(2n/m-2k+3)^{m/2}$ the size of the
Pareto front. This result together with the existing negative result on the
original NSGA-II shows that in principle, the general approach of the NSGA-II
is suitable for many-objective optimization, but the crowding distance as
tie-breaker has deficiencies.
<br />We obtain three additional insights on the SMS-EMOA. Different from a recent
result for the bi-objective OJZJ benchmark, the stochastic population update
often does not help for mOJZJ. It results in a
$1/\Theta(\min\{Mk^{1/2}/2^{k/2},1\})$ speed-up, which is $\Theta(1)$ for large
$m$ such as $m&gt;k$. On the positive side, we prove that heavy-tailed mutation
still results in a speed-up of order $k^{0.5+k-\beta}$. Finally, we conduct the
first runtime analyses of the SMS-EMOA on the bi-objective OneMinMax and LOTZ
benchmarks and show that it has a performance comparable to the GSEMO and the
NSGA-II.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10293" title="Abstract">arXiv:2312.10293</a> [<a href="/pdf/2312.10293" title="Download PDF">pdf</a>, <a href="/format/2312.10293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inductive Link Prediction in Knowledge Graphs using Path-based Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Canlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiuwen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Link prediction is a crucial research area in knowledge graphs, with many
downstream applications. In many real-world scenarios, inductive link
prediction is required, where predictions have to be made among unseen
entities. Embedding-based models usually need fine-tuning on new entity
embeddings, and hence are difficult to be directly applied to inductive link
prediction tasks. Logical rules captured by rule-based models can be directly
applied to new entities with the same graph typologies, but the captured rules
are discrete and usually lack generosity. Graph neural networks (GNNs) can
generalize topological information to new graphs taking advantage of deep
neural networks, which however may still need fine-tuning on new entity
embeddings. In this paper, we propose SiaILP, a path-based model for inductive
link prediction using siamese neural networks. Our model only depends on
relation and path embeddings, which can be generalized to new entities without
fine-tuning. Experiments show that our model achieves several new
state-of-the-art performances in link prediction tasks using inductive versions
of WN18RR, FB15k-237, and Nell995.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10294" title="Abstract">arXiv:2312.10294</a> [<a href="/pdf/2312.10294" title="Download PDF">pdf</a>, <a href="/format/2312.10294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing A Middleware API for Facilitating Heterogeneous IoT Device  Communication Protocols and Data Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadlamudi%2C+S+V">Sai Varun Vadlamudi</a>, 
<a href="/search/cs?searchtype=author&query=Krikorian%2C+S">Sasoun Krikorian</a>, 
<a href="/search/cs?searchtype=author&query=Skarnes%2C+B">Benjamin Skarnes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Currently, there are over 14 billion IoT devices [7], and with many devices
come many protocols, the main ones being MQTT and CoAP. We are interested in
connecting the many diverse IoT devices to the cloud. To do so, we use the
middleware architecture proposed by article [8] in which a device, called the
middleware, acts as the middleman between the various IoT networks and the
cloud. Since IoT devices typically operate in real-time, performance is of
great concern. Therefore, we conducted a simulation to measure the data latency
of using middleware and the overall fairness between different IoT networks.
Our simulation had an MQTT and a CoAP network interacting with the middleware.
The simulation results showed that CoAP always had a lower travel time than
MQTT, mainly because CoAP is a more lightweight protocol. However, we also
found that MQTT had slightly more throughput, which was unexpected since we
initially thought that CoAP would have had higher throughput. We have shown
that analyzing data via a middleware device is possible and that there are
potential directions to explore, such as evaluating different Quality of
Service Algorithms in the context of having a middleware device.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10297" title="Abstract">arXiv:2312.10297</a> [<a href="/pdf/2312.10297" title="Download PDF">pdf</a>, <a href="/format/2312.10297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shedding Light on Software Engineering-specific Metaphors and Idioms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+M">Mia Mohammad Imran</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Preetha Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Damevski%2C+K">Kostadin Damevski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Use of figurative language, such as metaphors and idioms, is common in our
daily-life communications, and it can also be found in Software Engineering
(SE) channels, such as comments on GitHub. Automatically interpreting
figurative language is a challenging task, even with modern Large Language
Models (LLMs), as it often involves subtle nuances. This is particularly true
in the SE domain, where figurative language is frequently used to convey
technical concepts, often bearing developer affect (e.g., `spaghetti code').
Surprisingly, there is a lack of studies on how figurative language in SE
communications impacts the performance of automatic tools that focus on
understanding developer communications, e.g., bug prioritization, incivility
detection. Furthermore, it is an open question to what extent state-of-the-art
LLMs interpret figurative expressions in domain-specific communication such as
software engineering. To address this gap, we study the prevalence and impact
of figurative language in SE communication channels. This study contributes to
understanding the role of figurative language in SE, the potential of LLMs in
interpreting them, and its impact on automated SE communication analysis. Our
results demonstrate the effectiveness of fine-tuning LLMs with figurative
language in SE and its potential impact on automated tasks that involve affect.
We found that, among three state-of-the-art LLMs, the best improved fine-tuned
versions have an average improvement of 6.66% on a GitHub emotion
classification dataset, 7.07% on a GitHub incivility classification dataset,
and 3.71% on a Bugzilla bug report prioritization dataset.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10299" title="Abstract">arXiv:2312.10299</a> [<a href="/pdf/2312.10299" title="Download PDF">pdf</a>, <a href="/format/2312.10299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Restoration Through Generalized Ornstein-Uhlenbeck Bridge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Conghan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhengwei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junlong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Shiyan Du</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+P">Pengxu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models possess powerful generative capabilities enabling the
mapping of noise to data using reverse stochastic differential equations.
However, in image restoration tasks, the focus is on the mapping relationship
from low-quality images to high-quality images. To address this, we introduced
the Generalized Ornstein-Uhlenbeck Bridge (GOUB) model. By leveraging the
natural mean-reverting property of the generalized OU process and further
adjusting the variance of its steady-state distribution through the Doob's
h-transform, we achieve diffusion mappings from point to point with minimal
cost. This allows for end-to-end training, enabling the recovery of
high-quality images from low-quality ones. Additionally, we uncovered the
mathematical essence of some bridge models, all of which are special cases of
the GOUB and empirically demonstrated the optimality of our proposed models.
Furthermore, benefiting from our distinctive parameterization mechanism, we
proposed the Mean-ODE model that is better at capturing pixel-level information
and structural perceptions. Experimental results show that both models achieved
state-of-the-art results in various tasks, including inpainting, deraining, and
super-resolution. Code is available at https://github.com/Hammour-steak/GOUB.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10300" title="Abstract">arXiv:2312.10300</a> [<a href="/pdf/2312.10300" title="Download PDF">pdf</a>, <a href="/format/2312.10300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shot2Story20K: A New Benchmark for Comprehensive Understanding of  Multi-shot Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See <a href="https://mingfei.info/shot2story">this https URL</a> for updates and more information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A short clip of video may contain progression of multiple events and an
interesting story line. A human need to capture both the event in every shot
and associate them together to understand the story behind it. In this work, we
present a new multi-shot video understanding benchmark Shot2Story20K with
detailed shot-level captions and comprehensive video summaries. To facilitate
better semantic understanding of videos, we provide captions for both visual
signals and human narrations. We design several distinct tasks including
single-shot video and narration captioning, multi-shot video summarization, and
video retrieval with shot descriptions. Preliminary experiments show some
challenges to generate a long and comprehensive video summary. Nevertheless,
the generated imperfect summaries can already significantly boost the
performance of existing video understanding tasks such as video
question-answering, promoting an under-explored setting of video understanding
with detailed summaries.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10301" title="Abstract">arXiv:2312.10301</a> [<a href="/pdf/2312.10301" title="Download PDF">pdf</a>, <a href="/format/2312.10301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FCBench: Cross-Domain Benchmarking of Lossless Compression for  Floating-Point Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiannan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Beaver%2C+I">Ian Beaver</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+C">Cynthia Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianguo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, 11 tables, submitted to VLDB '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">While both the database and high-performance computing (HPC) communities
utilize lossless compression methods to minimize floating-point data size, a
disconnect persists between them. Each community designs and assesses methods
in a domain-specific manner, making it unclear if HPC compression techniques
can benefit database applications or vice versa. With the HPC community
increasingly leaning towards in-situ analysis and visualization, more
floating-point data from scientific simulations are being stored in databases
like Key-Value Stores and queried using in-memory retrieval paradigms. This
trend underscores the urgent need for a collective study of these compression
methods' strengths and limitations, not only based on their performance in
compressing data from various domains but also on their runtime
characteristics. Our study extensively evaluates the performance of eight
CPU-based and five GPU-based compression methods developed by both communities,
using 33 real-world datasets assembled in the Floating-point Compressor
Benchmark (FCBench). Additionally, we utilize the roofline model to profile
their runtime bottlenecks. Our goal is to offer insights into these compression
methods that could assist researchers in selecting existing methods or
developing new ones for integrated database and HPC applications.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10302" title="Abstract">arXiv:2312.10302</a> [<a href="/pdf/2312.10302" title="Download PDF">pdf</a>, <a href="/format/2312.10302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Shot Learning as Instruction Data Prospector for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunshui Li</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Shuzheng Si</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aligning large language models(LLMs) with human is a critical step in
effectively utilizing their pre-trained capabilities across a wide array of
language tasks. Current instruction tuning practices often rely on expanding
dataset size without a clear strategy for ensuring data quality, which can
inadvertently introduce noise and degrade model performance. To address this
challenge, we introduce Nuggets, a novel and efficient methodology that employs
one shot learning to select high-quality instruction data from expansive
datasets. Nuggets assesses the potential of individual instruction examples to
act as effective one shot examples, thereby identifying those that can
significantly enhance diverse task performance. Nuggets utilizes a scoring
system based on the impact of candidate examples on the perplexity of a diverse
anchor set, facilitating the selection of the most beneficial data for
instruction tuning. Through rigorous testing on two benchmarks, including
MT-Bench and Alpaca-Eval, we demonstrate that instruction tuning with the top
1% of Nuggets-curated examples substantially outperforms conventional methods
that use the full dataset. These findings advocate for a data selection
paradigm that prioritizes quality, offering a more efficient pathway to align
LLMs with humans.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10303" title="Abstract">arXiv:2312.10303</a> [<a href="/pdf/2312.10303" title="Download PDF">pdf</a>, <a href="/ps/2312.10303" title="Download PostScript">ps</a>, <a href="/format/2312.10303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Restless Multi-Armed Bandits with Long-Term Fairness Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shufan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guojun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Restless multi-armed bandits (RMAB) have been widely used to model sequential
decision making problems with constraints. The decision maker (DM) aims to
maximize the expected total reward over an infinite horizon under an
"instantaneous activation constraint" that at most B arms can be activated at
any decision epoch, where the state of each arm evolves stochastically
according to a Markov decision process (MDP). However, this basic model fails
to provide any fairness guarantee among arms. In this paper, we introduce
RMAB-F, a new RMAB model with "long-term fairness constraints", where the
objective now is to maximize the long term reward while a minimum long-term
activation fraction for each arm must be satisfied. For the online RMAB-F
setting (i.e., the underlying MDPs associated with each arm are unknown to the
DM), we develop a novel reinforcement learning (RL) algorithm named Fair-UCRL.
We prove that Fair-UCRL ensures probabilistic sublinear bounds on both the
reward regret and the fairness violation regret. Compared with off-the-shelf RL
methods, our Fair-UCRL is much more computationally efficient since it contains
a novel exploitation that leverages a low-complexity index policy for making
decisions. Experimental results further demonstrate the effectiveness of our
Fair-UCRL.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10305" title="Abstract">arXiv:2312.10305</a> [<a href="/pdf/2312.10305" title="Download PDF">pdf</a>, <a href="/format/2312.10305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Disentangled Representation Learning for Robust Target  Speech Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+Z">Zhaoxi Mu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sining Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech signals are inherently complex as they encompass both global acoustic
characteristics and local semantic information. However, in the task of target
speech extraction, certain elements of global and local semantic information in
the reference speech, which are irrelevant to speaker identity, can lead to
speaker confusion within the speech extraction network. To overcome this
challenge, we propose a self-supervised disentangled representation learning
method. Our approach tackles this issue through a two-phase process, utilizing
a reference speech encoding network and a global information disentanglement
network to gradually disentangle the speaker identity information from other
irrelevant factors. We exclusively employ the disentangled speaker identity
information to guide the speech extraction network. Moreover, we introduce the
adaptive modulation Transformer to ensure that the acoustic representation of
the mixed signal remains undisturbed by the speaker embeddings. This component
incorporates speaker embeddings as conditional information, facilitating
natural and efficient guidance for the speech extraction network. Experimental
results substantiate the effectiveness of our meticulously crafted approach,
showcasing a substantial reduction in the likelihood of speaker confusion.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10306" title="Abstract">arXiv:2312.10306</a> [<a href="/pdf/2312.10306" title="Download PDF">pdf</a>, <a href="/format/2312.10306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping Housing Stock Characteristics from Drone Images for Climate  Resilience in the Caribbean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tingzon%2C+I">Isabelle Tingzon</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+N+M">Nuala Margaret Cowan</a>, 
<a href="/search/cs?searchtype=author&query=Chrzanowski%2C+P">Pierre Chrzanowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tackling Climate Change with Machine Learning: Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Comprehensive information on housing stock is crucial for climate adaptation
initiatives aiming to reduce the adverse impacts of climate-extreme hazards in
high-risk regions like the Caribbean. In this study, we propose a workflow for
rapidly generating critical baseline housing stock data using very
high-resolution drone images and deep learning techniques. Specifically, our
work leverages the Segment Anything Model and convolutional neural networks for
the automated generation of building footprints and roof classification maps.
By strengthening local capacity within government agencies to leverage AI and
Earth Observation-based solutions, this work seeks to improve the climate
resilience of the housing sector in small island developing states in the
Caribbean.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10307" title="Abstract">arXiv:2312.10307</a> [<a href="/pdf/2312.10307" title="Download PDF">pdf</a>, <a href="/format/2312.10307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MusER: Musical Element-Based Regularization for Generating Symbolic  Music with Emotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shulei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Generating music with emotion is an important task in automatic music
generation, in which emotion is evoked through a variety of musical elements
(such as pitch and duration) that change over time and collaborate with each
other. However, prior research on deep learning-based emotional music
generation has rarely explored the contribution of different musical elements
to emotions, let alone the deliberate manipulation of these elements to alter
the emotion of music, which is not conducive to fine-grained element-level
control over emotions. To address this gap, we present a novel approach
employing musical element-based regularization in the latent space to
disentangle distinct elements, investigate their roles in distinguishing
emotions, and further manipulate elements to alter musical emotions.
Specifically, we propose a novel VQ-VAE-based model named MusER. MusER
incorporates a regularization loss to enforce the correspondence between the
musical element sequences and the specific dimensions of latent variable
sequences, providing a new solution for disentangling discrete sequences.
Taking advantage of the disentangled latent vectors, a two-level decoding
strategy that includes multiple decoders attending to latent vectors with
different semantics is devised to better predict the elements. By visualizing
latent space, we conclude that MusER yields a disentangled and interpretable
latent space and gain insights into the contribution of distinct elements to
the emotional dimensions (i.e., arousal and valence). Experimental results
demonstrate that MusER outperforms the state-of-the-art models for generating
emotional music in both objective and subjective evaluation. Besides, we
rearrange music through element transfer and attempt to alter the emotion of
music by transferring emotion-distinguishable elements.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10308" title="Abstract">arXiv:2312.10308</a> [<a href="/pdf/2312.10308" title="Download PDF">pdf</a>, <a href="/format/2312.10308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Based Contrastive Learning for Medical Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyewon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Oufattole%2C+N">Nassim Oufattole</a>, 
<a href="/search/cs?searchtype=author&query=Balagopalan%2C+A">Aparna Balagopalan</a>, 
<a href="/search/cs?searchtype=author&query=Mcdermott%2C+M">Matthew Mcdermott</a>, 
<a href="/search/cs?searchtype=author&query=Chandak%2C+P">Payal Chandak</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Stultz%2C+C">Collin Stultz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Unifying Representations in Neural Models Workshop in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In clinical practice, one often needs to identify whether a patient is at
high risk of adverse outcomes after some key medical event; e.g., the
short-term risk of death after an admission for heart failure. This task,
however, remains challenging due to the complexity, variability, and
heterogeneity of longitudinal medical data, especially for individuals
suffering from chronic diseases like heart failure. In this paper, we introduce
Event-Based Contrastive Learning (EBCL) - a method for learning embeddings of
heterogeneous patient data that preserves temporal information before and after
key index events. We demonstrate that EBCL produces models that yield better
fine-tuning performance on critical downstream tasks including 30-day
readmission, 1-year mortality, and 1-week length of stay relative to other
representation learning methods that do not exploit temporal information
surrounding key medical events.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10309" title="Abstract">arXiv:2312.10309</a> [<a href="/pdf/2312.10309" title="Download PDF">pdf</a>, <a href="/format/2312.10309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Mammography with Co-Robotic Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yifan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+J">Julian Brown</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+R+H">Russell H. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Boctor%2C+E+M">Emad M. Boctor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ultrasound (US) imaging is a vital adjunct to mammography in breast cancer
screening and diagnosis, but its reliance on hand-held transducers often lacks
repeatability and heavily depends on sonographers' skills. Integrating US
systems from different vendors further complicates clinical standards and
workflows. This research introduces a co-robotic US platform for repeatable,
accurate, and vendor-independent breast US image acquisition. The platform can
autonomously perform 3D volume scans or swiftly acquire real-time 2D images of
suspicious lesions. Utilizing a Universal Robot UR5 with an RGB camera, a force
sensor, and an L7-4 linear array transducer, the system achieves autonomous
navigation, motion control, and image acquisition. The calibrations, including
camera-mammogram, robot-camera, and robot-US, were rigorously conducted and
validated. Governed by a PID force control, the robot-held transducer maintains
a constant contact force with the compression plate during the scan for safety
and patient comfort. The framework was validated on a lesion-mimicking phantom.
Our results indicate that the developed co-robotic US platform promises to
enhance the precision and repeatability of breast cancer screening and
diagnosis. Additionally, the platform offers straightforward integration into
most mammographic devices to ensure vendor-independence.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10310" title="Abstract">arXiv:2312.10310</a> [<a href="/pdf/2312.10310" title="Download PDF">pdf</a>, <a href="/format/2312.10310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> scBiGNN: Bilevel Graph Representation Learning for Cell Type  Classification from Single-cell RNA Sequencing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Junni Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dapeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 AI for Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Genomics (q-bio.GN)

</div>
<p class="mathjax">Single-cell RNA sequencing (scRNA-seq) technology provides high-throughput
gene expression data to study the cellular heterogeneity and dynamics of
complex organisms. Graph neural networks (GNNs) have been widely used for
automatic cell type classification, which is a fundamental problem to solve in
scRNA-seq analysis. However, existing methods do not sufficiently exploit both
gene-gene and cell-cell relationships, and thus the true potential of GNNs is
not realized. In this work, we propose a bilevel graph representation learning
method, named scBiGNN, to simultaneously mine the relationships at both gene
and cell levels for more accurate single-cell classification. Specifically,
scBiGNN comprises two GNN modules to identify cell types. A gene-level GNN is
established to adaptively learn gene-gene interactions and cell representations
via the self-attention mechanism, and a cell-level GNN builds on the cell-cell
graph that is constructed from the cell representations generated by the
gene-level GNN. To tackle the scalability issue for processing a large number
of cells, scBiGNN adopts an Expectation Maximization (EM) framework in which
the two modules are alternately trained via the E-step and M-step to learn from
each other. Through this interaction, the gene- and cell-level structural
information is integrated to gradually enhance the classification performance
of both GNN modules. Experiments on benchmark datasets demonstrate that our
scBiGNN outperforms a variety of existing methods for cell type classification
from scRNA-seq data.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10312" title="Abstract">arXiv:2312.10312</a> [<a href="/pdf/2312.10312" title="Download PDF">pdf</a>, <a href="/ps/2312.10312" title="Download PostScript">ps</a>, <a href="/format/2312.10312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STELLAR: Siamese Multi-Headed Attention Neural Networks for Overcoming  Temporal Variations and Device Heterogeneity with Indoor Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gufran%2C+D">Danish Gufran</a>, 
<a href="/search/cs?searchtype=author&query=Tiku%2C+S">Saideep Tiku</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Smartphone-based indoor localization has emerged as a cost-effective and
accurate solution to localize mobile and IoT devices indoors. However, the
challenges of device heterogeneity and temporal variations have hindered its
widespread adoption and accuracy. Towards jointly addressing these challenges
comprehensively, we propose STELLAR, a novel framework implementing a
contrastive learning approach that leverages a Siamese multi-headed attention
neural network. STELLAR is the first solution that simultaneously tackles
device heterogeneity and temporal variations in indoor localization, without
the need for retraining the model (re-calibration-free). Our evaluations across
diverse indoor environments show 8-75% improvements in accuracy compared to
state-of-the-art techniques, to effectively address the device heterogeneity
challenge. Moreover, STELLAR outperforms existing methods by 18-165% over 2
years of temporal variations, showcasing its robustness and adaptability.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10314" title="Abstract">arXiv:2312.10314</a> [<a href="/pdf/2312.10314" title="Download PDF">pdf</a>, <a href="/format/2312.10314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCalliFont: Few-shot Chinese Calligraphy Font Synthesis by  Integrating Dual-modality Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yitian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhouhui Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot font generation, especially for Chinese calligraphy fonts, is a
challenging and ongoing problem. With the help of prior knowledge that is
mainly based on glyph consistency assumptions, some recently proposed methods
can synthesize high-quality Chinese glyph images. However, glyphs in
calligraphy font styles often do not meet these assumptions. To address this
problem, we propose a novel model, DeepCalliFont, for few-shot Chinese
calligraphy font synthesis by integrating dual-modality generative models.
Specifically, the proposed model consists of image synthesis and sequence
generation branches, generating consistent results via a dual-modality
representation learning strategy. The two modalities (i.e., glyph images and
writing sequences) are properly integrated using a feature recombination module
and a rasterization loss function. Furthermore, a new pre-training strategy is
adopted to improve the performance by exploiting large amounts of uni-modality
data. Both qualitative and quantitative experiments have been conducted to
demonstrate the superiority of our method to other state-of-the-art approaches
in the task of few-shot Chinese calligraphy font synthesis. The source code can
be found at https://github.com/lsflyt-pku/DeepCalliFont.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10315" title="Abstract">arXiv:2312.10315</a> [<a href="/pdf/2312.10315" title="Download PDF">pdf</a>, <a href="/ps/2312.10315" title="Download PostScript">ps</a>, <a href="/format/2312.10315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A neural network kernel decomposition for learning multiple steady  states in parameterized dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yimeng Zhang</a>, 
<a href="/search/math?searchtype=author&query=Cloninger%2C+A">Alexander Cloninger</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/math?searchtype=author&query=Tian%2C+X">Xiaochuan Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We develop a machine learning approach to identifying parameters with
steady-state solutions, locating such solutions, and determining their linear
stability for systems of ordinary differential equations and dynamical systems
with parameters. Our approach begins with the construction of target functions
that can be used to identify parameters with steady-state solution and the
linear stability of such solutions. We design a parameter-solution neural
network (PSNN) that couples a parameter neural network and a solution neural
network to approximate the target function, and develop efficient algorithms to
train the PSNN and to locate steady-state solutions. We also present a theory
of approximation of the target function by our PSNN based on the neural network
kernel decomposition. Numerical results are reported to show that our approach
is robust in identifying the phase boundaries separating different regions in
the parameter space corresponding to no solution or different numbers of
solutions and in classifying the stability of solutions. These numerical
results also validate our analysis. Although the primary focus in this study
centers on steady states of parameterized dynamical systems, our approach is
applicable generally to finding solutions for parameterized nonlinear systems
of algebraic equations. Some potential improvements and future work are
discussed.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10316" title="Abstract">arXiv:2312.10316</a> [<a href="/pdf/2312.10316" title="Download PDF">pdf</a>, <a href="/ps/2312.10316" title="Download PostScript">ps</a>, <a href="/format/2312.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-relaxation-time regularized lattice Boltzmann model for  convection-diffusion equation with variable coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+Y">Yuan Yu</a>, 
<a href="/search/math?searchtype=author&query=Qin%2C+Z">Zuojian Qin</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+H">Haizhuan Yuan</a>, 
<a href="/search/math?searchtype=author&query=Shu%2C+S">Shi Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">In this paper, a new two-relaxation-time regularized (TRT-R) lattice
Boltzmann (LB) model for convection-diffusion equation (CDE) with variable
coefficients is proposed. Within this framework, we first derive a TRT-R
collision operator by constructing a new regularized procedure through the
high-order Hermite expansion of non-equilibrium. Then a first-order
discrete-velocity form of discrete source term is introduced to improve the
accuracy of the source term. Finally and most importantly, a new first-order
space-derivative auxiliary term is proposed to recover the correct CDE with
variable coefficients. To evaluate this model, we simulate a classic benchmark
problem of the rotating Gaussian pulse. The results show that our model has
better accuracy, stability and convergence than other popular LB models,
especially in the case of a large time step.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10317" title="Abstract">arXiv:2312.10317</a> [<a href="/pdf/2312.10317" title="Download PDF">pdf</a>, <a href="/format/2312.10317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal DAG Convolutional Networks for End-to-End Joint  Effective Connectivity Learning and Resting-State fMRI Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+H">Huajun She</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y+P">Yiping P. Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dapeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Temporal Graph Learning Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Building comprehensive brain connectomes has proved of fundamental importance
in resting-state fMRI (rs-fMRI) analysis. Based on the foundation of brain
network, spatial-temporal-based graph convolutional networks have dramatically
improved the performance of deep learning methods in rs-fMRI time series
classification. However, existing works either pre-define the brain network as
the correlation matrix derived from the raw time series or jointly learn the
connectome and model parameters without any topology constraint. These methods
could suffer from degraded classification performance caused by the deviation
from the intrinsic brain connectivity and lack biological interpretability of
demonstrating the causal structure (i.e., effective connectivity) among brain
regions. Moreover, most existing methods for effective connectivity learning
are unaware of the downstream classification task and cannot sufficiently
exploit useful rs-fMRI label information. To address these issues in an
end-to-end manner, we model the brain network as a directed acyclic graph (DAG)
to discover direct causal connections between brain regions and propose
Spatial-Temporal DAG Convolutional Network (ST-DAGCN) to jointly infer
effective connectivity and classify rs-fMRI time series by learning brain
representations based on nonlinear structural equation model. The optimization
problem is formulated into a continuous program and solved with score-based
learning method via gradient descent. We evaluate ST-DAGCN on two public
rs-fMRI databases. Experiments show that ST-DAGCN outperforms existing models
by evident margins in rs-fMRI classification and simultaneously learns
meaningful edges of effective connectivity that help understand brain activity
patterns and pathological mechanisms in brain disease.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10319" title="Abstract">arXiv:2312.10319</a> [<a href="/pdf/2312.10319" title="Download PDF">pdf</a>, <a href="/ps/2312.10319" title="Download PostScript">ps</a>, <a href="/format/2312.10319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building AI and Human Capital for Road Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dedhia%2C+Y">Yug Dedhia</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anjali Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tomar%2C+V+S">Vaibhav Singh Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Rangaswamy%2C+N">Nimmi Rangaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Thakur%2C+D+S">Dev Singh Thakur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">AI is about learning algorithms and huge amounts of data and are drivers of
economic growth -- what does this mean for the field of development studies?
Can we re-orient to twin AI studies and development theory and practice to
generate how development challenges are identified and researched? To do this a
good grasp is needed of AI internal mechanisms and outcomes in addressing
development issues -- this argument will be developed through a case study of
the ADAS [Advanced Driver Assistance System] deployment in India. Over and
above discussing the ADAS we bring an anthropological lens to understand the
social context that surrounds the system. Focusing on bus drivers, we offer
findings from a qualitative and ethnographic study of drivers in a
collaborative effort to achieve road safety by deploying AI-driven technology
and empowering stakeholders in the transport industry in India especially, bus
drivers as critical actors in the city transport network.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10320" title="Abstract">arXiv:2312.10320</a> [<a href="/pdf/2312.10320" title="Download PDF">pdf</a>, <a href="/format/2312.10320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetrical Bidirectional Knowledge Alignment for Zero-Shot Sketch-Based  Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper studies the problem of zero-shot sketch-based image retrieval
(ZS-SBIR), which aims to use sketches from unseen categories as queries to
match the images of the same category. Due to the large cross-modality
discrepancy, ZS-SBIR is still a challenging task and mimics realistic zero-shot
scenarios. The key is to leverage transferable knowledge from the pre-trained
model to improve generalizability. Existing researchers often utilize the
simple fine-tuning training strategy or knowledge distillation from a teacher
model with fixed parameters, lacking efficient bidirectional knowledge
alignment between student and teacher models simultaneously for better
generalization. In this paper, we propose a novel Symmetrical Bidirectional
Knowledge Alignment for zero-shot sketch-based image retrieval (SBKA). The
symmetrical bidirectional knowledge alignment learning framework is designed to
effectively learn mutual rich discriminative information between teacher and
student models to achieve the goal of knowledge alignment. Instead of the
former one-to-one cross-modality matching in the testing stage, a one-to-many
cluster cross-modality matching method is proposed to leverage the inherent
relationship of intra-class images to reduce the adverse effects of the
existing modality gap. Experiments on several representative ZS-SBIR datasets
(Sketchy Ext dataset, TU-Berlin Ext dataset and QuickDraw Ext dataset) prove
the proposed algorithm can achieve superior performance compared with
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10321" title="Abstract">arXiv:2312.10321</a> [<a href="/pdf/2312.10321" title="Download PDF">pdf</a>, <a href="/format/2312.10321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fuheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+L">Lawrence Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I">Ishtiyaque Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+D">Divyakant Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Abbadi%2C+A+E">Amr El Abbadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Judging the equivalence between two SQL queries is a fundamental problem with
many practical applications in data management and SQL generation (i.e.,
evaluating the quality of generated SQL queries in text-to-SQL task). While the
research community has reasoned about SQL equivalence for decades, it poses
considerable difficulties and no complete solutions exist. Recently, Large
Language Models (LLMs) have shown strong reasoning capability in conversation,
question answering and solving mathematics challenges. In this paper, we study
if LLMs can be used to determine the equivalence between SQL queries under two
notions of SQL equivalence (semantic equivalence and relaxed equivalence). To
assist LLMs in generating high quality responses, we present two prompting
techniques: Miniature &amp; Mull and Explain &amp; Compare. The former technique is
used to evaluate the semantic equivalence in which it asks LLMs to execute a
query on a simple database instance and then explore if a counterexample exists
by modifying the database. The latter technique is used to evaluate the relaxed
equivalence in which it asks LLMs to explain the queries and then compare if
they contain significant logical differences. Our experiments demonstrate using
our techniques, LLMs is a promising tool to help data engineers in writing
semantically equivalent SQL queries, however challenges still persist, and is a
better metric for evaluating SQL generation than the popular execution
accuracy.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10323" title="Abstract">arXiv:2312.10323</a> [<a href="/pdf/2312.10323" title="Download PDF">pdf</a>, <a href="/format/2312.10323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Prompt Generation from Linear Combination of Discrete Prompt  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Passigan%2C+P">Pascal Passigan</a>, 
<a href="/search/cs?searchtype=author&query=Yohannes%2C+K">Kidus Yohannes</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J">Joshua Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The wayward quality of continuous prompts stresses the importance of their
interpretability as unexpected and unpredictable behaviors appear following
training, especially in the context of large language models automating
people-sensitive tasks such as resume screening. In this paper we present a
novel method of constructing continuous prompts via discrete prompt embeddings
and evaluate improvements to continuous prompt interpretability and inference
accuracy. For a set of manually designed discrete prompts $\mathcal{D}$, which
we tokenize each into tensor form, we train a model to predict the weights such
that the linear combinations of those prompts correspond to higher performance
on natural language understanding tasks.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10324" title="Abstract">arXiv:2312.10324</a> [<a href="/pdf/2312.10324" title="Download PDF">pdf</a>, <a href="/format/2312.10324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Instance-Dependent Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jieming Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated learning (FL) with noisy labels poses a significant challenge.
Existing methods designed for handling noisy labels in centralized learning
tend to lose their effectiveness in the FL setting, mainly due to the small
dataset size and the heterogeneity of client data. While some attempts have
been made to tackle FL with noisy labels, they primarily focused on scenarios
involving class-conditional noise. In this paper, we study the more challenging
and practical issue of instance-dependent noise (IDN) in FL. We introduce a
novel algorithm called FedBeat (Federated Learning with Bayesian
Ensemble-Assisted Transition Matrix Estimation). FedBeat aims to build a global
statistically consistent classifier using the IDN transition matrix (IDNTM),
which encompasses three synergistic steps: (1) A federated data extraction step
that constructs a weak global model and extracts high-confidence data using a
Bayesian model ensemble method. (2) A federated transition matrix estimation
step in which clients collaboratively train an IDNTM estimation network based
on the extracted data. (3) A federated classifier correction step that enhances
the global model's performance by training it using a loss function tailored
for noisy labels, leveraging the IDNTM. Experiments conducted on CIFAR-10 and
SVHN verify that the proposed method significantly outperforms state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10325" title="Abstract">arXiv:2312.10325</a> [<a href="/pdf/2312.10325" title="Download PDF">pdf</a>, <a href="/format/2312.10325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Attentive Inductive Bias for Sequential Recommendation Beyond the  Self-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Yehjin Shin and Jeongwhan Choi are co-first authors with equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Sequential recommendation (SR) models based on Transformers have achieved
remarkable successes. The self-attention mechanism of Transformers for computer
vision and natural language processing suffers from the oversmoothing problem,
i.e., hidden representations becoming similar to tokens. In the SR domain, we,
for the first time, show that the same problem occurs. We present pioneering
investigations that reveal the low-pass filtering nature of self-attention in
the SR, which causes oversmoothing. To this end, we propose a novel method
called Beyond Self-Attention for Sequential Recommendation (BSARec), which
leverages the Fourier transform to i) inject an inductive bias by considering
fine-grained sequential patterns and ii) integrate low and high-frequency
information to mitigate oversmoothing. Our discovery shows significant
advancements in the SR domain and is expected to bridge the gap for existing
Transformer-based SR models. We test our proposed approach through extensive
experiments on 6 benchmark datasets. The experimental results demonstrate that
our model outperforms 7 baseline methods in terms of recommendation
performance.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10326" title="Abstract">arXiv:2312.10326</a> [<a href="/pdf/2312.10326" title="Download PDF">pdf</a>, <a href="/format/2312.10326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Algorithms for Finite Element nonlinear Discrete Systems to Solve  the PNP Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Shu%2C+S">Shi Shu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Ying Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Poisson-Nernst-Planck (PNP) equations are one of the most effective model
for describing electrostatic interactions and diffusion processes in ion
solution systems, and have been widely used in the numerical simulations of
biological ion channels, semiconductor devices, and nanopore systems. Due to
the characteristics of strong coupling, convection dominance, nonlinearity and
multiscale, the classic Gummel iteration for the nonlinear discrete system of
PNP equations converges slowly or even diverges. We focus on fast algorithms of
nonlinear discrete system for the general PNP equations, which have better
adaptability, friendliness and efficiency than the Gummel iteration. First, a
geometric full approximation storage (FAS) algorithm is proposed to improve the
slow convergence speed of the Gummel iteration. Second, an algebraic FAS
algorithm is designed, which does not require multi-level geometric information
and is more suitable for practical computation compared with the geometric one.
Finally, improved algorithms based on the acceleration technique and adaptive
method are proposed to solve the problems of excessive coarse grid iterations
and insufficient adaptability to the size of computational domain in the
algebraic FAS algorithm. The numerical experiments are shown for the geometric,
algebraic FAS and improved algorithms respectively to illustrate the effiency
of the algorithms.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10328" title="Abstract">arXiv:2312.10328</a> [<a href="/pdf/2312.10328" title="Download PDF">pdf</a>, <a href="/format/2312.10328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deriving Rewards for Reinforcement Learning from Symbolic Behaviour  Descriptions of Bipedal Walking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harnack%2C+D">Daniel Harnack</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCth%2C+C">Christoph L&#xfc;th</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+L">Lukas Gross</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shivesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kirchner%2C+F">Frank Kirchner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 62nd IEEE Conference on Decision and Control (CDC). For supplemental material, see here <a href="https://dfki-ric-underactuated-lab.github.io/orthant_rewards_biped_rl/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Generating physical movement behaviours from their symbolic description is a
long-standing challenge in artificial intelligence (AI) and robotics, requiring
insights into numerical optimization methods as well as into formalizations
from symbolic AI and reasoning. In this paper, a novel approach to finding a
reward function from a symbolic description is proposed. The intended system
behaviour is modelled as a hybrid automaton, which reduces the system state
space to allow more efficient reinforcement learning. The approach is applied
to bipedal walking, by modelling the walking robot as a hybrid automaton over
state space orthants, and used with the compass walker to derive a reward that
incentivizes following the hybrid automaton cycle. As a result, training times
of reinforcement learning controllers are reduced while final walking speed is
increased. The approach can serve as a blueprint how to generate reward
functions from symbolic AI and reasoning.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10329" title="Abstract">arXiv:2312.10329</a> [<a href="/pdf/2312.10329" title="Download PDF">pdf</a>, <a href="/format/2312.10329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perturbation-Invariant Adversarial Training for Neural Ranking Models:  Improving the Effectiveness-Robustness Trade-Off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingkun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Neural ranking models (NRMs) have shown great success in information
retrieval (IR). But their predictions can easily be manipulated using
adversarial examples, which are crafted by adding imperceptible perturbations
to legitimate documents. This vulnerability raises significant concerns about
their reliability and hinders the widespread deployment of NRMs. By
incorporating adversarial examples into training data, adversarial training has
become the de facto defense approach to adversarial attacks against NRMs.
However, this defense mechanism is subject to a trade-off between effectiveness
and adversarial robustness. In this study, we establish theoretical guarantees
regarding the effectiveness-robustness trade-off in NRMs. We decompose the
robust ranking error into two components, i.e., a natural ranking error for
effectiveness evaluation and a boundary ranking error for assessing adversarial
robustness. Then, we define the perturbation invariance of a ranking model and
prove it to be a differentiable upper bound on the boundary ranking error for
attainable computation. Informed by our theoretical analysis, we design a novel
\emph{perturbation-invariant adversarial training} (PIAT) method for ranking
models to achieve a better effectiveness-robustness trade-off. We design a
regularized surrogate loss, in which one term encourages the effectiveness to
be maximized while the regularization term encourages the output to be smooth,
so as to improve adversarial robustness. Experimental results on several
ranking models demonstrate the superiority of PITA compared to existing
adversarial defenses.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10332" title="Abstract">arXiv:2312.10332</a> [<a href="/pdf/2312.10332" title="Download PDF">pdf</a>, <a href="/format/2312.10332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProTIP: Progressive Tool Retrieval Improves Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anantha%2C+R">Raviteja Anantha</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+B">Bortik Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Kashi%2C+A">Anirudh Kashi</a>, 
<a href="/search/cs?searchtype=author&query=Mahinder%2C+S">Sayantan Mahinder</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+A+W">Andrew W Hill</a>, 
<a href="/search/cs?searchtype=author&query=Chappidi%2C+S">Srinivas Chappidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are increasingly employed for complex multi-step
planning tasks, where the tool retrieval (TR) step is crucial for achieving
successful outcomes. Two prevalent approaches for TR are single-step retrieval,
which utilizes the complete query, and sequential retrieval using task
decomposition (TD), where a full query is segmented into discrete atomic
subtasks. While single-step retrieval lacks the flexibility to handle
"inter-tool dependency," the TD approach necessitates maintaining "subtask-tool
atomicity alignment," as the toolbox can evolve dynamically. To address these
limitations, we introduce the Progressive Tool retrieval to Improve Planning
(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based
framework that implicitly performs TD without the explicit requirement of
subtask labels, while simultaneously maintaining subtask-tool atomicity. On the
ToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based
approach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for
TR and a 41% enhancement in tool accuracy for plan generation.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10336" title="Abstract">arXiv:2312.10336</a> [<a href="/pdf/2312.10336" title="Download PDF">pdf</a>, <a href="/ps/2312.10336" title="Download PostScript">ps</a>, <a href="/format/2312.10336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certified Minimax Unlearning with Generalization Rates and Deletion  Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study the problem of $(\epsilon,\delta)$-certified machine unlearning for
minimax models. Most of the existing works focus on unlearning from standard
statistical learning models that have a single variable and their unlearning
steps hinge on the direct Hessian-based conventional Newton update. We develop
a new $(\epsilon,\delta)$-certified machine unlearning algorithm for minimax
models. It proposes a minimax unlearning step consisting of a
total-Hessian-based complete Newton update and the Gaussian mechanism borrowed
from differential privacy. To obtain the unlearning certification, our method
injects calibrated Gaussian noises by carefully analyzing the "sensitivity" of
the minimax unlearning step (i.e., the closeness between the minimax unlearning
variables and the retraining-from-scratch variables). We derive the
generalization rates in terms of population strong and weak primal-dual risk
for three different cases of loss functions, i.e.,
(strongly-)convex-(strongly-)concave losses. We also provide the deletion
capacity to guarantee that a desired population risk can be maintained as long
as the number of deleted samples does not exceed the derived amount. With
training samples $n$ and model dimension $d$, it yields the order $\mathcal
O(n/d^{1/4})$, which shows a strict gap over the baseline method of
differentially private minimax learning that has $\mathcal O(n/d^{1/2})$. In
addition, our rates of generalization and deletion capacity match the
state-of-the-art rates derived previously for standard statistical learning
models.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10338" title="Abstract">arXiv:2312.10338</a> [<a href="/pdf/2312.10338" title="Download PDF">pdf</a>, <a href="/format/2312.10338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Material Point Methods on Unstructured Tessellations: A Stable Kernel  Approach With Continuous Gradient Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yadi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yidong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jinhyun Choo</a>, 
<a href="/search/cs?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenfanfu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The Material Point Method (MPM) is a hybrid Eulerian-Lagrangian simulation
technique for solid mechanics with significant deformation. Structured
background grids are commonly employed in the standard MPM, but they may give
rise to several accuracy problems in handling complex geometries. When using
(2D) unstructured triangular or (3D) tetrahedral background elements, however,
significant challenges arise (eg, cell-crossing error). Substantial numerical
errors develop due to the inherent C0 continuity property of the interpolation
function, which causes discontinuous gradients across element boundaries. Prior
efforts in constructing C1 continuous interpolation functions have either not
been adapted for unstructured grids or have only been applied to 2D triangular
meshes. In this study, an Unstructured Moving Least Squares MPM (UMLS-MPM) is
introduced to accommodate 2D and 3D simplex tessellation. The central idea is
to incorporate a diminishing function into the sample weights of the MLS
kernel, ensuring an analytically continuous velocity gradient estimation.
Numerical analyses confirm the method's capability in mitigating cell crossing
inaccuracies and realizing expected convergence.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10339" title="Abstract">arXiv:2312.10339</a> [<a href="/pdf/2312.10339" title="Download PDF">pdf</a>, <a href="/format/2312.10339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-free Learning of Corridor Clearance: A Near-term Deployment  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suo%2C+D">Dajiang Suo</a>, 
<a href="/search/cs?searchtype=author&query=Jayawardana%2C+V">Vindula Jayawardana</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An emerging public health application of connected and automated vehicle
(CAV) technologies is to reduce response times of emergency medical service
(EMS) by indirectly coordinating traffic. Therefore, in this work we study the
CAV-assisted corridor clearance for EMS vehicles from a short term deployment
perspective. Existing research on this topic often overlooks the impact of EMS
vehicle disruptions on regular traffic, assumes 100% CAV penetration, relies on
real-time traffic signal timing data and queue lengths at intersections, and
makes various assumptions about traffic settings when deriving optimal
model-based CAV control strategies. However, these assumptions pose significant
challenges for near-term deployment and limit the real-world applicability of
such methods. To overcome these challenges and enhance real-world applicability
in near-term, we propose a model-free approach employing deep reinforcement
learning (DRL) for designing CAV control strategies, showing its reduced
overhead in designing and greater scalability and performance compared to
model-based methods. Our qualitative analysis highlights the complexities of
designing scalable EMS corridor clearance controllers for diverse traffic
settings in which DRL controller provides ease of design compared to the
model-based methods. In numerical evaluations, the model-free DRL controller
outperforms the model-based counterpart by improving traffic flow and even
improving EMS travel times in scenarios when a single CAV is present. Across 19
considered settings, the learned DRL controller excels by 25% in reducing the
travel time in six instances, achieving an average improvement of 9%. These
findings underscore the potential and promise of model-free DRL strategies in
advancing EMS response and traffic flow coordination, with a focus on practical
near-term deployment.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10342" title="Abstract">arXiv:2312.10342</a> [<a href="/pdf/2312.10342" title="Download PDF">pdf</a>, <a href="/format/2312.10342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Adaptive Weighting for Cooperative Perception in V2V  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianjun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Payton%2C+R">Ryan Payton</a>, 
<a href="/search/cs?searchtype=author&query=Riley%2C+M">Michael Riley</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang-Hua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Intelligent Vehicles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Perception of the driving environment is critical for collision avoidance and
route planning to ensure driving safety. Cooperative perception has been widely
studied as an effective approach to addressing the shortcomings of
single-vehicle perception. However, the practical limitations of
vehicle-to-vehicle (V2V) communications have not been adequately investigated.
In particular, current cooperative fusion models rely on supervised models and
do not address dynamic performance degradation caused by arbitrary channel
impairments. In this paper, a self-supervised adaptive weighting model is
proposed for intermediate fusion to mitigate the adverse effects of channel
distortion. The performance of cooperative perception is investigated in
different system settings. Rician fading and imperfect channel state
information (CSI) are also considered. Numerical results demonstrate that the
proposed adaptive weighting algorithm significantly outperforms the benchmarks
without weighting. Visualization examples validate that the proposed weighting
algorithm can flexibly adapt to various channel conditions. Moreover, the
adaptive weighting algorithm demonstrates good generalization to untrained
channels and test datasets from different domains.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10344" title="Abstract">arXiv:2312.10344</a> [<a href="/pdf/2312.10344" title="Download PDF">pdf</a>, <a href="/format/2312.10344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Passive and Active EMF Exposure in Large-Scale Cellular  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Elzanaty%2C+A">Ahmed Elzanaty</a>, 
<a href="/search/cs?searchtype=author&query=Chiaraviglio%2C+L">Luca Chiaraviglio</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">With the development of fifth-generation (5G) networks, the number of user
equipments (UE) increases dramatically. However, the potential health risks
from electromagnetic fields (EMF) tend to be a public concern. Generally, EMF
exposure-related analysis mainly considers the passive exposure from base
stations (BSs) and active exposure that results from the user's personal
devices while communicating. However, the passive radiation that is generated
by nearby devices of other users is typically ignored. In fact, with the
increase in the density of UE, their passive exposure to human bodies can no
longer be ignored. In this work, we propose a stochastic geometry framework to
analyze the EMF exposure from active and passive radiation sources. In
particular, considering a typical user, we account for their exposure to EMF
from BSs, their own UE, and other UE. We derive the distribution of the
Exposure index (EI) and the coverage probability for two typical models for
spatial distributions of UE, i.e., \textit{i)} a Poisson point process (PPP);
\textit{ii)} a Matern cluster process. Also, we show the trade-off between the
EMF exposure and the coverage probability. Our numerical results suggest that
the passive exposure from other users is non-negligible compared to the
exposure from BSs when user density is $10^2$ times higher than BS density, and
non-negligible compared to active exposure from the user's own UE when user
density is $10^5$ times the BS density.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10346" title="Abstract">arXiv:2312.10346</a> [<a href="/pdf/2312.10346" title="Download PDF">pdf</a>, <a href="/format/2312.10346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMBaT: A Multi-task Framework for mmWave-based Human Body Reconstruction  and Translation Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiarui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Songpengcheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Ling Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted by IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human body reconstruction with Millimeter Wave (mmWave) radar point clouds
has gained significant interest due to its ability to work in adverse
environments and its capacity to mitigate privacy concerns associated with
traditional camera-based solutions. Despite pioneering efforts in this field,
two challenges persist. Firstly, raw point clouds contain massive noise points,
usually caused by the ambient objects and multi-path effects of Radio Frequency
(RF) signals. Recent approaches typically rely on prior knowledge or elaborate
preprocessing methods, limiting their applicability. Secondly, even after noise
removal, the sparse and inconsistent body-related points pose an obstacle to
accurate human body reconstruction. To address these challenges, we introduce
mmBaT, a novel multi-task deep learning framework that concurrently estimates
the human body and predicts body translations in subsequent frames to extract
body-related point clouds. Our method is evaluated on two public datasets that
are collected with different radar devices and noise levels. A comprehensive
comparison against other state-of-the-art methods demonstrates our method has a
superior reconstruction performance and generalization ability from noisy raw
data, even when compared to methods provided with body-related point clouds.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10349" title="Abstract">arXiv:2312.10349</a> [<a href="/pdf/2312.10349" title="Download PDF">pdf</a>, <a href="/format/2312.10349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Large Language Models for Code Documentation  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvivedi%2C+S+S">Shubhang Shekhar Dvivedi</a>, 
<a href="/search/cs?searchtype=author&query=Vijay%2C+V">Vyshnav Vijay</a>, 
<a href="/search/cs?searchtype=author&query=Pujari%2C+S+L+R">Sai Leela Rahul Pujari</a>, 
<a href="/search/cs?searchtype=author&query=Lodh%2C+S">Shoumik Lodh</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a comprehensive comparative analysis of Large Language
Models (LLMs) for generation of code documentation. Code documentation is an
essential part of the software writing process. The paper evaluates models such
as GPT-3.5, GPT-4, Bard, Llama2, and Starchat on various parameters like
Accuracy, Completeness, Relevance, Understandability, Readability and Time
Taken for different levels of code documentation. Our evaluation employs a
checklist-based system to minimize subjectivity, providing a more objective
assessment. We find that, barring Starchat, all LLMs consistently outperform
the original documentation. Notably, closed-source models GPT-3.5, GPT-4, and
Bard exhibit superior performance across various parameters compared to
open-source/source-available LLMs, namely LLama 2 and StarChat. Considering the
time taken for generation, GPT-4 demonstrated the longest duration, followed by
Llama2, Bard, with ChatGPT and Starchat having comparable generation times.
Additionally, file level documentation had a considerably worse performance
across all parameters (except for time taken) as compared to inline and
function level documentation.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10351" title="Abstract">arXiv:2312.10351</a> [<a href="/pdf/2312.10351" title="Download PDF">pdf</a>, <a href="/format/2312.10351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opara: Exploiting Operator Parallelism for Expediting DNN Inference on  GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aodong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Li Han</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">GPUs have become the defacto hardware devices to accelerate Deep Neural
Network (DNN) inference in deep learning(DL) frameworks. However, the
conventional sequential execution mode of DNN operators in mainstream DL
frameworks cannot fully utilize GPU resources, due to the increasing complexity
of DNN model structures and the progressively smaller computational sizes of
DNN operators. Moreover, the inadequate operator launch order in parallelized
execution scenarios can lead to GPU resource wastage and unexpected performance
interference among operators. To address such performance issues above, we
propose Opara, a resource- and interference-aware DNN Operator parallel
scheduling framework to accelerate the execution of DNN inference on GPUs.
Specifically, Opara first employs CUDA Streams and CUDA Graph to automatically
parallelize the execution of multiple DNN operators. It further leverages the
resource demands of DNN operators to judiciously adjust the operator launch
order on GPUs by overlapping the execution of compute-intensive and
memory-intensive operators, so as to expedite DNN inference. We implement and
open source a prototype of Opara based on PyTorch in a non-intrusive manner.
Extensive prototype experiments with representative DNN and Transformer-based
models demonstrate that Opara outperforms the default sequential CUDA Graph in
PyTorch and the state-of-the-art DNN operator parallelism systems by up to
1.68$\times$ and 1.29$\times$, respectively, yet with acceptable runtime
overhead.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10355" title="Abstract">arXiv:2312.10355</a> [<a href="/pdf/2312.10355" title="Download PDF">pdf</a>, <a href="/format/2312.10355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoAScore: Chain-of-Aspects Prompting for NLG Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+P">Peiyuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiaxin Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, natural language generation (NLG) evaluation has shifted from a
single-aspect to a multi-aspect paradigm, allowing for a more accurate
assessment. Large language models (LLMs) achieve superior performance on
various NLG evaluation tasks. However, current work often employs the LLM to
independently evaluate different aspects, which largely ignores the rich
correlation between various aspects. To fill this research gap, in this work,
we propose an NLG evaluation metric called CoAScore. Powered by LLMs, the
CoAScore utilizes multi-aspect knowledge through a CoA
(\textbf{C}hain-\textbf{o}f-\textbf{A}spects) prompting framework when
assessing the quality of a certain aspect. Specifically, for a given aspect to
evaluate, we first prompt the LLM to generate a chain of aspects that are
relevant to the target aspect and could be useful for the evaluation. We then
collect evaluation scores for each generated aspect, and finally, leverage the
knowledge of these aspects to improve the evaluation of the target aspect. We
evaluate CoAScore across five NLG evaluation tasks (e.g., summarization, dialog
response generation, etc) and nine aspects (e.g., overall quality, relevance,
coherence, etc). Our experimental findings highlight that, in comparison to
individual aspect evaluation, CoAScore exhibits a higher correlation with human
judgments. This improvement significantly outperforms existing unsupervised
evaluation metrics, whether for assessing overall quality or other aspects. We
also conducted extensive ablation studies to validate the effectiveness of the
three stages within the CoAScore framework and conducted case studies to show
how the LLM performs in these stages. Our code and scripts are available.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10356" title="Abstract">arXiv:2312.10356</a> [<a href="/pdf/2312.10356" title="Download PDF">pdf</a>, <a href="/format/2312.10356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Asynchronous Traffic Scheduling in Converged 5G and  Time-Sensitive Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zonghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K+G">Kang G. Shin</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As required by Industry 4.0, companies will move towards flexible and
individual manufacturing. To succeed in this transition, convergence of 5G and
time-sensitive networks (TSN) is the most promising technology and has thus
attracted considerable interest from industry and standardization groups.
However, the delay and jitter of end-to-end (e2e) transmission will get
exacerbated if the transmission opportunities are missed in TSN due to the 5G
transmission jitter and the clock skew between the two network systems. To
mitigate this phenomenon, we propose a novel asynchronous access mechanism
(AAM) that isolates the jitter only in the 5G system and ensures zero
transmission jitter in TSN. We then exploit AAM to develop an e2e asynchronous
traffic scheduling model for coordinated allocation of resources for 5G and TSN
to provide e2e transmission delay guarantees for time-critical flows. The
results of our extensive simulation of AAM on OMNET++ corroborate the superior
performance of AAM and the scheduling model.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10358" title="Abstract">arXiv:2312.10358</a> [<a href="/pdf/2312.10358" title="Download PDF">pdf</a>, <a href="/format/2312.10358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONCSS: Contrastive-based Context Comprehension for Dialogue-appropriate  Prosody in Conversational Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yayue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jinlong Xue</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yukang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yichen Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fengping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yingming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+D">Dengfeng Ke</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ya Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 3 tables, Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Conversational speech synthesis (CSS) incorporates historical dialogue as
supplementary information with the aim of generating speech that has
dialogue-appropriate prosody. While previous methods have already delved into
enhancing context comprehension, context representation still lacks effective
representation capabilities and context-sensitive discriminability. In this
paper, we introduce a contrastive learning-based CSS framework, CONCSS. Within
this framework, we define an innovative pretext task specific to CSS that
enables the model to perform self-supervised learning on unlabeled
conversational datasets to boost the model's context understanding.
Additionally, we introduce a sampling strategy for negative sample augmentation
to enhance context vectors' discriminability. This is the first attempt to
integrate contrastive learning into CSS. We conduct ablation studies on
different contrastive learning strategies and comprehensive experiments in
comparison with prior CSS systems. Results demonstrate that the synthesized
speech from our proposed method exhibits more contextually appropriate and
sensitive prosody.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10359" title="Abstract">arXiv:2312.10359</a> [<a href="/pdf/2312.10359" title="Download PDF">pdf</a>, <a href="/format/2312.10359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformer-Based Speech Recognition On Extreme Edge-Computing Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+A">Alex Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+M">Mu Su</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+T">Tim Ng</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+H">Henry Mason</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shiyi Han</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yaqiao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+M">Mahesh Krishnamoorthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">With increasingly more powerful compute capabilities and resources in today's
devices, traditionally compute-intensive automatic speech recognition (ASR) has
been moving from the cloud to devices to better protect user privacy. However,
it is still challenging to implement on-device ASR on resource-constrained
devices, such as smartphones, smart wearables, and other small home automation
devices. In this paper, we propose a series of model architecture adaptions,
neural network graph transformations, and numerical optimizations to fit an
advanced Conformer based end-to-end streaming ASR system on
resource-constrained devices without accuracy degradation. We achieve over 5.26
times faster than realtime (0.19 RTF) speech recognition on small wearables
while minimizing energy consumption and achieving state-of-the-art accuracy.
The proposed methods are widely applicable to other transformer-based
server-free AI applications. In addition, we provide a complete theory on
optimal pre-normalizers that numerically stabilize layer normalization in any
Lp-norm using any floating point precision.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10360" title="Abstract">arXiv:2312.10360</a> [<a href="/pdf/2312.10360" title="Download PDF">pdf</a>, <a href="/format/2312.10360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Data Access Load in Distributed Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktas%2C+M">Mehmet Aktas</a>, 
<a href="/search/cs?searchtype=author&query=Soljanin%2C+E">Emina Soljanin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Transactions on Networking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Distributed systems store data objects redundantly to balance the data access
load over multiple nodes. Load balancing performance depends mainly on 1) the
level of storage redundancy and 2) the assignment of data objects to storage
nodes. We analyze the performance implications of these design choices by
considering four practical storage schemes that we refer to as clustering,
cyclic, block and random design. We formulate the problem of load balancing as
maintaining the load on any node below a given threshold. Regarding the level
of redundancy, we find that the desired load balance can be achieved in a
system of $n$ nodes only if the replication factor $d = \Omega(\log(n)^{1/3})$,
which is a necessary condition for any storage design. For clustering and
cyclic designs, $d = \Omega(\log(n))$ is necessary and sufficient. For block
and random designs, $d = \Omega(\log(n))$ is sufficient but unnecessary.
Whether $d = \Omega(\log(n)^{1/3})$ is sufficient remains open. The assignment
of objects to nodes essentially determines which objects share the access
capacity on each node. We refer to the number of nodes jointly shared by a set
of objects as the \emph{overlap} between those objects. We find that many
consistently slight overlaps between the objects (block, random) are better
than few but occasionally significant overlaps (clustering, cyclic). However,
when the demand is ''skewed beyond a level'' the impact of overlaps becomes the
opposite. We derive our results by connecting the load-balancing problem to
mathematical constructs that have been used to study other problems. For a
class of storage designs containing the clustering and cyclic design, we
express load balance in terms of the maximum of moving sums of i.i.d. random
variables, which is known as the scan statistic. For random design, we express
load balance by using the occupancy metric for random allocation with
complexes.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10361" title="Abstract">arXiv:2312.10361</a> [<a href="/pdf/2312.10361" title="Download PDF">pdf</a>, <a href="/format/2312.10361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring UMAP in hybrid models of entropy-based and representativeness  sampling for active learning in biomedical segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+H+S">H. S. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuancheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mcbeth%2C+R">Rafe Mcbeth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Medical Physics (physics.med-ph)

</div>
<p class="mathjax">In this work, we study various hybrid models of entropy-based and
representativeness sampling techniques in the context of active learning in
medical segmentation, in particular examining the role of UMAP (Uniform
Manifold Approximation and Projection) as a technique for capturing
representativeness. Although UMAP has been shown viable as a general purpose
dimension reduction method in diverse areas, its role in deep learning-based
medical segmentation has yet been extensively explored. Using the cardiac and
prostate datasets in the Medical Segmentation Decathlon for validation, we
found that a novel hybrid combination of Entropy-UMAP sampling technique
achieved a statistically significant Dice score advantage over the random
baseline ($3.2 \%$ for cardiac, $4.5 \%$ for prostate), and attained the
highest Dice coefficient among the spectrum of 10 distinct active learning
methodologies we examined. This provides preliminary evidence that there is an
interesting synergy between entropy-based and UMAP methods when the former
precedes the latter in a hybrid model of active learning.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10365" title="Abstract">arXiv:2312.10365</a> [<a href="/pdf/2312.10365" title="Download PDF">pdf</a>, <a href="/format/2312.10365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPT: Fine-Tuning Transformer-based Language Models Efficiently with  Sparsification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+Y">Yuntao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Peiqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Han Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">James Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Firstly submitted to VLDB November 1, 2023, rejection received on December 15, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer-based large language models (e.g., BERT and GPT) achieve great
success, and fine-tuning, which tunes a pre-trained model on a task-specific
dataset, is the standard practice to utilize these models for downstream tasks.
However, Transformer fine-tuning has long running time and high memory
consumption due to the large size of the models. We propose the SPT system to
fine-tune Transformer-based models efficiently by introducing sparsity. We
observe that the memory consumption of Transformer mainly comes from storing
attention weights for multi-head attention (MHA), and the majority of running
time is spent on feed-forward network (FFN). Thus, we design the sparse MHA
module, which computes and stores only large attention weights to reduce memory
consumption, and the routed FFN module, which dynamically activates a subset of
model parameters for each token to reduce computation cost. We implement SPT on
PyTorch and customize CUDA kernels to run sparse MHA and routed FFN
efficiently. Specifically, we use product quantization to identify the large
attention weights and compute attention via sparse matrix multiplication for
sparse MHA. For routed FFN, we batch the tokens according to their activated
model parameters for efficient computation. We conduct extensive experiments to
evaluate SPT on various model configurations. The results show that SPT
consistently outperforms well-optimized baselines, reducing the peak memory
consumption by up to 50% and accelerating fine-tuning by up to 2.2x.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10366" title="Abstract">arXiv:2312.10366</a> [<a href="/pdf/2312.10366" title="Download PDF">pdf</a>, <a href="/format/2312.10366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing Conditional Submodular GAN and Programmatic Weak Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shubham%2C+K">Kumar Shubham</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+P">Pranav Sastry</a>, 
<a href="/search/cs?searchtype=author&query=AP%2C+P">Prathosh AP</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Programmatic Weak Supervision (PWS) and generative models serve as crucial
tools that enable researchers to maximize the utility of existing datasets
without resorting to laborious data gathering and manual annotation processes.
PWS uses various weak supervision techniques to estimate the underlying class
labels of data, while generative models primarily concentrate on sampling from
the underlying distribution of the given dataset. Although these methods have
the potential to complement each other, they have mostly been studied
independently. Recently, WSGAN proposed a mechanism to fuse these two models.
Their approach utilizes the discrete latent factors of InfoGAN to train the
label model and leverages the class-dependent information of the label model to
generate images of specific classes. However, the disentangled latent factors
learned by InfoGAN might not necessarily be class-specific and could
potentially affect the label model's accuracy. Moreover, prediction made by the
label model is often noisy in nature and can have a detrimental impact on the
quality of images generated by GAN. In our work, we address these challenges by
(i) implementing a noise-aware classifier using the pseudo labels generated by
the label model (ii) utilizing the noise-aware classifier's prediction to train
the label model and generate class-conditional images. Additionally, we also
investigate the effect of training the classifier with a subset of the dataset
within a defined uncertainty budget on pseudo labels. We accomplish this by
formalizing the subset selection problem as a submodular maximization objective
with a knapsack constraint on the entropy of pseudo labels. We conduct
experiments on multiple datasets and demonstrate the efficacy of our methods on
several tasks vis-a-vis the current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10369" title="Abstract">arXiv:2312.10369</a> [<a href="/pdf/2312.10369" title="Download PDF">pdf</a>, <a href="/format/2312.10369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proportional Representation in Metric Spaces and Low-Distortion  Committee Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalayci%2C+Y+H">Yusuf Hakan Kalayci</a>, 
<a href="/search/cs?searchtype=author&query=Kempe%2C+D">David Kempe</a>, 
<a href="/search/cs?searchtype=author&query=Kher%2C+V">Vikram Kher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a novel definition for a small set R of k points being
"representative" of a larger set in a metric space. Given a set V (e.g.,
documents or voters) to represent, and a set C of possible representatives, our
criterion requires that for any subset S comprising a theta fraction of V, the
average distance of S to their best theta*k points in R should not be more than
a factor gamma compared to their average distance to the best theta*k points
among all of C. This definition is a strengthening of proportional fairness and
core fairness, but - different from those notions - requires that large
cohesive clusters be represented proportionally to their size.
<br />Since there are instances for which - unless gamma is polynomially large - no
solutions exist, we study this notion in a resource augmentation framework,
implicitly stating the constraints for a set R of size k as though its size
were only k/alpha, for alpha &gt; 1. Furthermore, motivated by the application to
elections, we mostly focus on the "ordinal" model, where the algorithm does not
learn the actual distances; instead, it learns only for each point v in V and
each candidate pairs c, c' which of c, c' is closer to v. Our main result is
that the Expanding Approvals Rule (EAR) of Aziz and Lee is (alpha, gamma)
representative with gamma &lt;= 1 + 6.71 * (alpha)/(alpha-1).
<br />Our results lead to three notable byproducts. First, we show that the EAR
achieves constant proportional fairness in the ordinal model, giving the first
positive result on metric proportional fairness with ordinal information.
Second, we show that for the core fairness objective, the EAR achieves the same
asymptotic tradeoff between resource augmentation and approximation as the
recent results of Li et al., which used full knowledge of the metric. Finally,
our results imply a very simple single-winner voting rule with metric
distortion at most 44.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10370" title="Abstract">arXiv:2312.10370</a> [<a href="/pdf/2312.10370" title="Download PDF">pdf</a>, <a href="/format/2312.10370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Similar Entities have Similar Embeddings?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubert%2C+N">Nicolas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Paulheim%2C+H">Heiko Paulheim</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+A">Armelle Brun</a>, 
<a href="/search/cs?searchtype=author&query=Monticolo%2C+D">Davy Monticolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge graph embedding models (KGEMs) developed for link prediction learn
vector representations for graph entities, known as embeddings. A common tacit
assumption is the KGE entity similarity assumption, which states that these
KGEMs retain the graph's structure within their embedding space, i.e., position
similar entities close to one another. This desirable property make KGEMs
widely used in downstream tasks such as recommender systems or drug
repurposing. Yet, the alignment of graph similarity with embedding space
similarity has rarely been formally evaluated. Typically, KGEMs are assessed
based on their sole link prediction capabilities, using ranked-based metrics
such as Hits@K or Mean Rank. This paper challenges the prevailing assumption
that entity similarity in the graph is inherently mirrored in the embedding
space. Therefore, we conduct extensive experiments to measure the capability of
KGEMs to cluster similar entities together, and investigate the nature of the
underlying factors. Moreover, we study if different KGEMs expose a different
notion of similarity. Datasets, pre-trained embeddings and code are available
at: https://github.com/nicolas-hbt/similar-embeddings.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10371" title="Abstract">arXiv:2312.10371</a> [<a href="/pdf/2312.10371" title="Download PDF">pdf</a>, <a href="/format/2312.10371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-ESConv: Knowledge Injection for Emotional Support Dialogue Systems via  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Gang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic psychological counseling requires mass of professional knowledge
that can be found in online counseling forums. Motivated by this, we propose
K-ESConv, a novel prompt learning based knowledge injection method for
emotional support dialogue system, transferring forum knowledge to response
generation. We evaluate our model on an emotional support dataset ESConv, where
the model retrieves and incorporates knowledge from external professional
emotional Q\&amp;A forum. Experiment results show that the proposed method
outperforms existing baselines on both automatic evaluation and human
evaluation, which shows that our approach significantly improves the
correlation and diversity of responses and provides more comfort and better
suggestion for the seeker.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10372" title="Abstract">arXiv:2312.10372</a> [<a href="/pdf/2312.10372" title="Download PDF">pdf</a>, <a href="/format/2312.10372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Graph Data Meets Multimodal: A New Paradigm for Graph Understanding  and Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qihang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianwu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Graph data is ubiquitous in the physical world, and it has always been a
challenge to efficiently model graph structures using a unified paradigm for
the understanding and reasoning on various graphs. Moreover, in the era of
large language models, integrating complex graph information into text
sequences has become exceptionally difficult, which hinders the ability to
interact with graph data through natural language instructions.The paper
presents a new paradigm for understanding and reasoning about graph data by
integrating image encoding and multimodal technologies. This approach enables
the comprehension of graph data through an instruction-response format,
utilizing GPT-4V's advanced capabilities. The study evaluates this paradigm on
various graph types, highlighting the model's strengths and weaknesses,
particularly in Chinese OCR performance and complex reasoning tasks. The
findings suggest new direction for enhancing graph data processing and natural
language interaction.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10373" title="Abstract">arXiv:2312.10373</a> [<a href="/pdf/2312.10373" title="Download PDF">pdf</a>, <a href="/format/2312.10373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm of Robotic Aerial Base Stations for mmWave Multi-Hop Backhauling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liao%2C+Y">Yuan Liao</a>, 
<a href="/search/eess?searchtype=author&query=Friderikos%2C+V">Vasilis Friderikos</a>, 
<a href="/search/eess?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Wireless Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Robotic aerial base stations (RABSs) that are able to anchor at tall urban
landforms are expected to bring further flexibility to millimeter-wave (mmWave)
multi-hop backhaul networks in highly dense urban environments. In this paper,
a swarm of RABSs are deployed to construct a dynamic mmWave backhaul network
according to the traffic spatial distribution, and relocate their positions in
subsequent time epochs according to the traffic temporal dynamic. The overall
energy efficiency of the proposed framework is maximized by determining the
RABS deployment, relocation and route formation under the channel capacity and
hop constraints. The problem is formulated as a mixed-integer linear fractional
programming (MILFP) and a two-stage method is developed to overcome the
computational complexity. A wide set of numerical investigations reveal that
compared to fixed small cells, only half as many RABSs are required to cover
the same volume of traffic demand.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10374" title="Abstract">arXiv:2312.10374</a> [<a href="/pdf/2312.10374" title="Download PDF">pdf</a>, <a href="/format/2312.10374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Operators for Boundary Stabilization of Stop-and-go Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ruiguo Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces a novel approach to PDE boundary control design using
neural operators to alleviate stop-and-go instabilities in congested traffic
flow. Our framework leverages neural operators to design control strategies for
traffic flow systems. The traffic dynamics are described by the Aw-Rascle-Zhang
(ARZ) model, which comprises a set of second-order coupled hyperbolic partial
differential equations (PDEs). Backstepping method is widely used for boundary
control of such PDE systems. The PDE model-based control design can be
time-consuming and require intensive depth of expertise since it involves
constructing and solving backstepping control kernels. To overcome these
challenges, we present two distinct neural operator (NO) learning schemes aimed
at stabilizing the traffic PDE system. The first scheme embeds NO-approximated
gain kernels within a predefined backstepping controller, while the second one
directly learns a boundary control law. The Lyapunov analysis is conducted to
evaluate the stability of the NO-approximated gain kernels and control law. It
is proved that the NO-based closed-loop system is practical stable under
certain approximation accuracy conditions in NO-learning. To validate the
efficacy of the proposed approach, simulations are conducted to compare the
performance of the two neural operator controllers with a PDE backstepping
controller and a Proportional Integral (PI) controller. While the
NO-approximated methods exhibit higher errors compared to the backstepping
controller, they consistently outperform the PI controller, demonstrating
faster computation speeds across all scenarios. This result suggests that
neural operators can significantly expedite and simplify the process of
obtaining boundary controllers in traffic PDE systems.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10375" title="Abstract">arXiv:2312.10375</a> [<a href="/pdf/2312.10375" title="Download PDF">pdf</a>, <a href="/ps/2312.10375" title="Download PostScript">ps</a>, <a href="/format/2312.10375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collect and Connect Data Leaves to Feature Concepts: Interactive Graph  Generation Toward Well-being
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohsawa%2C+Y">Yukio Ohsawa</a>, 
<a href="/search/cs?searchtype=author&query=Maekawa%2C+T">Tomohide Maekawa</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+H">Hiroki Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+H">Hiro Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Sekiguchi%2C+K">Kaira Sekiguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB)

</div>
<p class="mathjax">Feature concepts and data leaves have been invented using datasets to foster
creative thoughts for creating well-being in daily life. The idea, simply put,
is to attach selected and collected data leaves that are summaries of event
flows to be discovered from corresponding datasets, on the target feature
concept representing the well-being aimed. A graph of existing or expected
datasets to be attached to a feature concept is generated semi-automatically.
Rather than sheer automated generative AI, our work addresses the process of
generative artificial and natural intelligence to create the basis for data use
and reuse.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10376" title="Abstract">arXiv:2312.10376</a> [<a href="/pdf/2312.10376" title="Download PDF">pdf</a>, <a href="/format/2312.10376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA$^2$VP: Spatially Aligned-and-Adapted Visual Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+W">Wenjie Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tongqi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fanglin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As a prominent parameter-efficient fine-tuning technique in NLP, prompt
tuning is being explored its potential in computer vision. Typical methods for
visual prompt tuning follow the sequential modeling paradigm stemming from NLP,
which represents an input image as a flattened sequence of token embeddings and
then learns a set of unordered parameterized tokens prefixed to the sequence
representation as the visual prompts for task adaptation of large vision
models. While such sequential modeling paradigm of visual prompt has shown
great promise, there are two potential limitations. First, the learned visual
prompts cannot model the underlying spatial relations in the input image, which
is crucial for image encoding. Second, since all prompt tokens play the same
role of prompting for all image tokens without distinction, it lacks the
fine-grained prompting capability, i.e., individual prompting for different
image tokens. In this work, we propose the \mymodel model (\emph{SA$^2$VP}),
which learns a two-dimensional prompt token map with equal (or scaled) size to
the image token map, thereby being able to spatially align with the image map.
Each prompt token is designated to prompt knowledge only for the spatially
corresponding image tokens. As a result, our model can conduct individual
prompting for different image tokens in a fine-grained manner. Moreover,
benefiting from the capability of preserving the spatial structure by the
learned prompt token map, our \emph{SA$^2$VP} is able to model the spatial
relations in the input image, leading to more effective prompting. Extensive
experiments on three challenging benchmarks for image classification
demonstrate the superiority of our model over other state-of-the-art methods
for visual prompt tuning. Code is available at
\emph{https://github.com/tommy-xq/SA2VP}.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10380" title="Abstract">arXiv:2312.10380</a> [<a href="/pdf/2312.10380" title="Download PDF">pdf</a>, <a href="/format/2312.10380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPIDSG: A Privacy-Preserving Image Distribution Sharing Scheme with GAN  in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuting Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuanzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohua Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) has attracted growing attention since it allows for
privacy-preserving collaborative training on decentralized clients without
explicitly uploading sensitive data to the central server. However, recent
works have revealed that it still has the risk of exposing private data to
adversaries. In this paper, we conduct reconstruction attacks and enhance
inference attacks on various datasets to better understand that sharing trained
classification model parameters to a central server is the main problem of
privacy leakage in FL. To tackle this problem, a privacy-preserving image
distribution sharing scheme with GAN (PPIDSG) is proposed, which consists of a
block scrambling-based encryption algorithm, an image distribution sharing
method, and local classification training. Specifically, our method can capture
the distribution of a target image domain which is transformed by the block
encryption algorithm, and upload generator parameters to avoid classifier
sharing with negligible influence on model performance. Furthermore, we apply a
feature extractor to motivate model utility and train it separately from the
classifier. The extensive experimental results and security analyses
demonstrate the superiority of our proposed scheme compared to other
state-of-the-art defense methods. The code is available at
https://github.com/ytingma/PPIDSG.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10381" title="Abstract">arXiv:2312.10381</a> [<a href="/pdf/2312.10381" title="Download PDF">pdf</a>, <a href="/format/2312.10381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SECap: Speech Emotion Captioning with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yaoxun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiaochu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shixiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Rongzhi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech emotions are crucial in human communication and are extensively used
in fields like speech synthesis and natural language understanding. Most prior
studies, such as speech emotion recognition, have categorized speech emotions
into a fixed set of classes. Yet, emotions expressed in human speech are often
complex, and categorizing them into predefined groups can be insufficient to
adequately represent speech emotions. On the contrary, describing speech
emotions directly by means of natural language may be a more effective
approach. Regrettably, there are not many studies available that have focused
on this direction. Therefore, this paper proposes a speech emotion captioning
framework named SECap, aimed at effectively describing speech emotions using
natural language. Owing to the impressive capabilities of large language models
in language comprehension and text generation, SECap employs LLAMA as the text
decoder to allow the production of coherent speech emotion captions. In
addition, SECap leverages HuBERT as the audio encoder to extract general speech
features and Q-Former as the Bridge-Net to provide LLAMA with emotion-related
speech features. To accomplish this, Q-Former utilizes mutual information
learning to disentangle emotion-related speech features and speech contents,
while implementing contrastive learning to extract more emotion-related speech
features. The results of objective and subjective evaluations demonstrate that:
1) the SECap framework outperforms the HTSAT-BART baseline in all objective
evaluations; 2) SECap can generate high-quality speech emotion captions that
attain performance on par with human annotators in subjective mean opinion
score tests.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10383" title="Abstract">arXiv:2312.10383</a> [<a href="/pdf/2312.10383" title="Download PDF">pdf</a>, <a href="/format/2312.10383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian experimental design for head imaging by electrical impedance  tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hyv%C3%B6nen%2C+N">N. Hyv&#xf6;nen</a>, 
<a href="/search/math?searchtype=author&query=J%C3%A4%C3%A4skel%C3%A4inen%2C+A">A. J&#xe4;&#xe4;skel&#xe4;inen</a>, 
<a href="/search/math?searchtype=author&query=Maity%2C+R">R. Maity</a>, 
<a href="/search/math?searchtype=author&query=Vavilov%2C+A">A. Vavilov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">This work considers the optimization of electrode positions in head imaging
by electrical impedance tomography. The study is motivated by maximizing the
sensitivity of electrode measurements to conductivity changes when monitoring
the condition of a stroke patient, which justifies adopting a linearized
version of the complete electrode model as the forward model. The algorithm is
based on finding a (locally) A-optimal measurement configuration via gradient
descent with respect to the electrode positions. The efficient computation of
the needed derivatives of the complete electrode model is one of the focal
points. Two algorithms are introduced and numerically tested on a three-layer
head model. The first one assumes a region of interest and a Gaussian prior for
the conductivity in the brain, and it can be run offline, i.e., prior to taking
any measurements. The second algorithm first computes a reconstruction of the
conductivity anomaly caused by the stroke with an initial electrode
configuration by combining lagged diffusivity iteration with sequential
linearizations, which can be interpreted to produce an approximate Gaussian
probability density for the conductivity perturbation. It then resorts to the
first algorithm to find new, more informative positions for the available
electrodes with the constructed density as the prior.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10385" title="Abstract">arXiv:2312.10385</a> [<a href="/pdf/2312.10385" title="Download PDF">pdf</a>, <a href="/format/2312.10385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitate the Good and Avoid the Bad: An Incremental Approach to Safe  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+H">Huy Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+T+M+P">Tien Mai Pradeep Varakantham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A popular framework for enforcing safe actions in Reinforcement Learning (RL)
is Constrained RL, where trajectory based constraints on expected cost (or
other cost measures) are employed to enforce safety and more importantly these
constraints are enforced while maximizing expected reward. Most recent
approaches for solving Constrained RL convert the trajectory based cost
constraint into a surrogate problem that can be solved using minor
modifications to RL methods. A key drawback with such approaches is an over or
underestimation of the cost constraint at each state. Therefore, we provide an
approach that does not modify the trajectory based cost constraint and instead
imitates ``good'' trajectories and avoids ``bad'' trajectories generated from
incrementally improving policies. We employ an oracle that utilizes a reward
threshold (which is varied with learning) and the overall cost constraint to
label trajectories as ``good'' or ``bad''. A key advantage of our approach is
that we are able to work from any starting policy or set of trajectories and
improve on it. In an exhaustive set of experiments, we demonstrate that our
approach is able to outperform top benchmark approaches for solving Constrained
RL problems, with respect to expected cost, CVaR cost, or even unknown cost
constraints.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10386" title="Abstract">arXiv:2312.10386</a> [<a href="/pdf/2312.10386" title="Download PDF">pdf</a>, <a href="/format/2312.10386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RedCore: Relative Advantage Aware Cross-modal Representation Learning  for Missing Modalities with Imbalanced Missing Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shoukang Han</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yu-ping Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multimodal learning is susceptible to modality missing, which poses a major
obstacle for its practical applications and, thus, invigorates increasing
research interest. In this paper, we investigate two challenging problems: 1)
when modality missing exists in the training data, how to exploit the
incomplete samples while guaranteeing that they are properly supervised? 2)
when the missing rates of different modalities vary, causing or exacerbating
the imbalance among modalities, how to address the imbalance and ensure all
modalities are well-trained? To tackle these two challenges, we first introduce
the variational information bottleneck (VIB) method for the cross-modal
representation learning of missing modalities, which capitalizes on the
available modalities and the labels as supervision. Then, accounting for the
imbalanced missing rates, we define relative advantage to quantify the
advantage of each modality over others. Accordingly, a bi-level optimization
problem is formulated to adaptively regulate the supervision of all modalities
during training. As a whole, the proposed approach features \textbf{Re}lative
a\textbf{d}vantage aware \textbf{C}ross-m\textbf{o}dal \textbf{r}epresentation
l\textbf{e}arning (abbreviated as \textbf{RedCore}) for missing modalities with
imbalanced missing rates. Extensive empirical results demonstrate that RedCore
outperforms competing models in that it exhibits superior robustness against
either large or imbalanced missing rates.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10387" title="Abstract">arXiv:2312.10387</a> [<a href="/pdf/2312.10387" title="Download PDF">pdf</a>, <a href="/format/2312.10387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Sense of Presence and Learning Efficacy in Immersive  Virtual Assembly Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weichao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+K">Kang Ran</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+A">Anlan Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the rapid progress in virtual reality (VR) technology, the scope of VR
applications has greatly expanded across various domains. However, the
superiority of VR training over traditional methods and its impact on learning
efficacy are still uncertain. To investigate whether VR training is more
effective than traditional methods, we designed virtual training systems for
mechanical assembly on both VR and desktop platforms, subsequently conducting
pre-test and post-test experiments. A cohort of 53 students, all enrolled in
engineering drawing course without prior knowledge distinctions, was randomly
divided into three groups: physical training, desktop virtual training, and
immersive VR training. Our investigation utilized analysis of covariance
(ANCOVA) to examine the differences in post-test scores among the three groups
while controlling for pre-test scores. The group that received VR training
showed the highest scores on the post-test. Another facet of our study delved
into the presence of the virtual system. We developed a specialized scale to
assess this aspect for our research objectives. Our findings indicate that VR
training can enhance the sense of presence, particularly in terms of sensory
factors and realism factors. Moreover, correlation analysis uncovers
connections between the various dimensions of presence. This study confirms
that using VR training can improve learning efficacy and the presence in the
context of mechanical assembly, surpassing traditional training methods.
Furthermore, it provides empirical evidence supporting the integration of VR
technology in higher education and engineering training. This serves as a
reference for the practical application of VR technology in different fields.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10389" title="Abstract">arXiv:2312.10389</a> [<a href="/pdf/2312.10389" title="Download PDF">pdf</a>, <a href="/format/2312.10389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ElasticLaneNet: A Geometry-Flexible Approach for Lane Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yaxin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yuan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luchan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of lane detection involves identifying the boundaries of driving
areas. Recognizing lanes with complex and variable geometric structures remains
a challenge. In this paper, we introduce a new lane detection framework named
ElasticLaneNet (Elastic-interaction-energy guided Lane detection Network). A
novel and flexible way of representing lanes, namely, implicit representation
is proposed. The training strategy considers predicted lanes as moving curves
that being attracted to the ground truth guided by an elastic interaction
energy based loss function (EIE loss). An auxiliary feature refinement (AFR)
module is designed to gather information from different layers. The method
performs well in complex lane scenarios, including those with large curvature,
weak geometric features at intersections, complicated cross lanes, Y-shapes
lanes, dense lanes, etc. We apply our approach on three datasets: SDLane,
CULane, and TuSimple. The results demonstrate the exceptional performance of
our method, with the state-of-the-art results on the structure-diversity
dataset SDLane, achieving F1-score of 89.51, Recall rate of 87.50, and
Precision of 91.61.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10390" title="Abstract">arXiv:2312.10390</a> [<a href="/pdf/2312.10390" title="Download PDF">pdf</a>, <a href="/format/2312.10390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not Every Side Is Equal: Localization Uncertainty Estimation for  Semi-Supervised 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">ChuXin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised 3D object detection from point cloud aims to train a detector
with a small number of labeled data and a large number of unlabeled data. The
core of existing methods lies in how to select high-quality pseudo-labels using
the designed quality evaluation criterion. However, these methods treat each
pseudo bounding box as a whole and assign equal importance to each side during
training, which is detrimental to model performance due to many sides having
poor localization quality. Besides, existing methods filter out a large number
of low-quality pseudo-labels, which also contain some correct regression values
that can help with model training. To address the above issues, we propose a
side-aware framework for semi-supervised 3D object detection consisting of
three key designs: a 3D bounding box parameterization method, an uncertainty
estimation module, and a pseudo-label selection strategy. These modules work
together to explicitly estimate the localization quality of each side and
assign different levels of importance during the training phase. Extensive
experiment results demonstrate that the proposed method can consistently
outperform baseline models under different scenes and evaluation criteria.
Moreover, our method achieves state-of-the-art performance on three datasets
with different labeled ratios.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10392" title="Abstract">arXiv:2312.10392</a> [<a href="/pdf/2312.10392" title="Download PDF">pdf</a>, <a href="/format/2312.10392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical approximation of discontinuous solutions of the semilinear  wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+J">Jiachuan Cao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+B">Buyang Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Y">Yanping Lin</a>, 
<a href="/search/math?searchtype=author&query=Yao%2C+F">Fangyan Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A fully discrete low-regularity integrator with high-frequency recovery
techniques is constructed to approximate rough and possibly discontinuous
solutions of the semilinear wave equation. The proposed method can capture the
discontinuities of the solutions correctly without spurious oscillations and
can approximate rough and discontinuous solutions with a higher convergence
rate than pre-existing methods. Rigorous analysis is presented for the
convergence rates of the proposed method in approximating solutions such that
$(u,\partial_{t}u)\in C([0,T];H^{\gamma}\times H^{\gamma-1})$ for
$\gamma\in(0,1]$. For discontinuous solutions of bounded variation in one
dimension (which allow jump discontinuities), the proposed method is proved to
have almost first-order convergence under the step size condition $\tau \sim
N^{-1}$, where $\tau$ and $N$ denote the time step size and the number of
Fourier terms in the space discretization, respectively. Extensive numerical
examples are presented in both one and two dimensions to illustrate the
advantages of the proposed method in improving the accuracy in approximating
rough and discontinuous solutions of the semilinear wave equation. The
numerical results are consistent with the theoretical results and show the
efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10393" title="Abstract">arXiv:2312.10393</a> [<a href="/pdf/2312.10393" title="Download PDF">pdf</a>, <a href="/format/2312.10393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lecture Notes in Probabilistic Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Str%C3%BCmke%2C+I">Inga Str&#xfc;mke</a>, 
<a href="/search/cs?searchtype=author&query=Langseth%2C+H">Helge Langseth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models are loosely modelled based on non-equilibrium
thermodynamics, where \textit{diffusion} refers to particles flowing from
high-concentration regions towards low-concentration regions. In statistics,
the meaning is quite similar, namely the process of transforming a complex
distribution $p_{\text{complex}}$ on $\mathbb{R}^d$ to a simple distribution
$p_{\text{prior}}$ on the same domain. This constitutes a Markov chain of
diffusion steps of slowly adding random noise to data, followed by a reverse
diffusion process in which the data is reconstructed from the noise. The
diffusion model learns the data manifold to which the original and thus the
reconstructed data samples belong, by training on a large number of data
points. While the diffusion process pushes a data sample off the data manifold,
the reverse process finds a trajectory back to the data manifold. Diffusion
models have -- unlike variational autoencoder and flow models -- latent
variables with the same dimensionality as the original data, and they are
currently\footnote{At the time of writing, 2023.} outperforming other
approaches -- including Generative Adversarial Networks (GANs) -- to modelling
the distribution of, e.g., natural images.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10394" title="Abstract">arXiv:2312.10394</a> [<a href="/pdf/2312.10394" title="Download PDF">pdf</a>, <a href="/ps/2312.10394" title="Download PostScript">ps</a>, <a href="/format/2312.10394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Far-field Beam Training Be Deployed for Cross-field Beam Alignment  in Terahertz UM-MIMO Communications?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+C+H+E">Chong Han Emil Bj&#xf6;rnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Ultra-massive multiple-input multiple-output (UM-MIMO) is the enabler of
Terahertz (THz) communications in next-generation wireless networks. In THz
UM-MIMO systems, a new paradigm of cross-field communications spanning from
near-field to far-field is emerging, since the near-field range expands with
higher frequencies and larger array apertures. Precise beam alignment in
cross-field is critical but challenging. Specifically, unlike far-field beams
that rely only on the angle domain, the incorporation of dual-domain (angle and
distance) training significantly increases overhead. A natural question arises
of whether far-field beam training can be deployed for cross-field beam
alignment. In this paper, this question is answered, by demonstrating that the
far-field training enables sufficient signal-to-noise ratio (SNR) in both far-
and near-field scenarios, while exciting all channel dimensions. Based on that,
we propose a subarray-coordinated hierarchical (SCH) training with greatly
reduced overhead. To further obtain high-precision beam designs, we propose a
two-phase angle and distance beam estimator (TPBE). Extensive simulations
demonstrate the effectiveness of the proposed methods. Compared to near-field
exhaustive search, the SCH possesses 0.2\% training overhead. The TPBE achieves
0.01~degrees and 0.02~m estimation root-mean-squared errors for angle and
distance. Furthermore, with the estimated beam directions, a near-optimal SNR
with 0.11~dB deviation is attained after beam alignment.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10395" title="Abstract">arXiv:2312.10395</a> [<a href="/pdf/2312.10395" title="Download PDF">pdf</a>, <a href="/ps/2312.10395" title="Download PostScript">ps</a>, <a href="/format/2312.10395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboPainter -- a conceptual towards robotized interior finishes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorour%2C+M">Mohamed Sorour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">High demand for painters is required nowadays and foreseen in the near future
for both developed and developing countries. To satisfy such demand, this paper
presents the detailed computer aided design (CAD) model of a fully functional
wall painting robot for interior finishes. The RoboPainter is capable of
performing full scale wall-ceil painting in addition to decorative wall
drawings. The 8 degrees of freedom (DOF) mobile robot structure consists of a
6DOF spray painting arm mounted on a 2DOF differentially driven mobile base.
The design presented endows several achievements in terms of total robot mass
and painting rate as compared to existing literature. Detailed dynamic model
parameters are presented to allow for further enhancement in terms of robot
motion control.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10396" title="Abstract">arXiv:2312.10396</a> [<a href="/pdf/2312.10396" title="Download PDF">pdf</a>, <a href="/ps/2312.10396" title="Download PostScript">ps</a>, <a href="/format/2312.10396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Can Fairness Constraints Help Recover From Biased Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mohit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Amit Deshpande</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Blum &amp; Stangl (2019) propose a data bias model to simulate
under-representation and label bias in underprivileged population. For a
stylized data distribution with i.i.d. label noise, under certain simple
conditions on the bias parameters, they show that fair classification with
equal opportunity constraints even on extremely biased distribution can recover
an optimally accurate and fair classifier on the original distribution.
Although their distribution is stylized, their result is interesting because it
demonstrates that fairness constraints can implicitly rectify data bias and
simultaneously overcome a perceived fairness-accuracy trade-off. In this paper,
we give an alternate proof of their result using threshold-based
characterization of optimal fair classifiers. Moreover, we show that their
conditions on the bias parameters are both necessary and sufficient for their
recovery result. Our technique is arguably more flexible, as it readily extends
to more general distributions, e.g., when the labels in the original
distribution have Massart noise instead of i.i.d. noise. Finally, we prove that
for any data distribution, if the optimally accurate classifier in a hypothesis
class is fair and robust, then it can be recovered through fair classification
on the biased distribution, whenever the bias parameters satisfy certain simple
conditions.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10401" title="Abstract">arXiv:2312.10401</a> [<a href="/pdf/2312.10401" title="Download PDF">pdf</a>, <a href="/format/2312.10401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Dimensional Rationale in Graph Contrastive Learning from  Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qirui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fanjiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph contrastive learning is a general learning paradigm excelling at
capturing invariant information from diverse perturbations in graphs. Recent
works focus on exploring the structural rationale from graphs, thereby
increasing the discriminability of the invariant information. However, such
methods may incur in the mis-learning of graph models towards the
interpretability of graphs, and thus the learned noisy and task-agnostic
information interferes with the prediction of graphs. To this end, with the
purpose of exploring the intrinsic rationale of graphs, we accordingly propose
to capture the dimensional rationale from graphs, which has not received
sufficient attention in the literature. The conducted exploratory experiments
attest to the feasibility of the aforementioned roadmap. To elucidate the
innate mechanism behind the performance improvement arising from the
dimensional rationale, we rethink the dimensional rationale in graph
contrastive learning from a causal perspective and further formalize the
causality among the variables in the pre-training stage to build the
corresponding structural causal model. On the basis of the understanding of the
structural causal model, we propose the dimensional rationale-aware graph
contrastive learning approach, which introduces a learnable dimensional
rationale acquiring network and a redundancy reduction constraint. The
learnable dimensional rationale acquiring network is updated by leveraging a
bi-level meta-learning technique, and the redundancy reduction constraint
disentangles the redundant features through a decorrelation process during
learning. Empirically, compared with state-of-the-art methods, our method can
yield significant performance boosts on various benchmarks with respect to
discriminability and transferability. The code implementation of our method is
available at https://github.com/ByronJi/DRGCL.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10402" title="Abstract">arXiv:2312.10402</a> [<a href="/pdf/2312.10402" title="Download PDF">pdf</a>, <a href="/format/2312.10402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotation-Free Automatic Music Transcription with Scalable Synthetic  Data and Adversarial Domain Confusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+G">Gakusei Sato</a>, 
<a href="/search/cs?searchtype=author&query=Akama%2C+T">Taketo Akama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic Music Transcription (AMT) is a crucial technology in music
information processing. Despite recent improvements in performance through
machine learning approaches, existing methods often achieve high accuracy in
domains with abundant annotation data, primarily due to the difficulty of
creating annotation data. A practical transcription model requires an
architecture that does not require an annotation data. In this paper, we
propose an annotation-free transcription model achieved through the utilization
of scalable synthetic audio for pre-training and adversarial domain confusion
using unannotated real audio. Through evaluation experiments, we confirm that
our proposed method can achieve higher accuracy under annotation-free
conditions compared to when learning with mixture of annotated real audio data.
Additionally, through ablation studies, we gain insights into the scalability
of this approach and the challenges that lie ahead in the field of AMT
research.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10403" title="Abstract">arXiv:2312.10403</a> [<a href="/pdf/2312.10403" title="Download PDF">pdf</a>, <a href="/format/2312.10403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing the SVD of a matrix under non-standard inner product and  its applications to linear ill-posed problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haibo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The singular value decomposition (SVD) of a matrix is a powerful tool for
many matrix computation problems. In this paper, we consider generalizing the
standard SVD to analyze and compute the regularized solution of linear
ill-posed problems that arise from discretizing the first kind Fredholm
integral equations. For the commonly used quadrature method for discretization,
a regularizer of the form $\|x\|_{M}^2:=x^TMx$ should be exploited, where $M$
is symmetric positive definite. To handle this regularizer, we give the
weighted SVD (WSVD) of a matrix under the $M$-inner product. Several important
applications of WSVD, such as low-rank approximation and solving the least
squares problems with minimum $\|\cdot\|_M$-norm, are studied. We propose the
weighted Golub-Kahan bidiagonalization (WGKB) to compute several dominant WSVD
components and a corresponding weighted LSQR algorithm to iteratively solve the
least squares problem. All the above tools and methods are used to analyze and
solve linear ill-posed problems with the regularizer $\|x\|_{M}^2$. A
WGKB-based subspace projection regularization method is proposed to efficiently
compute a good regularized solution, which can incorporate the prior
information about $x$ encoded by the regularizer $\|x\|_{M}^2$. Several
numerical experiments are performed to illustrate the fruitfulness of our
methods.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10406" title="Abstract">arXiv:2312.10406</a> [<a href="/pdf/2312.10406" title="Download PDF">pdf</a>, <a href="/format/2312.10406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Analysis of Inter Coding in VVC Test Model (VTM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Abdoli%2C+M">Mohsen Abdoli</a>, 
<a href="/search/cs?searchtype=author&query=Guionnet%2C+T">Thomas Guionnet</a>, 
<a href="/search/cs?searchtype=author&query=Guillemot%2C+C">Christine Guillemot</a>, 
<a href="/search/cs?searchtype=author&query=Roumy%2C+A">Aline Roumy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICIP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">The promising improvement in compression efficiency of Versatile Video Coding
(VVC) compared to High Efficiency Video Coding (HEVC) comes at the cost of a
non-negligible encoder side complexity. The largely increased complexity
overhead is a possible obstacle towards its industrial implementation. Many
papers have proposed acceleration methods for VVC. Still, a better
understanding of VVC complexity, especially related to new partitions and
coding tools, is desirable to help the design of new and better acceleration
methods. For this purpose, statistical analyses have been conducted, with a
focus on Coding Unit (CU) sizes and inter coding modes.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10407" title="Abstract">arXiv:2312.10407</a> [<a href="/pdf/2312.10407" title="Download PDF">pdf</a>, <a href="/ps/2312.10407" title="Download PostScript">ps</a>, <a href="/format/2312.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepArt: A Benchmark to Advance Fidelity Research in AI-Generated  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wentao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanyao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Swalpa Kumar Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the initial version of this work, and a more comprehensive and improved version will be updated later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">This paper explores the image synthesis capabilities of GPT-4, a leading
multi-modal large language model. We establish a benchmark for evaluating the
fidelity of texture features in images generated by GPT-4, comprising manually
painted pictures and their AI-generated counterparts. The contributions of this
study are threefold: First, we provide an in-depth analysis of the fidelity of
image synthesis features based on GPT-4, marking the first such study on this
state-of-the-art model. Second, the quantitative and qualitative experiments
fully reveals the limitations of the GPT-4 model in image synthesis. Third, we
have compiled a unique benchmark of manual drawings and corresponding
GPT-4-generated images, introducing a new task to advance fidelity research in
AI-generated content (AIGC). The dataset will be available after being
accepted: \url{https://github.com/rickwang28574/DeepArt}. We hope this study
will fuel knowledge, scholarship, and innovation, inspiring uses that transform
how we discover and understand the world of art and promote the development of
AIGC while retaining respect for art.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10411" title="Abstract">arXiv:2312.10411</a> [<a href="/pdf/2312.10411" title="Download PDF">pdf</a>, <a href="/format/2312.10411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable Participation in UAV-Enabled Federated Edge Learning on  Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheriguene%2C+Y">Youssra Cheriguene</a>, 
<a href="/search/cs?searchtype=author&query=Jaafar%2C+W">Wael Jaafar</a>, 
<a href="/search/cs?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>, 
<a href="/search/cs?searchtype=author&query=Kerrache%2C+C+A">Chaker Abdelaziz Kerrache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a decentralized machine learning (ML) technique
that allows a number of participants to train an ML model collaboratively
without having to share their private local datasets with others. When
participants are unmanned aerial vehicles (UAVs), UAV-enabled FL would
experience heterogeneity due to the majorly skewed (non-independent and
identically distributed -IID) collected data. In addition, UAVs may demonstrate
unintentional misbehavior in which the latter may fail to send updates to the
FL server due, for instance, to UAVs' disconnectivity from the FL system caused
by high mobility, unavailability, or battery depletion. Such challenges may
significantly affect the convergence of the FL model. A recent way to tackle
these challenges is client selection, based on customized criteria that
consider UAV computing power and energy consumption. However, most existing
client selection schemes neglected the participants' reliability. Indeed, FL
can be targeted by poisoning attacks, in which malicious UAVs upload poisonous
local models to the FL server, by either providing targeted false predictions
for specifically chosen inputs or by compromising the global model's accuracy
through tampering with the local model. Hence, we propose in this paper a novel
client selection scheme that enhances convergence by prioritizing fast UAVs
with high-reliability scores, while eliminating malicious UAVs from training.
Through experiments, we assess the effectiveness of our scheme in resisting
different attack scenarios, in terms of convergence and achieved model
accuracy. Finally, we demonstrate the performance superiority of the proposed
approach compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10412" title="Abstract">arXiv:2312.10412</a> [<a href="/pdf/2312.10412" title="Download PDF">pdf</a>, <a href="/ps/2312.10412" title="Download PostScript">ps</a>, <a href="/format/2312.10412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate Outage and Meta-Distribution for Uplink Networks in Finite  Block-Length Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hesham%2C+N">Nourhan Hesham</a>, 
<a href="/search/cs?searchtype=author&query=ElSawy%2C+H">Hesham ElSawy</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+J">Jahangir Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Chaaban%2C+A">Anas Chaaban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publications as a Correspondence in the IEEE Transactions on Vehicular Technology. (6 Pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">With the expected proliferation of delay constrained applications, future
communication technologies are pushed towards using short codes. The
performance using short codes cannot be inferred through classical channel
capacity analysis, which intrinsically assumes long codes and vanishing frame
error rate (FER). This paper studies the performance of an uplink large-scale
network in the finite blocklength regime. Bounds on the spatially averaged rate
outage probability as well as the coding rate meta distribution are derived.
The results reveal the exact achievable rate for a given blocklength and FER,
and demonstrate the discrepancy between the actual network rate and idealistic
classical channel capacity.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10417" title="Abstract">arXiv:2312.10417</a> [<a href="/pdf/2312.10417" title="Download PDF">pdf</a>, <a href="/format/2312.10417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M2ConceptBase: A Fine-grained Aligned Multi-modal Conceptual Knowledge  Base
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zhiwei Zha</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wei Song</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 7 tables, Submitted to TKDE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large multi-modal models (LMMs) have demonstrated promising intelligence
owing to the rapid development of pre-training techniques. However, their
fine-grained cross-modal alignment ability is constrained by the coarse
alignment in image-text pairs. This limitation hinders awareness of
fine-grained concepts, resulting in sub-optimal performance. In this paper, we
propose a multi-modal conceptual knowledge base, named M2ConceptBase, which
aims to provide fine-grained alignment between images and concepts.
Specifically, M2ConceptBase models concepts as nodes, associating each with
relevant images and detailed text, thereby enhancing LMMs' cross-modal
alignment with rich conceptual knowledge. To collect concept-image and
concept-description alignments, we propose a context-aware multi-modal symbol
grounding approach that considers context information in existing large-scale
image-text pairs with respect to each concept. A cutting-edge large language
model supplements descriptions for concepts not grounded via our symbol
grounding approach. Finally, our M2ConceptBase contains more than 951K images
and 152K concepts, each associating with an average of 6.27 images and a single
detailed description. We conduct experiments on the OK-VQA task, demonstrating
that our M2ConceptBase facilitates the model in achieving state-of-the-art
performance. Moreover, we construct a comprehensive benchmark to evaluate the
concept understanding of LMMs and show that M2ConceptBase could effectively
improve LMMs' concept understanding and cross-modal alignment abilities.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10418" title="Abstract">arXiv:2312.10418</a> [<a href="/pdf/2312.10418" title="Download PDF">pdf</a>, <a href="/format/2312.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional Deep Reinforcement Learning for Age-Minimal Mobile Edge  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lyudong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Mobile edge computing (MEC) is a promising paradigm for real-time
applications with intensive computational needs (e.g., autonomous driving), as
it can reduce the processing delay. In this work, we focus on the timeliness of
computational-intensive updates, measured by Age-ofInformation (AoI), and study
how to jointly optimize the task updating and offloading policies for AoI with
fractional form. Specifically, we consider edge load dynamics and formulate a
task scheduling problem to minimize the expected time-average AoI. The
uncertain edge load dynamics, the nature of the fractional objective, and
hybrid continuous-discrete action space (due to the joint optimization) make
this problem challenging and existing approaches not directly applicable. To
this end, we propose a fractional reinforcement learning(RL) framework and
prove its convergence. We further design a model-free fractional deep RL (DRL)
algorithm, where each device makes scheduling decisions with the hybrid action
space without knowing the system dynamics and decisions of other devices.
Experimental results show that our proposed algorithms reduce the average AoI
by up to 57.6% compared with several non-fractional benchmarks.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10419" title="Abstract">arXiv:2312.10419</a> [<a href="/pdf/2312.10419" title="Download PDF">pdf</a>, <a href="/format/2312.10419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Robotic Manipulation of Deformable Objects: Recent Advances,  Open Challenges and New Frontiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+F">Feida Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanmin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bin He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deformable object manipulation (DOM) for robots has a wide range of
applications in various fields such as industrial, service and health care
sectors. However, compared to manipulation of rigid objects, DOM poses
significant challenges for robotic perception, modeling and manipulation, due
to the infinite dimensionality of the state space of deformable objects (DOs)
and the complexity of their dynamics. The development of computer graphics and
machine learning has enabled novel techniques for DOM. These techniques, based
on data-driven paradigms, can address some of the challenges that analytical
approaches of DOM face. However, some existing reviews do not include all
aspects of DOM, and some previous reviews do not summarize data-driven
approaches adequately. In this article, we survey more than 150 relevant
studies (data-driven approaches mainly) and summarize recent advances, open
challenges, and new frontiers for aspects of perception, modeling and
manipulation for DOs. Particularly, we summarize initial progress made by Large
Language Models (LLMs) in robotic manipulation, and indicates some valuable
directions for further research. We believe that integrating data-driven
approaches and analytical approaches can provide viable solutions to open
challenges of DOM.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10420" title="Abstract">arXiv:2312.10420</a> [<a href="/pdf/2312.10420" title="Download PDF">pdf</a>, <a href="/ps/2312.10420" title="Download PostScript">ps</a>, <a href="/format/2312.10420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying MILP Certificates with SMT Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Runtian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+H">Hammurabi Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Pulaj%2C+J">Jonad Pulaj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We present a SMT-based checker for the recently proposed VIPR certificate,
the first proof format for the correctness of answers produced by mixed-integer
linear programming (MILP) solvers. The checker is based on the equivalence
between the correctness of a VIPR certificate and the satisfiability of a
formula in the theory of linear/integer real arithmetic. Evaluation on existing
benchmark instances demonstrates the effectiveness of this approach.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10421" title="Abstract">arXiv:2312.10421</a> [<a href="/pdf/2312.10421" title="Download PDF">pdf</a>, <a href="/ps/2312.10421" title="Download PostScript">ps</a>, <a href="/format/2312.10421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Use of Walsh Domain Equalizer for Performance Enhancement of  MIMO-OFDM Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+K">Khaled Ramadan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The purpose of this article is to investigate the viability of Multi-Carrier
Modulation (MCM) systems based on the Fast Walsh Hadamard Transform (FWHT). In
addition, a nonlinear Joint Low-Complexity Optimized Zero Forcing Successive
Interference Cancellation (JLCOZF-SIC) equalizer is proposed. To that end,
general equations for the number of flops of the proposed equalizer and various
other equalizers are given. This article discusses the use of Banded Matrix
Approximation (BMA) as a technique for reducing complexity. The proposed
equalizer uses BMA to accomplish both equalization and co-Carrier Frequency
Offset (co-CFO) corrections. In addition, three cases involving the proposed
equalizer were investigated. In the first case, diagonal compensation is used.
In the second case, BMA compensation is used. In the third case, complete
matrix compensation is used. In the presence of frequency offset, noise, and
frequency-selective Rayleigh fading environments, analysis and simulation
results show that the OFDM-FWHT system with the proposed equalizer outperforms
the conventional OFDM system with various linear and nonlinear equalizers.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10422" title="Abstract">arXiv:2312.10422</a> [<a href="/pdf/2312.10422" title="Download PDF">pdf</a>, <a href="/format/2312.10422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dense Correspondence for NeRF-Based Face Reenactment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yushi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiangyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings of the AAAI Conference on Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face reenactment is challenging due to the need to establish dense
correspondence between various face representations for motion transfer. Recent
studies have utilized Neural Radiance Field (NeRF) as fundamental
representation, which further enhanced the performance of multi-view face
reenactment in photo-realism and 3D consistency. However, establishing dense
correspondence between different face NeRFs is non-trivial, because implicit
representations lack ground-truth correspondence annotations like mesh-based 3D
parametric models (e.g., 3DMM) with index-aligned vertexes. Although aligning
3DMM space with NeRF-based face representations can realize motion control, it
is sub-optimal for their limited face-only modeling and low identity fidelity.
Therefore, we are inspired to ask: Can we learn the dense correspondence
between different NeRF-based face representations without a 3D parametric model
prior? To address this challenge, we propose a novel framework, which adopts
tri-planes as fundamental NeRF representation and decomposes face tri-planes
into three components: canonical tri-planes, identity deformations, and motion.
In terms of motion control, our key contribution is proposing a Plane
Dictionary (PlaneDict) module, which efficiently maps the motion conditions to
a linear weighted addition of learnable orthogonal plane bases. To the best of
our knowledge, our framework is the first method that achieves one-shot
multi-view face reenactment without a 3D parametric model prior. Extensive
experiments demonstrate that we produce better results in fine-grained motion
control and identity preservation than previous methods.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10423" title="Abstract">arXiv:2312.10423</a> [<a href="/pdf/2312.10423" title="Download PDF">pdf</a>, <a href="/format/2312.10423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Bayesian Optimization with Unknown Continuous Context  Distribution via Kernel Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaobin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lei Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+K">Ke Xue</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Accept
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Bayesian optimization (BO) is a sample-efficient method and has been widely
used for optimizing expensive black-box functions. Recently, there has been a
considerable interest in BO literature in optimizing functions that are
affected by context variable in the environment, which is uncontrollable by
decision makers. In this paper, we focus on the optimization of functions'
expectations over continuous context variable, subject to an unknown
distribution. To address this problem, we propose two algorithms that employ
kernel density estimation to learn the probability density function (PDF) of
continuous context variable online. The first algorithm is simpler, which
directly optimizes the expectation under the estimated PDF. Considering that
the estimated PDF may have high estimation error when the true distribution is
complicated, we further propose the second algorithm that optimizes the
distributionally robust objective. Theoretical results demonstrate that both
algorithms have sub-linear Bayesian cumulative regret on the expectation
objective. Furthermore, we conduct numerical experiments to empirically
demonstrate the effectiveness of our algorithms.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10424" title="Abstract">arXiv:2312.10424</a> [<a href="/pdf/2312.10424" title="Download PDF">pdf</a>, <a href="/format/2312.10424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Concentration Bound for TD(0) with Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandak%2C+S">Siddharth Chandak</a>, 
<a href="/search/cs?searchtype=author&query=Borkar%2C+V+S">Vivek S. Borkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Stochastic Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">We derive a concentration bound of the type `for all $n \geq n_0$ for some
$n_0$' for TD(0) with linear function approximation. We work with online TD
learning with samples from a single sample path of the underlying Markov chain.
This makes our analysis significantly different from offline TD learning or TD
learning with access to independent samples from the stationary distribution of
the Markov chain. We treat TD(0) as a contractive stochastic approximation
algorithm, with both martingale and Markov noises. Markov noise is handled
using the Poisson equation and the lack of almost sure guarantees on
boundedness of iterates is handled using the concept of relaxed concentration
inequalities.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10425" title="Abstract">arXiv:2312.10425</a> [<a href="/pdf/2312.10425" title="Download PDF">pdf</a>, <a href="/format/2312.10425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take History as a Mirror in Heterogeneous Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaorui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hengwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) allows several clients to cooperatively train machine
learning models without disclosing the raw data. In practice, due to the system
and statistical heterogeneity among devices, synchronous FL often encounters
the straggler effect. In contrast, asynchronous FL can mitigate this problem,
making it suitable for scenarios involving numerous participants. However,
Non-IID data and stale models present significant challenges to asynchronous
FL, as they would diminish the practicality of the global model and even lead
to training failures. In this work, we propose a novel asynchronous FL
framework called Federated Historical Learning (FedHist), which effectively
addresses the challenges posed by both Non-IID data and gradient staleness.
FedHist enhances the stability of local gradients by performing weighted fusion
with historical global gradients cached on the server. Relying on hindsight, it
assigns aggregation weights to each participant in a multi-dimensional manner
during each communication round. To further enhance the efficiency and
stability of the training process, we introduce an intelligent $\ell_2$-norm
amplification scheme, which dynamically regulates the learning progress based
on the $\ell_2$-norms of the submitted gradients. Extensive experiments
demonstrate that FedHist outperforms state-of-the-art methods in terms of
convergence performance and test accuracy.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10426" title="Abstract">arXiv:2312.10426</a> [<a href="/pdf/2312.10426" title="Download PDF">pdf</a>, <a href="/ps/2312.10426" title="Download PostScript">ps</a>, <a href="/format/2312.10426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Branch Prediction in Hardcaml for a RISC-V 32im CPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saveau%2C+A">Alex Saveau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Accurate branch prediction is a critical part of high performance instruction
stream processing. In this paper, I present a hardware implementation of branch
prediction for a RV32IM CPU, starting with static decode stage predictions and
culminating in the use of BATAGE. In addition, I detail my experience writing
the RTL in Hardcaml, a hardware description library for the functional
programming language OCaml.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10430" title="Abstract">arXiv:2312.10430</a> [<a href="/pdf/2312.10430" title="Download PDF">pdf</a>, <a href="/ps/2312.10430" title="Download PostScript">ps</a>, <a href="/format/2312.10430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Post-Quantum Cryptography: State-of-the-Art and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+M">Marel Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Gayler%2C+L">Luke Gayler</a>, 
<a href="/search/cs?searchtype=author&query=Seals%2C+A">Alex Seals</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tao Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The paper explains that post-quantum cryptography is necessary due to the
introduction of quantum computing causing certain algorithms to be broken. We
analyze the different types of post-quantum cryptography, quantum cryptography
and quantum-resistant cryptography, to provide a thorough understanding of the
current solutions to the problems and their limitations. We explain the current
state of quantum computing and how it has changed over time while discussing
possible attacks on both types of post-quantum cryptography. Next, current
post-quantum algorithms are discussed, and implementations are demonstrated.
Lastly, we conclude that due to quantum cryptography's present limitations it
is not a viable solution like it is often presented to be and that it is
currently better to use quantum-resistant cryptography.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10431" title="Abstract">arXiv:2312.10431</a> [<a href="/pdf/2312.10431" title="Download PDF">pdf</a>, <a href="/format/2312.10431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Diffusion for Mixed-Type Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mueller%2C+M">Markus Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+K">Kathrin Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Fok%2C+D">Dennis Fok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based generative models (or diffusion models for short) have proven
successful across many domains in generating text and image data. However, the
consideration of mixed-type tabular data with this model family has fallen
short so far. Existing research mainly combines different diffusion processes
without explicitly accounting for the feature heterogeneity inherent to tabular
data. In this paper, we combine score matching and score interpolation to
ensure a common type of continuous noise distribution that affects both
continuous and categorical features alike. Further, we investigate the impact
of distinct noise schedules per feature or per data type. We allow for
adaptive, learnable noise schedules to ensure optimally allocated model
capacity and balanced generative capability. Results show that our model
consistently outperforms state-of-the-art benchmark models and that accounting
for heterogeneity within the noise schedule design boosts the sample quality.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10432" title="Abstract">arXiv:2312.10432</a> [<a href="/pdf/2312.10432" title="Download PDF">pdf</a>, <a href="/format/2312.10432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Dialogue to Diagram: Task and Relationship Extraction from Natural  Language for Accelerated Business Process Prototyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qayyum%2C+S">Sara Qayyum</a>, 
<a href="/search/cs?searchtype=author&query=Asghar%2C+M+M">Muhammad Moiz Asghar</a>, 
<a href="/search/cs?searchtype=author&query=Yaseen%2C+M+F">Muhammad Fouzan Yaseen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The automatic transformation of verbose, natural language descriptions into
structured process models remains a challenge of significant complexity - This
paper introduces a contemporary solution, where central to our approach, is the
use of dependency parsing and Named Entity Recognition (NER) for extracting key
elements from textual descriptions. Additionally, we utilize
Subject-Verb-Object (SVO) constructs for identifying action relationships and
integrate semantic analysis tools, including WordNet, for enriched contextual
understanding. A novel aspect of our system is the application of neural
coreference resolution, integrated with the SpaCy framework, enhancing the
precision of entity linkage and anaphoric references. Furthermore, the system
adeptly handles data transformation and visualization, converting extracted
information into BPMN (Business Process Model and Notation) diagrams. This
methodology not only streamlines the process of capturing and representing
business workflows but also significantly reduces the manual effort and
potential for error inherent in traditional modeling approaches.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10436" title="Abstract">arXiv:2312.10436</a> [<a href="/pdf/2312.10436" title="Download PDF">pdf</a>, <a href="/format/2312.10436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing Hard SAT Instances with Metaheuristic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chivilikhin%2C+D">Daniil Chivilikhin</a>, 
<a href="/search/cs?searchtype=author&query=Pavlenko%2C+A">Artem Pavlenko</a>, 
<a href="/search/cs?searchtype=author&query=Semenov%2C+A">Alexander Semenov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of the paper published in Intern. J. Artificial Intelligence. 2023. V. 21. No. 2. P. 61-92
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In the article, within the framework of the Boolean Satisfiability problem
(SAT), the problem of estimating the hardness of specific Boolean formulas
w.r.t. a specific complete SAT solving algorithm is considered. Based on the
well-known Strong Backdoor Set (SBS) concept, we introduce the notion of
decomposition hardness (d-hardness). If $B$ is an arbitrary subset of the set
of variables occurring in a SAT formula $C$, and $A$ is an arbitrary complete
SAT solver , then the d-hardness expresses an estimate of the hardness of $C$
w.r.t. $A$ and $B$. We show that the d-hardness of $C$ w.r.t. a particular $B$
can be expressed in terms of the expected value of a special random variable
associated with $A$, $B$, and $C$. For its computational evaluation, algorithms
based on the Monte Carlo method can be used. The problem of finding $B$ with
the minimum value of d-hardness is formulated as an optimization problem for a
pseudo-Boolean function whose values are calculated as a result of a
probabilistic experiment. To minimize this function, we use evolutionary
algorithms. In the experimental part, we demonstrate the applicability of the
concept of d-hardness and the methods of its estimation to solving hard
unsatisfiable SAT instances.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10437" title="Abstract">arXiv:2312.10437</a> [<a href="/pdf/2312.10437" title="Download PDF">pdf</a>, <a href="/ps/2312.10437" title="Download PostScript">ps</a>, <a href="/format/2312.10437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tender Notice Extraction from E-papers Using Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+A">Ashmin Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Sedhai%2C+A">Anuj Sedhai</a>, 
<a href="/search/cs?searchtype=author&query=Neupane%2C+D">Devraj Neupane</a>, 
<a href="/search/cs?searchtype=author&query=Khadka%2C+M">Manish Khadka</a>, 
<a href="/search/cs?searchtype=author&query=Bastola%2C+R">Rama Bastola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Tender notices are usually sought by most of the companies at regular
intervals as a means for obtaining the contracts of various projects. These
notices consist of all the required information like description of the work,
period of construction, estimated amount of project, etc. In the context of
Nepal, tender notices are usually published in national as well as local
newspapers. The interested bidders should search all the related tender notices
in newspapers. However, it is very tedious for these companies to manually
search tender notices in every newspaper and figure out which bid is best
suited for them. This project is built with the purpose of solving this tedious
task of manually searching the tender notices. Initially, the newspapers are
downloaded in PDF format using the selenium library of python. After
downloading the newspapers, the e-papers are scanned and tender notices are
automatically extracted using a neural network. For extraction purposes,
different architectures of CNN namely ResNet, GoogleNet and Xception are used
and a model with highest performance has been implemented. Finally, these
extracted notices are then published on the website and are accessible to the
users. This project is helpful for construction companies as well as
contractors assuring quality and efficiency. This project has great application
in the field of competitive bidding as well as managing them in a systematic
manner.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10439" title="Abstract">arXiv:2312.10439</a> [<a href="/pdf/2312.10439" title="Download PDF">pdf</a>, <a href="/format/2312.10439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Image-level Classification Improves Open-vocabulary Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Ruohuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-Vocabulary Object Detection (OVOD) aims to detect novel objects beyond a
given set of base categories on which the detection model is trained. Recent
OVOD methods focus on adapting the image-level pre-trained vision-language
models (VLMs), such as CLIP, to a region-level object detection task via, eg.,
region-level knowledge distillation, regional prompt learning, or region-text
pre-training, to expand the detection vocabulary. These methods have
demonstrated remarkable performance in recognizing regional visual concepts,
but they are weak in exploiting the VLMs' powerful global scene understanding
ability learned from the billion-scale image-level text descriptions. This
limits their capability in detecting hard objects of small, blurred, or
occluded appearance from novel/base categories, whose detection heavily relies
on contextual information. To address this, we propose a novel approach, namely
Simple Image-level Classification for Context-Aware Detection Scoring
(SIC-CADS), to leverage the superior global knowledge yielded from CLIP for
complementing the current OVOD models from a global perspective. The core of
SIC-CADS is a multi-modal multi-label recognition (MLR) module that learns the
object co-occurrence-based contextual information from CLIP to recognize all
possible object categories in the scene. These image-level MLR scores can then
be utilized to refine the instance-level detection scores of the current OVOD
models in detecting those hard objects. This is verified by extensive empirical
results on two popular benchmarks, OV-LVIS and OV-COCO, which show that
SIC-CADS achieves significant and consistent improvement when combined with
different types of OVOD models. Further, SIC-CADS also improves the
cross-dataset generalization ability on Objects365 and OpenImages. The code is
available at https://github.com/mala-lab/SIC-CADS.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10440" title="Abstract">arXiv:2312.10440</a> [<a href="/pdf/2312.10440" title="Download PDF">pdf</a>, <a href="/format/2312.10440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weight-Entanglement Meets Gradient-Based Neural Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukthanker%2C+R+S">Rhea Sanjay Sukthanker</a>, 
<a href="/search/cs?searchtype=author&query=Krishnakumar%2C+A">Arjun Krishnakumar</a>, 
<a href="/search/cs?searchtype=author&query=Safari%2C+M">Mahmoud Safari</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Weight sharing is a fundamental concept in neural architecture search (NAS),
enabling gradient-based methods to explore cell-based architecture spaces
significantly faster than traditional blackbox approaches. In parallel, weight
\emph{entanglement} has emerged as a technique for intricate parameter sharing
among architectures within macro-level search spaces. %However, the macro
structure of such spaces poses compatibility challenges for gradient-based NAS
methods. %As a result, blackbox optimization methods have been commonly
employed, particularly in conjunction with supernet training, to maintain
search efficiency. %Due to the inherent differences in the structure of these
search spaces, these Since weight-entanglement poses compatibility challenges
for gradient-based NAS methods, these two paradigms have largely developed
independently in parallel sub-communities. This paper aims to bridge the gap
between these sub-communities by proposing a novel scheme to adapt
gradient-based methods for weight-entangled spaces. This enables us to conduct
an in-depth comparative assessment and analysis of the performance of
gradient-based NAS in weight-entangled search spaces. Our findings reveal that
this integration of weight-entanglement and gradient-based NAS brings forth the
various benefits of gradient-based methods (enhanced performance, improved
supernet training properties and superior any-time performance), while
preserving the memory efficiency of weight-entangled spaces. The code for our
work is openly accessible
\href{https://anonymous.4open.science/r/TangleNAS-527C}{here}
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10441" title="Abstract">arXiv:2312.10441</a> [<a href="/pdf/2312.10441" title="Download PDF">pdf</a>, <a href="/ps/2312.10441" title="Download PostScript">ps</a>, <a href="/format/2312.10441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disjunctive Policies for Database-Backed Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadian%2C+A+M">Amir M. Ahmadian</a>, 
<a href="/search/cs?searchtype=author&query=Soloviev%2C+M">Matvey Soloviev</a>, 
<a href="/search/cs?searchtype=author&query=Balliu%2C+M">Musard Balliu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, including references and appendix. Extended version of paper accepted to CSF 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">When specifying security policies for databases, it is often natural to
formulate disjunctive dependencies, where a piece of information may depend on
at most one of two dependencies P1 or P2, but not both. A formal semantic model
of such disjunctive dependencies, the Quantale of Information, was recently
introduced by Hunt and Sands as a generalization of the Lattice of Information.
In this paper, we seek to contribute to the understanding of disjunctive
dependencies in database-backed programs and introduce a practical framework to
statically enforce disjunctive security policies. To that end, we introduce the
Determinacy Quantale, a new query-based structure which captures the ordering
of disjunctive information in databases. This structure can be understood as a
query-based counterpart to the Quantale of Information. Based on this
structure, we design a sound enforcement mechanism to check disjunctive
policies for database-backed programs. This mechanism is based on a type-based
analysis for a simple imperative language with database queries, which is
precise enough to accommodate a variety of row- and column-level database
policies flexibly while keeping track of disjunctions due to control flow. We
validate our mechanism by implementing it in a tool, DiVerT, and demonstrate
its feasibility on a number of use cases.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10445" title="Abstract">arXiv:2312.10445</a> [<a href="/pdf/2312.10445" title="Download PDF">pdf</a>, <a href="/ps/2312.10445" title="Download PostScript">ps</a>, <a href="/format/2312.10445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Evolution of Keylogger Technologies: A Survey from Historical  Origins to Emerging Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salas-Nino%2C+M">Marco Salas-Nino</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+G">Grant Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Hamdan%2C+D">Daniel Hamdan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tao Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the digital world evolves, so do the threats to our security do too.
Keyloggers were once a large threat to the cyber world. Though undergoing many
transformations alongside the technological advancements of today, it is
important to raise questions about the importance of Anti-Keyloggers in our
current state of cyber security. This survey dives into the historical
evolution of Keyloggers and investigates their current day forms. Within this
inspection of Keyloggers, we must propose whether Anti-Keyloggers serve a
purpose to this ever-changing landscape before us or if emerging strategies
have rendered them obsolete.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10447" title="Abstract">arXiv:2312.10447</a> [<a href="/pdf/2312.10447" title="Download PDF">pdf</a>, <a href="/ps/2312.10447" title="Download PostScript">ps</a>, <a href="/format/2312.10447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finger biometric recognition with feature selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Asish Bera</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+D">Debotosh Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Nasipuri%2C+M">Mita Nasipuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages. The Biometric Computing: Recognition and Registration, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Biometrics is indispensable in this modern digital era for secure automated
human authentication in various fields of machine learning and pattern
recognition. Hand geometry is a promising physiological biometric trait with
ample deployed application areas for identity verification. Due to the
intricate anatomic foundation of the thumb and substantial inter-finger posture
variation, satisfactory performances cannot be achieved while the thumb is
included in the contact-free environment. To overcome the hindrances associated
with the thumb, four finger-based (excluding the thumb) biometric approaches
have been devised. In this chapter, a four-finger based biometric method has
been presented. Again, selection of salient features is essential to reduce the
feature dimensionality by eliminating the insignificant features. Weights are
assigned according to the discriminative efficiency of the features to
emphasize on the essential features. Two different strategies namely, the
global and local feature selection methods are adopted based on the adaptive
forward-selection and backward-elimination (FoBa) algorithm. The identification
performances are evaluated using the weighted k-nearest neighbor (wk-NN) and
random forest (RF) classifiers. The experiments are conducted using the
selected feature subsets over the 300 subjects of the Bosphorus hand database.
The best identification accuracy of 98.67%, and equal error rate (EER) of 4.6%
have been achieved using the subset of 25 features which are selected by the
rank-based local FoBa algorithm.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10448" title="Abstract">arXiv:2312.10448</a> [<a href="/pdf/2312.10448" title="Download PDF">pdf</a>, <a href="/format/2312.10448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving Crash Bugs via Large Language Models: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xueying Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yiling Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Crash bugs cause unexpected program behaviors or even termination, requiring
high-priority resolution. However, manually resolving crash bugs is challenging
and labor-intensive, and researchers have proposed various techniques for their
automated localization and repair. ChatGPT, a recent large language model
(LLM), has garnered significant attention due to its exceptional performance
across various domains. This work performs the first investigation into
ChatGPT's capability in resolve real-world crash bugs, focusing on its
effectiveness in both localizing and repairing code-related and
environment-related crash bugs. Specifically, we initially assess ChatGPT's
fundamental ability to resolve crash bugs with basic prompts in a single
iteration. We observe that ChatGPT performs better at resolving code-related
crash bugs compared to environment-related ones, and its primary challenge in
resolution lies in inaccurate localization. Additionally, we explore ChatGPT's
potential with various advanced prompts. Furthermore, by stimulating ChatGPT's
self-planning, it methodically investigates each potential crash-causing
environmental factor through proactive inquiry, ultimately identifying the root
cause of the crash. Based on our findings, we propose IntDiagSolver, an
interaction methodology designed to facilitate precise crash bug resolution
through continuous interaction with LLMs. Evaluating IntDiagSolver on multiple
LLMs reveals consistent enhancement in the accuracy of crash bug resolution,
including ChatGPT, Claude, and CodeLlama.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10456" title="Abstract">arXiv:2312.10456</a> [<a href="/pdf/2312.10456" title="Download PDF">pdf</a>, <a href="/format/2312.10456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WRTester: Differential Testing of WebAssembly Runtimes via  Semantic-aware Binary Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shangtong Cao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Ningyu He</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+X">Xinyu She</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Wasm runtime is a fundamental component in the Wasm ecosystem, as it directly
impacts whether Wasm applications can be executed as expected. Bugs in Wasm
runtime bugs are frequently reported, thus our research community has made a
few attempts to design automated testing frameworks for detecting bugs in Wasm
runtimes. However, existing testing frameworks are limited by the quality of
test cases, i.e., they face challenges of generating both semantic-rich and
syntactic-correct Wasm binaries, thus complicated bugs cannot be triggered. In
this work, we present WRTester, a novel differential testing framework that can
generated complicated Wasm test cases by disassembling and assembling of
real-world Wasm binaries, which can trigger hidden inconsistencies among Wasm
runtimes. For further pinpointing the root causes of unexpected behaviors, we
design a runtime-agnostic root cause location method to accurately locate bugs.
Extensive evaluation suggests that WRTester outperforms SOTA techniques in
terms of both efficiency and effectiveness. We have uncovered 33 unique bugs in
popular Wasm runtimes, among which 25 have been confirmed.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10457" title="Abstract">arXiv:2312.10457</a> [<a href="/pdf/2312.10457" title="Download PDF">pdf</a>, <a href="/ps/2312.10457" title="Download PostScript">ps</a>, <a href="/format/2312.10457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Autoregressive Image Modeling for Visual Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiyou Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of autoregressive modeling (AM) in computer vision lags
behind natural language processing (NLP) in self-supervised pre-training. This
is mainly caused by the challenge that images are not sequential signals and
lack a natural order when applying autoregressive modeling. In this study,
inspired by human beings' way of grasping an image, i.e., focusing on the main
object first, we present a semantic-aware autoregressive image modeling
(SemAIM) method to tackle this challenge. The key insight of SemAIM is to
autoregressive model images from the semantic patches to the less semantic
patches. To this end, we first calculate a semantic-aware permutation of
patches according to their feature similarities and then perform the
autoregression procedure based on the permutation. In addition, considering
that the raw pixels of patches are low-level signals and are not ideal
prediction targets for learning high-level semantic representation, we also
explore utilizing the patch features as the prediction targets. Extensive
experiments are conducted on a broad range of downstream tasks, including image
classification, object detection, and instance/semantic segmentation, to
evaluate the performance of SemAIM. The results demonstrate SemAIM achieves
state-of-the-art performance compared with other self-supervised methods.
Specifically, with ViT-B, SemAIM achieves 84.1% top-1 accuracy for fine-tuning
on ImageNet, 51.3% AP and 45.4% AP for object detection and instance
segmentation on COCO, which outperforms the vanilla MAE by 0.5%, 1.0%, and
0.5%, respectively.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10458" title="Abstract">arXiv:2312.10458</a> [<a href="/pdf/2312.10458" title="Download PDF">pdf</a>, <a href="/format/2312.10458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degree-based stratification of nodes in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Ameen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Cevikalp%2C+H">Hakan Cevikalp</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite much research, Graph Neural Networks (GNNs) still do not display the
favorable scaling properties of other deep neural networks such as
Convolutional Neural Networks and Transformers. Previous work has identified
issues such as oversmoothing of the latent representation and have suggested
solutions such as skip connections and sophisticated normalization schemes.
Here, we propose a different approach that is based on a stratification of the
graph nodes. We provide motivation that the nodes in a graph can be stratified
into those with a low degree and those with a high degree and that the two
groups are likely to behave differently. Based on this motivation, we modify
the Graph Neural Network (GNN) architecture so that the weight matrices are
learned, separately, for the nodes in each group. This simple-to-implement
modification seems to improve performance across datasets and GNN methods. To
verify that this increase in performance is not only due to the added capacity,
we also perform the same modification for random splits of the nodes, which
does not lead to any improvement.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10461" title="Abstract">arXiv:2312.10461</a> [<a href="/pdf/2312.10461" title="Download PDF">pdf</a>, <a href="/format/2312.10461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Up-Sampling Operations in CNN-based Generative Network  for Generalizable Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuangchuang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shikui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Guanghua Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Ping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the proliferation of highly realistic synthetic images, facilitated
through a variety of GANs and Diffusions, has significantly heightened the
susceptibility to misuse. While the primary focus of deepfake detection has
traditionally centered on the design of detection algorithms, an investigative
inquiry into the generator architectures has remained conspicuously absent in
recent years. This paper contributes to this lacuna by rethinking the
architectures of CNN-based generators, thereby establishing a generalized
representation of synthetic artifacts. Our findings illuminate that the
up-sampling operator can, beyond frequency-based artifacts, produce generalized
forgery artifacts. In particular, the local interdependence among image pixels
caused by upsampling operators is significantly demonstrated in synthetic
images generated by GAN or diffusion. Building upon this observation, we
introduce the concept of Neighboring Pixel Relationships(NPR) as a means to
capture and characterize the generalized structural artifacts stemming from
up-sampling operations. A comprehensive analysis is conducted on an open-world
dataset, comprising samples generated by \tft{28 distinct generative models}.
This analysis culminates in the establishment of a novel state-of-the-art
performance, showcasing a remarkable \tft{12.8\%} improvement over existing
methods. The code is available at
https://github.com/chuangchuangtan/NPR-DeepfakeDetection.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10462" title="Abstract">arXiv:2312.10462</a> [<a href="/pdf/2312.10462" title="Download PDF">pdf</a>, <a href="/ps/2312.10462" title="Download PostScript">ps</a>, <a href="/format/2312.10462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion of Deep and Shallow Features for Face Kinship Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouanas%2C+B+E">Belabbaci El Ouanas</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+K">Khammari Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+C">Chouchane Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Bessaoudi%2C+M">Mohcene Bessaoudi</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+A+A">Akram Abderraouf Gharbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.03562">arXiv:2312.03562</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Kinship verification from face images is a novel and formidable challenge in
the realms of pattern recognition and computer vision. This work makes notable
contributions by incorporating a preprocessing technique known as Multiscale
Retinex (MSR), which enhances image quality. Our approach harnesses the
strength of complementary deep (VGG16) and shallow texture descriptors (BSIF)
by combining them at the score level using Logistic Regression (LR) technique.
We assess the effectiveness of our approach by conducting comprehensive
experiments on three challenging kinship datasets: Cornell Kin Face, UB Kin
Face and TS Kin Face
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10463" title="Abstract">arXiv:2312.10463</a> [<a href="/pdf/2312.10463" title="Download PDF">pdf</a>, <a href="/format/2312.10463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecPrompt: A Prompt Tuning Framework for News Recommendation Using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dairui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Honghui Du</a>, 
<a href="/search/cs?searchtype=author&query=Greene%2C+D">Derek Greene</a>, 
<a href="/search/cs?searchtype=author&query=Lawlor%2C+A">Aonghus Lawlor</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruihai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, and 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In the evolving field of personalized news recommendation, understanding the
semantics of the underlying data is crucial. Large Language Models (LLMs) like
GPT-4 have shown promising performance in understanding natural language.
However, the extent of their applicability in news recommendation systems
remains to be validated. This paper introduces RecPrompt, the first framework
for news recommendation that leverages the capabilities of LLMs through prompt
engineering. This system incorporates a prompt optimizer that applies an
iterative bootstrapping process, enhancing the LLM-based recommender's ability
to align news content with user preferences and interests more effectively.
Moreover, this study offers insights into the effective use of LLMs in news
recommendation, emphasizing both the advantages and the challenges of
incorporating LLMs into recommendation systems.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10464" title="Abstract">arXiv:2312.10464</a> [<a href="/pdf/2312.10464" title="Download PDF">pdf</a>, <a href="/format/2312.10464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Empirical Pathologies of Laplace Approximation for Uncertainty  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhdanov%2C+M">Maksim Zhdanov</a>, 
<a href="/search/cs?searchtype=author&query=Dereka%2C+S">Stanislav Dereka</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we critically evaluate Bayesian methods for uncertainty
estimation in deep learning, focusing on the widely applied Laplace
approximation and its variants. Our findings reveal that the conventional
method of fitting the Hessian matrix negatively impacts out-of-distribution
(OOD) detection efficiency. We propose a different point of view, asserting
that focusing solely on optimizing prior precision can yield more accurate
uncertainty estimates in OOD detection while preserving adequate calibration
metrics. Moreover, we demonstrate that this property is not connected to the
training stage of a model but rather to its intrinsic properties. Through
extensive experimental evaluation, we establish the superiority of our
simplified approach over traditional methods in the out-of-distribution domain.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10466" title="Abstract">arXiv:2312.10466</a> [<a href="/pdf/2312.10466" title="Download PDF">pdf</a>, <a href="/format/2312.10466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIGHT: Retrieval-augmented Generation for Mainstream Hashtag  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Run-Ze Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yixing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiangui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ECIR2024 full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Automatic mainstream hashtag recommendation aims to accurately provide users
with concise and popular topical hashtags before publication. Generally,
mainstream hashtag recommendation faces challenges in the comprehensive
difficulty of newly posted tweets in response to new topics, and the accurate
identification of mainstream hashtags beyond semantic correctness. However,
previous retrieval-based methods based on a fixed predefined mainstream hashtag
list excel in producing mainstream hashtags, but fail to understand the
constant flow of up-to-date information. Conversely, generation-based methods
demonstrate a superior ability to comprehend newly posted tweets, but their
capacity is constrained to identifying mainstream hashtags without additional
features. Inspired by the recent success of the retrieval-augmented technique,
in this work, we attempt to adopt this framework to combine the advantages of
both approaches. Meantime, with the help of the generator component, we could
rethink how to further improve the quality of the retriever component at a low
cost. Therefore, we propose RetrIeval-augmented Generative Mainstream HashTag
Recommender (RIGHT), which consists of three components: 1) a retriever seeks
relevant hashtags from the entire tweet-hashtags set; 2) a selector enhances
mainstream identification by introducing global signals; and 3) a generator
incorporates input tweets and selected hashtags to directly generate the
desired hashtags. The experimental results show that our method achieves
significant improvements over state-of-the-art baselines. Moreover, RIGHT can
be easily integrated into large language models, improving the performance of
ChatGPT by more than 10%.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10467" title="Abstract">arXiv:2312.10467</a> [<a href="/pdf/2312.10467" title="Download PDF">pdf</a>, <a href="/format/2312.10467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrojFSP: Trojan Insertion in Few-shot Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mengxin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jiaqi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">YanShan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Q">Qian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Prompt tuning is one of the most effective solutions to adapting a fixed
pre-trained language model (PLM) for various downstream tasks, especially with
only a few input samples. However, the security issues, e.g., Trojan attacks,
of prompt tuning on a few data samples are not well-studied. Transferring
established data poisoning attacks directly to few-shot prompt tuning presents
multiple challenges. One significant issue is the \textit{poisoned imbalance
issue}, where non-target class samples are added to the target class, resulting
in a greater number of target-class samples compared to non-target class. While
this issue is not critical in regular tuning, it significantly hampers the
few-shot prompt tuning, making it difficult to simultaneously achieve a high
attack success rate (ASR) and maintain clean data accuracy (CDA). Additionally,
few-shot prompting is prone to overfitting in terms of both ASR and CDA. In
this paper, we introduce \textit{TrojFSP}, a method designed to address the
challenges. To solve the poisoned imbalance issue, we develop a
\textit{Target-Class Shrink (TC-Shrink)} technique, which aims to equalize the
number of poisoning samples. To combat overfitting, we employ a
\textit{Selective Token Poisoning} technique to boost attack performance.
Furthermore, we introduce a \textit{Trojan-Trigger Attention} objective
function to amplify the attention of the poisoned trojan prompt on triggers.
Experiments show that our TrojFSP achieves an ASR of over 99\% while
maintaining negligible decreases in CDA across various PLMs and datasets.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10469" title="Abstract">arXiv:2312.10469</a> [<a href="/pdf/2312.10469" title="Download PDF">pdf</a>, <a href="/format/2312.10469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One step closer to unbiased aleatoric uncertainty estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziwen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tsui-Wei Weng</a>, 
<a href="/search/cs?searchtype=author&query=Megretski%2C+A">Alexandre Megretski</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+L">Luca Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+M">Lam M. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural networks are powerful tools in various applications, and quantifying
their uncertainty is crucial for reliable decision-making. In the deep learning
field, the uncertainties are usually categorized into aleatoric (data) and
epistemic (model) uncertainty. In this paper, we point out that the existing
popular variance attenuation method highly overestimates aleatoric uncertainty.
To address this issue, we propose a new estimation method by actively
de-noising the observed data \footnote{Source code available at
\url{https://github.com/wz16/DVA}.}. By conducting a broad range of
experiments, we demonstrate that our proposed approach provides a much closer
approximation to the actual data uncertainty than the standard method.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10470" title="Abstract">arXiv:2312.10470</a> [<a href="/pdf/2312.10470" title="Download PDF">pdf</a>, <a href="/ps/2312.10470" title="Download PostScript">ps</a>, <a href="/format/2312.10470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Person Re-Identification through Tensor Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+A+A">Akram Abderraouf Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Chouchane%2C+A">Ammar Chouchane</a>, 
<a href="/search/cs?searchtype=author&query=Bessaoudi%2C+M">Mohcene Bessaoudi</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>, 
<a href="/search/cs?searchtype=author&query=Belabbaci%2C+E+o">El ouanas Belabbaci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present a novel person reidentification (PRe-ID) system
that based on tensor feature representation and multilinear subspace learning.
Our approach utilizes pretrained CNNs for high-level feature extraction, along
with Local Maximal Occurrence (LOMO) and Gaussian Of Gaussian (GOG )
descriptors. Additionally, Cross-View Quadratic Discriminant Analysis (TXQDA)
algorithm is used for multilinear subspace learning, which models the data in a
tensor framework to enhance discriminative capabilities. Similarity measure
based on Mahalanobis distance is used for matching between training and test
pedestrian images. Experimental evaluations on VIPeR and PRID450s datasets
demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10472" title="Abstract">arXiv:2312.10472</a> [<a href="/pdf/2312.10472" title="Download PDF">pdf</a>, <a href="/format/2312.10472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Analysis of Policy Networks: An Example of  Double-Integrator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruining Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haoran Han</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+M">Maolong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qisong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Extensive utilization of deep reinforcement learning (DRL) policy networks in
diverse continuous control tasks has raised questions regarding performance
degradation in expansive state spaces where the input state norm is larger than
that in the training environment. This paper aims to uncover the underlying
factors contributing to such performance deterioration when dealing with
expanded state spaces, using a novel analysis technique known as state
division. In contrast to prior approaches that employ state division merely as
a post-hoc explanatory tool, our methodology delves into the intrinsic
characteristics of DRL policy networks. Specifically, we demonstrate that the
expansion of state space induces the activation function $\tanh$ to exhibit
saturability, resulting in the transformation of the state division boundary
from nonlinear to linear. Our analysis centers on the paradigm of the
double-integrator system, revealing that this gradual shift towards linearity
imparts a control behavior reminiscent of bang-bang control. However, the
inherent linearity of the division boundary prevents the attainment of an ideal
bang-bang control, thereby introducing unavoidable overshooting. Our
experimental investigations, employing diverse RL algorithms, establish that
this performance phenomenon stems from inherent attributes of the DRL policy
network, remaining consistent across various optimization algorithms.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10475" title="Abstract">arXiv:2312.10475</a> [<a href="/pdf/2312.10475" title="Download PDF">pdf</a>, <a href="/ps/2312.10475" title="Download PostScript">ps</a>, <a href="/format/2312.10475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRS-Aided Sectorized Base Station Design and 3D Coverage Performance  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xintong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiangbin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Liqun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted to IEEE IWQoS 2023 on 12 Feb. 2023; accepted 13 April 2023; published 27 July 2023. An associated Chinese patent was applied on 9 Aug. 2022 and granted on 1 Sep. 2023, under No. ZL202210948626.X
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Intelligent reflecting surface (IRS) is regarded as a revolutionary paradigm
that can reconfigure the wireless propagation environment for enhancing the
desired signal and/or weakening the interference, and thus improving the
quality of service (QoS) for communication systems. In this paper, we propose
an IRS-aided sectorized BS design where the IRS is mounted in front of a
transmitter (TX) and reflects/reconfigures signal towards the desired user
equipment (UE). Unlike prior works that address link-level
analysis/optimization of IRS-aided systems, we focus on the system-level
three-dimensional (3D) coverage performance in both single-/multiple-cell
scenarios. To this end, a distance/angle-dependent 3D channel model is
considered for UEs in the 3D space, as well as the non-isotropic TX beam
pattern and IRS element radiation pattern (ERP), both of which affect the
average channel power as well as the multi-path fading statistics. Based on the
above, a general formula of received signal power in our design is obtained,
along with derived power scaling laws and upper/lower bounds on the mean
signal/interference power under IRS passive beamforming or random scattering.
Numerical results validate our analysis and demonstrate that our proposed
design outperforms the benchmark schemes with fixed BS antenna patterns or
active 3D beamforming. In particular, for aerial UEs that suffer from strong
inter-cell interference, the IRS-aided BS design provides much better QoS in
terms of the ergodic throughput performance compared with benchmarks, thanks to
the IRS-inherent double pathloss effect that helps weaken the interference.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10479" title="Abstract">arXiv:2312.10479</a> [<a href="/pdf/2312.10479" title="Download PDF">pdf</a>, <a href="/format/2312.10479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Soft Contrastive Learning-based Prompt Model for Few-shot Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiabao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Haijun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Gui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Few-shot text classification has attracted great interest in both academia
and industry due to the lack of labeled data in many fields. Different from
general text classification (e.g., topic classification), few-shot sentiment
classification is more challenging because the semantic distances among the
classes are more subtle. For instance, the semantic distances between the
sentiment labels in a positive or negative polarity (e.g., ``love" and ``joy",
``remorse" and ``sadness") are close, while the distances are large for the
sentiment labels in two opposite polarities (e.g., ``love" and ``sadness"). To
address this problem, we propose a Soft Contrastive learning-based Prompt
(\texttt{SCP}) model for few-shot sentiment analysis. First, we design a
sentiment-aware chain of thought prompt module to guide the model to predict
the sentiment from coarse grain to fine grain via a series of intermediate
reasoning steps. Then, we propose a soft contrastive learning algorithm to take
the correlation of the labels into account. A series of experiments on several
sentiment analysis datasets show the great advantages of \texttt{SCP} by
comparing it with SOTA baselines (e.g., ChatGPT).
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10482" title="Abstract">arXiv:2312.10482</a> [<a href="/pdf/2312.10482" title="Download PDF">pdf</a>, <a href="/ps/2312.10482" title="Download PostScript">ps</a>, <a href="/format/2312.10482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new method color MS-BSIF Features learning for the robust kinship  verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliradi%2C+R">Rachid Aliradi</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdealmalik Ouamane</a>, 
<a href="/search/cs?searchtype=author&query=Amrane%2C+A">Abdeslam Amrane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">the paper presents a new method color MS-BSIF learning and MS-LBP for the
kinship verification is the machine's ability to identify the genetic and blood
the relationship and its degree between the facial images of humans. Facial
verification of kinship refers to the task of training a machine to recognize
the blood relationship between a pair of faces parent and non-parent
(verification) based on features extracted from facial images, and determining
the exact type or degree of this genetic relationship. We use the LBP and color
BSIF learning features for the comparison and the TXQDA method for
dimensionality reduction and data classification. We let's test the kinship
facial verification application is namely the kinface Cornell database. This
system improves the robustness of learning while controlling efficiency. The
experimental results obtained and compared to other methods have proven the
reliability of our framework and surpass the performance of other
state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10485" title="Abstract">arXiv:2312.10485</a> [<a href="/pdf/2312.10485" title="Download PDF">pdf</a>, <a href="/format/2312.10485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation between broadcast domination and multipacking numbers on  chordal and other hyperbolic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sandip Das</a>, 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S+S">Sk Samim Islam</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+J">Joydeep Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.04882">arXiv:2308.04882</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">For a graph $ G = (V, E) $ with a vertex set $ V $ and an edge set $ E $, a
function
<br />$ f : V \rightarrow \{0, 1, 2, . . . , diam(G)\} $ is called a
\emph{broadcast} on $ G $. For each
<br />vertex $ u \in V $, if there exists a vertex $ v $ in $ G $ (possibly, $ u =
v $) such that $ f (v) &gt; 0 $ and
<br />$ d(u, v) \leq f (v) $, then $ f $ is called a dominating broadcast on $ G $.
The cost of the dominating broadcast $f$ is the quantity $ \sum_{v\in V}f(v) $.
The minimum cost of a dominating broadcast is the broadcast domination number
of $G$, denoted by $ \gamma_{b}(G) $.
<br />A multipacking is a set $ S \subseteq V $ in a
<br />graph $ G = (V, E) $ such that for every vertex $ v \in V $ and for every
integer $ r \geq 1 $, the
<br />ball of radius $ r $ around $ v $ contains at most $ r $ vertices of $ S $,
that is, there are at most
<br />$ r $ vertices in $ S $ at a distance at most $ r $ from $ v $ in $ G $. The
<br />multipacking number of $ G $ is the maximum cardinality of a multipacking of
$ G $ and
<br />is denoted by $ mp(G) $.
<br />We show that, for any connected chordal graph $G$, $\gamma_{b}(G)\leq
\big\lceil{\frac{3}{2} mp(G)\big\rceil}$. We also show that $\gamma_b(G)-mp(G)$
can be arbitrarily large for connected chordal graphs by constructing an
infinite family of connected chordal graphs such that the ratio
$\gamma_b(G)/mp(G)=10/9$, with $mp(G)$ arbitrarily large. Moreover, we show
that $\gamma_{b}(G)\leq \big\lfloor{\frac{3}{2} mp(G)+2\delta\big\rfloor} $
holds for all $\delta$-hyperbolic graphs. In addition, we provide a
polynomial-time algorithm to construct a multipacking of a $\delta$-hyperbolic
graph $G$ of size at least $ \big\lceil{\frac{2mp(G)-4\delta}{3} \big\rceil} $.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10486" title="Abstract">arXiv:2312.10486</a> [<a href="/pdf/2312.10486" title="Download PDF">pdf</a>, <a href="/format/2312.10486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Constrained Continuous Subgraph Matching Using Temporal Information  for Filtering and Backtracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Seunghwan Min</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jihoon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kunsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Giammarresi%2C+D">Dora Giammarresi</a>, 
<a href="/search/cs?searchtype=author&query=Italiano%2C+G+F">Giuseppe F. Italiano</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wook-Shin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Real-time analysis of graphs containing temporal information, such as social
media streams, Q&amp;A networks, and cyber data sources, plays an important role in
various applications. Among them, detecting patterns is one of the fundamental
graph analysis problems. In this paper, we study time-constrained continuous
subgraph matching, which detects a pattern with a strict partial order on the
edge set in real-time whenever a temporal data graph changes over time. We
propose a new algorithm based on two novel techniques. First, we introduce a
filtering technique called time-constrained matchable edge that uses temporal
information for filtering with polynomial space. Second, we develop
time-constrained pruning techniques that reduce the search space by pruning
some of the parallel edges in backtracking, utilizing temporal information.
Extensive experiments on real and synthetic datasets show that our approach
outperforms the state-of-the-art algorithm by up to two orders of magnitude in
terms of query processing time.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10490" title="Abstract">arXiv:2312.10490</a> [<a href="/pdf/2312.10490" title="Download PDF">pdf</a>, <a href="/format/2312.10490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Deep Learning for Site-Specific Movement Optimization of Aerial  Base Stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiangbin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiefeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Liqun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted to IEEE Trans. Wireless Communications on 15 Jan. 2023; revised 11 Sep. 2023; accepted 5 Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations
(ABSs) to provide wireless connectivity for ground users (GUs) in various
emergency scenarios. However, it is a NP-hard problem with exponential
complexity in $M$ and $N$, in order to maximize the coverage rate of $M$ GUs by
jointly placing $N$ ABSs with limited coverage range. The problem is further
complicated when the coverage range becomes irregular due to site-specific
blockages (e.g., buildings) on the air-ground channel, and/or when the GUs are
moving. To address the above challenges, we study a multi-ABS movement
optimization problem to maximize the average coverage rate of mobile GUs in a
site-specific environment. The Spatial Deep Learning with Multi-dimensional
Archive of Phenotypic Elites (SDL-ME) algorithm is proposed to tackle this
challenging problem by 1) partitioning the complicated ABS movement problem
into ABS placement sub-problems each spanning finite time horizon; 2) using an
encoder-decoder deep neural network (DNN) as the emulator to capture the
spatial correlation of ABSs/GUs and thereby reducing the cost of interaction
with the actual environment; 3) employing the emulator to speed up a
quality-diversity search for the optimal placement solution; and 4) proposing a
planning-exploration-serving scheme for multi-ABS movement coordination.
Numerical results demonstrate that the proposed approach significantly
outperforms the benchmark Deep Reinforcement Learning (DRL)-based method and
other two baselines in terms of average coverage rate, training time and/or
sample efficiency. Moreover, with one-time training, our proposed method can be
applied in scenarios where the number of ABSs/GUs dynamically changes on site
and/or with different/varying GU speeds, which is thus more robust and flexible
compared with conventional DRL-based methods.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10493" title="Abstract">arXiv:2312.10493</a> [<a href="/pdf/2312.10493" title="Download PDF">pdf</a>, <a href="/format/2312.10493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Multimodal Sarcasm Detection with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mengzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Can Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Despite commendable achievements made by existing work, prevailing multimodal
sarcasm detection studies rely more on textual content over visual information.
It unavoidably induces spurious correlations between textual words and labels,
thereby significantly hindering the models' generalization capability. To
address this problem, we define the task of out-of-distribution (OOD)
multimodal sarcasm detection, which aims to evaluate models' generalizability
when the word distribution is different in training and testing settings.
Moreover, we propose a novel debiasing multimodal sarcasm detection framework
with contrastive learning, which aims to mitigate the harmful effect of biased
textual factors for robust OOD generalization. In particular, we first design
counterfactual data augmentation to construct the positive samples with
dissimilar word biases and negative samples with similar word biases.
Subsequently, we devise an adapted debiasing contrastive learning mechanism to
empower the model to learn robust task-relevant features and alleviate the
adverse effect of biased words. Extensive experiments show the superiority of
the proposed framework.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10494" title="Abstract">arXiv:2312.10494</a> [<a href="/pdf/2312.10494" title="Download PDF">pdf</a>, <a href="/ps/2312.10494" title="Download PostScript">ps</a>, <a href="/format/2312.10494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Bayesian Neural Networks Weapon System Improve Predictive  Maintenance?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potter%2C+M">Michael Potter</a>, 
<a href="/search/cs?searchtype=author&query=Jun%2C+M">Miru Jun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">We implement a Bayesian inference process for Neural Networks to model the
time to failure of highly reliable weapon systems with interval-censored data
and time-varying covariates. We analyze and benchmark our approach, LaplaceNN,
on synthetic and real datasets with standard classification metrics such as
Receiver Operating Characteristic (ROC) Area Under Curve (AUC) Precision-Recall
(PR) AUC, and reliability curve visualizations.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10504" title="Abstract">arXiv:2312.10504</a> [<a href="/pdf/2312.10504" title="Download PDF">pdf</a>, <a href="/format/2312.10504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubAnom: Efficient Subgraph Anomaly Detection Framework over Dynamic  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wenkai Xiang</a> (1), 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xingzhi Guo</a> (2), 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Baojian Zhou</a> (1), 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Deqing Yang</a> (1) ((1) Fudan University, Shanghai Key Laboratory of Data Science, (2) Stony Brook University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Given a dynamic graph, the efficient tracking of anomalous subgraphs via
their node embeddings poses a significant challenge. Addressing this issue
necessitates an effective scoring mechanism and an innovative anomalous
subgraph strategy. Existing methods predominantly focus on designing scoring
strategies or employing graph structures that consider nodes in isolation,
resulting in ineffective capture of the anomalous subgraph structure
information.
<br />In this paper, we introduce SUBANOM, a novel framework for subgraph anomaly
detection that is adept at identifying anomalous subgraphs. SUBANOM has three
key components: 1) We implement current state-of-the-art dynamic embedding
methods to efficiently calculate node embeddings, thereby capturing all
node-level anomalies successfully; 2) We devise novel subgraph identification
strategies, which include k-hop and triadic-closure. These strategies form the
crucial component that can proficiently differentiate between strong and weak
neighbors, thus effectively capturing the anomaly structure information; 3) For
qualifying the anomaly subgraphs, we propose using Lp-norm-based score
aggregation functions. These iterative steps enable us to process large-scale
dynamic graphs effectively.
<br />Experiments conducted on a real-world dynamic graph underscore the efficacy
of our framework in detecting anomalous subgraphs, outperforming
state-of-the-art methods. Experimental results further signify that our
framework is a potent tool for identifying anomalous subgraphs in real-world
scenarios. For instance, the F1 score under the optimal subgraph identification
strategy, can peak at 0.6679, while the highest achievable score using the
corresponding baseline method is 0.5677.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10508" title="Abstract">arXiv:2312.10508</a> [<a href="/pdf/2312.10508" title="Download PDF">pdf</a>, <a href="/format/2312.10508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrojFair: Trojan Fairness Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mengxin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jiaqi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yi Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Q">Qian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning models have been incorporated into high-stakes sectors,
including healthcare diagnosis, loan approvals, and candidate recruitment,
among others. Consequently, any bias or unfairness in these models can harm
those who depend on such models. In response, many algorithms have emerged to
ensure fairness in deep learning. However, while the potential for harm is
substantial, the resilience of these fair deep learning models against
malicious attacks has never been thoroughly explored, especially in the context
of emerging Trojan attacks. Moving beyond prior research, we aim to fill this
void by introducing \textit{TrojFair}, a Trojan fairness attack. Unlike
existing attacks, TrojFair is model-agnostic and crafts a Trojaned model that
functions accurately and equitably for clean inputs. However, it displays
discriminatory behaviors \text{-} producing both incorrect and unfair results
\text{-} for specific groups with tainted inputs containing a trigger. TrojFair
is a stealthy Fairness attack that is resilient to existing model fairness
audition detectors since the model for clean inputs is fair. TrojFair achieves
a target group attack success rate exceeding $88.77\%$, with an average
accuracy loss less than $0.44\%$. It also maintains a high discriminative score
between the target and non-target groups across various datasets and models.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10512" title="Abstract">arXiv:2312.10512</a> [<a href="/pdf/2312.10512" title="Download PDF">pdf</a>, <a href="/format/2312.10512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value of Information and Timing-aware Scheduling for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Azeem Khan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard H. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Iera%2C+A">Antonio Iera</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Conference on Standards for Communications and Networking 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data possesses significant value as it fuels advancements in AI. However,
protecting the privacy of the data generated by end-user devices has become
crucial. Federated Learning (FL) offers a solution by preserving data privacy
during training. FL brings the model directly to User Equipments (UEs) for
local training by an access point (AP). The AP periodically aggregates trained
parameters from UEs, enhancing the model and sending it back to them. However,
due to communication constraints, only a subset of UEs can update parameters
during each global aggregation. Consequently, developing innovative scheduling
algorithms is vital to enable complete FL implementation and enhance FL
convergence. In this paper, we present a scheduling policy combining Age of
Update (AoU) concepts and data Shapley metrics. This policy considers the
freshness and value of received parameter updates from individual data sources
and real-time channel conditions to enhance FL's operational efficiency. The
proposed algorithm is simple, and its effectiveness is demonstrated through
simulations.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10515" title="Abstract">arXiv:2312.10515</a> [<a href="/pdf/2312.10515" title="Download PDF">pdf</a>, <a href="/format/2312.10515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PETDet: Proposal Enhancement for Two-Stage Fine-Grained Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wentao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Danpei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE TGRS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fine-grained object detection (FGOD) extends object detection with the
capability of fine-grained recognition. In recent two-stage FGOD methods, the
region proposal serves as a crucial link between detection and fine-grained
recognition. However, current methods overlook that some proposal-related
procedures inherited from general detection are not equally suitable for FGOD,
limiting the multi-task learning from generation, representation, to
utilization. In this paper, we present PETDet (Proposal Enhancement for
Two-stage fine-grained object detection) to better handle the sub-tasks in
two-stage FGOD methods. Firstly, an anchor-free Quality Oriented Proposal
Network (QOPN) is proposed with dynamic label assignment and attention-based
decomposition to generate high-quality oriented proposals. Additionally, we
present a Bilinear Channel Fusion Network (BCFN) to extract independent and
discriminative features of the proposals. Furthermore, we design a novel
Adaptive Recognition Loss (ARL) which offers guidance for the R-CNN head to
focus on high-quality proposals. Extensive experiments validate the
effectiveness of PETDet. Quantitative analysis reveals that PETDet with
ResNet50 reaches state-of-the-art performance on various FGOD datasets,
including FAIR1M-v1.0 (42.96 AP), FAIR1M-v2.0 (48.81 AP), MAR20 (85.91 AP) and
ShipRSImageNet (74.90 AP). The proposed method also achieves superior
compatibility between accuracy and inference speed. Our code and models will be
released at https://github.com/canoe-Z/PETDet.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10518" title="Abstract">arXiv:2312.10518</a> [<a href="/pdf/2312.10518" title="Download PDF">pdf</a>, <a href="/format/2312.10518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seq2seq for Automatic Paraphasia Detection in Aphasic Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+M">Matthew Perez</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc Le</a>, 
<a href="/search/cs?searchtype=author&query=Romana%2C+A">Amrit Romana</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Elise Jones</a>, 
<a href="/search/cs?searchtype=author&query=Licata%2C+K">Keli Licata</a>, 
<a href="/search/cs?searchtype=author&query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Paraphasias are speech errors that are often characteristic of aphasia and
they represent an important signal in assessing disease severity and subtype.
Traditionally, clinicians manually identify paraphasias by transcribing and
analyzing speech-language samples, which can be a time-consuming and burdensome
process. Identifying paraphasias automatically can greatly help clinicians with
the transcription process and ultimately facilitate more efficient and
consistent aphasia assessment. Previous research has demonstrated the
feasibility of automatic paraphasia detection by training an automatic speech
recognition (ASR) model to extract transcripts and then training a separate
paraphasia detection model on a set of hand-engineered features. In this paper,
we propose a novel, sequence-to-sequence (seq2seq) model that is trained
end-to-end (E2E) to perform both ASR and paraphasia detection tasks. We show
that the proposed model outperforms the previous state-of-the-art approach for
both word-level and utterance-level paraphasia detection tasks and provide
additional follow-up evaluations to further understand the proposed model
behavior.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10523" title="Abstract">arXiv:2312.10523</a> [<a href="/pdf/2312.10523" title="Download PDF">pdf</a>, <a href="/format/2312.10523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paloma: A Benchmark for Evaluating Language Model Fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+V">Valentin Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A+H">Ananya Harsh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+E+P">Evan Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://paloma.allen.ai/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language models (LMs) commonly report perplexity on monolithic data held out
from training. Implicitly or explicitly, this data is composed of
domains$\unicode{x2013}$varying distributions of language. Rather than assuming
perplexity on one distribution extrapolates to others, Perplexity Analysis for
Language Model Assessment (Paloma), measures LM fit to 585 text domains,
ranging from nytimes.com to r/depression on Reddit. We invite submissions to
our benchmark and organize results by comparability based on compliance with
guidelines such as removal of benchmark contamination from pretraining.
Submissions can also record parameter and training token count to make
comparisons of Pareto efficiency for performance as a function of these
measures of cost. We populate our benchmark with results from 6 baselines
pretrained on popular corpora. In case studies, we demonstrate analyses that
are possible with Paloma, such as finding that pretraining without data beyond
Common Crawl leads to inconsistent fit to many domains.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10524" title="Abstract">arXiv:2312.10524</a> [<a href="/pdf/2312.10524" title="Download PDF">pdf</a>, <a href="/format/2312.10524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Evaluation of ChatGPT Reliability Through Multilingual  Inquiries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puttaparthi%2C+P+C+R">Poorna Chander Reddy Puttaparthi</a>, 
<a href="/search/cs?searchtype=author&query=Deo%2C+S+S">Soham Sanjay Deo</a>, 
<a href="/search/cs?searchtype=author&query=Gul%2C+H">Hakan Gul</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Weiyi Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhe Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">ChatGPT is currently the most popular large language model (LLM), with over
100 million users, making a significant impact on people's lives. However, due
to the presence of jailbreak vulnerabilities, ChatGPT might have negative
effects on people's lives, potentially even facilitating criminal activities.
Testing whether ChatGPT can cause jailbreak is crucial because it can enhance
ChatGPT's security, reliability, and social responsibility. Inspired by
previous research revealing the varied performance of LLMs in different
language translations, we suspected that wrapping prompts in multiple languages
might lead to ChatGPT jailbreak. To investigate this, we designed a study with
a fuzzing testing approach to analyzing ChatGPT's cross-linguistic proficiency.
Our study includes three strategies by automatically posing different formats
of malicious questions to ChatGPT: (1) each malicious question involving only
one language, (2) multilingual malicious questions, (3) specifying that ChatGPT
responds in a language different from the prompts. In addition, we also combine
our strategies by utilizing prompt injection templates to wrap the three
aforementioned types of questions. We examined a total of 7,892 Q&amp;A data
points, discovering that multilingual wrapping can indeed lead to ChatGPT's
jailbreak, with different wrapping methods having varying effects on jailbreak
probability. Prompt injection can amplify the probability of jailbreak caused
by multilingual wrapping. This work provides insights for OpenAI developers to
enhance ChatGPT's support for language diversity and inclusion.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10525" title="Abstract">arXiv:2312.10525</a> [<a href="/pdf/2312.10525" title="Download PDF">pdf</a>, <a href="/format/2312.10525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Architecture and Task Plan Co-Adaptation for Autonomous Robots  with Metaplan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zwanepol%2C+J+M">Jeroen M. Zwanepol</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+G+R">Gustavo Rezende Silva</a>, 
<a href="/search/cs?searchtype=author&query=Corbato%2C+C+H">Carlos Hern&#xe1;ndez Corbato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous robots need to be able to handle uncertainties when deployed in
the real world. For the robot to be able to robustly work in such an
environment, it needs to be able to adapt both its architecture as well as its
task plan. Architecture adaptation and task plan adaptation are mutually
dependent, and therefore require the system to apply runtime architecture and
task plan co-adaptation. This work presents Metaplan, which makes use of models
of the robot and its environment, together with a PDDL planner to apply runtime
architecture and task plan co-adaptation. Metaplan is designed to be easily
reusable across different domains. Metaplan is shown to successfully perform
runtime architecture and task plan co-adaptation with a self-adaptive unmanned
underwater vehicle exemplar, and its reusability is demonstrated by applying it
to an unmanned ground vehicle.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10526" title="Abstract">arXiv:2312.10526</a> [<a href="/pdf/2312.10526" title="Download PDF">pdf</a>, <a href="/format/2312.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Nash Equilibrium to Social Optimum and vice versa: a Mean Field  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmona%2C+R">Rene Carmona</a>, 
<a href="/search/cs?searchtype=author&query=Dayanikli%2C+G">Gokce Dayanikli</a>, 
<a href="/search/cs?searchtype=author&query=Delarue%2C+F">Francois Delarue</a>, 
<a href="/search/cs?searchtype=author&query=Lauriere%2C+M">Mathieu Lauriere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Mean field games (MFG) and mean field control (MFC) problems have been
introduced to study large populations of strategic players. They correspond
respectively to non-cooperative or cooperative scenarios, where the aim is to
find the Nash equilibrium and social optimum. These frameworks provide
approximate solutions to situations with a finite number of players and have
found a wide range of applications, from economics to biology and machine
learning. In this paper, we study how the players can pass from a
non-cooperative to a cooperative regime, and vice versa. The first direction is
reminiscent of mechanism design, in which the game's definition is modified so
that non-cooperative players reach an outcome similar to a cooperative
scenario. The second direction studies how players that are initially
cooperative gradually deviate from a social optimum to reach a Nash equilibrium
when they decide to optimize their individual cost similar to the free rider
phenomenon. To formalize these connections, we introduce two new classes of
games which lie between MFG and MFC: $\lambda$-interpolated mean field games,
in which the cost of an individual player is a $\lambda$-interpolation of the
MFG and the MFC costs, and $p$-partial mean field games, in which a proportion
$p$ of the population deviates from the social optimum by playing the game
non-cooperatively. We conclude the paper by providing an algorithm for myopic
players to learn a $p$-partial mean field equilibrium, and we illustrate it on
a stylized model.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10527" title="Abstract">arXiv:2312.10527</a> [<a href="/pdf/2312.10527" title="Download PDF">pdf</a>, <a href="/format/2312.10527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoCoGen: Physically-Consistent and Conditioned Score-based Generative  Models for Forward and Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+C">Christian Jacobsen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yilin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Duraisamy%2C+K">Karthik Duraisamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent advances in generative artificial intelligence have had a significant
impact on diverse domains spanning computer vision, natural language
processing, and drug discovery. This work extends the reach of generative
models into physical problem domains, particularly addressing the efficient
enforcement of physical laws and conditioning for forward and inverse problems
involving partial differential equations (PDEs). Our work introduces two key
contributions: firstly, we present an efficient approach to promote consistency
with the underlying PDE. By incorporating discretized information into
score-based generative models, our method generates samples closely aligned
with the true data distribution, showcasing residuals comparable to data
generated through conventional PDE solvers, significantly enhancing fidelity.
Secondly, we showcase the potential and versatility of score-based generative
models in various physics tasks, specifically highlighting surrogate modeling
as well as probabilistic field reconstruction and inversion from sparse
measurements. A robust foundation is laid by designing unconditional
score-based generative models that utilize reversible probability flow ordinary
differential equations. Leveraging conditional models that require minimal
training, we illustrate their flexibility when combined with a frozen
unconditional model. These conditional models generate PDE solutions by
incorporating parameters, macroscopic quantities, or partial field measurements
as guidance. The results illustrate the inherent flexibility of score-based
generative models and explore the synergy between unconditional score-based
generative models and the present physically-consistent sampling approach,
emphasizing the power and flexibility in solving for and inverting physical
fields governed by differential equations, and in other scientific machine
learning tasks.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10528" title="Abstract">arXiv:2312.10528</a> [<a href="/pdf/2312.10528" title="Download PDF">pdf</a>, <a href="/ps/2312.10528" title="Download PostScript">ps</a>, <a href="/format/2312.10528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Linguistic Offensive Language Detection: BERT-Based Analysis of  Bengali, Assamese, &amp; Bodo Conversational Hateful Content from Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mim%2C+J+K">Jhuma Kabir Mim</a>, 
<a href="/search/cs?searchtype=author&query=Oussalah%2C+M">Mourad Oussalah</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+A">Akash Singhal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In today's age, social media reigns as the paramount communication platform,
providing individuals with the avenue to express their conjectures,
intellectual propositions, and reflections. Unfortunately, this freedom often
comes with a downside as it facilitates the widespread proliferation of hate
speech and offensive content, leaving a deleterious impact on our world. Thus,
it becomes essential to discern and eradicate such offensive material from the
realm of social media. This article delves into the comprehensive results and
key revelations from the HASOC-2023 offensive language identification result.
The primary emphasis is placed on the meticulous detection of hate speech
within the linguistic domains of Bengali, Assamese, and Bodo, forming the
framework for Task 4: Annihilate Hates. In this work, we used BERT models,
including XML-Roberta, L3-cube, IndicBERT, BenglaBERT, and BanglaHateBERT. The
research outcomes were promising and showed that XML-Roberta-lagre performed
better than monolingual models in most cases. Our team 'TeamBD' achieved rank
3rd for Task 4 - Assamese, &amp; 5th for Bengali.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10529" title="Abstract">arXiv:2312.10529</a> [<a href="/pdf/2312.10529" title="Download PDF">pdf</a>, <a href="/format/2312.10529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers in Unsupervised Structure-from-Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chawla%2C+H">Hemang Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+A">Arnav Varma</a>, 
<a href="/search/cs?searchtype=author&query=Arani%2C+E">Elahe Arani</a>, 
<a href="/search/cs?searchtype=author&query=Zonooz%2C+B">Bahram Zonooz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Joint Conference on Computer Vision, Imaging and Computer Graphics. Cham: Springer Nature Switzerland, 2022. Published at "Communications in Computer and Information Science, vol 1815. Springer Nature". arXiv admin note: text overlap with <a href="/abs/2202.03131">arXiv:2202.03131</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformers have revolutionized deep learning based computer vision with
improved performance as well as robustness to natural corruptions and
adversarial attacks. Transformers are used predominantly for 2D vision tasks,
including image classification, semantic segmentation, and object detection.
However, robots and advanced driver assistance systems also require 3D scene
understanding for decision making by extracting structure-from-motion (SfM). We
propose a robust transformer-based monocular SfM method that learns to predict
monocular pixel-wise depth, ego vehicle's translation and rotation, as well as
camera's focal length and principal point, simultaneously. With experiments on
KITTI and DDAD datasets, we demonstrate how to adapt different vision
transformers and compare them against contemporary CNN-based methods. Our study
shows that transformer-based architecture, though lower in run-time efficiency,
achieves comparable performance while being more robust against natural
corruptions, as well as untargeted and targeted attacks.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10531" title="Abstract">arXiv:2312.10531</a> [<a href="/pdf/2312.10531" title="Download PDF">pdf</a>, <a href="/format/2312.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Train Neural Field Representations: A Comprehensive Study and  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papa%2C+S">Samuele Papa</a>, 
<a href="/search/cs?searchtype=author&query=Valperga%2C+R">Riccardo Valperga</a>, 
<a href="/search/cs?searchtype=author&query=Knigge%2C+D">David Knigge</a>, 
<a href="/search/cs?searchtype=author&query=Kofinas%2C+M">Miltiadis Kofinas</a>, 
<a href="/search/cs?searchtype=author&query=Lippe%2C+P">Phillip Lippe</a>, 
<a href="/search/cs?searchtype=author&query=Sonke%2C+J">Jan-Jakob Sonke</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural fields (NeFs) have recently emerged as a versatile method for modeling
signals of various modalities, including images, shapes, and scenes.
Subsequently, a number of works have explored the use of NeFs as
representations for downstream tasks, e.g. classifying an image based on the
parameters of a NeF that has been fit to it. However, the impact of the NeF
hyperparameters on their quality as downstream representation is scarcely
understood and remains largely unexplored. This is in part caused by the large
amount of time required to fit datasets of neural fields.
<br />In this work, we propose $\verb|fit-a-nef|$, a JAX-based library that
leverages parallelization to enable fast optimization of large-scale NeF
datasets, resulting in a significant speed-up. With this library, we perform a
comprehensive study that investigates the effects of different hyperparameters
-- including initialization, network architecture, and optimization strategies
-- on fitting NeFs for downstream tasks. Our study provides valuable insights
on how to train NeFs and offers guidance for optimizing their effectiveness in
downstream applications. Finally, based on the proposed library and our
analysis, we propose Neural Field Arena, a benchmark consisting of neural field
variants of popular vision datasets, including MNIST, CIFAR, variants of
ImageNet, and ShapeNetv2. Our library and the Neural Field Arena will be
open-sourced to introduce standardized benchmarking and promote further
research on neural fields.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10534" title="Abstract">arXiv:2312.10534</a> [<a href="/pdf/2312.10534" title="Download PDF">pdf</a>, <a href="/format/2312.10534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Robustness of Model Attributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamath%2C+S">Sandesh Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sankalp Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Amit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+V+N">Vineeth N Balasubramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For machine learning models to be reliable and trustworthy, their decisions
must be interpretable. As these models find increasing use in safety-critical
applications, it is important that not just the model predictions but also
their explanations (as feature attributions) be robust to small
human-imperceptible input perturbations. Recent works have shown that many
attribution methods are fragile and have proposed improvements in either these
methods or the model training. We observe two main causes for fragile
attributions: first, the existing metrics of robustness (e.g., top-k
intersection) over-penalize even reasonable local shifts in attribution,
thereby making random perturbations to appear as a strong attack, and second,
the attribution can be concentrated in a small region even when there are
multiple important parts in an image. To rectify this, we propose simple ways
to strengthen existing metrics and attribution methods that incorporate
locality of pixels in robustness metrics and diversity of pixel locations in
attributions. Towards the role of model training in attributional robustness,
we empirically observe that adversarially trained models have more robust
attributions on smaller datasets, however, this advantage disappears in larger
datasets. Code is available at https://github.com/ksandeshk/LENS.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10536" title="Abstract">arXiv:2312.10536</a> [<a href="/pdf/2312.10536" title="Download PDF">pdf</a>, <a href="/format/2312.10536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USTHB at NADI 2023 shared task: Exploring Preprocessing and Feature  Engineering Strategies for Arabic Dialect Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lichouri%2C+M">Mohamed Lichouri</a>, 
<a href="/search/cs?searchtype=author&query=Lounnas%2C+K">Khaled Lounnas</a>, 
<a href="/search/cs?searchtype=author&query=Zitouni%2C+A">Aicha Zitouni</a>, 
<a href="/search/cs?searchtype=author&query=Latrache%2C+H">Houda Latrache</a>, 
<a href="/search/cs?searchtype=author&query=Djeradi%2C+R">Rachida Djeradi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the conference proceedings of ArabicNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we conduct an in-depth analysis of several key factors
influencing the performance of Arabic Dialect Identification NADI'2023, with a
specific focus on the first subtask involving country-level dialect
identification. Our investigation encompasses the effects of surface
preprocessing, morphological preprocessing, FastText vector model, and the
weighted concatenation of TF-IDF features. For classification purposes, we
employ the Linear Support Vector Classification (LSVC) model. During the
evaluation phase, our system demonstrates noteworthy results, achieving an F1
score of 62.51%. This achievement closely aligns with the average F1 scores
attained by other systems submitted for the first subtask, which stands at
72.91%.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10537" title="Abstract">arXiv:2312.10537</a> [<a href="/pdf/2312.10537" title="Download PDF">pdf</a>, <a href="/ps/2312.10537" title="Download PostScript">ps</a>, <a href="/format/2312.10537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpolation by integrals on balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruno%2C+L+B">Ludovico Bruni Bruno</a>, 
<a href="/search/math?searchtype=author&query=Elefante%2C+G">Giacomo Elefante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we blend interpolation theory with numerical integration,
constructing an interpolator based on integrals over $n$-dimensional balls. We
show that, under hypotheses on the radius of the $n$-balls, the problem can be
treated as an interpolation problem both on a collection of $(n-1)$-spheres $
S^{n-1} $ and multivariate point sets, for which a wide literature is
available. With the aim of exact quadrature and cubature formulae, we offer a
neat strategy for the exact computation of the Vandermonde matrix of the
problem and propose a meaningful Lebesgue constant. Problematic situations are
evidenced and a charming aspect is enlightened: the majority of the theoretical
results only deal with the centre of the domains of integration and are not
really sensitive to their radius. We flank our theoretical results by a large
amount of comprehensive numerical examples.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10539" title="Abstract">arXiv:2312.10539</a> [<a href="/pdf/2312.10539" title="Download PDF">pdf</a>, <a href="/format/2312.10539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DETER: Detecting Edited Regions for Deterring Generative Manipulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ye Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dharmasiri%2C+A">Amaya Dharmasiri</a>, 
<a href="/search/cs?searchtype=author&query=Russakovsky%2C+O">Olga Russakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contribute equally to this work. Project page at <a href="https://deter2024.github.io/deter/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative AI capabilities have grown substantially in recent years, raising
renewed concerns about potential malicious use of generated data, or "deep
fakes". However, deep fake datasets have not kept up with generative AI
advancements sufficiently to enable the development of deep fake detection
technology which can meaningfully alert human users in real-world settings.
Existing datasets typically use GAN-based models and introduce spurious
correlations by always editing similar face regions. To counteract the
shortcomings, we introduce DETER, a large-scale dataset for DETEcting edited
image Regions and deterring modern advanced generative manipulations. DETER
includes 300,000 images manipulated by four state-of-the-art generators with
three editing operations: face swapping (a standard coarse image manipulation),
inpainting (a novel manipulation for deep fake datasets), and attribute editing
(a subtle fine-grained manipulation). While face swapping and attribute editing
are performed on similar face regions such as eyes and nose, the inpainting
operation can be performed on random image regions, removing the spurious
correlations of previous datasets. Careful image post-processing is performed
to ensure deep fakes in DETER look realistic, and human studies confirm that
human deep fake detection rate on DETER is 20.4% lower than on other fake
datasets. Equipped with the dataset, we conduct extensive experiments and
break-down analysis using our rich annotations and improved benchmark
protocols, revealing future directions and the next set of challenges in
developing reliable regional fake detection models.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10540" title="Abstract">arXiv:2312.10540</a> [<a href="/pdf/2312.10540" title="Download PDF">pdf</a>, <a href="/format/2312.10540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VecFusion: Vector Font Generation with Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thamizharasan%2C+V">Vikas Thamizharasan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Difan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shantanu Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Michael Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+O">Oliver Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+A">Alec Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Kalogerakis%2C+E">Evangelos Kalogerakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present VecFusion, a new neural architecture that can generate vector
fonts with varying topological structures and precise control point positions.
Our approach is a cascaded diffusion model which consists of a raster diffusion
model followed by a vector diffusion model. The raster model generates
low-resolution, rasterized fonts with auxiliary control point information,
capturing the global style and shape of the font, while the vector model
synthesizes vector fonts conditioned on the low-resolution raster fonts from
the first stage. To synthesize long and complex curves, our vector diffusion
model uses a transformer architecture and a novel vector representation that
enables the modeling of diverse vector geometry and the precise prediction of
control points. Our experiments show that, in contrast to previous generative
models for vector graphics, our new cascaded vector diffusion model generates
higher quality vector fonts, with complex structures and diverse styles.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10547" title="Abstract">arXiv:2312.10547</a> [<a href="/pdf/2312.10547" title="Download PDF">pdf</a>, <a href="/format/2312.10547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing RAN Slicing with Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+S">Shu-ping Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Menglei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sydir%2C+J">Jerry Sydir</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages. 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Dynamic radio resource management (RRM) in wireless networks presents
significant challenges, particularly in the context of Radio Access Network
(RAN) slicing. This technology, crucial for catering to varying user
requirements, often grapples with complex optimization scenarios. Existing
Reinforcement Learning (RL) approaches, while achieving good performance in RAN
slicing, typically rely on online algorithms or behavior cloning. These methods
necessitate either continuous environmental interactions or access to
high-quality datasets, hindering their practical deployment. Towards addressing
these limitations, this paper introduces offline RL to solving the RAN slicing
problem, marking a significant shift towards more feasible and adaptive RRM
methods. We demonstrate how offline RL can effectively learn near-optimal
policies from sub-optimal datasets, a notable advancement over existing
practices. Our research highlights the inherent flexibility of offline RL,
showcasing its ability to adjust policy criteria without the need for
additional environmental interactions. Furthermore, we present empirical
evidence of the efficacy of offline RL in adapting to various service-level
requirements, illustrating its potential in diverse RAN slicing scenarios.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10549" title="Abstract">arXiv:2312.10549</a> [<a href="/pdf/2312.10549" title="Download PDF">pdf</a>, <a href="/ps/2312.10549" title="Download PostScript">ps</a>, <a href="/format/2312.10549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catastrophic Forgetting in Deep Learning: A Comprehensive Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aleixo%2C+E+L">Everton L. Aleixo</a>, 
<a href="/search/cs?searchtype=author&query=Colonna%2C+J+G">Juan G. Colonna</a>, 
<a href="/search/cs?searchtype=author&query=Cristo%2C+M">Marco Cristo</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+E">Everlandio Fernandes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep Learning models have achieved remarkable performance in tasks such as
image classification or generation, often surpassing human accuracy. However,
they can struggle to learn new tasks and update their knowledge without access
to previous data, leading to a significant loss of accuracy known as
Catastrophic Forgetting (CF). This phenomenon was first observed by McCloskey
and Cohen in 1989 and remains an active research topic. Incremental learning
without forgetting is widely recognized as a crucial aspect in building better
AI systems, as it allows models to adapt to new tasks without losing the
ability to perform previously learned ones. This article surveys recent studies
that tackle CF in modern Deep Learning models that use gradient descent as
their learning algorithm. Although several solutions have been proposed, a
definitive solution or consensus on assessing CF is yet to be established. The
article provides a comprehensive review of recent solutions, proposes a
taxonomy to organize them, and identifies research gaps in this area.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10550" title="Abstract">arXiv:2312.10550</a> [<a href="/pdf/2312.10550" title="Download PDF">pdf</a>, <a href="/format/2312.10550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortized Reparametrization: Efficient and Scalable Variational  Inference for Latent SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Course%2C+K">Kevin Course</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+P+B">Prasanth B. Nair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Advances in Neural Information Processing Systems. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of inferring latent stochastic differential equations
(SDEs) with a time and memory cost that scales independently with the amount of
data, the total length of the time series, and the stiffness of the approximate
differential equations. This is in stark contrast to typical methods for
inferring latent differential equations which, despite their constant memory
cost, have a time complexity that is heavily dependent on the stiffness of the
approximate differential equation. We achieve this computational advancement by
removing the need to solve differential equations when approximating gradients
using a novel amortization strategy coupled with a recently derived
reparametrization of expectations under linear SDEs. We show that, in practice,
this allows us to achieve similar performance to methods based on adjoint
sensitivities with more than an order of magnitude fewer evaluations of the
model in training.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10551" title="Abstract">arXiv:2312.10551</a> [<a href="/pdf/2312.10551" title="Download PDF">pdf</a>, <a href="/format/2312.10551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Regional Road Transport Emissions From Satellite Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horsler%2C+A">Adam Horsler</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+J">Jake Baker</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+P+M+B">Pedro M. Baiz. V</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, submitted to CVPR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper presents a novel two-part pipeline for monitoring progress towards
the UN Sustainable Development Goals (SDG's) related to Climate Action and
Sustainable Cities and Communities. The pipeline consists of two main parts:
the first part takes a raw satellite image of a motorway section and produces
traffic count predictions for count sites within the image; the second part
takes these predicted traffic counts and other variables to produce estimates
of Local Authority (LA) motorway Average Annual Daily Traffic (AADT) and
Greenhouse Gas (GHG) emissions on a per vehicle type basis. We also provide
flexibility to the pipeline by implementing a novel method for estimating
emissions when data on AADT per vehicle type or/and live vehicle speeds are not
available. Finally, we extend the pipeline to also estimate LA A-Roads and
minor roads AADT and GHG emissions. We treat the 2017 year as training and 2018
as the test year. Results show that it is possible to predict AADT and GHG
emissions from satellite imagery, with motorway test year $R^2$ values of 0.92
and 0.78 respectively, and for A-roads' $R^2$ values of 0.94 and 0.98. This
end-to-end two-part pipeline builds upon and combines previous research in road
transportation traffic flows, speed estimation from satellite imagery, and
emissions estimation, providing new contributions and insights into these
areas.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10553" title="Abstract">arXiv:2312.10553</a> [<a href="/pdf/2312.10553" title="Download PDF">pdf</a>, <a href="/format/2312.10553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-Enhanced Prediction of Surface Smoothness for Inertial  Confinement Fusion Target Polishing Using Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alexos%2C+A">Antonios Alexos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+A">Akash Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Kshitij Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+S">Sean Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Baldi%2C+P">Pierre Baldi</a>, 
<a href="/search/cs?searchtype=author&query=Bukkapatnam%2C+S">Satish Bukkapatnam</a>, 
<a href="/search/cs?searchtype=author&query=Bhandarkar%2C+S">Suhas Bhandarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Extended Abstract in AIM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In Inertial Confinement Fusion (ICF) process, roughly a 2mm spherical shell
made of high density carbon is used as target for laser beams, which compress
and heat it to energy levels needed for high fusion yield. These shells are
polished meticulously to meet the standards for a fusion shot. However, the
polishing of these shells involves multiple stages, with each stage taking
several hours. To make sure that the polishing process is advancing in the
right direction, we are able to measure the shell surface roughness. This
measurement, however, is very labor-intensive, time-consuming, and requires a
human operator. We propose to use machine learning models that can predict
surface roughness based on the data collected from a vibration sensor that is
connected to the polisher. Such models can generate surface roughness of the
shells in real-time, allowing the operator to make any necessary changes to the
polishing for optimal result.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10555" title="Abstract">arXiv:2312.10555</a> [<a href="/pdf/2312.10555" title="Download PDF">pdf</a>, <a href="/ps/2312.10555" title="Download PostScript">ps</a>, <a href="/format/2312.10555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation for Secure Ultra-Reliable Low-Latency-Communication  in IoT Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asbaghi%2C+S+S">Solmaz Sorkhi Asbaghi</a>, 
<a href="/search/eess?searchtype=author&query=Feghhi%2C+M+M">Mahmood Mohassel Feghhi</a>, 
<a href="/search/eess?searchtype=author&query=niya%2C+J+M">Javad Musevi niya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, Accepted for publication in Journal of Communication Engineering, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The Internet of Things (IoT) has a significant demand in society due to its
features, and it is constantly improving. In the context of wireless
technology, Ultra-reliable and low-latency communication (URLLC) is one of the
essential and challenging services in fifth-generation (5G) networks and
beyond. The research on URLLC is still in its early stages due to its
conflicting requirements, regarding high reliability and low latency. In this
paper, we study the performance of secure short-packet communications and
resource allocation in IoT systems. To this end, we investigate a health center
automation, where the goal of the access point is to send critical messages to
devices without eavesdropping. In this context, our goal is to maximize the
weighted sum throughput and minimize the total transmit power, respectively.
The problems of maximizing the weighted sum throughput, and minimizing the
total transmit power are non-convex and hard to solve. To overcome this
challenge, we use efficient mathematical techniques, such as the block
coordinate descent (BCD) method and gradient ascent algorithm; we also use
estimation methods such as Ralston, Heun, and forward-backward, in the
derivative part of the gradient ascent algorithm. The simulation results show
the performance advantages of the BCD algorithm and the gradient ascent in the
short packet transmission scheme, also the simulation results show the
superiority of the proposed methods in most cases.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10556" title="Abstract">arXiv:2312.10556</a> [<a href="/pdf/2312.10556" title="Download PDF">pdf</a>, <a href="/format/2312.10556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Similarity Learning Loss Functions in Data Transformation for Class  Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horna%2C+D">Damian Horna</a>, 
<a href="/search/cs?searchtype=author&query=Mateusz%2C+L">Lango Mateusz</a>, 
<a href="/search/cs?searchtype=author&query=Stefanowski%2C+J">Jerzy Stefanowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint is an extended version of the paper presented at LIDTA'2023 workshop at ECMLPKDD202
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Improving the classification of multi-class imbalanced data is more difficult
than its two-class counterpart. In this paper, we use deep neural networks to
train new representations of tabular multi-class data. Unlike the typically
developed re-sampling pre-processing methods, our proposal modifies the
distribution of features, i.e. the positions of examples in the learned
embedded representation, and it does not modify the class sizes. To learn such
embedded representations we introduced various definitions of triplet loss
functions: the simplest one uses weights related to the degree of class
imbalance, while the next proposals are intended for more complex distributions
of examples and aim to generate a safe neighborhood of minority examples.
Similarly to the resampling approaches, after applying such preprocessing,
different classifiers can be trained on new representations. Experiments with
popular multi-class imbalanced benchmark data sets and three classifiers showed
the advantage of the proposed approach over popular pre-processing methods as
well as basic versions of neural networks with classical loss function
formulations.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10557" title="Abstract">arXiv:2312.10557</a> [<a href="/pdf/2312.10557" title="Download PDF">pdf</a>, <a href="/format/2312.10557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Environment Robustness of Deep Reinforcement Learning  Approaches for Autonomous Racing Using Bayesian Optimization-based Curriculum  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+R">Rohan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+P">Prishita Ray</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+M">Mark Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IROS 2023 Workshop on Learning Robot Super Autonomy. The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep reinforcement learning (RL) approaches have been broadly applied to a
large number of robotics tasks, such as robot manipulation and autonomous
driving. However, an open problem in deep RL is learning policies that are
robust to variations in the environment, which is an important condition for
such systems to be deployed into real-world, unstructured settings. Curriculum
learning is one approach that has been applied to improve generalization
performance in both supervised and reinforcement learning domains, but
selecting the appropriate curriculum to achieve robustness can be a
user-intensive process. In our work, we show that performing probabilistic
inference of the underlying curriculum-reward function using Bayesian
Optimization can be a promising technique for finding a robust curriculum. We
demonstrate that a curriculum found with Bayesian optimization can outperform a
vanilla deep RL agent and a hand-engineered curriculum in the domain of
autonomous racing with obstacle avoidance. Our code is available at
https://github.com/PRISHIta123/Curriculum_RL_for_Driving.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10560" title="Abstract">arXiv:2312.10560</a> [<a href="/pdf/2312.10560" title="Download PDF">pdf</a>, <a href="/format/2312.10560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Dense Feed-Forward Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balderas%2C+L">Luis Balderas</a>, 
<a href="/search/cs?searchtype=author&query=Lastra%2C+M">Miguel Lastra</a>, 
<a href="/search/cs?searchtype=author&query=Ben%C3%ADtez%2C+J+M">Jos&#xe9; M. Ben&#xed;tez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks, Volume 171, 2024, Pages 229-241, ISSN 0893-6080,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning models have been widely used during the last decade due to
their outstanding learning and abstraction capacities. However, one of the main
challenges any scientist has to face using deep learning models is to establish
the network's architecture. Due to this difficulty, data scientists usually
build over complex models and, as a result, most of them result computationally
intensive and impose a large memory footprint, generating huge costs,
contributing to climate change and hindering their use in computational-limited
devices. In this paper, we propose a novel feed-forward neural network
constructing method based on pruning and transfer learning. Its performance has
been thoroughly assessed in classification and regression problems. Without any
accuracy loss, our approach can compress the number of parameters by more than
70%. Even further, choosing the pruning parameter carefully, most of the
refined models outperform original ones. We also evaluate the transfer learning
level comparing the refined model and the original one training from scratch a
neural network with the same hyper parameters as the optimized model. The
results obtained show that our constructing method not only helps in the design
of more efficient models but also more effective ones.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10561" title="Abstract">arXiv:2312.10561</a> [<a href="/pdf/2312.10561" title="Download PDF">pdf</a>, <a href="/format/2312.10561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Accelerators for Graph Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shivdikar%2C+K">Kaustubh Shivdikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Northeastern University Doctoral Dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of Graph Neural Networks (GNNs) has revolutionized the field of
machine learning, offering a novel paradigm for learning on graph-structured
data. Unlike traditional neural networks, GNNs are capable of capturing complex
relationships and dependencies inherent in graph data, making them particularly
suited for a wide range of applications including social network analysis,
molecular chemistry, and network security. The impact of GNNs in these domains
is profound, enabling more accurate models and predictions, and thereby
contributing significantly to advancements in these fields.
<br />GNNs, with their unique structure and operation, present new computational
challenges compared to conventional neural networks. This requires
comprehensive benchmarking and a thorough characterization of GNNs to obtain
insight into their computational requirements and to identify potential
performance bottlenecks. In this thesis, we aim to develop a better
understanding of how GNNs interact with the underlying hardware and will
leverage this knowledge as we design specialized accelerators and develop new
optimizations, leading to more efficient and faster GNN computations.
<br />Synthesizing these insights and optimizations, we design a state-of-the-art
hardware accelerator capable of efficiently handling various GNN workloads. Our
accelerator architecture is built on our characterization of GNN computational
demands, providing clear motivation for our approach. Furthermore, we extend
our exploration to emerging GNN workloads in the domain of graph neural
networks. This exploration into novel models underlines our comprehensive
approach, as we strive to enable accelerators that are not just performant, but
also versatile, able to adapt to the evolving landscape of graph computing.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10569" title="Abstract">arXiv:2312.10569</a> [<a href="/pdf/2312.10569" title="Download PDF">pdf</a>, <a href="/format/2312.10569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Causal Inference for Analyzing Wearable, Sensor, and  Distributional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katta%2C+S">Srikar Katta</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+H">Harsh Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Volfovsky%2C+A">Alexander Volfovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">Many modern causal questions ask how treatments affect complex outcomes that
are measured using wearable devices and sensors. Current analysis approaches
require summarizing these data into scalar statistics (e.g., the mean), but
these summaries can be misleading. For example, disparate distributions can
have the same means, variances, and other statistics. Researchers can overcome
the loss of information by instead representing the data as distributions. We
develop an interpretable method for distributional data analysis that ensures
trustworthy and robust decision-making: Analyzing Distributional Data via
Matching After Learning to Stretch (ADD MALTS). We (i) provide analytical
guarantees of the correctness of our estimation strategy, (ii) demonstrate via
simulation that ADD MALTS outperforms other distributional data analysis
methods at estimating treatment effects, and (iii) illustrate ADD MALTS'
ability to verify whether there is enough cohesion between treatment and
control units within subpopulations to trustworthily estimate treatment
effects. We demonstrate ADD MALTS' utility by studying the effectiveness of
continuous glucose monitors in mitigating diabetes risks.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10570" title="Abstract">arXiv:2312.10570</a> [<a href="/pdf/2312.10570" title="Download PDF">pdf</a>, <a href="/format/2312.10570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarially Balanced Representation for Continuous Treatment Effect  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+A">Amirreza Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Ester%2C+M">Martin Ester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Individual treatment effect (ITE) estimation requires adjusting for the
covariate shift between populations with different treatments, and deep
representation learning has shown great promise in learning a balanced
representation of covariates. However the existing methods mostly consider the
scenario of binary treatments. In this paper, we consider the more practical
and challenging scenario in which the treatment is a continuous variable (e.g.
dosage of a medication), and we address the two main challenges of this setup.
We propose the adversarial counterfactual regression network (ACFR) that
adversarially minimizes the representation imbalance in terms of KL divergence,
and also maintains the impact of the treatment value on the outcome prediction
by leveraging an attention mechanism. Theoretically we demonstrate that ACFR
objective function is grounded in an upper bound on counterfactual outcome
prediction error. Our experimental evaluation on semi-synthetic datasets
demonstrates the empirical superiority of ACFR over a range of state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10571" title="Abstract">arXiv:2312.10571</a> [<a href="/pdf/2312.10571" title="Download PDF">pdf</a>, <a href="/format/2312.10571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Reasoning for Robotic Assembly: From Sequence Inference to  Contact Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D+K">Devesh K. Jha</a>, 
<a href="/search/cs?searchtype=author&query=Romeres%2C+D">Diego Romeres</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingfeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Cherian%2C+A">Anoop Cherian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary video is available at <a href="https://www.youtube.com/watch?v=XNYkWSHkAaU">this https URL</a>&amp;ab_channel=MitsubishiElectricResearchLabs%28MERL%29
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automating the assembly of objects from their parts is a complex problem with
innumerable applications in manufacturing, maintenance, and recycling. Unlike
existing research, which is limited to target segmentation, pose regression, or
using fixed target blueprints, our work presents a holistic multi-level
framework for part assembly planning consisting of part assembly sequence
inference, part motion planning, and robot contact optimization. We present the
Part Assembly Sequence Transformer (PAST) -- a sequence-to-sequence neural
network -- to infer assembly sequences recursively from a target blueprint. We
then use a motion planner and optimization to generate part movements and
contacts. To train PAST, we introduce D4PAS: a large-scale Dataset for Part
Assembly Sequences (D4PAS) consisting of physically valid sequences for
industrial objects. Experimental results show that our approach generalizes
better than prior methods while needing significantly less computational time
for inference.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10572" title="Abstract">arXiv:2312.10572</a> [<a href="/pdf/2312.10572" title="Download PDF">pdf</a>, <a href="/format/2312.10572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Anonymous Multi Agent Path Finding Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+Z+A">Zain Alabedeen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We consider an Anonymous Multi-Agent Path-Finding (AMAPF) problem where the
set of agents is confined to a graph, a set of goal vertices is given and each
of these vertices has to be reached by some agent. The problem is to find an
assignment of the goals to the agents as well as the collision-free paths, and
we are interested in finding the solution with the optimal makespan. A
well-established approach to solve this problem is to reduce it to a special
type of a graph search problem, i.e. to the problem of finding a maximum flow
on an auxiliary graph induced by the input one. The size of the former graph
may be very large and the search on it may become a bottleneck. To this end, we
suggest a specific search algorithm that leverages the idea of exploring the
search space not through considering separate search states but rather bulks of
them simultaneously. That is, we implicitly compress, store and expand bulks of
the search states as single states, which results in high reduction in runtime
and memory. Empirically, the resultant AMAPF solver demonstrates superior
performance compared to the state-of-the-art competitor and is able to solve
all publicly available MAPF instances from the well-known MovingAI benchmark in
less than 30 seconds.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10577" title="Abstract">arXiv:2312.10577</a> [<a href="/pdf/2312.10577" title="Download PDF">pdf</a>, <a href="/ps/2312.10577" title="Download PostScript">ps</a>, <a href="/format/2312.10577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fractional block-centered finite difference method for two-sided  space-fractional diffusion equations on general nonuniform grids and its fast  implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kong%2C+M">Meijie Kong</a>, 
<a href="/search/math?searchtype=author&query=Fu%2C+H">Hongfei Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this paper, a two-sided variable-coefficient space-fractional diffusion
equation with fractional Neumann boundary condition is considered. To conquer
the weak singularity caused by the nonlocal space-fractional differential
operators, by introducing an auxiliary fractional flux variable and using
piecewise linear interpolations, a fractional block-centered finite difference
(BCFD) method on general nonuniform grids is proposed. However, like other
numerical methods, the proposed method still produces linear algebraic systems
with unstructured dense coefficient matrices under the general nonuniform
grids.Consequently, traditional direct solvers such as Gaussian elimination
method shall require $\mathcal{O}(M^2)$ memory and $\mathcal{O}(M^3)$
computational work per time level, where $M$ is the number of spatial unknowns
in the numerical discretization. To address this issue, we combine the
well-known sum-of-exponentials (SOE) approximation technique with the
fractional BCFD method to propose a fast version fractional BCFD algorithm.
Based upon the Krylov subspace iterative methods, fast matrix-vector
multiplications of the resulting coefficient matrices with any vector are
developed, in which they can be implemented in only $\mathcal{O}(MN_{exp})$
operations per iteration, where $N_{exp}\ll M$ is the number of exponentials in
the SOE approximation. Moreover, the coefficient matrices do not necessarily
need to be generated explicitly, while they can be stored in
$\mathcal{O}(MN_{exp})$ memory by only storing some coefficient vectors.
Numerical experiments are provided to demonstrate the efficiency and accuracy
of the method.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10578" title="Abstract">arXiv:2312.10578</a> [<a href="/pdf/2312.10578" title="Download PDF">pdf</a>, <a href="/format/2312.10578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAME: Sample Reconstruction Against Model Extraction Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaofeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">While deep learning models have shown significant performance across various
domains, their deployment needs extensive resources and advanced computing
infrastructure. As a solution, Machine Learning as a Service (MLaaS) has
emerged, lowering the barriers for users to release or productize their deep
learning models. However, previous studies have highlighted potential privacy
and security concerns associated with MLaaS, and one primary threat is model
extraction attacks. To address this, there are many defense solutions but they
suffer from unrealistic assumptions and generalization issues, making them less
practical for reliable protection. Driven by these limitations, we introduce a
novel defense mechanism, SAME, based on the concept of sample reconstruction.
This strategy imposes minimal prerequisites on the defender's capabilities,
eliminating the need for auxiliary Out-of-Distribution (OOD) datasets, user
query history, white-box model access, and additional intervention during model
training. It is compatible with existing active defense methods. Our extensive
experiments corroborate the superior efficacy of SAME over state-of-the-art
solutions. Our code is available at https://github.com/xythink/SAME.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10579" title="Abstract">arXiv:2312.10579</a> [<a href="/pdf/2312.10579" title="Download PDF">pdf</a>, <a href="/format/2312.10579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DER-GCN: Dialogue and Event Relation-Aware Graph Convolutional Neural  Network for Multimodal Dialogue Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the continuous development of deep learning (DL), the task of multimodal
dialogue emotion recognition (MDER) has recently received extensive research
attention, which is also an essential branch of DL. The MDER aims to identify
the emotional information contained in different modalities, e.g., text, video,
and audio, in different dialogue scenes. However, existing research has focused
on modeling contextual semantic information and dialogue relations between
speakers while ignoring the impact of event relations on emotion. To tackle the
above issues, we propose a novel Dialogue and Event Relation-Aware Graph
Convolutional Neural Network for Multimodal Emotion Recognition (DER-GCN)
method. It models dialogue relations between speakers and captures latent event
relations information. Specifically, we construct a weighted multi-relationship
graph to simultaneously capture the dependencies between speakers and event
relations in a dialogue. Moreover, we also introduce a Self-Supervised Masked
Graph Autoencoder (SMGAE) to improve the fusion representation ability of
features and structures. Next, we design a new Multiple Information Transformer
(MIT) to capture the correlation between different relations, which can provide
a better fuse of the multivariate information between relations. Finally, we
propose a loss optimization strategy based on contrastive learning to enhance
the representation learning ability of minority class features. We conduct
extensive experiments on the IEMOCAP and MELD benchmark datasets, which verify
the effectiveness of the DER-GCN model. The results demonstrate that our model
significantly improves both the average accuracy and the f1 value of emotion
recognition.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10580" title="Abstract">arXiv:2312.10580</a> [<a href="/pdf/2312.10580" title="Download PDF">pdf</a>, <a href="/ps/2312.10580" title="Download PostScript">ps</a>, <a href="/format/2312.10580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment Analysis and Text Analysis of the Public Discourse on Twitter  about COVID-19 and MPox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nirmalya Thakur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mining and analysis of the big data of Twitter conversations have been of
significant interest to the scientific community in the fields of healthcare,
epidemiology, big data, data science, computer science, and their related
areas, as can be seen from several works in the last few years that focused on
sentiment analysis and other forms of text analysis of tweets related to Ebola,
E-Coli, Dengue, Human Papillomavirus, Middle East Respiratory Syndrome,
Measles, Zika virus, H1N1, influenza like illness, swine flu, flu, Cholera,
Listeriosis, cancer, Liver Disease, Inflammatory Bowel Disease, kidney disease,
lupus, Parkinsons, Diphtheria, and West Nile virus. The recent outbreaks of
COVID-19 and MPox have served as catalysts for Twitter usage related to seeking
and sharing information, views, opinions, and sentiments involving both of
these viruses. None of the prior works in this field analyzed tweets focusing
on both COVID-19 and MPox simultaneously. To address this research gap, a total
of 61,862 tweets that focused on MPox and COVID-19 simultaneously, posted
between 7 May 2022 and 3 March 2023, were studied. The findings and
contributions of this study are manifold. First, the results of sentiment
analysis using the VADER approach show that nearly half the tweets had a
negative sentiment. It was followed by tweets that had a positive sentiment and
tweets that had a neutral sentiment, respectively. Second, this paper presents
the top 50 hashtags used in these tweets. Third, it presents the top 100 most
frequently used words in these tweets after performing tokenization, removal of
stopwords, and word frequency analysis. Finally, a comprehensive comparative
study that compares the contributions of this paper with 49 prior works in this
field is presented to further uphold the relevance and novelty of this work.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10584" title="Abstract">arXiv:2312.10584</a> [<a href="/pdf/2312.10584" title="Download PDF">pdf</a>, <a href="/format/2312.10584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Optimization in RLHF: The Impact of Out-of-preference Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziniu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Aligning intelligent agents with human preferences and values is important.
This paper examines two popular alignment methods: Direct Preference
Optimization (DPO) and Reward-Model-Based Policy Optimization (RMB-PO). A
variant of RMB-PO, referred to as RMB-PO+ is also considered. These methods,
either explicitly or implicitly, learn a reward model from preference data and
differ in the data used for policy optimization to unlock the generalization
ability of the reward model. In particular, compared with DPO, RMB-PO
additionally uses policy-generated data, and RMB-PO+ further leverages new,
preference-free data. We examine the impact of such out-of-preference data. Our
study, conducted through controlled and synthetic experiments, demonstrates
that DPO performs poorly, whereas RMB-PO+ performs the best. In particular,
even when providing the policy model with a good feature representation, we
find that policy optimization with adequate out-of-preference data
significantly improves performance by harnessing the reward model's
generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10586" title="Abstract">arXiv:2312.10586</a> [<a href="/pdf/2312.10586" title="Download PDF">pdf</a>, <a href="/format/2312.10586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Learning from Augmented Label-Uncertain Queries in Bongard-HOI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qinqian Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting human-object interactions (HOI) in a few-shot setting remains a
challenge. Existing meta-learning methods struggle to extract representative
features for classification due to the limited data, while existing few-shot
HOI models rely on HOI text labels for classification. Moreover, some query
images may display visual similarity to those outside their class, such as
similar backgrounds between different HOI classes. This makes learning more
challenging, especially with limited samples. Bongard-HOI (Jiang et al. 2022)
epitomizes this HOI few-shot problem, making it the benchmark we focus on in
this paper. In our proposed method, we introduce novel label-uncertain query
augmentation techniques to enhance the diversity of the query inputs, aiming to
distinguish the positive HOI class from the negative ones. As these augmented
inputs may or may not have the same class label as the original inputs, their
class label is unknown. Those belonging to a different class become hard
samples due to their visual similarity to the original ones. Additionally, we
introduce a novel pseudo-label generation technique that enables a mean teacher
model to learn from the augmented label-uncertain inputs. We propose to augment
the negative support set for the student model to enrich the semantic
information, fostering diversity that challenges and enhances the student's
learning. Experimental results demonstrate that our method sets a new
state-of-the-art (SOTA) performance by achieving 68.74% accuracy on the
Bongard-HOI benchmark, a significant improvement over the existing SOTA of
66.59%. In our evaluation on HICO-FS, a more general few-shot recognition
dataset, our method achieves 73.27% accuracy, outperforming the previous SOTA
of 71.20% in the 5-way 5-shot task.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10587" title="Abstract">arXiv:2312.10587</a> [<a href="/pdf/2312.10587" title="Download PDF">pdf</a>, <a href="/format/2312.10587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2E-AT: A Unified Framework for Tackling Uncertainty in Task-aware  End-to-end Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wangkun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Successful machine learning involves a complete pipeline of data, model, and
downstream applications. Instead of treating them separately, there has been a
prominent increase of attention within the constrained optimization (CO) and
machine learning (ML) communities towards combining prediction and optimization
models. The so-called end-to-end (E2E) learning captures the task-based
objective for which they will be used for decision making. Although a large
variety of E2E algorithms have been presented, it has not been fully
investigated how to systematically address uncertainties involved in such
models. Most of the existing work considers the uncertainties of ML in the
input space and improves robustness through adversarial training. We apply the
same idea to E2E learning and prove that there is a robustness certification
procedure by solving augmented integer programming. Furthermore, we show that
neglecting the uncertainty of COs during training causes a new trigger for
generalization errors. To include all these components, we propose a unified
framework that covers the uncertainties emerging in both the input feature
space of the ML models and the COs. The framework is described as a robust
optimization problem and is practically solved via end-to-end adversarial
training (E2E-AT). Finally, the performance of E2E-AT is evaluated by a
real-world end-to-end power system operation problem, including load
forecasting and sequential scheduling tasks.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10588" title="Abstract">arXiv:2312.10588</a> [<a href="/pdf/2312.10588" title="Download PDF">pdf</a>, <a href="/format/2312.10588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-Training Quantization for Re-parameterization via Coarse &amp; Fine  Weight Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dawei Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Ning He</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiangyong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although neural networks have made remarkable advancements in various
applications, they require substantial computational and memory resources.
Network quantization is a powerful technique to compress neural networks,
allowing for more efficient and scalable AI deployments. Recently,
Re-parameterization has emerged as a promising technique to enhance model
performance while simultaneously alleviating the computational burden in
various computer vision tasks. However, the accuracy drops significantly when
applying quantization on the re-parameterized networks. We identify that the
primary challenge arises from the large variation in weight distribution across
the original branches. To address this issue, we propose a coarse &amp; fine weight
splitting (CFWS) method to reduce quantization error of weight, and develop an
improved KL metric to determine optimal quantization scales for activation. To
the best of our knowledge, our approach is the first work that enables
post-training quantization applicable on re-parameterized networks. For
example, the quantized RepVGG-A1 model exhibits a mere 0.3% accuracy loss. The
code is in https://github.com/NeonHo/Coarse-Fine-Weight-Split.git
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10589" title="Abstract">arXiv:2312.10589</a> [<a href="/pdf/2312.10589" title="Download PDF">pdf</a>, <a href="/format/2312.10589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NN-Steiner: A Mixed Neural-algorithmic Approach for the Rectilinear  Steiner Minimum Tree Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahng%2C+A+B">Andrew B. Kahng</a>, 
<a href="/search/cs?searchtype=author&query=Nerem%2C+R+R">Robert R. Nerem</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chien-Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the full version with appendix of an accepted paper in AAAI'24 with the same paper title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent years have witnessed rapid advances in the use of neural networks to
solve combinatorial optimization problems. Nevertheless, designing the "right"
neural model that can effectively handle a given optimization problem can be
challenging, and often there is no theoretical understanding or justification
of the resulting neural model. In this paper, we focus on the rectilinear
Steiner minimum tree (RSMT) problem, which is of critical importance in IC
layout design and as a result has attracted numerous heuristic approaches in
the VLSI literature. Our contributions are two-fold. On the methodology front,
we propose NN-Steiner, which is a novel mixed neural-algorithmic framework for
computing RSMTs that leverages the celebrated PTAS algorithmic framework of
Arora to solve this problem (and other geometric optimization problems). Our
NN-Steiner replaces key algorithmic components within Arora's PTAS by suitable
neural components. In particular, NN-Steiner only needs four neural network
(NN) components that are called repeatedly within an algorithmic framework.
Crucially, each of the four NN components is only of bounded size independent
of input size, and thus easy to train. Furthermore, as the NN component is
learning a generic algorithmic step, once learned, the resulting mixed
neural-algorithmic framework generalizes to much larger instances not seen in
training. Our NN-Steiner, to our best knowledge, is the first neural
architecture of bounded size that has capacity to approximately solve RSMT (and
variants). On the empirical front, we show how NN-Steiner can be implemented
and demonstrate the effectiveness of our resulting approach, especially in
terms of generalization, by comparing with state-of-the-art methods (both
neural or non-neural based).
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10593" title="Abstract">arXiv:2312.10593</a> [<a href="/pdf/2312.10593" title="Download PDF">pdf</a>, <a href="/format/2312.10593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel RFID Authentication Protocol Based on A Block-Order-Modulus  Variable Matrix Encryption Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuemei Lei</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+G">Guan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, authentication for mobile radio frequency identification
(RFID) systems with low-cost tags is studied. Firstly, a diagonal block key
matrix (DBKM) encryption algorithm is proposed, which effectively expands the
feasible domain of the key space. Subsequently, in order to enhance the
security, a self updating encryption order (SUEO) algorithm is conceived. To
further weaken the correlation between plaintext and ciphertext, a self
updating modulus (SUM) algorithm is constructed. Based on the above three
algorithms, a new joint DBKM-SUEO-SUM matrix encryption algorithm is
established, which intends to enhance security without the need of additional
storage for extra key matrices. Making full use of the advantages of the
proposed joint algorithm, a two-way RFID authentication protocol named
DBKM-SUEO-SUM-RFID is proposed for mobile RFID systems. In addition, the
Burrows-Abadi-Needham (BAN) logic and security analysis indicate that the newly
proposed DBKM-SUEO-SUM-RFID protocol can effectively resist various typical
attacks, such as replay attacks and de-synchronization. Finally, numerical
results demonstrate that the DBKM-SUEO-SUM algorithm can save at least 90.46\%
of tag storage compared to traditional algorithms, and thus, is friendly to be
employed with low-cost RFID tags.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10594" title="Abstract">arXiv:2312.10594</a> [<a href="/pdf/2312.10594" title="Download PDF">pdf</a>, <a href="/ps/2312.10594" title="Download PostScript">ps</a>, <a href="/format/2312.10594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Representation and Learning: Control and Risk  Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhuoyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Keller%2C+R">Reece Keller</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+X">Xiyu Deng</a>, 
<a href="/search/eess?searchtype=author&query=Hoshino%2C+K">Kenta Hoshino</a>, 
<a href="/search/eess?searchtype=author&query=Tanaka%2C+T">Takashi Tanaka</a>, 
<a href="/search/eess?searchtype=author&query=Nakahira%2C+Y">Yorie Nakahira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the AAAI 24 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Optimal and safety-critical control are fundamental problems for stochastic
systems, and are widely considered in real-world scenarios such as robotic
manipulation and autonomous driving. In this paper, we consider the problem of
efficiently finding optimal and safe control for high-dimensional systems.
Specifically, we propose to use dimensionality reduction techniques from a
comparison theorem for stochastic differential equations together with a
generalizable physics-informed neural network to estimate the optimal value
function and the safety probability of the system. The proposed framework
results in substantial sample efficiency improvement compared to existing
methods. We further develop an autoencoder-like neural network to automatically
identify the low-dimensional features in the system to enhance the ease of
design for system integration. We also provide theoretical analysis and
experiments to validate the efficacy of the proposed method.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10599" title="Abstract">arXiv:2312.10599</a> [<a href="/pdf/2312.10599" title="Download PDF">pdf</a>, <a href="/format/2312.10599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Aspects of Generating Instances with Unique Solutions:  Pre-assignment Models for Unique Vertex Cover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horiyama%2C+T">Takashi Horiyama</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+Y">Yasuaki Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+H">Hirotaka Ono</a>, 
<a href="/search/cs?searchtype=author&query=Seto%2C+K">Kazuhisa Seto</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+R">Ryu Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures. An extended abstract will appear in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The uniqueness of an optimal solution to a combinatorial optimization problem
attracts many fields of researchers' attention because it has a wide range of
applications, it is related to important classes in computational complexity,
and an instance with only one solution is often critical for algorithm designs
in theory. However, as the authors know, there is no major benchmark set
consisting of only instances with unique solutions, and no algorithm generating
instances with unique solutions is known; a systematic approach to getting a
problem instance guaranteed having a unique solution would be helpful. A
possible approach is as follows: Given a problem instance, we specify a small
part of a solution in advance so that only one optimal solution meets the
specification. This paper formulates such a ``pre-assignment'' approach for the
vertex cover problem as a typical combinatorial optimization problem and
discusses its computational complexity. First, we show that the problem is
$\Sigma^P_2$-complete in general, while the problem becomes NP-complete when an
input graph is bipartite. We then present an $O(2.1996^n)$-time algorithm for
general graphs and an $O(1.9181^n)$-time algorithm for bipartite graphs, where
$n$ is the number of vertices. The latter is based on an FPT algorithm with
$O^*(3.6791^{\tau})$ time for vertex cover number $\tau$. Furthermore, we show
that the problem for trees can be solved in $O(1.4143^n)$ time.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10600" title="Abstract">arXiv:2312.10600</a> [<a href="/pdf/2312.10600" title="Download PDF">pdf</a>, <a href="/format/2312.10600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cut your annotation cost: An empirical study on the use of weak, noisy,  and SAM-generated annotations for segmentation network training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanxue Gu</a>, 
<a href="/search/cs?searchtype=author&query=Mazurowski%2C+M+A">Maciej A. Mazurowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have been deployed for many image segmentation
tasks and achieved outstanding performance. However, preparing a dataset for
training segmentation DNNs is laborious and costly since typically pixel-level
annotations are provided for each object of interest. To alleviate this issue,
one can provide only weak labels such as bounding boxes or scribbles, or less
accurate (noisy) annotations of the objects. These are significantly faster to
generate and thus result in more annotated images given the same time budget.
However, the reduction in quality might negatively affect the segmentation
performance of the resulting model. In this study, we perform a thorough
cost-effectiveness evaluation of several weak and noisy labels. We considered
11 variants of annotation strategies and 4 datasets. We conclude that the
common practice of accurately outlining the objects of interest is virtually
never the optimal approach when the annotation time is limited, even if notable
annotation time is available (10s of hours). Annotation approaches that stood
out in such scenarios were (1) polygon-based annotation with few vertices, and
(2) box annotations combined with the Segment Anything Model (SAM). In
situations where unlimited annotation time was available, precise annotations
still lead to the highest segmentation model performance.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10602" title="Abstract">arXiv:2312.10602</a> [<a href="/pdf/2312.10602" title="Download PDF">pdf</a>, <a href="/format/2312.10602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Weighted K-Center Algorithm for Data Subset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramalingam%2C+S">Srikumar Ramalingam</a>, 
<a href="/search/cs?searchtype=author&query=Awasthi%2C+P">Pranjal Awasthi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> data selection, k-center, subset selection,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The success of deep learning hinges on enormous data and large models, which
require labor-intensive annotations and heavy computation costs. Subset
selection is a fundamental problem that can play a key role in identifying
smaller portions of the training data, which can then be used to produce
similar models as the ones trained with full data. Two prior methods are shown
to achieve impressive results: (1) margin sampling that focuses on selecting
points with high uncertainty, and (2) core-sets or clustering methods such as
k-center for informative and diverse subsets. We are not aware of any work that
combines these methods in a principled manner. To this end, we develop a novel
and efficient factor 3-approximation algorithm to compute subsets based on the
weighted sum of both k-center and uncertainty sampling objective functions. To
handle large datasets, we show a parallel algorithm to run on multiple machines
with approximation guarantees. The proposed algorithm achieves similar or
better performance compared to other strong baselines on vision datasets such
as CIFAR-10, CIFAR-100, and ImageNet.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10603" title="Abstract">arXiv:2312.10603</a> [<a href="/pdf/2312.10603" title="Download PDF">pdf</a>, <a href="/ps/2312.10603" title="Download PostScript">ps</a>, <a href="/format/2312.10603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating AI Vocational Skills Through Professional Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>, 
<a href="/search/cs?searchtype=author&query=Ciolino%2C+M">Matt Ciolino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.05377">arXiv:2305.05377</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Using a novel professional certification survey, the study focuses on
assessing the vocational skills of two highly cited AI models, GPT-3 and
Turbo-GPT3.5. The approach emphasizes the importance of practical readiness
over academic performance by examining the models' performances on a benchmark
dataset consisting of 1149 professional certifications. This study also
includes a comparison with human test scores, providing perspective on the
potential of AI models to match or even surpass human performance in
professional certifications. GPT-3, even without any fine-tuning or exam
preparation, managed to achieve a passing score (over 70% correct) on 39% of
the professional certifications. It showcased proficiency in computer-related
fields, including cloud and virtualization, business analytics, cybersecurity,
network setup and repair, and data analytics. Turbo-GPT3.5, on the other hand,
scored a perfect 100% on the highly regarded Offensive Security Certified
Professional (OSCP) exam. This model also demonstrated competency in diverse
professional fields, such as nursing, licensed counseling, pharmacy, and
aviation. Turbo-GPT3.5 exhibited strong performance on customer service tasks,
indicating potential use cases in enhancing chatbots for call centers and
routine advice services. Both models also scored well on sensory and
experience-based tests outside a machine's traditional roles, including wine
sommelier, beer tasting, emotional quotient, and body language reading. The
study found that OpenAI's model improvement from Babbage to Turbo led to a 60%
better performance on the grading scale within a few years. This progress
indicates that addressing the current model's limitations could yield an AI
capable of passing even the most rigorous professional certifications.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10604" title="Abstract">arXiv:2312.10604</a> [<a href="/pdf/2312.10604" title="Download PDF">pdf</a>, <a href="/format/2312.10604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual Domain Multi-exposure Image Fusion Network based on the  Spatial-Frequency Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-exposure image fusion aims to generate a single high-dynamic image by
integrating images with different exposures. Existing deep learning-based
multi-exposure image fusion methods primarily focus on spatial domain fusion,
neglecting the global modeling ability of the frequency domain. To effectively
leverage the global illumination modeling ability of the frequency domain, we
propose a novelty perspective on multi-exposure image fusion via the
Spatial-Frequency Integration Framework, named MEF-SFI. Initially, we revisit
the properties of the Fourier transform on the 2D image, and verify the
feasibility of multi-exposure image fusion on the frequency domain where the
amplitude and phase component is able to guide the integration of the
illumination information. Subsequently, we present the deep Fourier-based
multi-exposure image fusion framework, which consists of a spatial path and
frequency path for local and global modeling separately. Specifically, we
introduce a Spatial-Frequency Fusion Block to facilitate efficient interaction
between dual domains and capture complementary information from input images
with different exposures. Finally, we combine a dual domain loss function to
ensure the retention of complementary information in both the spatial and
frequency domains. Extensive experiments on the PQA-MEF dataset demonstrate
that our method achieves visual-appealing fusion results against
state-of-the-art multi-exposure image fusion approaches. Our code is available
at https://github.com/SSyangguang/MEF-freq.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10605" title="Abstract">arXiv:2312.10605</a> [<a href="/pdf/2312.10605" title="Download PDF">pdf</a>, <a href="/format/2312.10605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-AF Echo Cancellation for Improved Keyword Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casebeer%2C+J">Jonah Casebeer</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Smaragdis%2C+P">Paris Smaragdis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Adaptive filters (AFs) are vital for enhancing the performance of downstream
tasks, such as speech recognition, sound event detection, and keyword spotting.
However, traditional AF design prioritizes isolated signal-level objectives,
often overlooking downstream task performance. This can lead to suboptimal
performance. Recent research has leveraged meta-learning to automatically learn
AF update rules from data, alleviating the need for manual tuning when using
simple signal-level objectives. This paper improves the Meta-AF framework by
expanding it to support end-to-end training for arbitrary downstream tasks. We
focus on classification tasks, where we introduce a novel training methodology
that harnesses self-supervision and classifier feedback. We evaluate our
approach on the combined task of acoustic echo cancellation and keyword
spotting. Our findings demonstrate consistent performance improvements with
both pre-trained and joint-trained keyword spotting models across synthetic and
real playback. Notably, these improvements come without requiring additional
tuning, increased inference-time complexity, or reliance on oracle signal-level
training data.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10608" title="Abstract">arXiv:2312.10608</a> [<a href="/pdf/2312.10608" title="Download PDF">pdf</a>, <a href="/format/2312.10608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust 3D Tracking with Quality-Aware Shape Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+W">Wenjie Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A detailed version of the paper accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D single object tracking remains a challenging problem due to the sparsity
and incompleteness of the point clouds. Existing algorithms attempt to address
the challenges in two strategies. The first strategy is to learn dense
geometric features based on the captured sparse point cloud. Nevertheless, it
is quite a formidable task since the learned dense geometric features are with
high uncertainty for depicting the shape of the target object. The other
strategy is to aggregate the sparse geometric features of multiple templates to
enrich the shape information, which is a routine solution in 2D tracking.
However, aggregating the coarse shape representations can hardly yield a
precise shape representation. Different from 2D pixels, 3D points of different
frames can be directly fused by coordinate transform, i.e., shape completion.
Considering that, we propose to construct a synthetic target representation
composed of dense and complete point clouds depicting the target shape
precisely by shape completion for robust 3D tracking. Specifically, we design a
voxelized 3D tracking framework with shape completion, in which we propose a
quality-aware shape completion mechanism to alleviate the adverse effect of
noisy historical predictions. It enables us to effectively construct and
leverage the synthetic target representation. Besides, we also develop a
voxelized relation modeling module and box refinement module to improve
tracking performance. Favorable performance against state-of-the-art algorithms
on three benchmarks demonstrates the effectiveness and generalization ability
of our method.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10610" title="Abstract">arXiv:2312.10610</a> [<a href="/pdf/2312.10610" title="Download PDF">pdf</a>, <a href="/format/2312.10610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question  Answering and Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Masry%2C+A">Ahmed Masry</a>, 
<a href="/search/cs?searchtype=author&query=Kavehzadeh%2C+P">Parsa Kavehzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+E">Enamul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A number of tasks have been proposed recently to facilitate easy access to
charts such as chart QA and summarization. The dominant paradigm to solve these
tasks has been to fine-tune a pretrained model on the task data. However, this
approach is not only expensive but also not generalizable to unseen tasks. On
the other hand, large language models (LLMs) have shown impressive
generalization capabilities to unseen tasks with zero- or few-shot prompting.
However, their application to chart-related tasks is not trivial as these tasks
typically involve considering not only the underlying data but also the visual
features in the chart image. We propose PromptChart, a multimodal few-shot
prompting framework with LLMs for chart-related applications. By analyzing the
tasks carefully, we have come up with a set of prompting guidelines for each
task to elicit the best few-shot performance from LLMs. We further propose a
strategy to inject visual information into the prompts. Our experiments on
three different chart-related information consumption tasks show that with
properly designed prompts LLMs can excel on the benchmarks, achieving
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10611" title="Abstract">arXiv:2312.10611</a> [<a href="/pdf/2312.10611" title="Download PDF">pdf</a>, <a href="/format/2312.10611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-directional Adapter for Multi-modal Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengfei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Code is available at <a href="https://github.com/SparkTempest/BAT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the rapid development of computer vision, single-modal (RGB) object
tracking has made significant progress in recent years. Considering the
limitation of single imaging sensor, multi-modal images (RGB, Infrared, etc.)
are introduced to compensate for this deficiency for all-weather object
tracking in complex environments. However, as acquiring sufficient multi-modal
tracking data is hard while the dominant modality changes with the open
environment, most existing techniques fail to extract multi-modal complementary
information dynamically, yielding unsatisfactory tracking performance. To
handle this problem, we propose a novel multi-modal visual prompt tracking
model based on a universal bi-directional adapter, cross-prompting multiple
modalities mutually. Our model consists of a universal bi-directional adapter
and multiple modality-specific transformer encoder branches with sharing
parameters. The encoders extract features of each modality separately by using
a frozen pre-trained foundation model. We develop a simple but effective light
feature adapter to transfer modality-specific information from one modality to
another, performing visual feature prompt fusion in an adaptive manner. With
adding fewer (0.32M) trainable parameters, our model achieves superior tracking
performance in comparison with both the full fine-tuning methods and the prompt
learning-based methods. Our code is available:
https://github.com/SparkTempest/BAT.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10613" title="Abstract">arXiv:2312.10613</a> [<a href="/pdf/2312.10613" title="Download PDF">pdf</a>, <a href="/format/2312.10613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> p-Laplacian Adaptation for Generative Pre-trained Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+P">Peiyu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xufeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24. The first two authors contributed equally to this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language models (VLMs) pre-trained on large corpora have demonstrated
notable success across a range of downstream tasks. In light of the rapidly
increasing size of pre-trained VLMs, parameter-efficient transfer learning
(PETL) has garnered attention as a viable alternative to full fine-tuning. One
such approach is the adapter, which introduces a few trainable parameters into
the pre-trained models while preserving the original parameters during
adaptation. In this paper, we present a novel modeling framework that recasts
adapter tuning after attention as a graph message passing process on attention
graphs, where the projected query and value features and attention matrix
constitute the node features and the graph adjacency matrix, respectively.
Within this framework, tuning adapters in VLMs necessitates handling
heterophilic graphs, owing to the disparity between the projected query and
value space. To address this challenge, we propose a new adapter architecture,
$p$-adapter, which employs $p$-Laplacian message passing in Graph Neural
Networks (GNNs). Specifically, the attention weights are re-normalized based on
the features, and the features are then aggregated using the calibrated
attention matrix, enabling the dynamic exploitation of information with varying
frequencies in the heterophilic attention graphs. We conduct extensive
experiments on different pre-trained VLMs and multi-modal tasks, including
visual question answering, visual entailment, and image captioning. The
experimental results validate our method's significant superiority over other
PETL methods.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10615" title="Abstract">arXiv:2312.10615</a> [<a href="/pdf/2312.10615" title="Download PDF">pdf</a>, <a href="/format/2312.10615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Symmetric Multigrid-Preconditioned Krylov Subspace Solver for Stokes  Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tao%2C+Y">Yutian Tao</a>, 
<a href="/search/math?searchtype=author&query=Sifakis%2C+E">Eftychios Sifakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Numerical solution of discrete PDEs corresponding to saddle point problems is
highly relevant to physical systems such as Stokes flow. However, scaling up
numerical solvers for such systems is often met with challenges in efficiency
and convergence. Multigrid is an approach with excellent applicability to
elliptic problems such as the Stokes equations, and can be a solution to such
challenges of scalability and efficiency. The degree of success of such
methods, however, is highly contingent on the design of key components of a
multigrid scheme, including the hierarchy of discretizations, and the
relaxation scheme used. Additionally, in many practical cases, it may be more
effective to use a multigrid scheme as a preconditioner to an iterative Krylov
subspace solver, as opposed to striving for maximum efficacy of the relaxation
scheme in all foreseeable settings. In this paper, we propose an efficient
symmetric multigrid preconditioner for the Stokes Equations on a staggered
finite-difference discretization. Our contribution is focused on crafting a
preconditioner that (a) is symmetric indefinite, matching the property of the
Stokes system itself, (b) is appropriate for preconditioning the SQMR iterative
scheme, and (c) has the requisite symmetry properties to be used in this
context. In addition, our design is efficient in terms of computational cost
and facilitates scaling to large domains.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10616" title="Abstract">arXiv:2312.10616</a> [<a href="/pdf/2312.10616" title="Download PDF">pdf</a>, <a href="/format/2312.10616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DistilVPR: Cross-Modal Knowledge Distillation for Visual Place  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+X">Xingchao Jian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The utilization of multi-modal sensor data in visual place recognition (VPR)
has demonstrated enhanced performance compared to single-modal counterparts.
Nonetheless, integrating additional sensors comes with elevated costs and may
not be feasible for systems that demand lightweight operation, thereby
impacting the practical deployment of VPR. To address this issue, we resort to
knowledge distillation, which empowers single-modal students to learn from
cross-modal teachers without introducing additional sensors during inference.
Despite the notable advancements achieved by current distillation approaches,
the exploration of feature relationships remains an under-explored area. In
order to tackle the challenge of cross-modal distillation in VPR, we present
DistilVPR, a novel distillation pipeline for VPR. We propose leveraging feature
relationships from multiple agents, including self-agents and cross-agents for
teacher and student neural networks. Furthermore, we integrate various
manifolds, characterized by different space curvatures for exploring feature
relationships. This approach enhances the diversity of feature relationships,
including Euclidean, spherical, and hyperbolic relationship modules, thereby
enhancing the overall representational capacity. The experiments demonstrate
that our proposed pipeline achieves state-of-the-art performance compared to
other distillation baselines. We also conduct necessary ablation studies to
show design effectiveness. The code is released at:
https://github.com/sijieaaa/DistilVPR
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10617" title="Abstract">arXiv:2312.10617</a> [<a href="/pdf/2312.10617" title="Download PDF">pdf</a>, <a href="/format/2312.10617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep dive into language traits of AI-generated Abstracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikas Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bharti%2C+A">Amisha Bharti</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+D">Devanshu Verma</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+V">Vasudha Bhatnagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Cods-Comad Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative language models, such as ChatGPT, have garnered attention for
their ability to generate human-like writing in various fields, including
academic research. The rapid proliferation of generated texts has bolstered the
need for automatic identification to uphold transparency and trust in the
information. However, these generated texts closely resemble human writing and
often have subtle differences in the grammatical structure, tones, and
patterns, which makes systematic scrutinization challenging. In this work, we
attempt to detect the Abstracts generated by ChatGPT, which are much shorter in
length and bounded. We extract the texts semantic and lexical properties and
observe that traditional machine learning models can confidently detect these
Abstracts.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10620" title="Abstract">arXiv:2312.10620</a> [<a href="/pdf/2312.10620" title="Download PDF">pdf</a>, <a href="/ps/2312.10620" title="Download PostScript">ps</a>, <a href="/format/2312.10620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human AI Collaboration in Software Engineering: Lessons Learned from a  Hands On Workshop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamza%2C+M">Muhammad Hamza</a>, 
<a href="/search/cs?searchtype=author&query=Siemon%2C+D">Dominik Siemon</a>, 
<a href="/search/cs?searchtype=author&query=Akbar%2C+M+A">Muhammad Azeem Akbar</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+T">Tahsinur Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper investigates the dynamics of human AI collaboration in software
engineering, focusing on the use of ChatGPT. Through a thematic analysis of a
hands on workshop in which 22 professional software engineers collaborated for
three hours with ChatGPT, we explore the transition of AI from a mere tool to a
collaborative partner. The study identifies key themes such as the evolving
nature of human AI interaction, the capabilities of AI in software engineering
tasks, and the challenges and limitations of integrating AI in this domain. The
findings show that while AI, particularly ChatGPT, improves the efficiency of
code generation and optimization, human oversight remains crucial, especially
in areas requiring complex problem solving and security considerations. This
research contributes to the theoretical understanding of human AI collaboration
in software engineering and provides practical insights for effectively
integrating AI tools into development processes. It highlights the need for
clear role allocation, effective communication, and balanced AI human
collaboration to realize the full potential of AI in software engineering.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10622" title="Abstract">arXiv:2312.10622</a> [<a href="/pdf/2312.10622" title="Download PDF">pdf</a>, <a href="/format/2312.10622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unit Test Generation using Generative AI : A Comparative Performance  Analysis of Autogeneration Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Shreya Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+T">Tarushi Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jalote%2C+P">Pankaj Jalote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating unit tests is a crucial task in software development, demanding
substantial time and effort from programmers. The advent of Large Language
Models (LLMs) introduces a novel avenue for unit test script generation. This
research aims to experimentally investigate the effectiveness of LLMs,
specifically exemplified by ChatGPT, for generating unit test scripts for
Python programs, and how the generated test cases compare with those generated
by an existing unit test generator (Pynguin). For experiments, we consider
three types of code units: 1) Procedural scripts, 2) Function-based modular
code, and 3) Class-based code. The generated test cases are evaluated based on
criteria such as coverage, correctness, and readability. Our results show that
ChatGPT's performance is comparable with Pynguin in terms of coverage. At the
same time, ChatGPT's ability to generate tests is superior to Pynguin, as the
latter is not able to generate test cases for Category 1. We also find that
about 39% and 28% of assertions generated by ChatGPT for Category 2 and 3,
respectively, were incorrect. Our results also show that there is minimal
overlap in missed statements between ChatGPT and Pynguin, thus, suggesting that
a combination of both tools may enhance unit test generation performance.
Finally, prompt engineering improved ChatGPT's performance, achieving an
average 28% coverage improvement in Category 2 and 15% improvement in Category
3 after about 4 iterations.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10623" title="Abstract">arXiv:2312.10623</a> [<a href="/pdf/2312.10623" title="Download PDF">pdf</a>, <a href="/format/2312.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Query-based API Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Moshi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z+M">Zhen Ming Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Application Programming Interfaces (APIs) are designed to help developers
build software more effectively. Recommending the right APIs for specific tasks
has gained increasing attention among researchers and developers in recent
years. To comprehensively understand this research domain, we have surveyed to
analyze API recommendation studies published in the last 10 years. Our study
begins with an overview of the structure of API recommendation tools.
Subsequently, we systematically analyze prior research and pose four key
research questions. For RQ1, we examine the volume of published papers and the
venues in which these papers appear within the API recommendation field. In
RQ2, we categorize and summarize the prevalent data sources and collection
methods employed in API recommendation research. In RQ3, we explore the types
of data and common data representations utilized by API recommendation
approaches. We also investigate the typical data extraction procedures and
collection approaches employed by the existing approaches. RQ4 delves into the
modeling techniques employed by API recommendation approaches, encompassing
both statistical and deep learning models. Additionally, we compile an overview
of the prevalent ranking strategies and evaluation metrics used for assessing
API recommendation tools. Drawing from our survey findings, we identify current
challenges in API recommendation research that warrant further exploration,
along with potential avenues for future research.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10624" title="Abstract">arXiv:2312.10624</a> [<a href="/pdf/2312.10624" title="Download PDF">pdf</a>, <a href="/format/2312.10624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Offline A/B Testing Be Automated for Data-Driven Requirement  Engineering?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+J">Jie JW Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Online A/B testing has been widely used by software companies to evaluate the
impact of new technologies by offering it to a groups of users and comparing
against the unmodified product. However, running online A/B testing needs not
only efforts in design, implementation and stakeholders' approval to be served
in production, but also several weeks to collect the data in iterations. To
address these issues, a recent emerging topic, called \textit{offline A/B
testing}, is getting increasing attention, with the goal to conduct offline
evaluation of a new technology by estimating historical logged data. Although
this approach is promising due to lower implementation effort, faster
turnaround time and no potential user harm, for it to be effectively
prioritized as requirements in practice, several limitations need to be
addressed, including its discrepancy with online A/B test results, and lack of
systematic updates on new data. In response, in this vision paper, we introduce
AutoOffAB, an idea to automatically runs variants of offline A/B testing
against recent logging and update the offline evaluation results, which are
used to make decisions on requirements more reliably and systematically.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10626" title="Abstract">arXiv:2312.10626</a> [<a href="/pdf/2312.10626" title="Download PDF">pdf</a>, <a href="/format/2312.10626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Concerns: Multi-label Classification of Vaccine Sentiments in  Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%2C+S">Somsubhra De</a>, 
<a href="/search/cs?searchtype=author&query=Vats%2C+S">Shaurya Vats</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Submitted to the AISoMe Track at FIRE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of public health, vaccination stands as the cornerstone for
mitigating disease risks and controlling their proliferation. The recent
COVID-19 pandemic has highlighted how vaccines play a crucial role in keeping
us safe. However the situation involves a mix of perspectives, with skepticism
towards vaccines prevailing for various reasons such as political dynamics,
apprehensions about side effects, and more. The paper addresses the challenge
of comprehensively understanding and categorizing these diverse concerns
expressed in the context of vaccination. Our focus is on developing a robust
multi-label classifier capable of assigning specific concern labels to tweets
based on the articulated apprehensions towards vaccines. To achieve this, we
delve into the application of a diverse set of advanced natural language
processing techniques and machine learning algorithms including transformer
models like BERT, state of the art GPT 3.5, Classifier Chains &amp; traditional
methods like SVM, Random Forest, Naive Bayes. We see that the cutting-edge
large language model outperforms all other methods in this context.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10628" title="Abstract">arXiv:2312.10628</a> [<a href="/pdf/2312.10628" title="Download PDF">pdf</a>, <a href="/format/2312.10628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T2M-HiFiGPT: Generating High Quality Human Motion from Textual  Descriptions with Residual Discrete Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Congyi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we introduce T2M-HiFiGPT, a novel conditional generative
framework for synthesizing human motion from textual descriptions. This
framework is underpinned by a Residual Vector Quantized Variational AutoEncoder
(RVQ-VAE) and a double-tier Generative Pretrained Transformer (GPT)
architecture. We demonstrate that our CNN-based RVQ-VAE is capable of producing
highly accurate 2D temporal-residual discrete motion representations. Our
proposed double-tier GPT structure comprises a temporal GPT and a residual GPT.
The temporal GPT efficiently condenses information from previous frames and
textual descriptions into a 1D context vector. This vector then serves as a
context prompt for the residual GPT, which generates the final residual
discrete indices. These indices are subsequently transformed back into motion
data by the RVQ-VAE decoder. To mitigate the exposure bias issue, we employ
straightforward code corruption techniques for RVQ and a conditional dropout
strategy, resulting in enhanced synthesis performance. Remarkably, T2M-HiFiGPT
not only simplifies the generative process but also surpasses existing methods
in both performance and parameter efficacy, including the latest
diffusion-based and GPT-based models. On the HumanML3D and KIT-ML datasets, our
framework achieves exceptional results across nearly all primary metrics. We
further validate the efficacy of our framework through comprehensive ablation
studies on the HumanML3D dataset, examining the contribution of each component.
Our findings reveal that RVQ-VAE is more adept at capturing precise 3D human
motion with comparable computational demand compared to its VQ-VAE
counterparts. As a result, T2M-HiFiGPT enables the generation of human motion
with significantly increased accuracy, outperforming recent state-of-the-art
approaches such as T2M-GPT and Att-T2M.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10631" title="Abstract">arXiv:2312.10631</a> [<a href="/pdf/2312.10631" title="Download PDF">pdf</a>, <a href="/format/2312.10631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Twin: Mini-Giant Model-driven Beyond 5G Digital Twin Networking  Framework with Semantic Secure Communication and Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Morello%2C+R">Rosario Morello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures, submitted to Scientific Reports on Nov. 12, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Beyond 5G networks provide solutions for next-generation communications,
especially digital twins networks (DTNs) have gained increasing popularity for
bridging physical space and digital space. However, current DTNs networking
frameworks pose a number of challenges especially when applied in scenarios
that require high communication efficiency and multimodal data processing.
First, current DTNs frameworks are unavoidable regarding high resource
consumption and communication congestion because of original bit-level
communication and high-frequency computation, especially distributed
learning-based DTNs. Second, current machine learning models for DTNs are
domain-specific (e.g. E-health), making it difficult to handle DT scenarios
with multimodal data processing requirements. Last but not least, current
security schemes for DTNs, such as blockchain, introduce additional overheads
that impair the efficiency of DTNs. To address the above challenges, we propose
a large language model (LLM) empowered DTNs networking framework, LLM-Twin.
First, we design the mini-giant model collaboration scheme to achieve efficient
deployment of LLM in DTNs, since LLM are naturally conducive to processing
multimodal data. Then, we design a semantic-level high-efficiency, and secure
communication model for DTNs. The feasibility of LLM-Twin is demonstrated by
numerical experiments and case studies. To our knowledge, this is the first to
propose LLM-based semantic-level digital twin networking framework.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10634" title="Abstract">arXiv:2312.10634</a> [<a href="/pdf/2312.10634" title="Download PDF">pdf</a>, <a href="/format/2312.10634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Score: Evaluating Generative Models and Individual Generated  Images based on Complexity and Vulnerability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaehui Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junghyuk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-Seok Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the advancement of generative models, the assessment of generated images
becomes more and more important. Previous methods measure distances between
features of reference and generated images from trained vision models. In this
paper, we conduct an extensive investigation into the relationship between the
representation space and input space around generated images. We first propose
two measures related to the presence of unnatural elements within images:
complexity, which indicates how non-linear the representation space is, and
vulnerability, which is related to how easily the extracted feature changes by
adversarial input changes. Based on these, we introduce a new metric to
evaluating image-generative models called anomaly score (AS). Moreover, we
propose AS-i (anomaly score for individual images) that can effectively
evaluate generated images individually. Experimental results demonstrate the
validity of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10636" title="Abstract">arXiv:2312.10636</a> [<a href="/pdf/2312.10636" title="Download PDF">pdf</a>, <a href="/format/2312.10636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graft: Efficient Inference Serving for Hybrid Deep Learning with SLO  Guarantees via DNN Re-alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qirui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have been widely adopted for various mobile
inference tasks, yet their ever-increasing computational demands are hindering
their deployment on resource-constrained mobile devices. Hybrid deep learning
partitions a DNN into two parts and deploys them across the mobile device and a
server, aiming to reduce inference latency or prolong battery life of mobile
devices. However, such partitioning produces (non-uniform) DNN fragments which
are hard to serve efficiently on the server.This paper presents Graft -- an
efficient inference serving system for hybrid deep learning with latency
service-level objective (SLO) guarantees. Our main insight is to mitigate the
non-uniformity by a core concept called DNN re-alignment, allowing multiple
heterogeneous DNN fragments to be restructured to share layers. To fully
exploit the potential of DNN re-alignment, Graft employs fine-grained GPU
resource sharing. Based on that, we propose efficient algorithms for merging,
grouping, and re-aligning DNN fragments to maximize request batching
opportunities, minimizing resource consumption while guaranteeing the inference
latency SLO. We implement a Graft prototype and perform extensive experiments
with five types of widely used DNNs and real-world network traces. Our results
show that Graft improves resource efficiency by up to 70% compared with the
state-of-the-art inference serving systems.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10637" title="Abstract">arXiv:2312.10637</a> [<a href="/pdf/2312.10637" title="Download PDF">pdf</a>, <a href="/format/2312.10637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of GPT-4V and Gemini in Online VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A comprehensive evaluation is critical to assess the capabilities of large
multimodal models (LMM). In this study, we evaluate the state-of-the-art LMMs,
namely GPT-4V and Gemini, utilizing the VQAonline dataset. VQAonline is an
end-to-end authentic VQA dataset sourced from a diverse range of everyday
users. Compared previous benchmarks, VQAonline well aligns with real-world
tasks. It enables us to effectively evaluate the generality of an LMM, and
facilitates a direct comparison with human performance. To comprehensively
evaluate GPT-4V and Gemini, we generate seven types of metadata for around
2,000 visual questions, such as image type and the required image processing
capabilities. Leveraging this array of metadata, we analyze the zero-shot
performance of GPT-4V and Gemini, and identify the most challenging questions
for both models.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10638" title="Abstract">arXiv:2312.10638</a> [<a href="/pdf/2312.10638" title="Download PDF">pdf</a>, <a href="/format/2312.10638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperPIE: Hyperparameter Information Extraction from Scientific  Publications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saier%2C+T">Tarek Saier</a>, 
<a href="/search/cs?searchtype=author&query=Ohta%2C+M">Mayumi Ohta</a>, 
<a href="/search/cs?searchtype=author&query=Asakura%2C+T">Takuto Asakura</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+M">Michael F&#xe4;rber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ECIR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Automatic extraction of information from publications is key to making
scientific knowledge machine readable at a large scale. The extracted
information can, for example, facilitate academic search, decision making, and
knowledge graph construction. An important type of information not covered by
existing approaches is hyperparameters. In this paper, we formalize and tackle
hyperparameter information extraction (HyperPIE) as an entity recognition and
relation extraction task. We create a labeled data set covering publications
from a variety of computer science disciplines. Using this data set, we train
and evaluate BERT-based fine-tuned models as well as five large language
models: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned
models, we develop a relation extraction approach that achieves an improvement
of 29% F1 over a state-of-the-art baseline. For large language models, we
develop an approach leveraging YAML output for structured data extraction,
which achieves an average improvement of 5.5% F1 in entity recognition over
using JSON. With our best performing model we extract hyperparameter
information from a large number of unannotated papers, and analyze patterns
across disciplines. All our data and source code is publicly available at
https://github.com/IllDepence/hyperpie
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10639" title="Abstract">arXiv:2312.10639</a> [<a href="/pdf/2312.10639" title="Download PDF">pdf</a>, <a href="/format/2312.10639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial intelligence optical hardware empowers high-resolution  hyperspectral video understanding at 1.2 Tb/s
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makarenko%2C+M">Maksim Makarenko</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Burguete-Lopez%2C+A">Arturo Burguete-Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Giancola%2C+S">Silvio Giancola</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Passone%2C+L">Luca Passone</a>, 
<a href="/search/cs?searchtype=author&query=Fratalocchi%2C+A">Andrea Fratalocchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Optics (physics.optics)

</div>
<p class="mathjax">Foundation models, exemplified by GPT technology, are discovering new
horizons in artificial intelligence by executing tasks beyond their designers'
expectations. While the present generation provides fundamental advances in
understanding language and images, the next frontier is video comprehension.
Progress in this area must overcome the 1 Tb/s data rate demanded to grasp
real-time multidimensional video information. This speed limit lies well beyond
the capabilities of the existing generation of hardware, imposing a roadblock
to further advances. This work introduces a hardware-accelerated integrated
optoelectronic platform for multidimensional video understanding in real-time.
The technology platform combines artificial intelligence hardware, processing
information optically, with state-of-the-art machine vision networks, resulting
in a data processing speed of 1.2 Tb/s with hundreds of frequency bands and
megapixel spatial resolution at video rates. Such performance, validated in the
AI tasks of video semantic segmentation and object understanding in indoor and
aerial applications, surpasses the speed of the closest technologies with
similar spectral resolution by three to four orders of magnitude. This platform
opens up new avenues for research in real-time AI video understanding of
multidimensional visual information, helping the empowerment of future
human-machine interactions and cognitive processing developments.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10641" title="Abstract">arXiv:2312.10641</a> [<a href="/pdf/2312.10641" title="Download PDF">pdf</a>, <a href="/format/2312.10641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming Design for Integrated Sensing and Communication with  Extended Target
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqiu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Meixia Tao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, published to 8th Workshop on Integrated Sensing and Communications for Internet of Things in IEEE Global Communications Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies transmit beamforming design in an integrated sensing and
communication (ISAC) system, where a base station sends symbols to perform
downlink multi-user communication and sense an extended target simultaneously.
We first model the extended target contour with truncated Fourier series. By
considering echo signals as reflections from the valid elements on the target
contour, a novel Cram\'er-Rao bound (CRB) on the direction estimation of
extended target is derived. We then formulate the transmit beamforming design
as an optimization problem by minimizing the CRB of radar sensing, and
satisfying a minimum signal-to-interference-plus-noise ratio requirement for
each communication user, as well as a 3-dB beam coverage requirement tailored
for the extended sensing target under a total transmit power constraint. In
view of the non-convexity of the above problem, we employ semidefinite
relaxation (SDR) technique for convex relaxation, followed by a rank-one
extraction scheme for non-tight relaxation circumstances. Numerical results
show that the proposed SDR beamforming scheme outperforms benchmark beampattern
design methods with lower CRBs for the circumstances considered.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10642" title="Abstract">arXiv:2312.10642</a> [<a href="/pdf/2312.10642" title="Download PDF">pdf</a>, <a href="/format/2312.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Episodic Return Decomposition by Difference of Implicitly Assigned  Sub-Trajectory Reward
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haoxin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongqiu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junyin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Real-world decision-making problems are usually accompanied by delayed
rewards, which affects the sample efficiency of Reinforcement Learning,
especially in the extremely delayed case where the only feedback is the
episodic reward obtained at the end of an episode. Episodic return
decomposition is a promising way to deal with the episodic-reward setting.
Several corresponding algorithms have shown remarkable effectiveness of the
learned step-wise proxy rewards from return decomposition. However, these
existing methods lack either attribution or representation capacity, leading to
inefficient decomposition in the case of long-term episodes. In this paper, we
propose a novel episodic return decomposition method called Diaster (Difference
of implicitly assigned sub-trajectory reward). Diaster decomposes any episodic
reward into credits of two divided sub-trajectories at any cut point, and the
step-wise proxy rewards come from differences in expectation. We theoretically
and empirically verify that the decomposed proxy reward function can guide the
policy to be nearly optimal. Experimental results show that our method
outperforms previous state-of-the-art methods in terms of both sample
efficiency and performance.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10645" title="Abstract">arXiv:2312.10645</a> [<a href="/pdf/2312.10645" title="Download PDF">pdf</a>, <a href="/format/2312.10645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMKGC: Privacy-Preserving Federated Multilingual Knowledge Graph  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge graph completion (KGC) aims to predict missing facts in knowledge
graphs (KGs), which is crucial as modern KGs remain largely incomplete. While
training KGC models on multiple aligned KGs can improve performance, previous
methods that rely on transferring raw data among KGs raise privacy concerns. To
address this challenge, we propose a new federated learning framework that
implicitly aggregates knowledge from multiple KGs without demanding raw data
exchange and entity alignment. We treat each KG as a client that trains a local
language model through textbased knowledge representation learning. A central
server then aggregates the model weights from clients. As natural language
provides a universal representation, the same knowledge thus has similar
semantic representations across KGs. As such, the aggregated language model can
leverage complementary knowledge from multilingual KGs without demanding raw
user data sharing. Extensive experiments on a benchmark dataset demonstrate
that our method substantially improves KGC on multilingual KGs, achieving
comparable performance to state-of-the-art alignment-based models without
requiring any labeled alignments or raw user data sharing. Our codes will be
publicly available.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10647" title="Abstract">arXiv:2312.10647</a> [<a href="/pdf/2312.10647" title="Download PDF">pdf</a>, <a href="/format/2312.10647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Stage Optimization of Open-loop Stable Limit Cycles with Smooth,  Symbolic Derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+M+S+U">Muhammad Saud Ul Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Hubicki%2C+C">Christian Hubicki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Open-loop stable limit cycles are foundational to the dynamics of legged
robots. They impart a self-stabilizing character to the robot's gait, thus
alleviating the need for compute-heavy feedback-based gait correction. This
paper proposes a general approach to rapidly generate limit cycles with
explicit stability constraints for a given dynamical system. In particular, we
pose the problem of open-loop limit cycle stability as a single-stage
constrained-optimization problem (COP), and use Direct Collocation to
transcribe it into a nonlinear program (NLP) with closed-form expressions for
constraints, objectives, and their gradients. The COP formulations of stability
are developed based (1) on the spectral radius of a discrete return map, and
(2) on the spectral radius of the system's monodromy matrix, where the spectral
radius is bounded using different constraint-satisfaction formulations of the
eigenvalue problem. We compare the performance and solution qualities of each
approach, but specifically highlight the Schur decomposition of the monodromy
matrix as a formulation which boasts wider applicability through weaker
assumptions and attractive numerical convergence properties. Moreover, we
present results from our experiments on a spring-loaded inverted pendulum model
of a robot, where our method generated actuation trajectories for open-loop
stable hopping in under 2 seconds (on the Intel Core i7-6700K), and produced
energy-minimizing actuation trajectories even under tight stability
constraints.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10648" title="Abstract">arXiv:2312.10648</a> [<a href="/pdf/2312.10648" title="Download PDF">pdf</a>, <a href="/format/2312.10648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Model Explanations through Energy-Constrained Conformal  Counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altmeyer%2C+P">Patrick Altmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Farmanbar%2C+M">Mojtaba Farmanbar</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>, 
<a href="/search/cs?searchtype=author&query=Liem%2C+C+C+S">Cynthia C. S. Liem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages main paper, 34 pages appendix. Pre-print of upcoming proceedings paper (Association for the Advancement of Artificial Intelligence (www.aaai.org))
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual explanations offer an intuitive and straightforward way to
explain black-box models and offer algorithmic recourse to individuals. To
address the need for plausible explanations, existing work has primarily relied
on surrogate models to learn how the input data is distributed. This
effectively reallocates the task of learning realistic explanations for the
data from the model itself to the surrogate. Consequently, the generated
explanations may seem plausible to humans but need not necessarily describe the
behaviour of the black-box model faithfully. We formalise this notion of
faithfulness through the introduction of a tailored evaluation metric and
propose a novel algorithmic framework for generating Energy-Constrained
Conformal Counterfactuals that are only as plausible as the model permits.
Through extensive empirical studies, we demonstrate that ECCCo reconciles the
need for faithfulness and plausibility. In particular, we show that for models
with gradient access, it is possible to achieve state-of-the-art performance
without the need for surrogate models. To do so, our framework relies solely on
properties defining the black-box model itself by leveraging recent advances in
energy-based modelling and conformal prediction. To our knowledge, this is the
first venture in this direction for generating faithful counterfactual
explanations. Thus, we anticipate that ECCCo can serve as a baseline for future
research. We believe that our work opens avenues for researchers and
practitioners seeking tools to better distinguish trustworthy from unreliable
models.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10649" title="Abstract">arXiv:2312.10649</a> [<a href="/pdf/2312.10649" title="Download PDF">pdf</a>, <a href="/format/2312.10649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PNeRFLoc: Visual Localization with Point-based Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Boming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+M">Mao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhaopeng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the ability to synthesize high-quality novel views, Neural Radiance
Fields (NeRF) have been recently exploited to improve visual localization in a
known environment. However, the existing methods mostly utilize NeRFs for data
augmentation to improve the regression model training, and the performance on
novel viewpoints and appearances is still limited due to the lack of geometric
constraints. In this paper, we propose a novel visual localization framework,
\ie, PNeRFLoc, based on a unified point-based representation. On the one hand,
PNeRFLoc supports the initial pose estimation by matching 2D and 3D feature
points as traditional structure-based methods; on the other hand, it also
enables pose refinement with novel view synthesis using rendering-based
optimization. Specifically, we propose a novel feature adaption module to close
the gaps between the features for visual localization and neural rendering. To
improve the efficacy and efficiency of neural rendering-based optimization, we
also develop an efficient rendering-based framework with a warping loss
function. Furthermore, several robustness techniques are developed to handle
illumination changes and dynamic objects for outdoor scenarios. Experiments
demonstrate that PNeRFLoc performs the best on synthetic data when the NeRF
model can be well learned and performs on par with the SOTA method on the
visual localization benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10650" title="Abstract">arXiv:2312.10650</a> [<a href="/pdf/2312.10650" title="Download PDF">pdf</a>, <a href="/format/2312.10650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Designing a Question-Answering Chatbot for Online News:  Understanding Perspectives and Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoque%2C+M+N">Md Naimul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Mahfuz%2C+A">Ayman Mahfuz</a>, 
<a href="/search/cs?searchtype=author&query=Kindi%2C+M">Mayukha Kindi</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+N">Naeemul Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have created opportunities for designing
chatbots that can support complex question-answering (QA) scenarios and improve
news audience engagement. However, we still lack an understanding of what roles
journalists and readers deem fit for such a chatbot in newsrooms. To address
this gap, we first interviewed six journalists to understand how they answer
questions from readers currently and how they want to use a QA chatbot for this
purpose. To understand how readers want to interact with a QA chatbot, we then
conducted an online experiment (N=124) where we asked each participant to read
three news articles and ask questions to either the author(s) of the articles
or a chatbot. By combining results from the studies, we present alignments and
discrepancies between how journalists and readers want to use QA chatbots and
propose a framework for designing effective QA chatbots in newsrooms.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10652" title="Abstract">arXiv:2312.10652</a> [<a href="/pdf/2312.10652" title="Download PDF">pdf</a>, <a href="/ps/2312.10652" title="Download PostScript">ps</a>, <a href="/format/2312.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explorers at #SMM4H 2023: Enhancing BERT for Health Applications through  Knowledge and Model Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xutong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xilai Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenkun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">An increasing number of individuals are willing to post states and opinions
in social media, which has become a valuable data resource for studying human
health. Furthermore, social media has been a crucial research point for
healthcare now. This paper outlines the methods in our participation in the
#SMM4H 2023 Shared Tasks, including data preprocessing, continual pre-training
and fine-tuned optimization strategies. Especially for the Named Entity
Recognition (NER) task, we utilize the model architecture named W2NER that
effectively enhances the model generalization ability. Our method achieved
first place in the Task 3. This paper has been peer-reviewed and accepted for
presentation at the #SMM4H 2023 Workshop.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10655" title="Abstract">arXiv:2312.10655</a> [<a href="/pdf/2312.10655" title="Download PDF">pdf</a>, <a href="/format/2312.10655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Non-Intrusive GUI Exploration Testing with Visual-based  Robotic Arms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shengcheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mingzhe Du</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Y">Yuchen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhendong Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 46th International Conference on Software Engineering (ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">GUI testing is significant in the SE community. Most existing frameworks are
intrusive and only support some specific platforms. With the development of
distinct scenarios, diverse embedded systems or customized operating systems on
different devices do not support existing intrusive GUI testing frameworks.
Some approaches adopt robotic arms to replace the interface invoking of mobile
apps under test and use computer vision technologies to identify GUI elements.
However, some challenges are unsolved. First, existing approaches assume that
GUI screens are fixed so that they cannot be adapted to diverse systems with
different screen conditions. Second, existing approaches use XY-plane robotic
arms, which cannot flexibly simulate testing operations. Third, existing
approaches ignore compatibility bugs and only focus on crash bugs. A more
practical approach is required for the non-intrusive scenario. We propose a
practical non-intrusive GUI testing framework with visual robotic arms.
RoboTest integrates novel GUI screen and widget detection algorithms, adaptive
to detecting screens of different sizes and then to extracting GUI widgets from
the detected screens. Then, a set of testing operations is applied with a 4-DOF
robotic arm, which effectively and flexibly simulates human testing operations.
During app exploration, RoboTest integrates the Principle of Proximity-guided
exploration strategy, choosing close widgets of the previous targets to reduce
robotic arm movement overhead and improve exploration efficiency. RoboTest can
effectively detect some compatibility bugs beyond crash bugs with a GUI
comparison on different devices of the same test operations. We evaluate
RoboTest with 20 mobile apps, with a case study on an embedded system. The
results show that RoboTest can effectively, efficiently, and generally explore
AUTs to find bugs and reduce exploration time overhead.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10656" title="Abstract">arXiv:2312.10656</a> [<a href="/pdf/2312.10656" title="Download PDF">pdf</a>, <a href="/format/2312.10656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidToMe: Video Token Merging for Zero-Shot Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vidtome-diffusion.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have made significant advances in generating high-quality
images, but their application to video generation has remained challenging due
to the complexity of temporal motion. Zero-shot video editing offers a solution
by utilizing pre-trained image diffusion models to translate source videos into
new ones. Nevertheless, existing methods struggle to maintain strict temporal
consistency and efficient memory consumption. In this work, we propose a novel
approach to enhance temporal consistency in generated videos by merging
self-attention tokens across frames. By aligning and compressing temporally
redundant tokens across frames, our method improves temporal coherence and
reduces memory consumption in self-attention computations. The merging strategy
matches and aligns tokens according to the temporal correspondence between
frames, facilitating natural temporal consistency in generated video frames. To
manage the complexity of video processing, we divide videos into chunks and
develop intra-chunk local token merging and inter-chunk global token merging,
ensuring both short-term video continuity and long-term content consistency.
Our video editing approach seamlessly extends the advancements in image editing
to video editing, rendering favorable results in temporal consistency over
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10657" title="Abstract">arXiv:2312.10657</a> [<a href="/pdf/2312.10657" title="Download PDF">pdf</a>, <a href="/format/2312.10657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraClean: A Simple Framework to Train Robust Neural Networks against  Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingyin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Y">Yingjie Lao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Backdoor attacks are emerging threats to deep neural networks, which
typically embed malicious behaviors into a victim model by injecting poisoned
samples. Adversaries can activate the injected backdoor during inference by
presenting the trigger on input images. Prior defensive methods have achieved
remarkable success in countering dirty-label backdoor attacks where the labels
of poisoned samples are often mislabeled. However, these approaches do not work
for a recent new type of backdoor -- clean-label backdoor attacks that
imperceptibly modify poisoned data and hold consistent labels. More complex and
powerful algorithms are demanded to defend against such stealthy attacks. In
this paper, we propose UltraClean, a general framework that simplifies the
identification of poisoned samples and defends against both dirty-label and
clean-label backdoor attacks. Given the fact that backdoor triggers introduce
adversarial noise that intensifies in feed-forward propagation, UltraClean
first generates two variants of training samples using off-the-shelf denoising
functions. It then measures the susceptibility of training samples leveraging
the error amplification effect in DNNs, which dilates the noise difference
between the original image and denoised variants. Lastly, it filters out
poisoned samples based on the susceptibility to thwart the backdoor
implantation. Despite its simplicity, UltraClean achieves a superior detection
rate across various datasets and significantly reduces the backdoor attack
success rate while maintaining a decent model accuracy on clean data,
outperforming existing defensive methods by a large margin. Code is available
at https://github.com/bxz9200/UltraClean.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10661" title="Abstract">arXiv:2312.10661</a> [<a href="/pdf/2312.10661" title="Download PDF">pdf</a>, <a href="/format/2312.10661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wikiformer: Pre-training with Structured Information of Wikipedia for  Ad-hoc Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weihang Su</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaolong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shengluan Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the development of deep learning and natural language processing
techniques, pre-trained language models have been widely used to solve
information retrieval (IR) problems. Benefiting from the pre-training and
fine-tuning paradigm, these models achieve state-of-the-art performance. In
previous works, plain texts in Wikipedia have been widely used in the
pre-training stage. However, the rich structured information in Wikipedia, such
as the titles, abstracts, hierarchical heading (multi-level title) structure,
relationship between articles, references, hyperlink structures, and the
writing organizations, has not been fully explored. In this paper, we devise
four pre-training objectives tailored for IR tasks based on the structured
knowledge of Wikipedia. Compared to existing pre-training methods, our approach
can better capture the semantic knowledge in the training corpus by leveraging
the human-edited structured data from Wikipedia. Experimental results on
multiple IR benchmark datasets show the superior performance of our model in
both zero-shot and fine-tuning settings compared to existing strong retrieval
baselines. Besides, experimental results in biomedical and legal domains
demonstrate that our approach achieves better performance in vertical domains
compared to previous models, especially in scenarios where long text similarity
matching is needed.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10663" title="Abstract">arXiv:2312.10663</a> [<a href="/pdf/2312.10663" title="Download PDF">pdf</a>, <a href="/format/2312.10663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristics and Metaheuristics for Dynamic Management of Computing and  Cooling Energy in Cloud Data Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arroba%2C+P">Patricia Arroba</a>, 
<a href="/search/cs?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Moya%2C+J+M">Jos&#xe9; M. Moya</a>, 
<a href="/search/cs?searchtype=author&query=Ayala%2C+J+L">Jos&#xe9; L. Ayala</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Software: Practice and Experience, 48(10), 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data centers handle impressive high figures in terms of energy consumption,
and the growing popularity of Cloud applications is intensifying their
computational demand. Moreover, the cooling needed to keep the servers within
reliable thermal operating conditions also has an impact on the thermal
distribution of the data room, thus affecting to servers' power leakage.
Optimizing the energy consumption of these infrastructures is a major challenge
to place data centers on a more scalable scenario. Thus, understanding the
relationship between power, temperature, consolidation and performance is
crucial to enable an energy-efficient management at the data center level. In
this research, we propose novel power and thermal-aware strategies and models
to provide joint cooling and computing optimizations from a local perspective
based on the global energy consumption of metaheuristic-based optimizations.
Our results show that the combined awareness from both metaheuristic and best
fit decreasing algorithms allow us to describe the global energy into faster
and lighter optimization strategies that may be used during runtime. This
approach allows us to improve the energy efficiency of the data center,
considering both computing and cooling infrastructures, in up to a 21.74\%
while maintaining quality of service.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10665" title="Abstract">arXiv:2312.10665</a> [<a href="/pdf/2312.10665" title="Download PDF">pdf</a>, <a href="/format/2312.10665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silkie: Preference Distillation for Large Visual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhihui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mukai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shunian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yazheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vlf-silkie.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper explores preference distillation for large vision language models
(LVLMs), improving their ability to generate helpful and faithful responses
anchoring the visual context. We first build a vision-language feedback
(VLFeedback) dataset utilizing AI annotation. Specifically, responses are
generated by models sampled from 12 LVLMs, conditioned on multi-modal
instructions sourced from various datasets. We adopt GPT-4V to assess the
generated outputs regarding helpfulness, visual faithfulness, and ethical
considerations. Furthermore, the preference supervision is distilled into
Qwen-VL-Chat through the direct preference optimization (DPO) method. The
resulting model Silkie, achieves 6.9% and 9.5% relative improvement on the MME
benchmark regarding the perception and cognition capabilities, respectively.
Silkie also demonstrates reduced hallucination by setting a new
state-of-the-art score of 3.02 on the MMHal-Bench benchmark. Further analysis
shows that DPO with our VLFeedback dataset mainly boosts the fine-grained
perception and complex cognition abilities of LVLMs, leading to more
comprehensive improvements compared to human-annotated preference datasets.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10666" title="Abstract">arXiv:2312.10666</a> [<a href="/pdf/2312.10666" title="Download PDF">pdf</a>, <a href="/format/2312.10666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CACTO-SL: Using Sobolev Learning to improve Continuous Actor-Critic with  Trajectory Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alboni%2C+E">Elisa Alboni</a>, 
<a href="/search/cs?searchtype=author&query=Grandesso%2C+G">Gianluigi Grandesso</a>, 
<a href="/search/cs?searchtype=author&query=Papini%2C+G+P+R">Gastone Pietro Rosati Papini</a>, 
<a href="/search/cs?searchtype=author&query=Carpentier%2C+J">Justin Carpentier</a>, 
<a href="/search/cs?searchtype=author&query=Del+Prete%2C+A">Andrea Del Prete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Trajectory Optimization (TO) and Reinforcement Learning (RL) are powerful and
complementary tools to solve optimal control problems. On the one hand, TO can
efficiently compute locally-optimal solutions, but it tends to get stuck in
local minima if the problem is not convex. On the other hand, RL is typically
less sensitive to non-convexity, but it requires a much higher computational
effort. Recently, we have proposed CACTO (Continuous Actor-Critic with
Trajectory Optimization), an algorithm that uses TO to guide the exploration of
an actor-critic RL algorithm. In turns, the policy encoded by the actor is used
to warm-start TO, closing the loop between TO and RL. In this work, we present
an extension of CACTO exploiting the idea of Sobolev learning. To make the
training of the critic network faster and more data efficient, we enrich it
with the gradient of the Value function, computed via a backward pass of the
differential dynamic programming algorithm. Our results show that the new
algorithm is more efficient than the original CACTO, reducing the number of TO
episodes by a factor ranging from 3 to 10, and consequently the computation
time. Moreover, we show that CACTO-SL helps TO to find better minima and to
produce more consistent results.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10669" title="Abstract">arXiv:2312.10669</a> [<a href="/pdf/2312.10669" title="Download PDF">pdf</a>, <a href="/ps/2312.10669" title="Download PostScript">ps</a>, <a href="/format/2312.10669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analisis Eksploratif Dan Augmentasi Data NSL-KDD Menggunakan Deep  Generative Adversarial Networks Untuk Meningkatkan Performa Algoritma Extreme  Gradient Boosting Dalam Klasifikasi Jenis Serangan Siber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santoso%2C+K+P">K. P. Santoso</a>, 
<a href="/search/cs?searchtype=author&query=Madany%2C+F+A">F. A. Madany</a>, 
<a href="/search/cs?searchtype=author&query=Suryotrisongko%2C+H">H. Suryotrisongko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Indonesian language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study proposes the implementation of Deep Generative Adversarial
Networks (GANs) for augmenting the NSL-KDD dataset. The primary objective is to
enhance the efficacy of eXtreme Gradient Boosting (XGBoost) in the
classification of cyber-attacks on the NSL-KDD dataset. As a result, the method
proposed in this research achieved an accuracy of 99.53% using the XGBoost
model without data augmentation with GAN, and 99.78% with data augmentation
using GAN.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10671" title="Abstract">arXiv:2312.10671</a> [<a href="/pdf/2312.10671" title="Download PDF">pdf</a>, <a href="/format/2312.10671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open3DIS: Open-vocabulary 3D Instance Segmentation with 2D Mask Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P+D+A">Phuc D.A. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+T+D">Tuan Duc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Kalogerakis%2C+E">Evangelos Kalogerakis</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Open3DIS, a novel solution designed to tackle the problem of
Open-Vocabulary Instance Segmentation within 3D scenes. Objects within 3D
environments exhibit diverse shapes, scales, and colors, making precise
instance-level identification a challenging task. Recent advancements in
Open-Vocabulary scene understanding have made significant strides in this area
by employing class-agnostic 3D instance proposal networks for object
localization and learning queryable features for each 3D mask. While these
methods produce high-quality instance proposals, they struggle with identifying
small-scale and geometrically ambiguous objects. The key idea of our method is
a new module that aggregates 2D instance masks across frames and maps them to
geometrically coherent point cloud regions as high-quality object proposals
addressing the above limitations. These are then combined with 3D
class-agnostic instance proposals to include a wide range of objects in the
real world. To validate our approach, we conducted experiments on three
prominent datasets, including ScanNet200, S3DIS, and Replica, demonstrating
significant performance gains in segmenting objects with diverse categories
over the state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10672" title="Abstract">arXiv:2312.10672</a> [<a href="/pdf/2312.10672" title="Download PDF">pdf</a>, <a href="/format/2312.10672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Optimisation of Normalised Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+N">Namhoon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyo-Sang Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures, submitted to 2024 L4DC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose automatic optimisation methods considering the geometry of matrix
manifold for the normalised parameters of neural networks. Layerwise weight
normalisation with respect to Frobenius norm is utilised to bound the Lipschitz
constant and to enhance gradient reliability so that the trained networks are
suitable for control applications. Our approach first initialises the network
and normalises the data with respect to the $\ell^{2}$-$\ell^{2}$ gain of the
initialised network. Then, the proposed algorithms take the update structure
based on the exponential map on high-dimensional spheres. Given an update
direction such as that of the negative Riemannian gradient, we propose two
different ways to determine the stepsize for descent. The first algorithm
utilises automatic differentiation of the objective function along the update
curve defined on the combined manifold of spheres. The directional second-order
derivative information can be utilised without requiring explicit construction
of the Hessian. The second algorithm utilises the majorisation-minimisation
framework via architecture-aware majorisation for neural networks. With these
new developments, the proposed methods avoid manual tuning and scheduling of
the learning rate, thus providing an automated pipeline for optimizing
normalised neural networks.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10674" title="Abstract">arXiv:2312.10674</a> [<a href="/pdf/2312.10674" title="Download PDF">pdf</a>, <a href="/ps/2312.10674" title="Download PostScript">ps</a>, <a href="/format/2312.10674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework of Full-Process Generation Design for Park Green Spaces  Based on Remote Sensing Segmentation-GAN-Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xingjian Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yueheng He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bainian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xueqi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zeke Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of generative design driven by artificial intelligence
algorithms is speedy. There are two research gaps in the current research: 1)
Most studies only focus on the relationship between design elements and pay
little attention to the external information of the site; 2) GAN and other
traditional generative algorithms generate results with low resolution and
insufficient details. To address these two problems, we integrate GAN, Stable
diffusion multimodal large-scale image pre-training model to construct a
full-process park generative design method: 1) First, construct a
high-precision remote sensing object extraction system for automated extraction
of urban environmental information; 2) Secondly, use GAN to construct a park
design generation system based on the external environment, which can quickly
infer and generate design schemes from urban environmental information; 3)
Finally, introduce Stable Diffusion to optimize the design plan, fill in
details, and expand the resolution of the plan by 64 times. This method can
achieve a fully unmanned design automation workflow. The research results show
that: 1) The relationship between the inside and outside of the site will
affect the algorithm generation results. 2) Compared with traditional GAN
algorithms, Stable diffusion significantly improve the information richness of
the generated results.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10676" title="Abstract">arXiv:2312.10676</a> [<a href="/pdf/2312.10676" title="Download PDF">pdf</a>, <a href="/format/2312.10676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzz Driver Synthesis for Rust Generic APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hui Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Fuzzing is a popular bug detection technique achieved by testing software
executables with random inputs. This technique can also be extended to
libraries by constructing executables that call library APIs, known as fuzz
drivers. Automated fuzz driver synthesis has been an important research topic
in recent years since it can facilitate the library fuzzing process.
Nevertheless, existing approaches generally ignore generic APIs or simply treat
them as normal APIs. As a result, they cannot generate effective fuzz drivers
for generic APIs.
<br />This paper studies the automated fuzz driver synthesis problem for Rust
libraries with generic APIs. The problem is essential because Rust emphasizes
security, and generic APIs are widely employed in Rust crates. Each generic API
can have numerous monomorphic versions as long as the type constraints are
satisfied. The critical challenge to this problem lies in prioritizing these
monomorphic versions and providing valid inputs for them. To address the
problem, we extend existing API-dependency graphs to support generic APIs. By
solving such dependencies and type constraints, we can generate a collection of
candidate monomorphic APIs. Further, we apply a similarity-based filter to
prune redundant versions, particularly if multiple monomorphic APIs adopt the
identical trait implementation. Experimental results with 29 popular
open-source libraries show that our approach can achieve promising generic API
coverage with a low rate of invalid fuzz drivers. Besides, we find 23 bugs
previously unknown in these libraries, with 18 bugs related to generic APIs.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10679" title="Abstract">arXiv:2312.10679</a> [<a href="/pdf/2312.10679" title="Download PDF">pdf</a>, <a href="/format/2312.10679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bengali Intent Classification with Generative Adversarial BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M">Mehedi Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Basher%2C+M+J+I">Mohammad Jahid Ibna Basher</a>, 
<a href="/search/cs?searchtype=author&query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Intent classification is a fundamental task in natural language
understanding, aiming to categorize user queries or sentences into predefined
classes to understand user intent. The most challenging aspect of this
particular task lies in effectively incorporating all possible classes of
intent into a dataset while ensuring adequate linguistic variation. Plenty of
research has been conducted in the related domains in rich-resource languages
like English. In this study, we introduce BNIntent30, a comprehensive Bengali
intent classification dataset containing 30 intent classes. The dataset is
excerpted and translated from the CLINIC150 dataset containing a diverse range
of user intents categorized over 150 classes. Furthermore, we propose a novel
approach for Bengali intent classification using Generative Adversarial BERT to
evaluate the proposed dataset, which we call GAN-BnBERT. Our approach leverages
the power of BERT-based contextual embeddings to capture salient linguistic
features and contextual information from the text data, while the generative
adversarial network (GAN) component complements the model's ability to learn
diverse representations of existing intent classes through generative modeling.
Our experimental results demonstrate that the GAN-BnBERT model achieves
superior performance on the newly introduced BNIntent30 dataset, surpassing the
existing Bi-LSTM and the stand-alone BERT-based classification model.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10680" title="Abstract">arXiv:2312.10680</a> [<a href="/pdf/2312.10680" title="Download PDF">pdf</a>, <a href="/format/2312.10680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainForensics: Exposing Face Forgery across Domains via Bi-directional  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qingxuan Lv</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuezun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent DeepFake detection methods have shown excellent performance on public
datasets but are significantly degraded on new forgeries. Solving this problem
is important, as new forgeries emerge daily with the continuously evolving
generative techniques. Many efforts have been made for this issue by seeking
the commonly existing traces empirically on data level. In this paper, we
rethink this problem and propose a new solution from the unsupervised domain
adaptation perspective. Our solution, called DomainForensics, aims to transfer
the forgery knowledge from known forgeries to new forgeries. Unlike recent
efforts, our solution does not focus on data view but on learning strategies of
DeepFake detectors to capture the knowledge of new forgeries through the
alignment of domain discrepancies. In particular, unlike the general domain
adaptation methods which consider the knowledge transfer in the semantic class
category, thus having limited application, our approach captures the subtle
forgery traces. We describe a new bi-directional adaptation strategy dedicated
to capturing the forgery knowledge across domains. Specifically, our strategy
considers both forward and backward adaptation, to transfer the forgery
knowledge from the source domain to the target domain in forward adaptation and
then reverse the adaptation from the target domain to the source domain in
backward adaptation. In forward adaptation, we perform supervised training for
the DeepFake detector in the source domain and jointly employ adversarial
feature adaptation to transfer the ability to detect manipulated faces from
known forgeries to new forgeries. In backward adaptation, we further improve
the knowledge transfer by coupling adversarial adaptation with
self-distillation on new forgeries. This enables the detector to expose new
forgery features from unlabeled data and avoid forgetting the known knowledge
of known...
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10684" title="Abstract">arXiv:2312.10684</a> [<a href="/pdf/2312.10684" title="Download PDF">pdf</a>, <a href="/format/2312.10684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State Estimation for Linear Systems with Quadratic Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Berkane%2C+S">Soulaimane Berkane</a>, 
<a href="/search/eess?searchtype=author&query=Theodosis%2C+D">Dionysis Theodosis</a>, 
<a href="/search/eess?searchtype=author&query=Hamel%2C+T">Tarek Hamel</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This letter deals with the problem of state estimation for a class of systems
involving linear dynamics with multiple quadratic output measurements. We
propose a systematic approach to immerse the original system into a linear
time-varying (LTV) system of a higher dimension. The methodology extends the
original system by incorporating a minimum number of auxiliary states, ensuring
that the resulting extended system exhibits both linear dynamics and linear
output. Consequently, any Kalman-type observer can showcase global state
estimation, provided the system is uniformly observable.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10686" title="Abstract">arXiv:2312.10686</a> [<a href="/pdf/2312.10686" title="Download PDF">pdf</a>, <a href="/format/2312.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated  Outlier Class Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+W">Wenjun Miao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing out-of-distribution (OOD) methods have shown great success on
balanced datasets but become ineffective in long-tailed recognition (LTR)
scenarios where 1) OOD samples are often wrongly classified into head classes
and/or 2) tail-class samples are treated as OOD samples. To address these
issues, current studies fit a prior distribution of auxiliary/pseudo OOD data
to the long-tailed in-distribution (ID) data. However, it is difficult to
obtain such an accurate prior distribution given the unknowingness of real OOD
samples and heavy class imbalance in LTR. A straightforward solution to avoid
the requirement of this prior is to learn an outlier class to encapsulate the
OOD samples. The main challenge is then to tackle the aforementioned confusion
between OOD samples and head/tail-class samples when learning the outlier
class. To this end, we introduce a novel calibrated outlier class learning
(COCL) approach, in which 1) a debiased large margin learning method is
introduced in the outlier class learning to distinguish OOD samples from both
head and tail classes in the representation space and 2) an outlier-class-aware
logit calibration method is defined to enhance the long-tailed classification
confidence. Extensive empirical results on three popular benchmarks CIFAR10-LT,
CIFAR100-LT, and ImageNet-LT demonstrate that COCL substantially outperforms
state-of-the-art OOD detection methods in LTR while being able to improve the
classification accuracy on ID data. Code is available at
https://github.com/mala-lab/COCL.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10692" title="Abstract">arXiv:2312.10692</a> [<a href="/pdf/2312.10692" title="Download PDF">pdf</a>, <a href="/format/2312.10692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pedestrian Attribute Recognition via CLIP based Prompt Vision-Language  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiandong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing pedestrian attribute recognition (PAR) algorithms adopt pre-trained
CNN (e.g., ResNet) as their backbone network for visual feature learning, which
might obtain sub-optimal results due to the insufficient employment of the
relations between pedestrian images and attribute labels. In this paper, we
formulate PAR as a vision-language fusion problem and fully exploit the
relations between pedestrian images and attribute labels. Specifically, the
attribute phrases are first expanded into sentences, and then the pre-trained
vision-language model CLIP is adopted as our backbone for feature embedding of
visual images and attribute descriptions. The contrastive learning objective
connects the vision and language modalities well in the CLIP-based feature
space, and the Transformer layers used in CLIP can capture the long-range
relations between pixels. Then, a multi-modal Transformer is adopted to fuse
the dual features effectively and feed-forward network is used to predict
attributes. To optimize our network efficiently, we propose the region-aware
prompt tuning technique to adjust very few parameters (i.e., only the prompt
vectors and classification heads) and fix both the pre-trained VL model and
multi-modal Transformer. Our proposed PAR algorithm only adjusts 0.75%
learnable parameters compared with the fine-tuning strategy. It also achieves
new state-of-the-art performance on both standard and zero-shot settings for
PAR, including RAPv1, RAPv2, WIDER, PA100K, and PETA-ZS, RAP-ZS datasets. The
source code and pre-trained models will be released on
https://github.com/Event-AHU/OpenPAR.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10693" title="Abstract">arXiv:2312.10693</a> [<a href="/pdf/2312.10693" title="Download PDF">pdf</a>, <a href="/format/2312.10693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An appointment with Reproducing Kernel Hilbert Space generated by  Generalized Gaussian RBF as $L^2-$measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Himanshu Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, MATLAB CODE, 11 figures, Results presented in AMS Spring Eastern Sectional Meeting on April 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">Gaussian Radial Basis Function (RBF) Kernels are the most-often-employed
kernels in artificial intelligence and machine learning routines for providing
optimally-best results in contrast to their respective counter-parts. However,
a little is known about the application of the Generalized Gaussian Radial
Basis Function on various machine learning algorithms namely, kernel
regression, support vector machine (SVM) and pattern-recognition via neural
networks. The results that are yielded by Generalized Gaussian RBF in the
kernel sense outperforms in stark contrast to Gaussian RBF Kernel, Sigmoid
Function and ReLU Function. This manuscript demonstrates the application of the
Generalized Gaussian RBF in the kernel sense on the aforementioned machine
learning routines along with the comparisons against the aforementioned
functions as well.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10694" title="Abstract">arXiv:2312.10694</a> [<a href="/pdf/2312.10694" title="Download PDF">pdf</a>, <a href="/format/2312.10694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretionary Trees: Understanding Street-Level Bureaucracy via Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pokharel%2C+G">Gaurab Pokharel</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sanmay Das</a>, 
<a href="/search/cs?searchtype=author&query=Fowler%2C+P+J">Patrick J. Fowler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024 AISI track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Street-level bureaucrats interact directly with people on behalf of
government agencies to perform a wide range of functions, including, for
example, administering social services and policing. A key feature of
street-level bureaucracy is that the civil servants, while tasked with
implementing agency policy, are also granted significant discretion in how they
choose to apply that policy in individual cases. Using that discretion could be
beneficial, as it allows for exceptions to policies based on human interactions
and evaluations, but it could also allow biases and inequities to seep into
important domains of societal resource allocation. In this paper, we use
machine learning techniques to understand street-level bureaucrats' behavior.
We leverage a rich dataset that combines demographic and other information on
households with information on which homelessness interventions they were
assigned during a period when assignments were not formulaic. We find that
caseworker decisions in this time are highly predictable overall, and some, but
not all of this predictivity can be captured by simple decision rules. We
theorize that the decisions not captured by the simple decision rules can be
considered applications of caseworker discretion. These discretionary decisions
are far from random in both the characteristics of such households and in terms
of the outcomes of the decisions. Caseworkers typically only apply discretion
to households that would be considered less vulnerable. When they do apply
discretion to assign households to more intensive interventions, the marginal
benefits to those households are significantly higher than would be expected if
the households were chosen at random; there is no similar reduction in marginal
benefit to households that are discretionarily allocated less intensive
interventions, suggesting that caseworkers are improving outcomes using their
knowledge.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10698" title="Abstract">arXiv:2312.10698</a> [<a href="/pdf/2312.10698" title="Download PDF">pdf</a>, <a href="/format/2312.10698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively  Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuping Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+G">George Shao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dennis Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mason Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Blockchain transactions have gained widespread adoption across various
industries, largely attributable to their unparalleled transparency and robust
security features. Nevertheless, this technique introduces various privacy
concerns, including pseudonymity, Sybil attacks, and potential susceptibilities
to quantum computing, to name a few. In response to these challenges,
innovative privacy-enhancing solutions like zero-knowledge proofs, homomorphic
encryption, and stealth addresses (SA) have been developed. Among the various
schemes, SA stands out as it prevents the association of a blockchain
transaction's output with the recipient's public address, thereby ensuring
transactional anonymity. However, the basic SA schemes have exhibited
vulnerabilities to key leakage and quantum computing attacks. To address these
shortcomings, we present a pioneering solution - Homomorphic Encryption-based
Dual-Key Stealth Address Protocol (HE-DKSAP), which can be further extended to
Fully HE-DKSAP (FHE-DKSAP). By leveraging the power of homomorphic encryption,
HE-DKSAP introduces a novel approach to safeguarding transaction privacy and
preventing potential quantum computing attacks. This paper delves into the core
principles of HE-DKSAP, highlighting its capacity to enhance privacy,
scalability, and security in programmable blockchains. Through a comprehensive
exploration of its design architecture, security analysis, and practical
implementations, this work establishes a privacy-preserving, practical, and
efficient stealth address protocol via additively homomorphic encryption.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10700" title="Abstract">arXiv:2312.10700</a> [<a href="/pdf/2312.10700" title="Download PDF">pdf</a>, <a href="/format/2312.10700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Domain Robustness of Transformer-based Keyphrase Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glazkova%2C+A">Anna Glazkova</a>, 
<a href="/search/cs?searchtype=author&query=Morozov%2C+D">Dmitry Morozov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the XXV International Conference "Data Analytics and Management in Data Intensive Domains" (DAMDID/RCDL), October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern models for text generation show state-of-the-art results in many
natural language processing tasks. In this work, we explore the effectiveness
of abstractive text summarization models for keyphrase selection. A list of
keyphrases is an important element of a text in databases and repositories of
electronic documents. In our experiments, abstractive text summarization models
fine-tuned for keyphrase generation show quite high results for a target text
corpus. However, in most cases, the zero-shot performance on other corpora and
domains is significantly lower. We investigate cross-domain limitations of
abstractive text summarization models for keyphrase generation. We present an
evaluation of the fine-tuned BART models for the keyphrase selection task
across six benchmark corpora for keyphrase extraction including scientific
texts from two domains and news texts. We explore the role of transfer learning
between different domains to improve the BART model performance on small text
corpora. Our experiments show that preliminary fine-tuning on out-of-domain
corpora can be effective under conditions of a limited number of samples.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10701" title="Abstract">arXiv:2312.10701</a> [<a href="/pdf/2312.10701" title="Download PDF">pdf</a>, <a href="/format/2312.10701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bengali License Plate Recognition: Unveiling Clarity with CNN and  GFP-GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afrin%2C+N">Noushin Afrin</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+M">Md Mahamudul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Safin%2C+M+F+E">Mohammed Fazlay Elahi Safin</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+K+R">Khondakar Rifat Amin</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+M+Z">Md Zahidul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Farzad Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated License Plate Recognition(ALPR) is a system that automatically
reads and extracts data from vehicle license plates using image processing and
computer vision techniques. The Goal of LPR is to identify and read the license
plate number accurately and quickly, even under challenging, conditions such as
poor lighting, angled or obscured plates, and different plate fonts and
layouts. The proposed method consists of processing the Bengali low-resolution
blurred license plates and identifying the plate's characters. The processes
include image restoration using GFPGAN, Maximizing contrast, Morphological
image processing like dilation, feature extraction and Using Convolutional
Neural Networks (CNN), character segmentation and recognition are accomplished.
A dataset of 1292 images of Bengali digits and characters was prepared for this
project.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10702" title="Abstract">arXiv:2312.10702</a> [<a href="/pdf/2312.10702" title="Download PDF">pdf</a>, <a href="/format/2312.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can persistent homology whiten Transformer-based black-box models? A  case study on BERT compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balderas%2C+L">Luis Balderas</a>, 
<a href="/search/cs?searchtype=author&query=Lastra%2C+M">Miguel Lastra</a>, 
<a href="/search/cs?searchtype=author&query=Ben%C3%ADtez%2C+J+M">Jos&#xe9; M. Ben&#xed;tez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) like BERT have gained significant prominence due
to their remarkable performance in various natural language processing tasks.
However, they come with substantial computational and memory costs.
Additionally, they are essentially black-box models, challenging to explain and
interpret. In this article, we propose Optimus BERT Compression and
Explainability (OBCE), a methodology to bring explainability to BERT models
using persistent homology, aiming to measure the importance of each neuron by
studying the topological characteristics of their outputs. As a result, we can
compress BERT significantly by reducing the number of parameters (58.47% of the
original parameters for BERT Base, 52.3% for BERT Large). We evaluated our
methodology on the standard GLUE Benchmark, comparing the results with
state-of-the-art techniques and achieving outstanding results. Consequently,
our methodology can "whiten" BERT models by providing explainability to its
neurons and reducing the model's size, making it more suitable for deployment
on resource-constrained devices.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10705" title="Abstract">arXiv:2312.10705</a> [<a href="/pdf/2312.10705" title="Download PDF">pdf</a>, <a href="/format/2312.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Numeric-SAM for Learning with Few Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mordoch%2C+A">Argaman Mordoch</a>, 
<a href="/search/cs?searchtype=author&query=Shperberg%2C+S+S">Shahaf S. Shperberg</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+R">Roni Stern</a>, 
<a href="/search/cs?searchtype=author&query=Juba%2C+B">Berndan Juba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A significant challenge in applying planning technology to real-world
problems lies in obtaining a planning model that accurately represents the
problem's dynamics. Numeric Safe Action Models Learning (N-SAM) is a recently
proposed algorithm that addresses this challenge. It is an algorithm designed
to learn the preconditions and effects of actions from observations in domains
that may involve both discrete and continuous state variables. N-SAM has
several attractive properties. It runs in polynomial time and is guaranteed to
output an action model that is safe, in the sense that plans generated by it
are applicable and will achieve their intended goals. To preserve this safety
guarantee, N-SAM must observe a substantial number of examples for each action
before it is included in the learned action model. We address this limitation
of N-SAM and propose N-SAM*, an enhanced version of N-SAM that always returns
an action model where every observed action is applicable at least in some
state, even if it was only observed once. N-SAM* does so without compromising
the safety of the returned action model. We prove that N-SAM* is optimal in
terms of sample complexity compared to any other algorithm that guarantees
safety. An empirical study on a set of benchmark domains shows that the action
models returned by N-SAM* enable solving significantly more problems compared
to the action models returned by N-SAM.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10708" title="Abstract">arXiv:2312.10708</a> [<a href="/pdf/2312.10708" title="Download PDF">pdf</a>, <a href="/format/2312.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Conditioning Bias in Binary Decision Trees and Random Forests and  Its Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tim%C3%A1r%2C+G">G&#xe1;bor Tim&#xe1;r</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+G">Gy&#xf6;rgy Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Decision tree and random forest classification and regression are some of the
most widely used in machine learning approaches. Binary decision tree
implementations commonly use conditioning in the form 'feature $\leq$ (or $&lt;$)
threshold', with the threshold being the midpoint between two observed feature
values. In this paper, we investigate the bias introduced by the choice of
conditioning operator (an intrinsic property of implementations) in the
presence of features with lattice characteristics. We propose techniques to
eliminate this bias, requiring an additional prediction with decision trees and
incurring no cost for random forests. Using 20 classification and 20 regression
datasets, we demonstrate that the bias can lead to statistically significant
differences in terms of AUC and $r^2$ scores. The proposed techniques
successfully mitigate the bias, compared to the worst-case scenario,
statistically significant improvements of up to 0.1-0.2 percentage points of
AUC and $r^2$ scores were achieved and the improvement of 1.5 percentage points
of $r^2$ score was measured in the most sensitive case of random forest
regression. The implementation of the study is available on GitHub at the
following repository: \url{https://github.com/gykovacs/conditioning_bias}.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10713" title="Abstract">arXiv:2312.10713</a> [<a href="/pdf/2312.10713" title="Download PDF">pdf</a>, <a href="/format/2312.10713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Black-box Anti-forensics DeepFakes with High Visual Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Bing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Feng Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">DeepFake, an AI technology for creating facial forgeries, has garnered global
attention. Amid such circumstances, forensics researchers focus on developing
defensive algorithms to counter these threats. In contrast, there are
techniques developed for enhancing the aggressiveness of DeepFake, e.g.,
through anti-forensics attacks, to disrupt forensic detectors. However, such
attacks often sacrifice image visual quality for improved undetectability. To
address this issue, we propose a method to generate novel adversarial
sharpening masks for launching black-box anti-forensics attacks. Unlike many
existing arts, with such perturbations injected, DeepFakes could achieve high
anti-forensics performance while exhibiting pleasant sharpening visual effects.
After experimental evaluations, we prove that the proposed method could
successfully disrupt the state-of-the-art DeepFake detectors. Besides, compared
with the images processed by existing DeepFake anti-forensics methods, the
visual qualities of anti-forensics DeepFakes rendered by the proposed method
are significantly refined.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10714" title="Abstract">arXiv:2312.10714</a> [<a href="/pdf/2312.10714" title="Download PDF">pdf</a>, <a href="/format/2312.10714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primitive-based 3D Human-Object Interaction Modelling and Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhou Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Embedding Human and Articulated Object Interaction (HAOI) in 3D is an
important direction for a deeper human activity understanding. Different from
previous works that use parametric and CAD models to represent humans and
objects, in this work, we propose a novel 3D geometric primitive-based language
to encode both humans and objects. Given our new paradigm, humans and objects
are all compositions of primitives instead of heterogeneous entities. Thus,
mutual information learning may be achieved between the limited 3D data of
humans and different object categories. Moreover, considering the simplicity of
the expression and the richness of the information it contains, we choose the
superquadric as the primitive representation. To explore an effective embedding
of HAOI for the machine, we build a new benchmark on 3D HAOI consisting of
primitives together with their images and propose a task requiring machines to
recover 3D HAOI using primitives from images. Moreover, we propose a baseline
of single-view 3D reconstruction on HAOI. We believe this primitive-based 3D
HAOI representation would pave the way for 3D HAOI studies. Our code and data
are available at https://mvig-rhos.com/p3haoi.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10715" title="Abstract">arXiv:2312.10715</a> [<a href="/pdf/2312.10715" title="Download PDF">pdf</a>, <a href="/format/2312.10715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite element analysis of the nearly incompressible linear elasticity  eigenvalue problem with variable coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Khan%2C+A">Arbaz Khan</a>, 
<a href="/search/math?searchtype=author&query=Lepe%2C+F">Felipe Lepe</a>, 
<a href="/search/math?searchtype=author&query=Mora%2C+D">David Mora</a>, 
<a href="/search/math?searchtype=author&query=Vellojin%2C+J">Jesus Vellojin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a mathematical and numerical analysis of an
eigenvalue problem associated to the elasticity-Stokes equations stated in two
and three dimensions. Both problems are related through the Herrmann pressure.
Employing the Babu\v ska--Brezzi theory, it is proved that the resulting
continuous and discrete variational formulations are well-posed. In particular,
the finite element method is based on general inf-sup stables pairs for the
Stokes system, such that, Taylor--Hood finite elements. By using a general
approximation theory for compact operators, we obtain optimal order error
estimates for the eigenfunctions and a double order for the eigenvalues. Under
mild assumptions, we have that these estimates hold with constants independent
of the Lam\'e coefficient $\lambda$. In addition, we carry out the reliability
and efficiency analysis of a residual-based a posteriori error estimator for
the spectral problem. We report a series of numerical tests in order to assess
the performance of the method and its behavior when the nearly incompressible
case of elasticity is considered.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10718" title="Abstract">arXiv:2312.10718</a> [<a href="/pdf/2312.10718" title="Download PDF">pdf</a>, <a href="/format/2312.10718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogCartoon: Towards Practical Story Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhongyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The state-of-the-art methods for story visualization demonstrate a
significant demand for training data and storage, as well as limited
flexibility in story presentation, thereby rendering them impractical for
real-world applications. We introduce CogCartoon, a practical story
visualization method based on pre-trained diffusion models. To alleviate
dependence on data and storage, we propose an innovative strategy of
character-plugin generation that can represent a specific character as a
compact 316 KB plugin by using a few training samples. To facilitate enhanced
flexibility, we employ a strategy of plugin-guided and layout-guided inference,
enabling users to seamlessly incorporate new characters and custom layouts into
the generated image results at their convenience. We have conducted
comprehensive qualitative and quantitative studies, providing compelling
evidence for the superiority of CogCartoon over existing methodologies.
Moreover, CogCartoon demonstrates its power in tackling challenging tasks,
including long story visualization and realistic style story visualization.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10725" title="Abstract">arXiv:2312.10725</a> [<a href="/pdf/2312.10725" title="Download PDF">pdf</a>, <a href="/format/2312.10725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Sample Inefficiency in Multi-View Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+K+K">Kumar Krishna Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Arna Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Oberman%2C+A">Adam Oberman</a>, 
<a href="/search/cs?searchtype=author&query=Richards%2C+B">Blake Richards</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins
and VICReg have shown great promise for label-free representation learning in
computer vision. Despite the apparent simplicity of these techniques,
researchers must rely on several empirical heuristics to achieve competitive
performance, most notably using high-dimensional projector heads and two
augmentations of the same image. In this work, we provide theoretical insights
on the implicit bias of the BarlowTwins and VICReg loss that can explain these
heuristics and guide the development of more principled recommendations. Our
first insight is that the orthogonality of the features is more critical than
projector dimensionality for learning good representations. Based on this, we
empirically demonstrate that low-dimensional projector heads are sufficient
with appropriate regularization, contrary to the existing heuristic. Our second
theoretical insight suggests that using multiple data augmentations better
represents the desiderata of the SSL objective. Based on this, we demonstrate
that leveraging more augmentations per sample improves representation quality
and trainability. In particular, it improves optimization convergence, leading
to better features emerging earlier in the training. Remarkably, we demonstrate
that we can reduce the pretraining dataset size by up to 4x while maintaining
accuracy and improving convergence simply by using more data augmentations.
Combining these insights, we present practical pretraining recommendations that
improve wall-clock time by 2x and improve performance on CIFAR-10/STL-10
datasets using a ResNet-50 backbone. Thus, this work provides a theoretical
insight into NC-SSL and produces practical recommendations for enhancing its
sample and compute efficiency.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10726" title="Abstract">arXiv:2312.10726</a> [<a href="/pdf/2312.10726" title="Download PDF">pdf</a>, <a href="/format/2312.10726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Compact 3D Representations via Point Feature Enhancement Masked  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zha%2C+Y">Yaohua Zha</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Huizhen Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning 3D representation plays a critical role in masked autoencoder (MAE)
based pre-training methods for point cloud, including single-modal and
cross-modal based MAE. Specifically, although cross-modal MAE methods learn
strong 3D representations via the auxiliary of other modal knowledge, they
often suffer from heavy computational burdens and heavily rely on massive
cross-modal data pairs that are often unavailable, which hinders their
applications in practice. Instead, single-modal methods with solely point
clouds as input are preferred in real applications due to their simplicity and
efficiency. However, such methods easily suffer from limited 3D representations
with global random mask input. To learn compact 3D representations, we propose
a simple yet effective Point Feature Enhancement Masked Autoencoders
(Point-FEMAE), which mainly consists of a global branch and a local branch to
capture latent semantic features. Specifically, to learn more compact features,
a share-parameter Transformer encoder is introduced to extract point features
from the global and local unmasked patches obtained by global random and local
block mask strategies, followed by a specific decoder to reconstruct.
Meanwhile, to further enhance features in the local branch, we propose a Local
Enhancement Module with local patch convolution to perceive fine-grained local
context at larger scales. Our method significantly improves the pre-training
efficiency compared to cross-modal alternatives, and extensive downstream
experiments underscore the state-of-the-art effectiveness, particularly
outperforming our baseline (Point-MAE) by 5.16%, 5.00%, and 5.04% in three
variants of ScanObjectNN, respectively. The code is available at
https://github.com/zyh16143998882/AAAI24-PointFEMAE.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10728" title="Abstract">arXiv:2312.10728</a> [<a href="/pdf/2312.10728" title="Download PDF">pdf</a>, <a href="/format/2312.10728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarks for Physical Reasoning AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnik%2C+A">Andrew Melnik</a>, 
<a href="/search/cs?searchtype=author&query=Schiewer%2C+R">Robin Schiewer</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+M">Moritz Lange</a>, 
<a href="/search/cs?searchtype=author&query=Muresanu%2C+A">Andrei Muresanu</a>, 
<a href="/search/cs?searchtype=author&query=Saeidi%2C+M">Mozhgan Saeidi</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+H">Helge Ritter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Physical reasoning is a crucial aspect in the development of general AI
systems, given that human learning starts with interacting with the physical
world before progressing to more complex concepts. Although researchers have
studied and assessed the physical reasoning of AI approaches through various
specific benchmarks, there is no comprehensive approach to evaluating and
measuring progress. Therefore, we aim to offer an overview of existing
benchmarks and their solution approaches and propose a unified perspective for
measuring the physical reasoning capacity of AI systems. We select benchmarks
that are designed to test algorithmic performance in physical reasoning tasks.
While each of the selected benchmarks poses a unique challenge, their ensemble
provides a comprehensive proving ground for an AI generalist agent with a
measurable skill level for various physical reasoning concepts. This gives an
advantage to such an ensemble of benchmarks over other holistic benchmarks that
aim to simulate the real world by intertwining its complexity and many
concepts. We group the presented set of physical reasoning benchmarks into
subcategories so that more narrow generalist AI agents can be tested first on
these groups.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10730" title="Abstract">arXiv:2312.10730</a> [<a href="/pdf/2312.10730" title="Download PDF">pdf</a>, <a href="/format/2312.10730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Distillation Helps Smaller Language Model Better Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chenglin%2C+L">Li Chenglin</a>, 
<a href="/search/cs?searchtype=author&query=Qianglong%2C+C">Chen Qianglong</a>, 
<a href="/search/cs?searchtype=author&query=Caiyu%2C+W">Wang Caiyu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhang Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in Progress, 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the remarkable performance of large language models (LLMs) in recent
NLP tasks, their deployment poses substantial challenges due to high
computational and memory demands. Recent research has concentrated on improving
open-source smaller models through knowledge distillation from LLMs to reduce
computational resource costs with promising outcomes. Nevertheless, they
frequently fall short of attaining LLM-level performance, particularly in tasks
demanding advanced reasoning. In this work, we introduce the \textbf{Mixed
Distillation} framework, which capitalizes on the strengths of
Program-of-Thought (PoT) and Chain-of-Thought (CoT) capabilities within LLMs
and distills these capabilities to smaller models. Regarding these two
capabilities, the PoT is dedicated to enhancing the performance of reasoning
results generated by smaller models, while CoT simultaneously optimizes the
results. Our Mixed Distillation framework offers a promising approach to
enhance the capabilities of smaller models, bridging the gap with LLMs, and
demonstrating better performance across various tasks. Specifically, on the
SVAMP dataset, employing a 7 billion parameter Llama2 and CodeLlama in a mixed
distillation framework not only boosts distillation capabilities beyond
single-path distillation methods but also outperforms the LLM (GPT-3.5-turbo)
in terms of reasoning accuracy. Through sampling in multiple-path reasoning,
the models achieve impressive accuracy performances of 85% and 85.5%,
respectively, signifying advancements over previous distillation methods.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10737" title="Abstract">arXiv:2312.10737</a> [<a href="/pdf/2312.10737" title="Download PDF">pdf</a>, <a href="/format/2312.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Incident Database with Multiple Labels Including Various  Perspective Environmental Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishiyama%2C+S">Shota Nishiyama</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+T">Takuma Saito</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+R">Ryo Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Ohtani%2C+G">Go Ohtani</a>, 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+H">Hirokatsu Kataoka</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+K">Kensho Hara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Traffic accident recognition is essential in developing automated driving and
Advanced Driving Assistant System technologies.A large dataset of annotated
traffic accidents is necessary to improve the accuracy of traffic accident
recognition using deep learning models.Conventional traffic accident datasets
provide annotations on the presence or absence of traffic accidents and other
teacher labels, improving traffic accident recognition performance. Therefore,
we propose V-TIDB, a large-scale traffic accident recognition dataset annotated
with various environmental information as multi-labels. Our proposed dataset
aims to improve the performance of traffic accident recognition by annotating
ten types of environmental information in addition to the presence or absence
of traffic accidents. V-TIDB is constructed by collecting many videos from the
Internet and annotating them with appropriate environmental information.In our
experiments, we compare the performance of traffic accident recognition when
only labels related to the presence or absence of traffic accidents are trained
and when environmental information is added as a multi-label. In the second
experiment, we compare the performance of the training with only contact level
which represents the severity of the traffic accident, and the performance with
environmental information added as a multi-label.The results showed that 6 out
of 10 environmental information labels improved the performance of recognizing
the presence or absence of traffic accidents. In the experiment on the degree
of recognition of traffic accidents, the performance of recognition of car
wrecks and contacts was improved for all environmental information. These
experiments show that V-TIDB can be used to learn traffic accident recognition
models that take environmental information into account in detail and can be
used for appropriate traffic accident analysis.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10740" title="Abstract">arXiv:2312.10740</a> [<a href="/pdf/2312.10740" title="Download PDF">pdf</a>, <a href="/format/2312.10740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unmasking Deepfake Faces from Videos Using An Explainable Cost-Sensitive  Deep Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+F">Faysal Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+Y">Yusha Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Minhajul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Aziz%2C+T">Tahsin Aziz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deepfake technology is widely used, which has led to serious worries about
the authenticity of digital media, making the need for trustworthy deepfake
face recognition techniques more urgent than ever. This study employs a
resource-effective and transparent cost-sensitive deep learning method to
effectively detect deepfake faces in videos. To create a reliable deepfake
detection system, four pre-trained Convolutional Neural Network (CNN) models:
XceptionNet, InceptionResNetV2, EfficientNetV2S, and EfficientNetV2M were used.
FaceForensics++ and CelebDf-V2 as benchmark datasets were used to assess the
performance of our method. To efficiently process video data, key frame
extraction was used as a feature extraction technique. Our main contribution is
to show the models adaptability and effectiveness in correctly identifying
deepfake faces in videos. Furthermore, a cost-sensitive neural network method
was applied to solve the dataset imbalance issue that arises frequently in
deepfake detection. The XceptionNet model on the CelebDf-V2 dataset gave the
proposed methodology a 98% accuracy, which was the highest possible whereas,
the InceptionResNetV2 model, achieves an accuracy of 94% on the FaceForensics++
dataset. Source Code:
https://github.com/Faysal-MD/Unmasking-Deepfake-Faces-from-Videos-An-Explainable-Cost-Sensitive-Deep-Learning-Approach-IEEE2023
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10742" title="Abstract">arXiv:2312.10742</a> [<a href="/pdf/2312.10742" title="Download PDF">pdf</a>, <a href="/ps/2312.10742" title="Download PostScript">ps</a>, <a href="/format/2312.10742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Sound vs Vibration for Robust Fault Detection on Rotating  Machinery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/cs?searchtype=author&query=Devecioglu%2C+O+C">Ozer Can Devecioglu</a>, 
<a href="/search/cs?searchtype=author&query=Alhams%2C+A">Amir Alhams</a>, 
<a href="/search/cs?searchtype=author&query=Sassi%2C+S">Sadok Sassi</a>, 
<a href="/search/cs?searchtype=author&query=Ince%2C+T">Turker Ince</a>, 
<a href="/search/cs?searchtype=author&query=Avci%2C+O">Onur Avci</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Robust and real-time detection of faults on rotating machinery has become an
ultimate objective for predictive maintenance in various industries.
Vibration-based Deep Learning (DL) methodologies have become the de facto
standard for bearing fault detection as they can produce state-of-the-art
detection performances under certain conditions. Despite such particular focus
on the vibration signal, the utilization of sound, on the other hand, has been
neglected whilst only a few studies have been proposed during the last two
decades, all of which were based on a conventional ML approach. One major
reason is the lack of a benchmark dataset providing a large volume of both
vibration and sound data over several working conditions for different machines
and sensor locations. In this study, we address this need by presenting the new
benchmark Qatar University Dual-Machine Bearing Fault Benchmark dataset
(QU-DMBF), which encapsulates sound and vibration data from two different
motors operating under 1080 working conditions overall. Then we draw the focus
on the major limitations and drawbacks of vibration-based fault detection due
to numerous installation and operational conditions. Finally, we propose the
first DL approach for sound-based fault detection and perform comparative
evaluations between the sound and vibration over the QU-DMBF dataset. A wide
range of experimental results shows that the sound-based fault detection method
is significantly more robust than its vibration-based counterpart, as it is
entirely independent of the sensor location, cost-effective (requiring no
sensor and sensor maintenance), and can achieve the same level of the best
detection performance by its vibration-based counterpart. With this study, the
QU-DMBF dataset, the optimized source codes in PyTorch, and comparative
evaluations are now publicly shared.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10743" title="Abstract">arXiv:2312.10743</a> [<a href="/pdf/2312.10743" title="Download PDF">pdf</a>, <a href="/format/2312.10743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Multi-Domain CTR Prediction via Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zichuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuhan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+K">Kuicai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Still being revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-Through Rate (CTR) prediction is a crucial task in online
recommendation platforms as it involves estimating the probability of user
engagement with advertisements or items by clicking on them. Given the
availability of various services like online shopping, ride-sharing, food
delivery, and professional services on commercial platforms, recommendation
systems in these platforms are required to make CTR predictions across multiple
domains rather than just a single domain. However, multi-domain click-through
rate (MDCTR) prediction remains a challenging task in online recommendation due
to the complex mutual influence between domains. Traditional MDCTR models
typically encode domains as discrete identifiers, ignoring rich semantic
information underlying. Consequently, they can hardly generalize to new
domains. Besides, existing models can be easily dominated by some specific
domains, which results in significant performance drops in the other domains
(\ie the ``seesaw phenomenon``). In this paper, we propose a novel solution
Uni-CTR to address the above challenges. Uni-CTR leverages a backbone Large
Language Model (LLM) to learn layer-wise semantic representations that capture
commonalities between domains. Uni-CTR also uses several domain-specific
networks to capture the characteristics of each domain. Note that we design a
masked loss strategy so that these domain-specific networks are decoupled from
backbone LLM. This allows domain-specific networks to remain unchanged when
incorporating new or removing domains, thereby enhancing the flexibility and
scalability of the system significantly. Experimental results on three public
datasets show that Uni-CTR outperforms the state-of-the-art (SOTA) MDCTR models
significantly. Furthermore, Uni-CTR demonstrates remarkable effectiveness in
zero-shot prediction. We have applied Uni-CTR in industrial scenarios,
confirming its efficiency.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10746" title="Abstract">arXiv:2312.10746</a> [<a href="/pdf/2312.10746" title="Download PDF">pdf</a>, <a href="/format/2312.10746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Trees: Gradient Boosting Decision Trees on Knowledge Neurons  as Probing Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saltykov%2C+S+A">Sergey A. Saltykov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To understand how well a large language model captures certain semantic or
syntactic features, researchers typically apply probing classifiers. However,
the accuracy of these classifiers is critical for the correct interpretation of
the results. If a probing classifier exhibits low accuracy, this may be due
either to the fact that the language model does not capture the property under
investigation, or to shortcomings in the classifier itself, which is unable to
adequately capture the characteristics encoded in the internal representations
of the model. Consequently, for more effective diagnosis, it is necessary to
use the most accurate classifiers possible for a particular type of task.
Logistic regression on the output representation of the transformer neural
network layer is most often used to probing the syntactic properties of the
language model.
<br />We show that using gradient boosting decision trees at the Knowledge Neuron
layer, i.e., at the hidden layer of the feed-forward network of the transformer
as a probing classifier for recognizing parts of a sentence is more
advantageous than using logistic regression on the output representations of
the transformer layer. This approach is also preferable to many other methods.
The gain in error rate, depending on the preset, ranges from 9-54%
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10747" title="Abstract">arXiv:2312.10747</a> [<a href="/pdf/2312.10747" title="Download PDF">pdf</a>, <a href="/format/2312.10747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CEIR: Concept-based Explainable Image Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liuzhuozheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhiyuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In modern machine learning, the trend of harnessing self-supervised learning
to derive high-quality representations without label dependency has garnered
significant attention. However, the absence of label information, coupled with
the inherently high-dimensional nature, improves the difficulty for the
interpretation of learned representations. Consequently, indirect evaluations
become the popular metric for evaluating the quality of these features, leading
to a biased validation of the learned representation rationale. To address
these challenges, we introduce a novel approach termed Concept-based
Explainable Image Representation (CEIR). Initially, using the Concept-based
Model (CBM) incorporated with pretrained CLIP and concepts generated by GPT-4,
we project input images into a concept vector space. Subsequently, a
Variational Autoencoder (VAE) learns the latent representation from these
projected concepts, which serves as the final image representation. Due to the
capability of the representation to encapsulate high-level, semantically
relevant concepts, the model allows for attributions to a human-comprehensible
concept space. This not only enhances interpretability but also preserves the
robustness essential for downstream tasks. For instance, our method exhibits
state-of-the-art unsupervised clustering performance on benchmarks such as
CIFAR10, CIFAR100, and STL10. Furthermore, capitalizing on the universality of
human conceptual understanding, CEIR can seamlessly extract the related concept
from open-world images without fine-tuning. This offers a fresh approach to
automatic label generation and label manipulation.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10748" title="Abstract">arXiv:2312.10748</a> [<a href="/pdf/2312.10748" title="Download PDF">pdf</a>, <a href="/format/2312.10748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Label Classification of COVID-Tweets Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subhankar Maity</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Vaccination is important to minimize the risk and spread of various diseases.
In recent years, vaccination has been a key step in countering the COVID-19
pandemic. However, many people are skeptical about the use of vaccines for
various reasons, including the politics involved, the potential side effects of
vaccines, etc. The goal in this task is to build an effective multi-label
classifier to label a social media post (particularly, a tweet) according to
the specific concern(s) towards vaccines as expressed by the author of the
post. We tried three different models-(a) Supervised BERT-large-uncased, (b)
Supervised HateXplain model, and (c) Zero-Shot GPT-3.5 Turbo model. The
Supervised BERT-large-uncased model performed best in our case. We achieved a
macro-F1 score of 0.66, a Jaccard similarity score of 0.66, and received the
sixth rank among other submissions. Code is available
at-https://github.com/anonmous1981/AISOME
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10750" title="Abstract">arXiv:2312.10750</a> [<a href="/pdf/2312.10750" title="Download PDF">pdf</a>, <a href="/format/2312.10750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distinguishing Translations by Human, NMT, and ChatGPT: A Linguistic and  Statistical Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhaokun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qianxi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The growing popularity of neural machine translation (NMT) and LLMs
represented by ChatGPT underscores the need for a deeper understanding of their
distinct characteristics and relationships. Such understanding is crucial for
language professionals and researchers to make informed decisions and tactful
use of these cutting-edge translation technology, but remains underexplored.
This study aims to fill this gap by investigating three key questions: (1) the
distinguishability of ChatGPT-generated translations from NMT and human
translation (HT), (2) the linguistic characteristics of each translation type,
and (3) the degree of resemblance between ChatGPT-produced translations and HT
or NMT. To achieve these objectives, we employ statistical testing, machine
learning algorithms, and multidimensional analysis (MDA) to analyze
Spokesperson's Remarks and their translations. After extracting a wide range of
linguistic features, supervised classifiers demonstrate high accuracy in
distinguishing the three translation types, whereas unsupervised clustering
techniques do not yield satisfactory results. Another major finding is that
ChatGPT-produced translations exhibit greater similarity with NMT than HT in
most MDA dimensions, which is further corroborated by distance computing and
visualization. These novel insights shed light on the interrelationships among
the three translation types and have implications for the future advancements
of NMT and generative AI.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10758" title="Abstract">arXiv:2312.10758</a> [<a href="/pdf/2312.10758" title="Download PDF">pdf</a>, <a href="/format/2312.10758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHaRPose: Sparse High-Resolution Representation for Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xiaoqi An</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-resolution representation is essential for achieving good performance in
human pose estimation models. To obtain such features, existing works utilize
high-resolution input images or fine-grained image tokens. However, this dense
high-resolution representation brings a significant computational burden. In
this paper, we address the following question: "Only sparse human keypoint
locations are detected for human pose estimation, is it really necessary to
describe the whole image in a dense, high-resolution manner?" Based on dynamic
transformer models, we propose a framework that only uses Sparse
High-resolution Representations for human Pose estimation (SHaRPose). In
detail, SHaRPose consists of two stages. At the coarse stage, the relations
between image regions and keypoints are dynamically mined while a coarse
estimation is generated. Then, a quality predictor is applied to decide whether
the coarse estimation results should be refined. At the fine stage, SHaRPose
builds sparse high-resolution representations only on the regions related to
the keypoints and provides refined high-precision human pose estimations.
Extensive experiments demonstrate the outstanding performance of the proposed
method. Specifically, compared to the state-of-the-art method ViTPose, our
model SHaRPose-Base achieves 77.4 AP (+0.5 AP) on the COCO validation set and
76.7 AP (+0.5 AP) on the COCO test-dev set, and infers at a speed of
$1.4\times$ faster than ViTPose-Base.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10763" title="Abstract">arXiv:2312.10763</a> [<a href="/pdf/2312.10763" title="Download PDF">pdf</a>, <a href="/format/2312.10763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3DBench: Let&#x27;s Instruct Large Models with Multi-modal 3D Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sijin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fukun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D understanding has become popular to facilitate autonomous agents
to perform further decisionmaking. However, existing 3D datasets and methods
are often limited to specific tasks. On the other hand, recent progress in
Large Language Models (LLMs) and Multimodal Language Models (MLMs) have
demonstrated exceptional general language and imagery tasking performance.
Therefore, it is interesting to unlock MLM's potential to be 3D generalist for
wider tasks. However, current MLMs' research has been less focused on 3D tasks
due to a lack of large-scale 3D instruction-following datasets. In this work,
we introduce a comprehensive 3D instructionfollowing dataset called M3DBench,
which possesses the following characteristics: 1) It supports general
multimodal instructions interleaved with text, images, 3D objects, and other
visual prompts. 2) It unifies diverse 3D tasks at both region and scene levels,
covering a variety of fundamental abilities in real-world 3D environments. 3)
It is a large-scale 3D instruction-following dataset with over 320k
instruction-response pairs. Furthermore, we establish a new benchmark for
assessing the performance of large models in understanding multi-modal 3D
prompts. Extensive experiments demonstrate the effectiveness of our dataset and
baseline, supporting general 3D-centric tasks, which can inspire future
research.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10764" title="Abstract">arXiv:2312.10764</a> [<a href="/pdf/2312.10764" title="Download PDF">pdf</a>, <a href="/ps/2312.10764" title="Download PostScript">ps</a>, <a href="/format/2312.10764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency of P-time event graphs is decidable in polynomial time  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zorzenon%2C+D">Davide Zorzenon</a>, 
<a href="/search/cs?searchtype=author&query=Raisch%2C+J">J&#xf6;rg Raisch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, extension of submitted conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM); Systems and Control (eess.SY)

</div>
<p class="mathjax">P-time event graphs are discrete event systems able to model cyclic
production systems where tasks need to be performed within given time windows.
Consistency is the property of admitting an infinite execution of such tasks
that does not violate any temporal constraints. In this paper, we solve the
long-standing problem of characterizing the decidability of consistency by
showing that, assuming unary encoding of the initial marking, this property can
be verified in strongly polynomial time. The proof is based on a reduction to
the problem of detecting paths with infinite weight in infinite weighted
digraphs called N-periodic graphs.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10766" title="Abstract">arXiv:2312.10766</a> [<a href="/pdf/2312.10766" title="Download PDF">pdf</a>, <a href="/format/2312.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaojun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Large Language Models and Multi-Modal LLMs have become pervasive, and so does
the importance of their security; yet, modern LLMs are known to be vulnerable
to jailbreaking attacks. These attacks can allow malicious users to exploit the
models, making the case for effective jailbreak detection mechanisms an
essential aspect of maintaining the integrity and trustworthiness of LLM-based
applications. However, existing detection works on jailbreak attacks have
limitations. Existing post-query-based strategies require target domain
knowledge, and pre-query-based methods mainly focus on text-level attacks and
fail to meet the increasingly complex multi-modal security requirements placed
upon contemporary LLMs. This gap underscores the need for a more comprehensive
approach to safeguarding these influential systems.
<br />In this work, we propose JailGuard, the first mutation-based jailbreaking
detection framework which supports both image and text modalities. Our key
observation is that attack queries inherently possess less robustness compared
to benign queries. Specifically, to confuse the model, attack queries are
usually crafted with well-designed templates or complicate perturbations,
leading to a fact that a slight disturbance in input may result in a drastic
change in the response. This lack of robustness can be utilized in attack
detection. Based on this intuition, we designed and implemented a detection
framework comprising 19 different mutators and a divergence-based detection
formula. To fully understand the effectiveness of our framework, we built the
first multi-modal LLM jailbreaking attack dataset, which has 304 items of data,
covering ten types of known jailbreaking attacks on image and text modalities.
The evaluation suggests that JailGuard achieves the best detection accuracy of
89.38%/85.42% on image and text inputs, outperforming state-of-the-art defense
methods by 15.28%.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10770" title="Abstract">arXiv:2312.10770</a> [<a href="/pdf/2312.10770" title="Download PDF">pdf</a>, <a href="/format/2312.10770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Knowledge Neurons in Protein Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nori%2C+D">Divya Nori</a>, 
<a href="/search/cs?searchtype=author&query=Singireddy%2C+S">Shivali Singireddy</a>, 
<a href="/search/cs?searchtype=author&query=Have%2C+M+T">Marina Ten Have</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Neural language models have become powerful tools for learning complex
representations of entities in natural language processing tasks. However,
their interpretability remains a significant challenge, particularly in domains
like computational biology where trust in model predictions is crucial. In this
work, we aim to enhance the interpretability of protein language models,
specifically the state-of-the-art ESM model, by identifying and characterizing
knowledge neurons - components that express understanding of key information.
After fine-tuning the ESM model for the task of enzyme sequence classification,
we compare two knowledge neuron selection methods that preserve a subset of
neurons from the original model. The two methods, activation-based and
integrated gradient-based selection, consistently outperform a random baseline.
In particular, these methods show that there is a high density of knowledge
neurons in the key vector prediction networks of self-attention modules. Given
that key vectors specialize in understanding different features of input
sequences, these knowledge neurons could capture knowledge of different enzyme
sequence motifs. In the future, the types of knowledge captured by each neuron
could be characterized.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10771" title="Abstract">arXiv:2312.10771</a> [<a href="/pdf/2312.10771" title="Download PDF">pdf</a>, <a href="/format/2312.10771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest  Neighbor In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongfen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiangshu Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunlong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Task-Oriented Parsing (TOP) enables conversational assistants to interpret
user commands expressed in natural language, transforming them into structured
outputs that combine elements of both natural language and intent/slot tags.
Recently, Large Language Models (LLMs) have achieved impressive performance in
synthesizing computer programs based on a natural language prompt, mitigating
the gap between natural language and structured programs. Our paper focuses on
harnessing the capabilities of LLMs for semantic parsing tasks, addressing the
following three key research questions: 1) How can LLMs be effectively utilized
for semantic parsing tasks? 2) What defines an effective prompt? and 3) How can
LLM overcome the length constraint and streamline prompt design by including
all examples as prompts? We introduce k Nearest Neighbor In-Context
Learning(kNN-ICL), which simplifies prompt engineering by allowing it to be
built on top of any design strategy while providing access to all demo
examples. Extensive experiments show that: 1)Simple ICL without kNN search can
achieve a comparable performance with strong supervised models on the TOP
tasks, and 2) kNN-ICL significantly improves the comprehension of complex
requests by seamlessly integrating ICL with a nearest-neighbor approach.
Notably, this enhancement is achieved without the need for additional data or
specialized prompts.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10775" title="Abstract">arXiv:2312.10775</a> [<a href="/pdf/2312.10775" title="Download PDF">pdf</a>, <a href="/format/2312.10775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes Digital Support Effective? How Therapeutic Skills Affect  Clinical Well-Being
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+A">Anna Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+Y">Yash Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haiyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kraut%2C+R">Robert Kraut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Online mental health support communities have grown in recent years for
providing accessible mental and emotional health support through volunteer
counselors. Despite millions of people participating in chat support on these
platforms, the clinical effectiveness of these communities on mental health
symptoms remains unknown. Furthermore, although volunteers receive some
training based on established therapeutic skills studied in face-to-face
environments such as active listening and motivational interviewing, it remains
understudied how the usage of these skills in this online context affects
people's mental health status. In our work, we collaborate with one of the
largest online peer support platforms and use both natural language processing
and machine learning techniques to measure how one-on-one support chats affect
depression and anxiety symptoms. We measure how the techniques and
characteristics of support providers, such as using affirmation, empathy, and
past experience on the platform, affect support-seekers' mental health changes.
We find that online peer support chats improve both depression and anxiety
symptoms with a statistically significant but relatively small effect size.
Additionally, support providers' techniques such as emphasizing the autonomy of
the client lead to better mental health outcomes. However, we also found that
some behaviors (e.g. persuading) are actually harmful to depression and anxiety
outcomes. Our work provides key understanding for mental health care in the
online setting and designing training systems for online support providers.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10787" title="Abstract">arXiv:2312.10787</a> [<a href="/pdf/2312.10787" title="Download PDF">pdf</a>, <a href="/format/2312.10787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Discrete-Time Major-Minor Mean Field Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Dayan%C4%B1kl%C4%B1%2C+G">G&#xf6;k&#xe7;e Dayan&#x131;kl&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Lauri%C3%A8re%2C+M">Mathieu Lauri&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/cs?searchtype=author&query=Pietquin%2C+O">Olivier Pietquin</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Recent techniques based on Mean Field Games (MFGs) allow the scalable
analysis of multi-player games with many similar, rational agents. However,
standard MFGs remain limited to homogeneous players that weakly influence each
other, and cannot model major players that strongly influence other players,
severely limiting the class of problems that can be handled. We propose a novel
discrete time version of major-minor MFGs (M3FGs), along with a learning
algorithm based on fictitious play and partitioning the probability simplex.
Importantly, M3FGs generalize MFGs with common noise and can handle not only
random exogeneous environment states but also major players. A key challenge is
that the mean field is stochastic and not deterministic as in standard MFGs.
Our theoretical investigation verifies both the M3FG model and its algorithmic
solution, showing firstly the well-posedness of the M3FG model starting from a
finite game of interest, and secondly convergence and approximation guarantees
of the fictitious play algorithm. Then, we empirically verify the obtained
theoretical results, ablating some of the theoretical assumptions made, and
show successful equilibrium learning in three example problems. Overall, we
establish a learning framework for a novel and broad class of tractable games.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10788" title="Abstract">arXiv:2312.10788</a> [<a href="/pdf/2312.10788" title="Download PDF">pdf</a>, <a href="/format/2312.10788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Model Predictive Control for a planar free-floating platform: A  comparison of binary input constraint formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stark%2C+F">Franek Stark</a>, 
<a href="/search/cs?searchtype=author&query=Vyas%2C+S">Shubham Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Schildbach%2C+G">Georg Schildbach</a>, 
<a href="/search/cs?searchtype=author&query=Kirchner%2C+F">Frank Kirchner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17th Symposium on Advanced Space Technologies in Robotics and Automation (ASTRA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work develops a first Model Predictive Control for European Space
Agencies 3-dof free-floating platform. The challenges of the platform are the
on/off thrusters, which cannot be actuated continuously and which are subject
to certain timing constraints. This work compares penalty-term, Linear
Complementarity Constraints, and classical Mixed Integer formulations in order
to develop a controller that natively handles binary inputs. Furthermore,
linear constraints are proposed which enforce the timing constraints. Only the
Mixed Integer formulation turns out to work sufficiently. Hence, this work
develops a new Mixed Integer MPC on the decoupled model of the platform.
Feasibility analysis and simulation results show that for a short enough
prediction horizon, this controller can (sub)optimally stabilize and control
the system under consideration of the constraints in real-time.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10789" title="Abstract">arXiv:2312.10789</a> [<a href="/pdf/2312.10789" title="Download PDF">pdf</a>, <a href="/format/2312.10789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated learning with differential privacy and an untrusted aggregator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Trinabh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures, to be published in ICISSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated learning for training models over mobile devices is gaining
popularity. Current systems for this task exhibit significant trade-offs
between model accuracy, privacy guarantee, and device efficiency. For instance,
Oort (OSDI 2021) provides excellent accuracy and efficiency but requires a
trusted central server. On the other hand, Orchard (OSDI 2020) provides good
accuracy and the rigorous guarantee of differential privacy over an untrusted
server, but creates huge overhead for the devices. This paper describes Aero, a
new federated learning system that significantly improves this trade-off. Aero
guarantees good accuracy, differential privacy over an untrusted server, and
keeps the device overhead low. The key idea of Aero is to tune system
architecture and design to a specific set of popular, federated learning
algorithms. This tuning requires novel optimizations and techniques, e.g., a
new protocol to securely aggregate updates from devices. An evaluation of Aero
demonstrates that it provides comparable accuracy to plain federated learning
(without differential privacy), and it improves efficiency (CPU and network)
over Orchard by up to $10^5\times$.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10793" title="Abstract">arXiv:2312.10793</a> [<a href="/pdf/2312.10793" title="Download PDF">pdf</a>, <a href="/format/2312.10793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Instruction Mixture for Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Renxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Instruction Tuning, Large Language Model, Alignment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While instructions fine-tuning of large language models (LLMs) has been
proven to enhance performance across various applications, the influence of the
instruction dataset mixture on LLMs has not been thoroughly explored. In this
study, we classify instructions into three main types: NLP downstream tasks,
coding, and general chatting, and investigate their impact on LLMs. Our
findings reveal that specific types of instructions are more beneficial for
particular uses, while it may cause harms to other aspects, emphasizing the
importance of meticulously designing the instruction mixture to maximize model
performance. This study sheds light on the instruction mixture and paves the
way for future research.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10794" title="Abstract">arXiv:2312.10794</a> [<a href="/pdf/2312.10794" title="Download PDF">pdf</a>, <a href="/format/2312.10794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A mathematical perspective on Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geshkovski%2C+B">Borjan Geshkovski</a>, 
<a href="/search/cs?searchtype=author&query=Letrouit%2C+C">Cyril Letrouit</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskiy%2C+Y">Yury Polyanskiy</a>, 
<a href="/search/cs?searchtype=author&query=Rigollet%2C+P">Philippe Rigollet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Transformers play a central role in the inner workings of large language
models. We develop a mathematical framework for analyzing Transformers based on
their interpretation as interacting particle systems, which reveals that
clusters emerge in long time. Our study explores the underlying theory and
offers new perspectives for mathematicians as well as computer scientists.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10795" title="Abstract">arXiv:2312.10795</a> [<a href="/pdf/2312.10795" title="Download PDF">pdf</a>, <a href="/format/2312.10795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Learn in Interactive Constraint Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsouros%2C+D">Dimos Tsouros</a>, 
<a href="/search/cs?searchtype=author&query=Berden%2C+S">Senne Berden</a>, 
<a href="/search/cs?searchtype=author&query=Guns%2C+T">Tias Guns</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Constraint Programming (CP) has been successfully used to model and solve
complex combinatorial problems. However, modeling is often not trivial and
requires expertise, which is a bottleneck to wider adoption. In Constraint
Acquisition (CA), the goal is to assist the user by automatically learning the
model. In (inter)active CA, this is done by interactively posting queries to
the user, e.g., asking whether a partial solution satisfies their (unspecified)
constraints or not. While interac tive CA methods learn the constraints, the
learning is related to symbolic concept learning, as the goal is to learn an
exact representation. However, a large number of queries is still required to
learn the model, which is a major limitation. In this paper, we aim to
alleviate this limitation by tightening the connection of CA and Machine
Learning (ML), by, for the first time in interactive CA, exploiting statistical
ML methods. We propose to use probabilistic classification models to guide
interactive CA to generate more promising queries. We discuss how to train
classifiers to predict whether a candidate expression from the bias is a
constraint of the problem or not, using both relation-based and scope-based
features. We then show how the predictions can be used in all layers of
interactive CA: the query generation, the scope finding, and the lowest-level
constraint finding. We experimentally evaluate our proposed methods using
different classifiers and show that our methods greatly outperform the state of
the art, decreasing the number of queries needed to converge by up to 72%.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10797" title="Abstract">arXiv:2312.10797</a> [<a href="/pdf/2312.10797" title="Download PDF">pdf</a>, <a href="/format/2312.10797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Multi-Robot Coverage Path Planning via Local Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingtao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study graph-based Multi-Robot Coverage Path Planning (MCPP) that aims to
compute coverage paths for multiple robots to cover all vertices of a given 2D
grid terrain graph $G$. Existing graph-based MCPP algorithms first compute a
tree cover on $G$ -- a forest of multiple trees that cover all vertices -- and
then employ the Spanning Tree Coverage (STC) paradigm to generate coverage
paths on the decomposed graph $D$ of the terrain graph $G$ by circumnavigating
the edges of the computed trees, aiming to optimize the makespan (i.e., the
maximum coverage path cost among all robots). In this paper, we take a
different approach by exploring how to systematically search for good coverage
paths directly on $D$. We introduce a new algorithmic framework, called
LS-MCPP, which leverages a local search to operate directly on $D$. We propose
a novel standalone paradigm, Extended-STC (ESTC), that extends STC to achieve
complete coverage for MCPP on any decomposed graphs, even those resulting from
incomplete terrain graphs. Furthermore, we demonstrate how to integrate ESTC
with three novel types of neighborhood operators into our framework to
effectively guide its search process. Our extensive experiments demonstrate the
effectiveness of LS-MCPP, consistently improving the initial solution returned
by two state-of-the-art baseline algorithms that compute suboptimal tree covers
on $G$, with a notable reduction in makespan by up to 35.7\% and 30.3\%,
respectively. Moreover, LS-MCPP consistently matches or surpasses the results
of optimal tree cover computation, achieving these outcomes with orders of
magnitude faster runtime, thereby showcasing its significant benefits for
large-scale real-world coverage tasks.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10798" title="Abstract">arXiv:2312.10798</a> [<a href="/pdf/2312.10798" title="Download PDF">pdf</a>, <a href="/ps/2312.10798" title="Download PostScript">ps</a>, <a href="/format/2312.10798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Land use/land cover classification of fused Sentinel-1 and Sentinel-2  imageries using ensembles of Random Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pande%2C+S">Shivam Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thesis for Master of Technology. Created: July 2018. Total pages 123
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The study explores the synergistic combination of Synthetic Aperture Radar
(SAR) and Visible-Near Infrared-Short Wave Infrared (VNIR-SWIR) imageries for
land use/land cover (LULC) classification. Image fusion, employing Bayesian
fusion, merges SAR texture bands with VNIR-SWIR imageries. The research aims to
investigate the impact of this fusion on LULC classification. Despite the
popularity of random forests for supervised classification, their limitations,
such as suboptimal performance with fewer features and accuracy stagnation, are
addressed. To overcome these issues, ensembles of random forests (RFE) are
created, introducing random rotations using the Forest-RC algorithm. Three
rotation approaches: principal component analysis (PCA), sparse random rotation
(SRP) matrix, and complete random rotation (CRP) matrix are employed.
Sentinel-1 SAR data and Sentinel-2 VNIR-SWIR data from the IIT-Kanpur region
constitute the training datasets, including SAR, SAR with texture, VNIR-SWIR,
VNIR-SWIR with texture, and fused VNIR-SWIR with texture. The study evaluates
classifier efficacy, explores the impact of SAR and VNIR-SWIR fusion on
classification, and significantly enhances the execution speed of Bayesian
fusion code. The SRP-based RFE outperforms other ensembles for the first two
datasets, yielding average overall kappa values of 61.80% and 68.18%, while the
CRP-based RFE excels for the last three datasets with average overall kappa
values of 95.99%, 96.93%, and 96.30%. The fourth dataset achieves the highest
overall kappa of 96.93%. Furthermore, incorporating texture with SAR bands
results in a maximum overall kappa increment of 10.00%, while adding texture to
VNIR-SWIR bands yields a maximum increment of approximately 3.45%.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10801" title="Abstract">arXiv:2312.10801</a> [<a href="/pdf/2312.10801" title="Download PDF">pdf</a>, <a href="/format/2312.10801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scope Compliance Uncertainty Estimate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhad%2C+A">Al-Harith Farhad</a>, 
<a href="/search/cs?searchtype=author&query=Sorokos%2C+I">Ioannis Sorokos</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+M+N">Mohammed Naveed Akram</a>, 
<a href="/search/cs?searchtype=author&query=Aslansefat%2C+K">Koorosh Aslansefat</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+D">Daniel Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The zeitgeist of the digital era has been dominated by an expanding
integration of Artificial Intelligence~(AI) in a plethora of applications
across various domains. With this expansion, however, questions of the safety
and reliability of these methods come have become more relevant than ever.
Consequently, a run-time ML model safety system has been developed to ensure
the model's operation within the intended context, especially in applications
whose environments are greatly variable such as Autonomous Vehicles~(AVs).
SafeML is a model-agnostic approach for performing such monitoring, using
distance measures based on statistical testing of the training and operational
datasets; comparing them to a predetermined threshold, returning a binary value
whether the model should be trusted in the context of the observed data or be
deemed unreliable. Although a systematic framework exists for this approach,
its performance is hindered by: (1) a dependency on a number of design
parameters that directly affect the selection of a safety threshold and
therefore likely affect its robustness, (2) an inherent assumption of certain
distributions for the training and operational sets, as well as (3) a high
computational complexity for relatively large sets. This work addresses these
limitations by changing the binary decision to a continuous metric.
Furthermore, all data distribution assumptions are made obsolete by
implementing non-parametric approaches, and the computational speed increased
by introducing a new distance measure based on the Empirical Characteristics
Functions~(ECF).
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10802" title="Abstract">arXiv:2312.10802</a> [<a href="/pdf/2312.10802" title="Download PDF">pdf</a>, <a href="/format/2312.10802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GO-DICE: Goal-Conditioned Option-Aware Offline Imitation Learning via  Stationary Distribution Correction Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Abhinav Jain</a>, 
<a href="/search/cs?searchtype=author&query=Unhelkar%2C+V">Vaibhav Unhelkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of an identically-titled paper accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline imitation learning (IL) refers to learning expert behavior solely
from demonstrations, without any additional interaction with the environment.
Despite significant advances in offline IL, existing techniques find it
challenging to learn policies for long-horizon tasks and require significant
re-training when task specifications change. Towards addressing these
limitations, we present GO-DICE an offline IL technique for goal-conditioned
long-horizon sequential tasks. GO-DICE discerns a hierarchy of sub-tasks from
demonstrations and uses these to learn separate policies for sub-task
transitions and action execution, respectively; this hierarchical policy
learning facilitates long-horizon reasoning. Inspired by the expansive
DICE-family of techniques, policy learning at both the levels transpires within
the space of stationary distributions. Further, both policies are learnt with
goal conditioning to minimize need for retraining when task goals change.
Experimental results substantiate that GO-DICE outperforms recent baselines, as
evidenced by a marked improvement in the completion rate of increasingly
challenging pick-and-place Mujoco robotic tasks. GO-DICE is also capable of
leveraging imperfect demonstration and partial task segmentation when
available, both of which boost task performance relative to learning from
expert demonstrations alone.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10806" title="Abstract">arXiv:2312.10806</a> [<a href="/pdf/2312.10806" title="Download PDF">pdf</a>, <a href="/format/2312.10806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Lingual Learning in Multilingual Scene Text Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jeonghun Baek</a>, 
<a href="/search/cs?searchtype=author&query=Matsui%2C+Y">Yusuke Matsui</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP2024, 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we investigate cross-lingual learning (CLL) for multilingual
scene text recognition (STR). CLL transfers knowledge from one language to
another. We aim to find the condition that exploits knowledge from
high-resource languages for improving performance in low-resource languages. To
do so, we first examine if two general insights about CLL discussed in previous
works are applied to multilingual STR: (1) Joint learning with high- and
low-resource languages may reduce performance on low-resource languages, and
(2) CLL works best between typologically similar languages. Through extensive
experiments, we show that two general insights may not be applied to
multilingual STR. After that, we show that the crucial condition for CLL is the
dataset size of high-resource languages regardless of the kind of high-resource
languages. Our code, data, and models are available at
https://github.com/ku21fan/CLL-STR.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10807" title="Abstract">arXiv:2312.10807</a> [<a href="/pdf/2312.10807" title="Download PDF">pdf</a>, <a href="/format/2312.10807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-conditioned Learning for Robotic Manipulation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongkuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiangtong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siming Sun</a>, 
<a href="/search/cs?searchtype=author&query=BIng%2C+Z">Zhenshan BIng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Language-conditioned robotic manipulation represents a cutting-edge area of
research, enabling seamless communication and cooperation between humans and
robotic agents. This field focuses on teaching robotic systems to comprehend
and execute instructions conveyed in natural language. To achieve this, the
development of robust language understanding models capable of extracting
actionable insights from textual input is essential. In this comprehensive
survey, we systematically explore recent advancements in language-conditioned
approaches within the context of robotic manipulation. We analyze these
approaches based on their learning paradigms, which encompass reinforcement
learning, imitation learning, and the integration of foundational models, such
as large language models and vision-language models. Furthermore, we conduct an
in-depth comparative analysis, considering aspects like semantic information
extraction, environment &amp; evaluation, auxiliary tasks, and task representation.
Finally, we outline potential future research directions in the realm of
language-conditioned learning for robotic manipulation, with the topic of
generalization capabilities and safety issues.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10808" title="Abstract">arXiv:2312.10808</a> [<a href="/pdf/2312.10808" title="Download PDF">pdf</a>, <a href="/format/2312.10808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Euclidean Spatial Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingcheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Angirekula%2C+A">Abhinav Angirekula</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Allen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatial networks are networks whose graph topology is constrained by their
embedded spatial space. Understanding the coupled spatial-graph properties is
crucial for extracting powerful representations from spatial networks.
Therefore, merely combining individual spatial and network representations
cannot reveal the underlying interaction mechanism of spatial networks.
Besides, existing spatial network representation learning methods can only
consider networks embedded in Euclidean space, and can not well exploit the
rich geometric information carried by irregular and non-uniform non-Euclidean
space. In order to address this issue, in this paper we propose a novel generic
framework to learn the representation of spatial networks that are embedded in
non-Euclidean manifold space. Specifically, a novel message-passing-based
neural network is proposed to combine graph topology and spatial geometry,
where spatial geometry is extracted as messages on the edges. We theoretically
guarantee that the learned representations are provably invariant to important
symmetries such as rotation or translation, and simultaneously maintain
sufficient ability in distinguishing different geometric structures. The
strength of our proposed method is demonstrated through extensive experiments
on both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10809" title="Abstract">arXiv:2312.10809</a> [<a href="/pdf/2312.10809" title="Download PDF">pdf</a>, <a href="/format/2312.10809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Dispatch: A Deep Reinforcement Learning-Based Vehicle Dispatch  Algorithm for Advanced Air Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varnousfaderani%2C+E+S">Elaheh Sabziyan Varnousfaderani</a>, 
<a href="/search/cs?searchtype=author&query=Shihab%2C+S+A+M">Syed A. M. Shihab</a>, 
<a href="/search/cs?searchtype=author&query=Dulia%2C+E+F">Esrat F. Dulia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Near future air taxi operations with electric vertical take-off and landing
(eVTOL) aircraft will be constrained by the need for frequent recharging of
eVTOLs, limited takeoff and landing pads in vertiports, and subject to
time-varying demand and electricity prices, making the eVTOL dispatch problem
unique and particularly challenging to solve. Previously, we have developed
optimization models to address this problem. Such optimization models however
suffer from prohibitively high computational run times when the scale of the
problem increases, making them less practical for real world implementation. To
overcome this issue, we have developed two deep reinforcement learning-based
eVTOL dispatch algorithms, namely single-agent and multi-agent deep Q-learning
eVTOL dispatch algorithms, where the objective is to maximize operating profit.
An eVTOL-based passenger transportation simulation environment was built to
assess the performance of our algorithms across $36$ numerical cases with
varying number of eVTOLs, vertiports, and demand. The results indicate that the
multi-agent eVTOL dispatch algorithm can closely approximate the optimal
dispatch policy with significantly less computational expenses compared to the
benchmark optimization model. The multi-agent algorithm was found to outperform
the single-agent counterpart with respect to both profits generated and
training time.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10810" title="Abstract">arXiv:2312.10810</a> [<a href="/pdf/2312.10810" title="Download PDF">pdf</a>, <a href="/ps/2312.10810" title="Download PostScript">ps</a>, <a href="/format/2312.10810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Automata and Logics Meet Computational Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostol%C3%A1nyi%2C+P">Peter Kostol&#xe1;nyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Complexity classes such as $\#\mathbf{P}$, $\oplus\mathbf{P}$,
$\mathbf{GapP}$, $\mathbf{OptP}$, $\mathbf{NPMV}$, or the class of fuzzy
languages realised by polynomial-time fuzzy nondeterministic Turing machines,
can all be described in terms of a class $\mathbf{NP}[S]$ for a suitable
semiring $S$, defined via weighted Turing machines over $S$ similarly as
$\mathbf{NP}$ is defined via the classical nondeterministic Turing machines.
Other complexity classes of decision problems can be lifted to the quantitative
world using the same recipe as well, and the resulting classes relate to the
original ones in the same way as weighted automata or logics relate to their
unweighted counterparts. The article surveys these too-little-known connexions
between weighted automata theory and computational complexity theory implicit
in the existing literature, suggests a systematic approach to the study of
weighted complexity classes, and presents several new observations
strengthening the relation between both fields. In particular, it is proved
that a natural extension of the Boolean satisfiability problem to weighted
propositional logic is complete for the class $\mathbf{NP}[S]$ when $S$ is a
finitely generated semiring. Moreover, a class of semiring-valued functions
$\mathbf{FP}[S]$ is introduced for each semiring $S$ as a counterpart to the
class $\mathbf{P}$, and the relations between $\mathbf{FP}[S]$ and
$\mathbf{NP}[S]$ are considered.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10812" title="Abstract">arXiv:2312.10812</a> [<a href="/pdf/2312.10812" title="Download PDF">pdf</a>, <a href="/format/2312.10812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Act without Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D">Dominik Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-training large models on vast amounts of web data has proven to be an
effective approach for obtaining powerful, general models in several domains,
including language and vision. However, this paradigm has not yet taken hold in
deep reinforcement learning (RL). This gap is due to the fact that the most
abundant form of embodied behavioral data on the web consists of videos, which
do not include the action labels required by existing methods for training
policies from offline data. We introduce Latent Action Policies from
Observation (LAPO), a method to infer latent actions and, consequently,
latent-action policies purely from action-free demonstrations. Our experiments
on challenging procedurally-generated environments show that LAPO can act as an
effective pre-training method to obtain RL policies that can then be rapidly
fine-tuned to expert-level performance. Our approach serves as a key stepping
stone to enabling the pre-training of powerful, generalist RL models on the
vast amounts of action-free demonstrations readily available on the web.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10813" title="Abstract">arXiv:2312.10813</a> [<a href="/pdf/2312.10813" title="Download PDF">pdf</a>, <a href="/format/2312.10813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model  within 0.5K Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+T">Tianxiang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Mengyao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the development of large pre-trained vision-language models, how to
effectively transfer the knowledge of such foundational models to downstream
tasks becomes a hot topic, especially in a data-deficient scenario. Recently,
prompt tuning has become a popular solution. When adapting the vision-language
models, researchers freeze the parameters in the backbone and only design and
tune the prompts. On the one hand, the delicate design of prompt tuning
exhibits strong performance. On the other hand, complicated structures and
update rules largely increase the computation and storage cost. Motivated by
the observation that the evolution pattern of the generalization capability in
visual-language models aligns harmoniously with the trend of rank variations in
the prompt matrix during adaptation, we design a new type of prompt,
Re-parameterized Low-rank Prompt (RLP), for both efficient and effective
adaptation. Our method could largely reduce the number of tunable parameters
and storage space, which is quite beneficial in resource-limited scenarios.
Extensive experiments further demonstrate the superiority of RLP. In
particular, RLP shows comparable or even stronger performance than the latest
state-of-the-art methods with an extremely small number of parameters. On a
series of tasks over 11 datasets, RLP significantly increases the average
downstream accuracy of classic prompt tuning by up to 5.25% using merely 0.5K
parameters.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10815" title="Abstract">arXiv:2312.10815</a> [<a href="/pdf/2312.10815" title="Download PDF">pdf</a>, <a href="/format/2312.10815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DePRL: Achieving Linear Convergence Speedup in Personalized  Decentralized Learning with Shared Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guojun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Gang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Decentralized learning has emerged as an alternative method to the popular
parameter-server framework which suffers from high communication burden,
single-point failure and scalability issues due to the need of a central
server. However, most existing works focus on a single shared model for all
workers regardless of the data heterogeneity problem, rendering the resulting
model performing poorly on individual workers. In this work, we propose a novel
personalized decentralized learning algorithm named DePRL via shared
representations. Our algorithm relies on ideas from representation learning
theory to learn a low-dimensional global representation collaboratively among
all workers in a fully decentralized manner, and a user-specific
low-dimensional local head leading to a personalized solution for each worker.
We show that DePRL achieves, for the first time, a provable linear speedup for
convergence with general non-linear representations (i.e., the convergence rate
is improved linearly with respect to the number of workers). Experimental
results support our theoretical findings showing the superiority of our method
in data heterogeneous environments.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10817" title="Abstract">arXiv:2312.10817</a> [<a href="/pdf/2312.10817" title="Download PDF">pdf</a>, <a href="/format/2312.10817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ocean Data Quality Assessment through Outlier Detection-enhanced Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yiyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+R">Ruyue Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiming Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data (IEEE BigData 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Ocean and climate research benefits from global ocean observation initiatives
such as Argo, GLOSS, and EMSO. The Argo network, dedicated to ocean profiling,
generates a vast volume of observatory data. However, data quality issues from
sensor malfunctions and transmission errors necessitate stringent quality
assessment. Existing methods, including machine learning, fall short due to
limited labeled data and imbalanced datasets. To address these challenges, we
propose an ODEAL framework for ocean data quality assessment, employing AL to
reduce human experts' workload in the quality assessment workflow and
leveraging outlier detection algorithms for effective model initialization. We
also conduct extensive experiments on five large-scale realistic Argo datasets
to gain insights into our proposed method, including the effectiveness of AL
query strategies and the initial set construction approach. The results suggest
that our framework enhances quality assessment efficiency by up to 465.5% with
the uncertainty-based query strategy compared to random sampling and minimizes
overall annotation costs by up to 76.9% using the initial set built with
outlier detectors.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10818" title="Abstract">arXiv:2312.10818</a> [<a href="/pdf/2312.10818" title="Download PDF">pdf</a>, <a href="/format/2312.10818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Emotion Recognition using CNN in PyTorch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+D">Deyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+S">Sudip Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Carrillo%2C+D">Dominic Carrillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this project, we have implemented a model to recognize real-time facial
emotions given the camera images. Current approaches would read all data and
input it into their model, which has high space complexity. Our model is based
on the Convolutional Neural Network utilizing the PyTorch library. We believe
our implementation will significantly improve the space complexity and provide
a useful contribution to facial emotion recognition. Our motivation is to
understanding clearly about deep learning, particularly in CNNs, and analysis
real-life scenarios. Therefore, we tunned the hyper parameter of model such as
learning rate, batch size, and number of epochs to meet our needs. In addition,
we also used techniques to optimize the networks, such as activation function,
dropout and max pooling. Finally, we analyzed the result from two optimizer to
observe the relationship between number of epochs and accuracy.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10819" title="Abstract">arXiv:2312.10819</a> [<a href="/pdf/2312.10819" title="Download PDF">pdf</a>, <a href="/format/2312.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satellite Data Shows Resilience of Tigrayan Farmers in Crop Cultivation  During Civil War
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kerner%2C+H">Hannah Kerner</a>, 
<a href="/search/cs?searchtype=author&query=Nakalembe%2C+C">Catherine Nakalembe</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+B">Benjamin Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zvonkov%2C+I">Ivan Zvonkov</a>, 
<a href="/search/cs?searchtype=author&query=Skakun%2C+S">Sergii Skakun</a>, 
<a href="/search/cs?searchtype=author&query=Becker-Reshef%2C+I">Inbal Becker-Reshef</a>, 
<a href="/search/cs?searchtype=author&query=McNally%2C+A">Amy McNally</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The Tigray War was an armed conflict that took place primarily in the Tigray
region of northern Ethiopia from November 3, 2020 to November 2, 2022. Given
the importance of agriculture in Tigray to livelihoods and food security,
determining the impact of the war on cultivated area is critical, but
quantifying this impact was difficult due to restricted movement within and
into the region due to conflict-driven insecurity and blockages. Using
satellite imagery and statistical area estimation techniques, we assessed
changes in crop cultivation area in Tigray before and during the war. Our
findings show that cultivated area was largely stable between 2020-2021 despite
the widespread impacts of the war. We estimated 1,132,000 +/- 133,000 hectares
of cultivation in pre-war 2020 compared to 1,217,000 +/- 132,000 hectares in
mid-war 2021. Comparing changes inside and outside of a 5 km buffer around
conflict events, we found a slightly higher upper confidence limit of cropland
loss within the buffer (0-3%) compared to outside the buffer (0-1%). Our
results support other reports that despite widespread war-related disruptions,
Tigrayan farmers were largely able to sustain cultivation. Our study
demonstrates the capability of remote sensing combined with machine learning
and statistical techniques to provide timely, transparent area estimates for
monitoring food security in regions inaccessible due to conflict.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10822" title="Abstract">arXiv:2312.10822</a> [<a href="/pdf/2312.10822" title="Download PDF">pdf</a>, <a href="/ps/2312.10822" title="Download PostScript">ps</a>, <a href="/format/2312.10822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of Rigorous Requirements Specifications and Document  Automation with the ITLingo RSL Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+A">Andre Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+A+R">Alberto Rodrigues da Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 2 tables, 1 spec
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Despite being an essential step in software development, writing requirements
specifications is frequently performed in natural language, leading to issues
like inconsistency, incompleteness, or ambiguity. The ITLingo initiative has
introduced a requirements specification language named RSL to enhance the rigor
and consistency of technical documentation. On the other hand, natural language
processing (NLP) is a field that has been supporting the automatic analysis of
requirements by helping to detect issues that may be difficult to see during a
manual review. Once the requirements specifications are validated, it is
important to automate the generation of documents for these specifications to
reduce manual work, reduce errors, and to produce documentation in multiple
formats that are more easily reusable or recognized by the different
stakeholders. This paper reviews existing research and tools in the fields of
requirements validation and document automation. We propose to extend RSL with
validation of specifications based on customized checks, and on linguistic
rules dynamically defined in the RSL itself. In addition, we also propose the
automatic generation of documents from these specifications to JSON, TXT, or
other file formats using template files. We use a fictitious business
information system to support the explanation and to demonstrate how these
validation checks can assist in writing better requirements specifications and
then generate documents in multiple formats based on them. Finally, we evaluate
the usability of the proposed validation and document automation approach
through a user session.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10823" title="Abstract">arXiv:2312.10823</a> [<a href="/pdf/2312.10823" title="Download PDF">pdf</a>, <a href="/ps/2312.10823" title="Download PostScript">ps</a>, <a href="/format/2312.10823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power and Hydrogen Hybrid Transmission for Renewable Energy Systems: An  Integrated Expansion Planning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jin Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The increasing interest in hydrogen as a clean energy source has led to
extensive research into its transmission, storage, and integration with bulk
power systems. With the evolution of hydrogen technologies towards greater
efficiency, and cost-effectiveness, it becomes essential to examine the
operation and expansion of grids that include both electric power and hydrogen
facilities. This paper introduces an expansion strategy for electric power and
hydrogen transmission systems, tailored for future renewable energy-enriched
grids. Our proposed transmission expansion planning with hydrogen facilities
(TEP-H) model integrates daily operations of both electric power and hydrogen
transmissions. The fuel cells and electrolyzers are used for
electrical-hydrogen energy conversion, and related constraints are considered
in TEP-H. We applied TEP-H to the Texas 123-bus backbone transmission grid
(TX-123BT), for various renewable penetration levels and hydrogen technology
development assumptions. It gave us insights on the scenarios that hydrogen
transmission become feasible and economically beneficial. We also compared the
performance of TX-123BT system with the hybrid transmission investment and the
pure electrical transmission investment obtained by a traditional transmission
expansion planning (TEP-T) model. The numerical results indicate that future
renewable grids can have lower total cost with TEP-H if future
electrical-hydrogen energy conversion efficiency is high.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10825" title="Abstract">arXiv:2312.10825</a> [<a href="/pdf/2312.10825" title="Download PDF">pdf</a>, <a href="/format/2312.10825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Space Editing in Transformer-Based Flow Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+W">David W Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Meng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G.M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 with Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper strives for image editing via generative models. Flow Matching is
an emerging generative modeling technique that offers the advantage of simple
and efficient training. Simultaneously, a new transformer-based U-ViT has
recently been proposed to replace the commonly used UNet for better scalability
and performance in generative modeling. Hence, Flow Matching with a transformer
backbone offers the potential for scalable and high-quality generative
modeling, but their latent structure and editing ability are as of yet unknown.
Hence, we adopt this setting and explore how to edit images through latent
space manipulation. We introduce an editing space, which we call $u$-space,
that can be manipulated in a controllable, accumulative, and composable manner.
Additionally, we propose a tailored sampling solution to enable sampling with
the more efficient adaptive step-size ODE solvers. Lastly, we put forth a
straightforward yet powerful method for achieving fine-grained and nuanced
editing using text prompts. Our framework is simple and efficient, all while
being highly effective at editing images while preserving the essence of the
original content. Our code will be publicly available at https://taohu.me/lfm/
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10826" title="Abstract">arXiv:2312.10826</a> [<a href="/pdf/2312.10826" title="Download PDF">pdf</a>, <a href="/format/2312.10826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Networks: Understanding Effective Teacher Practices in  AI-Supported Classrooms using Transmodal Ordered Network Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borchers%2C+C">Conrad Borchers</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karumbaiah%2C+S">Shamya Karumbaiah</a>, 
<a href="/search/cs?searchtype=author&query=Ashiq%2C+M">Muhammad Ashiq</a>, 
<a href="/search/cs?searchtype=author&query=Shaffer%2C+D+W">David Williamson Shaffer</a>, 
<a href="/search/cs?searchtype=author&query=Aleven%2C+V">Vincent Aleven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted to Learning Analytics and Knowledge (LAK 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning analytics research increasingly studies classroom learning with
AI-based systems through rich contextual data from outside these systems,
especially student-teacher interactions. One key challenge in leveraging such
data is generating meaningful insights into effective teacher practices.
Quantitative ethnography bears the potential to close this gap by combining
multimodal data streams into networks of co-occurring behavior that drive
insight into favorable learning conditions. The present study uses transmodal
ordered network analysis to understand effective teacher practices in
relationship to traditional metrics of in-system learning in a mathematics
classroom working with AI tutors. Incorporating teacher practices captured by
position tracking and human observation codes into modeling significantly
improved the inference of how efficiently students improved in the AI tutor
beyond a model with tutor log data features only. Comparing teacher practices
by student learning rates, we find that students with low learning rates
exhibited more hint use after monitoring. However, after an extended visit,
students with low learning rates showed learning behavior similar to their high
learning rate peers, achieving repeated correct attempts in the tutor.
Observation notes suggest conceptual and procedural support differences can
help explain visit effectiveness. Taken together, offering early conceptual
support to students with low learning rates could make classroom practice with
AI tutors more effective. This study advances the scientific understanding of
effective teacher practice in classrooms learning with AI tutors and
methodologies to make such practices visible.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10833" title="Abstract">arXiv:2312.10833</a> [<a href="/pdf/2312.10833" title="Download PDF">pdf</a>, <a href="/format/2312.10833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An answer to the questions regarding AI gender bias
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study delves into the pervasive issue of gender issues in artificial
intelligence (AI), specifically within automatic scoring systems for
student-written responses. The primary objective is to investigate the presence
of gender biases, disparities, and fairness in generally targeted training
samples with mixed-gender datasets in AI scoring outcomes. Utilizing a
fine-tuned version of BERT and GPT-3.5, this research analyzes more than 1000
human-graded student responses from male and female participants across six
assessment items. The study employs three distinct techniques for bias
analysis: Scoring accuracy difference to evaluate bias, mean score gaps by
gender (MSG) to evaluate disparity, and Equalized Odds (EO) to evaluate
fairness. The results indicate that scoring accuracy for mixed-trained models
shows an insignificant difference from either male- or female-trained models,
suggesting no significant scoring bias. Consistently with both BERT and
GPT-3.5, we found that mixed-trained models generated fewer MSG and
non-disparate predictions compared to humans. In contrast, compared to humans,
gender-specifically trained models yielded larger MSG, indicating that
unbalanced training data may create algorithmic models to enlarge gender
disparities. The EO analysis suggests that mixed-trained models generated more
fairness outcomes compared with gender-specifically trained models.
Collectively, the findings suggest that gender-unbalanced data do not
necessarily generate scoring bias but can enlarge gender disparities and reduce
scoring fairness.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10835" title="Abstract">arXiv:2312.10835</a> [<a href="/pdf/2312.10835" title="Download PDF">pdf</a>, <a href="/format/2312.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Student is Better Than Expected: Adaptive Teacher-Student  Collaboration for Text-Conditional Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Starodubcev%2C+N">Nikita Starodubcev</a>, 
<a href="/search/cs?searchtype=author&query=Fedorov%2C+A">Artem Fedorov</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Baranchuk%2C+D">Dmitry Baranchuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge distillation methods have recently shown to be a promising
direction to speedup the synthesis of large-scale diffusion models by requiring
only a few inference steps. While several powerful distillation methods were
recently proposed, the overall quality of student samples is typically lower
compared to the teacher ones, which hinders their practical usage. In this
work, we investigate the relative quality of samples produced by the teacher
text-to-image diffusion model and its distilled student version. As our main
empirical finding, we discover that a noticeable portion of student samples
exhibit superior fidelity compared to the teacher ones, despite the
``approximate'' nature of the student. Based on this finding, we propose an
adaptive collaboration between student and teacher diffusion models for
effective text-to-image synthesis. Specifically, the distilled model produces
the initial sample, and then an oracle decides whether it needs further
improvements with a slow teacher model. Extensive experiments demonstrate that
the designed pipeline surpasses state-of-the-art text-to-image alternatives for
various inference budgets in terms of human preference. Furthermore, the
proposed approach can be naturally used in popular applications such as
text-guided image editing and controllable generation.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10840" title="Abstract">arXiv:2312.10840</a> [<a href="/pdf/2312.10840" title="Download PDF">pdf</a>, <a href="/ps/2312.10840" title="Download PostScript">ps</a>, <a href="/format/2312.10840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Implementation of Arduino Microcontroller Boards in Science: A  Bibliometric Analysis from 2008 to 2022
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabowo%2C+N+K">Norbertus Krisnu Prabowo</a>, 
<a href="/search/cs?searchtype=author&query=Irwanto%2C+I">Irwanto Irwanto</a> (State University of Jakarta)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures, and 9 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Engineering Education Transformations , Journal of
  Engineering Education Transformations, Volume 37 , No. 2 , October 2023 ,
  ISSN 2349-2473, eISSN 2394-1707
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics Education (physics.ed-ph)

</div>
<p class="mathjax">The name "Arduino" made its international debut in 2005, marking the age of
Arduino as one of the most user-friendly and cost-effective microcontroller
boards (MCBs) for novices. The science implementation of Arduino boards in
automation, networking and data acquisition has been increasing steadily. This
study provides a thorough Bibliometric analysis from 1122 papers focused on the
Scopus database of published microcontroller research, from the first year the
Arduino keyword appeared in 2008 until 2022. Various science articles indexed
by Scopus and referring to the use of Arduino MCBs are selected. The
Bibliometric analysis explores comprehensive and general key attributes that
form a trend from the Scopus articles based on authors, titles, publication
years, keywords, citations, affiliations, abstracts, funding information, and
languages. The generated data is visualized and analyzed to find patterns that
appear within the time span. This study found a significant increase in the
number of articles on Arduino boards in Biology, Physics, Chemistry, Science,
and STEM category of the paper. Despite using only the Scopus database, this
study opens up to view the direction of the growing application of Arduino
boards in Science. The use of Bibliometric analysis maps the scientific
implementation of Arduino boards as an extensive guide for future
collaborations in education and industry.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10841" title="Abstract">arXiv:2312.10841</a> [<a href="/pdf/2312.10841" title="Download PDF">pdf</a>, <a href="/format/2312.10841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Boosting Adaptive Learning under Concept Drift for Multistream  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">En Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangquan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multistream classification poses significant challenges due to the necessity
for rapid adaptation in dynamic streaming processes with concept drift. Despite
the growing research outcomes in this area, there has been a notable oversight
regarding the temporal dynamic relationships between these streams, leading to
the issue of negative transfer arising from irrelevant data. In this paper, we
propose a novel Online Boosting Adaptive Learning (OBAL) method that
effectively addresses this limitation by adaptively learning the dynamic
correlation among different streams. Specifically, OBAL operates in a
dual-phase mechanism, in the first of which we design an Adaptive COvariate
Shift Adaptation (AdaCOSA) algorithm to construct an initialized ensemble model
using archived data from various source streams, thus mitigating the covariate
shift while learning the dynamic correlations via an adaptive re-weighting
strategy. During the online process, we employ a Gaussian Mixture Model-based
weighting mechanism, which is seamlessly integrated with the acquired
correlations via AdaCOSA to effectively handle asynchronous drift. This
approach significantly improves the predictive performance and stability of the
target stream. We conduct comprehensive experiments on several synthetic and
real-world data streams, encompassing various drifting scenarios and types. The
results clearly demonstrate that OBAL achieves remarkable advancements in
addressing multistream classification problems by effectively leveraging
positive knowledge derived from multiple sources.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10842" title="Abstract">arXiv:2312.10842</a> [<a href="/pdf/2312.10842" title="Download PDF">pdf</a>, <a href="/ps/2312.10842" title="Download PostScript">ps</a>, <a href="/format/2312.10842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Inductive Invariant Based Verification of Neural Network  Controlled Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tripakis%2C+S">Stavros Tripakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">The integration of neural networks into safety-critical systems has shown
great potential in recent years. However, the challenge of effectively
verifying the safety of Neural Network Controlled Systems (NNCS) persists. This
paper introduces a novel approach to NNCS safety verification, leveraging the
inductive invariant method. Verifying the inductiveness of a candidate
inductive invariant in the context of NNCS is hard because of the scale and
nonlinearity of neural networks. Our compositional method makes this
verification process manageable by decomposing the inductiveness proof
obligation into smaller, more tractable subproblems. Alongside the high-level
method, we present an algorithm capable of automatically verifying the
inductiveness of given candidates by automatically inferring the necessary
decomposition predicates. The algorithm significantly outperforms the baseline
method and shows remarkable reductions in execution time in our case studies,
shortening the verification time from hours (or timeout) to seconds.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10843" title="Abstract">arXiv:2312.10843</a> [<a href="/pdf/2312.10843" title="Download PDF">pdf</a>, <a href="/format/2312.10843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Face Swapping with Style Blending
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+H">Hongbo Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face swapping has gained significant traction, driven by the plethora of
human face synthesis facilitated by deep learning methods. However, previous
face swapping methods that used generative adversarial networks (GANs) as
backbones have faced challenges such as inconsistency in blending, distortions,
artifacts, and issues with training stability. To address these limitations, we
propose an innovative end-to-end framework for high-fidelity face swapping.
First, we introduce a StyleGAN-based facial attributes encoder that extracts
essential features from faces and inverts them into a latent style code,
encapsulating indispensable facial attributes for successful face swapping.
Second, we introduce an attention-based style blending module to effectively
transfer Face IDs from source to target. To ensure accurate and quality
transferring, a series of constraint measures including contrastive face ID
learning, facial landmark alignment, and dual swap consistency is implemented.
Finally, the blended style code is translated back to the image space via the
style decoder, which is of high training stability and generative capability.
Extensive experiments on the CelebA-HQ dataset highlight the superior visual
quality of generated images from our face-swapping methodology when compared to
other state-of-the-art methods, and the effectiveness of each proposed module.
Source code and weights will be publicly available.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10854" title="Abstract">arXiv:2312.10854</a> [<a href="/pdf/2312.10854" title="Download PDF">pdf</a>, <a href="/format/2312.10854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Right Losses for the Right Gains: Improving the Semantic Consistency  of Deep Text-to-Image Generation with Distribution-Sensitive Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Mahmoud Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Moussa%2C+O">Omer Moussa</a>, 
<a href="/search/cs?searchtype=author&query=Shaheen%2C+I">Ismail Shaheen</a>, 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+M">Mohamed Abdelfattah</a>, 
<a href="/search/cs?searchtype=author&query=Abdalla%2C+A">Amr Abdalla</a>, 
<a href="/search/cs?searchtype=author&query=Eid%2C+M">Marwan Eid</a>, 
<a href="/search/cs?searchtype=author&query=Eraqi%2C+H">Hesham Eraqi</a>, 
<a href="/search/cs?searchtype=author&query=Moustafa%2C+M">Mohamed Moustafa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">One of the major challenges in training deep neural networks for
text-to-image generation is the significant linguistic discrepancy between
ground-truth captions of each image in most popular datasets. The large
difference in the choice of words in such captions results in synthesizing
images that are semantically dissimilar to each other and to their ground-truth
counterparts. Moreover, existing models either fail to generate the
fine-grained details of the image or require a huge number of parameters that
renders them inefficient for text-to-image synthesis. To fill this gap in the
literature, we propose using the contrastive learning approach with a novel
combination of two loss functions: fake-to-fake loss to increase the semantic
consistency between generated images of the same caption, and fake-to-real loss
to reduce the gap between the distributions of real images and fake ones. We
test this approach on two baseline models: SSAGAN and AttnGAN (with style
blocks to enhance the fine-grained details of the images.) Results show that
our approach improves the qualitative results on AttnGAN with style blocks on
the CUB dataset. Additionally, on the challenging COCO dataset, our approach
achieves competitive results against the state-of-the-art Lafite model,
outperforms the FID score of SSAGAN model by 44.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10857" title="Abstract">arXiv:2312.10857</a> [<a href="/pdf/2312.10857" title="Download PDF">pdf</a>, <a href="/ps/2312.10857" title="Download PostScript">ps</a>, <a href="/format/2312.10857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Macro-Based Rewritings of Formal Languages: Theory and  Applications in Ontology Engineering (and beyond)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+C">Christian Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+A">Anne-Marie George</a>, 
<a href="/search/cs?searchtype=author&query=Parsia%2C+B">Bijan Parsia</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+U">Uli Sattler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended paper (including supplementary material) accepted at The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">In this paper, we introduce the problem of rewriting finite formal languages
using syntactic macros such that the rewriting is minimal in size. We present
polynomial-time algorithms to solve variants of this problem and show their
correctness. To demonstrate the practical relevance of the proposed problems
and the feasibility and effectiveness of our algorithms in practice, we apply
these to biomedical ontologies authored in OWL. We find that such rewritings
can significantly reduce the size of ontologies by capturing repeated
expressions with macros. In addition to offering valuable assistance in
enhancing ontology quality and comprehension, the presented approach introduces
a systematic way of analysing and evaluating features of rewriting systems
(including syntactic macros, templates, or other forms of rewriting rules) in
terms of their influence on computational problems.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10858" title="Abstract">arXiv:2312.10858</a> [<a href="/pdf/2312.10858" title="Download PDF">pdf</a>, <a href="/format/2312.10858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable Importance in High-Dimensional Settings Requires Grouping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chamma%2C+A">Ahmad Chamma</a> (1 and 2 and 3), 
<a href="/search/cs?searchtype=author&query=Thirion%2C+B">Bertrand Thirion</a> (1 and 2 and 3), 
<a href="/search/cs?searchtype=author&query=Engemann%2C+D+A">Denis A. Engemann</a> (4) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Explaining the decision process of machine learning algorithms is nowadays
crucial for both model's performance enhancement and human comprehension. This
can be achieved by assessing the variable importance of single variables, even
for high-capacity non-linear methods, e.g. Deep Neural Networks (DNNs). While
only removal-based approaches, such as Permutation Importance (PI), can bring
statistical validity, they return misleading results when variables are
correlated. Conditional Permutation Importance (CPI) bypasses PI's limitations
in such cases. However, in high-dimensional settings, where high correlations
between the variables cancel their conditional importance, the use of CPI as
well as other methods leads to unreliable results, besides prohibitive
computation costs. Grouping variables statistically via clustering or some
prior knowledge gains some power back and leads to better interpretations. In
this work, we introduce BCPI (Block-Based Conditional Permutation Importance),
a new generic framework for variable importance computation with statistical
guarantees handling both single and group cases. Furthermore, as handling
groups with high cardinality (such as a set of observations of a given
modality) are both time-consuming and resource-intensive, we also introduce a
new stacking approach extending the DNN architecture with sub-linear layers
adapted to the group structure. We show that the ensuing approach extended with
stacking controls the type-I error even with highly-correlated groups and shows
top accuracy across benchmarks. Furthermore, we perform a real-world data
analysis in a large-scale medical dataset where we aim to show the consistency
between our results and the literature for a biomarker prediction.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10860" title="Abstract">arXiv:2312.10860</a> [<a href="/pdf/2312.10860" title="Download PDF">pdf</a>, <a href="/format/2312.10860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The interior penalty virtual element method for fourth-order singular  perturbation problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+F">Fang Feng</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+Y">Yue Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IPVEM for singular perturbation problems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper is dedicated to the numerical solution of a fourth-order singular
perturbation problem using the interior penalty virtual element method (IPVEM)
proposed in [42]. The study introduces modifications to the jumps and averages
in the penalty term, as well as presents an automated mesh-dependent selection
of the penalty parameter. Drawing inspiration from the modified Morley finite
element methods, we leverage the conforming interpolation technique to handle
the lower part of the bilinear form. Through our analysis, we establish optimal
convergence in the energy norm and provide a rigorous proof of uniform
convergence concerning the perturbation parameter in the lowest-order case.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10861" title="Abstract">arXiv:2312.10861</a> [<a href="/pdf/2312.10861" title="Download PDF">pdf</a>, <a href="/format/2312.10861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Ownership in Open-Source AI Software Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jiawen Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, in submission for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As open-source AI software projects become an integral component in the AI
software development, it is critical to develop a novel methods to ensure and
measure the security of the open-source projects for developers. Code
ownership, pivotal in the evolution of such projects, offers insights into
developer engagement and potential vulnerabilities. In this paper, we leverage
the code ownership metrics to empirically investigate the correlation with the
latent vulnerabilities across five prominent open-source AI software projects.
The findings from the large-scale empirical study suggest a positive
relationship between high-level ownership (characterised by a limited number of
minor contributors) and a decrease in vulnerabilities. Furthermore, we
innovatively introduce the time metrics, anchored on the project's duration,
individual source code file timelines, and the count of impacted releases.
These metrics adeptly categorise distinct phases of open-source AI software
projects and their respective vulnerability intensities. With these novel code
ownership metrics, we have implemented a Python-based command-line application
to aid project curators and quality assurance professionals in evaluating and
benchmarking their on-site projects. We anticipate this work will embark a
continuous research development for securing and measuring open-source AI
project security.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10863" title="Abstract">arXiv:2312.10863</a> [<a href="/pdf/2312.10863" title="Download PDF">pdf</a>, <a href="/ps/2312.10863" title="Download PostScript">ps</a>, <a href="/format/2312.10863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disclosure Avoidance for the 2020 Census Demographic and Housing  Characteristics File
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cumings-Menon%2C+R">Ryan Cumings-Menon</a>, 
<a href="/search/cs?searchtype=author&query=Ashmead%2C+R">Robert Ashmead</a>, 
<a href="/search/cs?searchtype=author&query=Kifer%2C+D">Daniel Kifer</a>, 
<a href="/search/cs?searchtype=author&query=Leclerc%2C+P">Philip Leclerc</a>, 
<a href="/search/cs?searchtype=author&query=Spence%2C+M">Matthew Spence</a>, 
<a href="/search/cs?searchtype=author&query=Zhuravlev%2C+P">Pavel Zhuravlev</a>, 
<a href="/search/cs?searchtype=author&query=Abowd%2C+J+M">John M. Abowd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation (stat.CO)

</div>
<p class="mathjax">In "The 2020 Census Disclosure Avoidance System TopDown Algorithm," Abowd et
al. (2022) describe the concepts and methods used by the Disclosure Avoidance
System (DAS) to produce formally private output in support of the 2020 Census
data product releases, with a particular focus on the DAS implementation that
was used to create the 2020 Census Redistricting Data (P.L. 94-171) Summary
File. In this paper we describe the updates to the DAS that were required to
release the Demographic and Housing Characteristics (DHC) File, which provides
more granular tables than other data products, such as the Redistricting Data
Summary File. We also describe the final configuration parameters used for the
production DHC DAS implementation, as well as subsequent experimental data
products to facilitate development of tools that provide confidence intervals
for confidential 2020 Census tabulations.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10864" title="Abstract">arXiv:2312.10864</a> [<a href="/pdf/2312.10864" title="Download PDF">pdf</a>, <a href="/ps/2312.10864" title="Download PostScript">ps</a>, <a href="/format/2312.10864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-Device Recommender Systems: A Tutorial on The New-Generation  Recommendation Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical tutorial; to appear at The Web Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Given the sheer volume of contemporary e-commerce applications, recommender
systems (RSs) have gained significant attention in both academia and industry.
However, traditional cloud-based RSs face inevitable challenges, such as
resource-intensive computation, reliance on network access, and privacy
breaches. In response, a new paradigm called on-device recommender systems
(ODRSs) has emerged recently in various industries like Taobao, Google, and
Kuaishou. ODRSs unleash the computational capacity of user devices with
lightweight recommendation models tailored for resource-constrained
environments, enabling real-time inference with users' local data. This
tutorial aims to systematically introduce methodologies of ODRSs, including (1)
an overview of existing research on ODRSs; (2) a comprehensive taxonomy of
ODRSs, where the core technical content to be covered span across three major
ODRS research directions, including on-device deployment and inference,
on-device training, and privacy/security of ODRSs; (3) limitations and future
directions of ODRSs. This tutorial expects to lay the foundation and spark new
insights for follow-up research and applications concerning this new
recommendation paradigm.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10868" title="Abstract">arXiv:2312.10868</a> [<a href="/pdf/2312.10868" title="Download PDF">pdf</a>, <a href="/ps/2312.10868" title="Download PostScript">ps</a>, <a href="/format/2312.10868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the  Generative Artificial Intelligence (AI) Research Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+T+R">Timothy R. McIntosh</a>, 
<a href="/search/cs?searchtype=author&query=Susnjak%2C+T">Teo Susnjak</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Watters%2C+P">Paul Watters</a>, 
<a href="/search/cs?searchtype=author&query=Halgamuge%2C+M+N">Malka N. Halgamuge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This comprehensive survey explored the evolving landscape of generative
Artificial Intelligence (AI), with a specific focus on the transformative
impacts of Mixture of Experts (MoE), multimodal learning, and the speculated
advancements towards Artificial General Intelligence (AGI). It critically
examined the current state and future trajectory of generative Artificial
Intelligence (AI), exploring how innovations like Google's Gemini and the
anticipated OpenAI Q* project are reshaping research priorities and
applications across various domains, including an impact analysis on the
generative AI research taxonomy. It assessed the computational challenges,
scalability, and real-world implications of these technologies while
highlighting their potential in driving significant progress in fields like
healthcare, finance, and education. It also addressed the emerging academic
challenges posed by the proliferation of both AI-themed and AI-generated
preprints, examining their impact on the peer-review process and scholarly
communication. The study highlighted the importance of incorporating ethical
and human-centric methods in AI development, ensuring alignment with societal
norms and welfare, and outlined a strategy for future AI research that focuses
on a balanced and conscientious use of MoE, multimodality, and AGI in
generative AI.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10872" title="Abstract">arXiv:2312.10872</a> [<a href="/pdf/2312.10872" title="Download PDF">pdf</a>, <a href="/format/2312.10872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Country-Scale Cropland Mapping in Data-Scarce Settings Using Deep  Learning: A Case Study of Nigeria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gajardo%2C+J">Joaquin Gajardo</a>, 
<a href="/search/cs?searchtype=author&query=Volpi%2C+M">Michele Volpi</a>, 
<a href="/search/cs?searchtype=author&query=Onwude%2C+D">Daniel Onwude</a>, 
<a href="/search/cs?searchtype=author&query=Defraeye%2C+T">Thijs Defraeye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cropland maps are a core and critical component of remote-sensing-based
agricultural monitoring, providing dense and up-to-date information about
agricultural development. Machine learning is an effective tool for large-scale
agricultural mapping, but relies on geo-referenced ground-truth data for model
training and testing, which can be scarce or time-consuming to obtain. In this
study, we explore the usefulness of combining a global cropland dataset and a
hand-labeled dataset to train machine learning models for generating a new
cropland map for Nigeria in 2020 at 10 m resolution. We provide the models with
pixel-wise time series input data from remote sensing sources such as
Sentinel-1 and 2, ERA5 climate data, and DEM data, in addition to binary labels
indicating cropland presence. We manually labeled 1827 evenly distributed
pixels across Nigeria, splitting them into 50\% training, 25\% validation, and
25\% test sets used to fit the models and test our output map. We evaluate and
compare the performance of single- and multi-headed Long Short-Term Memory
(LSTM) neural network classifiers, a Random Forest classifier, and three
existing 10 m resolution global land cover maps (Google's Dynamic World, ESRI's
Land Cover, and ESA's WorldCover) on our proposed test set. Given the regional
variations in cropland appearance, we additionally experimented with excluding
or sub-setting the global crowd-sourced Geowiki cropland dataset, to
empirically assess the trade-off between data quantity and data quality in
terms of the similarity to the target data distribution of Nigeria. We find
that the existing WorldCover map performs the best with an F1-score of 0.825
and accuracy of 0.870 on the test set, followed by a single-headed LSTM model
trained with our hand-labeled training samples and the Geowiki data points in
Nigeria, with a F1-score of 0.814 and accuracy of 0.842.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10877" title="Abstract">arXiv:2312.10877</a> [<a href="/pdf/2312.10877" title="Download PDF">pdf</a>, <a href="/format/2312.10877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial  Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+K">Ke Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Haifeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wenxiong Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Speech-driven 3D facial animation aims to synthesize vivid facial animations
that accurately synchronize with speech and match the unique speaking style.
However, existing works primarily focus on achieving precise lip
synchronization while neglecting to model the subject-specific speaking style,
often resulting in unrealistic facial animations. To the best of our knowledge,
this work makes the first attempt to explore the coupled information between
the speaking style and the semantic content in facial motions. Specifically, we
introduce an innovative speaking style disentanglement method, which enables
arbitrary-subject speaking style encoding and leads to a more realistic
synthesis of speech-driven facial animations. Subsequently, we propose a novel
framework called \textbf{Mimic} to learn disentangled representations of the
speaking style and content from facial motions by building two latent spaces
for style and content, respectively. Moreover, to facilitate disentangled
representation learning, we introduce four well-designed constraints: an
auxiliary style classifier, an auxiliary inverse classifier, a content
contrastive loss, and a pair of latent cycle losses, which can effectively
contribute to the construction of the identity-related style space and
semantic-related content space. Extensive qualitative and quantitative
experiments conducted on three publicly available datasets demonstrate that our
approach outperforms state-of-the-art methods and is capable of capturing
diverse speaking styles for speech-driven 3D facial animation. The source code
and supplementary video are publicly available at:
https://zeqing-wang.github.io/Mimic/
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10879" title="Abstract">arXiv:2312.10879</a> [<a href="/pdf/2312.10879" title="Download PDF">pdf</a>, <a href="/ps/2312.10879" title="Download PostScript">ps</a>, <a href="/format/2312.10879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and Evaluation of Ensemble Learning-based Environmental  Methane Detection and Intensity Prediction Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumder%2C+R">Reek Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Pollard%2C+J">Jacquan Pollard</a>, 
<a href="/search/cs?searchtype=author&query=Salek%2C+M+S">M Sabbir Salek</a>, 
<a href="/search/cs?searchtype=author&query=Werth%2C+D">David Werth</a>, 
<a href="/search/cs?searchtype=author&query=Comert%2C+G">Gurcan Comert</a>, 
<a href="/search/cs?searchtype=author&query=Gale%2C+A">Adrian Gale</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+M">Sakib Mahmud Khan</a>, 
<a href="/search/cs?searchtype=author&query=Darko%2C+S">Samuel Darko</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mashrur Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The environmental impacts of global warming driven by methane (CH4) emissions
have catalyzed significant research initiatives in developing novel
technologies that enable proactive and rapid detection of CH4. Several
data-driven machine learning (ML) models were tested to determine how well they
identified fugitive CH4 and its related intensity in the affected areas.
Various meteorological characteristics, including wind speed, temperature,
pressure, relative humidity, water vapor, and heat flux, were included in the
simulation. We used the ensemble learning method to determine the
best-performing weighted ensemble ML models built upon several weaker
lower-layer ML models to (i) detect the presence of CH4 as a classification
problem and (ii) predict the intensity of CH4 as a regression problem.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10880" title="Abstract">arXiv:2312.10880</a> [<a href="/pdf/2312.10880" title="Download PDF">pdf</a>, <a href="/format/2312.10880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharable Clothoid-based Continuous Motion Planning for Connected  Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sanghoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+H+E">H. Eric Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+G">Gaurav Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Orosz%2C+G">Gabor Orosz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">A continuous motion planning method for connected automated vehicles is
considered for generating feasible trajectories in real-time using three
consecutive clothoids. The proposed method reduces path planning to a small set
of nonlinear algebraic equations such that the generated path can be
efficiently checked for feasibility and collision. After path planning,
velocity planning is executed while maintaining a parallel simple structure.
Key strengths of this framework include its interpretability, shareability, and
ability to specify boundary conditions. Its interpretability and shareability
stem from the succinct representation of the resulting local motion plan using
a handful of physically meaningful parameters. Vehicles may share these
parameters via V2X communication so that the recipients can precisely
reconstruct the planned trajectory of the senders and respond accordingly. The
proposed local planner guarantees the satisfaction of boundary conditions, thus
ensuring seamless integration with a wide array of higher-level global motion
planners. The tunable nature of the method enables tailoring the local plans to
specific maneuvers like turns at intersections, lane changes, and U-turns.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10884" title="Abstract">arXiv:2312.10884</a> [<a href="/pdf/2312.10884" title="Download PDF">pdf</a>, <a href="/format/2312.10884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Reinforcement Learning for Offshore Wind Farm Bidding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cole%2C+D">David Cole</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+H">Himanshu Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a framework for applying reinforcement learning to contextual
two-stage stochastic optimization and apply this framework to the problem of
energy market bidding of an off-shore wind farm. Reinforcement learning could
potentially be used to learn close to optimal solutions for first stage
variables of a two-stage stochastic program under different contexts. Under the
proposed framework, these solutions would be learned without having to solve
the full two-stage stochastic program. We present initial results of training
using the DDPG algorithm and present intended future steps to improve
performance.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10885" title="Abstract">arXiv:2312.10885</a> [<a href="/pdf/2312.10885" title="Download PDF">pdf</a>, <a href="/format/2312.10885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel diffusion recommendation algorithm based on multi-scale cnn and  residual lstm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xing Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhichun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruidi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+M">Mindong Xin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation aims to infer user preferences from historical
interaction sequences and predict the next item that users may be interested in
the future. The current mainstream design approach is to represent items as
fixed vectors, capturing the underlying relationships between items and user
preferences based on the order of interactions. However, relying on a single
fixed-item embedding may weaken the modeling capability of the system, and the
global dynamics and local saliency exhibited by user preferences need to be
distinguished. To address these issues, this paper proposes a novel diffusion
recommendation algorithm based on multi-scale cnn and residual lstm (AREAL). We
introduce diffusion models into the recommend system, representing items as
probability distributions instead of fixed vectors. This approach enables
adaptive reflection of multiple aspects of the items and generates item
distributions in a denoising manner. We use multi-scale cnn and residual lstm
methods to extract the local and global dependency features of user history
interactions, and use attention mechanism to distinguish weights as the guide
features of reverse diffusion recovery. The effectiveness of the proposed
method is validated through experiments conducted on two real-world datasets.
Specifically, AREAL obtains improvements over the best baselines by 2.63% and
4.25% in terms of HR@20 and 5.05% and 3.94% in terms of NDCG@20 on all
datasets.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10887" title="Abstract">arXiv:2312.10887</a> [<a href="/pdf/2312.10887" title="Download PDF">pdf</a>, <a href="/format/2312.10887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Computing Makespan-Optimal Solutions for Generalized Sliding-Tile  Puzzles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gozon%2C+M">Marcus Gozon</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingjin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In the $15$-puzzle game, $15$ labeled square tiles are reconfigured on a
$4\times 4$ board through an escort, wherein each (time) step, a single tile
neighboring it may slide into it, leaving the space previously occupied by the
tile as the new escort. We study a generalized sliding-tile puzzle (GSTP) in
which (1) there are $1+$ escorts and (2) multiple tiles can move synchronously
in a single time step. Compared with popular discrete multi-agent/robot motion
models, GSTP provides a more accurate model for a broad array of high-utility
applications, including warehouse automation and autonomous garage parking, but
is less studied due to the more involved tile interactions. In this work, we
analyze optimal GSTP solution structures, establishing that computing
makespan-optimal solutions for GSTP is NP-complete and developing polynomial
time algorithms yielding makespans approximating the minimum with expected/high
probability constant factors, assuming randomized start and goal
configurations.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10888" title="Abstract">arXiv:2312.10888</a> [<a href="/pdf/2312.10888" title="Download PDF">pdf</a>, <a href="/format/2312.10888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age-Threshold Slotted ALOHA for Optimizing Information Freshness in  Mobile Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fangming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinghua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard H. Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We optimize the Age of Information (AoI) in mobile networks using the
age-threshold slotted ALOHA (TSA) protocol. The network comprises multiple
source-destination pairs, where each source sends a sequence of status update
packets to its destination over a shared spectrum. The TSA protocol stipulates
that a source node must remain silent until its AoI reaches a predefined
threshold, after which the node accesses the radio channel with a certain
probability. Using stochastic geometry tools, we derive analytical expressions
for the transmission success probability, mean peak AoI, and time-average AoI.
Subsequently, we obtain closed-form expressions for the optimal update rate and
age threshold that minimize the mean peak and time-average AoI, respectively.
In addition, we establish a scaling law for the mean peak AoI and time-average
AoI in mobile networks, revealing that the optimal mean peak AoI and
time-average AoI increase linearly with the deployment density. Notably, the
growth rate of time-average AoI under TSA is half of that under conventional
slotted ALOHA. When considering the optimal mean peak AoI, the TSA protocol
exhibits comparable performance to the traditional slotted ALOHA protocol.
These findings conclusively affirm the advantage of TSA in reducing
higher-order AoI, particularly in densely deployed networks.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10890" title="Abstract">arXiv:2312.10890</a> [<a href="/pdf/2312.10890" title="Download PDF">pdf</a>, <a href="/format/2312.10890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-latency Space-time Supersampling for Real-time Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ri Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">With the rise of real-time rendering and the evolution of display devices,
there is a growing demand for post-processing methods that offer
high-resolution content in a high frame rate. Existing techniques often suffer
from quality and latency issues due to the disjointed treatment of frame
supersampling and extrapolation. In this paper, we recognize the shared context
and mechanisms between frame supersampling and extrapolation, and present a
novel framework, Space-time Supersampling (STSS). By integrating them into a
unified framework, STSS can improve the overall quality with lower latency. To
implement an efficient architecture, we treat the aliasing and warping holes
unified as reshading regions and put forth two key components to compensate the
regions, namely Random Reshading Masking (RRM) and Efficient Reshading Module
(ERM). Extensive experiments demonstrate that our approach achieves superior
visual fidelity compared to state-of-the-art (SOTA) methods. Notably, the
performance is achieved within only 4ms, saving up to 75\% of time against the
conventional two-stage pipeline that necessitates 17ms.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10891" title="Abstract">arXiv:2312.10891</a> [<a href="/pdf/2312.10891" title="Download PDF">pdf</a>, <a href="/ps/2312.10891" title="Download PostScript">ps</a>, <a href="/format/2312.10891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A generalization of the relaxation-based matrix splitting iterative  method for solving the system of generalized absolute value equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xuehua Li</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Cairong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">By incorporating a new matrix splitting and the momentum acceleration into
the relaxed-based matrix splitting (RMS) method \cite{soso2023}, a
generalization of the RMS (GRMS) iterative method for solving the generalized
absolute value equations (GAVEs) is proposed. Unlike some existing methods, by
using the Cauchy's convergence principle, we give some sufficient conditions
for the existence and uniqueness of the solution to the GAVEs and prove that
our method can converge to the unique solution of the GAVEs. Moreover, we can
obtain a few new and weaker convergence conditions for some existing methods.
Preliminary numerical experiments show that the proposed method is efficient.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10893" title="Abstract">arXiv:2312.10893</a> [<a href="/pdf/2312.10893" title="Download PDF">pdf</a>, <a href="/format/2312.10893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Metacognitive Demands and Opportunities of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tankelevitch%2C+L">Lev Tankelevitch</a>, 
<a href="/search/cs?searchtype=author&query=Kewenig%2C+V">Viktor Kewenig</a>, 
<a href="/search/cs?searchtype=author&query=Simkute%2C+A">Auste Simkute</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+A+E">Ava Elizabeth Scott</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Advait Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Sellen%2C+A">Abigail Sellen</a>, 
<a href="/search/cs?searchtype=author&query=Rintel%2C+S">Sean Rintel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative AI (GenAI) systems offer unprecedented opportunities for
transforming professional and personal work, yet present challenges around
prompting, evaluating and relying on outputs, and optimizing workflows. We
argue that metacognition$\unicode{x2013}$the psychological ability to monitor
and control one's thoughts and behavior$\unicode{x2013}$offers a valuable lens
to understand and design for these usability challenges. Drawing on research in
psychology and cognitive science, and recent GenAI user studies, we illustrate
how GenAI systems impose metacognitive demands on users, requiring a high
degree of metacognitive monitoring and control. We propose these demands could
be addressed by integrating metacognitive support strategies into GenAI
systems, and by designing GenAI systems to reduce their metacognitive demand by
targeting explainability and customizability. Metacognition offers a coherent
framework for understanding the usability challenges posed by GenAI, enabling
us to offer research and design directions to advance human-GenAI interaction.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10897" title="Abstract">arXiv:2312.10897</a> [<a href="/pdf/2312.10897" title="Download PDF">pdf</a>, <a href="/format/2312.10897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Category Discovery with Large Language Models in the Loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wenbin An</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenkai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+F">Feng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haonan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">QianYing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingxiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haiping Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalized Category Discovery (GCD) is a crucial task that aims to recognize
both known and novel categories from a set of unlabeled data by utilizing a few
labeled data with only known categories. Due to the lack of supervision and
category information, current methods usually perform poorly on novel
categories and struggle to reveal semantic meanings of the discovered clusters,
which limits their applications in the real world. To mitigate above issues, we
propose Loop, an end-to-end active-learning framework that introduces Large
Language Models (LLMs) into the training loop, which can boost model
performance and generate category names without relying on any human efforts.
Specifically, we first propose Local Inconsistent Sampling (LIS) to select
samples that have a higher probability of falling to wrong clusters, based on
neighborhood prediction consistency and entropy of cluster assignment
probabilities. Then we propose a Scalable Query strategy to allow LLMs to
choose true neighbors of the selected samples from multiple candidate samples.
Based on the feedback from LLMs, we perform Refined Neighborhood Contrastive
Learning (RNCL) to pull samples and their neighbors closer to learn
clustering-friendly representations. Finally, we select representative samples
from clusters corresponding to novel categories to allow LLMs to generate
category names for them. Extensive experiments on three benchmark datasets show
that Loop outperforms SOTA models by a large margin and generates accurate
category names for the discovered clusters. We will release our code and data
after publication.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10899" title="Abstract">arXiv:2312.10899</a> [<a href="/pdf/2312.10899" title="Download PDF">pdf</a>, <a href="/format/2312.10899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicScroll: Nontypical Aspect-Ratio Image Generation for Visual  Storytelling via Multi-Layered Semantic-Aware Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Hengyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zeyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lanjiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yue Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://magicscroll.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual storytelling often uses nontypical aspect-ratio images like scroll
paintings, comic strips, and panoramas to create an expressive and compelling
narrative. While generative AI has achieved great success and shown the
potential to reshape the creative industry, it remains a challenge to generate
coherent and engaging content with arbitrary size and controllable style,
concept, and layout, all of which are essential for visual storytelling. To
overcome the shortcomings of previous methods including repetitive content,
style inconsistency, and lack of controllability, we propose MagicScroll, a
multi-layered, progressive diffusion-based image generation framework with a
novel semantic-aware denoising process. The model enables fine-grained control
over the generated image on object, scene, and background levels with text,
image, and layout conditions. We also establish the first benchmark for
nontypical aspect-ratio image generation for visual storytelling including
mediums like paintings, comics, and cinematic panoramas, with customized
metrics for systematic evaluation. Through comparative and ablation studies,
MagicScroll showcases promising results in aligning with the narrative text,
improving visual coherence, and engaging the audience. We plan to release the
code and benchmark in the hope of a better collaboration between AI researchers
and creative practitioners involving visual storytelling.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10900" title="Abstract">arXiv:2312.10900</a> [<a href="/pdf/2312.10900" title="Download PDF">pdf</a>, <a href="/format/2312.10900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetroOOD: Understanding Out-of-Distribution Generalization in  Retrosynthesis Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yemin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Luotian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Ying Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hanyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinhai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Machine learning-assisted retrosynthesis prediction models have been gaining
widespread adoption, though their performances oftentimes degrade significantly
when deployed in real-world applications embracing out-of-distribution (OOD)
molecules or reactions. Despite steady progress on standard benchmarks, our
understanding of existing retrosynthesis prediction models under the premise of
distribution shifts remains stagnant. To this end, we first formally sort out
two types of distribution shifts in retrosynthesis prediction and construct two
groups of benchmark datasets. Next, through comprehensive experiments, we
systematically compare state-of-the-art retrosynthesis prediction models on the
two groups of benchmarks, revealing the limitations of previous in-distribution
evaluation and re-examining the advantages of each model. More remarkably, we
are motivated by the above empirical insights to propose two model-agnostic
techniques that can improve the OOD generalization of arbitrary off-the-shelf
retrosynthesis prediction algorithms. Our preliminary experiments show their
high potential with an average performance improvement of 4.6%, and the
established benchmarks serve as a foothold for further retrosynthesis
prediction research towards OOD generalization.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10903" title="Abstract">arXiv:2312.10903</a> [<a href="/pdf/2312.10903" title="Download PDF">pdf</a>, <a href="/format/2312.10903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Node Representation Learning via Graph Variational Diffusion  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jun Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+A">Mohammad Al Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Node representation learning by using Graph Neural Networks (GNNs) has been
widely explored. However, in recent years, compelling evidence has revealed
that GNN-based node representation learning can be substantially deteriorated
by delicately-crafted perturbations in a graph structure. To learn robust node
representation in the presence of perturbations, various works have been
proposed to safeguard GNNs. Within these existing works, Bayesian label
transition has been proven to be more effective, but this method is extensively
reliant on a well-built prior distribution. The variational inference could
address this limitation by sampling the latent node embedding from a Gaussian
prior distribution. Besides, leveraging the Gaussian distribution (noise) in
hidden layers is an appealing strategy to strengthen the robustness of GNNs.
However, our experiments indicate that such a strategy can cause over-smoothing
issues during node aggregation. In this work, we propose the Graph Variational
Diffusion Network (GVDN), a new node encoder that effectively manipulates
Gaussian noise to safeguard robustness on perturbed graphs while alleviating
over-smoothing issues through two mechanisms: Gaussian diffusion and node
embedding propagation. Thanks to these two mechanisms, our model can generate
robust node embeddings for recovery. Specifically, we design a retraining
mechanism using the generated node embedding to recover the performance of node
classifications in the presence of perturbations. The experiments verify the
effectiveness of our proposed model across six public datasets.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10904" title="Abstract">arXiv:2312.10904</a> [<a href="/pdf/2312.10904" title="Download PDF">pdf</a>, <a href="/ps/2312.10904" title="Download PostScript">ps</a>, <a href="/format/2312.10904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Retrieval Augmented Generation of Ontologies using Artificial  Intelligence (DRAGON-AI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toro%2C+S">Sabrina Toro</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostopoulos%2C+A+V">Anna V Anagnostopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+S">Sue Bello</a>, 
<a href="/search/cs?searchtype=author&query=Blumberg%2C+K">Kai Blumberg</a>, 
<a href="/search/cs?searchtype=author&query=Cameron%2C+R">Rhiannon Cameron</a>, 
<a href="/search/cs?searchtype=author&query=Carmody%2C+L">Leigh Carmody</a>, 
<a href="/search/cs?searchtype=author&query=Diehl%2C+A+D">Alexander D Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Dooley%2C+D">Damion Dooley</a>, 
<a href="/search/cs?searchtype=author&query=Duncan%2C+W">William Duncan</a>, 
<a href="/search/cs?searchtype=author&query=Fey%2C+P">Petra Fey</a>, 
<a href="/search/cs?searchtype=author&query=Gaudet%2C+P">Pascale Gaudet</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+N+L">Nomi L Harris</a>, 
<a href="/search/cs?searchtype=author&query=Joachimiak%2C+M">Marcin Joachimiak</a>, 
<a href="/search/cs?searchtype=author&query=Kiani%2C+L">Leila Kiani</a>, 
<a href="/search/cs?searchtype=author&query=Lubiana%2C+T">Tiago Lubiana</a>, 
<a href="/search/cs?searchtype=author&query=Munoz-Torres%2C+M+C">Monica C Munoz-Torres</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neil%2C+S">Shawn O&#x27;Neil</a>, 
<a href="/search/cs?searchtype=author&query=Osumi-Sutherland%2C+D">David Osumi-Sutherland</a>, 
<a href="/search/cs?searchtype=author&query=Puig%2C+A">Aleix Puig</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+J+P">Justin P Reese</a>, 
<a href="/search/cs?searchtype=author&query=Reiser%2C+L">Leonore Reiser</a>, 
<a href="/search/cs?searchtype=author&query=Robb%2C+S">Sofia Robb</a>, 
<a href="/search/cs?searchtype=author&query=Ruemping%2C+T">Troy Ruemping</a>, 
<a href="/search/cs?searchtype=author&query=Seager%2C+J">James Seager</a>, 
<a href="/search/cs?searchtype=author&query=Sid%2C+E">Eric Sid</a>, 
<a href="/search/cs?searchtype=author&query=Stefancsik%2C+R">Ray Stefancsik</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Magalie Weber</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+V">Valerie Wood</a>, 
<a href="/search/cs?searchtype=author&query=Haendel%2C+M+A">Melissa A Haendel</a>, 
<a href="/search/cs?searchtype=author&query=Mungall%2C+C+J">Christopher J Mungall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Ontologies are fundamental components of informatics infrastructure in
domains such as biomedical, environmental, and food sciences, representing
consensus knowledge in an accurate and computable form. However, their
construction and maintenance demand substantial resources, necessitating
substantial collaborative efforts of domain experts, curators, and ontology
experts.
<br />We present Dynamic Retrieval Augmented Generation of Ontologies using AI
(DRAGON-AI), an ontology generation method employing Large Language Models
(LLMs) and Retrieval Augmented Generation (RAG). This method can generate
textual and logical ontology components, drawing from existing knowledge in
multiple ontologies, as well as unstructured textual sources.
<br />We assessed DRAGON-AI across ten diverse ontologies, making use of extensive
manual evaluation of results. We demonstrate high precision for relationship
generation, close to but lower than precision from logic-based reasoning. We
also demonstrate definition generation comparable with but lower than
human-generated definitions. Notably, expert evaluators were better able to
discern subtle flaws in AI-generated definitions. We also demonstrated the
ability of DRAGON-AI to incorporate natural language instructions in the form
of GitHub issues.
<br />These findings suggest DRAGON-AI's potential to substantially aid the manual
ontology construction process. However, our results also underscore the
importance of having expert curators and ontology editors drive the ontology
generation process.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10905" title="Abstract">arXiv:2312.10905</a> [<a href="/pdf/2312.10905" title="Download PDF">pdf</a>, <a href="/ps/2312.10905" title="Download PostScript">ps</a>, <a href="/format/2312.10905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satellite Captioning: Large Language Models to Augment Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosario%2C+G">Grant Rosario</a>, 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the growing capabilities of modern object detection networks and
datasets to train them, it has gotten more straightforward and, importantly,
less laborious to get up and running with a model that is quite adept at
detecting any number of various objects. However, while image datasets for
object detection have grown and continue to proliferate (the current most
extensive public set, ImageNet, contains over 14m images with over 14m
instances), the same cannot be said for textual caption datasets. While they
have certainly been growing in recent years, caption datasets present a much
more difficult challenge due to language differences, grammar, and the time it
takes for humans to generate them. Current datasets have certainly provided
many instances to work with, but it becomes problematic when a captioner may
have a more limited vocabulary, one may not be adequately fluent in the
language, or there are simple grammatical mistakes. These difficulties are
increased when the images get more specific, such as remote sensing images.
This paper aims to address this issue of potential information and
communication shortcomings in caption datasets. To provide a more precise
analysis, we specify our domain of images to be remote sensing images in the
RSICD dataset and experiment with the captions provided here. Our findings
indicate that ChatGPT grammar correction is a simple and effective way to
increase the performance accuracy of caption models by making data captions
more diverse and grammatically correct.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10908" title="Abstract">arXiv:2312.10908</a> [<a href="/pdf/2312.10908" title="Download PDF">pdf</a>, <a href="/format/2312.10908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuntao Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xintong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wenjuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Leveraging large language models (LLMs) to integrate off-the-shelf tools
(e.g., visual models and image processing functions) is a promising research
direction to build powerful visual assistants for solving diverse visual tasks.
However, the learning capability is rarely explored in existing methods, as
they freeze the used tools after deployment, thereby limiting the
generalization to new environments requiring specific knowledge. In this paper,
we propose CLOVA, a Closed-LOop Visual Assistant to address this limitation,
which encompasses inference, reflection, and learning phases in a closed-loop
framework. During inference, LLMs generate programs and execute corresponding
tools to accomplish given tasks. The reflection phase introduces a multimodal
global-local reflection scheme to analyze whether and which tool needs to be
updated based on environmental feedback. Lastly, the learning phase uses three
flexible manners to collect training data in real-time and introduces a novel
prompt tuning scheme to update the tools, enabling CLOVA to efficiently learn
specific knowledge for new environments without human involvement. Experiments
show that CLOVA outperforms tool-usage methods by 5% in visual question
answering and multiple-image reasoning tasks, by 10% in knowledge tagging
tasks, and by 20% in image editing tasks, highlighting the significance of the
learning capability for general visual assistants.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10911" title="Abstract">arXiv:2312.10911</a> [<a href="/pdf/2312.10911" title="Download PDF">pdf</a>, <a href="/ps/2312.10911" title="Download PostScript">ps</a>, <a href="/format/2312.10911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pros and Cons of Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izza%2C+Y">Yacine Izza</a>, 
<a href="/search/cs?searchtype=author&query=Marques-Silva%2C+J">Joao Marques-Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robustness is widely regarded as a fundamental problem in the analysis of
machine learning (ML) models. Most often robustness equates with deciding the
non-existence of adversarial examples, where adversarial examples denote
situations where small changes on some inputs cause a change in the prediction.
The perceived importance of ML model robustness explains the continued progress
observed for most of the last decade. Whereas robustness is often assessed
locally, i.e. given some target point in feature space, robustness can also be
defined globally, i.e. where any point in feature space can be considered. The
importance of ML model robustness is illustrated for example by the existence
of competitions evaluating the progress of robustness tools, namely in the case
of neural networks (NNs) but also by efforts towards robustness certification.
More recently, robustness tools have also been used for computing rigorous
explanations of ML models. In contrast with the observed successes of
robustness, this paper uncovers some limitations with existing definitions of
robustness, both global and local, but also with efforts towards robustness
certification. The paper also investigates uses of adversarial examples besides
those related with robustness.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10913" title="Abstract">arXiv:2312.10913</a> [<a href="/pdf/2312.10913" title="Download PDF">pdf</a>, <a href="/format/2312.10913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GINN-LP: A Growing Interpretable Neural Network for Discovering  Multivariate Laurent Polynomial Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+N">Nisal Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Senanayake%2C+D">Damith Senanayake</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+S">Sachith Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Premaratne%2C+M">Malin Premaratne</a>, 
<a href="/search/cs?searchtype=author&query=Halgamuge%2C+S">Saman Halgamuge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional machine learning is generally treated as a black-box optimization
problem and does not typically produce interpretable functions that connect
inputs and outputs. However, the ability to discover such interpretable
functions is desirable. In this work, we propose GINN-LP, an interpretable
neural network to discover the form and coefficients of the underlying equation
of a dataset, when the equation is assumed to take the form of a multivariate
Laurent Polynomial. This is facilitated by a new type of interpretable neural
network block, named the "power-term approximator block", consisting of
logarithmic and exponential activation functions. GINN-LP is end-to-end
differentiable, making it possible to use backpropagation for training. We
propose a neural network growth strategy that will enable finding the suitable
number of terms in the Laurent polynomial that represents the data, along with
sparsity regularization to promote the discovery of concise equations. To the
best of our knowledge, this is the first model that can discover arbitrary
multivariate Laurent polynomial terms without any prior information on the
order. Our approach is first evaluated on a subset of data used in SRBench, a
benchmark for symbolic regression. We first show that GINN-LP outperforms the
state-of-the-art symbolic regression methods on datasets generated using 48
real-world equations in the form of multivariate Laurent polynomials. Next, we
propose an ensemble method that combines our method with a high-performing
symbolic regression method, enabling us to discover non-Laurent polynomial
equations. We achieve state-of-the-art results in equation discovery, showing
an absolute improvement of 7.1% over the best contender, by applying this
ensemble method to 113 datasets within SRBench with known ground-truth
equations.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10915" title="Abstract">arXiv:2312.10915</a> [<a href="/pdf/2312.10915" title="Download PDF">pdf</a>, <a href="/format/2312.10915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relaxation schemes for entropy dissipative system of viscous  conservation laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tuowei Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiequan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce a hyperbolic model for entropy dissipative system
of viscous conservation laws via a flux relaxation approach. We develop
numerical schemes for the resulting hyperbolic relaxation system by employing
the finite-volume methodology used in the community of hyperbolic conservation
laws, e.g., the generalized Riemann problem method. For fully discrete schemes
for the relaxation system of scalar viscous conservation laws, we show the
asymptotic preserving property in the coarse regime without resolving the
relaxation scale and prove the dissipation property by using the modified
equation approach. Further, we extend the idea to the compressible
Navier-Stokes equations. Finally, we display the performance of our relaxation
schemes by a number of numerical experiments.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10917" title="Abstract">arXiv:2312.10917</a> [<a href="/pdf/2312.10917" title="Download PDF">pdf</a>, <a href="/format/2312.10917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Clustering via Structural Entropy with Different  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guangjie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Angsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Runze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, accepted by SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Semi-supervised clustering techniques have emerged as valuable tools for
leveraging prior information in the form of constraints to improve the quality
of clustering outcomes. Despite the proliferation of such methods, the ability
to seamlessly integrate various types of constraints remains limited. While
structural entropy has proven to be a powerful clustering approach with
wide-ranging applications, it has lacked a variant capable of accommodating
these constraints. In this work, we present Semi-supervised clustering via
Structural Entropy (SSE), a novel method that can incorporate different types
of constraints from diverse sources to perform both partitioning and
hierarchical clustering. Specifically, we formulate a uniform view for the
commonly used pairwise and label constraints for both types of clustering.
Then, we design objectives that incorporate these constraints into structural
entropy and develop tailored algorithms for their optimization. We evaluate SSE
on nine clustering datasets and compare it with eleven semi-supervised
partitioning and hierarchical clustering methods. Experimental results
demonstrate the superiority of SSE on clustering accuracy with different types
of constraints. Additionally, the functionality of SSE for biological data
analysis is demonstrated by cell clustering experiments conducted on four
single-cell RNAseq datasets.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10918" title="Abstract">arXiv:2312.10918</a> [<a href="/pdf/2312.10918" title="Download PDF">pdf</a>, <a href="/format/2312.10918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing High-Dimensional Configuration Spaces For Robots: A  Comprehensive Approach for Quantitative and Qualitative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jimenez%2C+J+O">Jorge Ocampo Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Suleiman%2C+W">Wael Suleiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The reconstruction of Configuration Space (CS) from a limited number of
samples plays a vital role in expediting motion planning for random tree
algorithms. Traditionally, the evaluation of CS reconstruction is performed
through collision checking. However, employing the collision checker as an
evaluation measure can be misleading. In particular, a collision checker may
exhibit high accuracy even when only a subset of the original CS is
reconstructed, limiting the motion planner's ability to find paths comparable
to those in the original CS. Additionally, a significant challenge arises when
dealing with high-dimensional CSs, as it becomes increasingly difficult, if not
impossible, to perform qualitative evaluations when working in dimensions
higher than three.
<br />In this paper, we introduce a novel approach for representing
high-dimensional CSs of manipulator robots in a 2D format. Specifically, we
leverage the kinematic chain of manipulator robots and the human ability to
perceive colors based on hue. This allows us to construct a visualization
comprising a series of pairs of 2D projections. We showcase the efficacy of our
method in representing a 7-degree-of-freedom CS of a manipulator robot in a 2D
projection. This representation provides qualitative insights into the joint
boundaries of the robot and the collision state combinations. From a
quantitative perspective, we show that the proposed representation not only
captures accuracy but also furnishes additional information, enhancing our
ability to compare two different high-dimensional CSs during the deployment
phase, beyond what is usually offered by the collision checker. The source code
is publicly available on our repository.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10919" title="Abstract">arXiv:2312.10919</a> [<a href="/pdf/2312.10919" title="Download PDF">pdf</a>, <a href="/format/2312.10919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoT Ground Sensing Systems for Early Wildfire Detection: Technologies,  Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chan%2C+C+C">Chiu Chun Chan</a>, 
<a href="/search/eess?searchtype=author&query=Alvi%2C+S+A">Sheeraz A. Alvi</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xiangyun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Durrani%2C+S">Salman Durrani</a>, 
<a href="/search/eess?searchtype=author&query=Wilson%2C+N">Nicholas Wilson</a>, 
<a href="/search/eess?searchtype=author&query=Yebra%2C+M">Marta Yebra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The threat posed by wildfires or bushfires has become a severe global issue
due to the increase in human activities in forested areas and the impact of
climate change. Consequently, there is a surge in the development of automatic
wildfire detection methods. Approaches based on long-distance imagery from
satellites or watchtowers encounter limitations, such as restricted visibility,
which results in delayed response times. To address and overcome these
challenges, research interest has grown in the implementation of ground-based
Internet of Things (IoT) sensing systems for early wildfire detection. However,
research on energy consumption, detection latency, and detection accuracy of
IoT sensing systems, as well as the performance of various anomaly detection
algorithms when evaluated using these metrics, is lacking. Therefore, in this
article, we present an overview of current IoT ground sensing systems for early
wildfire detection. Camera and environmental sensing technologies suitable for
early wildfire detection are discussed, as well as vision-based detection
algorithms and detection algorithms for environmental sensing. Challenges
related to the development and implementation of IoT ground sensing systems for
early wildfire detection and the future research directions important for
creating a robust detection system to combat the growing threat of wildfires
worldwide are discussed.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10920" title="Abstract">arXiv:2312.10920</a> [<a href="/pdf/2312.10920" title="Download PDF">pdf</a>, <a href="/format/2312.10920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain adaption and physical constrains transfer learning for shale gas  production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaozhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+L">Liangjie Gou</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chao Min</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+D">Duo Yi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaogang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+G">Guoquan Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Effective prediction of shale gas production is crucial for strategic
reservoir development. However, in new shale gas blocks, two main challenges
are encountered: (1) the occurrence of negative transfer due to insufficient
data, and (2) the limited interpretability of deep learning (DL) models. To
tackle these problems, we propose a novel transfer learning methodology that
utilizes domain adaptation and physical constraints. This methodology
effectively employs historical data from the source domain to reduce negative
transfer from the data distribution perspective, while also using physical
constraints to build a robust and reliable prediction model that integrates
various types of data. The methodology starts by dividing the production data
from the source domain into multiple subdomains, thereby enhancing data
diversity. It then uses Maximum Mean Discrepancy (MMD) and global average
distance measures to decide on the feasibility of transfer. Through domain
adaptation, we integrate all transferable knowledge, resulting in a more
comprehensive target model. Lastly, by incorporating drilling, completion, and
geological data as physical constraints, we develop a hybrid model. This model,
a combination of a multi-layer perceptron (MLP) and a Transformer
(Transformer-MLP), is designed to maximize interpretability. Experimental
validation in China's southwestern region confirms the method's effectiveness.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10921" title="Abstract">arXiv:2312.10921</a> [<a href="/pdf/2312.10921" title="Download PDF">pdf</a>, <a href="/format/2312.10921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongze Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-driven talking head synthesis is a promising topic with wide
applications in digital human, film making and virtual reality. Recent
NeRF-based approaches have shown superiority in quality and fidelity compared
to previous studies. However, when it comes to few-shot talking head
generation, a practical scenario where only few seconds of talking video is
available for one identity, two limitations emerge: 1) they either have no base
model, which serves as a facial prior for fast convergence, or ignore the
importance of audio when building the prior; 2) most of them overlook the
degree of correlation between different face regions and audio, e.g., mouth is
audio related, while ear is audio independent. In this paper, we present Audio
Enhanced Neural Radiance Field (AE-NeRF) to tackle the above issues, which can
generate realistic portraits of a new speaker with fewshot dataset.
Specifically, we introduce an Audio Aware Aggregation module into the feature
fusion stage of the reference scheme, where the weight is determined by the
similarity of audio between reference and target image. Then, an Audio-Aligned
Face Generation strategy is proposed to model the audio related and audio
independent regions respectively, with a dual-NeRF framework. Extensive
experiments have shown AE-NeRF surpasses the state-of-the-art on image
fidelity, audio-lip synchronization, and generalization ability, even in
limited training set or training iterations.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10922" title="Abstract">arXiv:2312.10922</a> [<a href="/pdf/2312.10922" title="Download PDF">pdf</a>, <a href="/format/2312.10922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NTrack: A Multiple-Object Tracker and Dataset for Infield Cotton Boll  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muzaddid%2C+M+A+A">Md Ahmed Al Muzaddid</a>, 
<a href="/search/cs?searchtype=author&query=Beksi%2C+W+J">William J. Beksi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in IEEE Transactions on Automation Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In agriculture, automating the accurate tracking of fruits, vegetables, and
fiber is a very tough problem. The issue becomes extremely challenging in
dynamic field environments. Yet, this information is critical for making
day-to-day agricultural decisions, assisting breeding programs, and much more.
To tackle this dilemma, we introduce NTrack, a novel multiple object tracking
framework based on the linear relationship between the locations of neighboring
tracks. NTrack computes dense optical flow and utilizes particle filtering to
guide each tracker. Correspondences between detections and tracks are found
through data association via direct observations and indirect cues, which are
then combined to obtain an updated observation. Our modular multiple object
tracking system is independent of the underlying detection method, thus
allowing for the interchangeable use of any off-the-shelf object detector. We
show the efficacy of our approach on the task of tracking and counting infield
cotton bolls. Experimental results show that our system exceeds contemporary
tracking and cotton boll-based counting methods by a large margin. Furthermore,
we publicly release the first annotated cotton boll video dataset to the
research community.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10925" title="Abstract">arXiv:2312.10925</a> [<a href="/pdf/2312.10925" title="Download PDF">pdf</a>, <a href="/format/2312.10925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving Deeper Into Astromorphic Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+Z+A">Md Zesun Ahmed Mia</a>, 
<a href="/search/cs?searchtype=author&query=Bal%2C+M">Malyaban Bal</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Preliminary attempts at incorporating the critical role of astrocytes - cells
that constitute more than 50% of human brain cells - in brain-inspired
neuromorphic computing remain in infancy. This paper seeks to delve deeper into
various key aspects of neuron-synapse-astrocyte interactions to mimic
self-attention mechanisms in Transformers. The cross-layer perspective explored
in this work involves bio-plausible modeling of Hebbian and pre-synaptic
plasticities in neuron-astrocyte networks, incorporating effects of
non-linearities and feedback along with algorithmic formulations to map the
neuron-astrocyte computations to self-attention mechanism and evaluating the
impact of incorporating bio-realistic effects from the machine learning
application side. Our analysis on sentiment and image classification tasks on
the IMDB and CIFAR10 datasets underscores the importance of constructing
Astromorphic Transformers from both accuracy and learning speed improvement
perspectives.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10930" title="Abstract">arXiv:2312.10930</a> [<a href="/pdf/2312.10930" title="Download PDF">pdf</a>, <a href="/format/2312.10930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Approaches for Seizure Video Analysis: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmedt-Aristizabal%2C+D">David Ahmedt-Aristizabal</a>, 
<a href="/search/cs?searchtype=author&query=Armin%2C+M+A">Mohammad Ali Armin</a>, 
<a href="/search/cs?searchtype=author&query=Hayder%2C+Z">Zeeshan Hayder</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Cairasco%2C+N">Norberto Garcia-Cairasco</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Denman%2C+S">Simon Denman</a>, 
<a href="/search/cs?searchtype=author&query=McGonigal%2C+A">Aileen McGonigal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Epilepsy &amp; Behavior, NEWroscience 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Seizure events may manifest as transient disruptions in movement and
behavior, and the analysis of these clinical signs, referred to as semiology,
is subject to observer variations when specialists evaluate video-recorded
events in the clinical setting. To enhance the accuracy and consistency of
evaluations, computer-aided video analysis of seizures has emerged as a natural
avenue. In the field of medical applications, deep learning and computer vision
approaches have driven substantial advancements. Historically, these approaches
have been used for disease detection, classification, and prediction using
diagnostic data; however, there has been limited exploration of their
application in evaluating video-based motion detection in the clinical
epileptology setting. While vision-based technologies do not aim to replace
clinical expertise, they can significantly contribute to medical
decision-making and patient care by providing quantitative evidence and
decision support. Behavior monitoring tools offer several advantages such as
providing objective information, detecting challenging-to-observe events,
reducing documentation efforts, and extending assessment capabilities to areas
with limited expertise. In this paper, we detail the foundation technologies
used in vision-based systems in the analysis of seizure videos, highlighting
their success in semiology detection and analysis, focusing on work published
in the last 7 years. We systematically present these methods and indicate how
the adoption of deep learning for the analysis of video recordings of seizures
could be approached. Additionally, we illustrate how existing technologies can
be interconnected through an integrated system for video-based semiology
analysis. Finally, we discuss challenges and research directions for future
studies.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10932" title="Abstract">arXiv:2312.10932</a> [<a href="/pdf/2312.10932" title="Download PDF">pdf</a>, <a href="/format/2312.10932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Shape Detection Framework for Deformation Objects Using Clustering  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangqing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper uses clustering algorithms to introduce a shape framework for
deformable objects. Until now, the shape detection of the deformable objects
has faced several challenges: 1) unable to form a unified framework for
multiple shapes; 2) the calculation burden as a large number of calculations;
3) the inability to solve the 3D point-cloud case. A novel shape detection
framework for deformable objects is presented in this paper, which only uses
the input 2D-pixel data of the objects without any artificial markers. The
proposed detection approach runs in a highly real-time manner. For the
definitions of the shapes of the deformable objects, three shape configurations
are used to describe the outlines of the objects, i.e., centerline, contour,
and surface. In addition, for the obtaining of the 3D shape, Different from the
traditional 3D point cloud processing method, this article uses a one-to-one
mapping method between 2D-pixel points and 3D shape points. Therefore, this
guarantees a one-to-one correspondence between 2D and 3D shape points. Hence,
the proposed approach can enhance the autonomous capability to detect the shape
of deformable objects. Detailed experimental results are conducted within the
centerline configuration to evaluate the effectiveness of the proposed shape
detection framework.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10933" title="Abstract">arXiv:2312.10933</a> [<a href="/pdf/2312.10933" title="Download PDF">pdf</a>, <a href="/format/2312.10933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeeBel: Seeing is Believing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sourajit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Dipta%2C+S+R">Shubhashis Roy Dipta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PrePrint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic Segmentation is a significant research field in Computer Vision.
Despite being a widely studied subject area, many visualization tools do not
exist that capture segmentation quality and dataset statistics such as a class
imbalance in the same view. While the significance of discovering and
introspecting the correlation between dataset statistics and AI model
performance for dense prediction computer vision tasks such as semantic
segmentation is well established in the computer vision literature, to the best
of our knowledge, no visualization tools have been proposed to view and analyze
the aforementioned tasks. Our project aims to bridge this gap by proposing
three visualizations that enable users to compare dataset statistics and AI
performance for segmenting all images, a single image in the dataset, explore
the AI model's attention on image regions once trained and browse the quality
of masks predicted by AI for any selected (by user) number of objects under the
same tool. Our project tries to further increase the interpretability of the
trained AI model for segmentation by visualizing its image attention weights.
For visualization, we use Scatterplot and Heatmap to encode correlation and
features, respectively. We further propose to conduct surveys on real users to
study the efficacy of our visualization tool in computer vision and AI domain.
The full system can be accessed at https://github.com/dipta007/SeeBel
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10934" title="Abstract">arXiv:2312.10934</a> [<a href="/pdf/2312.10934" title="Download PDF">pdf</a>, <a href="/format/2312.10934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APIDocBooster: An Extract-Then-Abstract Framework Leveraging Large  Language Models for Augmenting API Documentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiakun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yunbo Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">API documentation is often the most trusted resource for programming. Many
approaches have been proposed to augment API documentation by summarizing
complementary information from external resources such as Stack Overflow.
Existing extractive-based summarization approaches excel in producing faithful
summaries that accurately represent the source content without input length
restrictions. Nevertheless, they suffer from inherent readability limitations.
On the other hand, our empirical study on the abstractive-based summarization
method, i.e., GPT-4, reveals that GPT-4 can generate coherent and concise
summaries but presents limitations in terms of informativeness and
faithfulness.
<br />We introduce APIDocBooster, an extract-then-abstract framework that
seamlessly fuses the advantages of both extractive (i.e., enabling faithful
summaries without length limitation) and abstractive summarization (i.e.,
producing coherent and concise summaries). APIDocBooster consists of two
stages: (1) \textbf{C}ontext-aware \textbf{S}entence \textbf{S}ection
\textbf{C}lassification (CSSC) and (2) \textbf{UP}date \textbf{SUM}marization
(UPSUM). CSSC classifies API-relevant information collected from multiple
sources into API documentation sections. UPSUM first generates extractive
summaries distinct from the original API documentation and then generates
abstractive summaries guided by extractive summaries through in-context
learning.
<br />To enable automatic evaluation of APIDocBooster, we construct the first
dataset for API document augmentation. Our automatic evaluation results reveal
that each stage in APIDocBooster outperforms its baselines by a large margin.
Our human evaluation also demonstrates the superiority of APIDocBooster over
GPT-4 and shows that it improves informativeness, relevance, and faithfulness
by 13.89\%, 15.15\%, and 30.56\%, respectively.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10935" title="Abstract">arXiv:2312.10935</a> [<a href="/pdf/2312.10935" title="Download PDF">pdf</a>, <a href="/format/2312.10935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AEDFL: Efficient Asynchronous Decentralized Federated Learning with  Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+T">Tianshi Che</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruoming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huaiyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>, 
<a href="/search/cs?searchtype=author&query=Valduriez%2C+P">Patrick Valduriez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SDM 2024, 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) has achieved significant achievements recently,
enabling collaborative model training on distributed data over edge devices.
Iterative gradient or model exchanges between devices and the centralized
server in the standard FL paradigm suffer from severe efficiency bottlenecks on
the server. While enabling collaborative training without a central server,
existing decentralized FL approaches either focus on the synchronous mechanism
that deteriorates FL convergence or ignore device staleness with an
asynchronous mechanism, resulting in inferior FL accuracy. In this paper, we
propose an Asynchronous Efficient Decentralized FL framework, i.e., AEDFL, in
heterogeneous environments with three unique contributions. First, we propose
an asynchronous FL system model with an efficient model aggregation method for
improving the FL convergence. Second, we propose a dynamic staleness-aware
model update approach to achieve superior accuracy. Third, we propose an
adaptive sparse training method to reduce communication and computation costs
without significant accuracy degradation. Extensive experimentation on four
public datasets and four models demonstrates the strength of AEDFL in terms of
accuracy (up to 16.3% higher), efficiency (up to 92.9% faster), and computation
costs (up to 42.3% lower).
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10937" title="Abstract">arXiv:2312.10937</a> [<a href="/pdf/2312.10937" title="Download PDF">pdf</a>, <a href="/format/2312.10937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extended Variational Mode Decomposition Algorithm Developed Speech  Emotion Recognition Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudd%2C+D+H">David Hason Rudd</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+H">Huan Huo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Knowledge Discovery and Data Mining. PAKDD 2023.
  Lecture Notes in Computer Science(), vol 13937. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Emotion recognition (ER) from speech signals is a robust approach since it
cannot be imitated like facial expression or text based sentiment analysis.
Valuable information underlying the emotions are significant for human-computer
interactions enabling intelligent machines to interact with sensitivity in the
real world. Previous ER studies through speech signal processing have focused
exclusively on associations between different signal mode decomposition methods
and hidden informative features. However, improper decomposition parameter
selections lead to informative signal component losses due to mode duplicating
and mixing. In contrast, the current study proposes VGG-optiVMD, an empowered
variational mode decomposition algorithm, to distinguish meaningful speech
features and automatically select the number of decomposed modes and optimum
balancing parameter for the data fidelity constraint by assessing their effects
on the VGG16 flattening output layer. Various feature vectors were employed to
train the VGG16 network on different databases and assess VGG-optiVMD
reproducibility and reliability. One, two, and three-dimensional feature
vectors were constructed by concatenating Mel-frequency cepstral coefficients,
Chromagram, Mel spectrograms, Tonnetz diagrams, and spectral centroids. Results
confirmed a synergistic relationship between the fine-tuning of the signal
sample rate and decomposition parameters with classification accuracy,
achieving state-of-the-art 96.09% accuracy in predicting seven emotions on the
Berlin EMO-DB database.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10941" title="Abstract">arXiv:2312.10941</a> [<a href="/pdf/2312.10941" title="Download PDF">pdf</a>, <a href="/ps/2312.10941" title="Download PostScript">ps</a>, <a href="/format/2312.10941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behaviour Description Database for AVs in Singapore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerra%2C+A+I+G">Ana Isabel Garcia Guerra</a>, 
<a href="/search/cs?searchtype=author&query=Shiuan%2C+T+S">Teng Sung Shiuan</a>, 
<a href="/search/cs?searchtype=author&query=Hibbard%2C+P">Paul Hibbard</a>, 
<a href="/search/cs?searchtype=author&query=Yew%2C+Y+J">Yap Jing Yew</a>, 
<a href="/search/cs?searchtype=author&query=Beng%2C+Y+T">Yeo Teck Beng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 69 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A Technical Reference for Autonomous Vehicles (AVs), with part 1 focusing on
basic behaviour guidelines (TR68-1) is published with the intent to be a
reference for evaluation of appropriated behaviour on Autonomous Vehicles for
Singapore. This is based on applicability from Basic Theory of Driving (BTD)
and Final Theory of Driving (FTD) which are the traffic code/rules for human
driving. This report contains a consolidation of current guidelines from
TR68-1, BTD and FTD. It will allow an initial identification of missing
guidelines for AV behaviour on roads; however, it is difficult to identify
conflicting rules or gaps in guidance without going into identified traffic
situations. Identified situations for analysis were chosen from Centre of
Excellence for Testing &amp; Research of Autonomous Vehicle (CETRAN) assessment
experience for further investigation. The outcome of the report proposes
additional behaviour characteristics and guidelines to situations identified to
close the gap between assessors and developers on expected AV behaviour. These
recommendations could improve current guidelines for AV behavioural in
assessment and generally for the local AV ecosystem for urban tropical roads in
Singapore. These recommendations could also serve as inputs for future TR 68-1
revisions where a sample set of reference situations can help to define clearer
expectations or requirements for AV behaviour in those situations. This will
help Singapore push forward in better definition of the expected AV behaviour
for AV systems.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10942" title="Abstract">arXiv:2312.10942</a> [<a href="/pdf/2312.10942" title="Download PDF">pdf</a>, <a href="/format/2312.10942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShuttleSHAP: A Turn-Based Feature Attribution Approach for Analyzing  Forecasting Models in Badminton
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Agent forecasting systems have been explored to investigate agent patterns
and improve decision-making in various domains, e.g., pedestrian predictions
and marketing bidding. Badminton represents a fascinating example of a
multifaceted turn-based sport, requiring both sophisticated tactic developments
and alternate-dependent decision-making. Recent deep learning approaches for
player tactic forecasting in badminton show promising performance partially
attributed to effective reasoning about rally-player interactions. However, a
critical obstacle lies in the unclear functionality of which features are
learned for simulating players' behaviors by black-box models, where existing
explainers are not equipped with turn-based and multi-output attributions. To
bridge this gap, we propose a turn-based feature attribution approach,
ShuttleSHAP, for analyzing forecasting models in badminton based on variants of
Shapley values. ShuttleSHAP is a model-agnostic explainer that aims to quantify
contribution by not only temporal aspects but also player aspects in terms of
multifaceted cues. Incorporating the proposed analysis tool into the
state-of-the-art turn-based forecasting model on the benchmark dataset reveals
that it is, in fact, insignificant to reason about past strokes, while
conventional sequential models have greater impacts. Instead, players' styles
influence the models for the future simulation of a rally. On top of that, we
investigate and discuss the causal analysis of these findings and demonstrate
the practicability with local analysis.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10943" title="Abstract">arXiv:2312.10943</a> [<a href="/pdf/2312.10943" title="Download PDF">pdf</a>, <a href="/format/2312.10943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Stealing Attack against Graph Classification with Authenticity,  Uncertainty and Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recent research demonstrates that GNNs are vulnerable to the model stealing
attack, a nefarious endeavor geared towards duplicating the target model via
query permissions. However, they mainly focus on node classification tasks,
neglecting the potential threats entailed within the domain of graph
classification tasks. Furthermore, their practicality is questionable due to
unreasonable assumptions, specifically concerning the large data requirements
and extensive model knowledge. To this end, we advocate following strict
settings with limited real data and hard-label awareness to generate synthetic
data, thereby facilitating the stealing of the target model. Specifically,
following important data generation principles, we introduce three model
stealing attacks to adapt to different actual scenarios: MSA-AU is inspired by
active learning and emphasizes the uncertainty to enhance query value of
generated samples; MSA-AD introduces diversity based on Mixup augmentation
strategy to alleviate the query inefficiency issue caused by over-similar
samples generated by MSA-AU; MSA-AUD combines the above two strategies to
seamlessly integrate the authenticity, uncertainty, and diversity of the
generated samples. Finally, extensive experiments consistently demonstrate the
superiority of the proposed methods in terms of concealment, query efficiency,
and stealing performance.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10944" title="Abstract">arXiv:2312.10944</a> [<a href="/pdf/2312.10944" title="Download PDF">pdf</a>, <a href="/ps/2312.10944" title="Download PostScript">ps</a>, <a href="/format/2312.10944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Whole-slide Image to Biomarker Prediction: A Protocol for  End-to-End Deep Learning in Computational Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/cs?searchtype=author&query=van+Treeck%2C+M">Marko van Treeck</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B6lflein%2C+G">Georg W&#xf6;lflein</a>, 
<a href="/search/cs?searchtype=author&query=Unger%2C+M">Michaela Unger</a>, 
<a href="/search/cs?searchtype=author&query=Ligero%2C+M">Marta Ligero</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+T">Tim Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S+J">Sophia J. Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Hewitt%2C+K+J">Katherine J. Hewitt</a>, 
<a href="/search/cs?searchtype=author&query=Khader%2C+F">Firas Khader</a>, 
<a href="/search/cs?searchtype=author&query=Foersch%2C+S">Sebastian Foersch</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob Nikolas Kather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hematoxylin- and eosin (H&amp;E) stained whole-slide images (WSIs) are the
foundation of diagnosis of cancer. In recent years, development of deep
learning-based methods in computational pathology enabled the prediction of
biomarkers directly from WSIs. However, accurately linking tissue phenotype to
biomarkers at scale remains a crucial challenge for democratizing complex
biomarkers in precision oncology. This protocol describes a practical workflow
for solid tumor associative modeling in pathology (STAMP), enabling prediction
of biomarkers directly from WSIs using deep learning. The STAMP workflow is
biomarker agnostic and allows for genetic- and clinicopathologic tabular data
to be included as an additional input, together with histopathology images. The
protocol consists of five main stages which have been successfully applied to
various research problems: formal problem definition, data preprocessing,
modeling, evaluation and clinical translation. The STAMP workflow
differentiates itself through its focus on serving as a collaborative framework
that can be used by clinicians and engineers alike for setting up research
projects in the field of computational pathology. As an example task, we
applied STAMP to the prediction of microsatellite instability (MSI) status in
colorectal cancer, showing accurate performance for the identification of
MSI-high tumors. Moreover, we provide an open-source codebase which has been
deployed at several hospitals across the globe to set up computational
pathology workflows. The STAMP workflow requires one workday of hands-on
computational execution and basic command line knowledge.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10945" title="Abstract">arXiv:2312.10945</a> [<a href="/pdf/2312.10945" title="Download PDF">pdf</a>, <a href="/format/2312.10945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaViP:Language-Grounded Visual Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunananthaseelan%2C+N">Nilakshan Kunananthaseelan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a language-grounded visual prompting method to adapt the visual
encoder of vision-language models for downstream tasks. By capitalizing on
language integration, we devise a parameter-efficient strategy to adjust the
input of the visual encoder, eliminating the need to modify or add to the
model's parameters. Due to this design choice, our algorithm can operate even
in black-box scenarios, showcasing adaptability in situations where access to
the model's parameters is constrained. We will empirically demonstrate that,
compared to prior art, grounding visual prompts with language enhances both the
accuracy and speed of adaptation. Moreover, our algorithm excels in
base-to-novel class generalization, overcoming limitations of visual prompting
and exhibiting the capacity to generalize beyond seen classes. We thoroughly
assess and evaluate our method across a variety of image recognition datasets,
such as EuroSAT, UCF101, DTD, and CLEVR, spanning different learning
situations, including few-shot learning, base-to-novel class generalization,
and transfer learning.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10946" title="Abstract">arXiv:2312.10946</a> [<a href="/pdf/2312.10946" title="Download PDF">pdf</a>, <a href="/format/2312.10946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Navigation Control of Cross-Domain Unmanned Systems via  Guiding Vector Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin-Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hai-Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jianing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chuanshang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Haosen Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published on IEEE Transactions on Control System Technology, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a distributed guiding-vector-field (DGVF) controller for
cross-domain unmanned systems (CDUSs) consisting of heterogeneous unmanned
aerial vehicles (UAVs) and unmanned surface vehicles (USVs), to achieve
coordinated navigation whereas maneuvering along their prescribed paths. In
particular, the DGVF controller provides a hierarchical architecture of an
upper-level heterogeneous guidance velocity controller and a lower-level signal
tracking regulator. Therein, the upper-level controller is to govern multiple
heterogeneous USVs and UAVs to approach and maneuver along the prescribed paths
and coordinate the formation simultaneously, whereas the low-level regulator is
to track the corresponding desired guidance signals provided by the upper-level
module. Significantly, the heterogeneous coordination among neighboring UAVs
and USVs is achieved merely by the lightweight communication of a scalar (i.e.,
the additional virtual coordinate), which substantially decreases the
communication and computational costs. Sufficient conditions assuring
asymptotical convergence of the closed-loop system are derived in presence of
the exponentially vanishing tracking errors. Finally, real-lake experiments are
conducted on a self-established cross-domain heterogeneous platform consisting
of three M-100 UAVs, two HUSTER-16 USVs, a HUSTER-12C USV, and a WiFi 5G
wireless communication station to verify the effectiveness of the present DGVF
controller.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10947" title="Abstract">arXiv:2312.10947</a> [<a href="/pdf/2312.10947" title="Download PDF">pdf</a>, <a href="/format/2312.10947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LabelCraft: Empowering Short Video Recommendations with Automated Label  Crafting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yimeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jianxin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+X">Xiaoxue Zang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yanan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Short video recommendations often face limitations due to the quality of user
feedback, which may not accurately depict user interests. To tackle this
challenge, a new task has emerged: generating more dependable labels from
original feedback. Existing label generation methods rely on manual rules,
demanding substantial human effort and potentially misaligning with the desired
objectives of the platform. To transcend these constraints, we introduce
LabelCraft, a novel automated label generation method explicitly optimizing
pivotal operational metrics for platform success. By formulating label
generation as a higher-level optimization problem above recommender model
optimization, LabelCraft introduces a trainable labeling model for automatic
label mechanism modeling. Through meta-learning techniques, LabelCraft
effectively addresses the bi-level optimization hurdle posed by the recommender
and labeling models, enabling the automatic acquisition of intricate label
generation mechanisms.Extensive experiments on real-world datasets corroborate
LabelCraft's excellence across varied operational metrics, encompassing usage
time, user engagement, and retention. Codes are available at
https://github.com/baiyimeng/LabelCraft.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10948" title="Abstract">arXiv:2312.10948</a> [<a href="/pdf/2312.10948" title="Download PDF">pdf</a>, <a href="/format/2312.10948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multimodal Approach for Advanced Pest Detection and Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinli Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Haoyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel multi modal deep learning framework for enhanced
agricultural pest detection, combining tiny-BERT's natural language processing
with R-CNN and ResNet-18's image processing. Addressing limitations of
traditional CNN-based visual methods, this approach integrates textual context
for more accurate pest identification. The R-CNN and ResNet-18 integration
tackles deep CNN issues like vanishing gradients, while tiny-BERT ensures
computational efficiency. Employing ensemble learning with linear regression
and random forest models, the framework demonstrates superior discriminate
ability, as shown in ROC and AUC analyses. This multi modal approach, blending
text and image data, significantly boosts pest detection in agriculture. The
study highlights the potential of multi modal deep learning in complex
real-world scenarios, suggesting future expansions in diversity of datasets,
advanced data augmentation, and cross-modal attention mechanisms to enhance
model performance.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10949" title="Abstract">arXiv:2312.10949</a> [<a href="/pdf/2312.10949" title="Download PDF">pdf</a>, <a href="/format/2312.10949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraged Mel spectrograms using Harmonic and Percussive Components in  Speech Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudd%2C+D+H">David Hason Rudd</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+H">Huan Huo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Knowledge Discovery and Data Mining. PAKDD 2022.
  Lecture Notes in Computer Science(), vol 13281. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech Emotion Recognition (SER) affective technology enables the intelligent
embedded devices to interact with sensitivity. Similarly, call centre employees
recognise customers' emotions from their pitch, energy, and tone of voice so as
to modify their speech for a high-quality interaction with customers. This work
explores, for the first time, the effects of the harmonic and percussive
components of Mel spectrograms in SER. We attempt to leverage the Mel
spectrogram by decomposing distinguishable acoustic features for exploitation
in our proposed architecture, which includes a novel feature map generator
algorithm, a CNN-based network feature extractor and a multi-layer perceptron
(MLP) classifier. This study specifically focuses on effective data
augmentation techniques for building an enriched hybrid-based feature map. This
process results in a function that outputs a 2D image so that it can be used as
input data for a pre-trained CNN-VGG16 feature extractor. Furthermore, we also
investigate other acoustic features such as MFCCs, chromagram, spectral
contrast, and the tonnetz to assess our proposed framework. A test accuracy of
92.79% on the Berlin EMO-DB database is achieved. Our result is higher than
previous works using CNN-VGG16.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10950" title="Abstract">arXiv:2312.10950</a> [<a href="/pdf/2312.10950" title="Download PDF">pdf</a>, <a href="/ps/2312.10950" title="Download PostScript">ps</a>, <a href="/format/2312.10950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Belief Propagation Decoding of Quantum LDPC Codes with Guided Decimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hanwen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Laban%2C+W+A">Waleed Abu Laban</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4ger%2C+C">Christian H&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Amat%2C+A+G+i">Alexandre Graell i Amat</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+H+D">Henry D. Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Quantum low-density parity-check (QLDPC) codes have emerged as a promising
technique for quantum error correction. A variety of decoders have been
proposed for QLDPC codes and many of them utilize belief propagation (BP)
decoding in some fashion. However, the use of BP decoding for degenerate QLDPC
codes is known to face issues with convergence. These issues are commonly
attributed to short cycles in the Tanner graph and multiple syndrome-matching
error patterns due to code degeneracy. Although various methods have been
proposed to mitigate the non-convergence issue, such as BP with ordered
statistics decoding (BP-OSD) and BP with stabilizer inactivation (BP-SI),
achieving better performance with lower complexity remains an active area of
research. In this work, we propose to decode QLDPC codes with BP guided
decimation (BPGD), which has been previously studied for constraint
satisfaction and lossy compression problems. The decimation process is
applicable to both binary BP and quaternary BP and involves sequentially
freezing the value of the most reliable qubits to encourage BP convergence.
Despite its simplicity, we find that BPGD significantly reduces BP failures due
to non-convergence while maintaining a low probability of error given
convergence, achieving performance on par with BP-OSD and BP-SI. To better
understand how and why BPGD improves performance, we discuss several
interpretations of BPGD and their connection to BP syndrome decoding.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10951" title="Abstract">arXiv:2312.10951</a> [<a href="/pdf/2312.10951" title="Download PDF">pdf</a>, <a href="/ps/2312.10951" title="Download PostScript">ps</a>, <a href="/format/2312.10951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viral Privacy: Contextual Integrity as a Lens to Understand Content  Creators&#x27; Privacy Perceptions and Needs After Sudden Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schafer%2C+J+S">Joseph S. Schafer</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+A">Annie Denton</a>, 
<a href="/search/cs?searchtype=author&query=Seelhoff%2C+C">Chloe Seelhoff</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+J">Jordyn Vo</a>, 
<a href="/search/cs?searchtype=author&query=Starbird%2C+K">Kate Starbird</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, presented at the "Multi-Stakeholder Privacy and Safety on Content Creation Platforms" workshop at the ACM DIS 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">When designing multi-stakeholder privacy systems, it is important to consider
how different groups of social media users have different goals and
requirements for privacy. Additionally, we must acknowledge that it is
important to keep in mind that even a single creator's needs can change as
their online visibility and presence shifts, and that robust multi-stakeholder
privacy systems should account for these shifts. Using the framework of
contextual integrity, we explain a theoretical basis for how to evaluate the
potential changing privacy needs of users as their profiles undergo a sudden
rise in online attention, and ongoing projects to understand these potential
shifts in perspectives.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10952" title="Abstract">arXiv:2312.10952</a> [<a href="/pdf/2312.10952" title="Download PDF">pdf</a>, <a href="/format/2312.10952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Alignment of Modality Space for End-to-end Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+K">Kaiqi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingbo Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">End-to-end Speech Translation (ST) aims to convert speech into target text
within a unified model. The inherent differences between speech and text
modalities often impede effective cross-modal and cross-lingual transfer.
Existing methods typically employ hard alignment (H-Align) of individual speech
and text segments, which can degrade textual representations. To address this,
we introduce Soft Alignment (S-Align), using adversarial training to align the
representation spaces of both modalities. S-Align creates a modality-invariant
space while preserving individual modality quality. Experiments on three
languages from the MuST-C dataset show S-Align outperforms H-Align across
multiple tasks and offers translation capabilities on par with specialized
translation models.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10953" title="Abstract">arXiv:2312.10953</a> [<a href="/pdf/2312.10953" title="Download PDF">pdf</a>, <a href="/format/2312.10953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric Stochastic Analysis of Dynamic Frequency in Power Systems:  A Generalized Ito Process Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wan%2C+C">Can Wan</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Y">Yupeng Ren</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+P">Ping Ju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The large-scale integration of intermittent renewable energy has brought
serious challenges to the frequency security of power systems. In this paper, a
novel nonparametric stochastic analysis method of system dynamic frequency is
proposed to accurately analyze the impact of renewable energy uncertainty on
power system frequency security, independent of any parametric distribution
assumption. The nonparametric uncertainty of renewable generation disturbance
is quantified based on probabilistic forecasting. Then, a novel generalized Ito
process is proposed as a linear combination of several Gaussian Ito processes,
which can represent any probability distribution. Furthermore, a stochastic
model of power system frequency response is constructed by considering virtual
synchronization control of wind power. On basis of generalized Ito process, the
complex nonlinear stochastic differential equation is transformed into a linear
combination of several linear stochastic differential equations to approximate
nonparametric probability distribution of the system dynamic frequency.
Finally, the validity of the proposed method is verified by the single-machine
system and IEEE 39-Bus system.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10959" title="Abstract">arXiv:2312.10959</a> [<a href="/pdf/2312.10959" title="Download PDF">pdf</a>, <a href="/format/2312.10959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker Mask Transformer for Multi-talker Overlapped Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+P">Peng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xugang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kawai%2C+H">Hisashi Kawai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multi-talker overlapped speech recognition remains a significant challenge,
requiring not only speech recognition but also speaker diarization tasks to be
addressed. In this paper, to better address these tasks, we first introduce
speaker labels into an autoregressive transformer-based speech recognition
model to support multi-speaker overlapped speech recognition. Then, to improve
speaker diarization, we propose a novel speaker mask branch to detection the
speech segments of individual speakers. With the proposed model, we can perform
both speech recognition and speaker diarization tasks simultaneously using a
single model. Experimental results on the LibriSpeech-based overlapped dataset
demonstrate the effectiveness of the proposed method in both speech recognition
and speaker diarization tasks, particularly enhancing the accuracy of speaker
diarization in relatively complex multi-talker scenarios.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10960" title="Abstract">arXiv:2312.10960</a> [<a href="/pdf/2312.10960" title="Download PDF">pdf</a>, <a href="/format/2312.10960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Detailed Text-to-Motion Synthesis via Basic-to-Advanced  Hierarchical Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xuehao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-guided motion synthesis aims to generate 3D human motion that not only
precisely reflects the textual description but reveals the motion details as
much as possible. Pioneering methods explore the diffusion model for
text-to-motion synthesis and obtain significant superiority. However, these
methods conduct diffusion processes either on the raw data distribution or the
low-dimensional latent space, which typically suffer from the problem of
modality inconsistency or detail-scarce. To tackle this problem, we propose a
novel Basic-to-Advanced Hierarchical Diffusion Model, named B2A-HDM, to
collaboratively exploit low-dimensional and high-dimensional diffusion models
for high quality detailed motion synthesis. Specifically, the basic diffusion
model in low-dimensional latent space provides the intermediate denoising
result that to be consistent with the textual description, while the advanced
diffusion model in high-dimensional latent space focuses on the following
detail-enhancing denoising process. Besides, we introduce a multi-denoiser
framework for the advanced diffusion model to ease the learning of
high-dimensional model and fully explore the generative potential of the
diffusion model. Quantitative and qualitative experiment results on two
text-to-motion benchmarks (HumanML3D and KIT-ML) demonstrate that B2A-HDM can
outperform existing state-of-the-art methods in terms of fidelity, modality
consistency, and diversity.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10961" title="Abstract">arXiv:2312.10961</a> [<a href="/pdf/2312.10961" title="Download PDF">pdf</a>, <a href="/format/2312.10961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspect-Based Sentiment Analysis with Explicit Sentiment Augmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jihong Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Silong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yimeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Ximing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect-based sentiment analysis (ABSA), a fine-grained sentiment
classification task, has received much attention recently. Many works
investigate sentiment information through opinion words, such as ''good'' and
''bad''. However, implicit sentiment widely exists in the ABSA dataset, which
refers to the sentence containing no distinct opinion words but still expresses
sentiment to the aspect term. To deal with implicit sentiment, this paper
proposes an ABSA method that integrates explicit sentiment augmentations. And
we propose an ABSA-specific augmentation method to create such augmentations.
Specifically, we post-trains T5 by rule-based data. We employ Syntax Distance
Weighting and Unlikelihood Contrastive Regularization in the training procedure
to guide the model to generate an explicit sentiment. Meanwhile, we utilize the
Constrained Beam Search to ensure the augmentation sentence contains the aspect
terms. We test ABSA-ESA on two of the most popular benchmarks of ABSA. The
results show that ABSA-ESA outperforms the SOTA baselines on implicit and
explicit sentiment accuracy.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10964" title="Abstract">arXiv:2312.10964</a> [<a href="/pdf/2312.10964" title="Download PDF">pdf</a>, <a href="/format/2312.10964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative linguistic representation for spoken language identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+P">Peng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xuguang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kawai%2C+H">Hisashi Kawai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Effective extraction and application of linguistic features are central to
the enhancement of spoken Language IDentification (LID) performance. With the
success of recent large models, such as GPT and Whisper, the potential to
leverage such pre-trained models for extracting linguistic features for LID
tasks has become a promising area of research. In this paper, we explore the
utilization of the decoder-based network from the Whisper model to extract
linguistic features through its generative mechanism for improving the
classification accuracy in LID tasks. We devised two strategies - one based on
the language embedding method and the other focusing on direct optimization of
LID outputs while simultaneously enhancing the speech recognition tasks. We
conducted experiments on the large-scale multilingual datasets MLS,
VoxLingua107, and CommonVoice to test our approach. The experimental results
demonstrated the effectiveness of the proposed method on both in-domain and
out-of-domain datasets for LID tasks.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10967" title="Abstract">arXiv:2312.10967</a> [<a href="/pdf/2312.10967" title="Download PDF">pdf</a>, <a href="/format/2312.10967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs and Pre-trained Language Models enhanced Representation  Learning for Conversational Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhangchi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Ye Tao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+A+W">Alan Wee-Chung Liew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Conversational recommender systems (CRS) utilize natural language
interactions and dialogue history to infer user preferences and provide
accurate recommendations. Due to the limited conversation context and
background knowledge, existing CRSs rely on external sources such as knowledge
graphs to enrich the context and model entities based on their inter-relations.
However, these methods ignore the rich intrinsic information within entities.
To address this, we introduce the Knowledge-Enhanced Entity Representation
Learning (KERL) framework, which leverages both the knowledge graph and a
pre-trained language model to improve the semantic understanding of entities
for CRS. In our KERL framework, entity textual descriptions are encoded via a
pre-trained language model, while a knowledge graph helps reinforce the
representation of these entities. We also employ positional encoding to
effectively capture the temporal information of entities in a conversation. The
enhanced entity representation is then used to develop a recommender component
that fuses both entity and contextual representations for more informed
recommendations, as well as a dialogue component that generates informative
entity-related information in the response text. A high-quality knowledge graph
with aligned entity descriptions is constructed to facilitate our study, namely
the Wiki Movie Knowledge Graph (WikiMKG). The experimental results show that
KERL achieves state-of-the-art results in both recommendation and response
generation tasks.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10968" title="Abstract">arXiv:2312.10968</a> [<a href="/pdf/2312.10968" title="Download PDF">pdf</a>, <a href="/format/2312.10968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARs: Predicate-based Association Rules for Efficient and Accurate  Model-Agnostic Anomaly Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Cheng Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">While new and effective methods for anomaly detection are frequently
introduced, many studies prioritize the detection task without considering the
need for explainability. Yet, in real-world applications, anomaly explanation,
which aims to provide explanation of why specific data instances are identified
as anomalies, is an equally important task. In this work, we present a novel
approach for efficient and accurate model-agnostic anomaly explanation for
tabular data using Predicate-based Association Rules (PARs). PARs can provide
intuitive explanations not only about which features of the anomaly instance
are abnormal, but also the reasons behind their abnormality. Our user study
indicates that the anomaly explanation form of PARs is better comprehended and
preferred by regular users of anomaly detection systems as compared to existing
model-agnostic explanation options. Furthermore, we conduct extensive
experiments on various benchmark datasets, demonstrating that PARs compare
favorably to state-of-the-art model-agnostic methods in terms of computing
efficiency and explanation accuracy on anomaly explanation tasks. The code for
PARs tool is available at https://github.com/NSIBF/PARs-EXAD.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10975" title="Abstract">arXiv:2312.10975</a> [<a href="/pdf/2312.10975" title="Download PDF">pdf</a>, <a href="/format/2312.10975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inducing Point Operator Transformer: A Flexible and Scalable  Architecture for Solving PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Taeil Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Solving partial differential equations (PDEs) by learning the solution
operators has emerged as an attractive alternative to traditional numerical
methods. However, implementing such architectures presents two main challenges:
flexibility in handling irregular and arbitrary input and output formats and
scalability to large discretizations. Most existing architectures are limited
by their desired structure or infeasible to scale large inputs and outputs. To
address these issues, we introduce an attention-based model called an
inducing-point operator transformer (IPOT). Inspired by inducing points
methods, IPOT is designed to handle any input function and output query while
capturing global interactions in a computationally efficient way. By detaching
the inputs/outputs discretizations from the processor with a smaller latent
bottleneck, IPOT offers flexibility in processing arbitrary discretizations and
scales linearly with the size of inputs/outputs. Our experimental results
demonstrate that IPOT achieves strong performances with manageable
computational complexity on an extensive range of PDE benchmarks and real-world
weather forecasting scenarios, compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10977" title="Abstract">arXiv:2312.10977</a> [<a href="/pdf/2312.10977" title="Download PDF">pdf</a>, <a href="/format/2312.10977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predict and Interpret Health Risk using EHR through Typical Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaohe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liantao Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting health risks from electronic health records (EHR) is a topic of
recent interest. Deep learning models have achieved success by modeling
temporal and feature interaction. However, these methods learn insufficient
representations and lead to poor performance when it comes to patients with few
visits or sparse records. Inspired by the fact that doctors may compare the
patient with typical patients and make decisions from similar cases, we propose
a Progressive Prototypical Network (PPN) to select typical patients as
prototypes and utilize their information to enhance the representation of the
given patient. In particular, a progressive prototype memory and two prototype
separation losses are proposed to update prototypes. Besides, a novel
integration is introduced for better fusing information from patients and
prototypes. Experiments on three real-world datasets demonstrate that our model
brings improvement on all metrics. To make our results better understood by
physicians, we developed an application at <a href="http://ppn.ai-care.top.">this http URL</a> Our code is
released at https://github.com/yzhHoward/PPN.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10979" title="Abstract">arXiv:2312.10979</a> [<a href="/pdf/2312.10979" title="Download PDF">pdf</a>, <a href="/ps/2312.10979" title="Download PostScript">ps</a>, <a href="/format/2312.10979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3S-TSE: Efficient Three-Stage Target Speaker Extraction for Real-Time  and Low-Resource Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shulin He</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+J">Jinjiang liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Target speaker extraction (TSE) aims to isolate a specific voice from
multiple mixed speakers relying on a registerd sample. Since voiceprint
features usually vary greatly, current end-to-end neural networks require large
model parameters which are computational intensive and impractical for
real-time applications, espetially on resource-constrained platforms. In this
paper, we address the TSE task using microphone array and introduce a novel
three-stage solution that systematically decouples the process: First, a neural
network is trained to estimate the direction of the target speaker. Second,
with the direction determined, the Generalized Sidelobe Canceller (GSC) is used
to extract the target speech. Third, an Inplace Convolutional Recurrent Neural
Network (ICRN) acts as a denoising post-processor, refining the GSC output to
yield the final separated speech. Our approach delivers superior performance
while drastically reducing computational load, setting a new standard for
efficient real-time target speaker extraction.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10980" title="Abstract">arXiv:2312.10980</a> [<a href="/pdf/2312.10980" title="Download PDF">pdf</a>, <a href="/format/2312.10980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liquid Leak Detection Using Thermal Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansod%2C+K">Kalpak Bansod</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yanshan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+Y">Yugesh Rai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">This paper presents a comprehensive solution to address the critical
challenge of liquid leaks in the oil and gas industry, leveraging advanced
computer vision and deep learning methodologies. Employing You Only Look Once
(YOLO) and Real-Time Detection Transformer (RT DETR) models, our project
focuses on enhancing early identification of liquid leaks in key infrastructure
components such as pipelines, pumps, and tanks. Through the integration of
surveillance thermal cameras and sensors, the combined YOLO and RT DETR models
demonstrate remarkable efficacy in the continuous monitoring and analysis of
visual data within oil and gas facilities. YOLO's real-time object detection
capabilities swiftly recognize leaks and their patterns, while RT DETR excels
in discerning specific leak-related features, particularly in thermal images.
This approach significantly improves the accuracy and speed of leak detection,
ultimately mitigating environmental and financial risks associated with liquid
leaks.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10982" title="Abstract">arXiv:2312.10982</a> [<a href="/pdf/2312.10982" title="Download PDF">pdf</a>, <a href="/ps/2312.10982" title="Download PostScript">ps</a>, <a href="/format/2312.10982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Attack Techniques, Implementation, and  Mitigation Strategies in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmradi%2C+A">Aysan Esmradi</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+D+W">Daniel Wankit Yip</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+F">Chun Fai Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to be published in the Proceedings of the 3rd International Conference on Ubiquitous Security 2023 (UbiSec-2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Ensuring the security of large language models (LLMs) is an ongoing challenge
despite their widespread popularity. Developers work to enhance LLMs security,
but vulnerabilities persist, even in advanced versions like GPT-4. Attackers
exploit these weaknesses, highlighting the need for proactive cybersecurity
measures in AI model development. This article explores two attack categories:
attacks on models themselves and attacks on model applications. The former
requires expertise, access to model data, and significant implementation time,
while the latter is more accessible to attackers and has seen increased
attention. Our study reviews over 100 recent research works, providing an
in-depth analysis of each attack type. We identify the latest attack methods
and explore various approaches to carry them out. We thoroughly investigate
mitigation techniques, assessing their effectiveness and limitations.
Furthermore, we summarize future defenses against these attacks. We also
examine real-world techniques, including reported and our implemented attacks
on LLMs, to consolidate our findings. Our research highlights the urgency of
addressing security concerns and aims to enhance the understanding of LLM
attacks, contributing to robust defense development in this evolving domain.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10983" title="Abstract">arXiv:2312.10983</a> [<a href="/pdf/2312.10983" title="Download PDF">pdf</a>, <a href="/format/2312.10983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatchDet: A Collaborative Framework for Image Matching and Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jinxiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bin-Bin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jiawei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+C">Congchong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image matching and object detection are two fundamental and challenging
tasks, while many related applications consider them two individual tasks (i.e.
task-individual). In this paper, a collaborative framework called MatchDet
(i.e. task-collaborative) is proposed for image matching and object detection
to obtain mutual improvements. To achieve the collaborative learning of the two
tasks, we propose three novel modules, including a Weighted Spatial Attention
Module (WSAM) for Detector, and Weighted Attention Module (WAM) and Box Filter
for Matcher. Specifically, the WSAM highlights the foreground regions of target
image to benefit the subsequent detector, the WAM enhances the connection
between the foreground regions of pair images to ensure high-quality matches,
and Box Filter mitigates the impact of false matches. We evaluate the
approaches on a new benchmark with two datasets called Warp-COCO and
miniScanNet. Experimental results show our approaches are effective and achieve
competitive improvements.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10984" title="Abstract">arXiv:2312.10984</a> [<a href="/pdf/2312.10984" title="Download PDF">pdf</a>, <a href="/format/2312.10984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Financial Literacy via Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudd%2C+D+H">David Hason Rudd</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+H">Huan Huo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Artificial Intelligence. AI 2022. Lecture Notes in
  Computer Science(), vol 13151. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY); Econometrics (econ.EM)

</div>
<p class="mathjax">Financial literacy (FL) represents a person's ability to turn assets into
income, and understanding digital currencies has been added to the modern
definition. FL can be predicted by exploiting unlabelled recorded data in
financial networks via semi-supervised learning (SSL). Measuring and predicting
FL has not been widely studied, resulting in limited understanding of customer
financial engagement consequences. Previous studies have shown that low FL
increases the risk of social harm. Therefore, it is important to accurately
estimate FL to allocate specific intervention programs to less financially
literate groups. This will not only increase company profitability, but will
also reduce government spending. Some studies considered predicting FL in
classification tasks, whereas others developed FL definitions and impacts. The
current paper investigated mechanisms to learn customer FL level from their
financial data using sampling by synthetic minority over-sampling techniques
for regression with Gaussian noise (SMOGN). We propose the SMOGN-COREG model
for semi-supervised regression, applying SMOGN to deal with unbalanced datasets
and a nonparametric multi-learner co-regression (COREG) algorithm for labeling.
We compared the SMOGN-COREG model with six well-known regressors on five
datasets to evaluate the proposed models effectiveness on unbalanced and
unlabelled financial data. Experimental results confirmed that the proposed
method outperformed the comparator models for unbalanced and unlabelled
financial data. Therefore, SMOGN-COREG is a step towards using unlabelled data
to estimate FL level.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10986" title="Abstract">arXiv:2312.10986</a> [<a href="/pdf/2312.10986" title="Download PDF">pdf</a>, <a href="/format/2312.10986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Tailed 3D Detection via 2D Late Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yechi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peri%2C+N">Neehar Peri</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuoquan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wei Hua</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous vehicles (AVs) must accurately detect objects from both common and
rare classes for safe navigation, motivating the problem of Long-Tailed 3D
Object Detection (LT3D). Contemporary LiDAR-based 3D detectors perform poorly
on rare classes (e.g., CenterPoint only achieves 5.1 AP on stroller) as it is
difficult to recognize objects from sparse LiDAR points alone. RGB images
provide visual evidence to help resolve such ambiguities, motivating the study
of RGB-LiDAR fusion. In this paper, we delve into a simple late-fusion
framework that ensembles independently trained RGB and LiDAR detectors. Unlike
recent end-to-end methods which require paired multi-modal training data, our
late-fusion approach can easily leverage large-scale uni-modal datasets,
significantly improving rare class detection.In particular, we examine three
critical components in this late-fusion framework from first principles,
including whether to train 2D or 3D RGB detectors, whether to match RGB and
LiDAR detections in 3D or the projected 2D image plane, and how to fuse matched
detections.Extensive experiments reveal that 2D RGB detectors achieve better
recognition accuracy than 3D RGB detectors, matching on the 2D image plane
mitigates depth estimation errors, and fusing scores probabilistically with
calibration leads to state-of-the-art LT3D performance. Our late-fusion
approach achieves 51.4 mAP on the established nuScenes LT3D benchmark,
improving over prior work by 5.9 mAP.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10987" title="Abstract">arXiv:2312.10987</a> [<a href="/pdf/2312.10987" title="Download PDF">pdf</a>, <a href="/format/2312.10987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Contamination Issues in Brain-to-Text Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Congchi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhiwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jie He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Changping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Piji Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Decoding non-invasive cognitive signals to natural language has long been the
goal of building practical brain-computer interfaces (BCIs). Recent major
milestones have successfully decoded cognitive signals like functional Magnetic
Resonance Imaging (fMRI) and electroencephalogram (EEG) into text under open
vocabulary setting. However, how to split the datasets for training,
validating, and testing in cognitive signal decoding task still remains
controversial. In this paper, we conduct systematic analysis on current dataset
splitting methods and find the existence of data contamination largely
exaggerates model performance. Specifically, first we find the leakage of test
subjects' cognitive signals corrupts the training of a robust encoder. Second,
we prove the leakage of text stimuli causes the auto-regressive decoder to
memorize information in test set. The decoder generates highly accurate text
not because it truly understands cognitive signals. To eliminate the influence
of data contamination and fairly evaluate different models' generalization
ability, we propose a new splitting method for different types of cognitive
datasets (e.g. fMRI, EEG). We also test the performance of SOTA Brain-to-Text
decoding models under the proposed dataset splitting paradigm as baselines for
further research.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10988" title="Abstract">arXiv:2312.10988</a> [<a href="/pdf/2312.10988" title="Download PDF">pdf</a>, <a href="/format/2312.10988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Invariant Learning with Subgraph Co-mixup for Out-Of-Distribution  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+T">Tianrui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+T">Tao Tao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Has been accepted at the 38th AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have been demonstrated to perform well in graph
representation learning, but always lacking in generalization capability when
tackling out-of-distribution (OOD) data. Graph invariant learning methods,
backed by the invariance principle among defined multiple environments, have
shown effectiveness in dealing with this issue. However, existing methods
heavily rely on well-predefined or accurately generated environment partitions,
which are hard to be obtained in practice, leading to sub-optimal OOD
generalization performances. In this paper, we propose a novel graph invariant
learning method based on invariant and variant patterns co-mixup strategy,
which is capable of jointly generating mixed multiple environments and
capturing invariant patterns from the mixed graph data. Specifically, we first
adopt a subgraph extractor to identify invariant subgraphs. Subsequently, we
design one novel co-mixup strategy, i.e., jointly conducting environment Mixup
and invariant Mixup. For the environment Mixup, we mix the variant
environment-related subgraphs so as to generate sufficiently diverse multiple
environments, which is important to guarantee the quality of the graph
invariant learning. For the invariant Mixup, we mix the invariant subgraphs,
further encouraging to capture invariant patterns behind graphs while getting
rid of spurious correlations for OOD generalization. We demonstrate that the
proposed environment Mixup and invariant Mixup can mutually promote each other.
Extensive experiments on both synthetic and real-world datasets demonstrate
that our method significantly outperforms state-of-the-art under various
distribution shifts.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10989" title="Abstract">arXiv:2312.10989</a> [<a href="/pdf/2312.10989" title="Download PDF">pdf</a>, <a href="/format/2312.10989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Localization in Dynamic Networks via Complex Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lihua Xie</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaolei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Different from most existing distributed localization approaches in static
networks where the agents in a network are static, this paper addresses the
distributed localization problem in dynamic networks where the positions of the
agents are time-varying. Firstly, complex constraints for the positions of the
agents are constructed based on local relative position (distance and local
bearing) measurements. Secondly, both algebraic condition and graph condition
of network localizability in dynamic networks are given. Thirdly, a distributed
localization protocol is proposed such that all the agents can cooperatively
find their positions by solving the complex constraints in dynamic networks.
Fourthly, the proposed method is extended to address the problem of integrated
distributed localization and formation control. It is worth mentioning that the
proposed algorithm can also be applied in the case that only distance and sign
of direction measurements are available, where the sign of direction
measurement is a kind of one bit local relative measurement and has less
information than local bearing.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10992" title="Abstract">arXiv:2312.10992</a> [<a href="/pdf/2312.10992" title="Download PDF">pdf</a>, <a href="/ps/2312.10992" title="Download PostScript">ps</a>, <a href="/format/2312.10992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Intelligent Framework for Maximising SAG Mill Throughput: An  Integration of Expert Knowledge, Machine Learning and Evolutionary Algorithms  for Parameter Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>, 
<a href="/search/eess?searchtype=author&query=Neshat%2C+M">Mehdi Neshat</a>, 
<a href="/search/eess?searchtype=author&query=Aldrich%2C+C">Chris Aldrich</a>, 
<a href="/search/eess?searchtype=author&query=Karageorgos%2C+J">John Karageorgos</a>, 
<a href="/search/eess?searchtype=author&query=Zanin%2C+M">Max Zanin</a>, 
<a href="/search/eess?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In mineral processing plants, grinding is a crucial step, accounting for
approximately 50 percent of the total mineral processing costs. Semi-autogenous
grinding mills are extensively employed in the grinding circuit of mineral
processing plants. Maximizing SAG mill throughput is of significant importance
considering its profound financial outcomes. However, the optimum process
parameter setting aimed at achieving maximum mill throughput remains an
uninvestigated domain in prior research. This study introduces a hybrid
intelligent framework leveraging expert knowledge, machine learning techniques,
and evolutionary algorithms to address this research need. In this study, we
utilize an extensive industrial dataset comprising 36743 records and select
relevant features based on the insights of industry experts. Following the
removal of erroneous data, a comprehensive evaluation of 17 diverse machine
learning models is undertaken to identify the most accurate predictive model.
To improve the model performance, feature selection and outlier detection are
executed. The resultant optimal model, trained with refined features, serves as
the objective function within three distinct evolutionary algorithms. These
algorithms are employed to identify parameter configurations that maximize SAG
mill throughput while adhering to the working limits of input parameters as
constraints. Notably, our analysis revealed that CatBoost, as an ensemble
model, stands out as the most accurate predictor. Furthermore, differential
evolution emerges as the preferred optimization algorithm, exhibiting superior
performance in both achieving the highest mill throughput predictions and
ensuring robustness in predictions, surpassing alternative methods.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10993" title="Abstract">arXiv:2312.10993</a> [<a href="/pdf/2312.10993" title="Download PDF">pdf</a>, <a href="/format/2312.10993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic Human Motion Generation with Cross-Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zeping Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoli Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the Cross Human Motion Diffusion Model (CrossDiff), a novel
approach for generating high-quality human motion based on textual
descriptions. Our method integrates 3D and 2D information using a shared
transformer network within the training of the diffusion model, unifying motion
noise into a single feature space. This enables cross-decoding of features into
both 3D and 2D motion representations, regardless of their original dimension.
The primary advantage of CrossDiff is its cross-diffusion mechanism, which
allows the model to reverse either 2D or 3D noise into clean motion during
training. This capability leverages the complementary information in both
motion representations, capturing intricate human movement details often missed
by models relying solely on 3D information. Consequently, CrossDiff effectively
combines the strengths of both representations to generate more realistic
motion sequences. In our experiments, our model demonstrates competitive
state-of-the-art performance on text-to-motion benchmarks. Moreover, our method
consistently provides enhanced motion generation quality, capturing complex
full-body movement intricacies. Additionally, with a pretrained model,our
approach accommodates using in the wild 2D motion data without 3D motion ground
truth during training to generate 3D motion, highlighting its potential for
broader applications and efficient use of available data resources. Project
page: https://wonderno.github.io/CrossDiff-webpage/.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10997" title="Abstract">arXiv:2312.10997</a> [<a href="/pdf/2312.10997" title="Download PDF">pdf</a>, <a href="/format/2312.10997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Generation for Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunfan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kangxiang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinliu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Y">Yuxi Bi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate powerful capabilities, but they
still face challenges in practical applications, such as hallucinations, slow
knowledge updates, and lack of transparency in answers. Retrieval-Augmented
Generation (RAG) refers to the retrieval of relevant information from external
knowledge bases before answering questions with LLMs. RAG has been demonstrated
to significantly enhance answer accuracy, reduce model hallucination,
particularly for knowledge-intensive tasks. By citing sources, users can verify
the accuracy of answers and increase trust in model outputs. It also
facilitates knowledge updates and the introduction of domain-specific
knowledge. RAG effectively combines the parameterized knowledge of LLMs with
non-parameterized external knowledge bases, making it one of the most important
methods for implementing large language models. This paper outlines the
development paradigms of RAG in the era of LLMs, summarizing three paradigms:
Naive RAG, Advanced RAG, and Modular RAG. It then provides a summary and
organization of the three main components of RAG: retriever, generator, and
augmentation methods, along with key technologies in each component.
Furthermore, it discusses how to evaluate the effectiveness of RAG models,
introducing two evaluation methods for RAG, emphasizing key metrics and
abilities for evaluation, and presenting the latest automatic evaluation
framework. Finally, potential future research directions are introduced from
three aspects: vertical optimization, horizontal scalability, and the technical
stack and ecosystem of RAG.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10998" title="Abstract">arXiv:2312.10998</a> [<a href="/pdf/2312.10998" title="Download PDF">pdf</a>, <a href="/format/2312.10998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID-Blau: Image Deblurring by Implicit Diffusion-based reBLurring  AUgmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jia-Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+F">Fu-Jen Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Chung-Chi Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chia-Wen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yen-Yu Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image deblurring aims to remove undesired blurs from an image captured in a
dynamic scene. Much research has been dedicated to improving deblurring
performance through model architectural designs. However, there is little work
on data augmentation for image deblurring. Since continuous motion causes
blurred artifacts during image exposure, we aspire to develop a groundbreaking
blur augmentation method to generate diverse blurred images by simulating
motion trajectories in a continuous space. This paper proposes Implicit
Diffusion-based reBLurring AUgmentation (ID-Blau), utilizing a sharp image
paired with a controllable blur condition map to produce a corresponding
blurred image. We parameterize the blur patterns of a blurred image with their
orientations and magnitudes as a pixel-wise blur condition map to simulate
motion trajectories and implicitly represent them in a continuous space. By
sampling diverse blur conditions, ID-Blau can generate various blurred images
unseen in the training set. Experimental results demonstrate that ID-Blau can
produce realistic blurred images for training and thus significantly improve
performance for state-of-the-art deblurring models.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10999" title="Abstract">arXiv:2312.10999</a> [<a href="/pdf/2312.10999" title="Download PDF">pdf</a>, <a href="/format/2312.10999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Self-Reducible Samplers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+R">Rishiraj Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sourav Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Pote%2C+Y">Yash Pote</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+U">Uddalok Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sayantan Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 38th AAAI Conference on Artificial Intelligence (AAAI-24); Abstract shortened to meet with arxiv criteria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Samplers are the backbone of the implementations of any randomised algorithm.
Unfortunately, obtaining an efficient algorithm to test the correctness of
samplers is very hard to find. Recently, in a series of works, testers like
$\mathsf{Barbarik}$, $\mathsf{Teq}$, $\mathsf{Flash}$ for testing of some
particular kinds of samplers, like CNF-samplers and Horn-samplers, were
obtained. But their techniques have a significant limitation because one can
not expect to use their methods to test for other samplers, such as perfect
matching samplers or samplers for sampling linear extensions in posets. In this
paper, we present a new testing algorithm that works for such samplers and can
estimate the distance of a new sampler from a known sampler (say, uniform
sampler). Testing the identity of distributions is the heart of testing the
correctness of samplers. This paper's main technical contribution is developing
a new distance estimation algorithm for distributions over high-dimensional
cubes using the recently proposed sub-cube conditioning sampling model. Given
subcube conditioning access to an unknown distribution $P$, and a known
distribution $Q$ defined over $\{0,1\}^n$, our algorithm
$\mathsf{CubeProbeEst}$ estimates the variation distance between $P$ and $Q$
within additive error $\zeta$ using $O\left({n^2}/{\zeta^4}\right)$ subcube
conditional samples from $P$. Following the testing-via-learning paradigm, we
also get a tester which distinguishes between the cases when $P$ and $Q$ are
$\varepsilon$-close or $\eta$-far in variation distance with probability at
least $0.99$ using $O({n^2}/{(\eta-\varepsilon)^4})$ subcube conditional
samples. The estimation algorithm in the sub-cube conditioning sampling model
helps us to design the first tester for self-reducible samplers.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11001" title="Abstract">arXiv:2312.11001</a> [<a href="/pdf/2312.11001" title="Download PDF">pdf</a>, <a href="/format/2312.11001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Versatile Causal Discovery Framework to Allow Causally-Related Hidden  Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xinshuai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+I">Ignavier Ng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiangchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yujia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Songyao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Legaspi%2C+R">Roberto Legaspi</a>, 
<a href="/search/cs?searchtype=author&query=Spirtes%2C+P">Peter Spirtes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Most existing causal discovery methods rely on the assumption of no latent
confounders, limiting their applicability in solving real-life problems. In
this paper, we introduce a novel, versatile framework for causal discovery that
accommodates the presence of causally-related hidden variables almost
everywhere in the causal network (for instance, they can be effects of observed
variables), based on rank information of covariance matrix over observed
variables. We start by investigating the efficacy of rank in comparison to
conditional independence and, theoretically, establish necessary and sufficient
conditions for the identifiability of certain latent structural patterns.
Furthermore, we develop a Rank-based Latent Causal Discovery algorithm, RLCD,
that can efficiently locate hidden variables, determine their cardinalities,
and discover the entire causal structure over both measured and hidden ones. We
also show that, under certain graphical conditions, RLCD correctly identifies
the Markov Equivalence Class of the whole latent causal graph asymptotically.
Experimental results on both synthetic and real-world personality data sets
demonstrate the efficacy of the proposed approach in finite-sample cases.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11005" title="Abstract">arXiv:2312.11005</a> [<a href="/pdf/2312.11005" title="Download PDF">pdf</a>, <a href="/format/2312.11005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Benefits of Rate-Adaptive Transceivers: A Network Planning Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Jasper M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Di+Rosa%2C+G">Gabriele Di Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Fehenberger%2C+T">Tobias Fehenberger</a>, 
<a href="/search/cs?searchtype=author&query=Wenning%2C+M">Mario Wenning</a>, 
<a href="/search/cs?searchtype=author&query=Patri%2C+S+K">Sai Kireet Patri</a>, 
<a href="/search/cs?searchtype=author&query=Elbers%2C+J">J&#xf6;rg-Peter Elbers</a>, 
<a href="/search/cs?searchtype=author&query=Mas-Machuca%2C+C">Carmen Mas-Machuca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2023 IEEE. This work has been partially funded in the framework of the CELTIC-NEXT project AI-NET-PROTECT (Project ID C2019/3-4) (#16KIS1279K) and in the programme "Souver\"an. Digital. Vernetzt." joint project 6G-life (#16KISK002) by the German Federal Ministry of Education and Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Flexible-grid Elastic Optical Networks (EONs) have been widely deployed in
recent years to support the growing demand for bandwidth-intensive
applications. To address this cost-efficiently, optimized utilization of EONs
is required. Next-generation bandwidth-variable transceivers (BVTs) will offer
increased adaptivity in symbol rate as well as modulation through probabilistic
constellation shaping. In this work, we therefore investigate the impact of
increased configuration granularity on various aspects of optical networks. We
account for practical implementation considerations of BVT configurations for
the estimation of the required signal-to-noise ratio. Additionally, an
optimization algorithm is presented that selects the most efficient
configuration for each considered data rate and bandwidth combination. Based on
the advanced transceiver configurations, we conduct a network planning study
using a physical-layer-aware algorithm for flexible-grid EONs, and present
results for a national and a continental optical backbone network topology. Our
research demonstrates that a rise in modulation rate adaptivity results in
substantial savings in resources, decreasing the number of necessary lightpaths
by as much as 20% in EONs. In contrast, increased symbol rate granularity only
results in minor savings.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11008" title="Abstract">arXiv:2312.11008</a> [<a href="/pdf/2312.11008" title="Download PDF">pdf</a>, <a href="/format/2312.11008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global-Local MAV Detection under Challenging Conditions based on  Appearance and Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Ye Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiyu Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual detection of micro aerial vehicles (MAVs) has received increasing
research attention in recent years due to its importance in many applications.
However, the existing approaches based on either appearance or motion features
of MAVs still face challenges when the background is complex, the MAV target is
small, or the computation resource is limited. In this paper, we propose a
global-local MAV detector that can fuse both motion and appearance features for
MAV detection under challenging conditions. This detector first searches MAV
target using a global detector and then switches to a local detector which
works in an adaptive search region to enhance accuracy and efficiency.
Additionally, a detector switcher is applied to coordinate the global and local
detectors. A new dataset is created to train and verify the effectiveness of
the proposed detector. This dataset contains more challenging scenarios that
can occur in practice. Extensive experiments on three challenging datasets show
that the proposed detector outperforms the state-of-the-art ones in terms of
detection accuracy and computational efficiency. In particular, this detector
can run with near real-time frame rate on NVIDIA Jetson NX Xavier, which
demonstrates the usefulness of our approach for real-world applications. The
dataset is available at https://github.com/WestlakeIntelligentRobotics/GLAD. In
addition, A video summarizing this work is available at
https://youtu.be/Tv473mAzHbU.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11011" title="Abstract">arXiv:2312.11011</a> [<a href="/pdf/2312.11011" title="Download PDF">pdf</a>, <a href="/format/2312.11011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VinaLLaMA: LLaMA-based Vietnamese Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H">Huy Pham</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+D">Dung Dao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VinaLLaMA Technical Report - 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this technical report, we present VinaLLaMA, an open-weight,
state-of-the-art (SOTA) Large Language Model for the Vietnamese language, built
upon LLaMA-2 with an additional 800 billion trained tokens. VinaLLaMA not only
demonstrates fluency in Vietnamese but also exhibits a profound understanding
of Vietnamese culture, making it a truly indigenous model. VinaLLaMA-7B-chat,
trained on 1 million high-quality synthetic samples, achieves SOTA results on
key benchmarks, including VLSP, VMLU, and Vicuna Benchmark Vietnamese, marking
a significant advancement in the Vietnamese AI landscape and offering a
versatile resource for various applications.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11013" title="Abstract">arXiv:2312.11013</a> [<a href="/pdf/2312.11013" title="Download PDF">pdf</a>, <a href="/format/2312.11013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPT4J: Patch Presence Test for Java Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xian Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The number of vulnerabilities reported in open source software has increased
substantially in recent years. Security patches provide the necessary measures
to protect software from attacks and vulnerabilities. In practice, it is
difficult to identify whether patches have been integrated into software,
especially if we only have binary files. Therefore, the ability to test whether
a patch is applied to the target binary, a.k.a. patch presence test, is crucial
for practitioners. However, it is challenging to obtain accurate semantic
information from patches, which could lead to incorrect results.
<br />In this paper, we propose a new patch presence test framework named PPT4J
($\textbf{P}$atch $\textbf{P}$resence $\textbf{T}$est $\textbf{for}$
$\textbf{J}$ava Binaries). PPT4J is designed for open-source Java libraries. It
takes Java binaries (i.e. bytecode files) as input, extracts semantic
information from patches, and uses feature-based techniques to identify patch
lines in the binaries. To evaluate the effectiveness of our proposed approach
PPT4J, we construct a dataset with binaries that include 110 vulnerabilities.
The results show that PPT4J achieves an F1 score of 98.5% with reasonable
efficiency, improving the baseline by 15.6%. Furthermore, we conduct an
in-the-wild evaluation of PPT4J on JetBrains IntelliJ IDEA. The results suggest
that a third-party library included in the software is not patched for two
CVEs, and we have reported this potential security problem to the vendor.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11015" title="Abstract">arXiv:2312.11015</a> [<a href="/pdf/2312.11015" title="Download PDF">pdf</a>, <a href="/format/2312.11015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Code: Simple Temporal Latent Code for Efficient Dynamic View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenhuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel view synthesis for dynamic scenes is one of the spotlights in computer
vision. The key to efficient dynamic view synthesis is to find a compact
representation to store the information across time. Though existing methods
achieve fast dynamic view synthesis by tensor decomposition or hash grid
feature concatenation, their mixed representations ignore the structural
difference between time domain and spatial domain, resulting in sub-optimal
computation and storage cost. This paper presents T-Code, the efficient
decoupled latent code for the time dimension only. The decomposed feature
design enables customizing modules to cater for different scenarios with
individual specialty and yielding desired results at lower cost. Based on
T-Code, we propose our highly compact hybrid neural graphics primitives
(HybridNGP) for multi-camera setting and deformation neural graphics primitives
with T-Code (DNGP-T) for monocular scenario. Experiments show that HybridNGP
delivers high fidelity results at top processing speed with much less storage
consumption, while DNGP-T achieves state-of-the-art quality and high training
speed for monocular reconstruction.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11017" title="Abstract">arXiv:2312.11017</a> [<a href="/pdf/2312.11017" title="Download PDF">pdf</a>, <a href="/ps/2312.11017" title="Download PostScript">ps</a>, <a href="/format/2312.11017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Inequalities via Ideas from Additive Combinatorics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wa%2C+C">Chin Wa</a> (Ken)Lau, 
<a href="/search/cs?searchtype=author&query=Nair%2C+C">Chandra Nair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO); Number Theory (math.NT)

</div>
<p class="mathjax">Ruzsa's equivalence theorem provided a framework for converting certain
families of inequalities in additive combinatorics to entropic inequalities
(which sometimes did not possess stand-alone entropic proofs). In this work, we
first establish formal equivalences between some families (different from
Ruzsa) of inequalities in additive combinatorics and entropic ones. Secondly,
we provide stand-alone entropic proofs for some previously known entropic
inequalities established via Ruzsa's equivalence theorem. As a first step to
further these equivalences, we establish an information-theoretic
characterization of the magnification ratio that could also be of independent
interest.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11018" title="Abstract">arXiv:2312.11018</a> [<a href="/pdf/2312.11018" title="Download PDF">pdf</a>, <a href="/format/2312.11018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergrah-Enhanced Dual Convolutional Network for Bundle Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaoxin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Bundle recommendations strive to offer users a set of items as a package
named bundle, enhancing convenience and contributing to the seller's revenue.
While previous approaches have demonstrated notable performance, we argue that
they may compromise the ternary relationship among users, items, and bundles.
This compromise can result in information loss, ultimately impacting the
overall model performance. To address this gap, we develop a unified model for
bundle recommendation, termed hypergraph-enhanced dual convolutional neural
network (HED). Our approach is characterized by two key aspects. Firstly, we
construct a complete hypergraph to capture interaction dynamics among users,
items, and bundles. Secondly, we incorporate U-B interaction information to
enhance the information representation derived from users and bundle embedding
vectors. Extensive experimental results on the Youshu and Netease datasets have
demonstrated that HED surpasses state-of-the-art baselines, proving its
effectiveness. In addition, various ablation studies and sensitivity analyses
revealed the working mechanism and proved our effectiveness. Codes and datasets
are available at https://github.com/AAI-Lab/HED
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11019" title="Abstract">arXiv:2312.11019</a> [<a href="/pdf/2312.11019" title="Download PDF">pdf</a>, <a href="/format/2312.11019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centroidal State Estimation and Control for Hardware-constrained  Humanoid Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ficht%2C+G">Grzegorz Ficht</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids), Austin, USA, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We introduce novel methods for state estimation, feedforward and feedback
control, which specifically target humanoid robots with hardware limitations.
Our method combines a five-mass model with approximate dynamics of each mass.
It enables acquiring an accurate assessment of the centroidal state and Center
of Pressure, even when direct forms of force or contact sensing are
unavailable. Upon this, we develop a feedforward scheme that operates on the
centroidal state, accounting for insufficient joint tracking capabilities.
Finally, we implement feedback mechanisms, which compensate for the lack in
Degrees of Freedom that our NimbRo-OP2X robot has. The whole approach allows
for reactive stepping to maintain balance despite these limitations, which was
verified on hardware during RoboCup 2023, in Bordeaux, France.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11020" title="Abstract">arXiv:2312.11020</a> [<a href="/pdf/2312.11020" title="Download PDF">pdf</a>, <a href="/format/2312.11020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Type Classification with Contrastive Task-Specialized  Sentence Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seeberger%2C+P">Philipp Seeberger</a>, 
<a href="/search/cs?searchtype=author&query=Bocklet%2C+T">Tobias Bocklet</a>, 
<a href="/search/cs?searchtype=author&query=Riedhammer%2C+K">Korbinian Riedhammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at KONVENS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">User-generated information content has become an important information source
in crisis situations. However, classification models suffer from noise and
event-related biases which still poses a challenging task and requires
sophisticated task-adaptation. To address these challenges, we propose the use
of contrastive task-specialized sentence encoders for downstream
classification. We apply the task-specialization on the CrisisLex, HumAID, and
TrecIS information type classification tasks and show performance gains w.r.t.
F1-score. Furthermore, we analyse the cross-corpus and cross-lingual
capabilities for two German event relevancy classification datasets.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11021" title="Abstract">arXiv:2312.11021</a> [<a href="/pdf/2312.11021" title="Download PDF">pdf</a>, <a href="/format/2312.11021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed virtual element methods for elliptic optimal control problems with  boundary observations in L^2(Gamma)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+M">Minghui Yang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhaojie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we study the mixed virtual element approximation to an elliptic
optimal control problem with boundary observations. The objective functional of
this type of optimal control problem contains the outward normal derivatives of
the state variable on the boundary, which reduces the regularity of solutions
to the optimal control problems. We construct the mixed virtual element
discrete scheme and derive a priori error estimate for the optimal control
problem based on the variational discretization for the control variable.
Numerical experiments are carried out on different meshes to support our
theoretical findings.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11023" title="Abstract">arXiv:2312.11023</a> [<a href="/pdf/2312.11023" title="Download PDF">pdf</a>, <a href="/format/2312.11023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Spectrum is More Effective for Multimodal Representation and  Fusion: A Multimodal Spectrum Rumor Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lao%2C+A">An Lao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chongyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Duoqian Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal content, such as mixing text with images, presents significant
challenges to rumor detection in social media. Existing multimodal rumor
detection has focused on mixing tokens among spatial and sequential locations
for unimodal representation or fusing clues of rumor veracity across
modalities. However, they suffer from less discriminative unimodal
representation and are vulnerable to intricate location dependencies in the
time-consuming fusion of spatial and sequential tokens. This work makes the
first attempt at multimodal rumor detection in the frequency domain, which
efficiently transforms spatial features into the frequency spectrum and obtains
highly discriminative spectrum features for multimodal representation and
fusion. A novel Frequency Spectrum Representation and fUsion network (FSRU)
with dual contrastive learning reveals the frequency spectrum is more effective
for multimodal representation and fusion, extracting the informative components
for rumor detection. FSRU involves three novel mechanisms: utilizing the
Fourier transform to convert features in the spatial domain to the frequency
domain, the unimodal spectrum compression, and the cross-modal spectrum
co-selection module in the frequency domain. Substantial experiments show that
FSRU achieves satisfactory multimodal rumor detection performance.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11024" title="Abstract">arXiv:2312.11024</a> [<a href="/pdf/2312.11024" title="Download PDF">pdf</a>, <a href="/format/2312.11024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Weakly Supervised Video Correlation Learning for  Procedure-Aware Instructional Video Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyao He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huabin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Cheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weiyao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> has been accepted by AAAI 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Video Correlation Learning (VCL), which aims to analyze the relationships
between videos, has been widely studied and applied in various general video
tasks. However, applying VCL to instructional videos is still quite challenging
due to their intrinsic procedural temporal structure. Specifically, procedural
knowledge is critical for accurate correlation analyses on instructional
videos. Nevertheless, current procedure-learning methods heavily rely on
step-level annotations, which are costly and not scalable. To address this
problem, we introduce a weakly supervised framework called Collaborative
Procedure Alignment (CPA) for procedure-aware correlation learning on
instructional videos. Our framework comprises two core modules: collaborative
step mining and frame-to-step alignment. The collaborative step mining module
enables simultaneous and consistent step segmentation for paired videos,
leveraging the semantic and temporal similarity between frames. Based on the
identified steps, the frame-to-step alignment module performs alignment between
the frames and steps across videos. The alignment result serves as a
measurement of the correlation distance between two videos. We instantiate our
framework in two distinct instructional video tasks: sequence verification and
action quality assessment. Extensive experiments validate the effectiveness of
our approach in providing accurate and interpretable correlation analyses for
instructional videos.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11025" title="Abstract">arXiv:2312.11025</a> [<a href="/pdf/2312.11025" title="Download PDF">pdf</a>, <a href="/ps/2312.11025" title="Download PostScript">ps</a>, <a href="/format/2312.11025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Goal Optimal Route Planning Using the Cell Mapping Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karagounis%2C+A">Athanasios Karagounis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This manuscript explores the complexities of multi-objective path planning,
aiming to optimize routes against a backdrop of conflicting performance
criteria. The study integrates the cell mapping approach as its foundational
concept. A two-pronged search strategy is introduced; initially, the cell
mapping technique is utilized to develop a comprehensive database, encompassing
all cells within the specified area. This database records the performance
metrics for the most efficient routes from each cell to the designated target.
The second phase involves analyzing this database to pinpoint the extent and
count of all Pareto optimal routes from a selected starting cell to the target.
This analysis contributes to solving the overarching multi-objective
optimization challenge inherent in path planning. To validate this approach,
case studies are included, and the results are benchmarked against the
well-established multi-objective A* (MOA*) method. The study discovers that
while the cell mapping method achieves similar outcomes to the MOA* method for
routes originating from a single point, it demonstrates superior computational
benefits, particularly when the starting and ending points are in separate,
non-overlapping areas.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11026" title="Abstract">arXiv:2312.11026</a> [<a href="/pdf/2312.11026" title="Download PDF">pdf</a>, <a href="/format/2312.11026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MISA: Unveiling the Vulnerabilities in Split Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Wei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yuxuan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Hu1%2C+S">Shengshan Hu1</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lulu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">\textit{Federated learning} (FL) and \textit{split learning} (SL) are
prevailing distributed paradigms in recent years. They both enable shared
global model training while keeping data localized on users' devices. The
former excels in parallel execution capabilities, while the latter enjoys low
dependence on edge computing resources and strong privacy protection.
\textit{Split federated learning} (SFL) combines the strengths of both FL and
SL, making it one of the most popular distributed architectures. Furthermore, a
recent study has claimed that SFL exhibits robustness against poisoning
attacks, with a fivefold improvement compared to FL in terms of robustness.
<br />In this paper, we present a novel poisoning attack known as MISA. It poisons
both the top and bottom models, causing a \textbf{\underline{misa}}lignment in
the global model, ultimately leading to a drastic accuracy collapse. This
attack unveils the vulnerabilities in SFL, challenging the conventional belief
that SFL is robust against poisoning attacks. Extensive experiments demonstrate
that our proposed MISA poses a significant threat to the availability of SFL,
underscoring the imperative for academia and industry to accord this matter due
attention.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11027" title="Abstract">arXiv:2312.11027</a> [<a href="/pdf/2312.11027" title="Download PDF">pdf</a>, <a href="/format/2312.11027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Top-k Subtask Planning Tree based on Discriminative  Representation Pre-training for Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaishen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+D">Dengpeng Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Machine Intelligence Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Many complicated real-world tasks can be broken down into smaller, more
manageable parts, and planning with prior knowledge extracted from these
simplified pieces is crucial for humans to make accurate decisions. However,
replicating this process remains a challenge for AI agents and naturally raises
two questions: How to extract discriminative knowledge representation from
priors? How to develop a rational plan to decompose complex problems? Most
existing representation learning methods employing a single encoder structure
are fragile and sensitive to complex and diverse dynamics. To address this
issue, we introduce a multiple-encoder and individual-predictor regime to learn
task-essential representations from sufficient data for simple subtasks.
Multiple encoders can extract adequate task-relevant dynamics without
confusion, and the shared predictor can discriminate the task characteristics.
We also use the attention mechanism to generate a top-k subtask planning tree,
which customizes subtask execution plans in guiding complex decisions on unseen
tasks. This process enables forward-looking and globality by flexibly adjusting
the depth and width of the planning tree. Empirical results on a challenging
platform composed of some basic simple tasks and combinatorially rich synthetic
tasks consistently outperform some competitive baselines and demonstrate the
benefits of our design.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11028" title="Abstract">arXiv:2312.11028</a> [<a href="/pdf/2312.11028" title="Download PDF">pdf</a>, <a href="/format/2312.11028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repeatability, Reproducibility, Replicability, Reusability (4R) in  Journals&#x27; Policies and Software/Data Management in Scientific Publications: A  Survey, Discussion, and Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez%2C+J+A">Jos&#xe9; Armando Hern&#xe1;ndez</a> (CB), 
<a href="/search/cs?searchtype=author&query=Colom%2C+M">Miguel Colom</a> (CB, CMLA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the recognized crisis of credibility in scientific research, there is a
growth of reproducibility studies in computer science, and although existing
surveys have reviewed reproducibility from various perspectives, especially
very specific technological issues, they do not address the author-publisher
relationship in the publication of reproducible computational scientific
articles. This aspect requires significant attention because it is the basis
for reliable research. We have found a large gap between the
reproducibility-oriented practices, journal policies, recommendations,
publisher artifact Description/Evaluation guidelines, submission guides,
technological reproducibility evolution, and its effective adoption to
contribute to tackling the crisis. We conducted a narrative survey, a
comprehensive overview and discussion identifying the mutual efforts required
from Authors, Journals, and Technological actors to achieve reproducibility
research. The relationship between authors and scientific journals in their
mutual efforts to jointly improve the reproducibility of scientific results is
analyzed. Eventually, we propose recommendations for the journal policies, as
well as a unified and standardized Reproducibility Guide for the submission of
scientific articles for authors. The main objective of this work is to analyze
the implementation and experiences of reproducibility policies, techniques and
technologies, standards, methodologies, software, and data management tools
required for scientific reproducible publications. Also, the benefits and
drawbacks of such an adoption, as well as open challenges and promising trends,
to propose possible strategies and efforts to mitigate the identified gaps. To
this purpose, we analyzed 200 scientific articles, surveyed 16 Computer Science
journals, and systematically classified them according to reproducibility
strategies, technologies, policies, code citation, and editorial business. We
conclude there is still a reproducibility gap in scientific publications,
although at the same time also the opportunity to reduce this gap with the
joint effort of authors, publishers, and technological providers.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11029" title="Abstract">arXiv:2312.11029</a> [<a href="/pdf/2312.11029" title="Download PDF">pdf</a>, <a href="/format/2312.11029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Picsou: Enabling Efficient Cross-Consensus Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frank%2C+R">Reginald Frank</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+M">Micah Murray</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Suyash Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+E">Ethan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Crooks%2C+N">Natacha Crooks</a>, 
<a href="/search/cs?searchtype=author&query=Kapritsos%2C+M">Manos Kapritsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Replicated state machines (RSMs) cannot effectively communicate today as
there is no formal framework or efficient protocol to do so. To address this
issue, we introduce a new primitive, the Cross-Cluster Consistent Broadcast
(C3B) and present PICSOU, a practical C3B implementation. PICSOU draws
inspiration from networking and TCP to allow two RSMs to communicate with
constant metadata overhead in the failure-free case and minimal number of
message resends in the case of failures. PICSOU is flexible and allows both
crash fault-tolerant and byzantine fault-tolerant protocols to communicate. At
the heart of PICSOU's good performance and generality lies a novel technique we
call QUACKs (quorum acknowledgements) that allow nodes in each RSM to precisely
determine when messages have definitely been received, or definitely been lost.
Our results are promising: we obtain up to 24x better performance than existing
all-to-all solutions.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11032" title="Abstract">arXiv:2312.11032</a> [<a href="/pdf/2312.11032" title="Download PDF">pdf</a>, <a href="/format/2312.11032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Crowd Navigation in Dynamic Environment with Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hao Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haodong He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot crowd navigation has been gaining increasing attention and popularity
in various practical applications. In existing research, deep reinforcement
learning has been applied to robot crowd navigation by training policies in an
online mode. However, this inevitably leads to unsafe exploration, and
consequently causes low sampling efficiency during pedestrian-robot
interaction. To this end, we propose an offline reinforcement learning based
robot crowd navigation algorithm by utilizing pre-collected crowd navigation
experience. Specifically, this algorithm integrates a spatial-temporal state
into implicit Q-Learning to avoid querying out-of-distribution robot actions of
the pre-collected experience, while capturing spatial-temporal features from
the offline pedestrian-robot interactions. Experimental results demonstrate
that the proposed algorithm outperforms the state-of-the-art methods by means
of qualitative and quantitative analysis.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11034" title="Abstract">arXiv:2312.11034</a> [<a href="/pdf/2312.11034" title="Download PDF">pdf</a>, <a href="/format/2312.11034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Label Learning with a Partner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chongjie Si</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zekun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuehui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024, AAAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In partial label learning (PLL), each instance is associated with a set of
candidate labels among which only one is ground-truth. The majority of the
existing works focuses on constructing robust classifiers to estimate the
labeling confidence of candidate labels in order to identify the correct one.
However, these methods usually struggle to rectify mislabeled samples. To help
existing PLL methods identify and rectify mislabeled samples, in this paper, we
introduce a novel partner classifier and propose a novel ``mutual supervision''
paradigm. Specifically, we instantiate the partner classifier predicated on the
implicit fact that non-candidate labels of a sample should not be assigned to
it, which is inherently accurate and has not been fully investigated in PLL.
Furthermore, a novel collaborative term is formulated to link the base
classifier and the partner one. During each stage of mutual supervision, both
classifiers will blur each other's predictions through a blurring mechanism to
prevent overconfidence in a specific label. Extensive experiments demonstrate
that the performance and disambiguation ability of several well-established
stand-alone and deep-learning based PLL approaches can be significantly
improved by coupling with this learning paradigm.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11035" title="Abstract">arXiv:2312.11035</a> [<a href="/pdf/2312.11035" title="Download PDF">pdf</a>, <a href="/format/2312.11035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Moving Camera Pedestrian Tracking with a New Dataset and Global  Link Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuanghong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Cairong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ensuring driving safety for autonomous vehicles has become increasingly
crucial, highlighting the need for systematic tracking of pedestrians on the
road. Most vehicles are equipped with visual sensors, however, the large-scale
visual dataset from different agents has not been well studied yet. Basically,
most of the multi-target multi-camera (MTMC) tracking systems are composed of
two modules: single camera tracking (SCT) and inter-camera tracking (ICT). To
reliably coordinate between them, MTMC tracking has been a very complicated
task, while tracking across multi-moving cameras makes it even more
challenging. In this paper, we focus on multi-target multi-moving camera
(MTMMC) tracking, which is attracting increasing attention from the research
community. Observing there are few datasets for MTMMC tracking, we collect a
new dataset, called Multi-Moving Camera Track (MMCT), which contains sequences
under various driving scenarios. To address the common problems of identity
switch easily faced by most existing SCT trackers, especially for moving
cameras due to ego-motion between the camera and targets, a lightweight
appearance-free global link model, called Linker, is proposed to mitigate the
identity switch by associating two disjoint tracklets of the same target into a
complete trajectory within the same camera. Incorporated with Linker, existing
SCT trackers generally obtain a significant improvement. Moreover, a strong
baseline approach of re-identification (Re-ID) is effectively incorporated to
extract robust appearance features under varying surroundings for pedestrian
association across moving cameras for ICT, resulting in a much improved MTMMC
tracking system, which can constitute a step further towards coordinated mining
of multiple moving cameras. The dataset is available at
https://github.com/dhu-mmct/DHU-MMCT}{https://github.com/dhu-mmct/DHU-MMCT .
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11036" title="Abstract">arXiv:2312.11036</a> [<a href="/pdf/2312.11036" title="Download PDF">pdf</a>, <a href="/format/2312.11036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniGen: A Unified Generative Framework for Retrieval and Question  Answering with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yujia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Generative information retrieval, encompassing two major tasks of Generative
Document Retrieval (GDR) and Grounded Answer Generation (GAR), has gained
significant attention in the area of information retrieval and natural language
processing. Existing methods for GDR and GAR rely on separate retrieval and
reader modules, which hinder simultaneous optimization. To overcome this, we
present \textbf{UniGen}, a \textbf{Uni}fied \textbf{Gen}erative framework for
retrieval and question answering that integrates both tasks into a single
generative model leveraging the capabilities of large language models. UniGen
employs a shared encoder and two distinct decoders for generative retrieval and
question answering. To facilitate the learning of both tasks, we introduce
connectors, generated by large language models, to bridge the gaps between
query inputs and generation targets, as well as between document identifiers
and answers. Furthermore, we propose an iterative enhancement strategy that
leverages generated answers and retrieved documents to iteratively improve both
tasks. Through extensive experiments on the MS MARCO and NQ datasets, we
demonstrate the effectiveness of UniGen, showcasing its superior performance in
both the retrieval and the question answering tasks.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11037" title="Abstract">arXiv:2312.11037</a> [<a href="/pdf/2312.11037" title="Download PDF">pdf</a>, <a href="/format/2312.11037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SinMPI: Novel View Synthesis from a Single Image with Expanded  Multiplane Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Guo Pu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng-Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhouhui Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-image novel view synthesis is a challenging and ongoing problem that
aims to generate an infinite number of consistent views from a single input
image. Although significant efforts have been made to advance the quality of
generated novel views, less attention has been paid to the expansion of the
underlying scene representation, which is crucial to the generation of
realistic novel view images. This paper proposes SinMPI, a novel method that
uses an expanded multiplane image (MPI) as the 3D scene representation to
significantly expand the perspective range of MPI and generate high-quality
novel views from a large multiplane space. The key idea of our method is to use
Stable Diffusion to generate out-of-view contents, project all scene contents
into an expanded multiplane image according to depths predicted by monocular
depth estimators, and then optimize the multiplane image under the supervision
of pseudo multi-view data generated by a depth-aware warping and inpainting
module. Both qualitative and quantitative experiments have been conducted to
validate the superiority of our method to the state of the art. Our code and
data are available at https://github.com/TrickyGo/SinMPI.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11038" title="Abstract">arXiv:2312.11038</a> [<a href="/pdf/2312.11038" title="Download PDF">pdf</a>, <a href="/format/2312.11038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniChest: Conquer-and-Divide Pre-training for Multi-Source Chest X-Ray  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tianjie Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Feng Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision-Language Pre-training (VLP) that utilizes the multi-modal information
to promote the training efficiency and effectiveness, has achieved great
success in vision recognition of natural domains and shown promise in medical
imaging diagnosis for the Chest X-Rays (CXRs). However, current works mainly
pay attention to the exploration on single dataset of CXRs, which locks the
potential of this powerful paradigm on larger hybrid of multi-source CXRs
datasets. We identify that although blending samples from the diverse sources
offers the advantages to improve the model generalization, it is still
challenging to maintain the consistent superiority for the task of each source
due to the existing heterogeneity among sources. To handle this dilemma, we
design a Conquer-and-Divide pre-training framework, termed as UniChest, aiming
to make full use of the collaboration benefit of multiple sources of CXRs while
reducing the negative influence of the source heterogeneity. Specially, the
``Conquer" stage in UniChest encourages the model to sufficiently capture
multi-source common patterns, and the ``Divide" stage helps squeeze
personalized patterns into different small experts (query networks). We conduct
thorough experiments on many benchmarks, e.g., ChestX-ray14, CheXpert,
Vindr-CXR, Shenzhen, Open-I and SIIM-ACR Pneumothorax, verifying the
effectiveness of UniChest over a range of baselines, and release our codes and
pre-training models at https://github.com/Elfenreigen/UniChest.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11042" title="Abstract">arXiv:2312.11042</a> [<a href="/pdf/2312.11042" title="Download PDF">pdf</a>, <a href="/format/2312.11042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VECOM: Variation Resilient Encoding and Offset Compensation Schemes for  Reliable ReRAM Based DNN Accelerator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Je-Woo Jang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thai-Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Joon-Sung Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 13 figures, This paper was accepted in International Conference on Computer-Aided Design (ICCAD) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Resistive Random Access Memory (ReRAM) based Processing In Memory (PIM)
Accelerator has emerged as a promising computing architecture for memory
intensive applications, such as Deep Neural Networks (DNNs). However, due to
its immaturity, ReRAM devices often suffer from various reliability issues,
which hinder the practicality of the PIM architecture and lead to a severe
degradation in DNN accuracy. Among various reliability issues, device variation
and offset current from High Resistance State (HRS) cell have been considered
as major problems in a ReRAM based PIM architecture. Due to these problems, the
throughput of the ReRAM based PIM is reduced as fewer wordlines are activated.
In this paper, we propose VECOM, a novel approach that includes a variation
resilient encoding technique and an offset compensation scheme for a robust
ReRAM based PIM architecture. The first technique (i.e., VECOM encoding) is
built based on the analysis of the weight pattern distribution of DNN models,
along with the insight into the ReRAM's variation property. The second
technique, VECOM offset compensation, tolerates offset current in PIM by
mapping the conductance of each Multi level Cell (MLC) level added with a
specific offset conductance. Experimental results in various DNN models and
datasets show that the proposed techniques can increase the throughput of the
PIM architecture by up to 9.1 times while saving 50% of energy consumption
without any software overhead. Additionally, VECOM is also found to endure low
R ratio ReRAM cell (up to 7) with a negligible accuracy drop.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11043" title="Abstract">arXiv:2312.11043</a> [<a href="/pdf/2312.11043" title="Download PDF">pdf</a>, <a href="/format/2312.11043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDeLTA: A Light-weight and Robust Table Detection Method based on  Learning Text Arrangement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangping Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingcai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhixiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qitian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The diversity of tables makes table detection a great challenge, leading to
existing models becoming more tedious and complex. Despite achieving high
performance, they often overfit to the table style in training set, and suffer
from significant performance degradation when encountering out-of-distribution
tables in other domains. To tackle this problem, we start from the essence of
the table, which is a set of text arranged in rows and columns. Based on this,
we propose a novel, light-weighted and robust Table Detection method based on
Learning Text Arrangement, namely TDeLTA. TDeLTA takes the text blocks as
input, and then models the arrangement of them with a sequential encoder and an
attention module. To locate the tables precisely, we design a
text-classification task, classifying the text blocks into 4 categories
according to their semantic roles in the tables. Experiments are conducted on
both the text blocks parsed from PDF and extracted by open-source OCR tools,
respectively. Compared to several state-of-the-art methods, TDeLTA achieves
competitive results with only 3.1M model parameters on the large-scale public
datasets. Moreover, when faced with the cross-domain data under the 0-shot
setting, TDeLTA outperforms baselines by a large margin of nearly 7%, which
shows the strong robustness and transferability of the proposed model.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11051" title="Abstract">arXiv:2312.11051</a> [<a href="/pdf/2312.11051" title="Download PDF">pdf</a>, <a href="/format/2312.11051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Correlation Siamese Transformer Network with Dense Connection for  3D Single Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shihao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Pengpeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+E">Erkang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version for IEEE Robotics and Automation Letters (RAL)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RAL), vol. 8, no. 12, pp.
  8066-8073, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Point cloud-based 3D object tracking is an important task in autonomous
driving. Though great advances regarding Siamese-based 3D tracking have been
made recently, it remains challenging to learn the correlation between the
template and search branches effectively with the sparse LIDAR point cloud
data. Instead of performing correlation of the two branches at just one point
in the network, in this paper, we present a multi-correlation Siamese
Transformer network that has multiple stages and carries out feature
correlation at the end of each stage based on sparse pillars. More
specifically, in each stage, self-attention is first applied to each branch
separately to capture the non-local context information. Then, cross-attention
is used to inject the template information into the search area. This strategy
allows the feature learning of the search area to be aware of the template
while keeping the individual characteristics of the template intact. To enable
the network to easily preserve the information learned at different stages and
ease the optimization, for the search area, we densely connect the initial
input sparse pillars and the output of each stage to all subsequent stages and
the target localization network, which converts pillars to bird's eye view
(BEV) feature maps and predicts the state of the target with a small densely
connected convolution network. Deep supervision is added to each stage to
further boost the performance as well. The proposed algorithm is evaluated on
the popular KITTI, nuScenes, and Waymo datasets, and the experimental results
show that our method achieves promising performance compared with the
state-of-the-art. Ablation study that shows the effectiveness of each component
is provided as well. Code is available at
https://github.com/liangp/MCSTN-3DSOT.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11053" title="Abstract">arXiv:2312.11053</a> [<a href="/pdf/2312.11053" title="Download PDF">pdf</a>, <a href="/format/2312.11053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict Detection for Temporal Knowledge Graphs:A Fast Constraint  Mining Algorithm and New Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Junyang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wentao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+H">Haoyuan Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuzhong Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Temporal facts, which are used to describe events that occur during specific
time periods, have become a topic of increased interest in the field of
knowledge graph (KG) research. In terms of quality management, the introduction
of time restrictions brings new challenges to maintaining the temporal
consistency of KGs. Previous studies rely on manually enumerated temporal
constraints to detect conflicts, which are labor-intensive and may have
granularity issues. To address this problem, we start from the common pattern
of temporal facts and propose a pattern-based temporal constraint mining
method, PaTeCon. Unlike previous studies, PaTeCon uses graph patterns and
statistical information relevant to the given KG to automatically generate
temporal constraints, without the need for human experts. In this paper, we
illustrate how this method can be optimized to achieve significant speed
improvement. We also annotate Wikidata and Freebase to build two new benchmarks
for conflict detection. Extensive experiments demonstrate that our
pattern-based automatic constraint mining approach is highly effective in
generating valuable temporal constraints.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11057" title="Abstract">arXiv:2312.11057</a> [<a href="/pdf/2312.11057" title="Download PDF">pdf</a>, <a href="/format/2312.11057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiachen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+P">Peizhuo Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yibing Lan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guozhu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hualong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Dataset sanitization is a widely adopted proactive defense against
poisoning-based backdoor attacks, aimed at filtering out and removing poisoned
samples from training datasets. However, existing methods have shown limited
efficacy in countering the ever-evolving trigger functions, and often leading
to considerable degradation of benign accuracy. In this paper, we propose
DataElixir, a novel sanitization approach tailored to purify poisoned datasets.
We leverage diffusion models to eliminate trigger features and restore benign
features, thereby turning the poisoned samples into benign ones. Specifically,
with multiple iterations of the forward and reverse process, we extract
intermediary images and their predicted labels for each sample in the original
dataset. Then, we identify anomalous samples in terms of the presence of label
transition of the intermediary images, detect the target label by quantifying
distribution discrepancy, select their purified images considering pixel and
feature distance, and determine their ground-truth labels by training a benign
model. Experiments conducted on 9 popular attacks demonstrates that DataElixir
effectively mitigates various complex attacks while exerting minimal impact on
benign accuracy, surpassing the performance of baseline defense methods.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11061" title="Abstract">arXiv:2312.11061</a> [<a href="/pdf/2312.11061" title="Download PDF">pdf</a>, <a href="/format/2312.11061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Exponential Stability of the Unidirectional Flow Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wiersdalen%2C+S">Sondre Wiersdalen</a>, 
<a href="/search/eess?searchtype=author&query=Pereira%2C+M">Mike Pereira</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+A">Annika Lang</a>, 
<a href="/search/eess?searchtype=author&query=Szederkenyi%2C+G">Gabor Szederkenyi</a>, 
<a href="/search/eess?searchtype=author&query=Auriol%2C+J">Jean Auriol</a>, 
<a href="/search/eess?searchtype=author&query=Kulcsar%2C+B">Balazs Kulcsar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">Incremental stability is assessed for the Unidirectional Flow Model, which
describes the flow of a conserved quantity in a cascade of compartments. The
model is governed by a cooperative system of nonlinear ordinary differential
equations with a right-hand side that depends on an input function. Suitable
conditions are given on the input function such that the solutions to the model
converge to each other at an exponential rate. Milder conditions, compared with
the latter, are given such that the solutions to the model converge to each
other asymptotically. These conditions are related to inflow-connected and
outflow-connected compartmental systems and are easy to check. Computational
means to estimate the exponential rate are given and tested against numerical
solutions of the model. A natural application of incremental stability is state
estimation, demonstrated in the numerical experiments, put into a traffic flow
context.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11062" title="Abstract">arXiv:2312.11062</a> [<a href="/pdf/2312.11062" title="Download PDF">pdf</a>, <a href="/format/2312.11062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entity or Relation Embeddings? An Analysis of Encoding Strategies for  Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mtumbuka%2C+F">Frank Mtumbuka</a>, 
<a href="/search/cs?searchtype=author&query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Relation extraction is essentially a text classification problem, which can
be tackled by fine-tuning a pre-trained language model (LM). However, a key
challenge arises from the fact that relation extraction cannot
straightforwardly be reduced to sequence or token classification. Existing
approaches therefore solve the problem in an indirect way: they fine-tune an LM
to learn embeddings of the head and tail entities, and then predict the
relationship from these entity embeddings. Our hypothesis in this paper is that
relation extraction models can be improved by capturing relationships in a more
direct way. In particular, we experiment with appending a prompt with a [MASK]
token, whose contextualised representation is treated as a relation embedding.
While, on its own, this strategy significantly underperforms the aforementioned
approach, we find that the resulting relation embeddings are highly
complementary to what is captured by embeddings of the head and tail entity. By
jointly considering both types of representations, we end up with a simple
model that outperforms the state-of-the-art across several relation extraction
benchmarks.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11063" title="Abstract">arXiv:2312.11063</a> [<a href="/pdf/2312.11063" title="Download PDF">pdf</a>, <a href="/ps/2312.11063" title="Download PostScript">ps</a>, <a href="/format/2312.11063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey on algorithms for Nash equilibria in finite normal-form games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhijian Duan</a>, 
<a href="/search/cs?searchtype=author&query=Mguni%2C+D+H">David Henry Mguni</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+K">Kun Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaotie Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The published version is in Computer Science Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Nash equilibrium is one of the most influential solution concepts in game
theory. With the development of computer science and artificial intelligence,
there is an increasing demand on Nash equilibrium computation, especially for
Internet economics and multi-agent learning. This paper reviews various
algorithms computing the Nash equilibrium and its approximation solutions in
finite normal-form games from both theoretical and empirical perspectives. For
the theoretical part, we classify algorithms in the literature and present
basic ideas on algorithm design and analysis. For the empirical part, we
present a comprehensive comparison on the algorithms in the literature over
different kinds of games. Based on these results, we provide practical
suggestions on implementations and uses of these algorithms. Finally, we
present a series of open problems from both theoretical and practical
considerations.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11069" title="Abstract">arXiv:2312.11069</a> [<a href="/pdf/2312.11069" title="Download PDF">pdf</a>, <a href="/format/2312.11069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patterns of Closeness and Abstractness in Colexifications: The Case of  Indigenous Languages in the Americas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bjerva%2C+J">Johannes Bjerva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures, 1 table, AmericasNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Colexification refers to linguistic phenomena where multiple concepts
(meanings) are expressed by the same lexical form, such as polysemy or
homophony. Colexifications have been found to be pervasive across languages and
cultures. The problem of concreteness/abstractness of concepts is
interdisciplinary, studied from a cognitive standpoint in linguistics,
psychology, psycholinguistics, neurophysiology, etc. In this paper, we
hypothesize that concepts that are closer in concreteness/abstractness are more
likey to colexify, and we test the hypothesis across indigenous languages in
Americas.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11071" title="Abstract">arXiv:2312.11071</a> [<a href="/pdf/2312.11071" title="Download PDF">pdf</a>, <a href="/format/2312.11071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low regularity error estimates for high dimensional nonlinear  Schr&#xf6;dinger equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ji%2C+L">Lun Ji</a>, 
<a href="/search/math?searchtype=author&query=Ostermann%2C+A">Alexander Ostermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The filtered Lie splitting scheme is an established method for the numerical
integration of the periodic nonlinear Schr\"{o}dinger equation at low
regularity. Its temporal convergence was recently analyzed in a framework of
discrete Bourgain spaces in one and two space dimensions for initial data in
$H^s$ with $0&lt;s\leq 2$. Here, this analysis is extended to dimensions $d=3, 4,
5$ for data satisfying $d/2-1 &lt; s \leq 2$. In this setting, convergence of
order $s/2$ in $L^2$ is proven. Numerical examples illustrate these convergence
results.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11075" title="Abstract">arXiv:2312.11075</a> [<a href="/pdf/2312.11075" title="Download PDF">pdf</a>, <a href="/format/2312.11075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split and Rephrase with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ponce%2C+D">David Ponce</a>, 
<a href="/search/cs?searchtype=author&query=Etchegoyhen%2C+T">Thierry Etchegoyhen</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+C">Calleja P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Gete%2C+H">Harritxu Gete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Split and Rephrase task, which consists in splitting complex sentences
into a sequence of shorter grammatical sentences, while preserving the original
meaning, can facilitate the processing of complex texts for humans and machines
alike. In this work, we describe an approach based on large language models,
which improves over the state of the art by large margins on all the major
metrics for the task, on publicly available datasets. We also describe results
from two human evaluations that further establish the significant improvements
obtained with large language models and the viability of the approach. We
evaluate different strategies, including fine-tuning pretrained language models
of varying parameter size, and applying both zero-shot and few-shot in-context
learning on instruction-tuned language models. Although the latter were
markedly outperformed by fine-tuned models, they still achieved promising
results overall. Our results thus demonstrate the strong potential of different
variants of large language models for the Split and Rephrase task, using
relatively small amounts of training samples and model parameters overall.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11076" title="Abstract">arXiv:2312.11076</a> [<a href="/pdf/2312.11076" title="Download PDF">pdf</a>, <a href="/format/2312.11076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Geo-dependent Stories by Combining Density-based Clustering  and Thread-based Aggregation techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerezo-Costas%2C+H">H&#xe9;ctor Cerezo-Costas</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Vicente%2C+M">Manuela Mart&#xed;n-Vicente</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, 2018, vol. 95, p. 32-42
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Citizens are actively interacting with their surroundings, especially through
social media. Not only do shared posts give important information about what is
happening (from the users' perspective), but also the metadata linked to these
posts offer relevant data, such as the GPS-location in Location-based Social
Networks (LBSNs). In this paper we introduce a global analysis of the
geo-tagged posts in social media which supports (i) the detection of unexpected
behavior in the city and (ii) the analysis of the posts to infer what is
happening. The former is obtained by applying density-based clustering
techniques, whereas the latter is consequence of applying natural language
processing. We have applied our methodology to a dataset obtained from
Instagram activity in New York City for seven months obtaining promising
results. The developed algorithms require very low resources, being able to
analyze millions of data-points in commodity hardware in less than one hour
without applying complex parallelization techniques. Furthermore, the solution
can be easily adapted to other geo-tagged data sources without extra effort.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11078" title="Abstract">arXiv:2312.11078</a> [<a href="/pdf/2312.11078" title="Download PDF">pdf</a>, <a href="/format/2312.11078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Image Retrieval with Few-Shot Learning and Relevance Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lerner%2C+B">Boaz Lerner</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this paper was presented in ICCV-Out Of Distribution Generalization on Computer Vision (OOD-CV) Workshop 2023. See also <a href="https://github.com/eccv22-ood-workshop/eccv22-ood-workshop.github.io/blob/new/camera_ready/CameraReady%2053.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With such a massive growth in the number of images stored, efficient search
in a database has become a crucial endeavor managed by image retrieval systems.
Image Retrieval with Relevance Feedback (IRRF) involves iterative human
interaction during the retrieval process, yielding more meaningful outcomes.
This process can be generally cast as a binary classification problem with only
{\it few} labeled samples derived from user feedback. The IRRF task frames a
unique few-shot learning characteristics including binary classification of
imbalanced and asymmetric classes, all in an open-set regime. In this paper, we
study this task through the lens of few-shot learning methods. We propose a new
scheme based on a hyper-network, that is tailored to the task and facilitates
swift adjustment to user feedback. Our approach's efficacy is validated through
comprehensive evaluations on multiple benchmarks and two supplementary tasks,
supported by theoretical analysis. We demonstrate the advantage of our model
over strong baselines on 4 different datasets in IRRF, addressing also
retrieval of images with multiple objects. Furthermore, we show that our method
can attain SoTA results in few-shot one-class classification and reach
comparable results in binary classification task of few-shot open-set
recognition.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11080" title="Abstract">arXiv:2312.11080</a> [<a href="/pdf/2312.11080" title="Download PDF">pdf</a>, <a href="/format/2312.11080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of cryptographic approaches for a quantum-resistant Galileo  OSNMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junquera-S%C3%A1nchez%2C+J">Javier Junquera-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Hernando-Ramiro%2C+C">Carlos Hernando-Ramiro</a>, 
<a href="/search/cs?searchtype=author&query=Gamallo-Palomares%2C+%C3%93">&#xd3;scar Gamallo-Palomares</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-S%C3%A1nchez%2C+J">Jos&#xe9;-Antonio G&#xf3;mez-S&#xe1;nchez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NAVIGATION, Journal of the Institute of Navigation. See navi.ion.org
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Quantum computing becomes more of a reality as time passes, bringing several
cybersecurity challenges. Modern cryptography is based on the computational
complexity of specific mathematical problems, but as new quantum-based
computers appear, classical methods might not be enough to secure
communications. In this paper, we analyse the state of the Galileo Open Service
Navigation Message Authentication (OSNMA) to overcome these new threats. This
analysis and its assessment have been performed using OSNMA documentation,
reviewing the available Post Quantum Cryptography (PQC) algorithms competing in
the National Institute of Standards and Technology (NIST) standardization
process, and studying the possibility of its implementation in the Galileo
service. The main barrier to adopting the PQC approach is the size of both the
signature and the key. The analysis shows that OSNMA is not yet prepared to
face the quantum threat, and a significant change would be required. This work
concludes by assessing different temporal countermeasures that can be
implemented to sustain the system's integrity in the short term.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11083" title="Abstract">arXiv:2312.11083</a> [<a href="/pdf/2312.11083" title="Download PDF">pdf</a>, <a href="/format/2312.11083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MA-BBOB: A Problem Generator for Black-Box Optimization Using Affine  Combinations and Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vermetten%2C+D">Diederick Vermetten</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Furong Ye</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4ck%2C+T">Thomas B&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+C">Carola Doerr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Choosing a set of benchmark problems is often a key component of any
empirical evaluation of iterative optimization heuristics. In continuous,
single-objective optimization, several sets of problems have become widespread,
including the well-established BBOB suite. While this suite is designed to
enable rigorous benchmarking, it is also commonly used for testing methods such
as algorithm selection, which the suite was never designed around.
<br />We present the MA-BBOB function generator, which uses the BBOB suite as
component functions in an affine combination. In this work, we describe the
full procedure to create these affine combinations and highlight the trade-offs
of several design decisions, specifically the choice to place the optimum
uniformly at random in the domain. We then illustrate how this generator can be
used to gain more low-level insight into the function landscapes through the
use of exploratory landscape analysis.
<br />Finally, we show a potential use-case of MA-BBOB in generating a wide set of
training and testing data for algorithm selectors. Using this setup, we show
that the basic scheme of using a set of landscape features to predict the best
algorithm does not lead to optimal results, and that an algorithm selector
trained purely on the BBOB functions generalizes poorly to the affine
combinations.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11084" title="Abstract">arXiv:2312.11084</a> [<a href="/pdf/2312.11084" title="Download PDF">pdf</a>, <a href="/format/2312.11084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for Connected and Automated Vehicles  Control: Recent Advancements and Future Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Min Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xinda Qi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z+E">Zemin Eitan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongming Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Connected and automated vehicles (CAVs) have emerged as a potential solution
to the future challenges of developing safe, efficient, and eco-friendly
transportation systems. However, CAV control presents significant challenges,
given the complexity of interconnectivity and coordination required among the
vehicles. To address this, multi-agent reinforcement learning (MARL), with its
notable advancements in addressing complex problems in autonomous driving,
robotics, and human-vehicle interaction, has emerged as a promising tool for
enhancing the capabilities of CAVs. However, there is a notable absence of
current reviews on the state-of-the-art MARL algorithms in the context of CAVs.
Therefore, this paper delivers a comprehensive review of the application of
MARL techniques within the field of CAV control. The paper begins by
introducing MARL, followed by a detailed explanation of its unique advantages
in addressing complex mobility and traffic scenarios that involve multiple
agents. It then presents a comprehensive survey of MARL applications on the
extent of control dimensions for CAVs, covering critical and typical scenarios
such as platooning control, lane-changing, and unsignalized intersections. In
addition, the paper provides a comprehensive review of the prominent simulation
platforms used to create reliable environments for training in MARL. Lastly,
the paper examines the current challenges associated with deploying MARL within
CAV control and outlines potential solutions that can effectively overcome
these issues. Through this review, the study highlights the tremendous
potential of MARL to enhance the performance and collaboration of CAV control
in terms of safety, travel efficiency, and economy.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11086" title="Abstract">arXiv:2312.11086</a> [<a href="/pdf/2312.11086" title="Download PDF">pdf</a>, <a href="/format/2312.11086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicut Problems in Embedded Graphs: The Dependency of Complexity on  the Demand Pattern
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Focke%2C+J">Jacob Focke</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6rsch%2C+F">Florian H&#xf6;rsch</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaohua Li</a>, 
<a href="/search/cs?searchtype=author&query=Marx%2C+D">D&#xe1;niel Marx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The Multicut problem asks for a minimum cut separating certain pairs of
vertices: formally, given a graph $G$ and demand graph $H$ on a set $T\subseteq
V(G)$ of terminals, the task is to find a minimum-weight set $C$ of edges of
$G$ such that whenever two vertices of $T$ are adjacent in $H$, they are in
different components of $G\setminus C$. Colin de Verdi\`{e}re [Algorithmica,
2017] showed that Multicut with $t$ terminals on a graph $G$ of genus $g$ can
be solved in time $f(t,g)n^{O(\sqrt{g^2+gt+t})}$. Cohen-Addad et al. [JACM,
2021] proved a matching lower bound showing that the exponent of $n$ is
essentially best possible (for fixed values of $t$ and $g$), even in the
special case of Multiway Cut, where the demand graph $H$ is a complete graph.
<br />However, this lower bound tells us nothing about other special cases of
Multicut such as Group 3-Terminal Cut. We show that if the demand pattern is,
in some sense, close to being a complete bipartite graph, then Multicut can be
solved faster than $f(t,g)n^{O(\sqrt{g^2+gt+t})}$, and furthermore this is the
only property that allows such an improvement. Formally, for a class
$\mathcal{H}$ of graphs, Multicut$(\mathcal{H})$ is the special case where the
demand graph $H$ is in $\mathcal{H}$. For every fixed class $\mathcal{H}$
(satisfying some mild closure property), fixed $g$, and fixed $t$, our main
result gives tight upper and lower bounds on the exponent of $n$ in algorithms
solving Multicut$(\mathcal{H})$.
<br />In addition, we investigate a similar setting where, instead of
parameterizing by the genus $g$ of $G$, we parameterize by the minimum number
$k$ of edges of $G$ that need to be deleted to obtain a planar graph.
Interestingly, in this setting it makes a significant difference whether the
graph $G$ is weighted or unweighted: further nontrivial algorithmic techniques
give substantial improvements in the unweighted case.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11091" title="Abstract">arXiv:2312.11091</a> [<a href="/pdf/2312.11091" title="Download PDF">pdf</a>, <a href="/format/2312.11091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Colored Noise in PPO: Improved Exploration and Performance Through  Correlated Action Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hollenstein%2C+J">Jakob Hollenstein</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Proximal Policy Optimization (PPO), a popular on-policy deep
<br />reinforcement learning method, employs a stochastic policy for
<br />exploration. In this paper, we propose a colored noise-based
<br />stochastic policy variant of PPO. Previous research highlighted the
<br />importance of temporal correlation in action noise for effective
<br />exploration in off-policy reinforcement learning. Building on
<br />this, we investigate whether correlated noise can also enhance
<br />exploration in on-policy methods like PPO. We discovered that
<br />correlated noise for action selection improves learning performance
<br />and outperforms the currently popular uncorrelated white noise
<br />approach in on-policy methods. Unlike off-policy learning, where pink
<br />noise was found to be highly effective, we found that a colored
<br />noise, intermediate between white and pink, performed best for
<br />on-policy learning in PPO. We examined the impact of varying the
<br />amount of data collected for each update by modifying the number of
<br />parallel simulation environments for data collection and observed
<br />that with a larger number of parallel environments, more strongly
<br />correlated noise is beneficial. Due to the significant impact and
<br />ease of implementation, we recommend switching to correlated noise as
<br />the default noise source in PPO.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11093" title="Abstract">arXiv:2312.11093</a> [<a href="/pdf/2312.11093" title="Download PDF">pdf</a>, <a href="/format/2312.11093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGCNN: a learnable multigrid solver for linear PDEs on structured grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xie%2C+Y">Yan Xie</a>, 
<a href="/search/math?searchtype=author&query=Lv%2C+M">Minrui Lv</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Chensong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a learnable solver tailored to solve discretized linear
partial differential equations (PDEs). This solver requires only
problem-specific training data, without using specialized expertise. Its
development is anchored by three core principles: (1) a multilevel hierarchy to
promote rapid convergence, (2) adherence to linearity concerning the right-hand
side of equations, and (3) weights sharing across different levels to
facilitate adaptability to various problem sizes. Built on these foundational
principles, we introduce a network adept at solving PDEs discretized on
structured grids, even when faced with heterogeneous coefficients. The
cornerstone of our proposed solver is the convolutional neural network (CNN),
chosen for its capacity to learn from structured data and its similar
computation pattern as multigrid components. To evaluate its effectiveness, the
solver was trained to solve convection-diffusion equations featuring
heterogeneous diffusion coefficients. The solver exhibited swift convergence to
high accuracy over a range of grid sizes, extending from $31 \times 31$ to
$4095 \times 4095$. Remarkably, our method outperformed the classical Geometric
Multigrid (GMG) solver, demonstrating a speedup of approximately 3 to 8 times.
Furthermore, we explored the solver's generalizability to untrained coefficient
distributions. The findings showed consistent reliability across various other
coefficient distributions, revealing that when trained on a mixed coefficient
distribution, the solver is nearly as effective in generalizing to all types of
coefficient distributions.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11094" title="Abstract">arXiv:2312.11094</a> [<a href="/pdf/2312.11094" title="Download PDF">pdf</a>, <a href="/format/2312.11094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Side-Channel Attacks in Context of Cache -- Taxonomies,  Analysis and Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pulkit%2C+A">Ankit Pulkit</a>, 
<a href="/search/cs?searchtype=author&query=Naval%2C+S">Smita Naval</a>, 
<a href="/search/cs?searchtype=author&query=Laxmi%2C+V">Vijay Laxmi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Side-channel attacks have become prominent attack surfaces in cyberspace.
Attackers use the side information generated by the system while performing a
task. Among the various side-channel attacks, cache side-channel attacks are
leading as there has been an enormous growth in cache memory size in last
decade, especially Last Level Cache (LLC). The adversary infers the information
from the observable behavior of shared cache memory. This paper covers the
detailed study of cache side-channel attacks and compares different
microarchitectures in the context of side-channel attacks. Our main
contributions are: (1) We have summarized the fundamentals and essentials of
side-channel attacks and various attack surfaces (taxonomies). We also
discussed different exploitation techniques, highlighting their capabilities
and limitations. (2) We discussed cache side-channel attacks and analyzed the
existing literature on cache side-channel attacks on various parameters like
microarchitectures, cross-core exploitation, methodology, target, etc. (3) We
discussed the detailed analysis of the existing mitigation strategies to
prevent cache side-channel attacks. The analysis includes hardware- and
software-based countermeasures, examining their strengths and weaknesses. We
also discussed the challenges and trade-offs associated with mitigation
strategies. This survey is supposed to provide a deeper understanding of the
threats posed by these attacks to the research community with valuable insights
into effective defense mechanisms.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11097" title="Abstract">arXiv:2312.11097</a> [<a href="/pdf/2312.11097" title="Download PDF">pdf</a>, <a href="/format/2312.11097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Change points detection in crime-related time series: an on-line fuzzy  approach based on a shape space representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albertetti%2C+F">Fabrizio Albertetti</a>, 
<a href="/search/cs?searchtype=author&query=Grossrieder%2C+L">Lionel Grossrieder</a>, 
<a href="/search/cs?searchtype=author&query=Ribaux%2C+O">Olivier Ribaux</a>, 
<a href="/search/cs?searchtype=author&query=Stoffel%2C+K">Kilian Stoffel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Volume 40, March 2016, Pages 441-454
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The extension of traditional data mining methods to time series has been
effectively applied to a wide range of domains such as finance, econometrics,
biology, security, and medicine. Many existing mining methods deal with the
task of change points detection, but very few provide a flexible approach.
Querying specific change points with linguistic variables is particularly
useful in crime analysis, where intuitive, understandable, and appropriate
detection of changes can significantly improve the allocation of resources for
timely and concise operations. In this paper, we propose an on-line method for
detecting and querying change points in crime-related time series with the use
of a meaningful representation and a fuzzy inference system. Change points
detection is based on a shape space representation, and linguistic terms
describing geometric properties of the change points are used to express
queries, offering the advantage of intuitiveness and flexibility. An empirical
evaluation is first conducted on a crime data set to confirm the validity of
the proposed method and then on a financial data set to test its general
applicability. A comparison to a similar change-point detection algorithm and a
sensitivity analysis are also conducted. Results show that the method is able
to accurately detect change points at very low computational costs. More
broadly, the detection of specific change points within time series of
virtually any domain is made more intuitive and more understandable, even for
experts not related to data mining.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11099" title="Abstract">arXiv:2312.11099</a> [<a href="/pdf/2312.11099" title="Download PDF">pdf</a>, <a href="/format/2312.11099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Setup to Test Obstacle-dealing Capabilities of  Prosthetic Feet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pace%2C+A">Anna Pace</a>, 
<a href="/search/cs?searchtype=author&query=Proksch%2C+L">Lukas Proksch</a>, 
<a href="/search/cs?searchtype=author&query=Grioli%2C+G">Giorgio Grioli</a>, 
<a href="/search/cs?searchtype=author&query=Aszmann%2C+O+C">Oskar C. Aszmann</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+M+G">Manuel G. Catalano</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Conference on Rehabilitation Robotics (ICORR),
  Singapore, Singapore, 2023, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Small obstacles on the ground often lead to a fall when caught with
commercial prosthetic feet. Despite some recently developed feet can actively
control the ankle angle, for instance over slopes, their flat and rigid sole
remains a cause of instability on uneven grounds. Soft robotic feet were
recently proposed to tackle that issue; however, they lack consistent
experimental validation. Therefore, this paper describes the experimental setup
realized to test soft and rigid prosthetic feet with lower-limb prosthetic
users. It includes a wooden walkway and differently shaped obstacles. It was
preliminary validated with an able-bodied subject, the same subject walking on
commercial prostheses through modified walking boots, and with a prosthetic
user. They performed walking firstly on even ground, and secondly on even
ground stepping on one of the obstacles. Results in terms of vertical ground
reaction force and knee moments in both the sagittal and frontal planes show
how the poor performance of commonly used prostheses is exacerbated in case of
obstacles. The prosthetic user, indeed, noticeably relies on the sound leg to
compensate for the stiff and unstable interaction of the prosthetic limb with
the obstacle. Therefore, since the limitations of non-adaptive prosthetic feet
in obstacle-dealing emerge from the experiments, as expected, this study
justifies the use of the setup for investigating the performance of soft feet
on uneven grounds and obstacle negotiation.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11109" title="Abstract">arXiv:2312.11109</a> [<a href="/pdf/2312.11109" title="Download PDF">pdf</a>, <a href="/format/2312.11109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Transformers for Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yozen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Neil Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tong Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformers have recently emerged as powerful neural networks for graph
learning, showcasing state-of-the-art performance on several graph property
prediction tasks. However, these results have been limited to small-scale
graphs, where the computational feasibility of the global attention mechanism
is possible. The next goal is to scale up these architectures to handle very
large graphs on the scale of millions or even billions of nodes. With
large-scale graphs, global attention learning is proven impractical due to its
quadratic complexity w.r.t. the number of nodes. On the other hand,
neighborhood sampling techniques become essential to manage large graph sizes,
yet finding the optimal trade-off between speed and accuracy with sampling
techniques remains challenging. This work advances representation learning on
single large-scale graphs with a focus on identifying model characteristics and
critical design constraints for developing scalable graph transformer (GT)
architectures. We argue such GT requires layers that can adeptly learn both
local and global graph representations while swiftly sampling the graph
topology. As such, a key innovation of this work lies in the creation of a fast
neighborhood sampling technique coupled with a local attention mechanism that
encompasses a 4-hop reception field, but achieved through just 2-hop
operations. This local node embedding is then integrated with a global node
embedding, acquired via another self-attention layer with an approximate global
codebook, before finally sent through a downstream layer for node predictions.
The proposed GT framework, named LargeGT, overcomes previous computational
bottlenecks and is validated on three large-scale node classification
benchmarks. We report a 3x speedup and 16.8% performance gain on ogbn-products
and snap-patents, while we also scale LargeGT on ogbn-papers100M with a 5.9%
performance improvement.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11110" title="Abstract">arXiv:2312.11110</a> [<a href="/pdf/2312.11110" title="Download PDF">pdf</a>, <a href="/format/2312.11110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws of Network Traffic Load: A Theoretical Explanation of  Metcalfe&#x27;s Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Metcalfe's Law captures the relationship between a network's value, and its
scale, asserting that a network's value is directly proportional to the square
of its size. Over the past four decades, various researchers have put forth
different derivative scaling laws on this matter. Remarkably, these seemingly
conflicting conclusions have all been substantiated by robust data validation,
raising the question of which law holds greater representativeness. Therefore,
there remains a need for a comprehensive and resilient theoretical model to
underpin these patterns. This study aims to bridge this disparity by offering a
theoretical interpretation of Metcalfe's Law and its variations. Building upon
a certain degree of consensus that, \textit{traffic is value}, we gauge network
effects by means of network traffic load. To deduce a general analytical
boundary for network traffic load, we strike a balance between practicality and
analytical feasibility by establishing a comprehensive network model. Building
upon this foundation, we provide potential theoretical interpretations for
Metcalfe's Law and its variants, achieving alignment between our theoretical
derivations and the previously validated empirical evidence for Metcalfe's Law.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11111" title="Abstract">arXiv:2312.11111</a> [<a href="/pdf/2312.11111" title="Download PDF">pdf</a>, <a href="/format/2312.11111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Good, The Bad, and Why: Unveiling Emotions in Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenxin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jianxun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report; an extension to EmotionPrompt (<a href="/abs/2307.11760">arXiv:2307.11760</a>); 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Emotion significantly impacts our daily behaviors and interactions. While
recent generative AI models, such as large language models, have shown
impressive performance in various tasks, it remains unclear whether they truly
comprehend emotions. This paper aims to address this gap by incorporating
psychological theories to gain a holistic understanding of emotions in
generative AI models. Specifically, we propose three approaches: 1)
EmotionPrompt to enhance AI model performance, 2) EmotionAttack to impair AI
model performance, and 3) EmotionDecode to explain the effects of emotional
stimuli, both benign and malignant. Through extensive experiments involving
language and multi-modal models on semantic understanding, logical reasoning,
and generation tasks, we demonstrate that both textual and visual EmotionPrompt
can boost the performance of AI models while EmotionAttack can hinder it.
Additionally, EmotionDecode reveals that AI models can comprehend emotional
stimuli akin to the mechanism of dopamine in the human brain. Our work heralds
a novel avenue for exploring psychology to enhance our understanding of
generative AI models. This paper is an extended version of our previous work
EmotionPrompt (https://arxiv.org/abs/2307.11760).
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11112" title="Abstract">arXiv:2312.11112</a> [<a href="/pdf/2312.11112" title="Download PDF">pdf</a>, <a href="/format/2312.11112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConDaFormer: Disassembled Transformer with Local Structure Enhancement  for 3D Point Cloud Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lunhao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shanshan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+N">Nan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code: <a href="https://github.com/LHDuan/ConDaFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have been recently explored for 3D point cloud understanding
with impressive progress achieved. A large number of points, over 0.1 million,
make the global self-attention infeasible for point cloud data. Thus, most
methods propose to apply the transformer in a local region, e.g., spherical or
cubic window. However, it still contains a large number of Query-Key pairs,
which requires high computational costs. In addition, previous methods usually
learn the query, key, and value using a linear projection without modeling the
local 3D geometric structure. In this paper, we attempt to reduce the costs and
model the local geometry prior by developing a new transformer block, named
ConDaFormer. Technically, ConDaFormer disassembles the cubic window into three
orthogonal 2D planes, leading to fewer points when modeling the attention in a
similar range. The disassembling operation is beneficial to enlarging the range
of attention without increasing the computational complexity, but ignores some
contexts. To provide a remedy, we develop a local structure enhancement
strategy that introduces a depth-wise convolution before and after the
attention. This scheme can also capture the local geometric information. Taking
advantage of these designs, ConDaFormer captures both long-range contextual
information and local priors. The effectiveness is demonstrated by experimental
results on several 3D point cloud understanding benchmarks. Code is available
at https://github.com/LHDuan/ConDaFormer .
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11113" title="Abstract">arXiv:2312.11113</a> [<a href="/pdf/2312.11113" title="Download PDF">pdf</a>, <a href="/format/2312.11113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Monotone Interleaving Distance for Merge Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beurskens%2C+T">Thijs Beurskens</a>, 
<a href="/search/cs?searchtype=author&query=Ophelders%2C+T">Tim Ophelders</a>, 
<a href="/search/cs?searchtype=author&query=Speckmann%2C+B">Bettina Speckmann</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+K">Kevin Verbeek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Merge trees are a common topological descriptor for data with a hierarchical
component, such as terrains and scalar fields. The interleaving distance, in
turn, is a common distance measure for comparing merge trees. However, the
interleaving distance for merge trees is solely based on the hierarchical
structure, and disregards any other geometrical or topological properties that
might be present in the underlying data. For example, the channel networks
formed by braided rivers carry intrinsic orders induced by the relative
position of channels: from one bank to another, or from upstream to downstream.
In this paper, we introduce a form of ordered merge trees that does capture
intrinsic order present in the data. Furthermore, we define the monotone
interleaving distance, which is an order preserving distance measure for
ordered merge trees. Analogous to the regular interleaving distance for merge
trees, we show that the monotone variant has three equivalent definitions in
terms of two maps, a single map, or a labelling. There is no efficient constant
factor approximation known to compute the interleaving distance. In contrast,
we describe an $O(n^2)$ time algorithm that computes a 2-approximation of the
monotone interleaving distance with an additive term $G$ that captures the
maximum height differences of leaves of the input merge trees. In the real
world setting of river network analysis, all leaves are at height 0; hence $G$
equals 0, and our algorithm is a proper 2-approximation.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11115" title="Abstract">arXiv:2312.11115</a> [<a href="/pdf/2312.11115" title="Download PDF">pdf</a>, <a href="/format/2312.11115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds and Constructions of Quantum Locally Recoverable Codes from  Quantum CSS Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Gaojun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bocong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ezerman%2C+M+F">Martianus Frederic Ezerman</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">San Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Classical locally recoverable codes (LRCs) have become indispensable in
distributed storage systems. They provide efficient recovery in terms of
localized errors. Quantum LRCs have very recently been introduced for their
potential application in quantum data storage. In this paper, we use classical
LRCs to investigate quantum LRCs. We prove that the parameters of quantum LRCs
are bounded by their classical counterparts. We deduce the bounds on the
parameters of quantum LRCs from the bounds on the parameters of the classical
ones. We establish a characterization of optimal pure quantum LRCs based on
classical codes with specific properties. Using well-crafted classical LRCs as
ingredients in the construction of quantum CSS codes, we offer the first
construction of several families of optimal pure quantum LRCs.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11116" title="Abstract">arXiv:2312.11116</a> [<a href="/pdf/2312.11116" title="Download PDF">pdf</a>, <a href="/format/2312.11116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of the IIIF Presentation API 3.0 based on Software  Support: Use Case of an Incremental IIIF Deployment within a Citizen Science  Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raemy">Raemy</a>, 
<a href="/search/cs?searchtype=author&query=Antoine%2C+J">Julien Antoine</a>, 
<a href="/search/cs?searchtype=author&query=Demleitner">Demleitner</a>, 
<a href="/search/cs?searchtype=author&query=Adrian">Adrian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures. This is the preprint version of a conference paper that was accepted at EuroMed2022, the International Conference on Digital Heritage, that took place in Limassol, Cyprus between the 7th November and the 11th November 2022. The conference proceedings are due to be published by Springer Nature Publisher in the Lecture Notes in Computer Science (LNCS) series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">As part of the Participatory Knowledge Practices in Analogue and Digital
Image Archives (PIA) research project, we have been implementing Linked Open
Usable Data (LOUD) standards including the International Image Interoperability
Framework (IIIF) specifications to disseminate digital objects, their related
metadata and streamline our processes. We have taken an incremental approach to
IIIF deployment, first by installing the Simple Image Presentation Interface
(SIPI), a IIIF Image API 3.0 server, followed by conceiving a workflow based on
cookbook recipes created and vetted by the IIIF community for the generation of
resources compatible with the IIIF Presentation API 3.0, one of the key
components of our architecture. This workflow resulted in a monitoring exercise
of this community-driven effort, principally to align the requirements of PIA
and the IIIF Presentation API support of software clients.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11118" title="Abstract">arXiv:2312.11118</a> [<a href="/pdf/2312.11118" title="Download PDF">pdf</a>, <a href="/format/2312.11118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Reinforcement Learning Agents Through Counterfactual Action  Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amitai%2C+Y">Yotam Amitai</a>, 
<a href="/search/cs?searchtype=author&query=Septon%2C+Y">Yael Septon</a>, 
<a href="/search/cs?searchtype=author&query=Amir%2C+O">Ofra Amir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable reinforcement learning (XRL) methods aim to help elucidate agent
policies and decision-making processes. The majority of XRL approaches focus on
local explanations, seeking to shed light on the reasons an agent acts the way
it does at a specific world state. While such explanations are both useful and
necessary, they typically do not portray the outcomes of the agent's selected
choice of action. In this work, we propose ``COViz'', a new local explanation
method that visually compares the outcome of an agent's chosen action to a
counterfactual one. In contrast to most local explanations that provide
state-limited observations of the agent's motivation, our method depicts
alternative trajectories the agent could have taken from the given state and
their outcomes. We evaluated the usefulness of COViz in supporting people's
understanding of agents' preferences and compare it with reward decomposition,
a local explanation method that describes an agent's expected utility for
different actions by decomposing it into meaningful reward types. Furthermore,
we examine the complementary benefits of integrating both methods. Our results
show that such integration significantly improved participants' performance.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11119" title="Abstract">arXiv:2312.11119</a> [<a href="/pdf/2312.11119" title="Download PDF">pdf</a>, <a href="/format/2312.11119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Reconstruction via Combinatorial Embedding of  Cross-Channel Spatio-Spectral Clues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zaifeng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing learning-based hyperspectral reconstruction methods show limitations
in fully exploiting the information among the hyperspectral bands. As such, we
propose to investigate the chromatic inter-dependencies in their respective
hyperspectral embedding space. These embedded features can be fully exploited
by querying the inter-channel correlations in a combinatorial manner, with the
unique and complementary information efficiently fused into the final
prediction. We found such independent modeling and combinatorial excavation
mechanisms are extremely beneficial to uncover marginal spectral features,
especially in the long wavelength bands. In addition, we have proposed a
spatio-spectral attention block and a spectrum-fusion attention module, which
greatly facilitates the excavation and fusion of information at both
semantically long-range levels and fine-grained pixel levels across all
dimensions. Extensive quantitative and qualitative experiments show that our
method (dubbed CESST) achieves SOTA performance. Code for this project is at:
https://github.com/AlexYangxx/CESST.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11122" title="Abstract">arXiv:2312.11122</a> [<a href="/pdf/2312.11122" title="Download PDF">pdf</a>, <a href="/format/2312.11122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Dataframe Libraries for Data Preparation on a Single  Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mozzillo%2C+A">Angelo Mozzillo</a>, 
<a href="/search/cs?searchtype=author&query=Zecchini%2C+L">Luca Zecchini</a>, 
<a href="/search/cs?searchtype=author&query=Gagliardelli%2C+L">Luca Gagliardelli</a>, 
<a href="/search/cs?searchtype=author&query=Aslam%2C+A">Adeel Aslam</a>, 
<a href="/search/cs?searchtype=author&query=Bergamaschi%2C+S">Sonia Bergamaschi</a>, 
<a href="/search/cs?searchtype=author&query=Simonini%2C+G">Giovanni Simonini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data preparation is a trial-and-error process that typically involves
countless iterations over the data to define the best pipeline of operators for
a given task. With tabular data, practitioners often perform that burdensome
activity on local machines by writing ad hoc scripts with libraries based on
the Pandas dataframe API and testing them on samples of the entire dataset--the
faster the library, the less idle time its users have. In this paper, we
evaluate the most popular Python dataframe libraries in general data
preparation use cases to assess how they perform on a single machine. To do so,
we employ 4 real-world datasets and pipelines with distinct characteristics,
covering a variety of scenarios. The insights gained with this experimentation
are useful to data scientists who need to choose which of the dataframe
libraries best suits their data preparation task at hand. In a nutshell, we
found that: for small datasets, Pandas consistently proves to be the best
choice with the richest API; when RAM is limited and there is no need to
complete compatibility with Pandas API, Polars is the go-to choice thanks to
its resource and query optimization; when a GPU is available, CuDF often yields
the best performance, while for very large datasets that cannot fit in the GPU
memory and RAM, PySpark (thanks to a multi-thread execution and a query
optimizer) and Vaex (exploiting a columnar data format) are the best options.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11123" title="Abstract">arXiv:2312.11123</a> [<a href="/pdf/2312.11123" title="Download PDF">pdf</a>, <a href="/format/2312.11123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Long-Form Speech Recognition by Jointly Modeling the Primary  and Non-primary Speakers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arumugam%2C+G+P">Guru Prakash Arumugam</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shuo-yiin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sainath%2C+T+N">Tara N. Sainath</a>, 
<a href="/search/cs?searchtype=author&query=Prabhavalkar%2C+R">Rohit Prabhavalkar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bijwadia%2C+S">Shaan Bijwadia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">ASR models often suffer from a long-form deletion problem where the model
predicts sequential blanks instead of words when transcribing a lengthy audio
(in the order of minutes or hours). From the perspective of a user or
downstream system consuming the ASR results, this behavior can be perceived as
the model "being stuck", and potentially make the product hard to use. One of
the culprits for long-form deletion is training-test data mismatch, which can
happen even when the model is trained on diverse and large-scale data collected
from multiple application domains. In this work, we introduce a novel technique
to simultaneously model different groups of speakers in the audio along with
the standard transcript tokens. Speakers are grouped as primary and
non-primary, which connects the application domains and significantly
alleviates the long-form deletion problem. This improved model neither needs
any additional training data nor incurs additional training or inference cost.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11127" title="Abstract">arXiv:2312.11127</a> [<a href="/pdf/2312.11127" title="Download PDF">pdf</a>, <a href="/format/2312.11127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-centric Flexible Resource Management Framework for LEO Satellites  with Fully Regenerative Payload
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+S">Sovit Bhandari</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+X">Thang X. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE JSAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The regenerative capabilities of next-generation satellite systems offer a
novel approach to design low earth orbit (LEO) satellite communication systems,
enabling full flexibility in bandwidth and spot beam management, power control,
and onboard data processing. These advancements allow the implementation of
intelligent spatial multiplexing techniques, addressing the ever-increasing
demand for future broadband data traffic. Existing satellite resource
management solutions, however, do not fully exploit these capabilities. To
address this issue, a novel framework called flexible resource management
algorithm for LEO satellites (FLARE-LEO) is proposed to jointly design
bandwidth, power, and spot beam coverage optimized for the geographic
distribution of users. It incorporates multi-spot beam multicasting, spatial
multiplexing, caching, and handover (HO). In particular, the spot beam coverage
is optimized by using the unsupervised K-means algorithm applied to the
realistic geographical user demands, followed by a proposed successive convex
approximation (SCA)-based iterative algorithm for optimizing the radio
resources. Furthermore, we propose two joint transmission architectures during
the HO period, which jointly estimate the downlink channel state information
(CSI) using deep learning and optimize the transmit power of the LEOs involved
in the HO process to improve the overall system throughput. Simulations
demonstrate superior performance in terms of delivery time reduction of the
proposed algorithm over the existing solutions.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11128" title="Abstract">arXiv:2312.11128</a> [<a href="/pdf/2312.11128" title="Download PDF">pdf</a>, <a href="/format/2312.11128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of CNN and Transformer for Balanced RGB-Event Video  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yao Rong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pattern recognition based on RGB-Event data is a newly arising research topic
and previous works usually learn their features using CNN or Transformer. As we
know, CNN captures the local features well and the cascaded self-attention
mechanisms are good at extracting the long-range global relations. It is
intuitive to combine them for high-performance RGB-Event based video
recognition, however, existing works fail to achieve a good balance between the
accuracy and model parameters, as shown in Fig.~\ref{firstimage}. In this work,
we propose a novel RGB-Event based recognition framework termed TSCFormer,
which is a relatively lightweight CNN-Transformer model. Specifically, we
mainly adopt the CNN as the backbone network to first encode both RGB and Event
data. Meanwhile, we initialize global tokens as the input and fuse them with
RGB and Event features using the BridgeFormer module. It captures the global
long-range relations well between both modalities and maintains the simplicity
of the whole model architecture at the same time. The enhanced features will be
projected and fused into the RGB and Event CNN blocks, respectively, in an
interactive manner using F2E and F2V modules. Similar operations are conducted
for other CNN blocks to achieve adaptive fusion and local-global feature
enhancement under different resolutions. Finally, we concatenate these three
features and feed them into the classification head for pattern recognition.
Extensive experiments on two large-scale RGB-Event benchmark datasets
(PokerEvent and HARDVS) fully validated the effectiveness of our proposed
TSCFormer. The source code and pre-trained models will be released at
https://github.com/Event-AHU/TSCFormer.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11135" title="Abstract">arXiv:2312.11135</a> [<a href="/pdf/2312.11135" title="Download PDF">pdf</a>, <a href="/format/2312.11135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Attention via Orthogonal Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiangtao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Efficient attentions have greatly improved the computational efficiency of
Transformers. However, most existing linear attention mechanisms suffer from an
\emph{efficiency degradation} problem, leading to inefficiencies in causal
language modeling and hindering their application in long-range language
models. This problem is more pronounced under language modeling with unbounded
contexts. In this paper, we propose \textbf{L}inear \textbf{A}ttention
\textbf{V}ia \textbf{O}rthogonal memory~(\shortname) to address these
limitations, achieving strong performance while maintaining linear complexity.
\shortname employs orthogonal decomposition to compress a context into a
fixed-size orthogonal memory while effectively minimizing redundancy within the
context. Given that orthogonal memory compresses global information, we further
dissect the context to amplify fine-grained local information. Additionally, we
embed the relative position encoding into \shortname to improve the
extrapolation ability. Experimental results show that \shortname greatly
improves the efficiency of the causal language model with the best
extrapolation performance and outperforms other efficient baselines. Further,
we endeavor to employ \shortname for unbounded language modeling and
successfully scale the context length to 128K.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11138" title="Abstract">arXiv:2312.11138</a> [<a href="/pdf/2312.11138" title="Download PDF">pdf</a>, <a href="/format/2312.11138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Open-World Adaptation by Adaptation Principles Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Cheng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Nikonova%2C+E">Ekaterina Nikonova</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Renz%2C+J">Jochen Renz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Novelty adaptation is the ability of an intelligent agent to adjust its
behavior in response to changes in its environment. This is an important
characteristic of intelligent agents, as it allows them to continue to function
effectively in novel or unexpected situations, but still stands as a critical
challenge for deep reinforcement learning (DRL). To tackle this challenge, we
propose a simple yet effective novel method, NAPPING (Novelty Adaptation
Principles Learning), that allows trained DRL agents to respond to different
classes of novelties in open worlds rapidly. With NAPPING, DRL agents can learn
to adjust the trained policy only when necessary. They can quickly generalize
to similar novel situations without affecting the part of the trained policy
that still works. To demonstrate the efficiency and efficacy of NAPPING, we
evaluate our method on four action domains that are different in reward
structures and the type of task. The domains are CartPole and MountainCar
(classic control), CrossRoad (path-finding), and AngryBirds (physical
reasoning). We compare NAPPING with standard online and fine-tuning DRL methods
in CartPole, MountainCar and CrossRoad, and state-of-the-art methods in the
more complicated AngryBirds domain. Our evaluation results demonstrate that
with our proposed method, DRL agents can rapidly and effectively adjust to a
wide range of novel situations across all tested domains.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11142" title="Abstract">arXiv:2312.11142</a> [<a href="/pdf/2312.11142" title="Download PDF">pdf</a>, <a href="/format/2312.11142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency-oriented approaches for self-supervised speech representation  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lugo%2C+L">Luis Lugo</a>, 
<a href="/search/cs?searchtype=author&query=Vielzeuf%2C+V">Valentin Vielzeuf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Self-supervised learning enables the training of large neural models without
the need for large, labeled datasets. It has been generating breakthroughs in
several fields, including computer vision, natural language processing,
biology, and speech. In particular, the state-of-the-art in several speech
processing applications, such as automatic speech recognition or speaker
identification, are models where the latent representation is learned using
self-supervised approaches. Several configurations exist in self-supervised
learning for speech, including contrastive, predictive, and multilingual
approaches. There is, however, a crucial limitation in most existing
approaches: their high computational costs. These costs limit the deployment of
models, the size of the training dataset, and the number of research groups
that can afford research with large self-supervised models. Likewise, we should
consider the environmental costs that high energy consumption implies. Efforts
in this direction comprise optimization of existing models, neural architecture
efficiency, improvements in finetuning for speech processing tasks, and data
efficiency. But despite current efforts, more work could be done to address
high computational costs in self-supervised representation learning.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11143" title="Abstract">arXiv:2312.11143</a> [<a href="/pdf/2312.11143" title="Download PDF">pdf</a>, <a href="/format/2312.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Domain-Independent Heuristics for Grounded and Lifted Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Dillon Z. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Trevizan%2C+F">Felipe Trevizan</a>, 
<a href="/search/cs?searchtype=author&query=Thiebaux%2C+S">Sylvie Thiebaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We present three novel graph representations of planning tasks suitable for
learning domain-independent heuristics using Graph Neural Networks (GNNs) to
guide search. In particular, to mitigate the issues caused by large grounded
GNNs we present the first method for learning domain-independent heuristics
with only the lifted representation of a planning task. We also provide a
theoretical analysis of the expressiveness of our models, showing that some are
more powerful than STRIPS-HGN, the only other existing model for learning
domain-independent heuristics. Our experiments show that our heuristics
generalise to much larger problems than those in the training set, vastly
surpassing STRIPS-HGN heuristics.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11144" title="Abstract">arXiv:2312.11144</a> [<a href="/pdf/2312.11144" title="Download PDF">pdf</a>, <a href="/format/2312.11144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSDvis: Hallucinatory Data Visualisations in Real World Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kouts%2C+A">Ari Kouts</a>, 
<a href="/search/cs?searchtype=author&query=Besan%C3%A7on%2C+L">Lonni Besan&#xe7;on</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmair%2C+M">Michael Sedlmair</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Benjamin Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the alt.VIS workshop at IEEE VIS 2023: <a href="https://altvis.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We propose the concept of "LSDvis": the (highly exaggerated) visual blending
of situated visualisations and the real-world environment to produce data
representations that resemble hallucinations. Such hallucinatory visualisations
incorporate elements of the physical environment, twisting and morphing their
appearance such that they become part of the visualisation itself. We
demonstrate LSDvis in a ``proof of proof of concept'', where we use Stable
Diffusion to modify images of real environments with abstract data
visualisations as input. We conclude by discussing considerations of LSDvis. We
hope that our work promotes visualisation designs which deprioritise saliency
in favour of quirkiness and ambience.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11146" title="Abstract">arXiv:2312.11146</a> [<a href="/pdf/2312.11146" title="Download PDF">pdf</a>, <a href="/format/2312.11146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OsmLocator: locating overlapping scatter marks by simulated annealing on  clustering-based re-visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pizurica%2C+A">Aleksandra Pizurica</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Q">Qi Ming</a>, 
<a href="/search/cs?searchtype=author&query=Nadisic%2C+N">Nicolas Nadisic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated mark localization in scatter images, greatly helpful for
discovering knowledge and understanding enormous document images and reasoning
in visual question answering AI systems, is a highly challenging problem
because of the ubiquity of overlapping marks. Locating overlapping marks faces
many difficulties such as no texture, less contextual information, hallow shape
and tiny size. Here, we formulate it as a combinatorial optimization problem on
clustering-based re-visualization, to locate scatter marks by finding the
status of multi-variables when an objective function reaches a minimum. The
objective function is constructed on difference between binarized scatter
images and corresponding re-visualization based on their clustering.
Fundamentally, re-visualization tries to redraw a new scatter graph only taking
a rasterized scatter image as an input, and clustering is employed to provide
the information for such re-visualization. This method could stably locate
severely-overlapping, variable-size and variable-shape marks in scatter images
without dependence of any training dataset or reference. Meanwhile, we propose
an adaptive variant of simulated annealing which can works on various connected
regions. In addition, we especially built a dataset named SML2023 containing
hundreds of scatter images with different markers and various levels of
overlapping severity, and tested the proposed method and compared it to
existing methods. The results show that it can accurately locate most marks in
scatter images with different overlapping severity and marker types, with about
0.3 absolute increase on an assignment-cost-based metric in comparison with
state-of-the-art methods. This work is of value to data mining on massive web
pages and literatures, and shedding new light on image measurement such as
bubble counting.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11152" title="Abstract">arXiv:2312.11152</a> [<a href="/pdf/2312.11152" title="Download PDF">pdf</a>, <a href="/format/2312.11152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Based Tri-Channel Graph Convolution Neural Network for Aspect  Sentiment Triplet Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiaqian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S.Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect Sentiment Triplet Extraction (ASTE) is an emerging task to extract a
given sentence's triplets, which consist of aspects, opinions, and sentiments.
Recent studies tend to address this task with a table-filling paradigm, wherein
word relations are encoded in a two-dimensional table, and the process involves
clarifying all the individual cells to extract triples. However, these studies
ignore the deep interaction between neighbor cells, which we find quite helpful
for accurate extraction. To this end, we propose a novel model for the ASTE
task, called Prompt-based Tri-Channel Graph Convolution Neural Network
(PT-GCN), which converts the relation table into a graph to explore more
comprehensive relational information. Specifically, we treat the original table
cells as nodes and utilize a prompt attention score computation module to
determine the edges' weights. This enables us to construct a target-aware
grid-like graph to enhance the overall extraction process. After that, a
triple-channel convolution module is conducted to extract precise sentiment
knowledge. Extensive experiments on the benchmark datasets show that our model
achieves state-of-the-art performance. The code is available at
https://github.com/KunPunCN/PT-GCN.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11153" title="Abstract">arXiv:2312.11153</a> [<a href="/pdf/2312.11153" title="Download PDF">pdf</a>, <a href="/format/2312.11153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on Multilingual Natural Scene Text Detection Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Natural scene text detection is a significant challenge in computer vision,
with tremendous potential applications in multilingual, diverse, and complex
text scenarios. We propose a multilingual text detection model to address the
issues of low accuracy and high difficulty in detecting multilingual text in
natural scenes. In response to the challenges posed by multilingual text images
with multiple character sets and various font styles, we introduce the SFM Swin
Transformer feature extraction network to enhance the model's robustness in
detecting characters and fonts across different languages. Dealing with the
considerable variation in text scales and complex arrangements in natural scene
text images, we present the AS-HRFPN feature fusion network by incorporating an
Adaptive Spatial Feature Fusion module and a Spatial Pyramid Pooling module.
The feature fusion network improvements enhance the model's ability to detect
text sizes and orientations. Addressing diverse backgrounds and font variations
in multilingual scene text images is a challenge for existing methods. Limited
local receptive fields hinder detection performance. To overcome this, we
propose a Global Semantic Segmentation Branch, extracting and preserving global
features for more effective text detection, aligning with the need for
comprehensive information. In this study, we collected and built a real-world
multilingual natural scene text image dataset and conducted comprehensive
experiments and analyses. The experimental results demonstrate that the
proposed algorithm achieves an F-measure of 85.02\%, which is 4.71\% higher
than the baseline model. We also conducted extensive cross-dataset validation
on MSRA-TD500, ICDAR2017MLT, and ICDAR2015 datasets to verify the generality of
our approach. The code and dataset can be found at
https://github.com/wangmelon/CEMLT.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11157" title="Abstract">arXiv:2312.11157</a> [<a href="/pdf/2312.11157" title="Download PDF">pdf</a>, <a href="/format/2312.11157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank non-convex norm method for multiview graph clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahir%2C+A">Alaeddine Zahir</a>, 
<a href="/search/cs?searchtype=author&query=Jbilou%2C+K">Khalide Jbilou</a>, 
<a href="/search/cs?searchtype=author&query=Ratnani%2C+A">Ahmed Ratnani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This study introduces a novel technique for multi-view clustering known as
the "Consensus Graph-Based Multi-View Clustering Method Using Low-Rank
Non-Convex Norm" (CGMVC-NC). Multi-view clustering is a challenging task in
machine learning as it requires the integration of information from multiple
data sources or views to cluster data points accurately. The suggested approach
makes use of the structural characteristics of multi-view data tensors,
introducing a non-convex tensor norm to identify correlations between these
views. In contrast to conventional methods, this approach demonstrates superior
clustering accuracy across several benchmark datasets. Despite the non-convex
nature of the tensor norm used, the proposed method remains amenable to
efficient optimization using existing algorithms. The approach provides a
valuable tool for multi-view data analysis and has the potential to enhance our
understanding of complex systems in various fields. Further research can
explore the application of this method to other types of data and extend it to
other machine-learning tasks.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11158" title="Abstract">arXiv:2312.11158</a> [<a href="/pdf/2312.11158" title="Download PDF">pdf</a>, <a href="/format/2312.11158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interventionally Consistent Surrogates for Agent-based Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dyer%2C+J">Joel Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Bishop%2C+N">Nicholas Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Felekis%2C+Y">Yorgos Felekis</a>, 
<a href="/search/cs?searchtype=author&query=Zennaro%2C+F+M">Fabio Massimo Zennaro</a>, 
<a href="/search/cs?searchtype=author&query=Calinescu%2C+A">Anisoara Calinescu</a>, 
<a href="/search/cs?searchtype=author&query=Damoulas%2C+T">Theodoros Damoulas</a>, 
<a href="/search/cs?searchtype=author&query=Wooldridge%2C+M">Michael Wooldridge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Agent-based simulators provide granular representations of complex
intelligent systems by directly modelling the interactions of the system's
constituent agents. Their high-fidelity nature enables hyper-local policy
evaluation and testing of what-if scenarios, but is associated with large
computational costs that inhibits their widespread use. Surrogate models can
address these computational limitations, but they must behave consistently with
the agent-based model under policy interventions of interest. In this paper, we
capitalise on recent developments on causal abstractions to develop a framework
for learning interventionally consistent surrogate models for agent-based
simulators. Our proposed approach facilitates rapid experimentation with policy
interventions in complex systems, while inducing surrogates to behave
consistently with high probability with respect to the agent-based simulator
across interventions of interest. We demonstrate with empirical studies that
observationally trained surrogates can misjudge the effect of interventions and
misguide policymakers towards suboptimal policies, while surrogates trained for
interventional consistency with our proposed method closely mimic the behaviour
of an agent-based model under interventions of interest.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11160" title="Abstract">arXiv:2312.11160</a> [<a href="/pdf/2312.11160" title="Download PDF">pdf</a>, <a href="/format/2312.11160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Sensing and Localization in an Aircraft Cabin Using a Wireless  Communication Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geyer%2C+F">Fabien Geyer</a>, 
<a href="/search/cs?searchtype=author&query=Multerer%2C+T">Thomas Multerer</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+P">Paulo Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Schupke%2C+D">Dominic Schupke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Advances in wireless localization techniques aiming to exploit
context-dependent data has been leading to a growing interest in services able
of localizing or tracking targets inside buildings with high accuracy and
precision. Hence, the demand for indoor localization services has become a key
prerequisite in some markets, such as in the aviation sector. In this context,
we propose a system to passively localize and track passenger movements inside
the cabin of an aircraft in a privacy preserving way using existing
communication networks such as Wi-Fi or 5G. The estimated passenger positions
can be used for various automation tasks such as measurement of passenger
behavior during boarding. The paper describes a novel wireless localization
system, based on Artificial Neural Networks, which passively senses the
location of passengers. The position estimation is based on the observation of
wireless communication signals that are already present in the environment. In
this context, "passive" means that no additional devices are needed for the
passengers. Experimental results show that the proposed system is able to
achieve an average accuracy of 12 cm in a challenging environment like an
aircraft cabin. This accuracy seems sufficient to control passenger separation.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11163" title="Abstract">arXiv:2312.11163</a> [<a href="/pdf/2312.11163" title="Download PDF">pdf</a>, <a href="/format/2312.11163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Aware Hierarchical Control of Joint Velocities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wittmann%2C+J">Jonas Wittmann</a>, 
<a href="/search/cs?searchtype=author&query=Hornung%2C+D">Daniel Hornung</a>, 
<a href="/search/cs?searchtype=author&query=Griesbauer%2C+K">Korbinian Griesbauer</a>, 
<a href="/search/cs?searchtype=author&query=Rixen%2C+D">Daniel Rixen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nowadays, robots are applied in dynamic environments. For a robust operation,
the motion planning module must consider other tasks besides reaching a
specified pose: (self) collision avoidance, joint limit avoidance, keeping an
advantageous configuration, etc. Each task demands different joint control
commands, which may counteract each other. We present a hierarchical control
that, depending on the robot and environment state, determines online a
suitable priority among those tasks. Thereby, the control command of a
lower-prioritized task never hinders the control command of a
higher-prioritized task. We ensure smooth control signals also during priority
rearrangement. Our hierarchical control computes reference joint velocities.
However, the underlying concepts of hierarchical control differ when using
joint accelerations or joint torques as control signals instead. So, as a
further contribution, we provide a comprehensive discussion on how joint
velocity control, joint acceleration control, and joint torque control differ
in hierarchical task control. We validate our formulation in an experiment on
hardware.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11166" title="Abstract">arXiv:2312.11166</a> [<a href="/pdf/2312.11166" title="Download PDF">pdf</a>, <a href="/format/2312.11166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Transformers for Learning Parametrized Hamiltonian  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brantner%2C+B">Benedikt Brantner</a>, 
<a href="/search/math?searchtype=author&query=de+Romemont%2C+G">Guillaume de Romemont</a>, 
<a href="/search/math?searchtype=author&query=Kraus%2C+M">Michael Kraus</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zeyuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Two of the many trends in neural network research of the past few years have
been (i) the learning of dynamical systems, especially with recurrent neural
networks such as long short-term memory networks (LSTMs) and (ii) the
introduction of transformer neural networks for natural language processing
(NLP) tasks. Both of these trends have created enormous amounts of traction,
particularly the second one: transformer networks now dominate the field of
NLP. Even though some work has been performed on the intersection of these two
trends, this work was largely limited to using the vanilla transformer directly
without adjusting its architecture for the setting of a physical system. In
this work we use a transformer-inspired neural network to learn a complicated
non-linear dynamical system and furthermore (for the first time) imbue it with
structure-preserving properties to improve long-term stability. This is shown
to be extremely important when applying the neural network to real world
applications.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11171" title="Abstract">arXiv:2312.11171</a> [<a href="/pdf/2312.11171" title="Download PDF">pdf</a>, <a href="/format/2312.11171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniDCP: Unifying Multiple Medical Vision-language Tasks via Dynamic  Cross-modal Learnable Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+C">Chenlu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yufei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical vision-language pre-training (Med-VLP) models have recently
accelerated the fast-growing medical diagnostics application. However, most
Med-VLP models learn task-specific representations independently from scratch,
thereby leading to great inflexibility when they work across multiple
fine-tuning tasks. In this work, we propose UniDCP, a Unified medical
vision-language model with Dynamic Cross-modal learnable Prompts, which can be
plastically applied to multiple medical vision-language tasks. Specifically, we
explicitly construct a unified framework to harmonize diverse inputs from
multiple pretraining tasks by leveraging cross-modal prompts for unification,
which accordingly can accommodate heterogeneous medical fine-tuning tasks.
Furthermore, we conceive a dynamic cross-modal prompt optimizing strategy that
optimizes the prompts within the shareable space for implicitly processing the
shareable clinic knowledge. UniDCP is the first Med-VLP model capable of
performing all 8 medical uni-modal and cross-modal tasks over 14 corresponding
datasets, consistently yielding superior results over diverse state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11176" title="Abstract">arXiv:2312.11176</a> [<a href="/pdf/2312.11176" title="Download PDF">pdf</a>, <a href="/format/2312.11176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Neural Operators with Automatically Encoded  Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yiming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Klower%2C+M">Milan Klower</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Neural operators (NOs) have emerged as effective tools for modeling complex
physical systems in scientific machine learning. In NOs, a central
characteristic is to learn the governing physical laws directly from data. In
contrast to other machine learning applications, partial knowledge is often
known a priori about the physical system at hand whereby quantities such as
mass, energy and momentum are exactly conserved. Currently, NOs have to learn
these conservation laws from data and can only approximately satisfy them due
to finite training data and random noise. In this work, we introduce
conservation law-encoded neural operators (clawNOs), a suite of NOs that endow
inference with automatic satisfaction of such conservation laws. ClawNOs are
built with a divergence-free prediction of the solution field, with which the
continuity equation is automatically guaranteed. As a consequence, clawNOs are
compliant with the most fundamental and ubiquitous conservation laws essential
for correct physical consistency. As demonstrations, we consider a wide variety
of scientific applications ranging from constitutive modeling of material
deformation, incompressible fluid dynamics, to atmospheric simulation. ClawNOs
significantly outperform the state-of-the-art NOs in learning efficacy,
especially in small-data regimes.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11177" title="Abstract">arXiv:2312.11177</a> [<a href="/pdf/2312.11177" title="Download PDF">pdf</a>, <a href="/format/2312.11177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modified Neumann-Neumann methods for semi- and quasilinear elliptic  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Engstr%C3%B6m%2C+E">Emil Engstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=Hansen%2C+E">Eskil Hansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Neumann--Neumann method is a commonly employed domain decomposition
method for linear elliptic equations. However, the method exhibits slow
convergence when applied to semilinear equations and does not seem to converge
at all for certain quasilinear equations. We therefore propose two modified
Neumann--Neumann methods that have better convergence properties and require
less computations. We provide numerical results that show the advantages of
these methods when applied to both semilinear and quasilinear equations. We
also prove linear convergence with mesh-independent error reduction under
certain assumptions on the equation. The analysis is carried out on general
Lipschitz domains and relies on the theory of nonlinear Steklov--Poincar\'e
operators.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11184" title="Abstract">arXiv:2312.11184</a> [<a href="/pdf/2312.11184" title="Download PDF">pdf</a>, <a href="/format/2312.11184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View Transition based Dual Camera Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tiantian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunli Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xinyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weixin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The dual camera system of wide-angle ($\bf{W}$) and telephoto ($\bf{T}$)
cameras has been widely adopted by popular phones. In the overlap region,
fusing the $\bf{W}$ and $\bf{T}$ images can generate a higher quality image.
Related works perform pixel-level motion alignment or high-dimensional feature
alignment of the $\bf{T}$ image to the view of the $\bf{W}$ image and then
perform image/feature fusion, but the enhancement in occlusion area is
ill-posed and can hardly utilize data from $\bf{T}$ images. Our insight is to
minimize the occlusion area and thus maximize the use of pixels from $\bf{T}$
images. Instead of insisting on placing the output in the $\bf{W}$ view, we
propose a view transition method to transform both $\bf{W}$ and $\bf{T}$ images
into a mixed view and then blend them into the output. The transformation ratio
is kept small and not apparent to users, and the center area of the output,
which has accumulated a sufficient amount of transformation, can directly use
the contents from the T view to minimize occlusions. Experimental results show
that, in comparison with the SOTA methods, occlusion area is largely reduced by
our method and thus more pixels of the $\bf{T}$ image can be used for improving
the quality of the output image.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11186" title="Abstract">arXiv:2312.11186</a> [<a href="/pdf/2312.11186" title="Download PDF">pdf</a>, <a href="/ps/2312.11186" title="Download PostScript">ps</a>, <a href="/format/2312.11186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An epistemic logic for modeling decisions in the context of incomplete  knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markovi%C4%87%2C+%C4%90">&#x110;or&#x111;e Markovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Vandevelde%2C+S">Simon Vandevelde</a>, 
<a href="/search/cs?searchtype=author&query=Vanbesien%2C+L">Linde Vanbesien</a>, 
<a href="/search/cs?searchtype=author&query=Vennekens%2C+J">Joost Vennekens</a>, 
<a href="/search/cs?searchtype=author&query=Denecker%2C+M">Marc Denecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, to be published as a poster version in the ACM/SIGAPP conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Substantial efforts have been made in developing various Decision Modeling
formalisms, both from industry and academia. A challenging problem is that of
expressing decision knowledge in the context of incomplete knowledge. In such
contexts, decisions depend on what is known or not known. We argue that none of
the existing formalisms for modeling decisions are capable of correctly
capturing the epistemic nature of such decisions, inevitably causing issues in
situations of uncertainty. This paper presents a new language for modeling
decisions with incomplete knowledge. It combines three principles:
stratification, autoepistemic logic, and definitions. A knowledge base in this
language is a hierarchy of epistemic theories, where each component theory may
epistemically reason on the knowledge in lower theories, and decisions are made
using definitions with epistemic conditions.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11187" title="Abstract">arXiv:2312.11187</a> [<a href="/pdf/2312.11187" title="Download PDF">pdf</a>, <a href="/format/2312.11187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Asynchronous Service Provisioning in the Edge-Cloud  Multi-tier Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+I">Itamar Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Giaccone%2C+P">Paolo Giaccone</a>, 
<a href="/search/cs?searchtype=author&query=Chiasserini%2C+C+F">Carla Fabiana Chiasserini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.00184">arXiv:2305.00184</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In an edge-cloud multi-tier network, datacenters provide services to mobile
users, with each service having specific latency constraints and computational
requirements. Deploying such a variety of services while matching their
requirements with the available computing resources is challenging. In
addition, time-critical services may have to be migrated as the users move, to
keep fulfilling their latency constraints. Unlike previous work relying on an
orchestrator with an always-updated global view of the available resources and
the users' locations, this work envisions a distributed solution to the above
problems. In particular, we propose a distributed asynchronous framework for
service deployment in the edge-cloud that increases the system resilience by
avoiding a single point of failure, as in the case of a central orchestrator.
Our solution ensures cost-efficient feasible placement of services, while using
negligible bandwidth. Our results, obtained through trace-driven, large-scale
simulations, show that the proposed solution provides performance very close to
those obtained by state-of-the-art centralized solutions, and at the cost of a
small communication overhead.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11190" title="Abstract">arXiv:2312.11190</a> [<a href="/pdf/2312.11190" title="Download PDF">pdf</a>, <a href="/format/2312.11190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Interfaces with AI for Enhanced User Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunpeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Y">Yiheng Bian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yongtao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongmin Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study introduces an innovative framework designed to automate tasks by
interacting with UIs through a sequential, human-like problem-solving approach.
Our approach initially transforms UI screenshots into natural language
explanations through a vision-based UI analysis, circumventing traditional view
hierarchy limitations. It then methodically engages with each interface,
guiding the LLM to pinpoint and act on relevant UI elements, thus bolstering
both precision and functionality. Employing the ERNIE Bot LLM, our approach has
been demonstrated to surpass existing methodologies. It delivers superior UI
interpretation across various datasets and exhibits remarkable efficiency in
automating varied tasks on an Android smartphone, outperforming human
capabilities in intricate tasks and significantly enhancing the PBD process.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11193" title="Abstract">arXiv:2312.11193</a> [<a href="/pdf/2312.11193" title="Download PDF">pdf</a>, <a href="/ps/2312.11193" title="Download PostScript">ps</a>, <a href="/format/2312.11193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chinese version of this paper can be downloaded from (<a href="https://cloud.tsinghua.edu.cn/d/5894ec4442e54a6aac96/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although LLMs continue to iterate and improve, most open-source models still
have a context window of no more than 4k, limiting their ability to handle
long-context problems. Most existing open-source models for long-context chat
still lack satisfactory accuracy. To address this issue, I approach it from the
perspective of training data and theoretically prove that training the
capability to handle long contexts requires "effective" rather than "long"
data. Based on this, I propose using the "original text paraphrase" task, and
successfully extend the context window of the existing model to 32k by a
low-cost and effective method, achieving extremely high accuracy in
multi-document-QA and surpassing all existing open-source models of the same
scale. The model and training data have been open-sourced on HuggingFace and
WiseModel.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11194" title="Abstract">arXiv:2312.11194</a> [<a href="/pdf/2312.11194" title="Download PDF">pdf</a>, <a href="/format/2312.11194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Imperfect Demonstrations through Dynamics Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+X">Xizhou Bu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiqiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengxiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Panfeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Standard imitation learning usually assumes that demonstrations are drawn
from an optimal policy distribution. However, in real-world scenarios, every
human demonstration may exhibit nearly random behavior and collecting
high-quality human datasets can be quite costly. This requires imitation
learning can learn from imperfect demonstrations to obtain robotic policies
that align human intent. Prior work uses confidence scores to extract useful
information from imperfect demonstrations, which relies on access to ground
truth rewards or active human supervision. In this paper, we propose a
dynamics-based method to evaluate the data confidence scores without above
efforts. We develop a generalized confidence-based imitation learning framework
called Confidence-based Inverse soft-Q Learning (CIQL), which can employ
different optimal policy matching methods by simply changing object functions.
Experimental results show that our confidence evaluation method can increase
the success rate by $40.3\%$ over the original algorithm and $13.5\%$ over the
simple noise filtering.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11195" title="Abstract">arXiv:2312.11195</a> [<a href="/pdf/2312.11195" title="Download PDF">pdf</a>, <a href="/format/2312.11195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Age Contrastive Learning for Age-Invariant Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+V">Victor Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chang-Tsun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-age facial images are typically challenging and expensive to collect,
making noise-free age-oriented datasets relatively small compared to
widely-used large-scale facial datasets. Additionally, in real scenarios,
images of the same subject at different ages are usually hard or even
impossible to obtain. Both of these factors lead to a lack of supervised data,
which limits the versatility of supervised methods for age-invariant face
recognition, a critical task in applications such as security and biometrics.
To address this issue, we propose a novel semi-supervised learning approach
named Cross-Age Contrastive Learning (CACon). Thanks to the identity-preserving
power of recent face synthesis models, CACon introduces a new contrastive
learning method that leverages an additional synthesized sample from the input
image. We also propose a new loss function in association with CACon to perform
contrastive learning on a triplet of samples. We demonstrate that our method
not only achieves state-of-the-art performance in homogeneous-dataset
experiments on several age-invariant face recognition benchmarks but also
outperforms other methods by a large margin in cross-dataset experiments.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11198" title="Abstract">arXiv:2312.11198</a> [<a href="/pdf/2312.11198" title="Download PDF">pdf</a>, <a href="/format/2312.11198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signed Graph Neural Ordinary Differential Equation for Modeling  Continuous-time Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lanlan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modeling continuous-time dynamics constitutes a foundational challenge, and
uncovering inter-component correlations within complex systems holds promise
for enhancing the efficacy of dynamic modeling. The prevailing approach of
integrating graph neural networks with ordinary differential equations has
demonstrated promising performance. However, they disregard the crucial signed
information intrinsic to graphs, impeding their capacity to accurately capture
real-world phenomena and leading to subpar outcomes.
<br />In response, we introduce a novel approach: a signed graph neural ordinary
differential equation, adeptly addressing the limitations of miscapturing
signed information. Our proposed solution boasts both flexibility and
efficiency. To substantiate its effectiveness, we seamlessly integrate our
devised strategies into three preeminent graph-based dynamic modeling
frameworks: graph neural ordinary differential equations, graph neural
controlled differential equations, and graph recurrent neural networks.
Rigorous assessments encompass three intricate dynamic scenarios from physics
and biology, as well as scrutiny across four authentic real-world traffic
datasets. Remarkably outperforming the trio of baselines, empirical results
underscore the substantial performance enhancements facilitated by our proposed
approach.Our code can be found at https://github.com/beautyonce/SGODE.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11207" title="Abstract">arXiv:2312.11207</a> [<a href="/pdf/2312.11207" title="Download PDF">pdf</a>, <a href="/format/2312.11207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized traffic management of autonomous drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%C3%A1zs%2C+B">Boldizs&#xe1;r Bal&#xe1;zs</a>, 
<a href="/search/cs?searchtype=author&query=Vicsek%2C+T">Tam&#xe1;s Vicsek</a>, 
<a href="/search/cs?searchtype=author&query=Somorjai%2C+G">Gerg&#x151; Somorjai</a>, 
<a href="/search/cs?searchtype=author&query=Nepusz%2C+T">Tam&#xe1;s Nepusz</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A1s%C3%A1rhelyi%2C+G">G&#xe1;bor V&#xe1;s&#xe1;rhelyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 7 figures, submitted to Swarm Intelligence on 20 January 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Coordination of local and global aerial traffic has become a legal and
technological bottleneck as the number of unmanned vehicles in the common
airspace continues to grow. To meet this challenge, automation and
decentralization of control is an unavoidable requirement. In this paper, we
present a solution that enables self-organization of cooperating autonomous
agents into an effective traffic flow state in which the common aerial
coordination task - filled with conflicts - is resolved. Using realistic
simulations, we show that our algorithm is safe, efficient, and scalable
regarding the number of drones and their speed range, while it can also handle
heterogeneous agents and even pairwise priorities between them. The algorithm
works in any sparse or dense traffic scenario in two dimensions and can be made
increasingly efficient by a layered flight space structure in three dimensions.
To support the feasibility of our solution, we experimentally demonstrate
coordinated aerial traffic of 100 autonomous drones within a circular area with
a radius of 125 meters.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11213" title="Abstract">arXiv:2312.11213</a> [<a href="/pdf/2312.11213" title="Download PDF">pdf</a>, <a href="/format/2312.11213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAKEPCD: Fake Point Cloud Detection via Source Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yiting Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 19th ACM ASIA Conference on Computer and Communications Security, July 1-5, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">To prevent the mischievous use of synthetic (fake) point clouds produced by
generative models, we pioneer the study of detecting point cloud authenticity
and attributing them to their sources. We propose an attribution framework,
FAKEPCD, to attribute (fake) point clouds to their respective generative models
(or real-world collections). The main idea of FAKEPCD is to train an
attribution model that learns the point cloud features from different sources
and further differentiates these sources using an attribution signal. Depending
on the characteristics of the training point clouds, namely, sources and
shapes, we formulate four attribution scenarios: close-world, open-world,
single-shape, and multiple-shape, and evaluate FAKEPCD's performance in each
scenario. Extensive experimental results demonstrate the effectiveness of
FAKEPCD on source attribution across different scenarios. Take the open-world
attribution as an example, FAKEPCD attributes point clouds to known sources
with an accuracy of 0.82-0.98 and to unknown sources with an accuracy of
0.73-1.00. Additionally, we introduce an approach to visualize unique patterns
(fingerprints) in point clouds associated with each source. This explains how
FAKEPCD recognizes point clouds from various sources by focusing on distinct
areas within them. Overall, we hope our study establishes a baseline for the
source attribution of (fake) point clouds.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11214" title="Abstract">arXiv:2312.11214</a> [<a href="/pdf/2312.11214" title="Download PDF">pdf</a>, <a href="/format/2312.11214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Gradient Explosion in Generative Adversarial Imitation  Learning: A Probabilistic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wanying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yirui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaomin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yaxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yangchun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Adversarial Imitation Learning (GAIL) stands as a cornerstone
approach in imitation learning. This paper investigates the gradient explosion
in two types of GAIL: GAIL with deterministic policy (DE-GAIL) and GAIL with
stochastic policy (ST-GAIL). We begin with the observation that the training
can be highly unstable for DE-GAIL at the beginning of the training phase and
end up divergence. Conversely, the ST-GAIL training trajectory remains
consistent, reliably converging. To shed light on these disparities, we provide
an explanation from a theoretical perspective. By establishing a probabilistic
lower bound for GAIL, we demonstrate that gradient explosion is an inevitable
outcome for DE-GAIL due to occasionally large expert-imitator policy disparity,
whereas ST-GAIL does not have the issue with it. To substantiate our assertion,
we illustrate how modifications in the reward function can mitigate the
gradient explosion challenge. Finally, we propose CREDO, a simple yet effective
strategy that clips the reward function during the training phase, allowing the
GAIL to enjoy high data efficiency and stable trainability.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11218" title="Abstract">arXiv:2312.11218</a> [<a href="/pdf/2312.11218" title="Download PDF">pdf</a>, <a href="/format/2312.11218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Knowledge with Ensemble Learning for Online Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+B">Baitan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Offline distillation is a two-stage pipeline that requires expensive
resources to train a teacher network and then distill the knowledge to a
student for deployment. Online knowledge distillation, on the other hand, is a
one-stage strategy that alleviates the requirement with mutual learning and
collaborative learning. Recent peer collaborative learning (PCL) integrates
online ensemble, collaboration of base networks and temporal mean teacher to
construct effective knowledge. However, the model collapses occasionally in PCL
due to high homogenization between the student and the teacher. In this paper,
the cause of the high homogenization is analyzed and the solution is presented.
A decoupled knowledge for online knowledge distillation is generated by an
independent teacher, separate from the student. Such design can increase the
diversity between the networks and reduce the possibility of model collapse. To
obtain early decoupled knowledge, an initialization scheme for the teacher is
devised, and a 2D geometry-based analysis experiment is conducted under ideal
conditions to showcase the effectiveness of this scheme. Moreover, to improve
the teacher's supervisory resilience, a decaying ensemble scheme is devised. It
assembles the knowledge of the teacher to which a dynamic weight which is large
at the start of the training and gradually decreases with the training process
is assigned. The assembled knowledge serves as a strong teacher during the
early training and the decreased-weight-assembled knowledge can eliminate the
distribution deviation under the potentially overfitted teacher's supervision.
A Monte Carlo-based simulation is conducted to evaluate the convergence.
Extensive experiments on CIFAR-10, CIFAR-100 and TinyImageNet show the
superiority of our method. Ablation studies and further analysis demonstrate
the effectiveness.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11219" title="Abstract">arXiv:2312.11219</a> [<a href="/pdf/2312.11219" title="Download PDF">pdf</a>, <a href="/format/2312.11219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalised Adaptive Cross Approximation for Convolution Quadrature  based Boundary Element Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haider%2C+A+M">A.M. Haider</a>, 
<a href="/search/math?searchtype=author&query=Rjasanow%2C+S">S. Rjasanow</a>, 
<a href="/search/math?searchtype=author&query=Schanz%2C+M">M. Schanz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The acoustic wave equation is solved in time domain with a boundary element
formulation. The time discretisation is performed with the generalised
convolution quadrature method and for the spatial approximation standard lowest
order elements are used. Collocation and Galerkin methods are applied. In the
interest of increasing the efficiency of the boundary element method, a
low-rank approximation such as the adaptive cross approximation (ACA) is
carried out. We discuss about a generalisation of the ACA to approximate a
three-dimensional array of data, i.e., usual boundary element matrices at
several complex frequencies. This method is used within the generalised
convolution quadrature (CQ) method to obtain a real time domain formulation.
The behaviour of the proposed method is studied with three examples, a unit
cube, a unit cube with a reentrant corner, and a unit ball. The properties of
the method are preserved in the data sparse representation and a significant
reduction in storage is obtained.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11220" title="Abstract">arXiv:2312.11220</a> [<a href="/pdf/2312.11220" title="Download PDF">pdf</a>, <a href="/format/2312.11220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of federated learning in renewable energy applications:  Potential, challenges, and future directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grataloup%2C+A">Albin Grataloup</a>, 
<a href="/search/cs?searchtype=author&query=Jonas%2C+S">Stefan Jonas</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+A">Angela Meyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)

</div>
<p class="mathjax">Federated learning has recently emerged as a privacy-preserving distributed
machine learning approach. Federated learning enables collaborative training of
multiple clients and entire fleets without sharing the involved training
datasets. By preserving data privacy, federated learning has the potential to
overcome the lack of data sharing in the renewable energy sector which is
inhibiting innovation, research and development. Our paper provides an overview
of federated learning in renewable energy applications. We discuss federated
learning algorithms and survey their applications and case studies in renewable
energy generation and consumption. We also evaluate the potential and the
challenges associated with federated learning applied in power and energy
contexts. Finally, we outline promising future research directions in federated
learning for applications in renewable energy.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11225" title="Abstract">arXiv:2312.11225</a> [<a href="/pdf/2312.11225" title="Download PDF">pdf</a>, <a href="/format/2312.11225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAD-MulW: A Multi-Window Anomaly Detection Framework for BGP Security  Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songtao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+X">Xincheng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+W">Wu Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shenhao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Z">Zhongyuan Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In recent years, various international security events have occurred
frequently and interacted between real society and cyberspace. Traditional
traffic monitoring mainly focuses on the local anomalous status of events due
to a large amount of data. BGP-based event monitoring makes it possible to
perform differential analysis of international events. For many existing
traffic anomaly detection methods, we have observed that the window-based noise
reduction strategy effectively improves the success rate of time series anomaly
detection. Motivated by this observation, we propose an unsupervised anomaly
detection model, MAD-MulW, which incorporates a multi-window serial framework.
Firstly, we design the W-GAT module to adaptively update the sample weights
within the window and retain the updated information of the trailing sample,
which not only reduces the outlier samples' noise but also avoids the space
consumption of data scale expansion. Then, the W-LAT module based on predictive
reconstruction both captures the trend of sample fluctuations over a certain
period of time and increases the interclass variation through the
reconstruction of the predictive sample. Our model has been experimentally
validated on multiple BGP anomalous events with an average F1 score of over
90\%, which demonstrates the significant improvement effect of the stage
windows and adaptive strategy on the efficiency and stability of the timing
model.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11226" title="Abstract">arXiv:2312.11226</a> [<a href="/pdf/2312.11226" title="Download PDF">pdf</a>, <a href="/ps/2312.11226" title="Download PostScript">ps</a>, <a href="/format/2312.11226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDRH Seeks Public Comment: Digital Health Technologies for Detecting  Prediabetes and Undiagnosed Type 2 Diabetes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cossio%2C+M">Manuel Cossio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Docket No. FDA-2023-N-4853
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This document provides responses to the FDA's request for public comments
(Docket No FDA 2023 N 4853) on the role of digital health technologies (DHTs)
in detecting prediabetes and undiagnosed type 2 diabetes. It explores current
DHT applications in prevention, detection, treatment and reversal of
prediabetes, highlighting AI chatbots, online forums, wearables and mobile
apps. The methods employed by DHTs to capture health signals like glucose,
diet, symptoms and community insights are outlined. Key subpopulations that
could benefit most from remote screening tools include rural residents,
minority groups, high-risk individuals and those with limited healthcare
access. Capturable high-impact risk factors encompass glycemic variability,
cardiovascular parameters, respiratory health, blood biomarkers and patient
reported symptoms. An array of non-invasive monitoring tools are discussed,
although further research into their accuracy for diverse groups is warranted.
Extensive health datasets providing immense opportunities for AI and ML based
risk modeling are presented. Promising techniques leveraging EHRs, imaging,
wearables and surveys to enhance screening through AI and ML algorithms are
showcased. Analysis of social media and streaming data further allows disease
prediction across populations. Ongoing innovation focused on inclusivity and
accessibility is highlighted as pivotal in unlocking DHTs potential for
transforming prediabetes and diabetes prevention and care.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11227" title="Abstract">arXiv:2312.11227</a> [<a href="/pdf/2312.11227" title="Download PDF">pdf</a>, <a href="/format/2312.11227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Active Measuring under Model Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krale%2C+M">Merlijn Krale</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%A3o%2C+T+D">Thiago D. Sim&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Tumova%2C+J">Jana Tumova</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Partial observability and uncertainty are common problems in sequential
decision-making that particularly impede the use of formal models such as
Markov decision processes (MDPs). However, in practice, agents may be able to
employ costly sensors to measure their environment and resolve partial
observability by gathering information. Moreover, imprecise transition
functions can capture model uncertainty. We combine these concepts and extend
MDPs to robust active-measuring MDPs (RAM-MDPs). We present an active-measure
heuristic to solve RAM-MDPs efficiently and show that model uncertainty can,
counterintuitively, let agents take fewer measurements. We propose a method to
counteract this behavior while only incurring a bounded additional cost. We
empirically compare our methods to several baselines and show their superior
scalability and performance.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11229" title="Abstract">arXiv:2312.11229</a> [<a href="/pdf/2312.11229" title="Download PDF">pdf</a>, <a href="/format/2312.11229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaseGNN: Graph Neural Networks for Legal Case Retrieval with  Text-Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yanran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Ruihong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Legal case retrieval is an information retrieval task in the legal domain,
which aims to retrieve relevant cases with a given query case. Recent research
of legal case retrieval mainly relies on traditional bag-of-words models and
language models. Although these methods have achieved significant improvement
in retrieval accuracy, there are still two challenges: (1) Legal structural
information neglect. Previous neural legal case retrieval models mostly encode
the unstructured raw text of case into a case representation, which causes the
lack of important legal structural information in a case and leads to poor case
representation; (2) Lengthy legal text limitation. When using the powerful
BERT-based models, there is a limit of input text lengths, which inevitably
requires to shorten the input via truncation or division with a loss of legal
context information. In this paper, a graph neural networks-based legal case
retrieval model, CaseGNN, is developed to tackle these challenges. To
effectively utilise the legal structural information during encoding, a case is
firstly converted into a Text-Attributed Case Graph (TACG), followed by a
designed Edge Graph Attention Layer and a readout function to obtain the case
graph representation. The CaseGNN model is optimised with a carefully designed
contrastive loss with easy and hard negative sampling. Since the text
attributes in the case graph come from individual sentences, the restriction of
using language models is further avoided without losing the legal context.
Extensive experiments have been conducted on two benchmarks from COLIEE 2022
and COLIEE 2023, which demonstrate that CaseGNN outperforms other
state-of-the-art legal case retrieval methods. The code has been released on
https://github.com/yanran-tang/CaseGNN.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11231" title="Abstract">arXiv:2312.11231</a> [<a href="/pdf/2312.11231" title="Download PDF">pdf</a>, <a href="/format/2312.11231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Feature Pyramid Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Weilin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yonggui Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The visual feature pyramid has proven its effectiveness and efficiency in
target detection tasks. Yet, current methodologies tend to overly emphasize
inter-layer feature interaction, neglecting the crucial aspect of intra-layer
feature adjustment. Experience underscores the significant advantages of
intra-layer feature interaction in enhancing target detection tasks. While some
approaches endeavor to learn condensed intra-layer feature representations
using attention mechanisms or visual transformers, they overlook the
incorporation of global information interaction. This oversight results in
increased false detections and missed targets.To address this critical issue,
this paper introduces the Global Feature Pyramid Network (GFPNet), an augmented
version of PAFPN that integrates global information for enhanced target
detection. Specifically, we leverage a lightweight MLP to capture global
feature information, utilize the VNC encoder to process these features, and
employ a parallel learnable mechanism to extract intra-layer features from the
input image. Building on this foundation, we retain the PAFPN method to
facilitate inter-layer feature interaction, extracting rich feature details
across various levels.Compared to conventional feature pyramids, GFPN not only
effectively focuses on inter-layer feature information but also captures global
feature details, fostering intra-layer feature interaction and generating a
more comprehensive and impactful feature representation. GFPN consistently
demonstrates performance improvements over object detection baselines.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11234" title="Abstract">arXiv:2312.11234</a> [<a href="/pdf/2312.11234" title="Download PDF">pdf</a>, <a href="/format/2312.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Musical Features for Interpretable Audio Tagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyberatos%2C+V">Vassilis Lyberatos</a>, 
<a href="/search/cs?searchtype=author&query=Kantarelis%2C+S">Spyridon Kantarelis</a>, 
<a href="/search/cs?searchtype=author&query=Dervakos%2C+E">Edmund Dervakos</a>, 
<a href="/search/cs?searchtype=author&query=Stamo%2C+G">Giorgos Stamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github Repository: <a href="https://github.com/vaslyb/perceptible-music-tagging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the age of music streaming platforms, the task of automatically tagging
music audio has garnered significant attention, driving researchers to devise
methods aimed at enhancing performance metrics on standard datasets. Most
recent approaches rely on deep neural networks, which, despite their impressive
performance, possess opacity, making it challenging to elucidate their output
for a given input. While the issue of interpretability has been emphasized in
other fields like medicine, it has not received attention in music-related
tasks. In this study, we explored the relevance of interpretability in the
context of automatic music tagging. We constructed a workflow that incorporates
three different information extraction techniques: a) leveraging symbolic
knowledge, b) utilizing auxiliary deep neural networks, and c) employing signal
processing to extract perceptual features from audio files. These features were
subsequently used to train an interpretable machine-learning model for tag
prediction. We conducted experiments on two datasets, namely the MTG-Jamendo
dataset and the GTZAN dataset. Our method surpassed the performance of baseline
models in both tasks and, in certain instances, demonstrated competitiveness
with the current state-of-the-art. We conclude that there are use cases where
the deterioration in performance is outweighed by the value of
interpretability.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11236" title="Abstract">arXiv:2312.11236</a> [<a href="/pdf/2312.11236" title="Download PDF">pdf</a>, <a href="/format/2312.11236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Round-optimal $n$-Block Broadcast Schedules in Logarithmic Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tr%C3%A4ff%2C+J+L">Jesper Larsson Tr&#xe4;ff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We give optimally fast $O(\log p)$ time (per processor) algorithms for
computing round-optimal broadcast schedules for message-passing parallel
computing systems. This affirmatively answers the questions posed in Tr\"aff
(2022). The problem is to broadcast $n$ indivisible blocks of data from a given
root processor to all other processors in a (subgraph of a) fully connected
network of $p$ processors with fully bidirectional, one-ported communication
capabilities. In this model, $n-1+\lceil\log_2 p\rceil$ communication rounds
are required. Our new algorithms compute for each processor in the network
receive and send schedules each of size $\lceil\log_2 p\rceil$ that determine
uniquely in $O(1)$ time for each communication round the new block that the
processor will receive, and the already received block it has to send. Schedule
computations are done independently per processor without communication. The
broadcast communication subgraph is the same, easily computable, directed,
$\lceil\log_2 p\rceil$-regular circulant graph used in Tr\"aff (2022) and
elsewhere. We show how the schedule computations can be done in optimal time
and space of $O(\log p)$, improving significantly over previous results of
$O(p\log^2 p)$ and $O(\log^3 p)$. The schedule computation and broadcast
algorithms are simple to implement, but correctness and complexity are not
obvious. All algorithms have been implemented, compared to previous algorithms,
and briefly evaluated on a small $36\times 32$ processor-core cluster.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11240" title="Abstract">arXiv:2312.11240</a> [<a href="/pdf/2312.11240" title="Download PDF">pdf</a>, <a href="/format/2312.11240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Barlow Twins and VICReg self-supervised learning for sound  patterns of bird and anuran species
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dias%2C+F+F">F&#xe1;bio Felix Dias</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+M+A">Moacir Antonelli Ponti</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+M+C">M&#xed;lton Cezar Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Minghim%2C+R">Rosane Minghim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Taking advantage of the structure of large datasets to pre-train Deep
Learning models is a promising strategy to decrease the need for supervised
data. Self-supervised learning methods, such as contrastive and its variation
are a promising way towards obtaining better representations in many Deep
Learning applications. Soundscape ecology is one application in which
annotations are expensive and scarce, therefore deserving investigation to
approximate methods that do not require annotations to those that rely on
supervision. Our study involves the use of the methods Barlow Twins and VICReg
to pre-train different models with the same small dataset with sound patterns
of bird and anuran species. In a downstream task to classify those animal
species, the models obtained results close to supervised ones, pre-trained in
large generic datasets, and fine-tuned with the same task.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11242" title="Abstract">arXiv:2312.11242</a> [<a href="/pdf/2312.11242" title="Download PDF">pdf</a>, <a href="/format/2312.11242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAC-SQL: Multi-Agent Collaboration for Text-to-SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Changyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinnian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian-Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in Text-to-SQL methods employing Large Language Models
(LLMs) have demonstrated remarkable performance. Nonetheless, these approaches
continue to encounter difficulties when handling extensive databases, intricate
user queries, and erroneous SQL results. To tackle these challenges, we present
\textbf{MAC-SQL}, a LLM-based multi-agent collaborative Text- to-SQL framework
based on LLMs. This framework comprises three agents: the \textit{Selector},
accountable for condensing voluminous databases and preserving relevant table
schemas for user questions; the \textit{Decomposer}, which disassembles complex
user questions into more straightforward sub-problems and resolves them
progressively; and the \textit{Refiner}, tasked with validating and refining
defective SQL queries. We perform thorough experiments on two Text-to-SQL
datasets, BIRD and Spider, attaining a state-of-the-art execution accuracy of
59.59\% on the BIRD test set. Moreover, we have open-sourced an instruction
fine-tuning model, \textbf{SQL-Llama}, based on Code Llama 7B, in addition to
an agent instruction dataset derived from training data based on BIRD and
Spider. The SQL-Llama model has demonstrated encouraging outcomes on the
development sets of both BIRD and Spider. However, when compared to the GPT-4
model, there remains a notable potential for enhancement. Our code and data can
be accessed publicly at
\href{https://github.com/wbbeyourself/MAC-SQL}{https://github.com/wbbeyourself/MAC-SQL}.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11243" title="Abstract">arXiv:2312.11243</a> [<a href="/pdf/2312.11243" title="Download PDF">pdf</a>, <a href="/format/2312.11243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraspLDM: Generative 6-DoF Grasp Synthesis using Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barad%2C+K+R">Kuldeep R Barad</a>, 
<a href="/search/cs?searchtype=author&query=Orsula%2C+A">Andrej Orsula</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Antoine Richard</a>, 
<a href="/search/cs?searchtype=author&query=Dentler%2C+J">Jan Dentler</a>, 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M">Miguel Olivares-Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+C">Carol Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Vision-based grasping of unknown objects in unstructured environments is a
key challenge for autonomous robotic manipulation. A practical grasp synthesis
system is required to generate a diverse set of 6-DoF grasps from which a
task-relevant grasp can be executed. Although generative models are suitable
for learning such complex data distributions, existing models have limitations
in grasp quality, long training times, and a lack of flexibility for
task-specific generation. In this work, we present GraspLDM- a modular
generative framework for 6-DoF grasp synthesis that uses diffusion models as
priors in the latent space of a VAE. GraspLDM learns a generative model of
object-centric $SE(3)$ grasp poses conditioned on point clouds. GraspLDM's
architecture enables us to train task-specific models efficiently by only
re-training a small de-noising network in the low-dimensional latent space, as
opposed to existing models that need expensive re-training. Our framework
provides robust and scalable models on both full and single-view point clouds.
GraspLDM models trained with simulation data transfer well to the real world
and provide an 80\% success rate for 80 grasp attempts of diverse test objects,
improving over existing generative models. We make our implementation available
at https://github.com/kuldeepbrd1/graspldm .
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11245" title="Abstract">arXiv:2312.11245</a> [<a href="/pdf/2312.11245" title="Download PDF">pdf</a>, <a href="/format/2312.11245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiSegRT: Dataset for Site-Specific Indoor Radio Propagation Modeling  with 3D Segmentation and Differentiable Ray-Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haijian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R+Q">Rose Qingyang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE conference for future publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The accurate modeling of indoor radio propagation is crucial for
localization, monitoring, and device coordination, yet remains a formidable
challenge, due to the complex nature of indoor environments where radio can
propagate along hundreds of paths. These paths are resulted from the room
layout, furniture, appliances and even small objects like a glass cup, and also
are influenced by the object material and surface roughness. Advanced machine
learning (ML) techniques have the potential to take such non-linear and
hard-to-model factors into consideration, but extensive and fine-grained
datasets are urgently required. This paper presents
WiSegRT\footnote{\url{https://github.com/SunLab-UGA/WiSegRT}}, an open-source
dataset for indoor radio propagation modeling. Generated by a differentiable
ray tracer within the segmented 3-dimensional (3D) indoor environments, WiSegRT
provides site-specific channel impulse responses for each grid point relative
to the given transmitter location. We expect WiSegRT to support a wide-range of
applications, such as ML-based channel prediction, accurate indoor
localization, radio-based object detection, wireless digital twin, etc.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11250" title="Abstract">arXiv:2312.11250</a> [<a href="/pdf/2312.11250" title="Download PDF">pdf</a>, <a href="/format/2312.11250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Multi-centric Generalization: Phase and Step Recognition  in Roux-en-Y Gastric Bypass Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lavanchy%2C+J+L">Joel L. Lavanchy</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+S">Sanat Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Alba%2C+D">Diego Dall&#x27;Alba</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C">Cristians Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+P">Paolo Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=Muller-Stich%2C+B">Beat Muller-Stich</a>, 
<a href="/search/cs?searchtype=author&query=Nett%2C+P+C">Philipp C. Nett</a>, 
<a href="/search/cs?searchtype=author&query=Marescaux%2C+J">Jacques Marescaux</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most studies on surgical activity recognition utilizing Artificial
intelligence (AI) have focused mainly on recognizing one type of activity from
small and mono-centric surgical video datasets. It remains speculative whether
those models would generalize to other centers. In this work, we introduce a
large multi-centric multi-activity dataset consisting of 140 videos
(MultiBypass140) of laparoscopic Roux-en-Y gastric bypass (LRYGB) surgeries
performed at two medical centers: the University Hospital of Strasbourg
(StrasBypass70) and Inselspital, Bern University Hospital (BernBypass70). The
dataset has been fully annotated with phases and steps. Furthermore, we assess
the generalizability and benchmark different deep learning models in 7
experimental studies: 1) Training and evaluation on BernBypass70; 2) Training
and evaluation on StrasBypass70; 3) Training and evaluation on the
MultiBypass140; 4) Training on BernBypass70, evaluation on StrasBypass70; 5)
Training on StrasBypass70, evaluation on BernBypass70; Training on
MultiBypass140, evaluation 6) on BernBypass70 and 7) on StrasBypass70. The
model's performance is markedly influenced by the training data. The worst
results were obtained in experiments 4) and 5) confirming the limited
generalization capabilities of models trained on mono-centric data. The use of
multi-centric training data, experiments 6) and 7), improves the generalization
capabilities of the models, bringing them beyond the level of independent
mono-centric training and validation (experiments 1) and 2)). MultiBypass140
shows considerable variation in surgical technique and workflow of LRYGB
procedures between centers. Therefore, generalization experiments demonstrate a
remarkable difference in model performance. These results highlight the
importance of multi-centric datasets for AI model generalization to account for
variance in surgical technique and workflows.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11251" title="Abstract">arXiv:2312.11251</a> [<a href="/pdf/2312.11251" title="Download PDF">pdf</a>, <a href="/format/2312.11251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Optimal Control With Binary Adjustable Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/eess?searchtype=author&query=Yorke-Smith%2C+N">Neil Yorke-Smith</a>, 
<a href="/search/eess?searchtype=author&query=Keviczky%2C+T">Tamas Keviczky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, submitted to the 22nd European Control Conference (ECC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Robust Optimal Control (ROC) with adjustable uncertainties has proven to be
effective in addressing critical challenges within modern energy networks,
especially the reserve and provision problem. However, prior research on ROC
with adjustable uncertainties has predominantly focused on the scenario of
uncertainties modeled as continuous variables. In this paper, we explore ROC
with binary adjustable uncertainties, where the uncertainties are modeled by
binary decision variables, marking the first investigation of its kind. To
tackle this new challenge, firstly we introduce a metric designed to
quantitatively measure the extent of binary adjustable uncertainties. Then, to
balance computational tractability and adaptability, we restrict control
policies to be affine functions with respect to uncertainties, and propose a
general design framework for ROC with binary adjustable uncertainties. To
address the inherent computational demands of the original ROC problem,
especially in large-scale applications, we employ strong duality (SD) and
big-M-based reformulations to create a scalable and computationally efficient
Mixed-Integer Linear Programming (MILP) formulation. Numerical simulations are
conducted to showcase the performance of our proposed approach, demonstrating
its applicability and effectiveness in handling binary adjustable uncertainties
within the context of modern energy networks.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11255" title="Abstract">arXiv:2312.11255</a> [<a href="/pdf/2312.11255" title="Download PDF">pdf</a>, <a href="/format/2312.11255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-action control barrier functions: Imposing safety on  learning-based control with low online computational costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+K">Kanghui He</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+S">Shengling Shi</a>, 
<a href="/search/eess?searchtype=author&query=van+den+Boom%2C+T">Ton van den Boom</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Learning-based control with safety guarantees usually requires real-time
safety certification and modifications of possibly unsafe learning-based
policies. The control barrier function (CBF) method uses a safety filter
containing a constrained optimization problem to produce safe policies.
However, finding a valid CBF for a general nonlinear system requires a complex
function parameterization, which in general, makes the policy optimization
problem difficult to solve in real time. For nonlinear systems with nonlinear
state constraints, this paper proposes the novel concept of state-action CBFs,
which not only characterize the safety at each state but also evaluate the
control inputs taken at each state. State-action CBFs, in contrast to CBFs,
enable a flexible parameterization, resulting in a safety filter that involves
a convex quadratic optimization problem. This, in turn, significantly
alleviates the online computational burden. To synthesize state-action CBFs, we
propose a learning-based approach exploiting Hamilton-Jacobi reachability. The
effect of learning errors on the effectiveness of state-action CBFs is
addressed by constraint tightening and introducing a new concept called
contractive CBFs. These contributions ensure formal safety guarantees for
learned CBFs and control policies, enhancing the applicability of
learning-based control in real-time scenarios. Simulation results on an
inverted pendulum with elastic walls validate the proposed CBFs in terms of
constraint satisfaction and CPU time.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11257" title="Abstract">arXiv:2312.11257</a> [<a href="/pdf/2312.11257" title="Download PDF">pdf</a>, <a href="/format/2312.11257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Destination-passing style programming: a Haskell implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagrel%2C+T">Thomas Bagrel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. 9 figures, 9 tables. Submitted and soon to be published at JFLA 2024 (<a href="https://jfla.inria.fr/jfla2024.html">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Destination-passing style programming introduces destinations, which
represent the address of a write-once memory cell. Those destinations can be
passed as function parameters, and thus enable the caller of a function to keep
control over memory management: the body of the called function will just be
responsible of filling that memory cell. This is especially useful in
functional programming languages, in which the body of a function is typically
responsible for allocation of the result value.
<br />Programming with destination in Haskell is an interesting way to improve
performance of critical parts of some programs, without sacrificing memory
guarantees. Indeed, thanks to a linearly-typed API I present, a write-once
memory cell cannot be left uninitialized before being read, and is still
disposed of by the garbage collector when it is not in use anymore, eliminating
the risk of uninitialized read, memory leak, or double-free errors that can
arise when memory is managed manually.
<br />In this article, I present an implementation of destinations for Haskell,
which relies on so-called compact regions. I demonstrate, in particular, a
simple parser example for which the destination-based version uses 35% less
memory and time than its naive counterpart for large inputs.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11260" title="Abstract">arXiv:2312.11260</a> [<a href="/pdf/2312.11260" title="Download PDF">pdf</a>, <a href="/format/2312.11260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Normalization Layer in Adapters With Progressive Learning and  Adaptive Distillation for Cross-Domain Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38th AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cross-domain few-shot learning presents a formidable challenge, as models
must be trained on base classes and then tested on novel classes from various
domains with only a few samples at hand. While prior approaches have primarily
focused on parameter-efficient methods of using adapters, they often overlook
two critical issues: shifts in batch statistics and noisy sample statistics
arising from domain discrepancy variations. In this paper, we introduce a novel
generic framework that leverages normalization layer in adapters with
Progressive Learning and Adaptive Distillation (ProLAD), marking two principal
contributions. First, our methodology utilizes two separate adapters: one
devoid of a normalization layer, which is more effective for similar domains,
and another embedded with a normalization layer, designed to leverage the batch
statistics of the target domain, thus proving effective for dissimilar domains.
Second, to address the pitfalls of noisy statistics, we deploy two strategies:
a progressive training of the two adapters and an adaptive distillation
technique derived from features determined by the model solely with the adapter
devoid of a normalization layer. Through this adaptive distillation, our
approach functions as a modulator, controlling the primary adapter for
adaptation, based on each domain. Evaluations on standard cross-domain few-shot
learning benchmarks confirm that our technique outperforms existing
state-of-the-art methodologies.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11264" title="Abstract">arXiv:2312.11264</a> [<a href="/pdf/2312.11264" title="Download PDF">pdf</a>, <a href="/format/2312.11264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling agency: trade-offs between regional and integrated energy  systems design flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Greevenbroek%2C+K">Koen van Greevenbroek</a>, 
<a href="/search/eess?searchtype=author&query=Grochowicz%2C+A">Aleksander Grochowicz</a>, 
<a href="/search/eess?searchtype=author&query=Zeyringer%2C+M">Marianne Zeyringer</a>, 
<a href="/search/eess?searchtype=author&query=Benth%2C+F+E">Fred Espen Benth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Europe as a whole as well as individual countries have many distinct pathways
to net carbon neutrality by 2050. We use novel near-optimal modelling
techniques to illuminate trade-offs and interactions between national and
continental energy transitions under uncertainty. Our results reveal extensive
and robust flexibility at a regional level in renewable and hydrogen
investments as well as in hydrogen and electricity exports. However, Europe's
energy interconnections lead to significant cross-border effects of national
energy strategies. Wind and hydrogen investments can easily be shifted
geographically within Europe, and Northern Europe's capacity as energy exporter
or importer can shape and be shaped by the remaining system. Solar in Southern
Europe and Germany comes out as an enabler, and can unlock design flexibility
for the rest of the system. Quantifying these regional trade-offs in energy
system planning is crucial in order to facilitate meaningful policy discussion
and enable a fair energy transition.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11269" title="Abstract">arXiv:2312.11269</a> [<a href="/pdf/2312.11269" title="Download PDF">pdf</a>, <a href="/format/2312.11269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spherical Mask: Coarse-to-Fine 3D Point Cloud Instance Segmentation with  Spherical Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Sangyun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Vankadari%2C+M">Madhu Vankadari</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Coarse-to-fine 3D instance segmentation methods show weak performances
compared to recent Grouping-based, Kernel-based and Transformer-based methods.
We argue that this is due to two limitations: 1) Instance size overestimation
by axis-aligned bounding box(AABB) 2) False negative error accumulation from
inaccurate box to the refinement phase. In this work, we introduce Spherical
Mask, a novel coarse-to-fine approach based on spherical representation,
overcoming those two limitations with several benefits. Specifically, our
coarse detection estimates each instance with a 3D polygon using a center and
radial distance predictions, which avoids excessive size estimation of AABB. To
cut the error propagation in the existing coarse-to-fine approaches, we
virtually migrate points based on the polygon, allowing all foreground points,
including false negatives, to be refined. During inference, the proposal and
point migration modules run in parallel and are assembled to form binary masks
of instances. We also introduce two margin-based losses for the point migration
to enforce corrections for the false positives/negatives and cohesion of
foreground points, significantly improving the performance. Experimental
results from three datasets, such as ScanNetV2, S3DIS, and STPLS3D, show that
our proposed method outperforms existing works, demonstrating the effectiveness
of the new instance representation with spherical coordinates.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11271" title="Abstract">arXiv:2312.11271</a> [<a href="/pdf/2312.11271" title="Download PDF">pdf</a>, <a href="/format/2312.11271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active flux for triangular meshes for compressible flows problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Abgrall%2C+R">R&#xe9;mi Abgrall</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Jianfang Lin</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yongle Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article, we show how to construct a numerical method for solving
hyperbolic problems, whether linear or nonlinear, using a continuous
representation of the variables and their mean value in each triangular
element. This type of approach has already been introduced by Roe, and others,
in the multidimensional framework under the name of Active flux, see
\cite{AF1,AF2,AF3,AF4,AF5}. Here, the presentation is more general and follows
\cite{Abgrall_AF,BarzukowAbgrall}. { Various} examples show the good behavior
of the method in both linear and nonlinear cases, including non-convex
problems. The expected order of precision is obtained in both the linear and
nonlinear cases. This work represents a step towards the development of methods
in the spirit of virtual finite elements for linear or nonlinear hyperbolic
problems, including the case where the solution is not regular.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11272" title="Abstract">arXiv:2312.11272</a> [<a href="/pdf/2312.11272" title="Download PDF">pdf</a>, <a href="/format/2312.11272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling continuous and discrete linguistic signals in  transformer-based sentence embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nastase%2C+V">Vivi Nastase</a>, 
<a href="/search/cs?searchtype=author&query=Merlo%2C+P">Paola Merlo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentence and word embeddings encode structural and semantic information in a
distributed manner. Part of the information encoded -- particularly lexical
information -- can be seen as continuous, whereas other -- like structural
information -- is most often discrete. We explore whether we can compress
transformer-based sentence embeddings into a representation that separates
different linguistic signals -- in particular, information relevant to
subject-verb agreement and verb alternations. We show that by compressing an
input sequence that shares a targeted phenomenon into the latent layer of a
variational autoencoder-like system, the targeted linguistic information
becomes more explicit. A latent layer with both discrete and continuous
components captures better the targeted phenomena than a latent layer with only
discrete or only continuous components. These experiments are a step towards
separating linguistic signals from distributed text embeddings and linking them
to more symbolic representations.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11274" title="Abstract">arXiv:2312.11274</a> [<a href="/pdf/2312.11274" title="Download PDF">pdf</a>, <a href="/ps/2312.11274" title="Download PostScript">ps</a>, <a href="/format/2312.11274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study  Quasi-Experimental Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D+R">Danielle R. Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jionghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gatz%2C+E">Erin Gatz</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+A">Ashish Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shivang Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Norberg%2C+K">Kole Norberg</a>, 
<a href="/search/cs?searchtype=author&query=Fancsali%2C+S+E">Stephen E. Fancsali</a>, 
<a href="/search/cs?searchtype=author&query=Aleven%2C+V">Vincent Aleven</a>, 
<a href="/search/cs?searchtype=author&query=Branstetter%2C+L">Lee Branstetter</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>, 
<a href="/search/cs?searchtype=author&query=Koedinger%2C+K+R">Kenneth R. Koedinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Artificial intelligence applications to support human tutoring have potential
to significantly improve learning outcomes, but engagement issues persist,
especially among students from low-income backgrounds. We introduce an
AI-assisted tutoring model that combines human and AI tutoring and hypothesize
this synergy will have positive impacts on learning processes. We introduce an
AI-assisted tutoring model that combines human and AI tutoring and hypothesize
this synergy will have positive impacts on learning processes. To investigate
this hypothesis, we conduct a three-study quasi-experiment across three urban
and low-income middle schools.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11276" title="Abstract">arXiv:2312.11276</a> [<a href="/pdf/2312.11276" title="Download PDF">pdf</a>, <a href="/format/2312.11276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Generalization for Multi-label Text Classification: A  Data-Augmentation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yuyang Chai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite significant advancements in multi-label text classification, the
ability of existing models to generalize to novel and seldom-encountered
complex concepts, which are compositions of elementary ones, remains
underexplored. This research addresses this gap. By creating unique data splits
across three benchmarks, we assess the compositional generalization ability of
existing multi-label text classification models. Our results show that these
models often fail to generalize to compositional concepts encountered
infrequently during training, leading to inferior performance on tests with
these new combinations. To address this, we introduce a data augmentation
method that leverages two innovative text generation models designed to enhance
the classification models' capacity for compositional generalization. Our
experiments show that this data augmentation approach significantly improves
the compositional generalization capabilities of classification models on our
benchmarks, with both generation models surpassing other text generation
baselines.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11279" title="Abstract">arXiv:2312.11279</a> [<a href="/pdf/2312.11279" title="Download PDF">pdf</a>, <a href="/format/2312.11279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPGAs (Can Get Some) SATisfaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godindasamy%2C+H">Hariprasadh Godindasamy</a>, 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+B">Babak Esfandiari</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+P">Paulo Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">We present a hardware-accelerated SAT solver suitable for processor/Field
Programmable Gate Arrays (FPGA) hybrid platforms, which have become the norm in
the embedded domain. Our solution addresses a known bottleneck in SAT solving
acceleration: unlike prior state-of-the-art solutions that have addressed the
same bottleneck by limiting the amount of exploited parallelism, our solver
takes advantage of fine-grained parallelization opportunities by hot-swapping
FPGA clause assignments at runtime. It is also the first modern completely
open-source SAT accelerator, and formula size is limited only by the amount of
available external memory, not by on-chip FPGA memory. Evaluation is performed
on a Xilinx Zynq platform: experiments support that hardware acceleration
results in shorter execution time across varying formula sizes, subject to
formula partitioning strategy. We outperform prior state-of-the-art by 1.7x and
1.1x, respectively, for 2 representative benchmarks, and boast up to 6x
performance increase over software-only implementation.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11280" title="Abstract">arXiv:2312.11280</a> [<a href="/pdf/2312.11280" title="Download PDF">pdf</a>, <a href="/format/2312.11280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fairness in Online Service with k Servers and its Application on  Fair Food Delivery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+D+D">Daman Deep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Amit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Abhijnan Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The k-SERVER problem is one of the most prominent problems in online
algorithms with several variants and extensions. However, simplifying
assumptions like instantaneous server movements and zero service time has
hitherto limited its applicability to real-world problems. In this paper, we
introduce a realistic generalization of k-SERVER without such assumptions - the
k-FOOD problem, where requests with source-destination locations and an
associated pickup time window arrive in an online fashion, and each has to be
served by exactly one of the available k servers. The k-FOOD problem offers the
versatility to model a variety of real-world use cases such as food delivery,
ride sharing, and quick commerce. Moreover, motivated by the need for fairness
in online platforms, we introduce the FAIR k-FOOD problem with the max-min
objective. We establish that both k-FOOD and FAIR k-FOOD problems are strongly
NP-hard and develop an optimal offline algorithm that arises naturally from a
time-expanded flow network. Subsequently, we propose an online algorithm
DOC4FOOD involving virtual movements of servers to the nearest request
location. Experiments on a real-world food-delivery dataset, alongside
synthetic datasets, establish the efficacy of the proposed algorithm against
state-of-the-art fair food delivery algorithms.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11282" title="Abstract">arXiv:2312.11282</a> [<a href="/pdf/2312.11282" title="Download PDF">pdf</a>, <a href="/format/2312.11282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-ARK: Knowledge Graph Reasoning Using Large Language Models via Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxuan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the evolution of pre-training methods, large language models (LLMs) have
exhibited exemplary reasoning capabilities via prompt engineering. However, the
absence of Knowledge Graph (KG) environment awareness and the challenge of
engineering viable optimization mechanisms for intermediary reasoning
processes, constrict the performance of LLMs on KG reasoning tasks compared to
smaller models. We introduce LLM-ARK, a LLM grounded KG reasoning agent
designed to deliver precise and adaptable predictions on KG paths. LLM-ARK
utilizes Full Textual Environment (FTE) prompts to assimilate state information
for each step-sized intelligence. Leveraging LLMs to richly encode and
represent various types of inputs and integrate the knowledge graph further
with path environment data, before making the final decision. Reframing the
Knowledge Graph (KG) multi-hop inference problem as a sequential
decision-making issue, we optimize our model using the Proximal Policy
Optimization (PPO) online policy gradient reinforcement learning algorithm
which allows the model to learn from a vast array of reward signals across
diverse tasks and environments. We evaluate state-of-the-art LLM(GPT-4) and our
method which using open-source models of varying sizes on OpenDialKG dataset.
Our experiment shows that LLaMA7B-ARK provides excellent results with a
performance rate of 48.75% for the target@1 evaluation metric, far exceeding
the current state-of-the-art model by 17.64 percentage points. Meanwhile, GPT-4
accomplished a score of only 14.91%, further highlighting the efficacy and
complexity of our methodology. Our code is available on GitHub for further
access.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11285" title="Abstract">arXiv:2312.11285</a> [<a href="/pdf/2312.11285" title="Download PDF">pdf</a>, <a href="/format/2312.11285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adv-Diffusion: Imperceptible Adversarial Face Identity Attack via Latent  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Adversarial attacks involve adding perturbations to the source image to cause
misclassification by the target model, which demonstrates the potential of
attacking face recognition models. Existing adversarial face image generation
methods still can't achieve satisfactory performance because of low
transferability and high detectability. In this paper, we propose a unified
framework Adv-Diffusion that can generate imperceptible adversarial identity
perturbations in the latent space but not the raw pixel space, which utilizes
strong inpainting capabilities of the latent diffusion model to generate
realistic adversarial images. Specifically, we propose the identity-sensitive
conditioned diffusion generative model to generate semantic perturbations in
the surroundings. The designed adaptive strength-based adversarial perturbation
algorithm can ensure both attack transferability and stealthiness. Extensive
qualitative and quantitative experiments on the public FFHQ and CelebA-HQ
datasets prove the proposed method achieves superior performance compared with
the state-of-the-art methods without an extra generative model training
process. The source code is available at
https://github.com/kopper-xdu/Adv-Diffusion.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11286" title="Abstract">arXiv:2312.11286</a> [<a href="/pdf/2312.11286" title="Download PDF">pdf</a>, <a href="/ps/2312.11286" title="Download PostScript">ps</a>, <a href="/format/2312.11286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Envy-free House Allocation under Uncertain Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aziz%2C+H">Haris Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Iliffe%2C+I">Isaiah Iliffe</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ritossa%2C+A">Angus Ritossa</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Ankang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+M">Mashbat Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceeding of AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the envy-free house allocation problem when agents have uncertain
preferences over items and consider several well-studied preference uncertainty
models. The central problem that we focus on is computing an allocation that
has the highest probability of being envy-free. We show that each model leads
to a distinct set of algorithmic and complexity results, including detailed
results on (in-)approximability. En route, we consider two related problems of
checking whether there exists an allocation that is possibly or necessarily
envy-free. We give a complete picture of the computational complexity of these
two problems for all the uncertainty models we consider.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11289" title="Abstract">arXiv:2312.11289</a> [<a href="/pdf/2312.11289" title="Download PDF">pdf</a>, <a href="/ps/2312.11289" title="Download PostScript">ps</a>, <a href="/format/2312.11289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Pseudo Personal Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pengjun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ryosuke%2C+S">Shibasaki Ryosuke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The importance of personal mobility data is widely recognized in various
fields. However, the utilization of real personal mobility data raises privacy
concerns. Therefore, it is crucial to generate pseudo personal mobility data
that accurately reflects real-world mobility patterns while safeguarding user
privacy. Nevertheless, existing methods for generating pseudo mobility data,
such as mechanism-based and deep-learning-based approaches, have limitations in
capturing sufficient individual heterogeneity. To address these gaps, taking
pseudo-person(avatar) as ground-zero, a novel individual-based human mobility
generator called GeoAvatar has been proposed - which considers individual
heterogeneity in spatial and temporal decision-making, incorporates demographic
characteristics, and provides interpretability. Our method utilizes a deep
generative model to simulate heterogeneous individual life patterns, a reliable
labeler for inferring individual demographic characteristics, and a Bayesian
approach for generating spatial choices. Through our method, we have achieved
the generation of heterogeneous individual human mobility data without
accessing individual-level personal information, with good quality - we
evaluated the proposed method based on physical features, activity patterns,
and spatial-temporal characteristics, demonstrating its good performance,
compared to mechanism-based modeling and black-box deep learning approaches.
Furthermore, this method maintains extensibility for broader applications,
making it a promising paradigm for generating human mobility data.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11290" title="Abstract">arXiv:2312.11290</a> [<a href="/pdf/2312.11290" title="Download PDF">pdf</a>, <a href="/ps/2312.11290" title="Download PostScript">ps</a>, <a href="/format/2312.11290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Powerful Face Preprocessing For Robust Kinship Verification based  Tensor Analyses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=chouchane%2C+A">Ammar chouchane</a>, 
<a href="/search/cs?searchtype=author&query=Bessaoudi%2C+M">Mohcene Bessaoudi</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Kinship verification using facial photographs captured in the wild is
difficult area of research in the science of computer vision. It might be used
for a variety of applications, including image annotation and searching for
missing children, etc. The largest challenge to kinship verification in
practice is the fact that parent and child photos frequently differ
significantly from one another. How to effectively respond to such a challenge
is important improving the efficiency of kinship verification. For this
purpose, we introduce a system to check relatedness that starts with a pair of
face images of a child and a parent, after which it is revealed whether two
people are related or not. The first step in our approach is face preprocessing
with two methods, a Retinex filter and an ellipse mask, then a feature
extraction step based on hist-Gabor wavelets, which is used before an efficient
dimensionality reduction method called TXQDA. Finally, determine if there is a
relationship. By using Cornell KinFace benchmark database, we ran a number of
tests to show the efficacy of our strategy. Our findings show that, in
comparison to other strategies currently in use, our system is robust.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11292" title="Abstract">arXiv:2312.11292</a> [<a href="/pdf/2312.11292" title="Download PDF">pdf</a>, <a href="/format/2312.11292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFRWS EU 10-Year Review and Future Directions in Digital Forensic  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breitinger%2C+F">Frank Breitinger</a>, 
<a href="/search/cs?searchtype=author&query=Hilgert%2C+J">Jan-Niclas Hilgert</a>, 
<a href="/search/cs?searchtype=author&query=Hargreaves%2C+C">Christopher Hargreaves</a>, 
<a href="/search/cs?searchtype=author&query=Sheppard%2C+J">John Sheppard</a>, 
<a href="/search/cs?searchtype=author&query=Overdorf%2C+R">Rebekah Overdorf</a>, 
<a href="/search/cs?searchtype=author&query=Scanlon%2C+M">Mark Scanlon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Conducting a systematic literature review and comprehensive analysis, this
paper surveys all 135 peer-reviewed articles published at the Digital Forensics
Research Conference Europe (DFRWS EU) spanning the decade since its inaugural
running (2014-2023). This comprehensive study of DFRWS EU articles encompasses
sub-disciplines such as digital forensic science, device forensics, techniques
and fundamentals, artefact forensics, multimedia forensics, memory forensics,
and network forensics. Quantitative analysis of the articles' co-authorships,
geographical spread and citation metrics are outlined. The analysis presented
offers insights into the evolution of digital forensic research efforts over
these ten years and informs some identified future research directions.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11296" title="Abstract">arXiv:2312.11296</a> [<a href="/pdf/2312.11296" title="Download PDF">pdf</a>, <a href="/format/2312.11296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Generalized Laughter to Personalized Chuckles: Unleashing the Power  of Data Fusion in Subjective Humor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bielaniewicz%2C+J">Julita Bielaniewicz</a>, 
<a href="/search/cs?searchtype=author&query=Kazienko%2C+P">Przemys&#x142;aw Kazienko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The vast area of subjectivity in Natural Language Processing (NLP) poses a
challenge to the solutions typically used in generalized tasks. As exploration
in the scope of generalized NLP is much more advanced, it implies the
tremendous gap that is still to be addressed amongst all feasible tasks where
an opinion, taste, or feelings are inherent, thus creating a need for a
solution, where a data fusion could take place. We have chosen the task of
funniness, as it heavily relies on the sense of humor, which is fundamentally
subjective. Our experiments across five personalized and four generalized
datasets involving several personalized deep neural architectures have shown
that the task of humor detection greatly benefits from the inclusion of
personalized data in the training process. We tested five scenarios of training
data fusion that focused on either generalized (majority voting) or
personalized approaches to humor detection. The best results were obtained for
the setup, in which all available personalized datasets were joined to train
the personalized reasoning model. It boosted the prediction performance by up
to approximately 35% of the macro F1 score. Such a significant gain was
observed for all five personalized test sets. At the same time, the impact of
the model's architecture was much less than the personalization itself. It
seems that concatenating personalized datasets, even with the cost of
normalizing the range of annotations across all datasets, if combined with the
personalized models, results in an enormous increase in the performance of
humor detection.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11297" title="Abstract">arXiv:2312.11297</a> [<a href="/pdf/2312.11297" title="Download PDF">pdf</a>, <a href="/format/2312.11297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimised Storage for Datalog Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nenov%2C+Y">Yavor Nenov</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Materialisation facilitates Datalog reasoning by precomputing all
consequences of the facts and the rules so that queries can be directly
answered over the materialised facts. However, storing all materialised facts
may be infeasible in practice, especially when the rules are complex and the
given set of facts is large. We observe that for certain combinations of rules,
there exist data structures that compactly represent the reasoning result and
can be efficiently queried when necessary. In this paper, we present a general
framework that allows for the integration of such optimised storage schemes
with standard materialisation algorithms. Moreover, we devise optimised storage
schemes targeting at transitive rules and union rules, two types of
(combination of) rules that commonly occur in practice. Our experimental
evaluation shows that our approach significantly improves memory consumption,
sometimes by orders of magnitude, while remaining competitive in terms of query
answering time.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11299" title="Abstract">arXiv:2312.11299</a> [<a href="/pdf/2312.11299" title="Download PDF">pdf</a>, <a href="/format/2312.11299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-based Fairness Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuzucu%2C+S">Selim Kuzucu</a>, 
<a href="/search/cs?searchtype=author&query=Cheong%2C+J">Jiaee Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Gunes%2C+H">Hatice Gunes</a>, 
<a href="/search/cs?searchtype=author&query=Kalkan%2C+S">Sinan Kalkan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">Unfair predictions of machine learning (ML) models impede their broad
acceptance in real-world settings. Tackling this arduous challenge first
necessitates defining what it means for an ML model to be fair. This has been
addressed by the ML community with various measures of fairness that depend on
the prediction outcomes of the ML models, either at the group level or the
individual level. These fairness measures are limited in that they utilize
point predictions, neglecting their variances, or uncertainties, making them
susceptible to noise, missingness and shifts in data. In this paper, we first
show that an ML model may appear to be fair with existing point-based fairness
measures but biased against a demographic group in terms of prediction
uncertainties. Then, we introduce new fairness measures based on different
types of uncertainties, namely, aleatoric uncertainty and epistemic
uncertainty. We demonstrate on many datasets that (i) our uncertainty-based
measures are complementary to existing measures of fairness, and (ii) they
provide more insights about the underlying issues leading to bias.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11301" title="Abstract">arXiv:2312.11301</a> [<a href="/pdf/2312.11301" title="Download PDF">pdf</a>, <a href="/format/2312.11301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensuring Cross-Device Portability of Electromagnetic Side-Channel  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navanesana%2C+L">Lojenaa Navanesana</a>, 
<a href="/search/cs?searchtype=author&query=Le-Khac%2C+N">Nhien-An Le-Khac</a>, 
<a href="/search/cs?searchtype=author&query=Scanlon%2C+M">Mark Scanlon</a>, 
<a href="/search/cs?searchtype=author&query=De+Zoysa%2C+K">Kasun De Zoysa</a>, 
<a href="/search/cs?searchtype=author&query=Sayakkara%2C+A+P">Asanka P. Sayakkara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Investigation on smart devices has become an essential subdomain in digital
forensics. The inherent diversity and complexity of smart devices pose a
challenge to the extraction of evidence without physically tampering with it,
which is often a strict requirement in law enforcement and legal proceedings.
Recently, this has led to the application of non-intrusive Electromagnetic
Side-Channel Analysis (EM-SCA) as an emerging approach to extract forensic
insights from smart devices. EM-SCA for digital forensics is still in its
infancy, and has only been tested on a small number of devices so far. Most
importantly, the question still remains whether Machine Learning (ML) models in
EM-SCA are portable across multiple devices to be useful in digital forensics,
i.e., cross-device portability. This study experimentally explores this aspect
of EM-SCA using a wide set of smart devices. The experiments using various
iPhones and Nordic Semiconductor nRF52-DK devices indicate that the direct
application of pre-trained ML models across multiple identical devices does not
yield optimal outcomes (under 20% accuracy in most cases). Subsequent
experiments included collecting distinct samples of EM traces from all the
devices to train new ML models with mixed device data; this also fell short of
expectations (still below 20% accuracy). This prompted the adoption of transfer
learning techniques, which showed promise for cross-model implementations. In
particular, for the iPhone 13 and nRF52-DK devices, applying transfer learning
techniques resulted in achieving the highest accuracy, with accuracy scores of
98% and 96%, respectively. This result makes a significant advancement in the
application of EM-SCA to digital forensics by enabling the use of pre-trained
models across identical or similar devices.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11302" title="Abstract">arXiv:2312.11302</a> [<a href="/pdf/2312.11302" title="Download PDF">pdf</a>, <a href="/format/2312.11302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFDM-SCMA: A Promising Waveform for Massive Connectivity over High  Mobility Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Thomos">Thomos</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaos">Nikolaos</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhen Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Ziming He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies the affine frequency division multiplexing
(AFDM)-empowered sparse code multiple access (SCMA) system, referred to as
AFDM-SCMA, for supporting massive connectivity in high-mobility environments.
First, by placing the sparse codewords on the AFDM chirp subcarriers, the
input-output (I/O) relation of AFDM-SCMA systems is presented. Next, we delve
into the generalized receiver design, chirp rate selection, and error rate
performance of the proposed AFDM-SCMA. The proposed AFDM-SCMA is shown to
provide a general framework and subsume the existing OFDM-SCMA as a special
case. Third, for efficient transceiver design, we further propose a class of
sparse codebooks for simplifying the I/O relation, referred to as I/O
relation-inspired codebook design in this paper. Building upon these codebooks,
we propose a novel iterative detection and decoding scheme with linear minimum
mean square error (LMMSE) estimator for both downlink and uplink channels based
on orthogonal approximate message passing principles. Our numerical results
demonstrate the superiority of the proposed AFDM-SCMA systems over OFDM-SCMA
systems in terms of the error rate performance. We show that the proposed
receiver can significantly enhance the error rate performance while reducing
the detection complexity.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11305" title="Abstract">arXiv:2312.11305</a> [<a href="/pdf/2312.11305" title="Download PDF">pdf</a>, <a href="/ps/2312.11305" title="Download PostScript">ps</a>, <a href="/format/2312.11305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Variants of Diffusive Representation of Fractional Integrals:  Construction and Numerical Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaudhary%2C+R">Renu Chaudhary</a>, 
<a href="/search/math?searchtype=author&query=Diethelm%2C+K">Kai Diethelm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we revisit the diffusive representations of fractional
integrals established in \cite{diethelm2023diffusive} to explore novel variants
of such representations which provide highly efficient numerical algorithms for
the approximate numerical evaluation of fractional integrals.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11306" title="Abstract">arXiv:2312.11306</a> [<a href="/pdf/2312.11306" title="Download PDF">pdf</a>, <a href="/ps/2312.11306" title="Download PostScript">ps</a>, <a href="/format/2312.11306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical design optimization for automated drug dispensing systems in a  human-machine interaction environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+M">Mengge Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+K">Kan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+N">Ning Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Automated drug dispensing systems (ADDSs) are increasingly in demand in
today's pharmacies due to the growing aging population. Recognizing the
practical needs faced by hospitals utilizing ADDSs, this study focuses on
optimizing the physical design of ADDSs in a human-machine interaction
environment. Specifically, we investigate the retrieval sequencing of drugs
among successive prescription orders. To compare the efficiency of ADDSs with
the different number of input/output designs, we formulate dual command
retrieval sequencing models that optimize the retrieval sequence of drugs in
adjacent prescription orders. In particular, we consider the stochastic service
time of pharmacists in the 0-1 integer programming models to analyze the impact
on humans. Through experimental comparisons of average picking times for
prescription orders under different layout designs, the system layout with two
input/output points significantly enhances the efficiency of prescription order
fulfillment within a human-machine interaction environment. Furthermore, the
proposed retrieval sequence method outperforms dynamic programming, greedy, and
random strategies in improving prescription order-picking efficiency.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11309" title="Abstract">arXiv:2312.11309</a> [<a href="/pdf/2312.11309" title="Download PDF">pdf</a>, <a href="/format/2312.11309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Ultimate Combo: Boosting Adversarial Example Transferability by  Composing Data Augmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+Z">Zebin Yun</a>, 
<a href="/search/cs?searchtype=author&query=Weingarten%2C+A">Achi-Or Weingarten</a>, 
<a href="/search/cs?searchtype=author&query=Ronen%2C+E">Eyal Ronen</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+M">Mahmood Sharif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transferring adversarial examples (AEs) from surrogate machine-learning (ML)
models to target models is commonly used in black-box adversarial robustness
evaluation. Attacks leveraging certain data augmentation, such as random
resizing, have been found to help AEs generalize from surrogates to targets.
Yet, prior work has explored limited augmentations and their composition. To
fill the gap, we systematically studied how data augmentation affects
transferability. Particularly, we explored 46 augmentation techniques of seven
categories originally proposed to help ML models generalize to unseen benign
samples, and assessed how they impact transferability, when applied
individually or composed. Performing exhaustive search on a small subset of
augmentation techniques and genetic search on all techniques, we identified
augmentation combinations that can help promote transferability. Extensive
experiments with the ImageNet and CIFAR-10 datasets and 18 models showed that
simple color-space augmentations (e.g., color to greyscale) outperform the
state of the art when combined with standard augmentations, such as translation
and scaling. Additionally, we discovered that composing augmentations impacts
transferability mostly monotonically (i.e., more methods composed $\rightarrow$
$\ge$ transferability). We also found that the best composition significantly
outperformed the state of the art (e.g., 93.7% vs. $\le$ 82.7% average
transferability on ImageNet from normally trained surrogates to adversarially
trained targets). Lastly, our theoretical analysis, backed up by empirical
evidence, intuitively explain why certain augmentations help improve
transferability.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11311" title="Abstract">arXiv:2312.11311</a> [<a href="/pdf/2312.11311" title="Download PDF">pdf</a>, <a href="/format/2312.11311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the swing-up and balance task for the Acrobot and Pendubot with  SAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sathuluri%2C+A">Akhil Sathuluri</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+M">Markus Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 2023, RealAIGym competition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a solution of the swing-up and balance task for the pendubot and
acrobot for the participation in the AI Olympics competition at IJCAI 2023. Our
solution is based on the Soft Actor Crtic (SAC) reinforcement learning (RL)
algorithm for training a policy for the swing-up and entering the region of
attraction of a linear quadratic regulator(LQR) controller for stabilizing the
double pendulum at the top position. Our controller achieves competitive scores
in performance and robustness for both, pendubot and acrobot, problem
scenarios.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11312" title="Abstract">arXiv:2312.11312</a> [<a href="/pdf/2312.11312" title="Download PDF">pdf</a>, <a href="/format/2312.11312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT  Training Data Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batheja%2C+A">Akshay Batheja</a>, 
<a href="/search/cs?searchtype=author&query=Deoghare%2C+S">Sourabh Deoghare</a>, 
<a href="/search/cs?searchtype=author&query=Kanojia%2C+D">Diptesh Kanojia</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.03507">arXiv:2306.03507</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic Post-Editing (APE) is the task of automatically identifying and
correcting errors in the Machine Translation (MT) outputs. We propose a
repair-filter-use methodology that uses an APE system to correct errors on the
target side of the MT training data. We select the sentence pairs from the
original and corrected sentence pairs based on the quality scores computed
using a Quality Estimation (QE) model. To the best of our knowledge, this is a
novel adaptation of APE and QE to extract quality parallel corpus from the
pseudo-parallel corpus. By training with this filtered corpus, we observe an
improvement in the Machine Translation system's performance by 5.64 and 9.91
BLEU points, for English-Marathi and Marathi-English, over the baseline model.
The baseline model is the one that is trained on the whole pseudo-parallel
corpus. Our work is not limited by the characteristics of English or Marathi
languages; and is language pair-agnostic, given the necessary QE and APE data.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11314" title="Abstract">arXiv:2312.11314</a> [<a href="/pdf/2312.11314" title="Download PDF">pdf</a>, <a href="/format/2312.11314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safeguarded Progress in Reinforcement Learning: Safe Bayesian  Exploration for Control Policy Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitta%2C+R">Rohan Mitta</a>, 
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+H">Hosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kroening%2C+D">Daniel Kroening</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>, 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the problem of maintaining safety during training in
Reinforcement Learning (RL), such that the safety constraint violations are
bounded at any point during learning. In a variety of RL applications the
safety of the agent is particularly important, e.g. autonomous platforms or
robots that work in proximity of humans. As enforcing safety during training
might severely limit the agent's exploration, we propose here a new
architecture that handles the trade-off between efficient progress and safety
during exploration. As the exploration progresses, we update via Bayesian
inference Dirichlet-Categorical models of the transition probabilities of the
Markov decision process that describes the environment dynamics. This paper
proposes a way to approximate moments of belief about the risk associated to
the action selection policy. We construct those approximations, and prove the
convergence results. We propose a novel method for leveraging the expectation
approximations to derive an approximate bound on the confidence that the risk
is below a certain level. This approach can be easily interleaved with RL and
we present experimental results to showcase the performance of the overall
architecture.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11315" title="Abstract">arXiv:2312.11315</a> [<a href="/pdf/2312.11315" title="Download PDF">pdf</a>, <a href="/format/2312.11315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaRe-CNN: Cascading Refinement CNN for Myocardial Infarct Segmentation  with Microvascular Obstructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thaler%2C+F">Franz Thaler</a>, 
<a href="/search/cs?searchtype=author&query=Gsell%2C+M+A+F">Matthias A.F. Gsell</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+G">Gernot Plank</a>, 
<a href="/search/cs?searchtype=author&query=Urschler%2C+M">Martin Urschler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Late gadolinium enhanced (LGE) magnetic resonance (MR) imaging is widely
established to assess the viability of myocardial tissue of patients after
acute myocardial infarction (MI). We propose the Cascading Refinement CNN
(CaRe-CNN), which is a fully 3D, end-to-end trained, 3-stage CNN cascade that
exploits the hierarchical structure of such labeled cardiac data. Throughout
the three stages of the cascade, the label definition changes and CaRe-CNN
learns to gradually refine its intermediate predictions accordingly.
Furthermore, to obtain more consistent qualitative predictions, we propose a
series of post-processing steps that take anatomical constraints into account.
Our CaRe-CNN was submitted to the FIMH 2023 MYOSAIQ challenge, where it ranked
second out of 18 participating teams. CaRe-CNN showed great improvements most
notably when segmenting the difficult but clinically most relevant myocardial
infarct tissue (MIT) as well as microvascular obstructions (MVO). When
computing the average scores over all labels, our method obtained the best
score in eight out of ten metrics. Thus, accurate cardiac segmentation after
acute MI via our CaRe-CNN allows generating patient-specific models of the
heart serving as an important step towards personalized medicine.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11316" title="Abstract">arXiv:2312.11316</a> [<a href="/pdf/2312.11316" title="Download PDF">pdf</a>, <a href="/format/2312.11316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Networks for an Inverse Problem in Peridynamic  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Difonzo%2C+F+V">Fabio Vito Difonzo</a>, 
<a href="/search/math?searchtype=author&query=Lopez%2C+L">Luciano Lopez</a>, 
<a href="/search/math?searchtype=author&query=Pellegrino%2C+S+F">Sabrina Francesca Pellegrino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Deep learning is a powerful tool for solving data driven differential
problems and has come out to have successful applications in solving direct and
inverse problems described by PDEs, even in presence of integral terms. In this
paper, we propose to apply radial basis functions (RBFs) as activation
functions in suitably designed Physics Informed Neural Networks (PINNs) to
solve the inverse problem of computing the peridynamic kernel in the nonlocal
formulation of classical wave equation, resulting in what we call RBF-iPINN. We
show that the selection of an RBF is necessary to achieve meaningful solutions,
that agree with the physical expectations carried by the data. We support our
results with numerical examples and experiments, comparing the solution
obtained with the proposed RBF-iPINN to the exact solutions.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11318" title="Abstract">arXiv:2312.11318</a> [<a href="/pdf/2312.11318" title="Download PDF">pdf</a>, <a href="/format/2312.11318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Invariant Learning for Gaussian Processes and Bayesian  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xilong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Siyuan Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qinying Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Nanyang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Out-of-distribution (OOD) generalization has long been a challenging problem
that remains largely unsolved. Gaussian processes (GP), as popular
probabilistic model classes, especially in the small data regime, presume
strong OOD generalization abilities. Surprisingly, their OOD generalization
abilities have been under-explored before compared with other lines of GP
research. In this paper, we identify that GP is not free from the problem and
propose a domain invariant learning algorithm for Gaussian processes (DIL-GP)
with a min-max optimization on the likelihood. DIL-GP discovers the
heterogeneity in the data and forces invariance across partitioned subsets of
data. We further extend the DIL-GP to improve Bayesian optimization's
adaptability on changing environments. Numerical experiments demonstrate the
superiority of DIL-GP for predictions on several synthetic and real-world
datasets. We further demonstrate the effectiveness of the DIL-GP Bayesian
optimization method on a PID parameters tuning experiment for a quadrotor. The
full version and source code are available at:
https://github.com/Billzxl/DIL-GP.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11323" title="Abstract">arXiv:2312.11323</a> [<a href="/pdf/2312.11323" title="Download PDF">pdf</a>, <a href="/format/2312.11323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniForCE: The Unimodality Forest Method for Clustering and Estimation of  the Number of Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vardakas%2C+G">Georgios Vardakas</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>, 
<a href="/search/cs?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Estimating the number of clusters k while clustering the data is a
challenging task. An incorrect cluster assumption indicates that the number of
clusters k gets wrongly estimated. Consequently, the model fitting becomes less
important. In this work, we focus on the concept of unimodality and propose a
flexible cluster definition called locally unimodal cluster. A locally unimodal
cluster extends for as long as unimodality is locally preserved across pairs of
subclusters of the data. Then, we propose the UniForCE method for locally
unimodal clustering. The method starts with an initial overclustering of the
data and relies on the unimodality graph that connects subclusters forming
unimodal pairs. Such pairs are identified using an appropriate statistical
test. UniForCE identifies maximal locally unimodal clusters by computing a
spanning forest in the unimodality graph. Experimental results on both real and
synthetic datasets illustrate that the proposed methodology is particularly
flexible and robust in discovering regular and highly complex cluster shapes.
Most importantly, it automatically provides an adequate estimation of the
number of clusters.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11324" title="Abstract">arXiv:2312.11324</a> [<a href="/pdf/2312.11324" title="Download PDF">pdf</a>, <a href="/format/2312.11324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring the Graph of Networked Dynamical Systems under Partial  Observability and Spatially Colored Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">Augusto Santos</a>, 
<a href="/search/cs?searchtype=author&query=Rente%2C+D">Diogo Rente</a>, 
<a href="/search/cs?searchtype=author&query=Seabra%2C+R">Rui Seabra</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J+M+F">Jos&#xe9; M. F. Moura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE ICASSP 2024. Camera-Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In a Networked Dynamical System (NDS), each node is a system whose dynamics
are coupled with the dynamics of neighboring nodes. The global dynamics
naturally builds on this network of couplings and it is often excited by a
noise input with nontrivial structure. The underlying network is unknown in
many applications and should be inferred from observed data. We assume: i)
Partial observability -- time series data is only available over a subset of
the nodes; ii) Input noise -- it is correlated across distinct nodes while
temporally independent, i.e., it is spatially colored. We present a feasibility
condition on the noise correlation structure wherein there exists a consistent
network inference estimator to recover the underlying fundamental dependencies
among the observed nodes. Further, we describe a structure identification
algorithm that exhibits competitive performance across distinct regimes of
network connectivity, observability, and noise correlation.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11326" title="Abstract">arXiv:2312.11326</a> [<a href="/pdf/2312.11326" title="Download PDF">pdf</a>, <a href="/format/2312.11326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic Shifts as a Proxy for Assessing Politicization in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Locatelli%2C+M+S">Marcelo Sartori Locatelli</a>, 
<a href="/search/cs?searchtype=author&query=Calais%2C+P">Pedro Calais</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+M+P">Matheus Prado Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Junho%2C+J+P">Jo&#xe3;o Pedro Junho</a>, 
<a href="/search/cs?searchtype=author&query=Muniz%2C+T+L">Tomas Lacerda Muniz</a>, 
<a href="/search/cs?searchtype=author&query=Meira%2C+W">Wagner Meira Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+V">Virgilio Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, accepted for the 18th AAAI International Conference on Web and Social Media (ICWSM-2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Politicization is a social phenomenon studied by political science
characterized by the extent to which ideas and facts are given a political
tone. A range of topics, such as climate change, religion and vaccines has been
subject to increasing politicization in the media and social media platforms.
In this work, we propose a computational method for assessing politicization in
online conversations based on topic shifts, i.e., the degree to which people
switch topics in online conversations. The intuition is that topic shifts from
a non-political topic to politics are a direct measure of politicization --
making something political, and that the more people switch conversations to
politics, the more they perceive politics as playing a vital role in their
daily lives. A fundamental challenge that must be addressed when one studies
politicization in social media is that, a priori, any topic may be politicized.
Hence, any keyword-based method or even machine learning approaches that rely
on topic labels to classify topics are expensive to run and potentially
ineffective. Instead, we learn from a seed of political keywords and use
Positive-Unlabeled (PU) Learning to detect political comments in reaction to
non-political news articles posted on Twitter, YouTube, and TikTok during the
2022 Brazilian presidential elections. Our findings indicate that all platforms
show evidence of politicization as discussion around topics adjacent to
politics such as economy, crime and drugs tend to shift to politics. Even the
least politicized topics had the rate in which their topics shift to politics
increased in the lead up to the elections and after other political events in
Brazil -- an evidence of politicization.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11331" title="Abstract">arXiv:2312.11331</a> [<a href="/pdf/2312.11331" title="Download PDF">pdf</a>, <a href="/format/2312.11331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Descent for Diversity Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D+H">David H. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Palaparthi%2C+A+V">Anishalakshmi V. Palaparthi</a>, 
<a href="/search/cs?searchtype=author&query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="/search/cs?searchtype=author&query=Tjanaka%2C+B">Bryon Tjanaka</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Diversity optimization seeks to discover a set of solutions that elicit
diverse features. Prior work has proposed Novelty Search (NS), which, given a
current set of solutions, seeks to expand the set by finding points in areas of
low density in the feature space. However, to estimate density, NS relies on a
heuristic that considers the k-nearest neighbors of the search point in the
feature space, which yields a weaker stability guarantee. We propose Density
Descent Search (DDS), an algorithm that explores the feature space via gradient
descent on a continuous density estimate of the feature space that also
provides stronger stability guarantee. We experiment with DDS and two density
estimation methods: kernel density estimation (KDE) and continuous normalizing
flow (CNF). On several standard diversity optimization benchmarks, DDS
outperforms NS, the recently proposed MAP-Annealing algorithm, and other
state-of-the-art baselines. Additionally, we prove that DDS with KDE provides
stronger stability guarantees than NS, making it more suitable for adaptive
optimizers. Furthermore, we prove that NS is a special case of DDS that
descends a KDE of the feature space.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11334" title="Abstract">arXiv:2312.11334</a> [<a href="/pdf/2312.11334" title="Download PDF">pdf</a>, <a href="/format/2312.11334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimize and Reduce: A Top-Down Approach for Image Vectorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirschorn%2C+O">Or Hirschorn</a>, 
<a href="/search/cs?searchtype=author&query=Jevnisek%2C+A">Amir Jevnisek</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Vector image representation is a popular choice when editability and
flexibility in resolution are desired. However, most images are only available
in raster form, making raster-to-vector image conversion (vectorization) an
important task. Classical methods for vectorization are either domain-specific
or yield an abundance of shapes which limits editability and interpretability.
Learning-based methods, that use differentiable rendering, have revolutionized
vectorization, at the cost of poor generalization to out-of-training
distribution domains, and optimization-based counterparts are either slow or
produce non-editable and redundant shapes. In this work, we propose Optimize &amp;
Reduce (O&amp;R), a top-down approach to vectorization that is both fast and
domain-agnostic. O&amp;R aims to attain a compact representation of input images by
iteratively optimizing B\'ezier curve parameters and significantly reducing the
number of shapes, using a devised importance measure. We contribute a benchmark
of five datasets comprising images from a broad spectrum of image complexities
- from emojis to natural-like images. Through extensive experiments on hundreds
of images, we demonstrate that our method is domain agnostic and outperforms
existing works in both reconstruction and perceptual quality for a fixed number
of shapes. Moreover, we show that our algorithm is $\times 10$ faster than the
state-of-the-art optimization-based method.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11336" title="Abstract">arXiv:2312.11336</a> [<a href="/pdf/2312.11336" title="Download PDF">pdf</a>, <a href="/format/2312.11336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRDT: Dynamic Reflection with Divergent Thinking for LLM-based  Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weiran Yao</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rise of Large Language Models (LLMs) has sparked interest in their
application to sequential recommendation tasks as they can provide supportive
item information. However, due to the inherent complexities of sequential
recommendation, such as sequential patterns across datasets, noise within
sequences, and the temporal evolution of user preferences, existing LLM
reasoning strategies, such as in-context learning and chain-of-thought are not
fully effective. To address these challenges, we introduce a novel reasoning
principle: Dynamic Reflection with Divergent Thinking within a
retriever-reranker framework. Our approach starts with a collaborative
in-context demonstration retriever, which collects sequences exhibiting
collaborative behaviors as in-context examples. Following this, we abstract
high-level user preferences across multiple aspects, providing a more nuanced
understanding of user interests and circumventing the noise within the raw
sequences. The cornerstone of our methodology is dynamic reflection, a process
that emulates human learning through probing, critiquing, and reflecting, using
user feedback to tailor the analysis more effectively to the target user in a
temporal manner. We evaluate our approach on three datasets using six
pre-trained LLMs. The superior performance observed across these models
demonstrates the efficacy of our reasoning strategy, notably achieved without
the need to fine-tune the LLMs. With our principle, we managed to outperform
GPT-Turbo-3.5 on three datasets using 7b models e.g., Vicuna-7b and Openchat-7b
on NDCG@10. This research not only highlights the potential of LLMs in
enhancing sequential recommendation systems but also underscores the importance
of developing tailored reasoning strategies to fully harness their
capabilities.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11340" title="Abstract">arXiv:2312.11340</a> [<a href="/pdf/2312.11340" title="Download PDF">pdf</a>, <a href="/format/2312.11340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Vision-Enabled Sports Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aderinola%2C+T+B">Timilehin B. Aderinola</a>, 
<a href="/search/cs?searchtype=author&query=Younesian%2C+H">Hananeh Younesian</a>, 
<a href="/search/cs?searchtype=author&query=Goulding%2C+C">Cathy Goulding</a>, 
<a href="/search/cs?searchtype=author&query=Whelan%2C+D">Darragh Whelan</a>, 
<a href="/search/cs?searchtype=author&query=Caulfield%2C+B">Brian Caulfield</a>, 
<a href="/search/cs?searchtype=author&query=Ifrim%2C+G">Georgiana Ifrim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">$\textbf{Goal:}$ This study investigates the feasibility of monocular 2D
markerless motion capture (MMC) using a single smartphone to measure jump
height, velocity, flight time, contact time, and range of motion (ROM) during
motor tasks. $\textbf{Methods:}$ Sixteen healthy adults performed three
repetitions of selected tests while their body movements were recorded using
force plates, optical motion capture (OMC), and a smartphone camera. MMC was
then performed on the smartphone videos using OpenPose v1.7.0.
$\textbf{Results:}$ MMC demonstrated excellent agreement with ground truth for
jump height and velocity measurements. However, MMC's performance varied from
poor to moderate for flight time, contact time, ROM, and angular velocity
measurements. $\textbf{Conclusions:}$ These findings suggest that monocular 2D
MMC may be a viable alternative to OMC or force plates for assessing sports
performance during jumps and velocity-based tests. Additionally, MMC could
provide valuable visual feedback for flight time, contact time, ROM, and
angular velocity measurements.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11341" title="Abstract">arXiv:2312.11341</a> [<a href="/pdf/2312.11341" title="Download PDF">pdf</a>, <a href="/ps/2312.11341" title="Download PostScript">ps</a>, <a href="/format/2312.11341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the existence of MRD self-dual codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berhuy%2C+G">Gr&#xe9;gory Berhuy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we investigate the existence of self-dual MRD codes $C\subset
L^n$, where $L/F$ is an arbitrary field extension of degree $m\geq n$. We then
apply our results to the case of finite fields, and prove that if $m=n$ and
$F=\mathbb{F}_q$, a self-dual MRD code exists if and only if $q\equiv n\equiv 3
\ [4].$
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11344" title="Abstract">arXiv:2312.11344</a> [<a href="/pdf/2312.11344" title="Download PDF">pdf</a>, <a href="/format/2312.11344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Muted: Multilingual Targeted Offensive Speech Identification and  Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tillmann%2C+C">Christoph Tillmann</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Aashka Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+S">Sara Rosenthal</a>, 
<a href="/search/cs?searchtype=author&query=Borse%2C+S">Santosh Borse</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sil%2C+A">Avirup Sil</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+B">Bishwaranjan Bhattacharjee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023 Demo Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Offensive language such as hate, abuse, and profanity (HAP) occurs in various
content on the web. While previous work has mostly dealt with sentence level
annotations, there have been a few recent attempts to identify offensive spans
as well. We build upon this work and introduce Muted, a system to identify
multilingual HAP content by displaying offensive arguments and their targets
using heat maps to indicate their intensity. Muted can leverage any
transformer-based HAP-classification model and its attention mechanism
out-of-the-box to identify toxic spans, without further fine-tuning. In
addition, we use the spaCy library to identify the specific targets and
arguments for the words predicted by the attention heatmaps. We present the
model's performance on identifying offensive spans and their targets in
existing datasets and present new annotations on German text. Finally, we
demonstrate our proposed visualization tool on multilingual inputs.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11345" title="Abstract">arXiv:2312.11345</a> [<a href="/pdf/2312.11345" title="Download PDF">pdf</a>, <a href="/format/2312.11345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Affordance Acquisition via Causal Action-Effect Modeling in the  Video Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hsiu-Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Silberer%2C+C">Carina Silberer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Affordance knowledge is a fundamental aspect of commonsense knowledge. Recent
findings indicate that world knowledge emerges through large-scale
self-supervised pretraining, motivating our exploration of acquiring affordance
knowledge from the visual domain. To this end, we augment an existing
instructional video resource to create the new Causal Action-Effect (CAE)
dataset and design two novel pretraining tasks -- Masked Action Modeling (MAM)
and Masked Effect Modeling (MEM) -- promoting the acquisition of two affordance
properties in models: behavior and entity equivalence, respectively. We
empirically demonstrate the effectiveness of our proposed methods in learning
affordance properties. Furthermore, we show that a model pretrained on both
tasks outperforms a strong image-based visual-linguistic foundation model
(FLAVA) as well as pure linguistic models on a zero-shot physical reasoning
probing task.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11348" title="Abstract">arXiv:2312.11348</a> [<a href="/pdf/2312.11348" title="Download PDF">pdf</a>, <a href="/format/2312.11348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo Tree Search in the Presence of Transition Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohankhaki%2C+F">Farnaz Kohankhaki</a>, 
<a href="/search/cs?searchtype=author&query=Aghakasiri%2C+K">Kiarash Aghakasiri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Ting-Han Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chao Gao</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Martin M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Monte Carlo Tree Search (MCTS) is an immensely popular search-based framework
used for decision making. It is traditionally applied to domains where a
perfect simulation model of the environment is available. We study and improve
MCTS in the context where the environment model is given but imperfect. We show
that the discrepancy between the model and the actual environment can lead to
significant performance degradation with standard MCTS. We therefore develop
Uncertainty Adapted MCTS (UA-MCTS), a more robust algorithm within the MCTS
framework. We estimate the transition uncertainty in the given model, and
direct the search towards more certain transitions in the state space. We
modify all four MCTS phases to improve the search behavior by considering these
estimates. We prove, in the corrupted bandit case, that adding uncertainty
information to adapt UCB leads to tighter regret bound than standard UCB.
Empirically, we evaluate UA-MCTS and its individual components on the
deterministic domains from the MinAtar test suite. Our results demonstrate that
UA-MCTS strongly improves MCTS in the presence of model transition errors.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11352" title="Abstract">arXiv:2312.11352</a> [<a href="/pdf/2312.11352" title="Download PDF">pdf</a>, <a href="/format/2312.11352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety verification of Neural-Network-based controllers: a set  invariance approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jouret%2C+L">Louis Jouret</a>, 
<a href="/search/eess?searchtype=author&query=Saoud%2C+A">Adnane Saoud</a>, 
<a href="/search/eess?searchtype=author&query=Olaru%2C+S">Sorin Olaru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: IEEE Control Systems Letters ( Early Access ) Electronic ISSN: 2475-1456
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel approach to ensure the safety of continuous-time
linear dynamical systems controlled by a neural network (NN) based
state-feedback. Our method capitalizes on the use of continuous piece-wise
affine (PWA) activation functions (e.g. ReLU) which render the NN a PWA
continuous function. By computing the affine regions of the latter and applying
Nagumo's theorem, a subset of boundary points can effectively verify the
invariance of a potentially non-convex set. Consequently, an algorithm that
partitions the state space in affine regions is proposed. The scalability of
our approach is thoroughly analyzed, and extensive tests are conducted to
validate its effectiveness.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11355" title="Abstract">arXiv:2312.11355</a> [<a href="/pdf/2312.11355" title="Download PDF">pdf</a>, <a href="/format/2312.11355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vesicoureteral Reflux Detection with Reliable Probabilistic Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+H">Harris Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Anastassopoulos%2C+G">George Anastassopoulos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Sciences, Volume 308, Pages 113-124, 2015
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Vesicoureteral Reflux (VUR) is a pediatric disorder in which urine flows
backwards from the bladder to the upper urinary tract. Its detection is of
great importance as it increases the risk of a Urinary Tract Infection, which
can then lead to a kidney infection since bacteria may have direct access to
the kidneys. Unfortunately the detection of VUR requires a rather painful
medical examination, called voiding cysteourethrogram (VCUG), that exposes the
child to radiation. In an effort to avoid the exposure to radiation required by
VCUG some recent studies examined the use of machine learning techniques for
the detection of VUR based on data that can be obtained without exposing the
child to radiation. This work takes one step further by proposing an approach
that provides lower and upper bounds for the conditional probability of a given
child having VUR. The important property of these bounds is that they are
guaranteed (up to statistical fluctuations) to contain well-calibrated
probabilities with the only requirement that observations are independent and
identically distributed (i.i.d.). Therefore they are much more informative and
reliable than the plain yes/no answers provided by other techniques.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11356" title="Abstract">arXiv:2312.11356</a> [<a href="/pdf/2312.11356" title="Download PDF">pdf</a>, <a href="/format/2312.11356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Problem of Coherence in Natural Language Explanations of  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raczy%C5%84ski%2C+J">Jakub Raczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Lango%2C+M">Mateusz Lango</a>, 
<a href="/search/cs?searchtype=author&query=Stefanowski%2C+J">Jerzy Stefanowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Providing natural language explanations for recommendations is particularly
useful from the perspective of a non-expert user. Although several methods for
providing such explanations have recently been proposed, we argue that an
important aspect of explanation quality has been overlooked in their
experimental evaluation. Specifically, the coherence between generated text and
predicted rating, which is a necessary condition for an explanation to be
useful, is not properly captured by currently used evaluation measures. In this
paper, we highlight the issue of explanation and prediction coherence by 1)
presenting results from a manual verification of explanations generated by one
of the state-of-the-art approaches 2) proposing a method of automatic coherence
evaluation 3) introducing a new transformer-based method that aims to produce
more coherent explanations than the state-of-the-art approaches 4) performing
an experimental evaluation which demonstrates that this method significantly
improves the explanation coherence without affecting the other aspects of
recommendation performance.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11357" title="Abstract">arXiv:2312.11357</a> [<a href="/pdf/2312.11357" title="Download PDF">pdf</a>, <a href="/ps/2312.11357" title="Download PostScript">ps</a>, <a href="/format/2312.11357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Assessment of Others Through the Lens of Self
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berry%2C+J+A">Jasmine A. Berry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The maturation of cognition, from introspection to understanding others, has
long been a hallmark of human development. This position paper posits that for
AI systems to truly emulate or approach human-like interactions, especially
within multifaceted environments populated with diverse agents, they must first
achieve an in-depth and nuanced understanding of self. Drawing parallels with
the human developmental trajectory from self-awareness to mentalizing (also
called theory of mind), the paper argues that the quality of an autonomous
agent's introspective capabilities of self are crucial in mirroring quality
human-like understandings of other agents. While counterarguments emphasize
practicality, computational efficiency, and ethical concerns, this position
proposes a development approach, blending algorithmic considerations of
self-referential processing. Ultimately, the vision set forth is not merely of
machines that compute but of entities that introspect, empathize, and
understand, harmonizing with the complex compositions of human cognition.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11359" title="Abstract">arXiv:2312.11359</a> [<a href="/pdf/2312.11359" title="Download PDF">pdf</a>, <a href="/format/2312.11359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Game Design and Data Visualization to Foster Collaboration between  Science, Policy, and Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pottinger%2C+A+S">A Samuel Pottinger</a>, 
<a href="/search/cs?searchtype=author&query=Biyani%2C+N">Nivedita Biyani</a>, 
<a href="/search/cs?searchtype=author&query=Geyer%2C+R">Roland Geyer</a>, 
<a href="/search/cs?searchtype=author&query=McCauley%2C+D+J">Douglas J McCauley</a>, 
<a href="/search/cs?searchtype=author&query=de+Bruyn%2C+M">Magali de Bruyn</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+M+R">Molly R Morse</a>, 
<a href="/search/cs?searchtype=author&query=Nathan%2C+N">Neil Nathan</a>, 
<a href="/search/cs?searchtype=author&query=Koy%2C+K">Kevin Koy</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+C">Ciera Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages of which 6 are citations, 3 figures, latex generated from markdown via Pandoc (<a href="https://pandoc.org/">this https URL</a>) for Arxiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This multi-disciplinary case study details how a public web application
combines information and game design to visualize effects of user-defined
policies intended to reduce plastic waste. Contextualizing this open source
software within a broader lineage of digital media research, this user
experience exploration outlines potential directions for facilitating
conversation between artificial intelligence, scientists, and decision makers
during an iterative policy building process. Furthermore, this system
dissection reveals how this interactive science effort considers the
practicalities of a treaty's shifting priorities and proposals in its designs.
Specifically, this historically situated investigation of the tool's approach
highlights options for centering human decision making where artificial
intelligence helps reason about interventions but does not prescribe them.
Finally, analysis summarizes this application's specific game design-inspired
mechanics and their efforts to: enable users' agency to explore solution
possibilities freely, invite deep engagement with scientific findings, and
simultaneously serve multiple audiences with divergent objectives and
expertise.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11360" title="Abstract">arXiv:2312.11360</a> [<a href="/pdf/2312.11360" title="Download PDF">pdf</a>, <a href="/format/2312.11360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map  Optimization and Physically-Based Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youwang%2C+K">Kim Youwang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://kim-youwang.github.io/paint-it">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We present Paint-it, a text-driven high-fidelity texture map synthesis method
for 3D meshes via neural re-parameterized texture optimization. Paint-it
synthesizes texture maps from a text description by
synthesis-through-optimization, exploiting the Score-Distillation Sampling
(SDS). We observe that directly applying SDS yields undesirable texture quality
due to its noisy gradients. We reveal the importance of texture
parameterization when using SDS. Specifically, we propose Deep Convolutional
Physically-Based Rendering (DC-PBR) parameterization, which re-parameterizes
the physically-based rendering (PBR) texture maps with randomly initialized
convolution-based neural kernels, instead of a standard pixel-based
parameterization. We show that DC-PBR inherently schedules the optimization
curriculum according to texture frequency and naturally filters out the noisy
signals from SDS. In experiments, Paint-it obtains remarkable quality PBR
texture maps within 15 min., given only a text description. We demonstrate the
generalizability and practicality of Paint-it by synthesizing high-quality
texture maps for large-scale mesh datasets and showing test-time applications
such as relighting and material control using a popular graphics engine.
Project page: https://kim-youwang.github.io/paint-it
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11361" title="Abstract">arXiv:2312.11361</a> [<a href="/pdf/2312.11361" title="Download PDF">pdf</a>, <a href="/format/2312.11361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoMIRACL: Knowing When You Don&#x27;t Know for Robust Multilingual  Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nandan Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Bonifacio%2C+L">Luiz Bonifacio</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ogundepo%2C+O">Odunayo Ogundepo</a>, 
<a href="/search/cs?searchtype=author&query=Kamalloo%2C+E">Ehsan Kamalloo</a>, 
<a href="/search/cs?searchtype=author&query=Alfonso-Hermelo%2C+D">David Alfonso-Hermelo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Retrieval-augmented generation (RAG) grounds large language model (LLM)
output by leveraging external knowledge sources to reduce factual
hallucinations. However, prior works lack a comprehensive evaluation of
different language families, making it challenging to evaluate LLM robustness
against errors in external retrieved knowledge. To overcome this, we establish
NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across
18 typologically diverse languages. NoMIRACL includes both a non-relevant and a
relevant subset. Queries in the non-relevant subset contain passages manually
judged as non-relevant or noisy, whereas queries in the relevant subset include
at least a single judged relevant passage. We measure LLM robustness using two
metrics: (i) hallucination rate, measuring model tendency to hallucinate an
answer, when the answer is not present in passages in the non-relevant subset,
and (ii) error rate, measuring model inaccuracy to recognize relevant passages
in the relevant subset. We build a GPT-4 baseline which achieves a 33.2%
hallucination rate on the non-relevant and a 14.9% error rate on the relevant
subset on average. Our evaluation reveals that GPT-4 hallucinates frequently in
high-resource languages, such as French or English. This work highlights an
important avenue for future research to improve LLM robustness to learn how to
better reject non-relevant information in RAG.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11363" title="Abstract">arXiv:2312.11363</a> [<a href="/pdf/2312.11363" title="Download PDF">pdf</a>, <a href="/format/2312.11363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Vertical Federated Learning for Cooperative Spectrum Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">The increasing demand for wireless communication underscores the need to
optimize radio frequency spectrum utilization. An effective strategy for
leveraging underutilized licensed frequency bands is cooperative spectrum
sensing (CSS), which enable multiple secondary users (SUs) to collaboratively
detect the spectrum usage of primary users (PUs) prior to accessing the
licensed spectrum. The increasing popularity of machine learning has led to a
shift from traditional CSS methods to those based on deep learning. However,
deep learning-based CSS methods often rely on centralized learning, posing
challenges like communication overhead and data privacy risks. Recent research
suggests vertical federated learning (VFL) as a potential solution, with its
core concept centered on partitioning the deep neural network into distinct
segments, with each segment is trained separately. However, existing VFL-based
CSS works do not fully address the practical challenges arising from streaming
data and the objective shift. In this work, we introduce online vertical
federated learning (OVFL), a robust framework designed to address the
challenges of ongoing data stream and shifting learning goals. Our theoretical
analysis reveals that OVFL achieves a sublinear regret bound, thereby
evidencing its efficiency. Empirical results from our experiments show that
OVFL outperforms benchmarks in CSS tasks. We also explore the impact of various
parameters on the learning performance.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11364" title="Abstract">arXiv:2312.11364</a> [<a href="/pdf/2312.11364" title="Download PDF">pdf</a>, <a href="/format/2312.11364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Reward Automata: Sample Efficient Reinforcement Learning  Through the Exploitation of Reward Function Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bester%2C+T">Tristan Bester</a>, 
<a href="/search/cs?searchtype=author&query=Rosman%2C+B">Benjamin Rosman</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Steven James</a>, 
<a href="/search/cs?searchtype=author&query=Tasse%2C+G+N">Geraud Nangue Tasse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 Figures, Submitted to AAAI W25: Neuro-Symbolic Learning and Reasoning in the era of Large Language Models (NuCLeaR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We present counting reward automata-a finite state machine variant capable of
modelling any reward function expressible as a formal language. Unlike previous
approaches, which are limited to the expression of tasks as regular languages,
our framework allows for tasks described by unrestricted grammars. We prove
that an agent equipped with such an abstract machine is able to solve a larger
set of tasks than those utilising current approaches. We show that this
increase in expressive power does not come at the cost of increased automaton
complexity. A selection of learning algorithms are presented which exploit
automaton structure to improve sample efficiency. We show that the state
machines required in our formulation can be specified from natural language
task descriptions using large language models. Empirical results demonstrate
that our method outperforms competing approaches in terms of sample efficiency,
automaton complexity, and task completion.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11370" title="Abstract">arXiv:2312.11370</a> [<a href="/pdf/2312.11370" title="Download PDF">pdf</a>, <a href="/format/2312.11370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiahui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Pi%2C+R">Renjie Pi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiacheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable proficiency in human-level
reasoning and generation capabilities, which encourages extensive research on
their application in mathematical problem solving. However, current work has
been largely focused on text-based mathematical problems, with limited
investigation in problems involving geometric information. Addressing this gap,
we aim to enable LLMs to solve geometric problems by understanding image input.
We first analyze the limitations of current Multimodal Large Language Models
(MLLMs) in this area: they struggle to accurately comprehending basic geometric
elements and their relationships. To overcome these challenges, we take
advantage of the unique characteristics of geometric problems (such as unique
geometric logical form, and geometric scalability) and the capacity of the
textual LLMs to build an enriched multimodal geometry dataset based on existing
data. The augmented dataset, Geo170K, contains more than 170K geometric
image-caption and question-answer pairs. Utilizing our constructed Geo170K
dataset, we develop G-LLaVA, which demonstrates exceptional performance in
solving geometric problems, significantly outperforming GPT-4-V on the
MathVista benchmark with only 7B parameters.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11374" title="Abstract">arXiv:2312.11374</a> [<a href="/pdf/2312.11374" title="Download PDF">pdf</a>, <a href="/format/2312.11374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mastering Stacking of Diverse Shapes with Large-Scale Iterative  Reinforcement Learning on Real Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lampe%2C+T">Thomas Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Abdolmaleki%2C+A">Abbas Abdolmaleki</a>, 
<a href="/search/cs?searchtype=author&query=Bechtle%2C+S">Sarah Bechtle</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+H">Sandy H. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Springenberg%2C+J+T">Jost Tobias Springenberg</a>, 
<a href="/search/cs?searchtype=author&query=Bloesch%2C+M">Michael Bloesch</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+O">Oliver Groth</a>, 
<a href="/search/cs?searchtype=author&query=Hafner%2C+R">Roland Hafner</a>, 
<a href="/search/cs?searchtype=author&query=Hertweck%2C+T">Tim Hertweck</a>, 
<a href="/search/cs?searchtype=author&query=Neunert%2C+M">Michael Neunert</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+F">Francesco Nori</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Reinforcement learning solely from an agent's self-generated data is often
believed to be infeasible for learning on real robots, due to the amount of
data needed. However, if done right, agents learning from real data can be
surprisingly efficient through re-using previously collected sub-optimal data.
In this paper we demonstrate how the increased understanding of off-policy
learning methods and their embedding in an iterative online/offline scheme
(``collect and infer'') can drastically improve data-efficiency by using all
the collected experience, which empowers learning from real robot experience
only. Moreover, the resulting policy improves significantly over the state of
the art on a recently proposed real robot manipulation benchmark. Our approach
learns end-to-end, directly from pixels, and does not rely on additional human
domain knowledge such as a simulator or demonstrations.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11375" title="Abstract">arXiv:2312.11375</a> [<a href="/pdf/2312.11375" title="Download PDF">pdf</a>, <a href="/format/2312.11375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of BIM Data as Input and Output for Improved Detection of Lighting  Elements in Buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troncoso-Pastoriza%2C+F">Francisco Troncoso-Pastoriza</a>, 
<a href="/search/cs?searchtype=author&query=Egu%C3%ADa-Oller%2C+P">Pablo Egu&#xed;a-Oller</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Granada-%C3%81lvarez%2C+E">Enrique Granada-&#xc1;lvarez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automation in Construction, 2019, vol. 106, p. 102852
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a complete method for the automatic detection,
identification and localization of lighting elements in buildings, leveraging
the available building information modeling (BIM) data of a building and
feeding the BIM model with the new collected information, which is key for
energy-saving strategies. The detection system is heavily improved from our
previous work, with the following two main contributions: (i) a new refinement
algorithm to provide a better detection rate and identification performance
with comparable computational resources and (ii) a new plane estimation,
filtering and projection step to leverage the BIM information earlier for lamps
that are both hanging and embedded. The two modifications are thoroughly tested
in five different case studies, yielding better results in terms of detection,
identification and localization.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11376" title="Abstract">arXiv:2312.11376</a> [<a href="/pdf/2312.11376" title="Download PDF">pdf</a>, <a href="/format/2312.11376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIM: Contrastive Language-Image Mosaic for Region Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Size Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lumin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting objects accurately from a large or open vocabulary necessitates the
vision-language alignment on region representations. However, learning such a
region-text alignment by obtaining high-quality box annotations with text
labels or descriptions is expensive and infeasible. In contrast, collecting
image-text pairs is simpler but lacks precise object location information to
associate regions with texts. In this paper, we propose a novel approach called
Contrastive Language-Image Mosaic (CLIM), which leverages large-scale
image-text pairs effectively for aligning region and text representations. CLIM
combines multiple images into a mosaicked image and treats each image as a
`pseudo region'. The feature of each pseudo region is extracted and trained to
be similar to the corresponding text embedding while dissimilar from others by
a contrastive loss, enabling the model to learn the region-text alignment
without costly box annotations. As a generally applicable approach, CLIM
consistently improves different open-vocabulary object detection methods that
use caption supervision. Furthermore, CLIM can effectively enhance the region
representation of vision-language models, thus providing stronger backbones for
open-vocabulary object detectors. Our experimental results demonstrate that
CLIM improves different baseline open-vocabulary object detectors by a large
margin on both OV-COCO and OV-LVIS benchmarks. The code is available at
https://github.com/wusize/CLIM.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11380" title="Abstract">arXiv:2312.11380</a> [<a href="/pdf/2312.11380" title="Download PDF">pdf</a>, <a href="/format/2312.11380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orientation-Constrained System for Lamp Detection in Buildings Based on  Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troncoso-Pastoriza%2C+F">Francisco Troncoso-Pastoriza</a>, 
<a href="/search/cs?searchtype=author&query=Egu%C3%ADa-Oller%2C+P">Pablo Egu&#xed;a-Oller</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Granada-%C3%81lvarez%2C+E">Enrique Granada-&#xc1;lvarez</a>, 
<a href="/search/cs?searchtype=author&query=Erkoreka%2C+A">Aitor Erkoreka</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2019, vol. 19, no 7, p. 1516
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computer vision is used in this work to detect lighting elements in buildings
with the goal of improving the accuracy of previous methods to provide a
precise inventory of the location and state of lamps. Using the framework
developed in our previous works, we introduce two new modifications to enhance
the system: first, a constraint on the orientation of the detected poses in the
optimization methods for both the initial and the refined estimates based on
the geometric information of the building information modelling (BIM) model;
second, an additional reprojection error filtering step to discard the
erroneous poses introduced with the orientation restrictions, keeping the
identification and localization errors low while greatly increasing the number
of detections. These~enhancements are tested in five different case studies
with more than 30,000 images, with results showing improvements in the number
of detections, the percentage of correct model and state identifications, and
the distance between detections and reference positions
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11383" title="Abstract">arXiv:2312.11383</a> [<a href="/pdf/2312.11383" title="Download PDF">pdf</a>, <a href="/ps/2312.11383" title="Download PostScript">ps</a>, <a href="/format/2312.11383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path-aware optimistic optimization for a mobile robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santejudean%2C+T">Tudor Santejudean</a>, 
<a href="/search/cs?searchtype=author&query=Busoniu%2C+L">Lucian Busoniu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of IEEE Conference on Decision and Control 2021, 9-13
  December 2021, Austin, TX
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider problems in which a mobile robot samples an unknown function
defined over its operating space, so as to find a global optimum of this
function. The path traveled by the robot matters, since it influences energy
and time requirements. We consider a branch-and-bound algorithm called
deterministic optimistic optimization, and extend it to the path-aware setting,
obtaining path-aware optimistic optimization (OOPA). In this new algorithm, the
robot decides how to move next via an optimal control problem that maximizes
the long-term impact of the robot trajectory on lowering the upper bound,
weighted by bound and function values to focus the search on the optima. An
online version of value iteration is used to solve an approximate version of
this optimal control problem. OOPA is evaluated in extensive experiments in two
dimensions, where it does better than path-unaware and local-optimization
baselines.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11384" title="Abstract">arXiv:2312.11384</a> [<a href="/pdf/2312.11384" title="Download PDF">pdf</a>, <a href="/ps/2312.11384" title="Download PostScript">ps</a>, <a href="/format/2312.11384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffTune-MPC: Closed-Loop Learning for Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Model predictive control (MPC) has been applied to many platforms in robotics
and autonomous systems for its capability to predict a system's future behavior
while incorporating constraints that a system may have. To enhance the
performance of a system with an MPC controller, one can manually tune the MPC's
cost function. However, it can be challenging due to the possibly high
dimension of the parameter space as well as the potential difference between
the open-loop cost function in MPC and the overall closed-loop performance
metric function. This paper presents DiffTune-MPC, a novel learning method, to
learn the cost function of an MPC in a closed-loop manner. The proposed
framework is compatible with the scenario where the time interval for
performance evaluation and MPC's planning horizon have different lengths. We
show the auxiliary problem whose solution admits the analytical gradients of
MPC and discuss its variations in different MPC settings. Simulation results
demonstrate the capability of DiffTune-MPC and illustrate the influence of
constraints (from actuation limits) on learning.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11385" title="Abstract">arXiv:2312.11385</a> [<a href="/pdf/2312.11385" title="Download PDF">pdf</a>, <a href="/format/2312.11385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph Transformer for Semi-Supervised Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zexi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bohan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Hypergraphs play a pivotal role in the modelling of data featuring
higher-order relations involving more than two entities. Hypergraph neural
networks emerge as a powerful tool for processing hypergraph-structured data,
delivering remarkable performance across various tasks, e.g., hypergraph node
classification. However, these models struggle to capture global structural
information due to their reliance on local message passing. To address this
challenge, we propose a novel hypergraph learning framework, HyperGraph
Transformer (HyperGT). HyperGT uses a Transformer-based neural network
architecture to effectively consider global correlations among all nodes and
hyperedges. To incorporate local structural information, HyperGT has two
distinct designs: i) a positional encoding based on the hypergraph incidence
matrix, offering valuable insights into node-node and hyperedge-hyperedge
interactions; and ii) a hypergraph structure regularization in the loss
function, capturing connectivities between nodes and hyperedges. Through these
designs, HyperGT achieves comprehensive hypergraph representation learning by
effectively incorporating global interactions while preserving local
connectivity patterns. Extensive experiments conducted on real-world hypergraph
node classification tasks showcase that HyperGT consistently outperforms
existing methods, establishing new state-of-the-art benchmarks. Ablation
studies affirm the effectiveness of the individual designs of our model.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11387" title="Abstract">arXiv:2312.11387</a> [<a href="/pdf/2312.11387" title="Download PDF">pdf</a>, <a href="/format/2312.11387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Continuous-Time Framework for Frequency-Constrained Unit  Commitment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajabdorri%2C+M">Mohammad Rajabdorri</a>, 
<a href="/search/eess?searchtype=author&query=Lobato%2C+E">Enrique Lobato</a>, 
<a href="/search/eess?searchtype=author&query=Sigrist%2C+L">Lukas Sigrist</a>, 
<a href="/search/eess?searchtype=author&query=Aghaei%2C+J">Jamshid Aghaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The conventional approach to solving the unit commitment problem involves
discrete intervals at an hourly scale, particularly when integrating frequency
dynamics to formulate a frequency-constrained unit commitment. To overcome this
limitation, a novel continuous-time frequency-constrained unit commitment
framework is proposed in this paper. In this approach, Bernstein polynomials
represent continuous variables in the unit commitment problem and enable the
calculation of frequency response-related metrics such as the rate of change of
frequency, quasi-steady-state frequency, and frequency nadir. Notably, startup
and shut-down trajectories are meticulously considered, transforming the
formulation into a fully continuous-time model and simplifying constraints
related to variable continuity. To address the complexities associated with
integrating the obtained non-linear frequency nadir constraint into a
mixed-integer linear problem, an alternative data-driven frequency nadir
constraint is proposed, which accurately constrains frequency nadir deviations
throughout the time interval. To validate the proposed model, it is applied to
the real-life network of the Spanish Island of La Palma. The results
demonstrate the effectiveness of the proposed formulation, indicating that the
model is solved timely while mitigating the impact of intra-hour real-time
power fluctuations on system frequency.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11388" title="Abstract">arXiv:2312.11388</a> [<a href="/pdf/2312.11388" title="Download PDF">pdf</a>, <a href="/format/2312.11388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioSpark: An End-to-End Generative System for Biological-Analogical  Inspirations and Ideation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+H+B">Hyeonsu B. Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D+C">David Chuan-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Martelaro%2C+N">Nikolas Martelaro</a>, 
<a href="/search/cs?searchtype=author&query=Kittur%2C+A">Aniket Kittur</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan-Ying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M+K">Matthew K. Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Machine Learning for Creativity and Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Nature is often used to inspire solutions for complex engineering problems,
but achieving its full potential is challenging due to difficulties in
discovering relevant analogies and synthesizing from them. Here, we present an
end-to-end system, BioSpark, that generates biological-analogical mechanisms
and provides an interactive interface to comprehend and synthesize from them.
BioSpark pipeline starts with a small seed set of mechanisms and expands it
using an iteratively constructed taxonomic hierarchies, overcoming data
sparsity in manual expert curation and limited conceptual diversity in
automated analogy generation via LLMs. The interface helps designers with
recognizing and understanding relevant analogs to design problems using four
main interaction features. We evaluate the biological-analogical mechanism
generation pipeline and showcase the value of BioSpark through case studies. We
end with discussion and implications for future work in this area.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11389" title="Abstract">arXiv:2312.11389</a> [<a href="/pdf/2312.11389" title="Download PDF">pdf</a>, <a href="/format/2312.11389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Estimation of Under Frequency Load Shedding after Outages in  Small Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajabdorri%2C+M">Mohammad Rajabdorri</a>, 
<a href="/search/eess?searchtype=author&query=Sigrist%2C+L">Lukas Sigrist</a>, 
<a href="/search/eess?searchtype=author&query=Lobato%2C+E">Enrique Lobato</a>, 
<a href="/search/eess?searchtype=author&query=Troffaes%2C+M+C+M">Matthias C. M. Troffaes</a>, 
<a href="/search/eess?searchtype=author&query=Kazemtabrizi%2C+B">Behzad Kazemtabrizi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a data-driven methodology for estimating Under Frequency
Load Shedding (UFLS) in small power systems. UFLS plays a vital role in
maintaining system stability by shedding load when the frequency drops below a
specified threshold following loss of generation. Using a dynamic System
Frequency Response (SFR) model we generate different values of UFLS (i.e.,
labels) predicated on a set of carefully selected operating conditions (i.e.,
features). Machine Learning (ML) algorithms are then applied to learn the
relationship between chosen features and the UFLS labels. A novel regression
tree and the Tobit model are suggested for this purpose and we show how the
resulting non-linear model can be directly incorporated into a Mixed Integer
Linear Programming (MILP) problem. The trained model can be used to estimate
UFLS in security-constrained operational planning problems, improving frequency
response, optimizing reserve allocation, and reducing costs. The methodology is
applied to the La Palma island power system, demonstrating its accuracy and
effectiveness. The results confirm that the amount of UFLS can be estimated
with the Mean Absolute Error (MAE) as small as 0.213 MW for the whole process,
with a model that is representable as a MILP for use in scheduling problems
such as unit commitment among others.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11390" title="Abstract">arXiv:2312.11390</a> [<a href="/pdf/2312.11390" title="Download PDF">pdf</a>, <a href="/ps/2312.11390" title="Download PostScript">ps</a>, <a href="/format/2312.11390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Computing Optimal Temporal Branchings and Spanning Subgraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bubboloni%2C+D">Daniela Bubboloni</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+C">Costanza Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Marino%2C+A">Andrea Marino</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Ana Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, figures 9, Conference version published at FCT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this work we extend the concept of out/in-branchings spanning the vertices
of a digraph (also called directed spanning trees) to temporal graphs, which
are digraphs where arcs are available only at prescribed times. While the
literature has focused on minimum weight/earliest arrival time Temporal
Out-Branchings (TOB), we solve the problem for other optimization criteria. In
particular, we define five different types of TOBs based on the optimization of
the travel duration (FT-TOB), of the departure time (LD-TOB), of the number of
transfers (MT-TOB), of the total waiting time (MW-TOB), and of the travelling
time (ST-TOB). For D$\in \{$LD,MT,ST$\}$, we provide necessary and sufficient
conditions for the existence of a spanning D-TOB; when it does not exist, we
characterize the maximum vertex set that a D-TOB can span. Moreover, we provide
a log linear algorithm for computing such branchings. For D$\in \{$FT,MW$\}$,
we prove that deciding the existence of a spanning D-TOB is NP-complete; we
also show that the same results hold for optimal temporal in-branchings.
Finally, we investigate the related problem of computing a spanning temporal
subgraph with the minimum number of arcs and optimizing a chosen criterion D.
This problem turns out to be NP-hard for any D. The hardness results are quite
surprising, as computing optimal paths between nodes can always be done in
polynomial time.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11391" title="Abstract">arXiv:2312.11391</a> [<a href="/pdf/2312.11391" title="Download PDF">pdf</a>, <a href="/format/2312.11391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedCompetitors: Harmonious Collaboration in Federated Learning with  Competing Participants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shanli Tan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaohu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tiantian He</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaofeng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) provides a privacy-preserving approach for
collaborative training of machine learning models. Given the potential data
heterogeneity, it is crucial to select appropriate collaborators for each FL
participant (FL-PT) based on data complementarity. Recent studies have
addressed this challenge. Similarly, it is imperative to consider the
inter-individual relationships among FL-PTs where some FL-PTs engage in
competition. Although FL literature has acknowledged the significance of this
scenario, practical methods for establishing FL ecosystems remain largely
unexplored. In this paper, we extend a principle from the balance theory,
namely ``the friend of my enemy is my enemy'', to ensure the absence of
conflicting interests within an FL ecosystem. The extended principle and the
resulting problem are formulated via graph theory and integer linear
programming. A polynomial-time algorithm is proposed to determine the
collaborators of each FL-PT. The solution guarantees high scalability, allowing
even competing FL-PTs to smoothly join the ecosystem without conflict of
interest. The proposed framework jointly considers competition and data
heterogeneity. Extensive experiments on real-world and synthetic data
demonstrate its efficacy compared to five alternative approaches, and its
ability to establish efficient collaboration networks among FL-PTs.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11392" title="Abstract">arXiv:2312.11392</a> [<a href="/pdf/2312.11392" title="Download PDF">pdf</a>, <a href="/format/2312.11392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCEdit: Efficient and Controllable Image Diffusion Generation via Skip  Connection Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zeyinzi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chaojie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yulin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhen Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingfeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image diffusion models have been utilized in various tasks, such as
text-to-image generation and controllable image synthesis. Recent research has
introduced tuning methods that make subtle adjustments to the original models,
yielding promising results in specific adaptations of foundational generative
diffusion models. Rather than modifying the main backbone of the diffusion
model, we delve into the role of skip connection in U-Net and reveal that
hierarchical features aggregating long-distance information across encoder and
decoder make a significant impact on the content and quality of image
generation. Based on the observation, we propose an efficient generative tuning
framework, dubbed SCEdit, which integrates and edits Skip Connection using a
lightweight tuning module named SC-Tuner. Furthermore, the proposed framework
allows for straightforward extension to controllable image synthesis by
injecting different conditions with Controllable SC-Tuner, simplifying and
unifying the network design for multi-condition inputs. Our SCEdit
substantially reduces training parameters, memory usage, and computational
expense due to its lightweight tuners, with backward propagation only passing
to the decoder blocks. Extensive experiments conducted on text-to-image
generation and controllable image synthesis tasks demonstrate the superiority
of our method in terms of efficiency and performance. Project page:
\url{https://scedit.github.io/}
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11395" title="Abstract">arXiv:2312.11395</a> [<a href="/pdf/2312.11395" title="Download PDF">pdf</a>, <a href="/format/2312.11395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verb Categorisation for Hindi Word Problem Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Pruthwik Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D+M">Dipti Misra Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 17 figures, ICON 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Word problem Solving is a challenging NLP task that deals with solving
mathematical problems described in natural language. Recently, there has been
renewed interest in developing word problem solvers for Indian languages. As
part of this paper, we have built a Hindi arithmetic word problem solver which
makes use of verbs. Additionally, we have created verb categorization data for
Hindi. Verbs are very important for solving word problems with
addition/subtraction operations as they help us identify the set of operations
required to solve the word problems. We propose a rule-based solver that uses
verb categorisation to identify operations in a word problem and generate
answers for it. To perform verb categorisation, we explore several approaches
and present a comparative study.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11396" title="Abstract">arXiv:2312.11396</a> [<a href="/pdf/2312.11396" title="Download PDF">pdf</a>, <a href="/format/2312.11396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAG-Edit: Localized Image Editing in Complex Scenarios via  $\underline{M}$ask-Based $\underline{A}$ttention-Adjusted  $\underline{G}$uidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for project page, see <a href="https://mag-edit.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent diffusion-based image editing approaches have exhibited impressive
editing capabilities in images with simple compositions. However, localized
editing in complex scenarios has not been well-studied in the literature,
despite its growing real-world demands. Existing mask-based inpainting methods
fall short of retaining the underlying structure within the edit region.
Meanwhile, mask-free attention-based methods often exhibit editing leakage and
misalignment in more complex compositions. In this work, we develop
$\textbf{MAG-Edit}$, a training-free, inference-stage optimization method,
which enables localized image editing in complex scenarios. In particular,
MAG-Edit optimizes the noise latent feature in diffusion models by maximizing
two mask-based cross-attention constraints of the edit token, which in turn
gradually enhances the local alignment with the desired prompt. Extensive
quantitative and qualitative experiments demonstrate the effectiveness of our
method in achieving both text alignment and structure preservation for
localized editing within complex scenarios.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11399" title="Abstract">arXiv:2312.11399</a> [<a href="/pdf/2312.11399" title="Download PDF">pdf</a>, <a href="/format/2312.11399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> News Signals: An NLP Library for Text and Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hokamp%2C+C">Chris Hokamp</a>, 
<a href="/search/cs?searchtype=author&query=Ghalandari%2C+D+G">Demian Gholipour Ghalandari</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+P">Parsa Ghaffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP NLP-OSS Workshop, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present an open-source Python library for building and using datasets
where inputs are clusters of textual data, and outputs are sequences of real
values representing one or more time series signals. The news-signals library
supports diverse data science and NLP problem settings related to the
prediction of time series behaviour using textual data feeds. For example, in
the news domain, inputs are document clusters corresponding to daily news
articles about a particular entity, and targets are explicitly associated
real-valued time series: the volume of news about a particular person or
company, or the number of pageviews of specific Wikimedia pages. Despite many
industry and research use cases for this class of problem settings, to the best
of our knowledge, News Signals is the only open-source library designed
specifically to facilitate data science and research settings with natural
language inputs and time series targets. In addition to the core codebase for
building and interacting with datasets, we also conduct a suite of experiments
using several popular Machine Learning libraries, which are used to establish
baselines for time series anomaly prediction using textual inputs.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11401" title="Abstract">arXiv:2312.11401</a> [<a href="/pdf/2312.11401" title="Download PDF">pdf</a>, <a href="/format/2312.11401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater Robot Pose Estimation Using Acoustic Methods and Intermittent  Position Measurements at the Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maer%2C+V">Vicu-Mihalis Maer</a>, 
<a href="/search/cs?searchtype=author&query=Tamas%2C+L">Levente Tamas</a>, 
<a href="/search/cs?searchtype=author&query=Busoniu%2C+L">Lucian Busoniu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2022 IEEE International Conference on
  Automation, Quality and Testing, Robotics (AQTR-22), 19-21 May 2022,
  Cluj-Napoca, Romania
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Global positioning systems can provide sufficient positioning accuracy for
large scale robotic tasks in open environments. However, in underwater
environments, these systems cannot be directly used, and measuring the position
of underwater robots becomes more difficult. In this paper we first evaluate
the performance of existing pose estimation techniques for an underwater robot
equipped with commonly used sensors for underwater control and pose estimation,
in a simulated environment. In our case these sensors are inertial measurement
units, Doppler velocity log sensors, and ultra-short baseline sensors.
Secondly, for situations in which underwater estimation suffers from drift, we
investigate the benefit of intermittently correcting the position using a
high-precision surface-based sensor, such as regular GPS or an assisting
unmanned aerial vehicle that tracks the underwater robot from above using a
camera.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11403" title="Abstract">arXiv:2312.11403</a> [<a href="/pdf/2312.11403" title="Download PDF">pdf</a>, <a href="/ps/2312.11403" title="Download PostScript">ps</a>, <a href="/format/2312.11403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Temporal Properties is NP-hard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordais%2C+B">Benjamin Bordais</a>, 
<a href="/search/cs?searchtype=author&query=Neider%2C+D">Daniel Neider</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R">Rajarshi Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We investigate the complexity of LTL learning, which consists in deciding
given a finite set of positive ultimately periodic words, a finite set of
negative ultimately periodic words, and a bound B given in unary, if there is
an LTL-formula of size less than or equal to B that all positive words satisfy
and that all negative violate. We prove that this decision problem is NP-hard.
We then use this result to show that CTL learning is also NP-hard. CTL learning
is similar to LTL learning except that words are replaced by finite Kripke
structures and we look for the existence of CTL formulae.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11404" title="Abstract">arXiv:2312.11404</a> [<a href="/pdf/2312.11404" title="Download PDF">pdf</a>, <a href="/ps/2312.11404" title="Download PostScript">ps</a>, <a href="/format/2312.11404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An information-theoretic proof of the Shannon-Hagelbarger theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anantharam%2C+V">Venkat Anantharam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">The Shannon-Hagelbarger theorem states that the effective resistance across
any pair of nodes in a resistive network is a concave function of the edge
resistances. We give an information-theoretic proof of this result, building on
the theory of the Gaussian free field.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11405" title="Abstract">arXiv:2312.11405</a> [<a href="/pdf/2312.11405" title="Download PDF">pdf</a>, <a href="/ps/2312.11405" title="Download PostScript">ps</a>, <a href="/format/2312.11405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning for Fault Detection of HVAC Systems: An OPTICS  -based Approach for Terminal Air Handling Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajabi%2C+F">Farivar Rajabi</a>, 
<a href="/search/eess?searchtype=author&query=McArthur%2C+J+J">J.J. McArthur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 6 Tables, 7 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rise of AI-powered classification techniques has ushered in a new era for
data-driven Fault Detection and Diagnosis in smart building systems. While
extensive research has championed supervised FDD approaches, the real-world
application of unsupervised methods remains limited. Among these, cluster
analysis stands out for its potential with Building Management System data.
This study introduces an unsupervised learning strategy to detect faults in
terminal air handling units and their associated systems. The methodology
involves pre-processing historical sensor data using Principal Component
Analysis to streamline dimensions. This is then followed by OPTICS clustering,
juxtaposed against k-means for comparison. The effectiveness of the proposed
strategy was gauged using several labeled datasets depicting various fault
scenarios and real-world building BMS data. Results showed that OPTICS
consistently surpassed k-means in accuracy across seasons. Notably, OPTICS
offers a unique visualization feature for users called reachability distance,
allowing a preview of detected clusters before setting thresholds. Moreover,
according to the results, while PCA is beneficial for reducing computational
costs and enhancing noise reduction, thereby generally improving the clarity of
cluster differentiation in reachability distance. It also has its limitations,
particularly in complex fault scenarios. In such cases, PCA's dimensionality
reduction may result in the loss of critical information, leading to some
clusters being less discernible or entirely undetected. These overlooked
clusters could be indicative of underlying faults, and their obscurity
represents a significant limitation of PCA when identifying potential fault
lines in intricate datasets.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11408" title="Abstract">arXiv:2312.11408</a> [<a href="/pdf/2312.11408" title="Download PDF">pdf</a>, <a href="/format/2312.11408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approval-Based Committee Voting in Practice: A Case Study of  (Over-)Representation in the Polkadot Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boehmer%2C+N">Niclas Boehmer</a>, 
<a href="/search/cs?searchtype=author&query=Brill%2C+M">Markus Brill</a>, 
<a href="/search/cs?searchtype=author&query=Cevallos%2C+A">Alfonso Cevallos</a>, 
<a href="/search/cs?searchtype=author&query=Gehrlein%2C+J">Jonas Gehrlein</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Fern%C3%A1ndez%2C+L">Luis S&#xe1;nchez-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Kraepelin%2C+U">Ulrike Schmidt-Kraepelin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We provide the first large-scale data collection of real-world approval-based
committee elections. These elections have been conducted on the Polkadot
blockchain as part of their Nominated Proof-of-Stake mechanism and contain
around one thousand candidates and tens of thousands of (weighted) voters each.
We conduct an in-depth study of application-relevant questions, including a
quantitative and qualitative analysis of the outcomes returned by different
voting rules. Besides considering proportionality measures that are standard in
the multiwinner voting literature, we pay particular attention to less-studied
measures of overrepresentation, as these are closely related to the security of
the Polkadot network. We also analyze how different design decisions such as
the committee size affect the examined measures.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11409" title="Abstract">arXiv:2312.11409</a> [<a href="/pdf/2312.11409" title="Download PDF">pdf</a>, <a href="/format/2312.11409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning disturbance models for offset-free reference tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Krupa%2C+P">Pablo Krupa</a>, 
<a href="/search/eess?searchtype=author&query=Zanon%2C+M">Mario Zanon</a>, 
<a href="/search/eess?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (8 pages, 4 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work presents a nonlinear MPC framework that guarantees asymptotic
offset-free tracking of generic reference trajectories by learning a nonlinear
disturbance model, which compensates for input disturbances and model-plant
mismatch. Our approach generalizes the well-established method of using an
observer to estimate a constant disturbance to allow tracking constant
setpoints with zero steady-state error. In this paper, the disturbance model is
generalized to a nonlinear static function of the plant's state and command
input, learned online, so as to perfectly track time-varying reference
trajectories under certain assumptions on the model and provided that future
reference samples are available. We compare our approach with the classical
constant disturbance model in numerical simulations, showing its superiority.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11410" title="Abstract">arXiv:2312.11410</a> [<a href="/pdf/2312.11410" title="Download PDF">pdf</a>, <a href="/format/2312.11410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active search and coverage using point-cloud reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rosynski%2C+M">Matthias Rosynski</a>, 
<a href="/search/eess?searchtype=author&query=Pop%2C+A">Alexandru Pop</a>, 
<a href="/search/eess?searchtype=author&query=Busoniu%2C+L">Lucian Busoniu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 27th International Conference on System Theory,
  Control and Computing, October 11-13, 2023, Timisoara, Romania
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider a problem in which the trajectory of a mobile 3D sensor must be
optimized so that certain objects are both found in the overall scene and
covered by the point cloud, as fast as possible. This problem is called target
search and coverage, and the paper provides an end-to-end deep reinforcement
learning (RL) solution to solve it. The deep neural network combines four
components: deep hierarchical feature learning occurs in the first stage,
followed by multi-head transformers in the second, max-pooling and merging with
bypassed information to preserve spatial relationships in the third, and a
distributional dueling network in the last stage. To evaluate the method, a
simulator is developed where cylinders must be found by a Kinect sensor. A
network architecture study shows that deep hierarchical feature learning works
for RL and that by using farthest point sampling (FPS) we can reduce the amount
of points and achieve not only a reduction of the network size but also better
results. We also show that multi-head attention for point-clouds helps to learn
the agent faster but converges to the same outcome. Finally, we compare RL
using the best network with a greedy baseline that maximizes immediate rewards
and requires for that purpose an oracle that predicts the next observation. We
decided RL achieves significantly better and more robust results than the
greedy strategy.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11413" title="Abstract">arXiv:2312.11413</a> [<a href="/pdf/2312.11413" title="Download PDF">pdf</a>, <a href="/format/2312.11413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeRDaVa: Deletion-Robust Data Valuation for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xiao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+R+H+L">Rachael Hwee Ling Sim</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data valuation is concerned with determining a fair valuation of data from
data sources to compensate them or to identify training examples that are the
most or least useful for predictions. With the rising interest in personal data
ownership and data protection regulations, model owners will likely have to
fulfil more data deletion requests. This raises issues that have not been
addressed by existing works: Are the data valuation scores still fair with
deletions? Must the scores be expensively recomputed? The answer is no. To
avoid recomputations, we propose using our data valuation framework DeRDaVa
upfront for valuing each data source's contribution to preserving robust model
performance after anticipated data deletions. DeRDaVa can be efficiently
approximated and will assign higher values to data that are more useful or less
likely to be deleted. We further generalize DeRDaVa to Risk-DeRDaVa to cater to
risk-averse/seeking model owners who are concerned with the worst/best-cases
model utility. We also empirically demonstrate the practicality of our
solutions.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11414" title="Abstract">arXiv:2312.11414</a> [<a href="/pdf/2312.11414" title="Download PDF">pdf</a>, <a href="/format/2312.11414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animal-AI 3: What&#x27;s New &amp; Why You Should Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+K">Konstantinos Voudouris</a>, 
<a href="/search/cs?searchtype=author&query=Alhas%2C+I">Ibrahim Alhas</a>, 
<a href="/search/cs?searchtype=author&query=Schellaert%2C+W">Wout Schellaert</a>, 
<a href="/search/cs?searchtype=author&query=Crosby%2C+M">Matthew Crosby</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+J">Joel Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Burden%2C+J">John Burden</a>, 
<a href="/search/cs?searchtype=author&query=Chaubey%2C+N">Niharika Chaubey</a>, 
<a href="/search/cs?searchtype=author&query=Donnelly%2C+N">Niall Donnelly</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Matishalin Patel</a>, 
<a href="/search/cs?searchtype=author&query=Halina%2C+M">Marta Halina</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Orallo%2C+J">Jos&#xe9; Hern&#xe1;ndez-Orallo</a>, 
<a href="/search/cs?searchtype=author&query=Cheke%2C+L+G">Lucy G. Cheke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The Animal-AI Environment is a unique game-based research platform designed
to serve both the artificial intelligence and cognitive science research
communities. In this paper, we present Animal-AI 3, the latest version of the
environment, outlining several major new features that make the game more
engaging for humans and more complex for AI systems. New features include
interactive buttons, reward dispensers, and player notifications, as well as an
overhaul of the environment's graphics and processing for significant increases
in agent training time and quality of the human player experience. We provide
detailed guidance on how to build computational and behavioural experiments
with Animal-AI 3. We present results from a series of agents, including the
state-of-the-art Deep Reinforcement Learning agent (dreamer-v3), on newly
designed tests and the Animal-AI Testbed of 900 tasks inspired by research in
comparative psychology. Animal-AI 3 is designed to facilitate collaboration
between the cognitive sciences and artificial intelligence. This paper serves
as a stand-alone document that motivates, describes, and demonstrates Animal-AI
3 for the end user.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11415" title="Abstract">arXiv:2312.11415</a> [<a href="/pdf/2312.11415" title="Download PDF">pdf</a>, <a href="/format/2312.11415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mend the gap: A smart repair algorithm for noisy polygonal tilings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clelland%2C+J+N">Jeanne N. Clelland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Let $T^* = \{P^*_1, \ldots, P^*_N\}$ be a polygonal tiling of a simply
connected region in the plane, and let $T = \{P_1, \ldots, P_N\}$ be a noisy
version of $T^*$ obtained by making small perturbations to the coordinates of
the vertices of the polygons in $T^*$. In general, $T$ will only be an
approximate tiling, due to the presence of gaps and overlaps between the
perturbed polygons in $T$. The areas of these gaps and overlaps are typically
small relative to the areas of the polygons themselves.
<br />Suppose that we are given the approximate tiling $T$ and we wish to recover
the tiling $T^*$. To address this problem, we introduce a new algorithm, called
{\tt smart\_repair}, to modify the polygons in $T$ to produce a tiling
$\widetilde{T} = \{\widetilde{P}_1, \ldots, \widetilde{P}_N\}$ that closely
approximates $T^*$, with special attention given to reproducing the {\em
adjacency relations} between the polygons in $T^*$ as closely as possible.
<br />The motivation for this algorithm comes from computational redistricting,
where algorithms are used to build districts from smaller geographic units.
Because districts in most U.S. states are required to be contiguous, these
algorithms are fundamentally based on adjacency relations between units.
Unfortunately, the best available map data for unit boundaries is often noisy,
containing gaps and overlaps between units that can lead to substantial
inaccuracies in the adjacency relations. Simple repair algorithms can
exacerbate these inaccuracies, with the result that algorithmically drawn
districts based on the ``repaired" units may be discontiguous, and hence not
legally compliant. The algorithm presented here is specifically designed to
avoid such problems.
<br />A Python implementation is publicly available as part of the MGGG
Redistricting Lab's {\tt Maup} package, available at
\url{https://github.com/mggg/maup}.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11417" title="Abstract">arXiv:2312.11417</a> [<a href="/pdf/2312.11417" title="Download PDF">pdf</a>, <a href="/format/2312.11417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyDiff: Generating 3D Polygonal Meshes with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alliegro%2C+A">Antonio Alliegro</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+Y">Yawar Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Tommasi%2C+T">Tatiana Tommasi</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce PolyDiff, the first diffusion-based approach capable of directly
generating realistic and diverse 3D polygonal meshes. In contrast to methods
that use alternate 3D shape representations (e.g. implicit representations),
our approach is a discrete denoising diffusion probabilistic model that
operates natively on the polygonal mesh data structure. This enables learning
of both the geometric properties of vertices and the topological
characteristics of faces. Specifically, we treat meshes as quantized triangle
soups, progressively corrupted with categorical noise in the forward diffusion
phase. In the reverse diffusion phase, a transformer-based denoising network is
trained to revert the noising process, restoring the original mesh structure.
At inference, new meshes can be generated by applying this denoising network
iteratively, starting with a completely noisy triangle soup. Consequently, our
model is capable of producing high-quality 3D polygonal meshes, ready for
integration into downstream 3D workflows. Our extensive experimental analysis
shows that PolyDiff achieves a significant advantage (avg. FID and JSD
improvement of 18.2 and 5.8 respectively) over current state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11418" title="Abstract">arXiv:2312.11418</a> [<a href="/pdf/2312.11418" title="Download PDF">pdf</a>, <a href="/ps/2312.11418" title="Download PostScript">ps</a>, <a href="/format/2312.11418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Cognitive Load Assessment Using Electrooculography Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Larki%2C+A+A">Arash Abbasi Larki</a>, 
<a href="/search/cs?searchtype=author&query=Shojaei%2C+A">Akram Shojaei</a>, 
<a href="/search/cs?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 30th National and 8th International Iranian Conference on Biomedical Engineering (ICBME 2023), Tehran, Iran, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cognitive load assessment is crucial for understanding human performance in
various domains. This study investigates the impact of different task
conditions and time constraints on cognitive load using multiple measures,
including subjective evaluations, performance metrics, and physiological
eye-tracking data. Fifteen participants completed a series of primary and
secondary tasks with different time limits. The NASA-TLX questionnaire,
reaction time, inverse efficiency score, and eye-related features (blink,
saccade, and fixation frequency) were utilized to assess cognitive load. The
study results show significant differences in the level of cognitive load
required for different tasks and when under time constraints. The study also
found that there was a positive correlation (r = 0.331, p = 0.014) between how
often participants blinked their eyes and the level of cognitive load required
but a negative correlation (r = -0.290, p = 0.032) between how often
participants made quick eye movements (saccades) and the level of cognitive
load required. Additionally, the analysis revealed a significant negative
correlation (r = -0.347, p = 0.009) and (r = -0.370, p = 0.005) between
fixation and saccade frequencies under time constraints.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11420" title="Abstract">arXiv:2312.11420</a> [<a href="/pdf/2312.11420" title="Download PDF">pdf</a>, <a href="/format/2312.11420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM  Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+H">Haoqin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper introduces an efficient strategy to transform Large Language
Models (LLMs) into Multi-Modal Large Language Models (MLLMs). By
conceptualizing this transformation as a domain adaptation process, i.e.,
transitioning from text understanding to embracing multiple modalities, we
intriguingly note that, within each attention block, tuning LayerNorm suffices
to yield strong performance. Moreover, when benchmarked against other tuning
approaches like full parameter finetuning or LoRA, its benefits on efficiency
are substantial. For example, when compared to LoRA on a 13B model scale,
performance can be enhanced by an average of over 20% across five multi-modal
tasks, and meanwhile, results in a significant reduction of trainable
parameters by 41.9% and a decrease in GPU memory usage by 17.6%. On top of this
LayerNorm strategy, we showcase that selectively tuning only with
conversational data can improve efficiency further. Beyond these empirical
outcomes, we provide a comprehensive analysis to explore the role of LayerNorm
in adapting LLMs to the multi-modal domain and improving the expressive power
of the model.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11422" title="Abstract">arXiv:2312.11422</a> [<a href="/pdf/2312.11422" title="Download PDF">pdf</a>, <a href="/format/2312.11422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Warping the Residuals for Image Editing with StyleGAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+A+B">Ahmet Burak Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Pehlivan%2C+H">Hamza Pehlivan</a>, 
<a href="/search/cs?searchtype=author&query=Dundar%2C+A">Aysegul Dundar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">StyleGAN models show editing capabilities via their semantically
interpretable latent organizations which require successful GAN inversion
methods to edit real images. Many works have been proposed for inverting images
into StyleGAN's latent space. However, their results either suffer from low
fidelity to the input image or poor editing qualities, especially for edits
that require large transformations. That is because low-rate latent spaces lose
many image details due to the information bottleneck even though it provides an
editable space. On the other hand, higher-rate latent spaces can pass all the
image details to StyleGAN for perfect reconstruction of images but suffer from
low editing qualities. In this work, we present a novel image inversion
architecture that extracts high-rate latent features and includes a flow
estimation module to warp these features to adapt them to edits. The flows are
estimated from StyleGAN features of edited and unedited latent codes. By
estimating the high-rate features and warping them for edits, we achieve both
high-fidelity to the input image and high-quality edits. We run extensive
experiments and compare our method with state-of-the-art inversion methods.
Qualitative metrics and visual comparisons show significant improvements.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11424" title="Abstract">arXiv:2312.11424</a> [<a href="/pdf/2312.11424" title="Download PDF">pdf</a>, <a href="/format/2312.11424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D exploration-based search for multiple targets using a UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousuf%2C+B">Bilal Yousuf</a>, 
<a href="/search/cs?searchtype=author&query=Lendek%2C+Z">Zsofia Lendek</a>, 
<a href="/search/cs?searchtype=author&query=Busoniu%2C+L">Lucian Busoniu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Consider an unmanned aerial vehicle (UAV) that searches for an unknown number
of targets at unknown positions in 3D space. A particle filter uses imperfect
measurements about the targets to update an intensity function that represents
the expected number of targets. We propose a receding-horizon planner that
selects the next UAV position by maximizing a joint, exploration and
target-refinement objective. Confidently localized targets are saved and
removed from consideration. A nonlinear controller with an obstacle-avoidance
component is used to reach the desired waypoints. We demonstrate the
performance of our approach through a series of simulations, as well as in
real-robot experiments with a Parrot Mambo drone that searches for targets from
a constant altitude. The proposed planner works better than a lawnmower and a
target-refinement-only method.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11431" title="Abstract">arXiv:2312.11431</a> [<a href="/pdf/2312.11431" title="Download PDF">pdf</a>, <a href="/format/2312.11431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make It Make Sense! Understanding and Facilitating Sensemaking in  Computational Notebooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+S">Souti Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zixuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Arteaga%2C+E">Emily Arteaga</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+A">Audrey Au</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+G">Gonzalo Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Barik%2C+T">Titus Barik</a>, 
<a href="/search/cs?searchtype=author&query=Sarma%2C+A">Anita Sarma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Reusing and making sense of other scientists' computational notebooks.
However, making sense of existing notebooks is a struggle, as these reference
notebooks are often exploratory, have messy structures, include multiple
alternatives, and have little explanation. To help mitigate these issues, we
developed a catalog of cognitive tasks associated with the sensemaking process.
Utilizing this catalog, we introduce Porpoise: an interactive overlay on
computational notebooks. Porpoise integrates computational notebook features
with digital design, grouping cells into labeled sections that can be expanded,
collapsed, or annotated for improved sensemaking.
<br />We investigated data scientists' needs with unfamiliar computational
notebooks and investigated the impact of Porpoise adaptations on their
comprehension process. Our counterbalanced study with 24 data scientists found
Porpoise enhanced code comprehension, making the experience more akin to
reading a book, with one participant describing it as It's really like reading
a book.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11434" title="Abstract">arXiv:2312.11434</a> [<a href="/pdf/2312.11434" title="Download PDF">pdf</a>, <a href="/ps/2312.11434" title="Download PostScript">ps</a>, <a href="/format/2312.11434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factored Online Planning in Many-Agent POMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galesloot%2C+M+F+L">Maris F.L. Galesloot</a>, 
<a href="/search/cs?searchtype=author&query=Simao%2C+T+D">Thiago D. Simao</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In centralized multi-agent systems, often modeled as multi-agent partially
observable Markov decision processes (MPOMDPs), the action and observation
spaces grow exponentially with the number of agents, making the value and
belief state estimation of single-agent online planning ineffective. Prior work
partially tackles value estimation by exploiting the inherent structure of
multi-agent settings via so-called coordination graphs. Additionally, belief
state estimation has been improved by incorporating the likelihood of
observations into the approximation. However, the challenges of value
estimation and state estimation have only been tackled individually, which
prevents these methods from scaling to many agents. Therefore, we address these
challenges simultaneously. First, we introduce weighted particle filtering to
sample-based online planners in MPOMDPs. Second, we present a scalable
approximation of the belief state. Third, we bring an approach that exploits
the typical locality of agent interactions to novel online planning algorithms
for MPOMDPs operating on a so-called sparse particle filter belief tree. Our
algorithms show competitive performance for settings with only a few agents and
outperform state-of-the-art algorithms on benchmarks with many agents.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11441" title="Abstract">arXiv:2312.11441</a> [<a href="/pdf/2312.11441" title="Download PDF">pdf</a>, <a href="/format/2312.11441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Learning: Towards Collaborative Learning with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohtashami%2C+A">Amirkeivan Mohtashami</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+F">Florian Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Gooding%2C+S">Sian Gooding</a>, 
<a href="/search/cs?searchtype=author&query=Zilka%2C+L">Lukas Zilka</a>, 
<a href="/search/cs?searchtype=author&query=Sharifi%2C+M">Matt Sharifi</a>, 
<a href="/search/cs?searchtype=author&query=Arcas%2C+B+A+y">Blaise Aguera y Arcas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce the framework of "social learning" in the context of large
language models (LLMs), whereby models share knowledge with each other in a
privacy-aware manner using natural language. We present and evaluate two
approaches for knowledge transfer between LLMs. In the first scenario, we allow
the model to generate abstract prompts aiming to teach the task. In our second
approach, models transfer knowledge by generating synthetic examples. We
evaluate these methods across diverse datasets and quantify memorization as a
proxy for privacy loss. These techniques inspired by social learning yield
promising results with low memorization of the original data. In particular, we
show that performance using these methods is comparable to results with the use
of original labels and prompts. Our work demonstrates the viability of social
learning for LLMs, establishes baseline approaches and highlights several
unexplored areas for future work.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11442" title="Abstract">arXiv:2312.11442</a> [<a href="/pdf/2312.11442" title="Download PDF">pdf</a>, <a href="/format/2312.11442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore 3D Dance Generation via Reward Model from Automatically-Ranked  Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+H">Haolin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Junjie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Boshi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an Exploratory 3D Dance generation framework, E3D2,
designed to address the exploration capability deficiency in existing
music-conditioned 3D dance generation models. Current models often generate
monotonous and simplistic dance sequences that misalign with human preferences
because they lack exploration capabilities. The E3D2 framework involves a
reward model trained from automatically-ranked dance demonstrations, which then
guides the reinforcement learning process. This approach encourages the agent
to explore and generate high quality and diverse dance movement sequences. The
soundness of the reward model is both theoretically and experimentally
validated. Empirical experiments demonstrate the effectiveness of E3D2 on the
AIST++ dataset. Project Page: https://sites.google.com/view/e3d2.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11444" title="Abstract">arXiv:2312.11444</a> [<a href="/pdf/2312.11444" title="Download PDF">pdf</a>, <a href="/format/2312.11444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-depth Look at Gemini&#x27;s Language Abilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+S+N">Syeda Nahida Akter</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zichun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Muhamed%2C+A">Aashiq Muhamed</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+T">Tianyue Ou</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uerle%2C+A">Alex B&#xe4;uerle</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+%C3%81+A">&#xc1;ngel Alexander Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Dholakia%2C+K">Krish Dholakia</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chenyan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recently released Google Gemini class of models are the first to
comprehensively report results that rival the OpenAI GPT series across a wide
variety of tasks. In this paper, we do an in-depth exploration of Gemini's
language abilities, making two contributions. First, we provide a third-party,
objective comparison of the abilities of the OpenAI GPT and Google Gemini
models with reproducible code and fully transparent results. Second, we take a
closer look at the results, identifying areas where one of the two model
classes excels. We perform this analysis over 10 datasets testing a variety of
language abilities, including reasoning, answering knowledge-based questions,
solving math problems, translating between languages, generating code, and
acting as instruction-following agents. From this analysis, we find that Gemini
Pro achieves accuracy that is close but slightly inferior to the corresponding
GPT 3.5 Turbo on all tasks that we benchmarked. We further provide explanations
for some of this under-performance, including failures in mathematical
reasoning with many digits, sensitivity to multiple-choice answer ordering,
aggressive content filtering, and others. We also identify areas where Gemini
demonstrates comparably high performance, including generation into non-English
languages, and handling longer and more complex reasoning chains. Code and data
for reproduction can be found at https://github.com/neulab/gemini-benchmark
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11451" title="Abstract">arXiv:2312.11451</a> [<a href="/pdf/2312.11451" title="Download PDF">pdf</a>, <a href="/format/2312.11451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Assisted 3D Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiankun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, with supplementary material, 16 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 38th AAAI Conference on Artificial Intelligence (AAAI2024),
  Vancouver, BC, Canada, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The scale and quality of point cloud datasets constrain the advancement of
point cloud learning. Recently, with the development of multi-modal learning,
the incorporation of domain-agnostic prior knowledge from other modalities,
such as images and text, to assist in point cloud feature learning has been
considered a promising avenue. Existing methods have demonstrated the
effectiveness of multi-modal contrastive training and feature distillation on
point clouds. However, challenges remain, including the requirement for paired
triplet data, redundancy and ambiguity in supervised features, and the
disruption of the original priors. In this paper, we propose a
language-assisted approach to point cloud feature learning (LAST-PCL),
enriching semantic concepts through LLMs-based text enrichment. We achieve
de-redundancy and feature dimensionality reduction without compromising textual
priors by statistical-based and training-free significant feature selection.
Furthermore, we also delve into an in-depth analysis of the impact of text
contrastive training on the point cloud. Extensive experiments validate that
the proposed method learns semantically meaningful point cloud features and
achieves state-of-the-art or comparable performance in 3D semantic
segmentation, 3D object detection, and 3D scene classification tasks. The
source code is available at https://github.com/yanmin-wu/LAST-PCL.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11452" title="Abstract">arXiv:2312.11452</a> [<a href="/pdf/2312.11452" title="Download PDF">pdf</a>, <a href="/format/2312.11452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upwind summation-by-parts finite differences: error estimates and WENO  methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yan Jiang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Siyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">High order upwind summation-by-parts finite difference operators have
recently been developed. When combining with the
simultaneous-approximation-term method to impose boundary conditions, the
method converges faster than using traditional summation-by-parts operators. We
prove the convergence rate by the normal mode analysis for such methods for a
class of hyperbolic partial differential equations. Our analysis shows that the
penalty parameter for imposing boundary conditions affects the convergence rate
for stable methods. In addition, to solve problems with discontinuous data, we
extend the method to also have the weighted essentially nonoscillatory
property. The overall method is stable, achieves high order accuracy for smooth
problems, and is capable of solving problems with discontinuities.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11456" title="Abstract">arXiv:2312.11456</a> [<a href="/pdf/2312.11456" title="Download PDF">pdf</a>, <a href="/format/2312.11456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gibbs Sampling from Human Feedback: A Provable KL- constrained Framework  for RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hanze Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chenlu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper studies the theoretical framework of the alignment process of
generative models with Reinforcement Learning from Human Feedback (RLHF). We
consider a standard mathematical formulation, the reverse-KL regularized
contextual bandit for RLHF. Despite its widespread practical application, a
rigorous theoretical analysis of this formulation remains open. We investigate
its theoretical properties both in offline and online settings and propose
efficient algorithms with finite-sample theoretical guarantees. Our work
bridges the gap between theory and practice by linking our theoretical insights
with existing practical alignment algorithms such as Direct Preference
Optimization (DPO) and Rejection Sampling Optimization (RSO). Furthermore,
these findings and connections also offer both theoretical and practical
communities new tools and insights for future algorithmic design of alignment
algorithms.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11458" title="Abstract">arXiv:2312.11458</a> [<a href="/pdf/2312.11458" title="Download PDF">pdf</a>, <a href="/format/2312.11458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GauFRe: Gaussian Deformation Fields for Real-time Dynamic Novel View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yiqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+N">Numair Khan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Phuoc%2C+T">Thu Nguyen-Phuoc</a>, 
<a href="/search/cs?searchtype=author&query=Lanman%2C+D">Douglas Lanman</a>, 
<a href="/search/cs?searchtype=author&query=Tompkin%2C+J">James Tompkin</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a method for dynamic scene reconstruction using deformable 3D
Gaussians that is tailored for monocular video. Building upon the efficiency of
Gaussian splatting, our approach extends the representation to accommodate
dynamic elements via a deformable set of Gaussians residing in a canonical
space, and a time-dependent deformation field defined by a multi-layer
perceptron (MLP). Moreover, under the assumption that most natural scenes have
large regions that remain static, we allow the MLP to focus its
representational power by additionally including a static Gaussian point cloud.
The concatenated dynamic and static point clouds form the input for the
Gaussian Splatting rasterizer, enabling real-time rendering. The differentiable
pipeline is optimized end-to-end with a self-supervised rendering loss. Our
method achieves results that are comparable to state-of-the-art dynamic neural
radiance field methods while allowing much faster optimization and rendering.
Project website: https://lynl7130.github.io/gaufre/index.html
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11459" title="Abstract">arXiv:2312.11459</a> [<a href="/pdf/2312.11459" title="Download PDF">pdf</a>, <a href="/format/2312.11459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VolumeDiffusion: Flexible Text-to-3D Generation with Efficient  Volumetric Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhicong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a pioneering 3D volumetric encoder designed for
text-to-3D generation. To scale up the training data for the diffusion model, a
lightweight network is developed to efficiently acquire feature volumes from
multi-view images. The 3D volumes are then trained on a diffusion model for
text-to-3D generation using a 3D U-Net. This research further addresses the
challenges of inaccurate object captions and high-dimensional feature volumes.
The proposed model, trained on the public Objaverse dataset, demonstrates
promising outcomes in producing diverse and recognizable samples from text
prompts. Notably, it empowers finer control over object part characteristics
through textual cues, fostering model creativity by seamlessly combining
multiple concepts within a single object. This research significantly
contributes to the progress of 3D generation by introducing an efficient,
flexible, and scalable representation methodology. Code is available at
https://github.com/tzco/VolumeDiffusion.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11460" title="Abstract">arXiv:2312.11460</a> [<a href="/pdf/2312.11460" title="Download PDF">pdf</a>, <a href="/format/2312.11460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Internal Model: A Simple and Efficient Learner for Agile Legged  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+J">Junfeng Long</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiawei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Use 1 hour to train a quadruped robot capable of traversing any terrain under any disturbances in the open world, Project Page: <a href="https://github.com/OpenRobotLab/HIMLoco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Robust locomotion control depends on accurate state estimations. However, the
sensors of most legged robots can only provide partial and noisy observations,
making the estimation particularly challenging, especially for external states
like terrain frictions and elevation maps. Inspired by the classical Internal
Model Control principle, we consider these external states as disturbances and
introduce Hybrid Internal Model (HIM) to estimate them according to the
response of the robot. The response, which we refer to as the hybrid internal
embedding, contains the robot's explicit velocity and implicit stability
representation, corresponding to two primary goals for locomotion tasks:
explicitly tracking velocity and implicitly maintaining stability. We use
contrastive learning to optimize the embedding to be close to the robot's
successor state, in which the response is naturally embedded. HIM has several
appealing benefits: It only needs the robot's proprioceptions, i.e., those from
joint encoders and IMU as observations. It innovatively maintains consistent
observations between simulation reference and reality that avoids information
loss in mimicking learning. It exploits batch-level information that is more
robust to noises and keeps better sample efficiency. It only requires 1 hour of
training on an RTX 4090 to enable a quadruped robot to traverse any terrain
under any disturbances. A wealth of real-world experiments demonstrates its
agility, even in high-difficulty tasks and cases never occurred during the
training process, revealing remarkable open-world generalizability.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11461" title="Abstract">arXiv:2312.11461</a> [<a href="/pdf/2312.11461" title="Download PDF">pdf</a>, <a href="/format/2312.11461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAvatar: Animatable 3D Gaussian Avatars with Implicit Mesh Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>, 
<a href="/search/cs?searchtype=author&query=Nagano%2C+K">Koki Nagano</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://nvlabs.github.io/GAvatar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Gaussian splatting has emerged as a powerful 3D representation that harnesses
the advantages of both explicit (mesh) and implicit (NeRF) 3D representations.
In this paper, we seek to leverage Gaussian splatting to generate realistic
animatable avatars from textual descriptions, addressing the limitations (e.g.,
flexibility and efficiency) imposed by mesh or NeRF-based representations.
However, a naive application of Gaussian splatting cannot generate high-quality
animatable avatars and suffers from learning instability; it also cannot
capture fine avatar geometries and often leads to degenerate body parts. To
tackle these problems, we first propose a primitive-based 3D Gaussian
representation where Gaussians are defined inside pose-driven primitives to
facilitate animation. Second, to stabilize and amortize the learning of
millions of Gaussians, we propose to use neural implicit fields to predict the
Gaussian attributes (e.g., colors). Finally, to capture fine avatar geometries
and extract detailed meshes, we propose a novel SDF-based implicit mesh
learning approach for 3D Gaussians that regularizes the underlying geometries
and extracts highly detailed textured meshes. Our proposed method, GAvatar,
enables the large-scale generation of diverse animatable avatars using only
text prompts. GAvatar significantly surpasses existing methods in terms of both
appearance and geometry quality, and achieves extremely fast rendering (100
fps) at 1K resolution.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11462" title="Abstract">arXiv:2312.11462</a> [<a href="/pdf/2312.11462" title="Download PDF">pdf</a>, <a href="/format/2312.11462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascade Speculative Drafting for Even Faster LLM Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaocong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiacheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenkai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Speculative decoding enhances the efficiency of large language models (LLMs)
by leveraging a draft model to draft for a larger target model to review.
However, drafting in speculative decoding involves slow autoregressive
generation and generating tokens of different importance with the same time
allocation. These two inefficiencies lead to its suboptimal performance. To
address this issue, we introduce Cascade Speculative Drafting (CS. Drafting), a
novel approach that employs two types of cascades. The Vertical Cascade
eliminates autoregressive generation from neural models. The Horizontal Cascade
constitutes efficient time allocation in drafting with its optimality supported
by our theoretical analysis. Combining both cascades, our CS. Drafting
algorithm has achieved up to 72 percent additional speedup over speculative
decoding in our experiments while keeping the same output distribution.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11463" title="Abstract">arXiv:2312.11463</a> [<a href="/pdf/2312.11463" title="Download PDF">pdf</a>, <a href="/format/2312.11463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Appearance-based Refinement for Object-Centric Motion Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Junyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Total 26 pages, 13 figures (including main text: 9 pages, 5 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of this paper is to discover, segment, and track independently
moving objects in complex visual scenes. Previous approaches have explored the
use of optical flow for motion segmentation, leading to imperfect predictions
due to partial motion, background distraction, and object articulations and
interactions. To address this issue, we introduce an appearance-based
refinement method that leverages temporal consistency in video streams to
correct inaccurate flow-based proposals. Our approach involves a simple
selection mechanism that identifies accurate flow-predicted masks as exemplars,
and an object-centric architecture that refines problematic masks based on
exemplar information. The model is pre-trained on synthetic data and then
adapted to real-world videos in a self-supervised manner, eliminating the need
for human annotations. Its performance is evaluated on multiple video
segmentation benchmarks, including DAVIS, YouTubeVOS, SegTrackv2, and FBMS-59.
We achieve competitive performance on single-object segmentation, while
significantly outperforming existing models on the more challenging problem of
multi-object segmentation. Finally, we investigate the benefits of using our
model as a prompt for a per-frame Segment Anything Model.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 19 Dec 23</h3>
<dl>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18003" title="Abstract">arXiv:2311.18003</a> (cross-list from quant-ph) [<a href="/pdf/2311.18003" title="Download PDF">pdf</a>, <a href="/format/2311.18003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsystem CSS codes, a tighter stabilizer-to-CSS mapping, and Goursat&#x27;s  Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+M+L">Michael Liaofan Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tantivasadakarn%2C+N">Nathanan Tantivasadakarn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Albert%2C+V+V">Victor V. Albert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The CSS code construction is a powerful framework used to express features of
a quantum code in terms of a pair of underlying classical codes. Its subsystem
extension allows for similar expressions, but the general case has not been
fully explored. Extending previous work of Aly et. al. [<a href="/abs/quant-ph/0610153">quant-ph/0610153</a>], we
determine subsystem CSS code parameters, express codewords, and develop a
Steane-type decoder using only data from the two underlying classical codes. We
show that any subsystem stabilizer code can be ``doubled'' to yield a subsystem
CSS code with twice the number of physical, logical, and gauge qudits and up to
twice the code distance. This mapping preserves locality and is tighter than
the Majorana-based mapping of Bravyi, Leemhuis, and Terhal [New J. Phys. 12
083039 (2010)]. Using Goursat's Lemma, we show that every subsystem stabilizer
code can be constructed from two nested subsystem CSS codes satisfying certain
constraints, and we characterize subsystem stabilizer codes based on the nested
codes' properties.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10037" title="Abstract">arXiv:2312.10037</a> (cross-list from math.RA) [<a href="/pdf/2312.10037" title="Download PDF">pdf</a>, <a href="/ps/2312.10037" title="Download PostScript">ps</a>, <a href="/format/2312.10037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A system of dual quaternion matrix equations with its applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xie%2C+L">Lv-Ming Xie</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qing-Wen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Rings and Algebras (math.RA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We employ the M-P inverses and ranks of quaternion matrices to establish the
necessary and sufficient conditions for solving a system of the dual quaternion
matrix equations $(AX, XC) = (B, D)$, along with providing an expression for
its general solution. Serving as an application, we investigate the solutions
to the dual quaternion matrix equations $AX = B$ and $XC=D$, including
$\eta$-Hermitian solutions. Lastly, we design a numerical example to validate
the main research findings of this paper.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10040" title="Abstract">arXiv:2312.10040</a> (cross-list from physics.acc-ph) [<a href="/pdf/2312.10040" title="Download PDF">pdf</a>, <a href="/format/2312.10040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Errant Beam Prognostics with Conditional Modeling for Particle  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rajput%2C+k">kishansingh Rajput</a>, 
<a href="/search/physics?searchtype=author&query=Schram%2C+M">Malachi Schram</a>, 
<a href="/search/physics?searchtype=author&query=Blokland%2C+W">Willem Blokland</a>, 
<a href="/search/physics?searchtype=author&query=Alanazi%2C+Y">Yasir Alanazi</a>, 
<a href="/search/physics?searchtype=author&query=Ramuhalli%2C+P">Pradeep Ramuhalli</a>, 
<a href="/search/physics?searchtype=author&query=Zhukov%2C+A">Alexander Zhukov</a>, 
<a href="/search/physics?searchtype=author&query=Peters%2C+C">Charles Peters</a>, 
<a href="/search/physics?searchtype=author&query=Vilalta%2C+R">Ricardo Vilalta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at Machine Learning: Science and Technology Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Particle accelerators are complex and comprise thousands of components, with
many pieces of equipment running at their peak power. Consequently, particle
accelerators can fault and abort operations for numerous reasons. These faults
impact the availability of particle accelerators during scheduled run-time and
hamper the efficiency and the overall science output. To avoid these faults, we
apply anomaly detection techniques to predict any unusual behavior and perform
preemptive actions to improve the total availability of particle accelerators.
Semi-supervised Machine Learning (ML) based anomaly detection approaches such
as autoencoders and variational autoencoders are often used for such tasks.
However, supervised ML techniques such as Siamese Neural Network (SNN) models
can outperform unsupervised or semi-supervised approaches for anomaly detection
by leveraging the label information. One of the challenges specific to anomaly
detection for particle accelerators is the data's variability due to system
configuration changes. To address this challenge, we employ Conditional Siamese
Neural Network (CSNN) models and Conditional Variational Auto Encoder (CVAE)
models to predict errant beam pulses at the Spallation Neutron Source (SNS)
under different system configuration conditions and compare their performance.
We demonstrate that CSNN outperforms CVAE in our application.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10052" title="Abstract">arXiv:2312.10052</a> (cross-list from eess.SP) [<a href="/pdf/2312.10052" title="Download PDF">pdf</a>, <a href="/format/2312.10052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESTformer: Transformer Utilizing Spatiotemporal Dependencies for EEG  Super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Dongdong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Z">Zhongliang Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hai Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Towards practical applications of Electroencephalography (EEG) data,
lightweight acquisition devices, equipped with a few electrodes, result in a
predicament where analysis methods can only leverage EEG data with extremely
low spatial resolution. Recent methods mainly focus on using mathematical
interpolation methods and Convolutional Neural Networks for EEG
super-resolution (SR), but they suffer from high computation costs, extra bias,
and few insights in spatiotemporal dependency modeling. To this end, we propose
the ESTformer, an EEG SR framework utilizing spatiotemporal dependencies based
on the Transformer. The ESTformer applies positional encoding methods and the
Multi-head Self-attention mechanism to the space and time dimensions, which can
learn spatial structural information and temporal functional variation. The
ESTformer, with the fixed masking strategy, adopts a mask token to up-sample
the low-resolution (LR) EEG data in case of disturbance from mathematical
interpolation methods. On this basis, we design various Transformer blocks to
construct the Spatial Interpolation Module (SIM) and the Temporal
Reconstruction Module (TRM). Finally, the ESTformer cascades the SIM and the
TRM to capture and model spatiotemporal dependencies for EEG SR with fidelity.
Extensive experimental results on two EEG datasets show the effectiveness of
the ESTformer against previous state-of-the-art methods and verify the
superiority of the SR data to the LR data in EEG-based downstream tasks of
person identification and emotion recognition. The proposed ESTformer
demonstrates the versatility of the Transformer for EEG SR tasks.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10056" title="Abstract">arXiv:2312.10056</a> (cross-list from eess.SP) [<a href="/pdf/2312.10056" title="Download PDF">pdf</a>, <a href="/format/2312.10056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoEEGNet: An Interpretable Approach for Detecting Interictal  Epileptiform Discharges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+D">Dennis Tang</a>, 
<a href="/search/eess?searchtype=author&query=Willard%2C+F">Frank Willard</a>, 
<a href="/search/eess?searchtype=author&query=Tegerdine%2C+R">Ronan Tegerdine</a>, 
<a href="/search/eess?searchtype=author&query=Triplett%2C+L">Luke Triplett</a>, 
<a href="/search/eess?searchtype=author&query=Donnelly%2C+J">Jon Donnelly</a>, 
<a href="/search/eess?searchtype=author&query=Moffett%2C+L">Luke Moffett</a>, 
<a href="/search/eess?searchtype=author&query=Semenova%2C+L">Lesia Semenova</a>, 
<a href="/search/eess?searchtype=author&query=Barnett%2C+A+J">Alina Jade Barnett</a>, 
<a href="/search/eess?searchtype=author&query=Jing%2C+J">Jin Jing</a>, 
<a href="/search/eess?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/eess?searchtype=author&query=Westover%2C+B">Brandon Westover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In electroencephalogram (EEG) recordings, the presence of interictal
epileptiform discharges (IEDs) serves as a critical biomarker for seizures or
seizure-like events.Detecting IEDs can be difficult; even highly trained
experts disagree on the same sample. As a result, specialists have turned to
machine-learning models for assistance. However, many existing models are black
boxes and do not provide any human-interpretable reasoning for their decisions.
In high-stakes medical applications, it is critical to have interpretable
models so that experts can validate the reasoning of the model before making
important diagnoses. We introduce ProtoEEGNet, a model that achieves
state-of-the-art accuracy for IED detection while additionally providing an
interpretable justification for its classifications. Specifically, it can
reason that one EEG looks similar to another ''prototypical'' EEG that is known
to contain an IED. ProtoEEGNet can therefore help medical professionals
effectively detect IEDs while maintaining a transparent decision-making
process.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10068" title="Abstract">arXiv:2312.10068</a> (cross-list from eess.SP) [<a href="/pdf/2312.10068" title="Download PDF">pdf</a>, <a href="/format/2312.10068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of Physical Parameters of Waveforms With Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jamal%2C+S+A">Saad Ahmed Jamal</a>, 
<a href="/search/eess?searchtype=author&query=Corpetti%2C+T">Thomas Corpetti</a>, 
<a href="/search/eess?searchtype=author&query=Tiede%2C+D">Dirk Tiede</a>, 
<a href="/search/eess?searchtype=author&query=Letard%2C+M">Mathilde Letard</a>, 
<a href="/search/eess?searchtype=author&query=Lague%2C+D">Dimitri Lague</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Light Detection and Ranging (LiDAR) are fast emerging sensors in the field of
Earth Observation. It is a remote sensing technology that utilizes laser beams
to measure distances and create detailed three-dimensional representations of
objects and environments. The potential of Full Waveform LiDAR is much greater
than just height estimation and 3D reconstruction only. Overall shape of signal
provides important information about properties of water body. However, the
shape of FWL is unexplored as most LiDAR software work on point cloud by
utilizing the maximum value within the waveform. Existing techniques in the
field of LiDAR data analysis include depth estimation through inverse modeling
and regression of logarithmic intensity and depth for approximating the
attenuation coefficient. However, these methods suffer from limitations in
accuracy. Depth estimation through inverse modeling provides only approximate
values and does not account for variations in surface properties, while the
regression approach for the attenuation coefficient is only able to generalize
a value through several data points which lacks precision and may lead to
significant errors in estimation. Additionally, there is currently no
established modeling method available for predicting bottom reflectance. This
research proposed a novel solution based on neural networks for parameter
estimation in LIDAR data analysis. By leveraging the power of neural networks,
the proposed solution successfully learned the inversion model, was able to do
prediction of parameters such as depth, attenuation coefficient, and bottom
reflectance. Performance of model was validated by testing it on real LiDAR
data. In future, more data availability would enable more accuracy and
reliability of such models.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10081" title="Abstract">arXiv:2312.10081</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.10081" title="Download PDF">pdf</a>, <a href="/ps/2312.10081" title="Download PostScript">ps</a>, <a href="/format/2312.10081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Business Adoption of Quantum and AI Technology Must Be Ethical
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hoffmann%2C+C+H">Christian Hugo Hoffmann</a>, 
<a href="/search/physics?searchtype=author&query=Fl%C3%B6ther%2C+F+F">Frederik F. Fl&#xf6;ther</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Artificial intelligence (AI) recently had its 'iPhone moment' and adoption
has drastically accelerated. Quantum computing appears poised to follow suit
over the next years. However, while there has been discourse about how to use
AI responsibly, there is still little appreciation and awareness among
executives, managers, and practitioners about the broader ethical questions and
implications raised by the intersection of these emerging technologies. In this
article, it is highlighted why quantum computing and AI ethics must be taken
seriously by businesspersons and how these technologies affect strategic
decisions; moreover, recommendations and action areas are formulated.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10087" title="Abstract">arXiv:2312.10087</a> (cross-list from eess.AS) [<a href="/pdf/2312.10087" title="Download PDF">pdf</a>, <a href="/ps/2312.10087" title="Download PostScript">ps</a>, <a href="/format/2312.10087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Entropy Semiring for Neural Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+D">Dongseong Hwang</a>, 
<a href="/search/eess?searchtype=author&query=Siohan%2C+O">Olivier Siohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In streaming settings, speech recognition models have to map sub-sequences of
speech to text before the full audio stream becomes available. However, since
alignment information between speech and text is rarely available during
training, models need to learn it in a completely self-supervised way. In
practice, the exponential number of possible alignments makes this extremely
challenging, with models often learning peaky or sub-optimal alignments. Prima
facie, the exponential nature of the alignment space makes it difficult to even
quantify the uncertainty of a model's alignment distribution. Fortunately, it
has been known for decades that the entropy of a probabilistic finite state
transducer can be computed in time linear to the size of the transducer via a
dynamic programming reduction based on semirings. In this work, we revisit the
entropy semiring for neural speech recognition models, and show how alignment
entropy can be used to supervise models through regularization or distillation.
We also contribute an open-source implementation of CTC and RNN-T in the
semiring framework that includes numerically stable and highly parallel
variants of the entropy semiring. Empirically, we observe that the addition of
alignment distillation improves the accuracy and latency of an already
well-optimized teacher-student distillation model, achieving state-of-the-art
performance on the Librispeech dataset in the streaming scenario.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10088" title="Abstract">arXiv:2312.10088</a> (cross-list from eess.AS) [<a href="/pdf/2312.10088" title="Download PDF">pdf</a>, <a href="/ps/2312.10088" title="Download PostScript">ps</a>, <a href="/format/2312.10088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robustness to Missing Video for Audiovisual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/eess?searchtype=author&query=Braga%2C+O">Otavio Braga</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/eess?searchtype=author&query=Serdyuk%2C+D">Dmitriy Serdyuk</a>, 
<a href="/search/eess?searchtype=author&query=Siohan%2C+O">Olivier Siohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">It has been shown that learning audiovisual features can lead to improved
speech recognition performance over audio-only features, especially for noisy
speech. However, in many common applications, the visual features are partially
or entirely missing, e.g.~the speaker might move off screen. Multi-modal models
need to be robust: missing video frames should not degrade the performance of
an audiovisual model to be worse than that of a single-modality audio-only
model. While there have been many attempts at building robust models, there is
little consensus on how robustness should be evaluated. To address this, we
introduce a framework that allows claims about robustness to be evaluated in a
precise and testable way. We also conduct a systematic empirical study of the
robustness of common audiovisual speech recognition architectures on a range of
acoustic noise conditions and test suites. Finally, we show that an
architecture-agnostic solution based on cascades can consistently achieve
robustness to missing video, even in settings where existing techniques for
robustness like dropout fall short.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10102" title="Abstract">arXiv:2312.10102</a> (cross-list from stat.ML) [<a href="/pdf/2312.10102" title="Download PDF">pdf</a>, <a href="/format/2312.10102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Estimation of Causal Heteroscedastic Noise Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tran%2C+Q">Quang-Duy Tran</a>, 
<a href="/search/stat?searchtype=author&query=Duong%2C+B">Bao Duong</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+P">Phuoc Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T">Thin Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Distinguishing the cause and effect from bivariate observational data is the
foundational problem that finds applications in many scientific disciplines.
One solution to this problem is assuming that cause and effect are generated
from a structural causal model, enabling identification of the causal direction
after estimating the model in each direction. The heteroscedastic noise model
is a type of structural causal model where the cause can contribute to both the
mean and variance of the noise. Current methods for estimating heteroscedastic
noise models choose the Gaussian likelihood as the optimization objective which
can be suboptimal and unstable when the data has a non-Gaussian distribution.
To address this limitation, we propose a novel approach to estimating this
model with Student's $t$-distribution, which is known for its robustness in
accounting for sampling variability with smaller sample sizes and extreme
values without significantly altering the overall distribution shape. This
adaptability is beneficial for capturing the parameters of the noise
distribution in heteroscedastic noise models. Our empirical evaluations
demonstrate that our estimators are more robust and achieve better overall
performance across synthetic and real benchmarks.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10130" title="Abstract">arXiv:2312.10130</a> (cross-list from physics.data-an) [<a href="/pdf/2312.10130" title="Download PDF">pdf</a>, <a href="/format/2312.10130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving new physics searches with diffusion models for event  observables and jet constituents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sengupta%2C+D">Debajyoti Sengupta</a>, 
<a href="/search/physics?searchtype=author&query=Leigh%2C+M">Matthew Leigh</a>, 
<a href="/search/physics?searchtype=author&query=Raine%2C+J+A">John Andrew Raine</a>, 
<a href="/search/physics?searchtype=author&query=Klein%2C+S">Samuel Klein</a>, 
<a href="/search/physics?searchtype=author&query=Golling%2C+T">Tobias Golling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph)

</div>
<p class="mathjax">We introduce a new technique called Drapes to enhance the sensitivity in
searches for new physics at the LHC. By training diffusion models on side-band
data, we show how background templates for the signal region can be generated
either directly from noise, or by partially applying the diffusion process to
existing data. In the partial diffusion case, data can be drawn from side-band
regions, with the inverse diffusion performed for new target conditional
values, or from the signal region, preserving the distribution over the
conditional property that defines the signal region. We apply this technique to
the hunt for resonances using the LHCO di-jet dataset, and achieve
state-of-the-art performance for background template generation using high
level input features. We also show how Drapes can be applied to low level
inputs with jet constituents, reducing the model dependence on the choice of
input observables. Using jet constituents we can further improve sensitivity to
the signal process, but observe a loss in performance where the signal
significance before applying any selection is below 4$\sigma$.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10156" title="Abstract">arXiv:2312.10156</a> (cross-list from quant-ph) [<a href="/pdf/2312.10156" title="Download PDF">pdf</a>, <a href="/format/2312.10156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secret extraction attacks against obfuscated IQP circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gross%2C+D">David Gross</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hangleiter%2C+D">Dominik Hangleiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Quantum computing devices can now perform sampling tasks which, according to
complexity-theoretic and numerical evidence, are beyond the reach of classical
computers. This raises the question of how one can efficiently verify that a
quantum computer operating in this regime works as intended. In 2008, Shepherd
and Bremner proposed a protocol in which a verifier constructs a unitary from
the comparatively easy-to-implement family of so-called IQP circuits, and
challenges a prover to execute it on a quantum computer. The challenge problem
is designed to contain an obfuscated secret, which can be turned into a
statistical test that accepts samples from a correct quantum implementation. It
was conjectured that extracting the secret from the challenge problem is
NP-hard, so that the ability to pass the test constitutes strong evidence that
the prover possesses a quantum device and that it works as claimed.
Unfortunately, about a decade later, Kahanamoku-Meyer found an efficient
classical secret extraction attack. Bremner, Cheng, and Ji very recently
followed up by constructing a wide-ranging generalization of the original
protocol. Their IQP Stabilizer Scheme has been explicitly designed to
circumvent the known weakness. They also suggested that the original
construction can be made secure by adjusting the problem parameters. In this
work, we develop a number of secret extraction attacks which are effective
against both new approaches in a wide range of problem parameters. The
important problem of finding an efficient and reliable verification protocol
for sampling-based proofs of quantum supremacy thus remains open.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10187" title="Abstract">arXiv:2312.10187</a> (cross-list from eess.SP) [<a href="/pdf/2312.10187" title="Download PDF">pdf</a>, <a href="/format/2312.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSRNet: Simple Framework for Real-time ECG Anomaly Detection with  Multimodal Time and Spectrogram Restoration Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Phan%2C+T">Thinh Phan</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+B">Brijesh Patel</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The electrocardiogram (ECG) is a valuable signal used to assess various
aspects of heart health, such as heart rate and rhythm. It plays a crucial role
in identifying cardiac conditions and detecting anomalies in ECG data. However,
distinguishing between normal and abnormal ECG signals can be a challenging
task. In this paper, we propose an approach that leverages anomaly detection to
identify unhealthy conditions using solely normal ECG data for training.
Furthermore, to enhance the information available and build a robust system, we
suggest considering both the time series and time-frequency domain aspects of
the ECG signal. As a result, we introduce a specialized network called the
Multimodal Time and Spectrogram Restoration Network (TSRNet) designed
specifically for detecting anomalies in ECG signals. TSRNet falls into the
category of restoration-based anomaly detection and draws inspiration from both
the time series and spectrogram domains. By extracting representations from
both domains, TSRNet effectively captures the comprehensive characteristics of
the ECG signal. This approach enables the network to learn robust
representations with superior discrimination abilities, allowing it to
distinguish between normal and abnormal ECG patterns more effectively.
Furthermore, we introduce a novel inference method, termed Peak-based Error,
that specifically focuses on ECG peaks, a critical component in detecting
abnormalities. The experimental result on the large-scale dataset PTB-XL has
demonstrated the effectiveness of our approach in ECG anomaly detection, while
also prioritizing efficiency by minimizing the number of trainable parameters.
Our code is available at https://github.com/UARK-AICV/TSRNet.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10197" title="Abstract">arXiv:2312.10197</a> (cross-list from math.OC) [<a href="/pdf/2312.10197" title="Download PDF">pdf</a>, <a href="/format/2312.10197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport of Linear Systems over Equilibrium Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elamvazhuthi%2C+K">Karthik Elamvazhuthi</a>, 
<a href="/search/math?searchtype=author&query=Jacobs%2C+M">Matt Jacobs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider the optimal transport problem over convex costs arising from
optimal control of linear time-invariant(LTI) systems when the initial and
target measures are assumed to be supported on the set of equilibrium points of
the LTI system. In this case, the probability measures are singular with
respect to the Lebesgue measure, thus not considered in previous results on
optimal transport of linear systems. This problem is motivated by applications,
such as robotics, where the initial and target configurations of robots,
represented by measures, are in equilibrium or stationary. Despite the singular
nature of the measures, for many cases of practical interest, we show that the
Monge problem has a solution by applying classical optimal transport results.
Moreover, the problem is computationally tractable even if the state space of
the LTI system is moderately high in dimension, provided the equilibrium set
lives in a low dimensional space. In fact, for an important subclass of linear
quadratic problems, such as control of the double integrator with linear
quadratic cost, the optimal transport map happens to coincide with that of the
Euclidean cost. We demonstrate our results by computing the optimal transport
map for the minimum energy cost for a two dimensional double integrator,
despite the fact that the state space is four dimensional due to position and
velocity variables.
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10204" title="Abstract">arXiv:2312.10204</a> (cross-list from math.LO) [<a href="/pdf/2312.10204" title="Download PDF">pdf</a>, <a href="/ps/2312.10204" title="Download PostScript">ps</a>, <a href="/format/2312.10204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normality, Relativization, and Randomness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Calvert%2C+W">Wesley Calvert</a>, 
<a href="/search/math?searchtype=author&query=Grunner%2C+E">Emma Grunner</a>, 
<a href="/search/math?searchtype=author&query=Mayordomo%2C+E">Elvira Mayordomo</a>, 
<a href="/search/math?searchtype=author&query=Turetsky%2C+D">Daniel Turetsky</a>, 
<a href="/search/math?searchtype=author&query=Villano%2C+J+D">Java Darleen Villano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Information Theory (cs.IT); Number Theory (math.NT)

</div>
<p class="mathjax">Normal numbers were introduced by Borel. Normality is certainly a weak notion
of randomness; for instance, there are computable numbers which are absolutely
normal. In the present paper, we introduce a relativization of normality to a
fixed representation system. When we require normality with respect to large
sets of such systems, we find variants of normality that imply randomness
notions much stronger than absolute normality.
<br />The primary classes of numbers investigated in this paper are the supernormal
numbers and the highly normal numbers, which we will define. These are
relativizations of normality which are robust to all reasonable changes of
representation.
<br />Among other results, we give a proof that the highly normal numbers are
exactly those of computable dimension 1, which we think gives a more natural
characterization than was previously known of this interesting class.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10218" title="Abstract">arXiv:2312.10218</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2312.10218" title="Download PDF">pdf</a>, <a href="/format/2312.10218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multifidelity Bayesian optimization method for inertial confinement  fusion design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+J">J. Wang</a>, 
<a href="/search/physics?searchtype=author&query=Chiang%2C+N">N. Chiang</a>, 
<a href="/search/physics?searchtype=author&query=Gillette%2C+A">A. Gillette</a>, 
<a href="/search/physics?searchtype=author&query=Peterson%2C+J+L">J. L. Peterson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Due to their cost, experiments for inertial confinement fusion (ICF) heavily
rely on numerical simulations to guide design. As simulation technology
progresses, so too can the fidelity of models used to plan for new experiments.
However, these high-fidelity models are by themselves insufficient for optimal
experimental design, because their computational cost remains too high to
efficiently and effectively explore the numerous parameters required to
describe a typical experiment. Traditionally, ICF design has relied on
low-fidelity modeling to initially identify potentially interesting design
regions, which are then subsequently explored via selected high-fidelity
modeling. In this paper, we demonstrate that this two-step approach can be
insufficient: even for simple design problems, a two-step optimization strategy
can lead high-fidelity searching towards incorrect regions and consequently
waste computational resources on parameter regimes far away from the true
optimal solution. We reveal that a primary cause of this behavior in ICF design
problems is the presence of low-fidelity optima in distinct regions of the
parameter space from high-fidelity optima. To address this issue, we propose an
iterative multifidelity Bayesian optimization method based on Gaussian Process
Regression that leverages both low- and high-fidelity modelings. We
demonstrate, using both two- and eight-dimensional ICF test problems, that our
algorithm can effectively utilize low-fidelity modeling for exploration, while
automatically refining promising designs with high-fidelity models. This
approach proves to be more efficient than relying solely on high-fidelity
modeling for optimization.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10224" title="Abstract">arXiv:2312.10224</a> (cross-list from math.OC) [<a href="/pdf/2312.10224" title="Download PDF">pdf</a>, <a href="/format/2312.10224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Expansion Planning of Power and Water Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hari%2C+S+K+K">Sai Krishna Kanth Hari</a>, 
<a href="/search/math?searchtype=author&query=Zamzam%2C+A">Ahmed Zamzam</a>, 
<a href="/search/math?searchtype=author&query=Tasseff%2C+B">Byron Tasseff</a>, 
<a href="/search/math?searchtype=author&query=Bent%2C+R">Russell Bent</a>, 
<a href="/search/math?searchtype=author&query=Barrows%2C+C">Clayton Barrows</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This research explores the joint expansion planning of power and water
distribution networks, which exhibit interdependence at various levels. We
specifically focus on the dependency arising from the power consumption of
pumps and develop models to seamlessly integrate new components into existing
networks. Subsequently, we formulate the joint expansion planning as a Mixed
Integer Nonlinear Program (MINLP). Through the application of this MINLP to a
small-scale test network, we demonstrate the advantages of combining expansion
planning, including cost savings and reduced redundancy, in comparison to
independently expanding power and water distribution networks
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10242" title="Abstract">arXiv:2312.10242</a> (cross-list from quant-ph) [<a href="/pdf/2312.10242" title="Download PDF">pdf</a>, <a href="/format/2312.10242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Classical And Quantum Sequence Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+I">I-Chi Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Singh%2C+H">Harshdeep Singh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Anukruti%2C+V+L">V L Anukruti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Quanz%2C+B">Brian Quanz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yogaraj%2C+K">Kavitha Yogaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, accepted as a COMSNETS paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Our primary objective is to conduct a brief survey of various classical and
quantum neural net sequence models, which includes self-attention and recurrent
neural networks, with a focus on recent quantum approaches proposed to work
with near-term quantum devices, while exploring some basic enhancements for
these quantum models. We re-implement a key representative set of these
existing methods, adapting an image classification approach using quantum
self-attention to create a quantum hybrid transformer that works for text and
image classification, and applying quantum self-attention and quantum recurrent
neural networks to natural language processing tasks. We also explore different
encoding techniques and introduce positional encoding into quantum
self-attention neural networks leading to improved accuracy and faster
convergence in text and image classification experiments. This paper also
performs a comparative analysis of classical self-attention models and their
quantum counterparts, helping shed light on the differences in these models and
their performance.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10243" title="Abstract">arXiv:2312.10243</a> (cross-list from math.DS) [<a href="/pdf/2312.10243" title="Download PDF">pdf</a>, <a href="/format/2312.10243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Closures &amp; Assimilation for Stiff Multiscale Random Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maltba%2C+T+E">Tyler E. Maltba</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+H">Hongli Zhao</a>, 
<a href="/search/math?searchtype=author&query=Maldonado%2C+D+A">D. Adrian Maldonado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We introduce a data-driven and physics-informed framework for propagating
uncertainty in stiff, multiscale random ordinary differential equations (RODEs)
driven by correlated (colored) noise. Unlike systems subjected to Gaussian
white noise, a deterministic equation for the joint probability density
function (PDF) of RODE state variables does not exist in closed form. Moreover,
such an equation would require as many phase-space variables as there are
states in the RODE system. To alleviate this curse of dimensionality, we
instead derive exact, albeit unclosed, reduced-order PDF (RoPDF) equations for
low-dimensional observables/quantities of interest. The unclosed terms take the
form of state-dependent conditional expectations, which are directly estimated
from data at sparse observation times. However, for systems exhibiting stiff,
multiscale dynamics, data sparsity introduces regression discrepancies that
compound during RoPDF evolution. This is overcome by introducing a kinetic-like
defect term to the RoPDF equation, which is learned by assimilating in sparse,
low-fidelity RoPDF estimates. Two assimilation methods are considered, namely
nudging and deep neural networks, which are successfully tested against Monte
Carlo simulations.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10270" title="Abstract">arXiv:2312.10270</a> (cross-list from stat.ML) [<a href="/pdf/2312.10270" title="Download PDF">pdf</a>, <a href="/format/2312.10270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Models for Fuzzy Clustering Similarity Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=DeWolfe%2C+R">Ryan DeWolfe</a>, 
<a href="/search/stat?searchtype=author&query=Andrews%2C+J+L">Jeffery L. Andrews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Adjusted Rand Index (ARI) is a widely used method for comparing hard
clusterings, but requires a choice of random model that is often left implicit.
Several recent works have extended the Rand Index to fuzzy clusterings, but the
assumptions of the most common random model is difficult to justify in fuzzy
settings. We propose a single framework for computing the ARI with three random
models that are intuitive and explainable for both hard and fuzzy clusterings,
along with the benefit of lower computational complexity. The theory and
assumptions of the proposed models are contrasted with the existing permutation
model. Computations on synthetic and benchmark data show that each model has
distinct behaviour, meaning that accurate model selection is important for the
reliability of results.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10271" title="Abstract">arXiv:2312.10271</a> (cross-list from eess.IV) [<a href="/pdf/2312.10271" title="Download PDF">pdf</a>, <a href="/format/2312.10271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness of Deep Learning for Accelerated MRI: Benefits of Diverse  Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+K">Kang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Heckel%2C+R">Reinhard Heckel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning based methods for image reconstruction are state-of-the-art for
a variety of imaging tasks. However, neural networks often perform worse if the
training data differs significantly from the data they are applied to. For
example, a network trained for accelerated magnetic resonance imaging (MRI) on
one scanner performs worse on another scanner. In this work, we investigate the
impact of the training data on the model's performance and robustness for
accelerated MRI. We find that models trained on the combination of various data
distributions, such as those obtained from different MRI scanners and
anatomies, exhibit robustness equal or superior to models trained on the best
single distribution for a specific target distribution. Thus training on
diverse data tends to improve robustness. Furthermore, training on diverse data
does not compromise in-distribution performance, i.e., a model trained on
diverse data yields in-distribution performance at least as good as models
trained on the more narrow individual distributions. Our results suggest that
training a model for imaging on a variety of distributions tends to yield a
more effective and robust model than maintaining separate models for individual
distributions.
</p>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10283" title="Abstract">arXiv:2312.10283</a> (cross-list from math.OC) [<a href="/pdf/2312.10283" title="Download PDF">pdf</a>, <a href="/format/2312.10283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cubic-quartic regularization models for solving polynomial subproblems  in third-order tensor methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhu%2C+W">Wenqi Zhu</a>, 
<a href="/search/math?searchtype=author&query=Cartis%2C+C">Coralia Cartis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">High-order tensor methods for solving both convex and nonconvex optimization
problems have generated significant research interest, leading to algorithms
with optimal global rates of convergence and local rates that are faster than
Newton's method. On each iteration, these methods require the unconstrained
local minimization of a (potentially nonconvex) multivariate polynomial of
degree higher than two, constructed using third-order (or higher) derivative
information, and regularized by an appropriate power of regularization.
Developing efficient techniques for solving such subproblems is an ongoing
topic of research, and this paper addresses the case of the third-order tensor
subproblem. We propose the CQR algorithmic framework, for minimizing a
nonconvex Cubic multivariate polynomial with Quartic Regularisation, by
minimizing a sequence of local quadratic models that incorporate simple cubic
and quartic terms. The role of the cubic term is to crudely approximate local
tensor information, while the quartic one controls model regularization and
progress. We provide necessary and sufficient optimality conditions that fully
characterise the global minimizers of these cubic-quartic models. We then turn
these conditions into secular equations that can be solved using nonlinear
eigenvalue techniques. We show, using our optimality characterisations, that a
CQR algorithmic variant has the optimal-order evaluation complexity of
$\mathcal{O}(\epsilon^{-3/2})$ when applied to minimizing our
quartically-regularised cubic subproblem, which can be further improved in
special cases. We propose practical CQR variants that use local tensor
information to construct the local cubic-quartic models. We test these variants
numerically and observe them to be competitive with ARC and other subproblem
solvers on typical instances and even superior on ill-conditioned subproblems
with special structure.
</p>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10295" title="Abstract">arXiv:2312.10295</a> (cross-list from math.OC) [<a href="/pdf/2312.10295" title="Download PDF">pdf</a>, <a href="/format/2312.10295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Generalization of Wasserstein Distance and the Beckmann Problem to  Connection Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Robertson%2C+S">Sawyer Robertson</a>, 
<a href="/search/math?searchtype=author&query=Kohli%2C+D">Dhruv Kohli</a>, 
<a href="/search/math?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>, 
<a href="/search/math?searchtype=author&query=Cloninger%2C+A">Alexander Cloninger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The intersection of connection graphs and discrete optimal transport presents
a novel paradigm for understanding complex graphs and node interactions. In
this paper, we delve into this unexplored territory by focusing on the Beckmann
problem within the context of connection graphs. Our study establishes
feasibility conditions for the resulting convex optimization problem on
connection graphs. Furthermore, we establish strong duality for the
conventional Beckmann problem, and extend our analysis to encompass strong
duality and duality correspondence for a quadratically regularized variant. To
put our findings into practice, we implement the regularized problem using
gradient descent, enabling a practical approach to solving this complex
problem. We showcase optimal flows and solutions, providing valuable insights
into the real-world implications of our theoretical framework.
</p>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10298" title="Abstract">arXiv:2312.10298</a> (cross-list from quant-ph) [<a href="/pdf/2312.10298" title="Download PDF">pdf</a>, <a href="/format/2312.10298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Qubit Reuse and Circuit Cutting for Large Quantum Circuit  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pawar%2C+A">Aditya Pawar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yingheng Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mo%2C+Z">Zewei Mo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guo%2C+Y">Yanan Guo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Y">Youtao Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tang%2C+X">Xulong Tang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+J">Jun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing has recently emerged as a promising computing paradigm for
many application domains. However, the size of quantum circuits that can run
with high fidelity is constrained by the limited quantity and quality of
physical qubits. Recently proposed schemes, such as wire cutting and qubit
reuse, mitigate the problem but produce sub-optimal results as they address the
problem individually. In addition, gate cutting, an alternative circuit-cutting
strategy, has not been fully explored in the field.
<br />In this paper, we propose IQRC, an integrated approach that exploits qubit
reuse and circuit cutting (including wire cutting and gate cutting) to run
large circuits on small quantum computers. Circuit-cutting techniques introduce
non-negligible post-processing overhead, which increases exponentially with the
number of cuts. IQRC exploits qubit reuse to find better cutting solutions to
minimize the cut numbers and thus the post-processing overhead. Our evaluation
results show that on average we reduce the number of cuts by 34\% and
additional reduction when considering gate cuts.
</p>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10343" title="Abstract">arXiv:2312.10343</a> (cross-list from eess.SP) [<a href="/pdf/2312.10343" title="Download PDF">pdf</a>, <a href="/format/2312.10343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Sensor Radio Frequency Computing for Energy-Efficient Intelligent  Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sui%2C+Y">Yang Sui</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+M">Minning Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Lingyi Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C+M">Chung-Tse Michael Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Radio Frequency Neural Networks (RFNNs) have demonstrated advantages in
realizing intelligent applications across various domains. However, as the
model size of deep neural networks rapidly increases, implementing large-scale
RFNN in practice requires an extensive number of RF interferometers and
consumes a substantial amount of energy. To address this challenge, we propose
to utilize low-rank decomposition to transform a large-scale RFNN into a
compact RFNN while almost preserving its accuracy. Specifically, we develop a
Tensor-Train RFNN (TT-RFNN) where each layer comprises a sequence of low-rank
third-order tensors, leading to a notable reduction in parameter count, thereby
optimizing RF interferometer utilization in comparison to the original
large-scale RFNN. Additionally, considering the inherent physical errors when
mapping TT-RFNN to RF device parameters in real-world deployment, from a
general perspective, we construct the Robust TT-RFNN (RTT-RFNN) by
incorporating a robustness solver on TT-RFNN to enhance its robustness. To
adapt the RTT-RFNN to varying requirements of reshaping operations, we further
provide a reconfigurable reshaping solution employing RF switch matrices.
Empirical evaluations conducted on MNIST and CIFAR-10 datasets show the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10388" title="Abstract">arXiv:2312.10388</a> (cross-list from stat.ME) [<a href="/pdf/2312.10388" title="Download PDF">pdf</a>, <a href="/format/2312.10388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Causal Impact of Credit Lines on Spending Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yijun Li</a>, 
<a href="/search/stat?searchtype=author&query=Leung%2C+C+H">Cheuk Hang Leung</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+X">Xiangqian Sun</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+C">Chaoqun Wang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+Y">Yiyan Huang</a>, 
<a href="/search/stat?searchtype=author&query=Yan%2C+X">Xing Yan</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+D">Dongdong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+Z">Zhixiang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); General Finance (q-fin.GN)

</div>
<p class="mathjax">Consumer credit services offered by e-commerce platforms provide customers
with convenient loan access during shopping and have the potential to stimulate
sales. To understand the causal impact of credit lines on spending, previous
studies have employed causal estimators, based on direct regression (DR),
inverse propensity weighting (IPW), and double machine learning (DML) to
estimate the treatment effect. However, these estimators do not consider the
notion that an individual's spending can be understood and represented as a
distribution, which captures the range and pattern of amounts spent across
different orders. By disregarding the outcome as a distribution, valuable
insights embedded within the outcome distribution might be overlooked. This
paper develops a distribution-valued estimator framework that extends existing
real-valued DR-, IPW-, and DML-based estimators to distribution-valued
estimators within Rubin's causal framework. We establish their consistency and
apply them to a real dataset from a large e-commerce platform. Our findings
reveal that credit lines positively influence spending across all quantiles;
however, as credit lines increase, consumers allocate more to luxuries (higher
quantiles) than necessities (lower quantiles).
</p>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10399" title="Abstract">arXiv:2312.10399</a> (cross-list from quant-ph) [<a href="/pdf/2312.10399" title="Download PDF">pdf</a>, <a href="/format/2312.10399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning, Optimizing, and Simulating Fermions with Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+A">Andrew Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis. Includes a background and overview of many-fermion systems, quantum-state learning, and NISQ/error mitigation. Main chapters are based on <a href="/abs/2010.16094">arXiv:2010.16094</a> (new: lower bound on sample complexity for local fermionic estimation), <a href="/abs/2310.03071">arXiv:2310.03071</a>, <a href="/abs/1908.08067">arXiv:1908.08067</a> (new: connection between unitary partitioning and matchgate circuits), and <a href="/abs/2301.01778">arXiv:2301.01778</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Fermions are fundamental particles which obey seemingly bizarre
quantum-mechanical principles, yet constitute all the ordinary matter that we
inhabit. As such, their study is heavily motivated from both fundamental and
practical incentives. In this dissertation, we will explore how the tools of
quantum information and computation can assist us on both of these fronts. We
primarily do so through the task of partial state learning: tomographic
protocols for acquiring a reduced, but sufficient, classical description of a
quantum system. Developing fast methods for partial tomography addresses a
critical bottleneck in quantum simulation algorithms, which is a particularly
pressing issue for currently available, imperfect quantum machines. At the same
time, in the search for such protocols, we also refine our notion of what it
means to learn quantum states. One important example is the ability to
articulate, from a computational perspective, how the learning of fermions
contrasts with other types of particles.
</p>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10429" title="Abstract">arXiv:2312.10429</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.10429" title="Download PDF">pdf</a>, <a href="/format/2312.10429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResoNet: Robust and Explainable ENSO Forecasts with Hybrid Convolution  and Transformer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lyu%2C+P">Pumeng Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Tang%2C+T">Tao Tang</a>, 
<a href="/search/physics?searchtype=author&query=Ling%2C+F">Fenghua Ling</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+J">Jing-Jia Luo</a>, 
<a href="/search/physics?searchtype=author&query=Boers%2C+N">Niklas Boers</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/physics?searchtype=author&query=Bai%2C+L">Lei Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 main figures and 12 supplementary figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent studies have shown that deep learning (DL) models can skillfully
predict the El Ni\~no-Southern Oscillation (ENSO) forecasts over 1.5 years
ahead. However, concerns regarding the reliability of predictions made by DL
methods persist, including potential overfitting issues and lack of
interpretability. Here, we propose ResoNet, a DL model that combines
convolutional neural network (CNN) and Transformer architectures. This hybrid
architecture design enables our model to adequately capture local SSTA as well
as long-range inter-basin interactions across oceans. We show that ResoNet can
robustly predict ESNO at lead times between 19 and 26 months, thus
outperforming existing approaches in terms of the forecast horizon. According
to an explainability method applied to ResoNet predictions of El Ni\~no and La
Ni\~na events from 1- to 18-month lead, we find that it predicts the Ni\~no3.4
index based on multiple physically reasonable mechanisms, such as the Recharge
Oscillator concept, Seasonal Footprint Mechanism, and Indian Ocean capacitor
effect. Moreover, we demonstrate that for the first time, the asymmetry between
El Ni\~no and La Ni\~na development can be captured by ResoNet. Our results
could help alleviate skepticism about applying DL models for ENSO prediction
and encourage more attempts to discover and predict climate phenomena using AI
methods.
</p>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10435" title="Abstract">arXiv:2312.10435</a> (cross-list from stat.ME) [<a href="/pdf/2312.10435" title="Download PDF">pdf</a>, <a href="/format/2312.10435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Heterogeneous Treatment Effect Estimation  with Gaussian-Process-Based Partially Linear Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Horii%2C+S">Shunsuke Horii</a>, 
<a href="/search/stat?searchtype=author&query=Chikahara%2C+Y">Yoichi Chikahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, accepted at The 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Estimating heterogeneous treatment effects across individuals has attracted
growing attention as a statistical tool for performing critical
decision-making. We propose a Bayesian inference framework that quantifies the
uncertainty in treatment effect estimation to support decision-making in a
relatively small sample size setting. Our proposed model places Gaussian
process priors on the nonparametric components of a semiparametric model called
a partially linear model. This model formulation has three advantages. First,
we can analytically compute the posterior distribution of a treatment effect
without relying on the computationally demanding posterior approximation.
Second, we can guarantee that the posterior distribution concentrates around
the true one as the sample size goes to infinity. Third, we can incorporate
prior knowledge about a treatment effect into the prior distribution, improving
the estimation efficiency. Our experimental results show that even in the small
sample size setting, our method can accurately estimate the heterogeneous
treatment effects and effectively quantify its estimation uncertainty.
</p>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10438" title="Abstract">arXiv:2312.10438</a> (cross-list from eess.SP) [<a href="/pdf/2312.10438" title="Download PDF">pdf</a>, <a href="/format/2312.10438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes-Optimal Unsupervised Learning for Channel Estimation in Near-Field  Holographic MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wentao Yu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+H">Hengtao He</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xianghao Yu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Shenghui Song</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Murch%2C+R+D">Ross D. Murch</a>, 
<a href="/search/eess?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 2 tables, submitted to IEEE journal. arXiv admin note: text overlap with <a href="/abs/2311.07908">arXiv:2311.07908</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Holographic MIMO (HMIMO) is being increasingly recognized as a key enabling
technology for 6G wireless systems through the deployment of an extremely large
number of antennas within a compact space to fully exploit the potentials of
the electromagnetic (EM) channel. Nevertheless, the benefits of HMIMO systems
cannot be fully unleashed without an efficient means to estimate the
high-dimensional channel, whose distribution becomes increasingly complicated
due to the accessibility of the near-field region. In this paper, we address
the fundamental challenge of designing a low-complexity Bayes-optimal channel
estimator in near-field HMIMO systems operating in unknown EM environments. The
core idea is to estimate the HMIMO channels solely based on the Stein's score
function of the received pilot signals and an estimated noise level, without
relying on priors or supervision that is not feasible in practical deployment.
A neural network is trained with the unsupervised denoising score matching
objective to learn the parameterized score function. Meanwhile, a principal
component analysis (PCA)-based algorithm is proposed to estimate the noise
level leveraging the low-rank near-field spatial correlation. Building upon
these techniques, we develop a Bayes-optimal score-based channel estimator for
fully-digital HMIMO transceivers in a closed form. The optimal score-based
estimator is also extended to hybrid analog-digital HMIMO systems by
incorporating it into a low-complexity message passing algorithm. The (quasi-)
Bayes-optimality of the proposed estimators is validated both in theory and by
extensive simulation results. In addition to optimality, it is shown that our
proposal is robust to various mismatches and can quickly adapt to dynamic EM
environments in an online manner thanks to its unsupervised nature,
demonstrating its potential in real-world deployment.
</p>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10476" title="Abstract">arXiv:2312.10476</a> (cross-list from econ.GN) [<a href="/pdf/2312.10476" title="Download PDF">pdf</a>, <a href="/format/2312.10476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sails and Anchors: The Complementarity of Exploratory and Exploitative  Scientists in Knowledge Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Pelletier%2C+P">Pierre Pelletier</a>, 
<a href="/search/econ?searchtype=author&query=Wirtz%2C+K">Kevin Wirtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">This paper investigates the relationship between scientists' cognitive
profile and their ability to generate innovative ideas and gain scientific
recognition. We propose a novel author-level metric based on the semantic
representation of researchers' past publications to measure cognitive diversity
both at individual and team levels. Using PubMed Knowledge Graph (PKG), we
analyze the impact of cognitive diversity on novelty, as measured by
combinatorial novelty indicators and peer labels on Faculty Opinion. We
assessed scientific impact through citations and disruption indicators. We show
that the presence of exploratory individuals (i.e., cognitively diverse) is
beneficial in generating distant knowledge combinations, but only when balanced
by a significant proportion of exploitative individuals (i.e., cognitively
specialized). Furthermore, teams with a high proportion of exploitative
profiles tend to consolidate science, whereas those with a significant share of
both profiles tend to disrupt it. Cognitive diversity between team members
appears to be always beneficial to combining more distant knowledge. However,
to maximize the relevance of these distant combinations of knowledge,
maintaining a limited number of exploratory individuals is essential, as
exploitative individuals must question and debate their novel perspectives.
These specialized individuals are the most qualified to extract the full
potential of novel ideas and integrate them within the existing scientific
paradigm.
</p>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10483" title="Abstract">arXiv:2312.10483</a> (cross-list from eess.IV) [<a href="/pdf/2312.10483" title="Download PDF">pdf</a>, <a href="/format/2312.10483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Attention U-NET for Semantic Segmentation of Intracranial  Hemorrhages In Head CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+C+S">Chia Shuo Chang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+T+S">Tian Sheuan Chang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+J+L">Jiun Lin Yan</a>, 
<a href="/search/eess?searchtype=author&query=Ko%2C+L">Li Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2022 IEEE Biomedical Circuits and Systems Conference (BioCAS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Intracranial hemorrhages in head CT scans serve as a first line tool to help
specialists diagnose different types. However, their types have diverse shapes
in the same type but similar confusing shape, size and location between types.
To solve this problem, this paper proposes an all attention U-Net. It uses
channel attentions in the U-Net encoder side to enhance class specific feature
extraction, and space and channel attentions in the U-Net decoder side for more
accurate shape extraction and type classification. The simulation results show
up to a 31.8\% improvement compared to baseline, ResNet50 + U-Net, and better
performance than in cases with limited attention.
</p>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10495" title="Abstract">arXiv:2312.10495</a> (cross-list from math.OC) [<a href="/pdf/2312.10495" title="Download PDF">pdf</a>, <a href="/format/2312.10495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Optimal Joint Chance Constrained Control Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schmid%2C+N">Niklas Schmid</a>, 
<a href="/search/math?searchtype=author&query=Fochesato%2C+M">Marta Fochesato</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+S+H+Q">Sarah H.Q. Li</a>, 
<a href="/search/math?searchtype=author&query=Sutter%2C+T">Tobias Sutter</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider the problem of optimally controlling stochastic, Markovian
systems subject to joint chance constraints over a finite-time horizon. For
such problems, standard Dynamic Programming is inapplicable due to the time
correlation of the joint chance constraints, which calls for non-Markovian, and
possibly stochastic, policies. Hence, despite the popularity of this problem,
solution approaches capable of providing provably-optimal and easy-to-compute
policies are still missing. We fill this gap by introducing an augmented binary
state to the system dynamics, allowing us to characterize the optimal policies
and propose a Dynamic Programming based solution method. Our analysis provides
a deep insight into the impact of joint chance constraints on the optimal
control policies.
</p>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10497" title="Abstract">arXiv:2312.10497</a> (cross-list from math.PR) [<a href="/pdf/2312.10497" title="Download PDF">pdf</a>, <a href="/format/2312.10497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Approximations of Speed-Aware Join-the-Shortest-Queue Scheme:  Transient and Stationary Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bhambay%2C+S">Sanidhay Bhambay</a>, 
<a href="/search/math?searchtype=author&query=B%C3%BCke%2C+B">Burak B&#xfc;ke</a>, 
<a href="/search/math?searchtype=author&query=Mukhopadhyay%2C+A">Arpan Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The Join-the-Shortest-Queue (JSQ) load balancing scheme is widely
acknowledged for its effectiveness in minimizing the average response time for
jobs in systems with identical servers. However, when applied to a
heterogeneous server system with servers of different processing speeds, the
JSQ scheme exhibits suboptimal performance. Recently, a variation of JSQ called
the Speed-Aware-Join-the-Shortest-Queue (SA-JSQ) scheme has been shown to
attain fluid limit optimality for systems with heterogeneous servers. In this
paper, we examine the SA-JSQ scheme for heterogeneous server systems under the
Halfin-Whitt regime. Our analysis begins by establishing that the scaled and
centered version of the system state weakly converges to a diffusion process
characterized by stochastic integral equations. Furthermore, we prove that the
diffusion process is positive recurrent and the sequence of stationary measures
for the scaled and centered queue length processes converge to the stationary
measure for the limiting diffusion process. To achieve this result, we employ
Stein's method with a generator expansion approach.
</p>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10545" title="Abstract">arXiv:2312.10545</a> (cross-list from eess.SP) [<a href="/pdf/2312.10545" title="Download PDF">pdf</a>, <a href="/format/2312.10545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning graphs and simplicial complexes from data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Buciulea%2C+A">Andrei Buciulea</a>, 
<a href="/search/eess?searchtype=author&query=Isufi%2C+E">Elvin Isufi</a>, 
<a href="/search/eess?searchtype=author&query=Leus%2C+G">Geert Leus</a>, 
<a href="/search/eess?searchtype=author&query=Marques%2C+A+G">Antonio G. Marques</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graphs are widely used to represent complex information and signal domains
with irregular support. Typically, the underlying graph topology is unknown and
must be estimated from the available data. Common approaches assume pairwise
node interactions and infer the graph topology based on this premise. In
contrast, our novel method not only unveils the graph topology but also
identifies three-node interactions, referred to in the literature as
second-order simplicial complexes (SCs). We model signals using a graph
autoregressive Volterra framework, enhancing it with structured graph Volterra
kernels to learn SCs. We propose a mathematical formulation for graph and SC
inference, solving it through convex optimization involving group norms and
mask matrices. Experimental results on synthetic and real-world data showcase a
superior performance for our approach compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10567" title="Abstract">arXiv:2312.10567</a> (cross-list from eess.IV) [<a href="/pdf/2312.10567" title="Download PDF">pdf</a>, <a href="/format/2312.10567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Light-weight CNN-based VVC Inter Partitioning Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Abdoli%2C+M">Mohsen Abdoli</a>, 
<a href="/search/eess?searchtype=author&query=Guionnet%2C+T">Thomas Guionnet</a>, 
<a href="/search/eess?searchtype=author&query=Guillemot%2C+C">Christine Guillemot</a>, 
<a href="/search/eess?searchtype=author&query=Roumy%2C+A">Aline Roumy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IVMSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">The Versatile Video Coding (VVC) standard has been finalized by Joint Video
Exploration Team (JVET) in 2020. Compared to the High Efficiency Video Coding
(HEVC) standard, VVC offers about 50% compression efficiency gain, in terms of
Bjontegaard Delta-Rate (BD-rate), at the cost of about 10x more encoder
complexity. In this paper, we propose a Convolutional Neural Network
(CNN)-based method to speed up inter partitioning in VVC. Our method operates
at the Coding Tree Unit (CTU) level, by splitting each CTU into a fixed grid of
8x8 blocks. Then each cell in this grid is associated with information about
the partitioning depth within that area. A lightweight network for predicting
this grid is employed during the rate-distortion optimization to limit the
Quaternary Tree (QT)-split search and avoid partitions that are unlikely to be
selected. Experiments show that the proposed method can achieve acceleration
ranging from 17% to 30% in the RandomAccess Group Of Picture 32 (RAGOP32) mode
of VVC Test Model (VTM)10 with a reasonable efficiency drop ranging from 0.37%
to 1.18% in terms of BD-rate increase.
</p>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10568" title="Abstract">arXiv:2312.10568</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.10568" title="Download PDF">pdf</a>, <a href="/format/2312.10568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IntraSeismic: a coordinate-based learning approach to seismic inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Romero%2C+J">Juan Romero</a>, 
<a href="/search/physics?searchtype=author&query=Heidrich%2C+W">Wolfgang Heidrich</a>, 
<a href="/search/physics?searchtype=author&query=Luiken%2C+N">Nick Luiken</a>, 
<a href="/search/physics?searchtype=author&query=Ravasi%2C+M">Matteo Ravasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> -
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Seismic imaging is the numerical process of creating a volumetric
representation of the subsurface geological structures from elastic waves
recorded at the surface of the Earth. As such, it is widely utilized in the
energy and construction sectors for applications ranging from oil and gas
prospection, to geothermal production and carbon capture and storage
monitoring, to geotechnical assessment of infrastructures. Extracting
quantitative information from seismic recordings, such as an acoustic impedance
model, is however a highly ill-posed inverse problem, due to the band-limited
and noisy nature of the data. This paper introduces IntraSeismic, a novel
hybrid seismic inversion method that seamlessly combines coordinate-based
learning with the physics of the post-stack modeling operator. Key features of
IntraSeismic are i) unparalleled performance in 2D and 3D post-stack seismic
inversion, ii) rapid convergence rates, iii) ability to seamlessly include hard
constraints (i.e., well data) and perform uncertainty quantification, and iv)
potential data compression and fast randomized access to portions of the
inverted model. Synthetic and field data applications of IntraSeismic are
presented to validate the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10573" title="Abstract">arXiv:2312.10573</a> (cross-list from stat.ML) [<a href="/pdf/2312.10573" title="Download PDF">pdf</a>, <a href="/format/2312.10573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Forest Variable Importance-based Selection Algorithm in Class  Imbalance Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nam%2C+Y">Yunbi Nam</a>, 
<a href="/search/stat?searchtype=author&query=Han%2C+S">Sunwoo Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Random Forest is a machine learning method that offers many advantages,
including the ability to easily measure variable importance. Class balancing
technique is a well-known solution to deal with class imbalance problem.
However, it has not been actively studied on RF variable importance. In this
paper, we study the effect of class balancing on RF variable importance. Our
simulation results show that over-sampling is effective in correctly measuring
variable importance in class imbalanced situations with small sample size,
while under-sampling fails to differentiate important and non-informative
variables. We then propose a variable selection algorithm that utilizes RF
variable importance and its confidence interval. Through an experimental study
using many real and artificial datasets, we demonstrate that our proposed
algorithm efficiently selects an optimal feature set, leading to improved
prediction performance in class imbalance problem.
</p>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10585" title="Abstract">arXiv:2312.10585</a> (cross-list from eess.IV) [<a href="/pdf/2312.10585" title="Download PDF">pdf</a>, <a href="/ps/2312.10585" title="Download PostScript">ps</a>, <a href="/format/2312.10585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESDMR-Net: A Lightweight Network With Expand-Squeeze and Dual Multiscale  Residual Connections for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+T+M">Tariq M Khan</a>, 
<a href="/search/eess?searchtype=author&query=Naqvi%2C+S+S">Syed S. Naqvi</a>, 
<a href="/search/eess?searchtype=author&query=Meijering%2C+E">Erik Meijering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Segmentation is an important task in a wide range of computer vision
applications, including medical image analysis. Recent years have seen an
increase in the complexity of medical image segmentation approaches based on
sophisticated convolutional neural network architectures. This progress has led
to incremental enhancements in performance on widely recognised benchmark
datasets. However, most of the existing approaches are computationally
demanding, which limits their practical applicability. This paper presents an
expand-squeeze dual multiscale residual network (ESDMR-Net), which is a fully
convolutional network that is particularly well-suited for resource-constrained
computing hardware such as mobile devices. ESDMR-Net focuses on extracting
multiscale features, enabling the learning of contextual dependencies among
semantically distinct features. The ESDMR-Net architecture allows dual-stream
information flow within encoder-decoder pairs. The expansion operation
(depthwise separable convolution) makes all of the rich features with
multiscale information available to the squeeze operation (bottleneck layer),
which then extracts the necessary information for the segmentation task. The
Expand-Squeeze (ES) block helps the network pay more attention to
under-represented classes, which contributes to improved segmentation accuracy.
To enhance the flow of information across multiple resolutions or scales, we
integrated dual multiscale residual (DMR) blocks into the skip connection. This
integration enables the decoder to access features from various levels of
abstraction, ultimately resulting in more comprehensive feature
representations. We present experiments on seven datasets from five distinct
examples of applications. Our model achieved the best results despite having
significantly fewer trainable parameters, with a reduction of two or even three
orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10618" title="Abstract">arXiv:2312.10618</a> (cross-list from stat.ME) [<a href="/pdf/2312.10618" title="Download PDF">pdf</a>, <a href="/ps/2312.10618" title="Download PostScript">ps</a>, <a href="/format/2312.10618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Learning and Class Probability Estimation with Weighted Support  Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zeng%2C+L">Liyun Zeng</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H+H">Hao Helen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classification and probability estimation have broad applications in modern
machine learning and data science applications, including biology, medicine,
engineering, and computer science. The recent development of a class of
weighted Support Vector Machines (wSVMs) has shown great values in robustly
predicting the class probability and classification for various problems with
high accuracy. The current framework is based on the $\ell^2$-norm regularized
binary wSVMs optimization problem, which only works with dense features and has
poor performance at sparse features with redundant noise in most real
applications. The sparse learning process requires a prescreen of the important
variables for each binary wSVMs for accurately estimating pairwise conditional
probability. In this paper, we proposed novel wSVMs frameworks that incorporate
automatic variable selection with accurate probability estimation for sparse
learning problems. We developed efficient algorithms for effective variable
selection for solving either the $\ell^1$-norm or elastic net regularized
binary wSVMs optimization problems. The binary class probability is then
estimated either by the $\ell^2$-norm regularized wSVMs framework with selected
variables or by elastic net regularized wSVMs directly. The two-step approach
of $\ell^1$-norm followed by $\ell^2$-norm wSVMs show a great advantage in both
automatic variable selection and reliable probability estimators with the most
efficient time. The elastic net regularized wSVMs offer the best performance in
terms of variable selection and probability estimation with the additional
advantage of variable grouping in the compensation of more computation time for
high dimensional problems. The proposed wSVMs-based sparse learning methods
have wide applications and can be further extended to $K$-class problems
through ensemble learning.
</p>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10633" title="Abstract">arXiv:2312.10633</a> (cross-list from math.OC) [<a href="/pdf/2312.10633" title="Download PDF">pdf</a>, <a href="/ps/2312.10633" title="Download PostScript">ps</a>, <a href="/format/2312.10633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Ideas for Improving Stock Price Prediction Based on Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bagherpour%2C+N">Negin Bagherpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Stock price prediction is a complicated and interesting task. Noisy trends
make stock pricing sensitive and complicated while the economical motivation
behind, keeps it interesting for researchers and investors. In this paper we
are to outline two novel ideas for stock pricing. We also test each of our
suggested algorithms for predicting the price of 6 stocks from different
sectors. To show the efficiency of our proposed algorithm, we compare the
predicted prices with real values and also perform a backtest to verify that
the annual returns based on real data and predicted price are almost the same.
</p>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10687" title="Abstract">arXiv:2312.10687</a> (cross-list from eess.AS) [<a href="/pdf/2312.10687" title="Download PDF">pdf</a>, <a href="/format/2312.10687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-TTS: Multi-modal Prompt based Style Transfer for Expressive  Text-to-Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guan%2C+W">Wenhao Guan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yishuang Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hukai Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jiayan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Lingyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The style transfer task in Text-to-Speech refers to the process of
transferring style information into text content to generate corresponding
speech with a specific style. However, most existing style transfer approaches
are either based on fixed emotional labels or reference speech clips, which
cannot achieve flexible style transfer. Recently, some methods have adopted
text descriptions to guide style transfer. In this paper, we propose a more
flexible multi-modal and style controllable TTS framework named MM-TTS. It can
utilize any modality as the prompt in unified multi-modal prompt space,
including reference speech, emotional facial images, and text descriptions, to
control the style of the generated speech in a system. The challenges of
modeling such a multi-modal style controllable TTS mainly lie in two
aspects:1)aligning the multi-modal information into a unified style space to
enable the input of arbitrary modality as the style prompt in a single system,
and 2)efficiently transferring the unified style representation into the given
text content, thereby empowering the ability to generate prompt style-related
voice. To address these problems, we propose an aligned multi-modal prompt
encoder that embeds different modalities into a unified style space, supporting
style transfer for different modalities. Additionally, we present a new
adaptive style transfer method named Style Adaptive Convolutions to achieve a
better style representation. Furthermore, we design a Rectified Flow based
Refiner to solve the problem of over-smoothing Mel-spectrogram and generate
audio of higher fidelity. Since there is no public dataset for multi-modal TTS,
we construct a dataset named MEAD-TTS, which is related to the field of
expressive talking head. Our experiments on the MEAD-TTS dataset and
out-of-domain datasets demonstrate that MM-TTS can achieve satisfactory results
based on multi-modal prompts.
</p>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10695" title="Abstract">arXiv:2312.10695</a> (cross-list from stat.ME) [<a href="/pdf/2312.10695" title="Download PDF">pdf</a>, <a href="/ps/2312.10695" title="Download PostScript">ps</a>, <a href="/format/2312.10695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric Strategy Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ganzfried%2C+S">Sam Ganzfried</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We present a nonparametric statistical test for determining whether an agent
is following a given mixed strategy in a repeated strategic-form game given
samples of the agent's play. This involves two components: determining whether
the agent's frequencies of pure strategies are sufficiently close to the target
frequencies, and determining whether the pure strategies selected are
independent between different game iterations. Our integrated test involves
applying a chi-squared goodness of fit test for the first component and a
generalized Wald-Wolfowitz runs test for the second component. The results from
both tests are combined using Bonferroni correction to produce a complete test
for a given significance level $\alpha.$ We applied the test to publicly
available data of human rock-paper-scissors play. The data consists of 50
iterations of play for 500 human players. We test with a null hypothesis that
the players are following a uniform random strategy independently at each game
iteration. Using a significance level of $\alpha = 0.05$, we conclude that 305
(61%) of the subjects are following the target strategy.
</p>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10696" title="Abstract">arXiv:2312.10696</a> (cross-list from eess.IV) [<a href="/pdf/2312.10696" title="Download PDF">pdf</a>, <a href="/format/2312.10696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interpretable Deep Learning Approach for Skin Cancer Categorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mahmud%2C+F">Faysal Mahmud</a>, 
<a href="/search/eess?searchtype=author&query=Mahfiz%2C+M+M">Md. Mahin Mahfiz</a>, 
<a href="/search/eess?searchtype=author&query=Kabir%2C+M+Z+I">Md. Zobayer Ibna Kabir</a>, 
<a href="/search/eess?searchtype=author&query=Abdullah%2C+Y">Yusha Abdullah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Skin cancer is a serious worldwide health issue, precise and early detection
is essential for better patient outcomes and effective treatment. In this
research, we use modern deep learning methods and explainable artificial
intelligence (XAI) approaches to address the problem of skin cancer detection.
To categorize skin lesions, we employ four cutting-edge pre-trained models:
XceptionNet, EfficientNetV2S, InceptionResNetV2, and EfficientNetV2M. Image
augmentation approaches are used to reduce class imbalance and improve the
generalization capabilities of our models. Our models decision-making process
can be clarified because of the implementation of explainable artificial
intelligence (XAI). In the medical field, interpretability is essential to
establish credibility and make it easier to implement AI driven diagnostic
technologies into clinical workflows. We determined the XceptionNet
architecture to be the best performing model, achieving an accuracy of 88.72%.
Our study shows how deep learning and explainable artificial intelligence (XAI)
can improve skin cancer diagnosis, laying the groundwork for future
developments in medical image analysis. These technologies ability to allow for
early and accurate detection could enhance patient care, lower healthcare
costs, and raise the survival rates for those with skin cancer. Source Code:
https://github.com/Faysal-MD/An-Interpretable-Deep-Learning?Approach-for-Skin-Cancer-Categorization-IEEE2023
</p>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10707" title="Abstract">arXiv:2312.10707</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.10707" title="Download PDF">pdf</a>, <a href="/format/2312.10707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLDR: Contrastive Learning Drug Response Models from Natural Language  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+W">Wenbin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Deep learning-based drug response prediction (DRP) methods can accelerate the
drug discovery process and reduce R\&amp;D costs. Although the mainstream methods
achieve high accuracy in predicting response regression values, the
regression-aware representations of these methods are fragmented and fail to
capture the continuity of the sample order. This phenomenon leads to models
optimized to sub-optimal solution spaces, reducing generalization ability and
may result in significant wasted costs in the drug discovery phase. In this
paper, we propose \MN, a contrastive learning framework with natural language
supervision for the DRP. The \MN~converts regression labels into text, which is
merged with the captions text of the drug response as a second modality of the
samples compared to the traditional modalities (graph, sequence). In each
batch, two modalities of one sample are considered positive pairs and the other
pairs are considered negative pairs. At the same time, in order to enhance the
continuous representation capability of the numerical text, a common-sense
numerical knowledge graph is introduced. We validated several hundred thousand
samples from the Genomics of Drug Sensitivity in Cancer dataset, observing the
average improvement of the DRP method ranges from 7.8\% to 31.4\% with the
application of our framework. The experiments prove that the \MN~effectively
constrains the samples to a continuous distribution in the representation
space, and achieves impressive prediction performance with only a few epochs of
fine-tuning after pre-training. The code is available at:
\url{https://gitee.com/xiaoyibang/clipdrug.git}.
</p>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10716" title="Abstract">arXiv:2312.10716</a> (cross-list from eess.IV) [<a href="/pdf/2312.10716" title="Download PDF">pdf</a>, <a href="/format/2312.10716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computationally Efficient Neural Video Compression Accelerator Based  on a Sparse CNN-Transformer Hybrid Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Siyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+W">Wendong Mao</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+H">Huihong Shi</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Video compression is widely used in digital television, surveillance systems,
and virtual reality. Real-time video decoding is crucial in practical
scenarios. Recently, neural video compression (NVC) combines traditional coding
with deep learning, achieving impressive compression efficiency. Nevertheless,
the NVC models involve high computational costs and complex memory access
patterns, challenging real-time hardware implementations. To relieve this
burden, we propose an algorithm and hardware co-design framework named NVCA for
video decoding on resource-limited devices. Firstly, a CNN-Transformer hybrid
network is developed to improve compression performance by capturing
multi-scale non-local features. In addition, we propose a fast algorithm-based
sparse strategy that leverages the dual advantages of pruning and fast
algorithms, sufficiently reducing computational complexity while maintaining
video compression efficiency. Secondly, a reconfigurable sparse computing core
is designed to flexibly support sparse convolutions and deconvolutions based on
the fast algorithm-based sparse strategy. Furthermore, a novel heterogeneous
layer chaining dataflow is incorporated to reduce off-chip memory traffic
stemming from extensive inter-frame motion and residual information. Thirdly,
the overall architecture of NVCA is designed and synthesized in TSMC 28nm CMOS
technology. Extensive experiments demonstrate that our design provides superior
coding quality and up to 22.7x decoding speed improvements over other video
compression designs. Meanwhile, our design achieves up to 2.2x improvements in
energy efficiency compared to prior accelerators.
</p>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10741" title="Abstract">arXiv:2312.10741</a> (cross-list from eess.AS) [<a href="/pdf/2312.10741" title="Download PDF">pdf</a>, <a href="/format/2312.10741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleSinger: Style Transfer for Out-Of-Domain Singing Voice Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ruiqi Li</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+J">JinZheng He</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+F">Feiyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xinyu Duan</a>, 
<a href="/search/eess?searchtype=author&query=Huai%2C+B">Baoxing Huai</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Style transfer for out-of-domain (OOD) singing voice synthesis (SVS) focuses
on generating high-quality singing voices with unseen styles (such as timbre,
emotion, pronunciation, and articulation skills) derived from reference singing
voice samples. However, the endeavor to model the intricate nuances of singing
voice styles is an arduous task, as singing voices possess a remarkable degree
of expressiveness. Moreover, existing SVS methods encounter a decline in the
quality of synthesized singing voices in OOD scenarios, as they rest upon the
assumption that the target vocal attributes are discernible during the training
phase. To overcome these challenges, we propose StyleSinger, the first singing
voice synthesis model for zero-shot style transfer of out-of-domain reference
singing voice samples. StyleSinger incorporates two critical approaches for
enhanced effectiveness: 1) the Residual Style Adaptor (RSA) which employs a
residual quantization module to capture diverse style characteristics in
singing voices, and 2) the Uncertainty Modeling Layer Normalization (UMLN) to
perturb the style attributes within the content representation during the
training phase and thus improve the model generalization. Our extensive
evaluations in zero-shot style transfer undeniably establish that StyleSinger
outperforms baseline models in both audio quality and similarity to the
reference singing voice samples. Access to singing voice samples can be found
at https://stylesinger.github.io/.
</p>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10756" title="Abstract">arXiv:2312.10756</a> (cross-list from eess.AS) [<a href="/pdf/2312.10756" title="Download PDF">pdf</a>, <a href="/format/2312.10756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Driven Multichannel Speech Enhancement in Moving Sound Source  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuzhu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Politis%2C+A">Archontis Politis</a>, 
<a href="/search/eess?searchtype=author&query=Virtanen%2C+T">Tuomas Virtanen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Current multichannel speech enhancement algorithms typically assume a
stationary sound source, a common mismatch with reality that limits their
performance in real-world scenarios. This paper focuses on attention-driven
spatial filtering techniques designed for dynamic settings. Specifically, we
study the application of linear and nonlinear attention-based methods for
estimating time-varying spatial covariance matrices used to design the filters.
We also investigate the direct estimation of spatial filters by attention-based
methods without explicitly estimating spatial statistics. The clean speech
clips from WSJ0 are employed for simulating speech signals of moving speakers
in a reverberant environment. The experimental dataset is built by mixing the
simulated speech signals with multichannel real noise from CHiME-3. Evaluation
results show that the attention-driven approaches are robust and consistently
outperform conventional spatial filtering approaches in both static and dynamic
sound environments.
</p>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10830" title="Abstract">arXiv:2312.10830</a> (cross-list from math.CO) [<a href="/pdf/2312.10830" title="Download PDF">pdf</a>, <a href="/format/2312.10830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bisimplicial separators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Penev%2C+I">Irena Penev</a>, 
<a href="/search/math?searchtype=author&query=Piva%C4%8D%2C+N">Nevena Piva&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Vu%C5%A1kovi%C4%87%2C+K">Kristina Vu&#x161;kovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A minimal separator of a graph $G$ is a set $S \subseteq V(G)$ such that
there exist vertices $a,b \in V(G) \setminus S$ with the property that $S$
separates $a$ from $b$ in $G$, but no proper subset of $S$ does. For an integer
$k\ge 0$, we say that a minimal separator is $k$-simplicial if it can be
covered by $k$ cliques and denote by $\mathcal{G}_k$ the class of all graphs in
which each minimal separator is $k$-simplicial. We show that for each $k \geq
0$, the class $\mathcal{G}_k$ is closed under induced minors, and we use this
to show that the Maximum Weight Stable Set problem can be solved in polynomial
time for $\mathcal{G}_k$. We also give a complete list of minimal forbidden
induced minors for $\mathcal{G}_2$. Next, we show that, for $k \geq 1$, every
nonnull graph in $\mathcal{G}_k$ has a $k$-simplicial vertex, i.e., a vertex
whose neighborhood is a union of $k$ cliques; we deduce that the Maximum Weight
Clique problem can be solved in polynomial time for graphs in $\mathcal{G}_2$.
Further, we show that, for $k \geq 3$, it is NP-hard to recognize graphs in
$\mathcal{G}_k$; the time complexity of recognizing graphs in $\mathcal{G}_2$
is unknown. We also show that the Maximum Clique problem is NP-hard for graphs
in $\mathcal{G}_3$. Finally, we prove a decomposition theorem for diamond-free
graphs in $\mathcal{G}_2$ (where the diamond is the graph obtained from $K_4$
by deleting one edge), and we use this theorem to obtain polynomial-time
algorithms for the Vertex Coloring and recognition problems for diamond-free
graphs in $\mathcal{G}_2$, and improved running times for the Maximum Weight
Clique and Maximum Weight Stable Set problems for this class of graphs.
</p>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10865" title="Abstract">arXiv:2312.10865</a> (cross-list from quant-ph) [<a href="/pdf/2312.10865" title="Download PDF">pdf</a>, <a href="/format/2312.10865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Photonic Cluster State Depth in Measurement-Based Quantum  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yingheng Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pawar%2C+A">Aditya Pawar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mo%2C+Z">Zewei Mo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Y">Youtao Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+J">Jun Yang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tang%2C+X">Xulong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Measurement-based quantum computing (MBQC) is a promising quantum computing
paradigm that performs computation through ``one-way'' measurements on
entangled quantum qubits. It is widely used in photonic quantum computing
(PQC), where the computation is carried out on photonic cluster states (i.e., a
2-D mesh of entangled photons). In MBQC-based PQC, the cluster state depth
(i.e., the length of one-way measurements) to execute a quantum circuit plays
an important role in the overall execution time and error. Thus, it is
important to reduce the cluster state depth. In this paper, we propose FMCC, a
compilation framework that employs dynamic programming to efficiently minimize
the cluster state depth. Experimental results on five representative quantum
algorithms show that FMCC achieves 53.6%, 60.6%, and 60.0% average depth
reductions in small, medium, and large qubit counts compared to the
state-of-the-art MBQC compilation frameworks.
</p>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10892" title="Abstract">arXiv:2312.10892</a> (cross-list from eess.IV) [<a href="/pdf/2312.10892" title="Download PDF">pdf</a>, <a href="/format/2312.10892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based MRI Reconstruction with Artificial Fourier Transform  (AFT)-Net
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yanting Yang</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+J+S">Jeffery Siyuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Dagommer%2C+M">Matthieu Dagommer</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jia Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The deep complex-valued neural network provides a powerful way to leverage
complex number operations and representations, which has succeeded in several
phase-based applications. However, most previously published networks have not
fully accessed the impact of complex-valued networks in the frequency domain.
Here, we introduced a unified complex-valued deep learning framework -
artificial Fourier transform network (AFT-Net) - which combined domain-manifold
learning and complex-valued neural networks. The AFT-Net can be readily used to
solve the image inverse problems in domain-transform, especially for
accelerated magnetic resonance imaging (MRI) reconstruction and other
applications. While conventional methods only accept magnitude images, the
proposed method takes raw k-space data in the frequency domain as inputs,
allowing a mapping between the k-space domain and the image domain to be
determined through cross-domain learning. We show that AFT-Net achieves
superior accelerated MRI reconstruction and is comparable to existing
approaches. Also, our approach can be applied to different tasks like denoised
MRS reconstruction and different datasets with various contrasts. The AFT-Net
presented here is a valuable preprocessing component for different preclinical
studies and provides an innovative alternative for solving inverse problems in
imaging and spectroscopy.
</p>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10894" title="Abstract">arXiv:2312.10894</a> (cross-list from stat.ML) [<a href="/pdf/2312.10894" title="Download PDF">pdf</a>, <a href="/format/2312.10894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectiveness of Constant Stepsize in Markovian LSA and Statistical  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huo%2C+D">Dongyan Huo</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">In this paper, we study the effectiveness of using a constant stepsize in
statistical inference via linear stochastic approximation (LSA) algorithms with
Markovian data. After establishing a Central Limit Theorem (CLT), we outline an
inference procedure that uses averaged LSA iterates to construct confidence
intervals (CIs). Our procedure leverages the fast mixing property of
constant-stepsize LSA for better covariance estimation and employs
Richardson-Romberg (RR) extrapolation to reduce the bias induced by constant
stepsize and Markovian data. We develop theoretical results for guiding
stepsize selection in RR extrapolation, and identify several important settings
where the bias provably vanishes even without extrapolation. We conduct
extensive numerical experiments and compare against classical inference
approaches. Our results show that using a constant stepsize enjoys easy
hyperparameter tuning, fast convergence, and consistently better CI coverage,
especially when data is limited.
</p>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10956" title="Abstract">arXiv:2312.10956</a> (cross-list from math.CO) [<a href="/pdf/2312.10956" title="Download PDF">pdf</a>, <a href="/ps/2312.10956" title="Download PostScript">ps</a>, <a href="/format/2312.10956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning caterpillar in biconvex bipartite graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antony%2C+D">Dhanyamol Antony</a>, 
<a href="/search/math?searchtype=author&query=Das%2C+A">Anita Das</a>, 
<a href="/search/math?searchtype=author&query=Gosavi%2C+S">Shirish Gosavi</a>, 
<a href="/search/math?searchtype=author&query=Jacob%2C+D">Dalu Jacob</a>, 
<a href="/search/math?searchtype=author&query=Kulamarva%2C+S">Shashanka Kulamarva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A bipartite graph $G=(A, B, E)$ is said to be a biconvex bipartite graph if
there exist orderings $&lt;_A$ in $A$ and $&lt;_B$ in $B$ such that the neighbors of
every vertex in $A$ are consecutive with respect to $&lt;_B$ and the neighbors of
every vertex in $B$ are consecutive with respect to $&lt;_A$. A caterpillar is a
tree that will result in a path upon deletion of all the leaves. In this note,
we prove that there exists a spanning caterpillar in any connected biconvex
bipartite graph. Besides being interesting on its own, this structural result
has other consequences. For instance, this directly resolves the burning number
conjecture for biconvex bipartite graphs.
</p>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10978" title="Abstract">arXiv:2312.10978</a> (cross-list from eess.IV) [<a href="/pdf/2312.10978" title="Download PDF">pdf</a>, <a href="/ps/2312.10978" title="Download PostScript">ps</a>, <a href="/format/2312.10978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Learning for Annotation-Efficient Volumetric MR Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Osman%2C+Y+B+M">Yousuf Babiker M. Osman</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+W">Weijian Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted by Journal of Magnetic Resonance Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Background: Deep learning has presented great potential in accurate MR image
segmentation when enough labeled data are provided for network optimization.
However, manually annotating 3D MR images is tedious and time-consuming,
requiring experts with rich domain knowledge and experience. Purpose: To build
a deep learning method exploring sparse annotations, namely only a single 2D
slice label for each 3D training MR image. Population: 3D MR images of 150
subjects from two publicly available datasets were included. Among them, 50
(1,377 image slices) are for prostate segmentation. The other 100 (8,800 image
slices) are for left atrium segmentation. Five-fold cross-validation
experiments were carried out utilizing the first dataset. For the second
dataset, 80 subjects were used for training and 20 were used for testing.
Assessment: A collaborative learning method by integrating the strengths of
semi-supervised and self-supervised learning schemes was developed. The method
was trained using labeled central slices and unlabeled non-central slices.
Segmentation performance on testing set was reported quantitatively and
qualitatively. Results: Compared to FS-LCS, MT, UA-MT, DCT-Seg, ICT, and AC-MT,
the proposed method achieved a substantial improvement in segmentation
accuracy, increasing the mean B-IoU significantly by more than 10.0% for
prostate segmentation (proposed method B-IoU: 70.3% vs. ICT B-IoU: 60.3%) and
by more than 6.0% for left atrium segmentation (proposed method B-IoU: 66.1%
vs. ICT B-IoU: 60.1%).
</p>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10996" title="Abstract">arXiv:2312.10996</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.10996" title="Download PDF">pdf</a>, <a href="/format/2312.10996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Paper on Materials Design -- A Modern Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Grossmann%2C+W">Willi Grossmann</a>, 
<a href="/search/cond-mat?searchtype=author&query=Eilermann%2C+S">Sebastian Eilermann</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rensmeyer%2C+T">Tim Rensmeyer</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liebert%2C+A">Artur Liebert</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hohmann%2C+M">Michael Hohmann</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wittke%2C+C">Christian Wittke</a>, 
<a href="/search/cond-mat?searchtype=author&query=Niggemann%2C+O">Oliver Niggemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at the AAAI 2024 Workshop on AI to Accelerate Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditional design cycles for new materials and assemblies have two
fundamental drawbacks. The underlying physical relationships are often too
complex to be precisely calculated and described. Aside from that, many unknown
uncertainties, such as exact manufacturing parameters or materials composition,
dominate the real assembly behavior. Machine learning (ML) methods overcome
these fundamental limitations through data-driven learning. In addition, modern
approaches can specifically increase system knowledge. Representation Learning
allows the physical, and if necessary, even symbolic interpretation of the
learned solution. In this way, the most complex physical relationships can be
considered and quickly described. Furthermore, generative ML approaches can
synthesize possible morphologies of the materials based on defined conditions
to visualize the effects of uncertainties. This modern approach accelerates the
design process for new materials and enables the prediction and interpretation
of realistic materials behavior.
</p>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11050" title="Abstract">arXiv:2312.11050</a> (cross-list from eess.SP) [<a href="/pdf/2312.11050" title="Download PDF">pdf</a>, <a href="/format/2312.11050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cardiac and extracardiac discharge diagnosis prediction from emergency  department ECGs using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Strodthoff%2C+N">Nils Strodthoff</a>, 
<a href="/search/eess?searchtype=author&query=Alcaraz%2C+J+M+L">Juan Miguel Lopez Alcaraz</a>, 
<a href="/search/eess?searchtype=author&query=Haverkamp%2C+W">Wilhelm Haverkamp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 6 figures, code available under <a href="https://github.com/AI4HealthUOL/ECG-MIMIC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Current deep learning algorithms designed for automatic ECG analysis have
exhibited notable accuracy. However, akin to traditional electrocardiography,
they tend to be narrowly focused and typically address a singular diagnostic
condition. In this study, we specifically demonstrate the capability of a
single model to predict a diverse range of both cardiac and non-cardiac
discharge diagnoses based on a sole ECG collected in the emergency department.
Among the 1,076 hierarchically structured ICD codes considered, our model
achieves an AUROC exceeding 0.8 in 439 of them. This underscores the models
proficiency in handling a wide array of diagnostic scenarios. We emphasize the
potential of utilizing this model as a screening tool, potentially integrated
into a holistic clinical decision support system for efficiently triaging
patients in the emergency department. This research underscores the remarkable
capabilities of comprehensive ECG analysis algorithms and the extensive range
of possibilities facilitated by the open MIMIC-IV-ECG dataset. Finally, our
data may play a pivotal role in revolutionizing the way ECG analysis is
performed, marking a significant advancement in the field.
</p>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11126" title="Abstract">arXiv:2312.11126</a> (cross-list from quant-ph) [<a href="/pdf/2312.11126" title="Download PDF">pdf</a>, <a href="/format/2312.11126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Inherent Noises for Privacy Preservation in Quantum Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ju%2C+K">Keyi Ju</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+H">Hui Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+M">Miao Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+B">Baoling Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 paged, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing revolutionizes the way of solving complex problems and
handling vast datasets, which shows great potential to accelerate the machine
learning process. However, data leakage in quantum machine learning (QML) may
present privacy risks. Although differential privacy (DP), which protects
privacy through the injection of artificial noise, is a well-established
approach, its application in the QML domain remains under-explored. In this
paper, we propose to harness inherent quantum noises to protect data privacy in
QML. Especially, considering the Noisy Intermediate-Scale Quantum (NISQ)
devices, we leverage the unavoidable shot noise and incoherent noise in quantum
computing to preserve the privacy of QML models for binary classification. We
mathematically analyze that the gradient of quantum circuit parameters in QML
satisfies a Gaussian distribution, and derive the upper and lower bounds on its
variance, which can potentially provide the DP guarantee. Through simulations,
we show that a target privacy protection level can be achieved by running the
quantum circuit a different number of times.
</p>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11169" title="Abstract">arXiv:2312.11169</a> (cross-list from stat.ML) [<a href="/pdf/2312.11169" title="Download PDF">pdf</a>, <a href="/format/2312.11169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Collapsed Gibbs Sampler for Dirichlet Process Mixture Models  in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Khoufache%2C+R">Reda Khoufache</a>, 
<a href="/search/stat?searchtype=author&query=Lebbah%2C+M">Mustapha Lebbah</a>, 
<a href="/search/stat?searchtype=author&query=Azzag%2C+H">Hanene Azzag</a>, 
<a href="/search/stat?searchtype=author&query=Goffinet%2C+E">Etienne Goffinet</a>, 
<a href="/search/stat?searchtype=author&query=Bouchaffra%2C+D">Djamel Bouchaffra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dirichlet Process Mixture Models (DPMMs) are widely used to address
clustering problems. Their main advantage lies in their ability to
automatically estimate the number of clusters during the inference process
through the Bayesian non-parametric framework. However, the inference becomes
considerably slow as the dataset size increases. This paper proposes a new
distributed Markov Chain Monte Carlo (MCMC) inference method for DPMMs (DisCGS)
using sufficient statistics. Our approach uses the collapsed Gibbs sampler and
is specifically designed to work on distributed data across independent and
heterogeneous machines, which habilitates its use in horizontal federated
learning. Our method achieves highly promising results and notable scalability.
For instance, with a dataset of 100K data points, the centralized algorithm
requires approximately 12 hours to complete 100 iterations while our approach
achieves the same number of iterations in just 3 minutes, reducing the
execution time by a factor of 200 without compromising clustering performance.
The code source is publicly available at
https://github.com/redakhoufache/DisCGS.
</p>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11182" title="Abstract">arXiv:2312.11182</a> (cross-list from math.FA) [<a href="/pdf/2312.11182" title="Download PDF">pdf</a>, <a href="/format/2312.11182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic refinable functions and the tile B-splines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Protasov%2C+V+Y">Vladimir Yu. Protasov</a>, 
<a href="/search/math?searchtype=author&query=Zaitseva%2C+T">Tatyana Zaitseva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The regularity of refinable functions has been analysed in an extensive
literature and is well-understood in two cases: 1) univariate 2) multivariate
with an isotropic dilation matrix. The general (non-isotropic) case offered a
great resistance. It was done only recently by developing the matrix method. In
this paper we make the next step and extend the Littlewood-Paley type method,
which is very efficient in the aforementioned special cases, to general
equations with arbitrary dilation matrices. This gives formulas for the higher
order regularity in $W_2^k(\mathbb{R}^n)$ by means of the Perron eigenvalue of
a finite-dimensional linear operator on a special cone. Applying those results
to recently introduced tile B-splines, we prove that they can have a higher
smoothness than the classical ones of the same order. Moreover, the two-digit
tile B-splines have the minimal support of the mask among all refinable
functions of the same order of approximation. This proves, in particular, the
lowest algorithmic complexity of the corresponding subdivision schemes.
Examples and numerical results are provided.
</p>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11201" title="Abstract">arXiv:2312.11201</a> (cross-list from eess.AS) [<a href="/pdf/2312.11201" title="Download PDF">pdf</a>, <a href="/format/2312.11201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Refining Underlying Information Framework for Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianrui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+M">Meng Ge</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">The advent of deep neural networks (DNN) has significantly improved the
performance of monaural speech enhancement (SE). Most of them attempt to
implicitly capture the structural features of speech through distribution
approximation. However, existing methods are susceptible to the issues of
degraded speech and residual noise. This letter is grounded in the Information
Bottleneck as an anchor to rethink the SE. By defining the incremental
convergence of mutual information between speech characteristics, we elucidate
that the acoustic characteristic of speech is crucial in alleviating the above
issues, for its explicit introduction contributes to further approximating the
optimal information-theoretic upper bound of the optimization. Referring to the
chain rule of entropy, we also propose a framework to reconstruct the
information composition of the optimization objective, aiming to integrate and
refine this underlying characteristic without loss of generality. The
visualization reflects consistency with analysis using information theory.
Experimental results show that with only 1.18 M additional parameters, the
refined CRN has yielded substantial progress over a number of advanced methods.
The source code is available at https://github.com/caoruitju/RUI_SE.
</p>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11206" title="Abstract">arXiv:2312.11206</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.11206" title="Download PDF">pdf</a>, <a href="/format/2312.11206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QDA$^2$: A principled approach to automatically annotating charge  stability diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Weber%2C+B">Brian Weber</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zwolak%2C+J+P">Justyna P. Zwolak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Gate-defined semiconductor quantum dot (QD) arrays are a promising platform
for quantum computing. However, presently, the large configuration spaces and
inherent noise make tuning of QD devices a nontrivial task and with the
increasing number of QD qubits, the human-driven experimental control becomes
unfeasible. Recently, researchers working with QD systems have begun putting
considerable effort into automating device control, with a particular focus on
machine-learning-driven methods. Yet, the reported performance statistics vary
substantially in both the meaning and the type of devices used for testing.
While systematic benchmarking of the proposed tuning methods is necessary for
developing reliable and scalable tuning approaches, the lack of openly
available standardized datasets of experimental data makes such testing
impossible. The QD auto-annotator -- a classical algorithm for automatic
interpretation and labeling of experimentally acquired data -- is a critical
step toward rectifying this. QD auto-annotator leverages the principles of
geometry to produce state labels for experimental double-QD charge stability
diagrams and is a first step towards building a large public repository of
labeled QD data.
</p>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11230" title="Abstract">arXiv:2312.11230</a> (cross-list from stat.ML) [<a href="/pdf/2312.11230" title="Download PDF">pdf</a>, <a href="/format/2312.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirichlet-based Uncertainty Quantification for Personalized Federated  Learning with Improved Posterior Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kotelevskii%2C+N">Nikita Kotelevskii</a>, 
<a href="/search/stat?searchtype=author&query=Horv%C3%A1th%2C+S">Samuel Horv&#xe1;th</a>, 
<a href="/search/stat?searchtype=author&query=Nandakumar%2C+K">Karthik Nandakumar</a>, 
<a href="/search/stat?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>, 
<a href="/search/stat?searchtype=author&query=Panov%2C+M">Maxim Panov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In modern federated learning, one of the main challenges is to account for
inherent heterogeneity and the diverse nature of data distributions for
different clients. This problem is often addressed by introducing
personalization of the models towards the data distribution of the particular
client. However, a personalized model might be unreliable when applied to the
data that is not typical for this client. Eventually, it may perform worse for
these data than the non-personalized global model trained in a federated way on
the data from all the clients. This paper presents a new approach to federated
learning that allows selecting a model from global and personalized ones that
would perform better for a particular input point. It is achieved through a
careful modeling of predictive uncertainties that helps to detect local and
global in- and out-of-distribution data and use this information to select the
model that is confident in a prediction. The comprehensive experimental
evaluation on the popular real-world image datasets shows the superior
performance of the model in the presence of out-of-distribution data while
performing on par with state-of-the-art personalized federated learning
algorithms in the standard scenarios.
</p>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11232" title="Abstract">arXiv:2312.11232</a> (cross-list from eess.IV) [<a href="/pdf/2312.11232" title="Download PDF">pdf</a>, <a href="/format/2312.11232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Image Super-Resolution and Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Scanvic%2C+J">J&#xe9;r&#xe9;my Scanvic</a>, 
<a href="/search/eess?searchtype=author&query=Davies%2C+M">Mike Davies</a>, 
<a href="/search/eess?searchtype=author&query=Abry%2C+P">Patrice Abry</a>, 
<a href="/search/eess?searchtype=author&query=Tachella%2C+J">Juli&#xe1;n Tachella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Self-supervised methods have recently proved to be nearly as effective as
supervised methods in various imaging inverse problems, paving the way for
learning-based methods in scientific and medical imaging applications where
ground truth data is hard or expensive to obtain. This is the case in magnetic
resonance imaging and computed tomography. These methods critically rely on
invariance to translations and/or rotations of the image distribution to learn
from incomplete measurement data alone. However, existing approaches fail to
obtain competitive performances in the problems of image super-resolution and
deblurring, which play a key role in most imaging systems. In this work, we
show that invariance to translations and rotations is insufficient to learn
from measurements that only contain low-frequency information. Instead, we
propose a new self-supervised approach that leverages the fact that many image
distributions are approximately scale-invariant, and that can be applied to any
inverse problem where high-frequency information is lost in the measurement
process. We demonstrate throughout a series of experiments on real datasets
that the proposed method outperforms other self-supervised approaches, and
obtains performances on par with fully supervised learning.
</p>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11281" title="Abstract">arXiv:2312.11281</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.11281" title="Download PDF">pdf</a>, <a href="/format/2312.11281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human mobility is well described by closed-form gravity-like models  learned automatically from data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cabanas-Tirapu%2C+O">Oriol Cabanas-Tirapu</a>, 
<a href="/search/physics?searchtype=author&query=Dan%C3%BAs%2C+L">Llu&#xed;s Dan&#xfa;s</a>, 
<a href="/search/physics?searchtype=author&query=Moro%2C+E">Esteban Moro</a>, 
<a href="/search/physics?searchtype=author&query=Sales-Pardo%2C+M">Marta Sales-Pardo</a>, 
<a href="/search/physics?searchtype=author&query=Guimer%C3%A0%2C+R">Roger Guimer&#xe0;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)

</div>
<p class="mathjax">Modeling of human mobility is critical to address questions in urban planning
and transportation, as well as global challenges in sustainability, public
health, and economic development. However, our understanding and ability to
model mobility flows within and between urban areas are still incomplete. At
one end of the modeling spectrum we have simple so-called gravity models, which
are easy to interpret and provide modestly accurate predictions of mobility
flows. At the other end, we have complex machine learning and deep learning
models, with tens of features and thousands of parameters, which predict
mobility more accurately than gravity models at the cost of not being
interpretable and not providing insight on human behavior. Here, we show that
simple machine-learned, closed-form models of mobility are able to predict
mobility flows more accurately, overall, than either gravity or complex machine
and deep learning models. At the same time, these models are simple and
gravity-like, and can be interpreted in terms similar to standard gravity
models. Furthermore, these models work for different datasets and at different
scales, suggesting that they may capture the fundamental universal features of
human mobility.
</p>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11283" title="Abstract">arXiv:2312.11283</a> (cross-list from stat.AP) [<a href="/pdf/2312.11283" title="Download PDF">pdf</a>, <a href="/format/2312.11283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The 2010 Census Confidentiality Protections Failed, Here&#x27;s How and Why
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Abowd%2C+J+M">John M. Abowd</a>, 
<a href="/search/stat?searchtype=author&query=Adams%2C+T">Tamara Adams</a>, 
<a href="/search/stat?searchtype=author&query=Ashmead%2C+R">Robert Ashmead</a>, 
<a href="/search/stat?searchtype=author&query=Darais%2C+D">David Darais</a>, 
<a href="/search/stat?searchtype=author&query=Dey%2C+S">Sourya Dey</a>, 
<a href="/search/stat?searchtype=author&query=Garfinkel%2C+S+L">Simson L. Garfinkel</a>, 
<a href="/search/stat?searchtype=author&query=Goldschlag%2C+N">Nathan Goldschlag</a>, 
<a href="/search/stat?searchtype=author&query=Kifer%2C+D">Daniel Kifer</a>, 
<a href="/search/stat?searchtype=author&query=Leclerc%2C+P">Philip Leclerc</a>, 
<a href="/search/stat?searchtype=author&query=Lew%2C+E">Ethan Lew</a>, 
<a href="/search/stat?searchtype=author&query=Moore%2C+S">Scott Moore</a>, 
<a href="/search/stat?searchtype=author&query=Rodr%C3%ADguez%2C+R+A">Rolando A. Rodr&#xed;guez</a>, 
<a href="/search/stat?searchtype=author&query=Tadros%2C+R+N">Ramy N. Tadros</a>, 
<a href="/search/stat?searchtype=author&query=Vilhuber%2C+L">Lars Vilhuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Cryptography and Security (cs.CR); Econometrics (econ.EM)

</div>
<p class="mathjax">Using only 34 published tables, we reconstruct five variables (census block,
sex, age, race, and ethnicity) in the confidential 2010 Census person records.
Using the 38-bin age variable tabulated at the census block level, at most
20.1% of reconstructed records can differ from their confidential source on
even a single value for these five variables. Using only published data, an
attacker can verify that all records in 70% of all census blocks (97 million
people) are perfectly reconstructed. The tabular publications in Summary File 1
thus have prohibited disclosure risk similar to the unreleased confidential
microdata. Reidentification studies confirm that an attacker can, within blocks
with perfect reconstruction accuracy, correctly infer the actual census
response on race and ethnicity for 3.4 million vulnerable population uniques
(persons with nonmodal characteristics) with 95% accuracy, the same precision
as the confidential data achieve and far greater than statistical baselines.
The flaw in the 2010 Census framework was the assumption that aggregation
prevented accurate microdata reconstruction, justifying weaker disclosure
limitation methods than were applied to 2010 Census public microdata. The
framework used for 2020 Census publications defends against attacks that are
based on reconstruction, as we also demonstrate here. Finally, we show that
alternatives to the 2020 Census Disclosure Avoidance System with similar
accuracy (enhanced swapping) also fail to protect confidentiality, and those
that partially defend against reconstruction attacks (incomplete suppression
implementations) destroy the primary statutory use case: data for redistricting
all legislatures in the country in compliance with the 1965 Voting Rights Act.
</p>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11329" title="Abstract">arXiv:2312.11329</a> (cross-list from math.OC) [<a href="/pdf/2312.11329" title="Download PDF">pdf</a>, <a href="/ps/2312.11329" title="Download PostScript">ps</a>, <a href="/format/2312.11329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence guarantees for adaptive model predictive control with kinky  inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zuliani%2C+R">Riccardo Zuliani</a>, 
<a href="/search/math?searchtype=author&query=Soloperto%2C+R">Raffaele Soloperto</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We analyze the convergence properties of a robust adaptive model predictive
control algorithm used to control an unknown nonlinear system. We show that by
employing a standard quadratic stabilizing cost function, and by recursively
updating the nominal model through kinky inference, the resulting controller
ensures convergence of the true system to the origin, despite the presence of
model uncertainty. We illustrate our theoretical findings through a numerical
simulation.
</p>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11337" title="Abstract">arXiv:2312.11337</a> (cross-list from quant-ph) [<a href="/pdf/2312.11337" title="Download PDF">pdf</a>, <a href="/format/2312.11337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges for Reinforcement Learning in Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=B%C3%A4rligea%2C+A">Adelina B&#xe4;rligea</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gabor%2C+T">Thomas Gabor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing (QC) in the current NISQ-era is still limited. To gain
early insights and advantages, hybrid applications are widely considered
mitigating those shortcomings. Hybrid quantum machine learning (QML) comprises
both the application of QC to improve machine learning (ML), and the
application of ML to improve QC architectures. This work considers the latter,
focusing on leveraging reinforcement learning (RL) to improve current QC
approaches. We therefore introduce various generic challenges arising from
quantum architecture search and quantum circuit optimization that RL algorithms
need to solve to provide benefits for more complex applications and
combinations of those. Building upon these challenges we propose a concrete
framework, formalized as a Markov decision process, to enable to learn policies
that are capable of controlling a universal set of quantum gates. Furthermore,
we provide benchmark results to assess shortcomings and strengths of current
state-of-the-art algorithms.
</p>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11381" title="Abstract">arXiv:2312.11381</a> (cross-list from math.OC) [<a href="/pdf/2312.11381" title="Download PDF">pdf</a>, <a href="/ps/2312.11381" title="Download PostScript">ps</a>, <a href="/format/2312.11381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling a Multi-Product Pipeline: A Discretized MILP Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wodecki%2C+A">Ales Wodecki</a>, 
<a href="/search/math?searchtype=author&query=Rytir%2C+P">Pavel Rytir</a>, 
<a href="/search/math?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="/search/math?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Multi-product pipelines are a highly efficient means of transporting liquids.
Traditionally used to transport petroleum, its products and derivatives, they
are now being repurposed to transport liquified natural gas admixed with
hydrogen of various colors. We propose a novel mixed-integer linear programming
(MILP) formulation, which optimizes efficiency while satisfying a wide range of
real-world constraints developed to meet the needs of the Czech national
pipeline operator CEPRO. We provide tests on well-known synthetic (path-graph)
networks and demonstrate the formulation's scaling properties using open-source
and commercial MILP solvers.
</p>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11425" title="Abstract">arXiv:2312.11425</a> (cross-list from math.OC) [<a href="/pdf/2312.11425" title="Download PDF">pdf</a>, <a href="/format/2312.11425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When can you trust feature selection? -- I: A condition-based analysis  of LASSO and generalised hardness of approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bastounis%2C+A">Alexander Bastounis</a>, 
<a href="/search/math?searchtype=author&query=Cucker%2C+F">Felipe Cucker</a>, 
<a href="/search/math?searchtype=author&query=Hansen%2C+A+C">Anders C. Hansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">The arrival of AI techniques in computations, with the potential for
hallucinations and non-robustness, has made trustworthiness of algorithms a
focal point. However, trustworthiness of the many classical approaches are not
well understood. This is the case for feature selection, a classical problem in
the sciences, statistics, machine learning etc. Here, the LASSO optimisation
problem is standard. Despite its widespread use, it has not been established
when the output of algorithms attempting to compute support sets of minimisers
of LASSO in order to do feature selection can be trusted. In this paper we
establish how no (randomised) algorithm that works on all inputs can determine
the correct support sets (with probability $&gt; 1/2$) of minimisers of LASSO when
reading approximate input, regardless of precision and computing power.
However, we define a LASSO condition number and design an efficient algorithm
for computing these support sets provided the input data is well-posed (has
finite condition number) in time polynomial in the dimensions and logarithm of
the condition number. For ill-posed inputs the algorithm runs forever, hence,
it will never produce a wrong answer. Furthermore, the algorithm computes an
upper bound for the condition number when this is finite. Finally, for any
algorithm defined on an open set containing a point with infinite condition
number, there is an input for which the algorithm will either run forever or
produce a wrong answer. Our impossibility results stem from generalised
hardness of approximation -- within the Solvability Complexity Index (SCI)
hierarchy framework -- that generalises the classical phenomenon of hardness of
approximation.
</p>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11436" title="Abstract">arXiv:2312.11436</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.11436" title="Download PDF">pdf</a>, <a href="/format/2312.11436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layerwise complexity-matched learning yields an improved model of  cortical area V2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Parthasarathy%2C+N">Nikhil Parthasarathy</a>, 
<a href="/search/q-bio?searchtype=author&query=H%C3%A9naff%2C+O+J">Olivier J. H&#xe9;naff</a>, 
<a href="/search/q-bio?searchtype=author&query=Simoncelli%2C+E+P">Eero P. Simoncelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Human ability to recognize complex visual patterns arises through
transformations performed by successive areas in the ventral visual cortex.
Deep neural networks trained end-to-end for object recognition approach human
capabilities, and offer the best descriptions to date of neural responses in
the late stages of the hierarchy. But these networks provide a poor account of
the early stages, compared to traditional hand-engineered models, or models
optimized for coding efficiency or prediction. Moreover, the gradient
backpropagation used in end-to-end learning is generally considered to be
biologically implausible. Here, we overcome both of these limitations by
developing a bottom-up self-supervised training methodology that operates
independently on successive layers. Specifically, we maximize feature
similarity between pairs of locally-deformed natural image patches, while
decorrelating features across patches sampled from other images. Crucially, the
deformation amplitudes are adjusted proportionally to receptive field sizes in
each layer, thus matching the task complexity to the capacity at each stage of
processing. In comparison with architecture-matched versions of previous
models, we demonstrate that our layerwise complexity-matched learning (LCL)
formulation produces a two-stage model (LCL-V2) that is better aligned with
selectivity properties and neural activity in primate area V2. We demonstrate
that the complexity-matched learning paradigm is critical for the emergence of
the improved biological alignment. Finally, when the two-stage model is used as
a fixed front-end for a deep network trained to perform object recognition, the
resultant model (LCL-V2Net) is significantly better than standard end-to-end
self-supervised, supervised, and adversarially-trained models in terms of
generalization to out-of-distribution tasks and alignment with human behavior.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 19 Dec 23</h3>
<dl>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1701.08338" title="Abstract">arXiv:1701.08338</a> (replaced) [<a href="/pdf/1701.08338" title="Download PDF">pdf</a>, <a href="/ps/1701.08338" title="Download PostScript">ps</a>, <a href="/format/1701.08338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter and State Estimation in Queues and Related Stochastic Models:  A Bibliography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Asanjarani%2C+A">Azam Asanjarani</a>, 
<a href="/search/math?searchtype=author&query=Nazarathy%2C+Y">Yoni Nazarathy</a>, 
<a href="/search/math?searchtype=author&query=Pollett%2C+P+K">Philip K. Pollett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1810.13029" title="Abstract">arXiv:1810.13029</a> (replaced) [<a href="/pdf/1810.13029" title="Download PDF">pdf</a>, <a href="/format/1810.13029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BCL: A Cross-Platform Distributed Container Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brock%2C+B">Benjamin Brock</a>, 
<a href="/search/cs?searchtype=author&query=Bulu%C3%A7%2C+A">Ayd&#x131;n Bulu&#xe7;</a>, 
<a href="/search/cs?searchtype=author&query=Yelick%2C+K">Katherine Yelick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.10018" title="Abstract">arXiv:2003.10018</a> (replaced) [<a href="/pdf/2003.10018" title="Download PDF">pdf</a>, <a href="/format/2003.10018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigation Systems May Deteriorate Stability in Traffic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bianchin%2C+G">Gianluca Bianchin</a>, 
<a href="/search/math?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.00203" title="Abstract">arXiv:2009.00203</a> (replaced) [<a href="/pdf/2009.00203" title="Download PDF">pdf</a>, <a href="/format/2009.00203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to  Any-Layer Graph Neural Networks via Influence Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianxiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Minhua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+M">Meng Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared in WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.03738" title="Abstract">arXiv:2011.03738</a> (replaced) [<a href="/pdf/2011.03738" title="Download PDF">pdf</a>, <a href="/format/2011.03738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Thresholds in Random Simple Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casteigts%2C+A">Arnaud Casteigts</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+M">Michael Raskin</a>, 
<a href="/search/cs?searchtype=author&query=Renken%2C+M">Malte Renken</a>, 
<a href="/search/cs?searchtype=author&query=Zamaraev%2C+V">Viktor Zamaraev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by the SIAM Journal on Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.02710" title="Abstract">arXiv:2102.02710</a> (replaced) [<a href="/pdf/2102.02710" title="Download PDF">pdf</a>, <a href="/format/2102.02710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Impatient and Heterogeneous Demand and Supply
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aveklouris%2C+A">Angelos Aveklouris</a>, 
<a href="/search/math?searchtype=author&query=DeValve%2C+L">Levi DeValve</a>, 
<a href="/search/math?searchtype=author&query=Stock%2C+M">Maximiliano Stock</a>, 
<a href="/search/math?searchtype=author&query=Ward%2C+A+R">Amy R. Ward</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Performance (cs.PF); Systems and Control (eess.SY); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03617" title="Abstract">arXiv:2104.03617</a> (replaced) [<a href="/pdf/2104.03617" title="Download PDF">pdf</a>, <a href="/format/2104.03617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Half-Truth: A Partially Fake Audio Detection Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Ye Bai</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhengkun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by Interspeech 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.04947" title="Abstract">arXiv:2105.04947</a> (replaced) [<a href="/pdf/2105.04947" title="Download PDF">pdf</a>, <a href="/format/2105.04947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Euclidean Distance Matrix Model for Convex Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingna Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.13172" title="Abstract">arXiv:2105.13172</a> (replaced) [<a href="/pdf/2105.13172" title="Download PDF">pdf</a>, <a href="/ps/2105.13172" title="Download PostScript">ps</a>, <a href="/format/2105.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Weight-Dynamic Network Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Paz%2C+A">Ami Paz</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in IFIP Networking 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.05075" title="Abstract">arXiv:2109.05075</a> (replaced) [<a href="/pdf/2109.05075" title="Download PDF">pdf</a>, <a href="/format/2109.05075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Compression of Neural Networks Using $\ell_0$-Norm Regularization  and Weight Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Resende+Oliveira%2C+F+D">Felipe Dennis de Resende Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Batista%2C+E+L+O">Eduardo Luiz Ortiz Batista</a>, 
<a href="/search/cs?searchtype=author&query=Seara%2C+R">Rui Seara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.05216" title="Abstract">arXiv:2110.05216</a> (replaced) [<a href="/pdf/2110.05216" title="Download PDF">pdf</a>, <a href="/format/2110.05216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order Tensor Pooling with Attention for Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Koniusz%2C+P">Piotr Koniusz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00152" title="Abstract">arXiv:2112.00152</a> (replaced) [<a href="/pdf/2112.00152" title="Download PDF">pdf</a>, <a href="/ps/2112.00152" title="Download PostScript">ps</a>, <a href="/format/2112.00152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-step replica symmetry breaking of random regular NAE-SAT II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nam%2C+D">Danny Nam</a>, 
<a href="/search/math?searchtype=author&query=Sly%2C+A">Allan Sly</a>, 
<a href="/search/math?searchtype=author&query=Sohn%2C+Y">Youngtak Sohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 1 figure. Accepted to Communications in Mathematical Physics. arXiv admin note: text overlap with <a href="/abs/2011.14270">arXiv:2011.14270</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.09445" title="Abstract">arXiv:2112.09445</a> (replaced) [<a href="/pdf/2112.09445" title="Download PDF">pdf</a>, <a href="/format/2112.09445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Efficient Language-supervised Zero-shot Recognition with Optimal  Transport Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ruizhe Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianren Gao</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11279" title="Abstract">arXiv:2112.11279</a> (replaced) [<a href="/pdf/2112.11279" title="Download PDF">pdf</a>, <a href="/ps/2112.11279" title="Download PostScript">ps</a>, <a href="/format/2112.11279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Relative Fairness in Human Decisions With Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xiaoyin Xi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00087" title="Abstract">arXiv:2201.00087</a> (replaced) [<a href="/pdf/2201.00087" title="Download PDF">pdf</a>, <a href="/format/2201.00087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persistent Homological State-Space Estimation of Functional Human Brain  Networks at Rest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chung%2C+M+K">Moo K. Chung</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+S">Shih-Gu Huang</a>, 
<a href="/search/math?searchtype=author&query=Carroll%2C+I+C">Ian C. Carroll</a>, 
<a href="/search/math?searchtype=author&query=Calhoun%2C+V+D">Vince D. Calhoun</a>, 
<a href="/search/math?searchtype=author&query=Goldsmith%2C+H+H">H. Hill Goldsmith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in PLOS Computational Biology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03281" title="Abstract">arXiv:2201.03281</a> (replaced) [<a href="/pdf/2201.03281" title="Download PDF">pdf</a>, <a href="/ps/2201.03281" title="Download PostScript">ps</a>, <a href="/format/2201.03281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoTGAN: GAN Powered Camouflage Against Machine Learning Based IoT Device  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tao Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sagduyu%2C+Y">Yalin Sagduyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.04736" title="Abstract">arXiv:2201.04736</a> (replaced) [<a href="/pdf/2201.04736" title="Download PDF">pdf</a>, <a href="/format/2201.04736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security for Machine Learning-based Software Systems: a survey of  threats, practices and challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+M+A">M. Ali Babar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12975" title="Abstract">arXiv:2201.12975</a> (replaced) [<a href="/pdf/2201.12975" title="Download PDF">pdf</a>, <a href="/format/2201.12975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotting Infinitely Many-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jung-hun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Vojnovic%2C+M">Milan Vojnovic</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.13446" title="Abstract">arXiv:2201.13446</a> (replaced) [<a href="/pdf/2201.13446" title="Download PDF">pdf</a>, <a href="/ps/2201.13446" title="Download PostScript">ps</a>, <a href="/format/2201.13446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on the Relation between Recognisable Series and Regular  Sequences, and their Minimal Linear Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Heuberger%2C+C">Clemens Heuberger</a>, 
<a href="/search/math?searchtype=author&query=Krenn%2C+D">Daniel Krenn</a>, 
<a href="/search/math?searchtype=author&query=Lipnik%2C+G+F">Gabriel F. Lipnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06491" title="Abstract">arXiv:2202.06491</a> (replaced) [<a href="/pdf/2202.06491" title="Download PDF">pdf</a>, <a href="/format/2202.06491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Graph Contrastive Learning with Information Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shengyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Baoyu Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yada Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11342" title="Abstract">arXiv:2202.11342</a> (replaced) [<a href="/pdf/2202.11342" title="Download PDF">pdf</a>, <a href="/format/2202.11342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Adaptive Reconstruction Networks for Blind Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gossard%2C+A">Alban Gossard</a> (IMT), 
<a href="/search/cs?searchtype=author&query=Weiss%2C+P">Pierre Weiss</a> (IRIT, CBI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03005" title="Abstract">arXiv:2203.03005</a> (replaced) [<a href="/pdf/2203.03005" title="Download PDF">pdf</a>, <a href="/format/2203.03005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Face Image Restoration with a One-Shot Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fangzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03456" title="Abstract">arXiv:2203.03456</a> (replaced) [<a href="/pdf/2203.03456" title="Download PDF">pdf</a>, <a href="/ps/2203.03456" title="Download PostScript">ps</a>, <a href="/format/2203.03456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative-Weight Single-Source Shortest Paths in Near-linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+A">Aaron Bernstein</a>, 
<a href="/search/cs?searchtype=author&query=Nanongkai%2C+D">Danupon Nanongkai</a>, 
<a href="/search/cs?searchtype=author&query=Wulff-Nilsen%2C+C">Christian Wulff-Nilsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Simplified algorithms and minor corrections throughout the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07370" title="Abstract">arXiv:2203.07370</a> (replaced) [<a href="/pdf/2203.07370" title="Download PDF">pdf</a>, <a href="/format/2203.07370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nivat Theorem for Weighted Alternating Automata over Commutative  Semirings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grabolle%2C+G">Gustav Grabolle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a paper at GandALF 2021, see <a href="/abs/2109.08323">arXiv:2109.08323</a>. Submitted to GandALF 2021 Special Issue on LMCS First revision: Typos &amp; grammar, slight changes in structure, additional explanations, new lmcs.cls
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01682" title="Abstract">arXiv:2204.01682</a> (replaced) [<a href="/pdf/2204.01682" title="Download PDF">pdf</a>, <a href="/format/2204.01682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Feature Screening: Feature Selection for Ultra High-Dimensional  Data via Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+K">Kexuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+F">Fangfang Wang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+L">Lingli Yang</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01884" title="Abstract">arXiv:2204.01884</a> (replaced) [<a href="/pdf/2204.01884" title="Download PDF">pdf</a>, <a href="/format/2204.01884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Learning with Competing Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sahoo%2C+R">Roshni Sahoo</a>, 
<a href="/search/stat?searchtype=author&query=Wager%2C+S">Stefan Wager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05980" title="Abstract">arXiv:2204.05980</a> (replaced) [<a href="/pdf/2204.05980" title="Download PDF">pdf</a>, <a href="/ps/2204.05980" title="Download PostScript">ps</a>, <a href="/format/2204.05980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optical flow GNSS for navigation in the Indian subcontinent (NavIC)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fulari%2C+S+S+D">Sunit Shantanu Digamber Fulari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.06754" title="Abstract">arXiv:2204.06754</a> (replaced) [<a href="/pdf/2204.06754" title="Download PDF">pdf</a>, <a href="/format/2204.06754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecurSeed and EdgePredictMix: Pseudo-Label Refinement Learning for  Weakly Supervised Semantic Segmentation across Single- and Multi-Stage  Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jo%2C+S">Sanghyun Jo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+I">In-Jae Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyungsu Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08117" title="Abstract">arXiv:2204.08117</a> (replaced) [<a href="/pdf/2204.08117" title="Download PDF">pdf</a>, <a href="/format/2204.08117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Decentralized Federated Low Rank Matrix Recovery from Column-wise  Linear Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moothedath%2C+S">Shana Moothedath</a>, 
<a href="/search/cs?searchtype=author&query=Vaswani%2C+N">Namrata Vaswani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11357" title="Abstract">arXiv:2205.11357</a> (replaced) [<a href="/pdf/2205.11357" title="Download PDF">pdf</a>, <a href="/format/2205.11357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POLTER: Policy Trajectory Ensemble Regularization for Unsupervised  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schubert%2C+F">Frederik Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Benjamins%2C+C">Carolin Benjamins</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6hler%2C+S">Sebastian D&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Rosenhahn%2C+B">Bodo Rosenhahn</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12787" title="Abstract">arXiv:2205.12787</a> (replaced) [<a href="/pdf/2205.12787" title="Download PDF">pdf</a>, <a href="/format/2205.12787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impartial Games: A Challenge for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12841" title="Abstract">arXiv:2205.12841</a> (replaced) [<a href="/pdf/2205.12841" title="Download PDF">pdf</a>, <a href="/format/2205.12841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marginal Post Processing of Bayesian Inference Products with Normalizing  Flows and Kernel Density Estimators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Bevins%2C+H+T+J">Harry T. J. Bevins</a>, 
<a href="/search/astro-ph?searchtype=author&query=Handley%2C+W+J">William J. Handley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sims%2C+P+H">Peter H. Sims</a>, 
<a href="/search/astro-ph?searchtype=author&query=de+Lera+Acedo%2C+E">Eloy de Lera Acedo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fialkov%2C+A">Anastasia Fialkov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Alsing%2C+J">Justin Alsing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for MNRAS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13428" title="Abstract">arXiv:2205.13428</a> (replaced) [<a href="/pdf/2205.13428" title="Download PDF">pdf</a>, <a href="/format/2205.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QBF Merge Resolution is powerful but unnatural
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+M">Meena Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+G">Gaurav Sood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02765" title="Abstract">arXiv:2206.02765</a> (replaced) [<a href="/pdf/2206.02765" title="Download PDF">pdf</a>, <a href="/format/2206.02765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-constrained hypothesis testing: Optimality, robustness,  and reverse data processing inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>, 
<a href="/search/math?searchtype=author&query=Jog%2C+V">Varun Jog</a>, 
<a href="/search/math?searchtype=author&query=Loh%2C+P">Po-Ling Loh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05662" title="Abstract">arXiv:2206.05662</a> (replaced) [<a href="/pdf/2206.05662" title="Download PDF">pdf</a>, <a href="/format/2206.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilience for Distributed Consensus with Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Mou%2C+S">Shaoshuai Mou</a>, 
<a href="/search/eess?searchtype=author&query=Sundaram%2C+S">Shreyas Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06004" title="Abstract">arXiv:2206.06004</a> (replaced) [<a href="/pdf/2206.06004" title="Download PDF">pdf</a>, <a href="/format/2206.06004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel multi-layer modular approach for real-time fuzzy-identification  of gravitational-wave signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Barone%2C+F+P">Francesco Pio Barone</a>, 
<a href="/search/gr-qc?searchtype=author&query=Dell%27Aquila%2C+D">Daniele Dell&#x27;Aquila</a>, 
<a href="/search/gr-qc?searchtype=author&query=Russo%2C+M">Marco Russo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach. Learn.: Sci. Technol. 4 045054 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.15092" title="Abstract">arXiv:2206.15092</a> (replaced) [<a href="/pdf/2206.15092" title="Download PDF">pdf</a>, <a href="/ps/2206.15092" title="Download PostScript">ps</a>, <a href="/format/2206.15092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treewidth versus clique number. III. Tree-independence number of graphs  with a forbidden structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0torgel%2C+K">Kenny &#x160;torgel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages; abstract has been shortened due to arXiv requirements. A previous arXiv post (<a href="/abs/2111.04543">arXiv:2111.04543</a>) has been reorganized into two parts; this is the second of the two parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03101" title="Abstract">arXiv:2207.03101</a> (replaced) [<a href="/pdf/2207.03101" title="Download PDF">pdf</a>, <a href="/format/2207.03101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A conditional gradient homotopy method with applications to Semidefinite  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dvurechensky%2C+P">Pavel Dvurechensky</a>, 
<a href="/search/math?searchtype=author&query=Shtern%2C+S">Shimrit Shtern</a>, 
<a href="/search/math?searchtype=author&query=Staudigl%2C+M">Mathias Staudigl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Largely revised and extended version. Submitted for Publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06950" title="Abstract">arXiv:2207.06950</a> (replaced) [<a href="/pdf/2207.06950" title="Download PDF">pdf</a>, <a href="/ps/2207.06950" title="Download PostScript">ps</a>, <a href="/format/2207.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+L">Linwei Hu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/stat?searchtype=author&query=Nair%2C+V+N">Vijayan N. Nair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages plus appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08012" title="Abstract">arXiv:2207.08012</a> (replaced) [<a href="/pdf/2207.08012" title="Download PDF">pdf</a>, <a href="/format/2207.08012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Referential Games to Learn Compositional Learning Behaviours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denamgana%C3%AF%2C+K">Kevin Denamgana&#xef;</a>, 
<a href="/search/cs?searchtype=author&query=Missaoui%2C+S">Sondess Missaoui</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+J+A">James Alfred Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02785" title="Abstract">arXiv:2208.02785</a> (replaced) [<a href="/pdf/2208.02785" title="Download PDF">pdf</a>, <a href="/ps/2208.02785" title="Download PostScript">ps</a>, <a href="/format/2208.02785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notions, Stability, Existence, and Robustness of Limit Cycles in Hybrid  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lou%2C+X">Xuyang Lou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchun Li</a>, 
<a href="/search/eess?searchtype=author&query=Sanfelice%2C+R+G">Ricardo G. Sanfelice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures, 2 tables. This work has been accepted to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09141" title="Abstract">arXiv:2208.09141</a> (replaced) [<a href="/pdf/2208.09141" title="Download PDF">pdf</a>, <a href="/format/2208.09141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G2P-DDM: Generating Sign Pose Sequence from Gloss Sequence with Discrete  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Taiyi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yao Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09147" title="Abstract">arXiv:2208.09147</a> (replaced) [<a href="/pdf/2208.09147" title="Download PDF">pdf</a>, <a href="/format/2208.09147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation with Causal Constraints for Counterfactual  Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by PAKDD 2023. Please check: <a href="https://doi.org/10.1007/978-3-031-33374-3_37">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10386" title="Abstract">arXiv:2208.10386</a> (replaced) [<a href="/pdf/2208.10386" title="Download PDF">pdf</a>, <a href="/format/2208.10386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Shooting Approach for Finding Approximately Shortest Paths for  Autonomous Robots in Unknown Environments in 2D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+P+T">Phan Thanh An</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N+T">Nguyen Thi Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 39 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Geometry (cs.CG); Discrete Mathematics (cs.DM); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12063" title="Abstract">arXiv:2208.12063</a> (replaced) [<a href="/pdf/2208.12063" title="Download PDF">pdf</a>, <a href="/format/2208.12063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Matrix Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Kanade%2C+V">Varun Kanade</a>, 
<a href="/search/cs?searchtype=author&query=Mohri%2C+C">Clara Mohri</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y+J">Y. Jennifer Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13232" title="Abstract">arXiv:2208.13232</a> (replaced) [<a href="/pdf/2208.13232" title="Download PDF">pdf</a>, <a href="/format/2208.13232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical composable cryptography: extended version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Broadbent%2C+A">Anne Broadbent</a>, 
<a href="/search/cs?searchtype=author&query=Karvonen%2C+M">Martti Karvonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of <a href="/abs/2105.05949">arXiv:2105.05949</a> which appeared in FoSSaCS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02178" title="Abstract">arXiv:2209.02178</a> (replaced) [<a href="/pdf/2209.02178" title="Download PDF">pdf</a>, <a href="/format/2209.02178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-CNN Cohort: Semi-supervised Semantic Segmentation by the  Best of Both Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06176" title="Abstract">arXiv:2209.06176</a> (replaced) [<a href="/pdf/2209.06176" title="Download PDF">pdf</a>, <a href="/ps/2209.06176" title="Download PostScript">ps</a>, <a href="/format/2209.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized dimension truncation error analysis for high-dimensional  numerical integration: lognormal setting and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guth%2C+P+A">Philipp A. Guth</a>, 
<a href="/search/math?searchtype=author&query=Kaarnioja%2C+V">Vesa Kaarnioja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08600" title="Abstract">arXiv:2209.08600</a> (replaced) [<a href="/pdf/2209.08600" title="Download PDF">pdf</a>, <a href="/format/2209.08600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenPIP: In-Memory Acceleration of Genome Analysis via Tight Integration  of Basecalling and Read Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haiyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Alser%2C+M">Mohammed Alser</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/cs?searchtype=author&query=Baranwal%2C+A">Akanksha Baranwal</a>, 
<a href="/search/cs?searchtype=author&query=Cali%2C+D+S">Damla Senol Cali</a>, 
<a href="/search/cs?searchtype=author&query=Manglik%2C+A">Aditya Manglik</a>, 
<a href="/search/cs?searchtype=author&query=Alserr%2C+N+A">Nour Almadhoun Alserr</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Data Structures and Algorithms (cs.DS); Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09130" title="Abstract">arXiv:2209.09130</a> (replaced) [<a href="/pdf/2209.09130" title="Download PDF">pdf</a>, <a href="/format/2209.09130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMP: A Model Inference Toolkit of Post-Training Quantization for Text  Processing via Self-Adaptive Mixed-Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Rong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zijing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weijie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weiquan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05662" title="Abstract">arXiv:2210.05662</a> (replaced) [<a href="/pdf/2210.05662" title="Download PDF">pdf</a>, <a href="/format/2210.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding or Manipulation: Rethinking Online Performance Gains of  Modern Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengbang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 11 figures, 4 tables, ACM Transactions on Information Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07857" title="Abstract">arXiv:2210.07857</a> (replaced) [<a href="/pdf/2210.07857" title="Download PDF">pdf</a>, <a href="/ps/2210.07857" title="Download PostScript">ps</a>, <a href="/format/2210.07857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commutativity and Disentanglement from the Manifold Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Qiu%2C+F">Frank Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13879" title="Abstract">arXiv:2210.13879</a> (replaced) [<a href="/pdf/2210.13879" title="Download PDF">pdf</a>, <a href="/format/2210.13879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proximal Mean Field Learning in Shallow Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teter%2C+A">Alexis Teter</a>, 
<a href="/search/cs?searchtype=author&query=Nodozi%2C+I">Iman Nodozi</a>, 
<a href="/search/cs?searchtype=author&query=Halder%2C+A">Abhishek Halder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14320" title="Abstract">arXiv:2210.14320</a> (replaced) [<a href="/pdf/2210.14320" title="Download PDF">pdf</a>, <a href="/format/2210.14320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FO-PINNs: A First-Order formulation for Physics Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gladstone%2C+R+J">Rini J. Gladstone</a>, 
<a href="/search/cs?searchtype=author&query=Nabian%2C+M+A">Mohammad A. Nabian</a>, 
<a href="/search/cs?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Ankit Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Meidani%2C+H">Hadi Meidani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, Selected for ML4PS workshop at NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15657" title="Abstract">arXiv:2210.15657</a> (replaced) [<a href="/pdf/2210.15657" title="Download PDF">pdf</a>, <a href="/format/2210.15657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting fake accounts through Generative Adversarial Network in online  social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Shiri%2C+M+E">Mohammad Ebrahim Shiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15849" title="Abstract">arXiv:2210.15849</a> (replaced) [<a href="/pdf/2210.15849" title="Download PDF">pdf</a>, <a href="/ps/2210.15849" title="Download PostScript">ps</a>, <a href="/format/2210.15849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical speaker representation for target speaker extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shulin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+W">Wei Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kanghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yukai Ju</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00369" title="Abstract">arXiv:2211.00369</a> (replaced) [<a href="/pdf/2211.00369" title="Download PDF">pdf</a>, <a href="/format/2211.00369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Search-based Framework for Generating Textual Counterfactual  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilo%2C+D">Daniel Gilo</a>, 
<a href="/search/cs?searchtype=author&query=Markovitch%2C+S">Shaul Markovitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03622" title="Abstract">arXiv:2211.03622</a> (replaced) [<a href="/pdf/2211.03622" title="Download PDF">pdf</a>, <a href="/format/2211.03622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Users Write More Insecure Code with AI Assistants?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perry%2C+N">Neil Perry</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Megha Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Deepak Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Boneh%2C+D">Dan Boneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, update adds names of statistical tests and survey questions, full version of conference paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CCS '23: Proceedings of the 2023 ACM SIGSAC Conference on Computer
  and Communications Security, November 2023, Pages 2785-2799
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04253" title="Abstract">arXiv:2211.04253</a> (replaced) [<a href="/pdf/2211.04253" title="Download PDF">pdf</a>, <a href="/format/2211.04253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eat-Radar: Continuous Fine-Grained Intake Gesture Detection Using FMCW  Radar and 3D Temporal Convolutional Network with Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunzhuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+T+S">T. Sunil Kumar</a>, 
<a href="/search/cs?searchtype=author&query=De+Raedt%2C+W">Walter De Raedt</a>, 
<a href="/search/cs?searchtype=author&query=Camps%2C+G">Guido Camps</a>, 
<a href="/search/cs?searchtype=author&query=Hallez%2C+H">Hans Hallez</a>, 
<a href="/search/cs?searchtype=author&query=Vanrumste%2C+B">Bart Vanrumste</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has been accepted in IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06319" title="Abstract">arXiv:2211.06319</a> (replaced) [<a href="/pdf/2211.06319" title="Download PDF">pdf</a>, <a href="/ps/2211.06319" title="Download PostScript">ps</a>, <a href="/format/2211.06319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Young and the Old, the Fast and the Slow: A Large-Scale Study of  Productivity Classes and Rank Advancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwiek%2C+M">Marek Kwiek</a>, 
<a href="/search/cs?searchtype=author&query=Roszka%2C+W">Wojciech Roszka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 tables, 4 figures. There is an Online Supplementary Material here: <a href="https://www.tandfonline.com/doi/full/10.1080/03075079.2023.2288172">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Studies in Higher Education
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06663" title="Abstract">arXiv:2211.06663</a> (replaced) [<a href="/pdf/2211.06663" title="Download PDF">pdf</a>, <a href="/format/2211.06663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeighborTrack: Improving Single Object Tracking by Bipartite Matching  with Neighbor Tracklets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-Hsi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chien-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hung-Shuo Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youn-Long Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yung-Yu Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H+M">Hong-Yuan Mark Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by 9th International Workshop on Computer Vision in Sports (CVsports) 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops, 2023, pp. 5139-5148
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10682" title="Abstract">arXiv:2211.10682</a> (replaced) [<a href="/pdf/2211.10682" title="Download PDF">pdf</a>, <a href="/format/2211.10682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffStyler: Controllable Dual Diffusion for Text-Driven Image  Stylization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nisha Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weiming Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11133" title="Abstract">arXiv:2211.11133</a> (replaced) [<a href="/pdf/2211.11133" title="Download PDF">pdf</a>, <a href="/format/2211.11133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Accuracy and Robustness of Steering Angle Prediction with  Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadella%2C+S">Swetha Nadella</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+P">Pramiti Barua</a>, 
<a href="/search/cs?searchtype=author&query=Hagler%2C+J+C">Jeremy C. Hagler</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+D+J">David J. Lamb</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qing Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11174" title="Abstract">arXiv:2211.11174</a> (replaced) [<a href="/pdf/2211.11174" title="Download PDF">pdf</a>, <a href="/format/2211.11174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Robust Generalization in Continual Learning: Better Transfer  and Less Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zenglin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+H">Joo Hwee Lim</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11650" title="Abstract">arXiv:2211.11650</a> (replaced) [<a href="/pdf/2211.11650" title="Download PDF">pdf</a>, <a href="/format/2211.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Meta-Symbolic Reasoning and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zihan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shindo%2C+H">Hikaru Shindo</a>, 
<a href="/search/cs?searchtype=author&query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15060" title="Abstract">arXiv:2211.15060</a> (replaced) [<a href="/pdf/2211.15060" title="Download PDF">pdf</a>, <a href="/format/2211.15060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Visual Feature Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulrich%2C+D">Devon Ulrich</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+R">Ruth Fong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS XAI in Action Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00229" title="Abstract">arXiv:2212.00229</a> (replaced) [<a href="/pdf/2212.00229" title="Download PDF">pdf</a>, <a href="/ps/2212.00229" title="Download PostScript">ps</a>, <a href="/format/2212.00229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NIR-Prompt: A Multi-task Generalized Neural Information Retrieval  Training Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is the extension of <a href="/abs/2204.02725">arXiv:2204.02725</a> and accepted by TOIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01071" title="Abstract">arXiv:2212.01071</a> (replaced) [<a href="/pdf/2212.01071" title="Download PDF">pdf</a>, <a href="/format/2212.01071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake detection in imbalance dataset by Semi-supervised learning with GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> have a more complete script in this subject
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05500" title="Abstract">arXiv:2212.05500</a> (replaced) [<a href="/pdf/2212.05500" title="Download PDF">pdf</a>, <a href="/format/2212.05500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Defense of Large Scale Networks Under False Data Injection  Attacks: An Attack Detection Scheduling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Suo%2C+Y">Yuhan Suo</a>, 
<a href="/search/eess?searchtype=author&query=Chai%2C+S">Senchun Chai</a>, 
<a href="/search/eess?searchtype=author&query=Chai%2C+R">Runqi Chai</a>, 
<a href="/search/eess?searchtype=author&query=Pang%2C+Z">Zhong-Hua Pang</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yuanqing Xia</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+G">Guo-Ping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06640" title="Abstract">arXiv:2212.06640</a> (replaced) [<a href="/pdf/2212.06640" title="Download PDF">pdf</a>, <a href="/ps/2212.06640" title="Download PostScript">ps</a>, <a href="/format/2212.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction graph-based characterization of quantum benchmarks for  improving quantum circuit mapping techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bandi%C4%87%2C+M">Medina Bandi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Almudever%2C+C+G">Carmen G. Almudever</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feld%2C+S">Sebastian Feld</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Machine Intelligence 5, Article number: 40 (2023), 5-40
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08262" title="Abstract">arXiv:2212.08262</a> (replaced) [<a href="/pdf/2212.08262" title="Download PDF">pdf</a>, <a href="/format/2212.08262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform Sequence Better: Time Interval Aware Data Augmentation for  Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yizhou Dang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Enneng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+G">Guibing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Linying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoxiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qinghui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, AAAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10621" title="Abstract">arXiv:2212.10621</a> (replaced) [<a href="/pdf/2212.10621" title="Download PDF">pdf</a>, <a href="/format/2212.10621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Body Articulated Human-Object Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhexuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jieming Cui</a>, 
<a href="/search/cs?searchtype=author&query=zhang%2C+Z">Zhiyuan zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yixin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13179" title="Abstract">arXiv:2212.13179</a> (replaced) [<a href="/pdf/2212.13179" title="Download PDF">pdf</a>, <a href="/format/2212.13179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Architectural Information: A Systematic Mapping Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Dieu%2C+M+J">Musengamana Jean de Dieu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zengyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages, 10 images, 9 tables, Manuscript submitted to a Journal (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02761" title="Abstract">arXiv:2301.02761</a> (replaced) [<a href="/pdf/2301.02761" title="Download PDF">pdf</a>, <a href="/format/2301.02761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning Guided by Efficient Surrogate Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yunpyo An</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Suyeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+I">Kwang In Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02885" title="Abstract">arXiv:2301.02885</a> (replaced) [<a href="/pdf/2301.02885" title="Download PDF">pdf</a>, <a href="/format/2301.02885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCOREH+: A High-Order Node Proximity Spectral Clustering on  Ratios-of-Eigenvectors Algorithm for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanhui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+F">Fang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+L+H">Lei Hsin Kuo</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+J">Jia liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03566" title="Abstract">arXiv:2301.03566</a> (replaced) [<a href="/pdf/2301.03566" title="Download PDF">pdf</a>, <a href="/format/2301.03566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Binary Hypothesis Testing under Local Differential Privacy and  Communication Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>, 
<a href="/search/math?searchtype=author&query=Asadi%2C+A+R">Amir R. Asadi</a>, 
<a href="/search/math?searchtype=author&query=Jog%2C+V">Varun Jog</a>, 
<a href="/search/math?searchtype=author&query=Loh%2C+P">Po-Ling Loh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03747" title="Abstract">arXiv:2301.03747</a> (replaced) [<a href="/pdf/2301.03747" title="Download PDF">pdf</a>, <a href="/format/2301.03747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiparametric Regression for Spatial Data via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+K">Kexuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Ives%2C+A+R">Anthony R. Ives</a>, 
<a href="/search/stat?searchtype=author&query=Radeloff%2C+V+C">Volker C. Radeloff</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+F">Fangfang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10343" title="Abstract">arXiv:2301.10343</a> (replaced) [<a href="/pdf/2301.10343" title="Download PDF">pdf</a>, <a href="/format/2301.10343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClimaX: A foundation model for weather and climate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Ashish Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J+K">Jayesh K. Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Machine Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12212" title="Abstract">arXiv:2301.12212</a> (replaced) [<a href="/pdf/2301.12212" title="Download PDF">pdf</a>, <a href="/format/2301.12212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Enumeration of Markov Equivalent DAGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wien%C3%B6bst%2C+M">Marcel Wien&#xf6;bst</a>, 
<a href="/search/cs?searchtype=author&query=Luttermann%2C+M">Malte Luttermann</a>, 
<a href="/search/cs?searchtype=author&query=Bannach%2C+M">Max Bannach</a>, 
<a href="/search/cs?searchtype=author&query=Li%C5%9Bkiewicz%2C+M">Maciej Li&#x15b;kiewicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of paper accepted to the Proceedings of the 37th AAAI Conference on Artificial Intelligence (AAAI-2023). [v2] includes minor fixes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00185" title="Abstract">arXiv:2302.00185</a> (replaced) [<a href="/pdf/2302.00185" title="Download PDF">pdf</a>, <a href="/format/2302.00185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensuring reliability: what is the optimal time for power plant  maintenance in Texas as the climate changes?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Daigle%2C+H">Hugh Daigle</a>, 
<a href="/search/eess?searchtype=author&query=Rhodes%2C+J+D">Joshua D. Rhodes</a>, 
<a href="/search/eess?searchtype=author&query=Pyrcz%2C+A">Aidan Pyrcz</a>, 
<a href="/search/eess?searchtype=author&query=Webber%2C+M+E">Michael E. Webber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01859" title="Abstract">arXiv:2302.01859</a> (replaced) [<a href="/pdf/2302.01859" title="Download PDF">pdf</a>, <a href="/format/2302.01859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing to Unseen Elements: A Survey on Knowledge Extrapolation for  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuxia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zezhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J+Z">Jeff Z. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCAI 2023 Survey Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02420" title="Abstract">arXiv:2302.02420</a> (replaced) [<a href="/pdf/2302.02420" title="Download PDF">pdf</a>, <a href="/format/2302.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Inference on the Final-Layer Output of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yadi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Khardon%2C+R">Roni Khardon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09694" title="Abstract">arXiv:2302.09694</a> (replaced) [<a href="/pdf/2302.09694" title="Download PDF">pdf</a>, <a href="/format/2302.09694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation for Causal Mediation Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by AAAI 2023. Please check: <a href="https://doi.org/10.1609/aaai.v37i9.26266">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12662" title="Abstract">arXiv:2302.12662</a> (replaced) [<a href="/pdf/2302.12662" title="Download PDF">pdf</a>, <a href="/format/2302.12662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDBL: Communication and Data Efficient Federated Deep-Broad Learning  for Histopathological Tissue Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+T">Tianpeng Deng</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yanqi Huang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+G">Guoqiang Han</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jiatai Lin</a>, 
<a href="/search/eess?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zaiyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xiao-jing Guo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C+L+P">C. L. Philip Chen</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Chu Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13036" title="Abstract">arXiv:2302.13036</a> (replaced) [<a href="/pdf/2302.13036" title="Download PDF">pdf</a>, <a href="/format/2302.13036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limited Query Graph Connectivity Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+A">Aneta Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hung Nguyen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13483" title="Abstract">arXiv:2302.13483</a> (replaced) [<a href="/pdf/2302.13483" title="Download PDF">pdf</a>, <a href="/format/2302.13483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Sagar Patel</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>, 
<a href="/search/cs?searchtype=author&query=Narodytska%2C+N">Nina Narodytska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00215" title="Abstract">arXiv:2303.00215</a> (replaced) [<a href="/pdf/2303.00215" title="Download PDF">pdf</a>, <a href="/format/2303.00215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Image Backdoor Inversion via Robust Smoothed Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023. v2: improved writing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00302" title="Abstract">arXiv:2303.00302</a> (replaced) [<a href="/pdf/2303.00302" title="Download PDF">pdf</a>, <a href="/format/2303.00302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Backdoors in Federated Learning with FLD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yihang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00355" title="Abstract">arXiv:2303.00355</a> (replaced) [<a href="/pdf/2303.00355" title="Download PDF">pdf</a>, <a href="/format/2303.00355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Scale-aware Network for Remote sensing Image Change  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiajun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zipeng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00800" title="Abstract">arXiv:2303.00800</a> (replaced) [<a href="/pdf/2303.00800" title="Download PDF">pdf</a>, <a href="/format/2303.00800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-Time Functional Diffusion Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giulio Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Corallo%2C+G">Giulio Corallo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+S">Simone Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Heinonen%2C+M">Markus Heinonen</a>, 
<a href="/search/cs?searchtype=author&query=Filippone%2C+M">Maurizio Filippone</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01213" title="Abstract">arXiv:2303.01213</a> (replaced) [<a href="/pdf/2303.01213" title="Download PDF">pdf</a>, <a href="/format/2303.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSD$^2$: Can We Dodge Sparse Double Descent and Compress the Neural  Network Worry-Free?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9tu%2C+V">Victor Qu&#xe9;tu</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01261" title="Abstract">arXiv:2303.01261</a> (replaced) [<a href="/pdf/2303.01261" title="Download PDF">pdf</a>, <a href="/format/2303.01261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Neil Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kosgi%2C+S">Saiteja Kosgi</a>, 
<a href="/search/cs?searchtype=author&query=Tambrahalli%2C+V">Vishal Tambrahalli</a>, 
<a href="/search/cs?searchtype=author&query=Sahipjohn%2C+N">Neha Sahipjohn</a>, 
<a href="/search/cs?searchtype=author&query=Pedanekar%2C+N">Niranjan Pedanekar</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+V">Vineet Gandhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02159" title="Abstract">arXiv:2303.02159</a> (replaced) [<a href="/pdf/2303.02159" title="Download PDF">pdf</a>, <a href="/ps/2303.02159" title="Download PostScript">ps</a>, <a href="/format/2303.02159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Parameter Estimation for Rational Ordinary Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bassik%2C+O">Oren Bassik</a>, 
<a href="/search/cs?searchtype=author&query=Berman%2C+Y">Yosef Berman</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+S">Soo Go</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hoon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ilmer%2C+I">Ilia Ilmer</a>, 
<a href="/search/cs?searchtype=author&query=Ovchinnikov%2C+A">Alexey Ovchinnikov</a>, 
<a href="/search/cs?searchtype=author&query=Rackauckas%2C+C">Chris Rackauckas</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+P">Pedro Soto</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+C">Chee Yap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updates regarding robustness
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Symbolic Computation (cs.SC); Dynamical Systems (math.DS); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03379" title="Abstract">arXiv:2303.03379</a> (replaced) [<a href="/pdf/2303.03379" title="Download PDF">pdf</a>, <a href="/format/2303.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUREL+: Moving from Walks to Sets for Scalable Subgraph-based Graph  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haoteng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianguo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of the full paper that appeared in PVLDB 16.11(VLDB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03932" title="Abstract">arXiv:2303.03932</a> (replaced) [<a href="/pdf/2303.03932" title="Download PDF">pdf</a>, <a href="/format/2303.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FFT-based Dynamic Token Mixer for Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tatsunami%2C+Y">Yuki Tatsunami</a>, 
<a href="/search/cs?searchtype=author&query=Taki%2C+M">Masato Taki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06315" title="Abstract">arXiv:2303.06315</a> (replaced) [<a href="/pdf/2303.06315" title="Download PDF">pdf</a>, <a href="/format/2303.06315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DETA: Denoised Task Adaptation for Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08518" title="Abstract">arXiv:2303.08518</a> (replaced) [<a href="/pdf/2303.08518" title="Download PDF">pdf</a>, <a href="/format/2303.08518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Daixuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Junyu Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yuefeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Denvy Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08815" title="Abstract">arXiv:2303.08815</a> (replaced) [<a href="/pdf/2303.08815" title="Download PDF">pdf</a>, <a href="/format/2303.08815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lane Graph as Path: Continuity-preserving Path-wise Modeling for Online  Lane Graph Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Bencheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tianheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08977" title="Abstract">arXiv:2303.08977</a> (replaced) [<a href="/pdf/2303.08977" title="Download PDF">pdf</a>, <a href="/format/2303.08977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeblurSR: Event-Based Motion Deblurring Under the Spiking Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chen Song</a>, 
<a href="/search/cs?searchtype=author&query=Bajaj%2C+C">Chandrajit Bajaj</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qixing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11098" title="Abstract">arXiv:2303.11098</a> (replaced) [<a href="/pdf/2303.11098" title="Download PDF">pdf</a>, <a href="/format/2303.11098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role of the Projector in Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miles%2C+R">Roy Miles</a>, 
<a href="/search/cs?searchtype=author&query=Mikolajczyk%2C+K">Krystian Mikolajczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Code available at <a href="https://github.com/roymiles/Simple-Recipe-Distillation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11611" title="Abstract">arXiv:2303.11611</a> (replaced) [<a href="/pdf/2303.11611" title="Download PDF">pdf</a>, <a href="/format/2303.11611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of Thin Air: Exploring Data-Free Adversarial Robustness Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pinxue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kaixun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lizhe Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11728" title="Abstract">arXiv:2303.11728</a> (replaced) [<a href="/pdf/2303.11728" title="Download PDF">pdf</a>, <a href="/format/2303.11728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Neural Radiance Fields Under Unconstrained Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">SeokYeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">JunYong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Ig-Jae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Junghyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://seokyeong94.github.io/ExtremeNeRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12787" title="Abstract">arXiv:2303.12787</a> (replaced) [<a href="/pdf/2303.12787" title="Download PDF">pdf</a>, <a href="/format/2303.12787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for  Monocular Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+W">Wei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Lu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/tjiiv-cprg/EPro-PnP-v2.">this https URL</a> Revised and fixed typos. arXiv admin note: substantial text overlap with <a href="/abs/2203.13254">arXiv:2203.13254</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13269" title="Abstract">arXiv:2303.13269</a> (replaced) [<a href="/pdf/2303.13269" title="Download PDF">pdf</a>, <a href="/format/2303.13269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disguise without Disruption: Utility-Preserving Face De-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zikui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhongpai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Planche%2C+B">Benjamin Planche</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Terrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+S">M. Salman Asif</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. Paper + supplementary material
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  38(1), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15458" title="Abstract">arXiv:2303.15458</a> (replaced) [<a href="/pdf/2303.15458" title="Download PDF">pdf</a>, <a href="/format/2303.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Method for Solving Time-Fractional Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guidotti%2C+N+L">Nicolas L. Guidotti</a>, 
<a href="/search/math?searchtype=author&query=Acebr%C3%B3n%2C+J">Juan Acebr&#xf3;n</a>, 
<a href="/search/math?searchtype=author&query=Monteiro%2C+J">Jos&#xe9; Monteiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computers and Mathematics with Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17561" title="Abstract">arXiv:2303.17561</a> (replaced) [<a href="/pdf/2303.17561" title="Download PDF">pdf</a>, <a href="/format/2303.17561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T+W+E">Tong Wu Enwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17594" title="Abstract">arXiv:2303.17594</a> (replaced) [<a href="/pdf/2303.17594" title="Download PDF">pdf</a>, <a href="/format/2303.17594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileInst: Video Instance Segmentation on the Mobile
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tianheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiancheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+X">Xiaowen Ying</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dashan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 Main Track; Code will be released
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17743" title="Abstract">arXiv:2303.17743</a> (replaced) [<a href="/pdf/2303.17743" title="Download PDF">pdf</a>, <a href="/format/2303.17743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairGen: Towards Fair Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dawei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiejun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yada Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00242" title="Abstract">arXiv:2304.00242</a> (replaced) [<a href="/e-print/2304.00242" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLT-T++: Global-Local Transformer for 3D Siamese Tracking with Ranking  Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xudong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Need further revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01168" title="Abstract">arXiv:2304.01168</a> (replaced) [<a href="/pdf/2304.01168" title="Download PDF">pdf</a>, <a href="/format/2304.01168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepAccident: A Motion and Accident Prediction Benchmark for V2X  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sukmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wenxuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01781" title="Abstract">arXiv:2304.01781</a> (replaced) [<a href="/pdf/2304.01781" title="Download PDF">pdf</a>, <a href="/ps/2304.01781" title="Download PostScript">ps</a>, <a href="/format/2304.01781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixing predictions for online metric algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antoniadis%2C+A">Antonios Antoniadis</a>, 
<a href="/search/cs?searchtype=author&query=Coester%2C+C">Christian Coester</a>, 
<a href="/search/cs?searchtype=author&query=Eli%C3%A1%C5%A1%2C+M">Marek Eli&#xe1;&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+A">Adam Polak</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+B">Bertrand Simon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08796" title="Abstract">arXiv:2304.08796</a> (replaced) [<a href="/pdf/2304.08796" title="Download PDF">pdf</a>, <a href="/format/2304.08796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unrestricted Document Image Rectification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaokai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiajun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00179" title="Abstract">arXiv:2305.00179</a> (replaced) [<a href="/pdf/2305.00179" title="Download PDF">pdf</a>, <a href="/format/2305.00179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communications: Recent Advances and Ten Open  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shihang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kecheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hongjia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jiaqi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+F">Fuwang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jia Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yifeng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuanhao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 22 figures, resubmitted to IEEE Journal. Appreciation for the outstanding contributions of coauthors in the paper!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02041" title="Abstract">arXiv:2305.02041</a> (replaced) [<a href="/pdf/2305.02041" title="Download PDF">pdf</a>, <a href="/format/2305.02041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-complexity subspace-descent over symmetric positive definite  manifold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Darmwal%2C+Y">Yogesh Darmwal</a>, 
<a href="/search/stat?searchtype=author&query=Rajawat%2C+K">Ketan Rajawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02704" title="Abstract">arXiv:2305.02704</a> (replaced) [<a href="/pdf/2305.02704" title="Download PDF">pdf</a>, <a href="/ps/2305.02704" title="Download PostScript">ps</a>, <a href="/format/2305.02704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Max-and-Min Fractional Programming for Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yannan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Licheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03453" title="Abstract">arXiv:2305.03453</a> (replaced) [<a href="/pdf/2305.03453" title="Download PDF">pdf</a>, <a href="/format/2305.03453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large  Language Model Signals for Science Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabang He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04926" title="Abstract">arXiv:2305.04926</a> (replaced) [<a href="/pdf/2305.04926" title="Download PDF">pdf</a>, <a href="/format/2305.04926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RelPose++: Recovering 6D Poses from Sparse-view Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+A">Amy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Y">Jason Y. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Tulsiani%2C+S">Shubham Tulsiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://amyxlase.github.io/relpose-plus-plus">this https URL</a> (Accepted to 3DV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05091" title="Abstract">arXiv:2305.05091</a> (replaced) [<a href="/pdf/2305.05091" title="Download PDF">pdf</a>, <a href="/format/2305.05091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-enhanced Agents for Interactive Text Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chhikara%2C+P">Prateek Chhikara</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiarui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+J">Jonathan Francis</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at K-CAP '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05129" title="Abstract">arXiv:2305.05129</a> (replaced) [<a href="/pdf/2305.05129" title="Download PDF">pdf</a>, <a href="/format/2305.05129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorting Finite Automata via Partition Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+R">Ruben Becker</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1ceres%2C+M">Manuel C&#xe1;ceres</a>, 
<a href="/search/cs?searchtype=author&query=Cenzato%2C+D">Davide Cenzato</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung-Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kodric%2C+B">Bojana Kodric</a>, 
<a href="/search/cs?searchtype=author&query=Olivares%2C+F">Francisco Olivares</a>, 
<a href="/search/cs?searchtype=author&query=Prezza%2C+N">Nicola Prezza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05206" title="Abstract">arXiv:2305.05206</a> (replaced) [<a href="/pdf/2305.05206" title="Download PDF">pdf</a>, <a href="/format/2305.05206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fair and Resilient Decentralized Clock Network for Transaction  Ordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Constantinescu%2C+A">Andrei Constantinescu</a>, 
<a href="/search/cs?searchtype=author&query=Ghinea%2C+D">Diana Ghinea</a>, 
<a href="/search/cs?searchtype=author&query=Heimbach%2C+L">Lioba Heimbach</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of 27th International Conference on Principles of Distributed Systems (OPODIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06252" title="Abstract">arXiv:2305.06252</a> (replaced) [<a href="/pdf/2305.06252" title="Download PDF">pdf</a>, <a href="/format/2305.06252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Feature Similarity Optimization with Specific Parameter  Initialization for 2D/3D Medical Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Youyong Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07490" title="Abstract">arXiv:2305.07490</a> (replaced) [<a href="/pdf/2305.07490" title="Download PDF">pdf</a>, <a href="/format/2305.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArtGPT-4: Towards Artistic-understanding Large Vision-Language Models  with Enhanced Adapter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhengqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yanyang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08049" title="Abstract">arXiv:2305.08049</a> (replaced) [<a href="/pdf/2305.08049" title="Download PDF">pdf</a>, <a href="/format/2305.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Surprisingly Simple Continuous-Action POMDP Solver: Lazy Cross-Entropy  Search Over Policy Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoerger%2C+M">Marcus Hoerger</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawati%2C+H">Hanna Kurniawati</a>, 
<a href="/search/cs?searchtype=author&query=Kroese%2C+D">Dirk Kroese</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Nan Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08658" title="Abstract">arXiv:2305.08658</a> (replaced) [<a href="/pdf/2305.08658" title="Download PDF">pdf</a>, <a href="/ps/2305.08658" title="Download PostScript">ps</a>, <a href="/format/2305.08658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the connections between optimization algorithms, Lyapunov functions,  and differential equations: theory and insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dobson%2C+P">Paul Dobson</a>, 
<a href="/search/math?searchtype=author&query=Sanz-Serna%2C+J+M">Jesus Maria Sanz-Serna</a>, 
<a href="/search/math?searchtype=author&query=Zygalakis%2C+K">Konstantinos Zygalakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10135" title="Abstract">arXiv:2305.10135</a> (replaced) [<a href="/pdf/2305.10135" title="Download PDF">pdf</a>, <a href="/format/2305.10135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Mind Visual Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaolong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10391" title="Abstract">arXiv:2305.10391</a> (replaced) [<a href="/pdf/2305.10391" title="Download PDF">pdf</a>, <a href="/format/2305.10391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimality of Message-Passing Architectures for Sparse Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baranwal%2C+A">Aseem Baranwal</a>, 
<a href="/search/cs?searchtype=author&query=Fountoulakis%2C+K">Kimon Fountoulakis</a>, 
<a href="/search/cs?searchtype=author&query=Jagannath%2C+A">Aukosh Jagannath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 3 figures, published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10512" title="Abstract">arXiv:2305.10512</a> (replaced) [<a href="/pdf/2305.10512" title="Download PDF">pdf</a>, <a href="/format/2305.10512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMAD: IMage-Augmented multi-modal Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskvoretskii%2C+V">Viktor Moskvoretskii</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+A">Anton Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+D">Denis Kuznetsov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main part contains 6 pages, 4 figures. It was accepted on AINL. We wait the publication and DOI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11011" title="Abstract">arXiv:2305.11011</a> (replaced) [<a href="/pdf/2305.11011" title="Download PDF">pdf</a>, <a href="/format/2305.11011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case VCG Redistribution Mechanism Design Based on the Lottery  Ticket Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12038" title="Abstract">arXiv:2305.12038</a> (replaced) [<a href="/pdf/2305.12038" title="Download PDF">pdf</a>, <a href="/ps/2305.12038" title="Download PostScript">ps</a>, <a href="/format/2305.12038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilized finite element methods for the time-spectral  convection-diffusion equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Esmaily%2C+M">Mahdi Esmaily</a>, 
<a href="/search/math?searchtype=author&query=Jia%2C+D">Dongjie Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *Correspondence: me399@cornell.edu
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12781" title="Abstract">arXiv:2305.12781</a> (replaced) [<a href="/pdf/2305.12781" title="Download PDF">pdf</a>, <a href="/format/2305.12781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform estimates for conforming Galerkin method for anisotropic  singularly perturbed elliptic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maltese%2C+D">David Maltese</a>, 
<a href="/search/math?searchtype=author&query=Ogabi%2C+C">Chokri Ogabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13071" title="Abstract">arXiv:2305.13071</a> (replaced) [<a href="/pdf/2305.13071" title="Download PDF">pdf</a>, <a href="/format/2305.13071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Created Universal Language for Cross-lingual Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanzhi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14196" title="Abstract">arXiv:2305.14196</a> (replaced) [<a href="/pdf/2305.14196" title="Download PDF">pdf</a>, <a href="/format/2305.14196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaham%2C+U">Uri Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Ivgi%2C+M">Maor Ivgi</a>, 
<a href="/search/cs?searchtype=author&query=Efrat%2C+A">Avia Efrat</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+O">Omer Levy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14561" title="Abstract">arXiv:2305.14561</a> (replaced) [<a href="/pdf/2305.14561" title="Download PDF">pdf</a>, <a href="/format/2305.14561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCIM DNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wujie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15747" title="Abstract">arXiv:2305.15747</a> (replaced) [<a href="/pdf/2305.15747" title="Download PDF">pdf</a>, <a href="/format/2305.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Union Subgraph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaxing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aihu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Q">Qingtian Bian</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Y">Yiping Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16081" title="Abstract">arXiv:2305.16081</a> (replaced) [<a href="/pdf/2305.16081" title="Download PDF">pdf</a>, <a href="/ps/2305.16081" title="Download PostScript">ps</a>, <a href="/format/2305.16081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Envy-Free Allocations of Indivisible Goods or Chores with  Entitlements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Springer%2C+M">Max Springer</a>, 
<a href="/search/cs?searchtype=author&query=Yami%2C+H">Hadi Yami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17021" title="Abstract">arXiv:2305.17021</a> (replaced) [<a href="/pdf/2305.17021" title="Download PDF">pdf</a>, <a href="/format/2305.17021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLOBE-CE: A Translation-Based Approach for Global Counterfactual  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ley%2C+D">Dan Ley</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Saumitra Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Magazzeni%2C+D">Daniele Magazzeni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICML 2023 (9 page main text, 3 page references, 16 page appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17423" title="Abstract">arXiv:2305.17423</a> (replaced) [<a href="/pdf/2305.17423" title="Download PDF">pdf</a>, <a href="/format/2305.17423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Text-to-image Editing via Cache-enabled Sparse Diffusion  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fangcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17770" title="Abstract">arXiv:2305.17770</a> (replaced) [<a href="/pdf/2305.17770" title="Download PDF">pdf</a>, <a href="/ps/2305.17770" title="Download PostScript">ps</a>, <a href="/format/2305.17770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Completion Guided by Prior Knowledge via Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songxue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+C">Chuanqi Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruidong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18270" title="Abstract">arXiv:2305.18270</a> (replaced) [<a href="/pdf/2305.18270" title="Download PDF">pdf</a>, <a href="/format/2305.18270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Two-Layer Neural Networks Learn, One (Giant) Step at a Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dandi%2C+Y">Yatin Dandi</a>, 
<a href="/search/stat?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="/search/stat?searchtype=author&query=Loureiro%2C+B">Bruno Loureiro</a>, 
<a href="/search/stat?searchtype=author&query=Pesce%2C+L">Luca Pesce</a>, 
<a href="/search/stat?searchtype=author&query=Stephan%2C+L">Ludovic Stephan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19496" title="Abstract">arXiv:2305.19496</a> (replaced) [<a href="/pdf/2305.19496" title="Download PDF">pdf</a>, <a href="/ps/2305.19496" title="Download PostScript">ps</a>, <a href="/format/2305.19496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Learning in Games Good for the Learners?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+W">William Brown</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jon Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Vodrahalli%2C+K">Kiran Vodrahalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19951" title="Abstract">arXiv:2305.19951</a> (replaced) [<a href="/pdf/2305.19951" title="Download PDF">pdf</a>, <a href="/format/2305.19951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and  Mitigation of Reasoning Shortcuts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marconato%2C+E">Emanuele Marconato</a>, 
<a href="/search/cs?searchtype=author&query=Teso%2C+S">Stefano Teso</a>, 
<a href="/search/cs?searchtype=author&query=Vergari%2C+A">Antonio Vergari</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19972" title="Abstract">arXiv:2305.19972</a> (replaced) [<a href="/pdf/2305.19972" title="Download PDF">pdf</a>, <a href="/format/2305.19972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VILAS: Exploring the Effects of Vision and Language Context in Automatic  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ni%2C+Z">Ziyi Ni</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+M">Minglun Han</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+F">Feilong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+L">Linghui Meng</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jing Shi</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+P">Pin Lv</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20052" title="Abstract">arXiv:2305.20052</a> (replaced) [<a href="/pdf/2305.20052" title="Download PDF">pdf</a>, <a href="/format/2305.20052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Decision Gradients: Compute Your Attributions Where the Model  Makes Its Decision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+C">Chase Walker</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Sumit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kenny Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ewetz%2C+R">Rickard Ewetz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, accepted at AAAI 2024, the full code implementation of the paper results is located at: <a href="https://github.com/chasewalker26/Integrated-Decision-Gradients">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00249" title="Abstract">arXiv:2306.00249</a> (replaced) [<a href="/pdf/2306.00249" title="Download PDF">pdf</a>, <a href="/format/2306.00249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BetaZero: Belief-State Planning for Long-Horizon POMDPs using Learned  Approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moss%2C+R+J">Robert J. Moss</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+A">Anthony Corso</a>, 
<a href="/search/cs?searchtype=author&query=Caers%2C+J">Jef Caers</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00461" title="Abstract">arXiv:2306.00461</a> (replaced) [<a href="/pdf/2306.00461" title="Download PDF">pdf</a>, <a href="/format/2306.00461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disjoint Partial Enumeration without Blocking Clauses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spallitta%2C+G">Giuseppe Spallitta</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+R">Roberto Sebastiani</a>, 
<a href="/search/cs?searchtype=author&query=Biere%2C+A">Armin Biere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00800" title="Abstract">arXiv:2306.00800</a> (replaced) [<a href="/pdf/2306.00800" title="Download PDF">pdf</a>, <a href="/format/2306.00800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FigGen: Text to Scientific Figure Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+J+A">Juan A Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+D">David Vazquez</a>, 
<a href="/search/cs?searchtype=author&query=Laradji%2C+I">Issam Laradji</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+P">Pau Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2023 as a Tiny Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00899" title="Abstract">arXiv:2306.00899</a> (replaced) [<a href="/pdf/2306.00899" title="Download PDF">pdf</a>, <a href="/format/2306.00899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pitfalls in Link Prediction with Graph Neural Networks: Understanding  the Impact of Target-link Inclusion &amp; Better Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+V+N">Vassilis N. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengyi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Koutra%2C+D">Danai Koutra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Version of our WSDM'24 paper. 8 pages, 2 page appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00919" title="Abstract">arXiv:2306.00919</a> (replaced) [<a href="/pdf/2306.00919" title="Download PDF">pdf</a>, <a href="/ps/2306.00919" title="Download PostScript">ps</a>, <a href="/format/2306.00919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning about Social Context from Smartphone Data: Generalization  Across Countries and Daily Life Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mader%2C+A+R">Aurel Ruben Mader</a>, 
<a href="/search/cs?searchtype=author&query=Meegahapola%2C+L">Lakmal Meegahapola</a>, 
<a href="/search/cs?searchtype=author&query=Gatica-Perez%2C+D">Daniel Gatica-Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02235" title="Abstract">arXiv:2306.02235</a> (replaced) [<a href="/pdf/2306.02235" title="Download PDF">pdf</a>, <a href="/format/2306.02235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Linear Causal Representations from Interventions under General  Nonlinear Mixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchholz%2C+S">Simon Buchholz</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+G">Goutham Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+E">Elan Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Oral paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02841" title="Abstract">arXiv:2306.02841</a> (replaced) [<a href="/pdf/2306.02841" title="Download PDF">pdf</a>, <a href="/format/2306.02841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTRL: Connect Collaborative and Language Model for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03832" title="Abstract">arXiv:2306.03832</a> (replaced) [<a href="/pdf/2306.03832" title="Download PDF">pdf</a>, <a href="/ps/2306.03832" title="Download PostScript">ps</a>, <a href="/format/2306.03832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Principal-Agent Problems with Communication: Efficient  Computation and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+J">Jiarui Gan</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+R">Rupak Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+D">Debmalya Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Radanovic%2C+G">Goran Radanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04445" title="Abstract">arXiv:2306.04445</a> (replaced) [<a href="/pdf/2306.04445" title="Download PDF">pdf</a>, <a href="/format/2306.04445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Latent Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bounoua%2C+M">Mustapha Bounoua</a>, 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giulio Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04737" title="Abstract">arXiv:2306.04737</a> (replaced) [<a href="/pdf/2306.04737" title="Download PDF">pdf</a>, <a href="/format/2306.04737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Wheeler Language Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+R">Ruben Becker</a>, 
<a href="/search/cs?searchtype=author&query=Cenzato%2C+D">Davide Cenzato</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung-Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kodric%2C+B">Bojana Kodric</a>, 
<a href="/search/cs?searchtype=author&query=Policriti%2C+A">Alberto Policriti</a>, 
<a href="/search/cs?searchtype=author&query=Prezza%2C+N">Nicola Prezza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05144" title="Abstract">arXiv:2306.05144</a> (replaced) [<a href="/pdf/2306.05144" title="Download PDF">pdf</a>, <a href="/format/2306.05144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in  the Mediterranean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondylatos%2C+S">Spyros Kondylatos</a>, 
<a href="/search/cs?searchtype=author&query=Prapas%2C+I">Ioannis Prapas</a>, 
<a href="/search/cs?searchtype=author&query=Camps-Valls%2C+G">Gustau Camps-Valls</a>, 
<a href="/search/cs?searchtype=author&query=Papoutsis%2C+I">Ioannis Papoutsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks (oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05156" title="Abstract">arXiv:2306.05156</a> (replaced) [<a href="/pdf/2306.05156" title="Download PDF">pdf</a>, <a href="/ps/2306.05156" title="Download PostScript">ps</a>, <a href="/format/2306.05156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFT-Based Channel Estimation for Holographic MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amico%2C+A+A">Antonio Alberto D&#x27;Amico</a>, 
<a href="/search/cs?searchtype=author&query=Bacci%2C+G">Giacomo Bacci</a>, 
<a href="/search/cs?searchtype=author&query=Sanguinetti%2C+L">Luca Sanguinetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,4 figures, Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, USA, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06963" title="Abstract">arXiv:2306.06963</a> (replaced) [<a href="/pdf/2306.06963" title="Download PDF">pdf</a>, <a href="/format/2306.06963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Fusion from Head to Tail for Long-Tailed Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengke Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhikai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+W">Weichao Lan</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y">Yiu-ming Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI24, similar to the conference version. Add the supplementry
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07254" title="Abstract">arXiv:2306.07254</a> (replaced) [<a href="/pdf/2306.07254" title="Download PDF">pdf</a>, <a href="/format/2306.07254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Expected Size of Conformal Prediction Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dhillon%2C+G+S">Guneet S. Dhillon</a>, 
<a href="/search/stat?searchtype=author&query=Deligiannidis%2C+G">George Deligiannidis</a>, 
<a href="/search/stat?searchtype=author&query=Rainforth%2C+T">Tom Rainforth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08393" title="Abstract">arXiv:2306.08393</a> (replaced) [<a href="/pdf/2306.08393" title="Download PDF">pdf</a>, <a href="/format/2306.08393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Personalized and Robust Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Werner%2C+M">Mariel Werner</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lie He</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M">Michael Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>, 
<a href="/search/cs?searchtype=author&query=Karimireddy%2C+S+P">Sai Praneeth Karimireddy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08451" title="Abstract">arXiv:2306.08451</a> (replaced) [<a href="/pdf/2306.08451" title="Download PDF">pdf</a>, <a href="/format/2306.08451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Blood Pressure Measurement Technologies: Addressing  Potential Sources of Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mousavi%2C+S+S">Seyedeh Somayyeh Mousavi</a>, 
<a href="/search/physics?searchtype=author&query=Reyna%2C+M+A">Matthew A. Reyna</a>, 
<a href="/search/physics?searchtype=author&query=Clifford%2C+G+D">Gari D. Clifford</a>, 
<a href="/search/physics?searchtype=author&query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08707" title="Abstract">arXiv:2306.08707</a> (replaced) [<a href="/pdf/2306.08707" title="Download PDF">pdf</a>, <a href="/format/2306.08707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidEdit: Zero-Shot and Spatially Aware Text-Driven Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Couairon%2C+P">Paul Couairon</a>, 
<a href="/search/cs?searchtype=author&query=Rambour%2C+C">Cl&#xe9;ment Rambour</a>, 
<a href="/search/cs?searchtype=author&query=Haugeard%2C+J">Jean-Emmanuel Haugeard</a>, 
<a href="/search/cs?searchtype=author&query=Thome%2C+N">Nicolas Thome</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project web-page at <a href="https://videdit.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10599" title="Abstract">arXiv:2306.10599</a> (replaced) [<a href="/pdf/2306.10599" title="Download PDF">pdf</a>, <a href="/ps/2306.10599" title="Download PostScript">ps</a>, <a href="/format/2306.10599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Untangling Patterns of Two-Class Dependency Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Huan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaotian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint accepted for publication in Empirical Software Engineering, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12153" title="Abstract">arXiv:2306.12153</a> (replaced) [<a href="/pdf/2306.12153" title="Download PDF">pdf</a>, <a href="/format/2306.12153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIAS: A Dataset and Benchmark for Intracranial Artery Segmentation in  DSA sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+T">Tong Tian</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lemeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Weijin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+W">Wenyi Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+S">Siyu Tian</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+X">Xipeng Pan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Huihua Yang</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+Y">Yiming Deng</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Ruisheng Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12212" title="Abstract">arXiv:2306.12212</a> (replaced) [<a href="/pdf/2306.12212" title="Download PDF">pdf</a>, <a href="/format/2306.12212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MimiC: Combating Client Dropouts in Federated Learning by Mimicking  Central Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuchang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuyi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12749" title="Abstract">arXiv:2306.12749</a> (replaced) [<a href="/pdf/2306.12749" title="Download PDF">pdf</a>, <a href="/format/2306.12749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical informed neural networks with soft and hard boundary  constraints for solving advection-diffusion equations using Fourier  expansions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xi&#x27;an Li</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+J">Jiaxin Deng</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+J">Jinran Wu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shaotong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Weide Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">You-Gan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13154" title="Abstract">arXiv:2306.13154</a> (replaced) [<a href="/pdf/2306.13154" title="Download PDF">pdf</a>, <a href="/ps/2306.13154" title="Download PostScript">ps</a>, <a href="/format/2306.13154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Free Distributed Charging Control for Electric Vehicle  Group
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Heyang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+C">Chuanzi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Geng%2C+G">Guangchao Geng</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Q">Quanyuan Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Smart Grid
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Smart Grid,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13803" title="Abstract">arXiv:2306.13803</a> (replaced) [<a href="/pdf/2306.13803" title="Download PDF">pdf</a>, <a href="/ps/2306.13803" title="Download PostScript">ps</a>, <a href="/format/2306.13803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elephants and Algorithms: A Review of the Current and Future Role of AI  in Elephant Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brickson%2C+L">Leandra Brickson</a>, 
<a href="/search/cs?searchtype=author&query=Vollrath%2C+F">Fritz Vollrath</a>, 
<a href="/search/cs?searchtype=author&query=Titus%2C+A+J">Alexander J. Titus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15222" title="Abstract">arXiv:2306.15222</a> (replaced) [<a href="/pdf/2306.15222" title="Download PDF">pdf</a>, <a href="/format/2306.15222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Rank in Generative Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15521" title="Abstract">arXiv:2306.15521</a> (replaced) [<a href="/pdf/2306.15521" title="Download PDF">pdf</a>, <a href="/format/2306.15521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blumenstiel%2C+B">Benedikt Blumenstiel</a>, 
<a href="/search/cs?searchtype=author&query=Jakubik%2C+J">Johannes Jakubik</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChne%2C+H">Hilde K&#xfc;hne</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6ssing%2C+M">Michael V&#xf6;ssing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00371" title="Abstract">arXiv:2307.00371</a> (replaced) [<a href="/pdf/2307.00371" title="Download PDF">pdf</a>, <a href="/format/2307.00371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Content-enhanced Mask Transformer for Domain Generalized  Urban-Scene Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+Q">Qi Bi</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shaodi You</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Camera-ready version with available source code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01003" title="Abstract">arXiv:2307.01003</a> (replaced) [<a href="/pdf/2307.01003" title="Download PDF">pdf</a>, <a href="/format/2307.01003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Instruction Tuning with Polite Flamingo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Delong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01146" title="Abstract">arXiv:2307.01146</a> (replaced) [<a href="/pdf/2307.01146" title="Download PDF">pdf</a>, <a href="/format/2307.01146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVSegFormer: Audio-Visual Segmentation with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shengyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01504" title="Abstract">arXiv:2307.01504</a> (replaced) [<a href="/pdf/2307.01504" title="Download PDF">pdf</a>, <a href="/format/2307.01504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All in One: Multi-task Prompting for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jihong Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 23 Best Research Paper Award, which is the first for Hong Kong and Mainland China. A Python Library is released as ProG: <a href="https://github.com/sheldonresearch/ProG">this https URL</a> Submitted to SIGKDD'23 in 03 Feb 2023; Receive Acceptance in 17 May 2023 (Rating 3 4 4 4); Submit to arXiv 1st time in 4 Jul 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02242" title="Abstract">arXiv:2307.02242</a> (replaced) [<a href="/pdf/2307.02242" title="Download PDF">pdf</a>, <a href="/format/2307.02242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-IRS-Enabled Integrated Sensing and Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xianghao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02507" title="Abstract">arXiv:2307.02507</a> (replaced) [<a href="/pdf/2307.02507" title="Download PDF">pdf</a>, <a href="/format/2307.02507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STS-CCL: Spatial-Temporal Synchronous Contextual Contrastive Learning  for Urban Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lincan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fengji Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Jichao Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was accepted by the 49th IEEE International Conference on Acoustics, Speech, &amp; Signal Processing (ICASSP 2024). We will present our work in Seoul, Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03856" title="Abstract">arXiv:2307.03856</a> (replaced) [<a href="/pdf/2307.03856" title="Download PDF">pdf</a>, <a href="/format/2307.03856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Categories Discovery Via Constraints on Empirical Prediction  Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+Z">Zahid Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Faridee%2C+A+Z+M">Abu Zaher Md Faridee</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Masud Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Purushotham%2C+S">Sanjay Purushotham</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Heesung Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungtae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nirmalya Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03998" title="Abstract">arXiv:2307.03998</a> (replaced) [<a href="/pdf/2307.03998" title="Download PDF">pdf</a>, <a href="/format/2307.03998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Improved Residual Network for Efficient Inverse Tone Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liqi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yongbao Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+X">Xiantong Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04923" title="Abstract">arXiv:2307.04923</a> (replaced) [<a href="/pdf/2307.04923" title="Download PDF">pdf</a>, <a href="/format/2307.04923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking with Long-Term Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brantley%2C+K">Kiant&#xe9; Brantley</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhichong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+S">Sarah Dean</a>, 
<a href="/search/cs?searchtype=author&query=Joachims%2C+T">Thorsten Joachims</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05210" title="Abstract">arXiv:2307.05210</a> (replaced) [<a href="/pdf/2307.05210" title="Download PDF">pdf</a>, <a href="/format/2307.05210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unique continuation for an elliptic interface problem using unfitted  isoparametric finite elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burman%2C+E">Erik Burman</a>, 
<a href="/search/math?searchtype=author&query=Preuss%2C+J">Janosch Preuss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05845" title="Abstract">arXiv:2307.05845</a> (replaced) [<a href="/pdf/2307.05845" title="Download PDF">pdf</a>, <a href="/format/2307.05845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIGEON: Predicting Image Geolocations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haas%2C+L">Lukas Haas</a>, 
<a href="/search/cs?searchtype=author&query=Skreta%2C+M">Michal Skreta</a>, 
<a href="/search/cs?searchtype=author&query=Alberti%2C+S">Silas Alberti</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06148" title="Abstract">arXiv:2307.06148</a> (replaced) [<a href="/pdf/2307.06148" title="Download PDF">pdf</a>, <a href="/format/2307.06148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NetGPT: A Native-AI Network Architecture Beyond Provisioning  Personalized Generative Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenghui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06561" title="Abstract">arXiv:2307.06561</a> (replaced) [<a href="/pdf/2307.06561" title="Download PDF">pdf</a>, <a href="/ps/2307.06561" title="Download PostScript">ps</a>, <a href="/format/2307.06561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Improvement of Federated Learning Server using Smart NIC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shibahara%2C+N">Naoki Shibahara</a>, 
<a href="/search/cs?searchtype=author&query=Koibuchi%2C+M">Michihiro Koibuchi</a>, 
<a href="/search/cs?searchtype=author&query=Matsutani%2C+H">Hiroki Matsutani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CANDAR'23 Workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08506" title="Abstract">arXiv:2307.08506</a> (replaced) [<a href="/pdf/2307.08506" title="Download PDF">pdf</a>, <a href="/format/2307.08506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Visual Pretraining Help End-to-End Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Calvin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Arnab%2C+A">Anurag Arnab</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11628" title="Abstract">arXiv:2307.11628</a> (replaced) [<a href="/pdf/2307.11628" title="Download PDF">pdf</a>, <a href="/format/2307.11628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Mesh Watermark: Towards Highly Robust and Adaptable Deep 3D  Mesh Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guanhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xuetao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13709" title="Abstract">arXiv:2307.13709</a> (replaced) [<a href="/pdf/2307.13709" title="Download PDF">pdf</a>, <a href="/ps/2307.13709" title="Download PostScript">ps</a>, <a href="/format/2307.13709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Bradley-Terry Rating: Quantifying Properties from Comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+S">Satoru Fujii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing on ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14302" title="Abstract">arXiv:2307.14302</a> (replaced) [<a href="/pdf/2307.14302" title="Download PDF">pdf</a>, <a href="/format/2307.14302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discontinuous Galerkin Finite Element Model for Compound Flood  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wichitrnithed%2C+C">Chayanon Wichitrnithed</a>, 
<a href="/search/cs?searchtype=author&query=Valseth%2C+E">Eirik Valseth</a>, 
<a href="/search/cs?searchtype=author&query=Kubatko%2C+E+J">Ethan J. Kubatko</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Younghun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+M">Mackenzie Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+C">Clint Dawson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15421" title="Abstract">arXiv:2307.15421</a> (replaced) [<a href="/pdf/2307.15421" title="Download PDF">pdf</a>, <a href="/format/2307.15421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLIC++: Linear Complexity Attention-based Multi-Reference Entropy  Modeling for Learned Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jiayu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhai%2C+Y">Yongqi Zhai</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ronggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v4 is the journel version. Short version (v1, v2, v3) is accepted at ICML 2023 Neural Compression Workshop. MLIC++ is an extension of our ACMMM 2023 paper MLIC: Multi-Reference Entropy Model for Learned Image Compression
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15484" title="Abstract">arXiv:2307.15484</a> (replaced) [<a href="/pdf/2307.15484" title="Download PDF">pdf</a>, <a href="/format/2307.15484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimally-Supervised Speech Synthesis with Conditional Diffusion Model  and Language Model: A Comparative Study of Semantic Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Hao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">He Qu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15494" title="Abstract">arXiv:2307.15494</a> (replaced) [<a href="/pdf/2307.15494" title="Download PDF">pdf</a>, <a href="/format/2307.15494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ETHER: Aligning Emergent Communication for Hindsight Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denamgana%C3%AF%2C+K">Kevin Denamgana&#xef;</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+D">Daniel Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Vardal%2C+O">Ozan Vardal</a>, 
<a href="/search/cs?searchtype=author&query=Missaoui%2C+S">Sondess Missaoui</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+J+A">James Alfred Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16446" title="Abstract">arXiv:2307.16446</a> (replaced) [<a href="/pdf/2307.16446" title="Download PDF">pdf</a>, <a href="/format/2307.16446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Transfer between Two Antenna Arrays in the Near Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+K+K">Krishan Kumar Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16456" title="Abstract">arXiv:2307.16456</a> (replaced) [<a href="/pdf/2307.16456" title="Download PDF">pdf</a>, <a href="/format/2307.16456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camoscio: an Italian Instruction-tuned LLaMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santilli%2C+A">Andrea Santilli</a>, 
<a href="/search/cs?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at CLiC-it 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02669" title="Abstract">arXiv:2308.02669</a> (replaced) [<a href="/pdf/2308.02669" title="Download PDF">pdf</a>, <a href="/format/2308.02669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConceptLab: Creative Concept Generation using VLM-Guided Diffusion Prior  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richardson%2C+E">Elad Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Kfir Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Alaluf%2C+Y">Yuval Alaluf</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://kfirgoldberg.github.io/ConceptLab/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06077" title="Abstract">arXiv:2308.06077</a> (replaced) [<a href="/pdf/2308.06077" title="Download PDF">pdf</a>, <a href="/format/2308.06077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fly-Swat or Cannon? Cost-Effective Language Model Choice via  Meta-Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A0akota%2C+M">Marija &#x160;akota</a>, 
<a href="/search/cs?searchtype=author&query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06587" title="Abstract">arXiv:2308.06587</a> (replaced) [<a href="/pdf/2308.06587" title="Download PDF">pdf</a>, <a href="/format/2308.06587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A User-centered Security Evaluation of Copilot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asare%2C+O">Owura Asare</a>, 
<a href="/search/cs?searchtype=author&query=Nagappan%2C+M">Meiyappan Nagappan</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in ICSE 2024 Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06764" title="Abstract">arXiv:2308.06764</a> (replaced) [<a href="/pdf/2308.06764" title="Download PDF">pdf</a>, <a href="/format/2308.06764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Class-incremental Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Silv%C3%A9n%2C+O">Olli Silv&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Pietik%C3%A4inen%2C+M">Matti Pietik&#xe4;inen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dewen Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06931" title="Abstract">arXiv:2308.06931</a> (replaced) [<a href="/pdf/2308.06931" title="Download PDF">pdf</a>, <a href="/format/2308.06931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionPlanner: A Multi-task Motion Planner for Mining Trucks via  Multi-sensor Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+S">Siyu Teng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuemin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Y">Yunfeng Ai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07170" title="Abstract">arXiv:2308.07170</a> (replaced) [<a href="/pdf/2308.07170" title="Download PDF">pdf</a>, <a href="/format/2308.07170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Voice Pitch Estimation: A Convolutional Network with Auto-Labeled  and Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cochoy%2C+J">Jeremy Cochoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07728" title="Abstract">arXiv:2308.07728</a> (replaced) [<a href="/pdf/2308.07728" title="Download PDF">pdf</a>, <a href="/format/2308.07728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Seokhyeon Ha</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sunbeom Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungwoo Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08536" title="Abstract">arXiv:2308.08536</a> (replaced) [<a href="/pdf/2308.08536" title="Download PDF">pdf</a>, <a href="/format/2308.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Transformers Learn Optimal Filtering for Unknown Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Balim%2C+H">Haldun Balim</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+Z">Zhe Du</a>, 
<a href="/search/eess?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/eess?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08796" title="Abstract">arXiv:2308.08796</a> (replaced) [<a href="/pdf/2308.08796" title="Download PDF">pdf</a>, <a href="/format/2308.08796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinese Spelling Correction as Rephrasing Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongqiu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08989" title="Abstract">arXiv:2308.08989</a> (replaced) [<a href="/pdf/2308.08989" title="Download PDF">pdf</a>, <a href="/format/2308.08989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural oscillators for generalization of physics-informed machine  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+T">Taniya Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+A">Abhishek Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+D+M">Daniel M. Tartakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nunez%2C+A">Alfredo Nunez</a>, 
<a href="/search/cs?searchtype=author&query=Dollevoet%2C+R">Rolf Dollevoet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09430" title="Abstract">arXiv:2308.09430</a> (replaced) [<a href="/pdf/2308.09430" title="Download PDF">pdf</a>, <a href="/format/2308.09430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding the Generalizability of Delayed Stochastic  Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaoge Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09437" title="Abstract">arXiv:2308.09437</a> (replaced) [<a href="/pdf/2308.09437" title="Download PDF">pdf</a>, <a href="/format/2308.09437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Hope to Safety: Unlearning Biases of Deep Models via Gradient  Penalization in Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreyer%2C+M">Maximilian Dreyer</a>, 
<a href="/search/cs?searchtype=author&query=Pahde%2C+F">Frederik Pahde</a>, 
<a href="/search/cs?searchtype=author&query=Anders%2C+C+J">Christopher J. Anders</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages (9 pages manuscript, 2 pages references, 24 pages appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09616" title="Abstract">arXiv:2308.09616</a> (replaced) [<a href="/pdf/2308.09616" title="Download PDF">pdf</a>, <a href="/format/2308.09616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Far3D: Expanding the Horizon for Surround-view 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaohui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuailin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lijin Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09720" title="Abstract">arXiv:2308.09720</a> (replaced) [<a href="/pdf/2308.09720" title="Download PDF">pdf</a>, <a href="/ps/2308.09720" title="Download PostScript">ps</a>, <a href="/format/2308.09720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Unexpected Abilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nolfi%2C+S">Stefano Nolfi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09936" title="Abstract">arXiv:2308.09936</a> (replaced) [<a href="/pdf/2308.09936" title="Download PDF">pdf</a>, <a href="/format/2308.09936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10144" title="Abstract">arXiv:2308.10144</a> (replaced) [<a href="/pdf/2308.10144" title="Download PDF">pdf</a>, <a href="/format/2308.10144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExpeL: LLM Agents Are Experiential Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Andrew Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Daniel Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Quentin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Matthieu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10439" title="Abstract">arXiv:2308.10439</a> (replaced) [<a href="/pdf/2308.10439" title="Download PDF">pdf</a>, <a href="/format/2308.10439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Approximation of Singular Functions by Series of Non-integer  Powers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+M">Mohan Zhao</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10852" title="Abstract">arXiv:2308.10852</a> (replaced) [<a href="/pdf/2308.10852" title="Download PDF">pdf</a>, <a href="/format/2308.10852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty benchmarks for time-dependent transport problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+W">William Bennett</a>, 
<a href="/search/cs?searchtype=author&query=McClarren%2C+R+G">Ryan G. McClarren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10997" title="Abstract">arXiv:2308.10997</a> (replaced) [<a href="/pdf/2308.10997" title="Download PDF">pdf</a>, <a href="/format/2308.10997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MarkovGen: Structured Prediction for Efficient Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayasumana%2C+S">Sadeep Jayasumana</a>, 
<a href="/search/cs?searchtype=author&query=Glasner%2C+D">Daniel Glasner</a>, 
<a href="/search/cs?searchtype=author&query=Ramalingam%2C+S">Srikumar Ramalingam</a>, 
<a href="/search/cs?searchtype=author&query=Veit%2C+A">Andreas Veit</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+A">Ayan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11730" title="Abstract">arXiv:2308.11730</a> (replaced) [<a href="/pdf/2308.11730" title="Download PDF">pdf</a>, <a href="/format/2308.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Prompting for Multi-Document Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R+A">Ryan A. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A">Alexa Siu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11875" title="Abstract">arXiv:2308.11875</a> (replaced) [<a href="/pdf/2308.11875" title="Download PDF">pdf</a>, <a href="/format/2308.11875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-to-Matching: A Mixed Paradigm for 3D Single Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yubo Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE Robotics and Automation Letters (RAL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11940" title="Abstract">arXiv:2308.11940</a> (replaced) [<a href="/pdf/2308.11940" title="Download PDF">pdf</a>, <a href="/format/2308.11940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Generation with Multiple Conditional Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhifang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jianguo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Rui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ouchi%2C+K">Kazushige Ouchi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11978" title="Abstract">arXiv:2308.11978</a> (replaced) [<a href="/pdf/2308.11978" title="Download PDF">pdf</a>, <a href="/format/2308.11978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Will More Expressive Graph Neural Networks do Better on Generative  Tasks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xiandong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12558" title="Abstract">arXiv:2308.12558</a> (replaced) [<a href="/pdf/2308.12558" title="Download PDF">pdf</a>, <a href="/format/2308.12558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperbolic Audio-visual Zero-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Hayder%2C+Z">Zeeshan Hayder</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junlin Han</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+P">Pengfei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13177" title="Abstract">arXiv:2308.13177</a> (replaced) [<a href="/pdf/2308.13177" title="Download PDF">pdf</a>, <a href="/format/2308.13177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Evaluate the Generalization of Detection? A Benchmark for  Comprehensive Open-Vocabulary Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yiyang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiancheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jiajia Liao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunxin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyusong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long paper accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13250" title="Abstract">arXiv:2308.13250</a> (replaced) [<a href="/pdf/2308.13250" title="Download PDF">pdf</a>, <a href="/format/2308.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TC-LIF: A Two-Compartment Spiking Neuron Model for Long-term Sequential  Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shimin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jibin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.07231">arXiv:2307.07231</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13616" title="Abstract">arXiv:2308.13616</a> (replaced) [<a href="/pdf/2308.13616" title="Download PDF">pdf</a>, <a href="/format/2308.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation in RIS-Enabled mmWave Wireless Systems: A Variational  Inference Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fredj%2C+F">Firas Fredj</a>, 
<a href="/search/eess?searchtype=author&query=Feriani%2C+A">Amal Feriani</a>, 
<a href="/search/eess?searchtype=author&query=Mezghani%2C+A">Amine Mezghani</a>, 
<a href="/search/eess?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13838" title="Abstract">arXiv:2308.13838</a> (replaced) [<a href="/pdf/2308.13838" title="Download PDF">pdf</a>, <a href="/format/2308.13838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Price-Discrimination Game for Distributed Resource Management in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Halvin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guopeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14277" title="Abstract">arXiv:2308.14277</a> (replaced) [<a href="/pdf/2308.14277" title="Download PDF">pdf</a>, <a href="/format/2308.14277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 9DTact: A Compact Vision-Based Tactile Sensor for Accurate 3D Shape  Reconstruction and Generalizable 6D Force Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Changyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jikai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://linchangyi1.github.io/9DTact/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14604" title="Abstract">arXiv:2308.14604</a> (replaced) [<a href="/pdf/2308.14604" title="Download PDF">pdf</a>, <a href="/format/2308.14604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-PARSER: Fine-tuning SAM Efficiently by Parameter Space  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zelin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhilin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15787" title="Abstract">arXiv:2308.15787</a> (replaced) [<a href="/pdf/2308.15787" title="Download PDF">pdf</a>, <a href="/format/2308.15787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does post-quantum cryptography affect Central Bank Digital Currency?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hupel%2C+L">Lars Hupel</a>, 
<a href="/search/cs?searchtype=author&query=Rafiee%2C+M">Makan Rafiee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version with an additional section on the new attack model posed by quantum computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00424" title="Abstract">arXiv:2309.00424</a> (replaced) [<a href="/pdf/2309.00424" title="Download PDF">pdf</a>, <a href="/format/2309.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Speech Representation From Contrastive Token-Acoustic  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yixin Tian</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00872" title="Abstract">arXiv:2309.00872</a> (replaced) [<a href="/pdf/2309.00872" title="Download PDF">pdf</a>, <a href="/format/2309.00872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer  for Exposure Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gehui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00913" title="Abstract">arXiv:2309.00913</a> (replaced) [<a href="/pdf/2309.00913" title="Download PDF">pdf</a>, <a href="/ps/2309.00913" title="Download PostScript">ps</a>, <a href="/format/2309.00913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced spike sorting approaches in implantable VLSI wireless brain  computer interfaces: a survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soujatya Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01574" title="Abstract">arXiv:2309.01574</a> (replaced) [<a href="/pdf/2309.01574" title="Download PDF">pdf</a>, <a href="/format/2309.01574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Size-Driven Design of Convolutional Neural Networks: Virtual Axle  Detection based on Raw Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riedel%2C+H">Henik Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzen%2C+R+S">Robert Steven Lorenzen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCbler%2C+C">Clemens H&#xfc;bler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02270" title="Abstract">arXiv:2309.02270</a> (replaced) [<a href="/pdf/2309.02270" title="Download PDF">pdf</a>, <a href="/format/2309.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-Deblur: Let Segment Anything Boost Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yating Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zifei Dou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02668" title="Abstract">arXiv:2309.02668</a> (replaced) [<a href="/pdf/2309.02668" title="Download PDF">pdf</a>, <a href="/format/2309.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks for Fast Optimisation in Model Predictive Control: A  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gonzalez%2C+C">Camilo Gonzalez</a> (1), 
<a href="/search/eess?searchtype=author&query=Asadi%2C+H">Houshyar Asadi</a> (1), 
<a href="/search/eess?searchtype=author&query=Kooijman%2C+L">Lars Kooijman</a> (1), 
<a href="/search/eess?searchtype=author&query=Lim%2C+C+P">Chee Peng Lim</a> (1) ((1) Institute for Intelligent Systems Research and Innovation, Waurn Ponds, Australia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 6 figures 3 tables. Submitted to Annual Reviews in Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04788" title="Abstract">arXiv:2309.04788</a> (replaced) [<a href="/pdf/2309.04788" title="Download PDF">pdf</a>, <a href="/format/2309.04788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Descent outperforms Gradient Descent in recovering a  high-dimensional signal in a glassy energy landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamali%2C+P+J">Persia Jana Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Urbani%2C+P">Pierfrancesco Urbani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages + appendix. 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05109" title="Abstract">arXiv:2309.05109</a> (replaced) [<a href="/e-print/2309.05109" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Aided Subspace-Based DOA Recovery for Sparse Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amiel%2C+Y">Yoav Amiel</a>, 
<a href="/search/eess?searchtype=author&query=Shmuel%2C+D+H">Dor H. Shmuel</a>, 
<a href="/search/eess?searchtype=author&query=Shlezinger%2C+N">Nir Shlezinger</a>, 
<a href="/search/eess?searchtype=author&query=Huleihel%2C+W">Wasim Huleihel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project is still under work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05173" title="Abstract">arXiv:2309.05173</a> (replaced) [<a href="/pdf/2309.05173" title="Download PDF">pdf</a>, <a href="/format/2309.05173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lipani%2C+A">Aldo Lipani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/ZhengxiangShi/DePT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05379" title="Abstract">arXiv:2309.05379</a> (replaced) [<a href="/pdf/2309.05379" title="Download PDF">pdf</a>, <a href="/ps/2309.05379" title="Download PostScript">ps</a>, <a href="/format/2309.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Truthful Constrained Heterogeneous Facility Location with Max-Variant  Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+M">Mohammad Lotfi</a>, 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+A+A">Alexandros A. Voudouris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06023" title="Abstract">arXiv:2309.06023</a> (replaced) [<a href="/pdf/2309.06023" title="Download PDF">pdf</a>, <a href="/format/2309.06023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from History: Task-agnostic Model Contrastive Learning for  Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06618" title="Abstract">arXiv:2309.06618</a> (replaced) [<a href="/pdf/2309.06618" title="Download PDF">pdf</a>, <a href="/format/2309.06618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional Fusion and Consistency for Semi-supervised Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yixing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 30th International Conference on MultiMedia Modeling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06810" title="Abstract">arXiv:2309.06810</a> (replaced) [<a href="/pdf/2309.06810" title="Download PDF">pdf</a>, <a href="/format/2309.06810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruihai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tie%2C+C">Chenrui Tie</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yushi Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://crtie.github.io/SE-3-part-assembly/">this https URL</a> , Code: <a href="https://github.com/crtie/Leveraging-SE-3-Equivariance-for-Learning-3D-Geometric-Shape-Assembly">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06933" title="Abstract">arXiv:2309.06933</a> (replaced) [<a href="/pdf/2309.06933" title="Download PDF">pdf</a>, <a href="/format/2309.06933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+N">Namhyuk Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chunggi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kunhee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daesik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seung-Hun Nam</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kibeom Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06961" title="Abstract">arXiv:2309.06961</a> (replaced) [<a href="/pdf/2309.06961" title="Download PDF">pdf</a>, <a href="/format/2309.06961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable Dermatology Evaluation Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6ger%2C+F">Fabian Gr&#xf6;ger</a>, 
<a href="/search/cs?searchtype=author&query=Lionetti%2C+S">Simone Lionetti</a>, 
<a href="/search/cs?searchtype=author&query=Gottfrois%2C+P">Philippe Gottfrois</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Jimenez%2C+A">Alvaro Gonzalez-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Groh%2C+M">Matthew Groh</a>, 
<a href="/search/cs?searchtype=author&query=Daneshjou%2C+R">Roxana Daneshjou</a>, 
<a href="/search/cs?searchtype=author&query=Consortium%2C+L">Labelling Consortium</a>, 
<a href="/search/cs?searchtype=author&query=Navarini%2C+A+A">Alexander A. Navarini</a>, 
<a href="/search/cs?searchtype=author&query=Pouly%2C+M">Marc Pouly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Link to the revised file lists: <a href="https://github.com/Digital-Dermatology/SelfClean-Revised-Benchmarks">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 3rd Machine Learning for Health Symposium, PMLR
  225:101-128, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07498" title="Abstract">arXiv:2309.07498</a> (replaced) [<a href="/pdf/2309.07498" title="Download PDF">pdf</a>, <a href="/format/2309.07498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Metadata Information Constrained Self-Supervised Learning  for Anomalous Sound Detection Under Domain Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lan%2C+H">Haiyan Lan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Q">Qiaoxi Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+J">Jian Guan</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Y">Yuming Wei</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07996" title="Abstract">arXiv:2309.07996</a> (replaced) [<a href="/pdf/2309.07996" title="Download PDF">pdf</a>, <a href="/format/2309.07996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient online update of model predictive control in embedded systems  using first-order methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gracia%2C+V">Victor Gracia</a>, 
<a href="/search/eess?searchtype=author&query=Krupa%2C+P">Pablo Krupa</a>, 
<a href="/search/eess?searchtype=author&query=Alamo%2C+T">Teodoro Alamo</a>, 
<a href="/search/eess?searchtype=author&query=Limon%2C+D">Daniel Limon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (6 pages, 2 figures)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Control Systems Letters, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08778" title="Abstract">arXiv:2309.08778</a> (replaced) [<a href="/pdf/2309.08778" title="Download PDF">pdf</a>, <a href="/format/2309.08778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satisfiability.jl: Satisfiability Modulo Theories in Julia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soroka%2C+E">Emiko Soroka</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+S">Sanjay Lall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, revised from a previous longer version to comply with a conference length requirement. Submitted to NASA Formal Methods 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09088" title="Abstract">arXiv:2309.09088</a> (replaced) [<a href="/pdf/2309.09088" title="Download PDF">pdf</a>, <a href="/format/2309.09088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing GAN-Based Vocoders with Contrastive Learning Under  Data-limited Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haoming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S+Z">Seth Z. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jiachen Lian</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G">Gopala Anumanchipalli</a>, 
<a href="/search/cs?searchtype=author&query=Friedland%2C+G">Gerald Friedland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09435" title="Abstract">arXiv:2309.09435</a> (replaced) [<a href="/pdf/2309.09435" title="Download PDF">pdf</a>, <a href="/format/2309.09435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy on Generative Data in AIGC: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Shuren Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhihua Xia</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jian Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09907" title="Abstract">arXiv:2309.09907</a> (replaced) [<a href="/pdf/2309.09907" title="Download PDF">pdf</a>, <a href="/format/2309.09907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Vision Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nguyen%2C+X+B">Xuan Bac Nguyen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Churchill%2C+H">Hugh Churchill</a>, 
<a href="/search/quant-ph?searchtype=author&query=Luu%2C+K">Khoa Luu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khan%2C+S+U">Samee U. Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.08837">arXiv:2202.08837</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10639" title="Abstract">arXiv:2309.10639</a> (replaced) [<a href="/pdf/2309.10639" title="Download PDF">pdf</a>, <a href="/ps/2309.10639" title="Download PostScript">ps</a>, <a href="/format/2309.10639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric structure of Deep Learning networks and construction of global  ${\mathcal L}^2$ minimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Thomas Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ewald%2C+P+M">Patricia Mu&#xf1;oz Ewald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMS Latex, 21 pages. Typos corrected, slightly extended
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11082" title="Abstract">arXiv:2309.11082</a> (replaced) [<a href="/pdf/2309.11082" title="Download PDF">pdf</a>, <a href="/format/2309.11082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial  Margin Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuzheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11343" title="Abstract">arXiv:2309.11343</a> (replaced) [<a href="/pdf/2309.11343" title="Download PDF">pdf</a>, <a href="/format/2309.11343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Property Elicitation to Understand the Impacts of Fairness  Regularizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finocchiaro%2C+J">Jessie Finocchiaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Please reach out if you have comments or thoughts; this is a living project. New version changing the proof of Theorem 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12458" title="Abstract">arXiv:2309.12458</a> (replaced) [<a href="/pdf/2309.12458" title="Download PDF">pdf</a>, <a href="/ps/2309.12458" title="Download PostScript">ps</a>, <a href="/format/2309.12458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhou Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added reference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13690" title="Abstract">arXiv:2309.13690</a> (replaced) [<a href="/pdf/2309.13690" title="Download PDF">pdf</a>, <a href="/format/2309.13690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable data concentrator with baseline interconnection network for  triggerless data acquisition systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zabo%C5%82otny%2C+W+M">Wojciech M. Zabo&#x142;otny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13782" title="Abstract">arXiv:2309.13782</a> (replaced) [<a href="/pdf/2309.13782" title="Download PDF">pdf</a>, <a href="/ps/2309.13782" title="Download PostScript">ps</a>, <a href="/format/2309.13782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Benefit of Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhou Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ALT 2024, to appear
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14950" title="Abstract">arXiv:2309.14950</a> (replaced) [<a href="/pdf/2309.14950" title="Download PDF">pdf</a>, <a href="/format/2309.14950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Source Domain Adaptation for Object Detection with Prototype-based  Mean-teacher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belal%2C+A">Atif Belal</a>, 
<a href="/search/cs?searchtype=author&query=Meethal%2C+A">Akhil Meethal</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+F+P">Francisco Perdigon Romero</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15293" title="Abstract">arXiv:2309.15293</a> (replaced) [<a href="/pdf/2309.15293" title="Download PDF">pdf</a>, <a href="/format/2309.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum diffusion reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrueta%2C+T+A">Thomas A. Berrueta</a>, 
<a href="/search/cs?searchtype=author&query=Pinosky%2C+A">Allison Pinosky</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T+D">Todd D. Murphey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The PDF file contains the collated main text and supplementary information. For supplementary movies, see <a href="https://www.youtube.com/playlist?list=PLO5AGPa3klrCTSO-t7HZsVNQinHXFQmn9">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15512" title="Abstract">arXiv:2309.15512</a> (replaced) [<a href="/pdf/2309.15512" title="Download PDF">pdf</a>, <a href="/format/2309.15512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Speech Synthesis with Minimal Supervision: All Using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yixin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024. arXiv admin note: substantial text overlap with <a href="/abs/2307.15484">arXiv:2307.15484</a>; text overlap with <a href="/abs/2309.00424">arXiv:2309.00424</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16899" title="Abstract">arXiv:2309.16899</a> (replaced) [<a href="/pdf/2309.16899" title="Download PDF">pdf</a>, <a href="/format/2309.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Contractivity of Plug-and-Play Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athalye%2C+C+D">Chirayu D. Athalye</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhury%2C+K+N">Kunal N. Chaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhartendu Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Errors in the proof of Lemma 1 and the statement of Theorem 2 were identified after the publication; these have been rectified in the revised version (v2)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Signal Processing Letters, vol. 30, pp. 1447-1451, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17176" title="Abstract">arXiv:2309.17176</a> (replaced) [<a href="/pdf/2309.17176" title="Download PDF">pdf</a>, <a href="/format/2309.17176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00681" title="Abstract">arXiv:2310.00681</a> (replaced) [<a href="/pdf/2310.00681" title="Download PDF">pdf</a>, <a href="/format/2310.00681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PharmacoNet: Accelerating Large-Scale Virtual Screening by Deep  Pharmacophore Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Seo%2C+S">Seonghwan Seo</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+W+Y">Woo Youn Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery
  and Development
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01910" title="Abstract">arXiv:2310.01910</a> (replaced) [<a href="/pdf/2310.01910" title="Download PDF">pdf</a>, <a href="/format/2310.01910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional independence on semiring relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hannula%2C+M">Miika Hannula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01998" title="Abstract">arXiv:2310.01998</a> (replaced) [<a href="/pdf/2310.01998" title="Download PDF">pdf</a>, <a href="/ps/2310.01998" title="Download PostScript">ps</a>, <a href="/format/2310.01998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Formalization of Complete Discrete Valuation Rings and Local Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Frutos-Fern%C3%A1ndez%2C+M+I">Mar&#xed;a In&#xe9;s de Frutos-Fern&#xe1;ndez</a> (UAM), 
<a href="/search/cs?searchtype=author&query=Di+Capriglio%2C+F+A+E+N+M+M">Filippo Alberto Edoardo Nuccio Mortarino Majno Di Capriglio</a> (CTN, ICJ)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13th ACM SIGPLAN International Conference on Certified Programs and Proofs (CPP '24), Jan 2024, London, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02123" title="Abstract">arXiv:2310.02123</a> (replaced) [<a href="/pdf/2310.02123" title="Download PDF">pdf</a>, <a href="/format/2310.02123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric re-meshing strategies to simulate contactless rebounds of  elastic solids in fluids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fara%2C+J">J. Fara</a>, 
<a href="/search/math?searchtype=author&query=Schwarzacher%2C+S">S. Schwarzacher</a>, 
<a href="/search/math?searchtype=author&query=T%C5%AFma%2C+K">K. T&#x16f;ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02161" title="Abstract">arXiv:2310.02161</a> (replaced) [<a href="/pdf/2310.02161" title="Download PDF">pdf</a>, <a href="/format/2310.02161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews  Elicited from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M+X">Michael Xieyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F+M">Franklin Mingzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Kittur%2C+A">Aniket Kittur</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+B+A">Brad A. Myers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02601" title="Abstract">arXiv:2310.02601</a> (replaced) [<a href="/pdf/2310.02601" title="Download PDF">pdf</a>, <a href="/format/2310.02601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicDrive: Street View Generation with Diverse 3D Geometry Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://flymin.github.io/magicdrive">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03018" title="Abstract">arXiv:2310.03018</a> (replaced) [<a href="/pdf/2310.03018" title="Download PDF">pdf</a>, <a href="/format/2310.03018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Resource Code-switched Speech Benchmark Using Speech Utterance  Pairs For Multiple Spoken Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kuan-Po Huang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chih-Kai Yang</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+Y">Yu-Kuan Fu</a>, 
<a href="/search/eess?searchtype=author&query=Dunbar%2C+E">Ewan Dunbar</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024 (v2)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03059" title="Abstract">arXiv:2310.03059</a> (replaced) [<a href="/pdf/2310.03059" title="Download PDF">pdf</a>, <a href="/format/2310.03059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yiwen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianzheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. The specialized PEFT framework for 3D pre-trained models, which achieves competitive performance to full fine-tuning, and significantly reduces the computational resources. Project page: <a href="https://github.com/Ivan-Tang-3D/PEFT-3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04314" title="Abstract">arXiv:2310.04314</a> (replaced) [<a href="/pdf/2310.04314" title="Download PDF">pdf</a>, <a href="/format/2310.04314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Inference with Limited Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianglin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yue Bai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yun Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04469" title="Abstract">arXiv:2310.04469</a> (replaced) [<a href="/pdf/2310.04469" title="Download PDF">pdf</a>, <a href="/format/2310.04469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Binarized Neural Networks and Mixed-Integer Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aspman%2C+J">Johannes Aspman</a>, 
<a href="/search/cs?searchtype=author&query=Korpas%2C+G">Georgios Korpas</a>, 
<a href="/search/cs?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04796" title="Abstract">arXiv:2310.04796</a> (replaced) [<a href="/pdf/2310.04796" title="Download PDF">pdf</a>, <a href="/format/2310.04796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerate Multi-Agent Reinforcement Learning in Zero-Sum Games with  Subgame Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zelai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05161" title="Abstract">arXiv:2310.05161</a> (replaced) [<a href="/pdf/2310.05161" title="Download PDF">pdf</a>, <a href="/format/2310.05161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Representing Finite-state Automata With Recurrent Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svete%2C+A">Anej Svete</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05292" title="Abstract">arXiv:2310.05292</a> (replaced) [<a href="/pdf/2310.05292" title="Download PDF">pdf</a>, <a href="/format/2310.05292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HypoCompass: Large-Language-Model-based Tutor for Hypothesis  Construction in Debugging for Novices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Koedinger%2C+K">Kenneth Koedinger</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05524" title="Abstract">arXiv:2310.05524</a> (replaced) [<a href="/pdf/2310.05524" title="Download PDF">pdf</a>, <a href="/format/2310.05524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterization-driven Neural Implicit Surfaces Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiangbei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+F">Fei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kwan-Yee Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07047" title="Abstract">arXiv:2310.07047</a> (replaced) [<a href="/pdf/2310.07047" title="Download PDF">pdf</a>, <a href="/format/2310.07047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A predict-and-optimize approach to profit-driven churn prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Vargas%2C+N">Nuria G&#xf3;mez-Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+S">Sebasti&#xe1;n Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Vairetti%2C+C">Carla Vairetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, submitted to INFORMATION SCIENCES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07521" title="Abstract">arXiv:2310.07521</a> (replaced) [<a href="/pdf/2310.07521" title="Download PDF">pdf</a>, <a href="/format/2310.07521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Factuality in Large Language Models: Knowledge, Retrieval and  Domain-Specificity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yuanhao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiayang%2C+C">Cheng Jiayang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wenyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zehan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages; 300+ references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08864" title="Abstract">arXiv:2310.08864</a> (replaced) [<a href="/pdf/2310.08864" title="Download PDF">pdf</a>, <a href="/format/2310.08864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open X-Embodiment: Robotic Learning Datasets and RT-X Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Open+X-Embodiment+Collaboration">Open X-Embodiment Collaboration</a>, 
<a href="/search/cs?searchtype=author&query=Padalkar%2C+A">Abhishek Padalkar</a>, 
<a href="/search/cs?searchtype=author&query=Pooley%2C+A">Acorn Pooley</a>, 
<a href="/search/cs?searchtype=author&query=Mandlekar%2C+A">Ajay Mandlekar</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ajinkya Jain</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+A">Albert Tung</a>, 
<a href="/search/cs?searchtype=author&query=Bewley%2C+A">Alex Bewley</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+A">Alex Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Khazatsky%2C+A">Alexander Khazatsky</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anant Rai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anikait Singh</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Brohan%2C+A">Anthony Brohan</a>, 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Wahid%2C+A">Ayzaan Wahid</a>, 
<a href="/search/cs?searchtype=author&query=Burgess-Limerick%2C+B">Ben Burgess-Limerick</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomjoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenguang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Christine Chan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chuer Pan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Devin%2C+C">Coline Devin</a>, 
<a href="/search/cs?searchtype=author&query=Driess%2C+D">Danny Driess</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>, 
<a href="/search/cs?searchtype=author&query=Kalashnikov%2C+D">Dmitry Kalashnikov</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>, 
<a href="/search/cs?searchtype=author&query=Ceola%2C+F">Federico Ceola</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gaoyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>, 
<a href="/search/cs?searchtype=author&query=Salhotra%2C+G">Gautam Salhotra</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Ge Yan</a>, 
<a href="/search/cs?searchtype=author&query=Schiavi%2C+G">Giulio Schiavi</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+G">Gregory Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao-Shu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+H">Hiroki Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Walke%2C+H">Homer Walke</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hongjie Fang</a>,  et al. (129 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10059" title="Abstract">arXiv:2310.10059</a> (replaced) [<a href="/pdf/2310.10059" title="Download PDF">pdf</a>, <a href="/format/2310.10059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow Dynamics Correction for Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Koniusz%2C+P">Piotr Koniusz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10505" title="Abstract">arXiv:2310.10505</a> (replaced) [<a href="/pdf/2310.10505" title="Download PDF">pdf</a>, <a href="/format/2310.10505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method  for Aligning Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziniu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhihang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10526" title="Abstract">arXiv:2310.10526</a> (replaced) [<a href="/pdf/2310.10526" title="Download PDF">pdf</a>, <a href="/format/2310.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A spectrally accurate step-by-step method for the numerical solution of  fractional differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brugnano%2C+L">L. Brugnano</a>, 
<a href="/search/math?searchtype=author&query=Burrage%2C+K">K. Burrage</a>, 
<a href="/search/math?searchtype=author&query=Burrage%2C+P">P. Burrage</a>, 
<a href="/search/math?searchtype=author&query=Iavernaro%2C+F">F. Iavernaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures, 7 tables, a few typos fixed in the updated version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10605" title="Abstract">arXiv:2310.10605</a> (replaced) [<a href="/pdf/2310.10605" title="Download PDF">pdf</a>, <a href="/ps/2310.10605" title="Download PostScript">ps</a>, <a href="/format/2310.10605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ForceGen: End-to-end de novo protein generation based on nonlinear  mechanical unfolding responses using a protein language diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ni%2C+B">Bo Ni</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kaplan%2C+D+L">David L. Kaplan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Buehler%2C+M+J">Markus J. Buehler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Computation and Language (cs.CL); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10790" title="Abstract">arXiv:2310.10790</a> (replaced) [<a href="/pdf/2310.10790" title="Download PDF">pdf</a>, <a href="/ps/2310.10790" title="Download PostScript">ps</a>, <a href="/format/2310.10790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Place Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhaoqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Etienne-Cummings%2C+R">Ralph Etienne-Cummings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, draft for Journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10912" title="Abstract">arXiv:2310.10912</a> (replaced) [<a href="/pdf/2310.10912" title="Download PDF">pdf</a>, <a href="/format/2310.10912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Training-free Open-world Segmentation via Image Prompt  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lv Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng-Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hao-Ke Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11099" title="Abstract">arXiv:2310.11099</a> (replaced) [<a href="/pdf/2310.11099" title="Download PDF">pdf</a>, <a href="/format/2310.11099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Local Patterns of Child Pornography Consumption in France  using Tor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koebe%2C+T">Till Koebe</a>, 
<a href="/search/cs?searchtype=author&query=del+Villar%2C+Z">Zinnya del Villar</a>, 
<a href="/search/cs?searchtype=author&query=Nutakki%2C+B">Brahmani Nutakki</a>, 
<a href="/search/cs?searchtype=author&query=Sagimbayeva%2C+N">Nursulu Sagimbayeva</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingmar Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the first version of the arXiv preprint of this paper, we reported this share to be 16.9 %. This was based on a misinterpretation of the Tor statistics. After expert discussions, we corrected it and any subsequent analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11374" title="Abstract">arXiv:2310.11374</a> (replaced) [<a href="/pdf/2310.11374" title="Download PDF">pdf</a>, <a href="/format/2310.11374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models  for Emotion Recognition in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yazhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P">Prayag Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiuchi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12439" title="Abstract">arXiv:2310.12439</a> (replaced) [<a href="/pdf/2310.12439" title="Download PDF">pdf</a>, <a href="/format/2310.12439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongwei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in IEEE ICASSP 2024, code is available at: <a href="https://github.com/grasses/PoisonPrompt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12763" title="Abstract">arXiv:2310.12763</a> (replaced) [<a href="/pdf/2310.12763" title="Download PDF">pdf</a>, <a href="/ps/2310.12763" title="Download PostScript">ps</a>, <a href="/format/2310.12763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liveness Properties in Geometric Logic for Domain-Theoretic Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riba%2C+C">Colin Riba</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+S">Solal Stern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13356" title="Abstract">arXiv:2310.13356</a> (replaced) [<a href="/pdf/2310.13356" title="Download PDF">pdf</a>, <a href="/format/2310.13356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seoha Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Jeongmin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+Y">Youngsik Yun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hahyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+G">Gun Bang</a>, 
<a href="/search/cs?searchtype=author&query=Uh%2C+Y">Youngjung Uh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, Project page: <a href="https://seoha-kim.github.io/sync-nerf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13916" title="Abstract">arXiv:2310.13916</a> (replaced) [<a href="/pdf/2310.13916" title="Download PDF">pdf</a>, <a href="/format/2310.13916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Southern Ocean Dynamics Under Climate Change: New Knowledge Through  Physics-Guided Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yik%2C+W">William Yik</a>, 
<a href="/search/physics?searchtype=author&query=Sonnewald%2C+M">Maike Sonnewald</a>, 
<a href="/search/physics?searchtype=author&query=Clare%2C+M+C+A">Mariana C. A. Clare</a>, 
<a href="/search/physics?searchtype=author&query=Lguensat%2C+R">Redouane Lguensat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14778" title="Abstract">arXiv:2310.14778</a> (replaced) [<a href="/pdf/2310.14778" title="Download PDF">pdf</a>, <a href="/format/2310.14778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Speaker Tracking: Progress, Challenges, and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinzheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xinyuan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Berghi%2C+D">Davide Berghi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peipei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Meng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+P+J+B">Philip J.B. Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14805" title="Abstract">arXiv:2310.14805</a> (replaced) [<a href="/pdf/2310.14805" title="Download PDF">pdf</a>, <a href="/format/2310.14805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Conceptualization in Bottleneck Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alukaev%2C+D">Danis Alukaev</a>, 
<a href="/search/cs?searchtype=author&query=Kiselev%2C+S">Semen Kiselev</a>, 
<a href="/search/cs?searchtype=author&query=Pershin%2C+I">Ilya Pershin</a>, 
<a href="/search/cs?searchtype=author&query=Ibragimov%2C+B">Bulat Ibragimov</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+V">Vladimir Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Kornaev%2C+A">Alexey Kornaev</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+I">Ivan Titov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023; camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14845" title="Abstract">arXiv:2310.14845</a> (replaced) [<a href="/pdf/2310.14845" title="Download PDF">pdf</a>, <a href="/format/2310.14845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ULTRA-DP: Unifying Graph Pre-training with Multi-task Graph Dual Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mouxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiheng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianling Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15318" title="Abstract">arXiv:2310.15318</a> (replaced) [<a href="/pdf/2310.15318" title="Download PDF">pdf</a>, <a href="/format/2310.15318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained  Heterogeneous Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yihong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+N">Ning Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+M">Masood Mortazavi</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ACM TheWebConf 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15566" title="Abstract">arXiv:2310.15566</a> (replaced) [<a href="/pdf/2310.15566" title="Download PDF">pdf</a>, <a href="/format/2310.15566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surface-Based Receive Generalized Spatial  Modulation Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xinghao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hanjiang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi-yan Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dazhi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15646" title="Abstract">arXiv:2310.15646</a> (replaced) [<a href="/pdf/2310.15646" title="Download PDF">pdf</a>, <a href="/format/2310.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Teacher DETR with Masked Feature Alignment: A Robust Domain  Adaptive Detection Transformer Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Weixi Weng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16407" title="Abstract">arXiv:2310.16407</a> (replaced) [<a href="/pdf/2310.16407" title="Download PDF">pdf</a>, <a href="/format/2310.16407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-Theoretic Generalization Analysis for Topology-aware  Heterogeneous Federated Edge Learning over Noisy Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16485" title="Abstract">arXiv:2310.16485</a> (replaced) [<a href="/pdf/2310.16485" title="Download PDF">pdf</a>, <a href="/format/2310.16485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Python Library for Deep Learning-Based Event Detection  in Multivariate Time Series Data and Information Retrieval in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azib%2C+M">Menouar Azib</a>, 
<a href="/search/cs?searchtype=author&query=Renard%2C+B">Benjamin Renard</a>, 
<a href="/search/cs?searchtype=author&query=Garnier%2C+P">Philippe Garnier</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A9not%2C+V">Vincent G&#xe9;not</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+N">Nicolas Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 International Conference on Machine Learning and Applications (ICMLA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16675" title="Abstract">arXiv:2310.16675</a> (replaced) [<a href="/pdf/2310.16675" title="Download PDF">pdf</a>, <a href="/format/2310.16675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agreeing to Stop: Reliable Latency-Adaptive Decision Making via  Ensembles of Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiechen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangwoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16741" title="Abstract">arXiv:2310.16741</a> (replaced) [<a href="/pdf/2310.16741" title="Download PDF">pdf</a>, <a href="/format/2310.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Latent Transformer: Efficient Modelling of Stochastically  Forced Zonal Jets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shokar%2C+I+J+S">Ira J. S. Shokar</a>, 
<a href="/search/cs?searchtype=author&query=Kerswell%2C+R+R">Rich R. Kerswell</a>, 
<a href="/search/cs?searchtype=author&query=Haynes%2C+P+H">Peter H. Haynes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17333" title="Abstract">arXiv:2310.17333</a> (replaced) [<a href="/pdf/2310.17333" title="Download PDF">pdf</a>, <a href="/format/2310.17333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arabic Fine-Grained Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liqreina%2C+H">Haneen Liqreina</a>, 
<a href="/search/cs?searchtype=author&query=Jarrar%2C+M">Mustafa Jarrar</a>, 
<a href="/search/cs?searchtype=author&query=Khalilia%2C+M">Mohammed Khalilia</a>, 
<a href="/search/cs?searchtype=author&query=El-Shangiti%2C+A+O">Ahmed Oumar El-Shangiti</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17589" title="Abstract">arXiv:2310.17589</a> (replaced) [<a href="/pdf/2310.17589" title="Download PDF">pdf</a>, <a href="/format/2310.17589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open Source Data Contamination Report for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17658" title="Abstract">arXiv:2310.17658</a> (replaced) [<a href="/pdf/2310.17658" title="Download PDF">pdf</a>, <a href="/format/2310.17658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Channel Independent strategy optimal for Time Series Forecasting?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peiwen%2C+Y">Yuan Peiwen</a>, 
<a href="/search/cs?searchtype=author&query=Changsheng%2C+Z">Zhu Changsheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17796" title="Abstract">arXiv:2310.17796</a> (replaced) [<a href="/pdf/2310.17796" title="Download PDF">pdf</a>, <a href="/format/2310.17796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlLLM: Augment Language Models with Tools by Searching on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zeqiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangwei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+E">Erfei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18021" title="Abstract">arXiv:2310.18021</a> (replaced) [<a href="/pdf/2310.18021" title="Download PDF">pdf</a>, <a href="/format/2310.18021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FormalGeo: The First Step Toward Human-like IMO-level Geometric  Automated Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+N">Na Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiming He</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qike Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaoxiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanjun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chenyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+D">Dengfeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangzhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Cheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhenbing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaorong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangfeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+T">Tuo Leng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18532" title="Abstract">arXiv:2310.18532</a> (replaced) [<a href="/pdf/2310.18532" title="Download PDF">pdf</a>, <a href="/format/2310.18532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkipAnalyzer: A Tool for Static Code Analysis with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohajer%2C+M+M">Mohammad Mahdi Mohajer</a>, 
<a href="/search/cs?searchtype=author&query=Aleithan%2C+R">Reem Aleithan</a>, 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Moshi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+V">Hung Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18541" title="Abstract">arXiv:2310.18541</a> (replaced) [<a href="/pdf/2310.18541" title="Download PDF">pdf</a>, <a href="/format/2310.18541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReConTab: Regularized Contrastive Representation Learning for Tabular  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Suiyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Handong Yao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Information Processing Systems (NeurIPS) Workshop, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18651" title="Abstract">arXiv:2310.18651</a> (replaced) [<a href="/pdf/2310.18651" title="Download PDF">pdf</a>, <a href="/ps/2310.18651" title="Download PostScript">ps</a>, <a href="/format/2310.18651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PW-Self: Patch-Wise Self-Supervised Visual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javidani%2C+A">Ali Javidani</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+M+A">Mohammad Amin Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Araabi%2C+B+N">Babak Nadjar Araabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18786" title="Abstract">arXiv:2310.18786</a> (replaced) [<a href="/pdf/2310.18786" title="Download PDF">pdf</a>, <a href="/format/2310.18786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Competitive Algorithm for Agnostic Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Price%2C+E">Eric Price</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yihan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18890" title="Abstract">arXiv:2310.18890</a> (replaced) [<a href="/pdf/2310.18890" title="Download PDF">pdf</a>, <a href="/format/2310.18890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalized Multi-stage Clustering: Multi-view Self-distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiatai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19251" title="Abstract">arXiv:2310.19251</a> (replaced) [<a href="/pdf/2310.19251" title="Download PDF">pdf</a>, <a href="/format/2310.19251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Recommender Systems: A Causal Debiasing Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziqian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N">Nghia Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Kveton%2C+B">Branislav Kveton</a>, 
<a href="/search/cs?searchtype=author&query=Deoras%2C+A">Anoop Deoras</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, WSDM 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19629" title="Abstract">arXiv:2310.19629</a> (replaced) [<a href="/pdf/2310.19629" title="Download PDF">pdf</a>, <a href="/format/2310.19629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoman Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luximon%2C+Y">Yan Luximon</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ajay Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinxi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added the last 3 authors in the camera-ready version. NeurIPS 2023. Code and data are available at: <a href="https://github.com/vLAR-group/RayDF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03167" title="Abstract">arXiv:2311.03167</a> (replaced) [<a href="/pdf/2311.03167" title="Download PDF">pdf</a>, <a href="/format/2311.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Design Optimization of Shared Powertrain Modules in a Family  of Electric Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Clemente%2C+M">Maurizio Clemente</a>, 
<a href="/search/math?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>, 
<a href="/search/math?searchtype=author&query=Hofman%2C+T">Theo Hofman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04498" title="Abstract">arXiv:2311.04498</a> (replaced) [<a href="/pdf/2311.04498" title="Download PDF">pdf</a>, <a href="/format/2311.04498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-Chat: An LMM for Chat, Detection and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report (<a href="https://next-chatv.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04666" title="Abstract">arXiv:2311.04666</a> (replaced) [<a href="/pdf/2311.04666" title="Download PDF">pdf</a>, <a href="/format/2311.04666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training LLMs using human-like development data corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Khushi Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07435" title="Abstract">arXiv:2311.07435</a> (replaced) [<a href="/pdf/2311.07435" title="Download PDF">pdf</a>, <a href="/format/2311.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectories and Platoon-forming Algorithm for Intersections with  Heterogeneous Autonomous Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Joshi%2C+P+C">P. C. Joshi</a>, 
<a href="/search/eess?searchtype=author&query=Boon%2C+M+A+A">M. A. A. Boon</a>, 
<a href="/search/eess?searchtype=author&query=Borst%2C+S+C">S. C. Borst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 16 figures. 3D Animations included as ancillary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07723" title="Abstract">arXiv:2311.07723</a> (replaced) [<a href="/pdf/2311.07723" title="Download PDF">pdf</a>, <a href="/format/2311.07723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Analogies: A Testbed for Generalizing AI Oversight to  Hard-To-Measure Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clymer%2C+J">Joshua Clymer</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+G">Garrett Baker</a>, 
<a href="/search/cs?searchtype=author&query=Subramani%2C+R">Rohan Subramani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sam Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/Joshuaclymer/GENIES">this https URL</a> Website: <a href="https://joshuaclymer.github.io/generalization-analogies-website/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07745" title="Abstract">arXiv:2311.07745</a> (replaced) [<a href="/pdf/2311.07745" title="Download PDF">pdf</a>, <a href="/format/2311.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Complex Observation Models in Continuous POMDP Planning with  Probabilistic Guarantees and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lev-Yehudi%2C+I">Idan Lev-Yehudi</a>, 
<a href="/search/cs?searchtype=author&query=Barenboim%2C+M">Moran Barenboim</a>, 
<a href="/search/cs?searchtype=author&query=Indelman%2C+V">Vadim Indelman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08152" title="Abstract">arXiv:2311.08152</a> (replaced) [<a href="/pdf/2311.08152" title="Download PDF">pdf</a>, <a href="/format/2311.08152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reasoning in Large Language Models via Multi-Agent Peer Review  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Senbao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jindi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuxiang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, 11 tables. Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08189" title="Abstract">arXiv:2311.08189</a> (replaced) [<a href="/pdf/2311.08189" title="Download PDF">pdf</a>, <a href="/format/2311.08189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Data on the Table: Novel Dataset and Benchmark for Cross-Modality  Scientific Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+B+F">B&#xf6;rje F. Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Okumura%2C+M">Manabu Okumura</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Yew Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 17 pages, 6 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08386" title="Abstract">arXiv:2311.08386</a> (replaced) [<a href="/pdf/2311.08386" title="Download PDF">pdf</a>, <a href="/format/2311.08386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity of Summation over a Symmetric Quantum Erasure MAC with  Replicated Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jafar%2C+S+A">Syed A. Jafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08500" title="Abstract">arXiv:2311.08500</a> (replaced) [<a href="/pdf/2311.08500" title="Download PDF">pdf</a>, <a href="/format/2311.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Steering of Gaussian Mixture Models for Discrete-Time Linear  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Balci%2C+I+M">Isin M. Balci</a>, 
<a href="/search/eess?searchtype=author&query=Bakolas%2C+E">Efstathios Bakolas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10522" title="Abstract">arXiv:2311.10522</a> (replaced) [<a href="/pdf/2311.10522" title="Download PDF">pdf</a>, <a href="/format/2311.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Object Coherence in Layout-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10599" title="Abstract">arXiv:2311.10599</a> (replaced) [<a href="/pdf/2311.10599" title="Download PDF">pdf</a>, <a href="/format/2311.10599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chatbots as social companions: How people perceive consciousness, human  likeness, and social health benefits in machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guingrich%2C+R">Rose Guingrich</a>, 
<a href="/search/cs?searchtype=author&query=Graziano%2C+M+S+A">Michael S. A. Graziano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11125" title="Abstract">arXiv:2311.11125</a> (replaced) [<a href="/pdf/2311.11125" title="Download PDF">pdf</a>, <a href="/format/2311.11125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecondPose: SE(3)-Consistent Dual-Stream Feature Fusion for  Category-Level Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yamei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yan Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangyao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Manhardt%2C+F">Fabian Manhardt</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyangguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruida Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11267" title="Abstract">arXiv:2311.11267</a> (replaced) [<a href="/pdf/2311.11267" title="Download PDF">pdf</a>, <a href="/format/2311.11267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Large Language Models in Mental Health Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>, 
<a href="/search/cs?searchtype=author&query=Cambria%2C+E">Erik Cambria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12435" title="Abstract">arXiv:2311.12435</a> (replaced) [<a href="/pdf/2311.12435" title="Download PDF">pdf</a>, <a href="/format/2311.12435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Enough? A map of the current limitations of the requirements to  have &quot;fair&quot; algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castelnovo%2C+A">Alessandro Castelnovo</a>, 
<a href="/search/cs?searchtype=author&query=Inverardi%2C+N">Nicole Inverardi</a>, 
<a href="/search/cs?searchtype=author&query=Nanino%2C+G">Gabriele Nanino</a>, 
<a href="/search/cs?searchtype=author&query=Penco%2C+I+G">Ilaria Giuseppina Penco</a>, 
<a href="/search/cs?searchtype=author&query=Regoli%2C+D">Daniele Regoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures, 2 tables. V2: added reference, update info on AI Act
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12813" title="Abstract">arXiv:2311.12813</a> (replaced) [<a href="/pdf/2311.12813" title="Download PDF">pdf</a>, <a href="/format/2311.12813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Activation Penalties Help CNNs Ignore Spurious Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M">Matthew Williams</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages including appendix; extended version of a paper accepted to AAAI-2024 under the same title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13155" title="Abstract">arXiv:2311.13155</a> (replaced) [<a href="/pdf/2311.13155" title="Download PDF">pdf</a>, <a href="/format/2311.13155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A threshold-type algorithm to the gradient flow of the Canham-Helfrich  functional
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishii%2C+K">Katsuyuki Ishii</a>, 
<a href="/search/math?searchtype=author&query=Kohsaka%2C+Y">Yoshihito Kohsaka</a>, 
<a href="/search/math?searchtype=author&query=Miyake%2C+N">Nobuhito Miyake</a>, 
<a href="/search/math?searchtype=author&query=Sakakibara%2C+K">Koya Sakakibara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13444" title="Abstract">arXiv:2311.13444</a> (replaced) [<a href="/pdf/2311.13444" title="Download PDF">pdf</a>, <a href="/format/2311.13444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkeletonGait: Gait Recognition Using Skeleton Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingzhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Dongyang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chuanfu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13648" title="Abstract">arXiv:2311.13648</a> (replaced) [<a href="/pdf/2311.13648" title="Download PDF">pdf</a>, <a href="/format/2311.13648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Pretrained models for Deployable Lifelong Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekkala%2C+K">Kiran Lekkala</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+E">Eshan Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yunhao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission to CoLLA 2024. Also published in the Proceedings of WACV 2024 Workshop on Pretraining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14865" title="Abstract">arXiv:2311.14865</a> (replaced) [<a href="/pdf/2311.14865" title="Download PDF">pdf</a>, <a href="/format/2311.14865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Cross-Domain Hate Speech Generalizability with Emotion  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+Y">Shi Yin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+S">Susan Gauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Pacific Asia Conference on Language, Information and Computation (PACLIC 37)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15145" title="Abstract">arXiv:2311.15145</a> (replaced) [<a href="/pdf/2311.15145" title="Download PDF">pdf</a>, <a href="/format/2311.15145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing Wisely and Learning Deeply: Selective Cross-Modality  Distillation via CLIP for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jixuan Leng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15786" title="Abstract">arXiv:2311.15786</a> (replaced) [<a href="/pdf/2311.15786" title="Download PDF">pdf</a>, <a href="/ps/2311.15786" title="Download PostScript">ps</a>, <a href="/format/2311.15786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YUAN 2.0: A Large Language Model with Localized Filtering-based  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shaohua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xudong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiangang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17326" title="Abstract">arXiv:2311.17326</a> (replaced) [<a href="/pdf/2311.17326" title="Download PDF">pdf</a>, <a href="/format/2311.17326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mostly Beneficial Clustering: Aggregating Data for Operational Decision  Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenkang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Ying Rong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17401" title="Abstract">arXiv:2311.17401</a> (replaced) [<a href="/pdf/2311.17401" title="Download PDF">pdf</a>, <a href="/ps/2311.17401" title="Download PostScript">ps</a>, <a href="/format/2311.17401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gene-MOE: A sparsely gated prognosis and classification framework  exploiting pan-cancer genomic information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huanhuan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lian Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongzhen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Long Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18550" title="Abstract">arXiv:2311.18550</a> (replaced) [<a href="/pdf/2311.18550" title="Download PDF">pdf</a>, <a href="/ps/2311.18550" title="Download PostScript">ps</a>, <a href="/format/2311.18550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Still Matters: Information Retrieval in the Era of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hersh%2C+W+R">William R. Hersh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00347" title="Abstract">arXiv:2312.00347</a> (replaced) [<a href="/pdf/2312.00347" title="Download PDF">pdf</a>, <a href="/format/2312.00347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTQ: Rethinking Video-language Understanding Based on Image-text Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+T">Tian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jingjing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023 as Oral representation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In International Conference on Multimedia. ACM, 557--566 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00377" title="Abstract">arXiv:2312.00377</a> (replaced) [<a href="/pdf/2312.00377" title="Download PDF">pdf</a>, <a href="/format/2312.00377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynFundus: A synthetic fundus images dataset with millions of samples  and multi-disease annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+F">Fangxin Shang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yehui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01040" title="Abstract">arXiv:2312.01040</a> (replaced) [<a href="/pdf/2312.01040" title="Download PDF">pdf</a>, <a href="/format/2312.01040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Beginner to Expert: Modeling Medical Knowledge into General LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoyan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+M">Mingyuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yicheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Teng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guannan+Zhang+Ant+Group">Guannan Zhang Ant Group</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Developed by Ant Group for PubMedQA leaderboard
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01090" title="Abstract">arXiv:2312.01090</a> (replaced) [<a href="/pdf/2312.01090" title="Download PDF">pdf</a>, <a href="/format/2312.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self Generated Wargame AI: Double Layer Agent Task Planning Based on  Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Y.Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">J.Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">C.Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">W.Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">X.Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01479" title="Abstract">arXiv:2312.01479</a> (replaced) [<a href="/pdf/2312.01479" title="Download PDF">pdf</a>, <a href="/format/2312.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenVoice: Versatile Instant Voice Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zengyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xumin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01597" title="Abstract">arXiv:2312.01597</a> (replaced) [<a href="/pdf/2312.01597" title="Download PDF">pdf</a>, <a href="/format/2312.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01916" title="Abstract">arXiv:2312.01916</a> (replaced) [<a href="/pdf/2312.01916" title="Download PDF">pdf</a>, <a href="/format/2312.01916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEACE: Prototype lEarning Augmented transferable framework for  Cross-domain rEcommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chunjing Gan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenliang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02025" title="Abstract">arXiv:2312.02025</a> (replaced) [<a href="/pdf/2312.02025" title="Download PDF">pdf</a>, <a href="/format/2312.02025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Synchronized Trichel Pulse Trains in Multi-Point Corona Discharge  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shaygani%2C+A">Afshin Shaygani</a>, 
<a href="/search/physics?searchtype=author&query=Adamiak%2C+K">Kazimierz Adamiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02102" title="Abstract">arXiv:2312.02102</a> (replaced) [<a href="/pdf/2312.02102" title="Download PDF">pdf</a>, <a href="/format/2312.02102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Data Injection Attacks on Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shalom%2C+O">Or Shalom</a>, 
<a href="/search/cs?searchtype=author&query=Leshem%2C+A">Amir Leshem</a>, 
<a href="/search/cs?searchtype=author&query=Bajwa%2C+W+U">Waheed U. Bajwa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02222" title="Abstract">arXiv:2312.02222</a> (replaced) [<a href="/pdf/2312.02222" title="Download PDF">pdf</a>, <a href="/format/2312.02222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvertAvatar: Incremental GAN Inversion for Generalized Head Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02246" title="Abstract">arXiv:2312.02246</a> (replaced) [<a href="/pdf/2312.02246" title="Download PDF">pdf</a>, <a href="/format/2312.02246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Variational Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=della+Maggiora%2C+G">Gabriel della Maggiora</a>, 
<a href="/search/cs?searchtype=author&query=Croquevielle%2C+L+A">Luis Alberto Croquevielle</a>, 
<a href="/search/cs?searchtype=author&query=Desphande%2C+N">Nikita Desphande</a>, 
<a href="/search/cs?searchtype=author&query=Horsley%2C+H">Harry Horsley</a>, 
<a href="/search/cs?searchtype=author&query=Heinis%2C+T">Thomas Heinis</a>, 
<a href="/search/cs?searchtype=author&query=Yakimovich%2C+A">Artur Yakimovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Denoising Diffusion Probabilistic Models, Inverse Problems, Generative Models, Super Resolution, Phase Quantification, Variational Methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02668" title="Abstract">arXiv:2312.02668</a> (replaced) [<a href="/pdf/2312.02668" title="Download PDF">pdf</a>, <a href="/ps/2312.02668" title="Download PostScript">ps</a>, <a href="/format/2312.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Nash Equilibria Algorithms for Shapley Network Design Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+H">Hangxin Gan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xianhao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Chunying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongtang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02674" title="Abstract">arXiv:2312.02674</a> (replaced) [<a href="/pdf/2312.02674" title="Download PDF">pdf</a>, <a href="/format/2312.02674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortized Bayesian Decision Making for simulation-based models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorecki%2C+M">Mila Gorecki</a>, 
<a href="/search/cs?searchtype=author&query=Macke%2C+J+H">Jakob H. Macke</a>, 
<a href="/search/cs?searchtype=author&query=Deistler%2C+M">Michael Deistler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02855" title="Abstract">arXiv:2312.02855</a> (replaced) [<a href="/pdf/2312.02855" title="Download PDF">pdf</a>, <a href="/format/2312.02855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Error Bits for Memory Failure Prediction: An In-Depth  Correlative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wengui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J">Jorge Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCAD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/ACM International Conference on Computer Aided Design
  (ICCAD), San Francisco, CA, USA, 2023, pp. 01-09
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03360" title="Abstract">arXiv:2312.03360</a> (replaced) [<a href="/pdf/2312.03360" title="Download PDF">pdf</a>, <a href="/ps/2312.03360" title="Download PostScript">ps</a>, <a href="/format/2312.03360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Specific Scientific Knowledge into Large Language Models  through Additional Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatakeyama-Sato%2C+K">Kan Hatakeyama-Sato</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+Y">Yasuhiko Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Katakami%2C+S">Shun Katakami</a>, 
<a href="/search/cs?searchtype=author&query=Nabae%2C+Y">Yuta Nabae</a>, 
<a href="/search/cs?searchtype=author&query=Hayakawa%2C+T">Teruaki Hayakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added token information for some texts, and fixed typo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03373" title="Abstract">arXiv:2312.03373</a> (replaced) [<a href="/pdf/2312.03373" title="Download PDF">pdf</a>, <a href="/format/2312.03373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnvGuard: Guaranteeing Environment-Centric Safety and Security  Properties in Web of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bingkun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liwei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jialin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04875" title="Abstract">arXiv:2312.04875</a> (replaced) [<a href="/pdf/2312.04875" title="Download PDF">pdf</a>, <a href="/format/2312.04875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVDD: Multi-View Depth Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05429" title="Abstract">arXiv:2312.05429</a> (replaced) [<a href="/pdf/2312.05429" title="Download PDF">pdf</a>, <a href="/ps/2312.05429" title="Download PostScript">ps</a>, <a href="/format/2312.05429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Nonlinear Algorithmic Bias in Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+W">Wendy Hui</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+W+K">Wai Kwong Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 12 tables. arXiv admin note: text overlap with <a href="/abs/2310.12421">arXiv:2310.12421</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05705" title="Abstract">arXiv:2312.05705</a> (replaced) [<a href="/pdf/2312.05705" title="Download PDF">pdf</a>, <a href="/format/2312.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Inverse-Free Natural Gradient: Memory-Efficient &amp;  Numerically-Stable KFAC for Large Neural Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dangel%2C+F">Felix Dangel</a>, 
<a href="/search/cs?searchtype=author&query=Eschenhagen%2C+R">Runa Eschenhagen</a>, 
<a href="/search/cs?searchtype=author&query=Neklyudov%2C+K">Kirill Neklyudov</a>, 
<a href="/search/cs?searchtype=author&query=Kristiadi%2C+A">Agustinus Kristiadi</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated Sec 3.2 to include more discussion about challenges of proposing a structured and inverse-free update rule
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05772" title="Abstract">arXiv:2312.05772</a> (replaced) [<a href="/pdf/2312.05772" title="Download PDF">pdf</a>, <a href="/format/2312.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Code Generation Framework for Code Repositories: Local,  Global, and Third-Party Library Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Dianshu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinying Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05797" title="Abstract">arXiv:2312.05797</a> (replaced) [<a href="/pdf/2312.05797" title="Download PDF">pdf</a>, <a href="/format/2312.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality in Online Education: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Immadisetty%2C+P">Praneeta Immadisetty</a>, 
<a href="/search/cs?searchtype=author&query=Rajesh%2C+P">Pooja Rajesh</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+A+M">Anala M R</a>, 
<a href="/search/cs?searchtype=author&query=A%2C+S">Soumya A</a>, 
<a href="/search/cs?searchtype=author&query=Subramanya%2C+K+N">K. N. Subramanya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05955" title="Abstract">arXiv:2312.05955</a> (replaced) [<a href="/pdf/2312.05955" title="Download PDF">pdf</a>, <a href="/format/2312.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Differentiable Particle Filter on the Fly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05974" title="Abstract">arXiv:2312.05974</a> (replaced) [<a href="/pdf/2312.05974" title="Download PDF">pdf</a>, <a href="/format/2312.05974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Causal Structure of Networked Dynamical Systems under  Latent Nodes and Structured Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">Augusto Santos</a>, 
<a href="/search/cs?searchtype=author&query=Rente%2C+D">Diogo Rente</a>, 
<a href="/search/cs?searchtype=author&query=Seabra%2C+R">Rui Seabra</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J+M+F">Jos&#xe9; M. F. Moura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 38th AAAI Conference on Artificial Intelligence (Main Track). Camera-Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06165" title="Abstract">arXiv:2312.06165</a> (replaced) [<a href="/pdf/2312.06165" title="Download PDF">pdf</a>, <a href="/format/2312.06165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecJPQ: Training Large-Catalogue Sequential Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrov%2C+A+V">Aleksandr V. Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06198" title="Abstract">arXiv:2312.06198</a> (replaced) [<a href="/pdf/2312.06198" title="Download PDF">pdf</a>, <a href="/format/2312.06198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized View and Geometry Distillation from Multi-view Diffuser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://youjiazhang.github.io/USD/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06200" title="Abstract">arXiv:2312.06200</a> (replaced) [<a href="/pdf/2312.06200" title="Download PDF">pdf</a>, <a href="/format/2312.06200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving the Fundamental Limit of Lossless Analog Compression via  Polarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liuquan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huazi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures. The short version is presented at the IEEE Global Communications Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06290" title="Abstract">arXiv:2312.06290</a> (replaced) [<a href="/pdf/2312.06290" title="Download PDF">pdf</a>, <a href="/format/2312.06290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Label Skews in Federated Learning with Model Concatenation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yiqun Diao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06372" title="Abstract">arXiv:2312.06372</a> (replaced) [<a href="/pdf/2312.06372" title="Download PDF">pdf</a>, <a href="/format/2312.06372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yufei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaode Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhe Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06683" title="Abstract">arXiv:2312.06683</a> (replaced) [<a href="/pdf/2312.06683" title="Download PDF">pdf</a>, <a href="/format/2312.06683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AT4CTR: Auxiliary Match Tasks for Enhancing Click-Through Rate  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xuyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jun Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06833" title="Abstract">arXiv:2312.06833</a> (replaced) [<a href="/pdf/2312.06833" title="Download PDF">pdf</a>, <a href="/ps/2312.06833" title="Download PostScript">ps</a>, <a href="/format/2312.06833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The unreasonable effectiveness of AI CADe polyp detectors to generalize  to new countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shor%2C+J">Joel Shor</a>, 
<a href="/search/cs?searchtype=author&query=Yamano%2C+H">Hiro-o Yamano</a>, 
<a href="/search/cs?searchtype=author&query=Tsurumaru%2C+D">Daisuke Tsurumaru</a>, 
<a href="/search/cs?searchtype=author&query=Intrator%2C+Y">Yotami Intrator</a>, 
<a href="/search/cs?searchtype=author&query=Kayama%2C+H">Hiroki Kayama</a>, 
<a href="/search/cs?searchtype=author&query=Ledsam%2C+J">Joe Ledsam</a>, 
<a href="/search/cs?searchtype=author&query=Hamabe%2C+A">Atsushi Hamabe</a>, 
<a href="/search/cs?searchtype=author&query=Ando%2C+K">Koji Ando</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+M">Mitsuhiko Ota</a>, 
<a href="/search/cs?searchtype=author&query=Ogino%2C+H">Haruei Ogino</a>, 
<a href="/search/cs?searchtype=author&query=Nakase%2C+H">Hiroshi Nakase</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Kaho Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Oki%2C+E">Eiji Oki</a>, 
<a href="/search/cs?searchtype=author&query=Goldenberg%2C+R">Roman Goldenberg</a>, 
<a href="/search/cs?searchtype=author&query=Rivlin%2C+E">Ehud Rivlin</a>, 
<a href="/search/cs?searchtype=author&query=Takemasa%2C+I">Ichiro Takemasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06872" title="Abstract">arXiv:2312.06872</a> (replaced) [<a href="/pdf/2312.06872" title="Download PDF">pdf</a>, <a href="/format/2312.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELSA: Partial Weight Freezing for Overhead-Free Sparse Network  Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halvachi%2C+P">Paniz Halvachi</a>, 
<a href="/search/cs?searchtype=author&query=Peste%2C+A">Alexandra Peste</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+C+H">Christoph H. Lampert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated to reflect PackNet prior work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06901" title="Abstract">arXiv:2312.06901</a> (replaced) [<a href="/pdf/2312.06901" title="Download PDF">pdf</a>, <a href="/format/2312.06901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Extractive Summarization with Learnable Length Control  Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jie%2C+R">Renlong Jie</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiaojun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06988" title="Abstract">arXiv:2312.06988</a> (replaced) [<a href="/pdf/2312.06988" title="Download PDF">pdf</a>, <a href="/format/2312.06988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box  Annotations for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangfeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pai Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07144" title="Abstract">arXiv:2312.07144</a> (replaced) [<a href="/pdf/2312.07144" title="Download PDF">pdf</a>, <a href="/format/2312.07144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Parameterized Complexity of Coordinated Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared in SoCG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07392" title="Abstract">arXiv:2312.07392</a> (replaced) [<a href="/pdf/2312.07392" title="Download PDF">pdf</a>, <a href="/format/2312.07392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReRoGCRL: Representation-based Robustness in Goal-Conditioned  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+W">Wenjie Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in AAAI24 (<a href="https://aaai.org/aaai-conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07398" title="Abstract">arXiv:2312.07398</a> (replaced) [<a href="/pdf/2312.07398" title="Download PDF">pdf</a>, <a href="/format/2312.07398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMEval: A Preliminary Study on How to Evaluate Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haipeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongyao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07492" title="Abstract">arXiv:2312.07492</a> (replaced) [<a href="/pdf/2312.07492" title="Download PDF">pdf</a>, <a href="/format/2312.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagireddy%2C+M">Manish Nagireddy</a>, 
<a href="/search/cs?searchtype=author&query=Chiazor%2C+L">Lamogha Chiazor</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Moninder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+I">Ioana Baldini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07547" title="Abstract">arXiv:2312.07547</a> (replaced) [<a href="/pdf/2312.07547" title="Download PDF">pdf</a>, <a href="/format/2312.07547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Inference and Intentional Behaviour
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Friston%2C+K+J">Karl J. Friston</a>, 
<a href="/search/q-bio?searchtype=author&query=Salvatori%2C+T">Tommaso Salvatori</a>, 
<a href="/search/q-bio?searchtype=author&query=Isomura%2C+T">Takuya Isomura</a>, 
<a href="/search/q-bio?searchtype=author&query=Tschantz%2C+A">Alexander Tschantz</a>, 
<a href="/search/q-bio?searchtype=author&query=Kiefer%2C+A">Alex Kiefer</a>, 
<a href="/search/q-bio?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/q-bio?searchtype=author&query=Koudahl%2C+M">Magnus Koudahl</a>, 
<a href="/search/q-bio?searchtype=author&query=Paul%2C+A">Aswin Paul</a>, 
<a href="/search/q-bio?searchtype=author&query=Parr%2C+T">Thomas Parr</a>, 
<a href="/search/q-bio?searchtype=author&query=Razi%2C+A">Adeel Razi</a>, 
<a href="/search/q-bio?searchtype=author&query=Kagan%2C+B">Brett Kagan</a>, 
<a href="/search/q-bio?searchtype=author&query=Buckley%2C+C+L">Christopher L. Buckley</a>, 
<a href="/search/q-bio?searchtype=author&query=Ramstead%2C+M+J+D">Maxwell J. D. Ramstead</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07696" title="Abstract">arXiv:2312.07696</a> (replaced) [<a href="/pdf/2312.07696" title="Download PDF">pdf</a>, <a href="/ps/2312.07696" title="Download PostScript">ps</a>, <a href="/format/2312.07696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Network Intrusion Detection via Decision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanhan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yongsheng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+G">Gina Adam</a>, 
<a href="/search/cs?searchtype=author&query=Bastian%2C+N+D">Nathaniel D. Bastian</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07753" title="Abstract">arXiv:2312.07753</a> (replaced) [<a href="/pdf/2312.07753" title="Download PDF">pdf</a>, <a href="/format/2312.07753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-based Self-Attention for Table Representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07759" title="Abstract">arXiv:2312.07759</a> (replaced) [<a href="/pdf/2312.07759" title="Download PDF">pdf</a>, <a href="/ps/2312.07759" title="Download PostScript">ps</a>, <a href="/format/2312.07759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDKM: Memory Efficient Neural Network Quantization via Implicit,  Differentiable k-Means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaffe%2C+S">Sean Jaffe</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Ambuj K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07823" title="Abstract">arXiv:2312.07823</a> (replaced) [<a href="/pdf/2312.07823" title="Download PDF">pdf</a>, <a href="/format/2312.07823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Lens: Instance-Centric Semantic Alignment for Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07827" title="Abstract">arXiv:2312.07827</a> (replaced) [<a href="/pdf/2312.07827" title="Download PDF">pdf</a>, <a href="/format/2312.07827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Fully Dynamic Directed Densest Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Richard Li</a>, 
<a href="/search/cs?searchtype=author&query=Quanrud%2C+K">Kent Quanrud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07859" title="Abstract">arXiv:2312.07859</a> (replaced) [<a href="/pdf/2312.07859" title="Download PDF">pdf</a>, <a href="/format/2312.07859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Graph Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Menghai Pan</a> (2), 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzhong Chen</a> (2), 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a> (2), 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuchen Yan</a> (1), 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mahashweta Das</a> (2), 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a> (1) ((1) University of Illinois Urbana-Champaign, (2) Visa Research)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07877" title="Abstract">arXiv:2312.07877</a> (replaced) [<a href="/pdf/2312.07877" title="Download PDF">pdf</a>, <a href="/format/2312.07877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment-Based Formal Verification of WiFi Fragmentation and Power Save  Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+I">Imtiaz Karim</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AsiaCCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07913" title="Abstract">arXiv:2312.07913</a> (replaced) [<a href="/pdf/2312.07913" title="Download PDF">pdf</a>, <a href="/format/2312.07913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Text Watermarking in the Era of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yijian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08064" title="Abstract">arXiv:2312.08064</a> (replaced) [<a href="/pdf/2312.08064" title="Download PDF">pdf</a>, <a href="/format/2312.08064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Lay User Feedback for Improving AI Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taka%2C+E">Evdoxia Taka</a>, 
<a href="/search/cs?searchtype=author&query=Nakao%2C+Y">Yuri Nakao</a>, 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+R">Ryosuke Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+T">Takuya Yokota</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+S">Simone Stumpf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08168" title="Abstract">arXiv:2312.08168</a> (replaced) [<a href="/pdf/2312.08168" title="Download PDF">pdf</a>, <a href="/format/2312.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat-3D v2: Bridging 3D Scene and Large Language Models with Object  Identifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xize Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08343" title="Abstract">arXiv:2312.08343</a> (replaced) [<a href="/pdf/2312.08343" title="Download PDF">pdf</a>, <a href="/ps/2312.08343" title="Download PostScript">ps</a>, <a href="/format/2312.08343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing CT Image synthesis from multi-modal MRI data based on a  multi-task neural network framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xin%2C+Z">Zhuoyao Xin</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Christopher Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+C">Chunming Gu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/eess?searchtype=author&query=Hua%2C+J">Jun Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08386" title="Abstract">arXiv:2312.08386</a> (replaced) [<a href="/pdf/2312.08386" title="Download PDF">pdf</a>, <a href="/format/2312.08386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerfectTailor: Scale-Preserving 2D Pattern Adjustment Driven by 3D  Garment Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+A">Anran Qi</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+T">Takeo Igarashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08470" title="Abstract">arXiv:2312.08470</a> (replaced) [<a href="/pdf/2312.08470" title="Download PDF">pdf</a>, <a href="/ps/2312.08470" title="Download PostScript">ps</a>, <a href="/format/2312.08470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best practices for machine learning in antibody discovery and  development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wossnig%2C+L">Leonard Wossnig</a>, 
<a href="/search/q-bio?searchtype=author&query=Furtmann%2C+N">Norbert Furtmann</a>, 
<a href="/search/q-bio?searchtype=author&query=Buchanan%2C+A">Andrew Buchanan</a>, 
<a href="/search/q-bio?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>, 
<a href="/search/q-bio?searchtype=author&query=Greiff%2C+V">Victor Greiff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08533" title="Abstract">arXiv:2312.08533</a> (replaced) [<a href="/pdf/2312.08533" title="Download PDF">pdf</a>, <a href="/format/2312.08533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> World Models via Policy-Guided Trajectory Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigter%2C+M">Marc Rigter</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+J">Jun Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08557" title="Abstract">arXiv:2312.08557</a> (replaced) [<a href="/pdf/2312.08557" title="Download PDF">pdf</a>, <a href="/format/2312.08557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating and Querying Data Cubes in Python using pyCube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vang%2C+S">Sigmundur Vang</a>, 
<a href="/search/cs?searchtype=author&query=Thomsen%2C+C">Christian Thomsen</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T+B">Torben Bach Pedersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of DOLAP2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08579" title="Abstract">arXiv:2312.08579</a> (replaced) [<a href="/pdf/2312.08579" title="Download PDF">pdf</a>, <a href="/format/2312.08579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Planetary Names in Astronomy Papers: A Multi-Step Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapurian%2C+G">Golnaz Shapurian</a>, 
<a href="/search/cs?searchtype=author&query=Kurtz%2C+M+J">Michael J Kurtz</a>, 
<a href="/search/cs?searchtype=author&query=Accomazzi%2C+A">Alberto Accomazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08583" title="Abstract">arXiv:2312.08583</a> (replaced) [<a href="/pdf/2312.08583" title="Download PDF">pdf</a>, <a href="/format/2312.08583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroQuant(4+2): Redefining LLMs Quantization with a New FP6-Centric  Strategy for Diverse Generative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haojun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+S">Stephen Youn</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bakhtiari%2C+A">Arash Bakhtiari</a>, 
<a href="/search/cs?searchtype=author&query=Wyatt%2C+M">Michael Wyatt</a>, 
<a href="/search/cs?searchtype=author&query=Aminabadi%2C+R+Y">Reza Yazdani Aminabadi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>, 
<a href="/search/cs?searchtype=author&query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Leon Song</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08606" title="Abstract">arXiv:2312.08606</a> (replaced) [<a href="/pdf/2312.08606" title="Download PDF">pdf</a>, <a href="/format/2312.08606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQCNIR: Clearer Night Image Restoration with Vector-Quantized Codebook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wenbin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongxia Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shasha Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongsheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sixiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08656" title="Abstract">arXiv:2312.08656</a> (replaced) [<a href="/pdf/2312.08656" title="Download PDF">pdf</a>, <a href="/format/2312.08656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural  Networks Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shivdikar%2C+K">Kaustubh Shivdikar</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+A">MD Amit Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+O">Omer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kaeli%2C+D">David Kaeli</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASPLOS 2024 accepted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08660" title="Abstract">arXiv:2312.08660</a> (replaced) [<a href="/pdf/2312.08660" title="Download PDF">pdf</a>, <a href="/format/2312.08660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank constrained multichannel signal denoising considering  channel-dependent sensitivity inspired by self-supervised learning for  optical fiber sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonami%2C+N">Noriyuki Tonami</a>, 
<a href="/search/cs?searchtype=author&query=Kohno%2C+W">Wataru Kohno</a>, 
<a href="/search/cs?searchtype=author&query=Mishima%2C+S">Sakiko Mishima</a>, 
<a href="/search/cs?searchtype=author&query=Arai%2C+Y">Yumi Arai</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+R">Reishi Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Hino%2C+T">Tomoyuki Hino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08684" title="Abstract">arXiv:2312.08684</a> (replaced) [<a href="/pdf/2312.08684" title="Download PDF">pdf</a>, <a href="/format/2312.08684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stein-MAP: A Sequential Variational Inference Framework for Maximum A  Posteriori Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Min-Won Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kia%2C+S+S">Solmaz S. Kia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08726" title="Abstract">arXiv:2312.08726</a> (replaced) [<a href="/pdf/2312.08726" title="Download PDF">pdf</a>, <a href="/format/2312.08726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Labels Need Prompts Too: Mask Matching for Natural Language  Understanding Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quansen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, Regular Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08737" title="Abstract">arXiv:2312.08737</a> (replaced) [<a href="/pdf/2312.08737" title="Download PDF">pdf</a>, <a href="/format/2312.08737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JPIS: A Joint Model for Profile-based Intent Detection and Slot Filling  with Slot-to-Intent Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thinh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Dat Quoc Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings of ICASSP 2024 (Camera-ready version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08746" title="Abstract">arXiv:2312.08746</a> (replaced) [<a href="/pdf/2312.08746" title="Download PDF">pdf</a>, <a href="/format/2312.08746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamDrone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">Hanyang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Dongze Lian</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, project page: <a href="https://hyokong.github.io/dreamdrone-page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08763" title="Abstract">arXiv:2312.08763</a> (replaced) [<a href="/pdf/2312.08763" title="Download PDF">pdf</a>, <a href="/format/2312.08763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Polar Representation: An Extreme-Adaptive Model for  Long-Term Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jack Xu</a>, 
<a href="/search/cs?searchtype=author&query=Anastasiu%2C+D+C">David C. Anastasiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08793" title="Abstract">arXiv:2312.08793</a> (replaced) [<a href="/pdf/2312.08793" title="Download PDF">pdf</a>, <a href="/format/2312.08793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forbidden Facts: An Investigation of Competing Objectives in Llama-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+T">Tony T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miles Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+K">Kaivalya Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Shavit%2C+N">Nir Shavit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ATTRIB and SoLaR workshops at NeurIPS 2023; (v2: fixed typos)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08818" title="Abstract">arXiv:2312.08818</a> (replaced) [<a href="/pdf/2312.08818" title="Download PDF">pdf</a>, <a href="/ps/2312.08818" title="Download PostScript">ps</a>, <a href="/format/2312.08818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyber-Physical Architecture for Microgrids based on Deep learning and  LORA Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mojtaba Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=KavousiFard%2C+A">Abdollah KavousiFard</a>, 
<a href="/search/cs?searchtype=author&query=Dabbaghjamanesh%2C+M">Mortza Dabbaghjamanesh</a>, 
<a href="/search/cs?searchtype=author&query=Shaaban%2C+M">Mostafa Shaaban</a>, 
<a href="/search/cs?searchtype=author&query=Zeineldin%2C+H+H">Hatem. H. Zeineldin</a>, 
<a href="/search/cs?searchtype=author&query=El-Saadany%2C+E+F">Ehab Fahmy El-Saadany</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08906" title="Abstract">arXiv:2312.08906</a> (replaced) [<a href="/pdf/2312.08906" title="Download PDF">pdf</a>, <a href="/format/2312.08906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using eye tracking to investigate what native Chinese speakers notice  about linguistic landscape images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zichao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yewei Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08916" title="Abstract">arXiv:2312.08916</a> (replaced) [<a href="/pdf/2312.08916" title="Download PDF">pdf</a>, <a href="/format/2312.08916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Feature Self-reinforcement for Weakly Supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chaowei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zunlei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tingting Mu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08926" title="Abstract">arXiv:2312.08926</a> (replaced) [<a href="/e-print/2312.08926" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Complex Mathematical Reasoning via Large Language Model based  MathAgent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haoran Liao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qinyi Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shaohua Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jidong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are unfair comparisons on miniF2F. This will be fixed in the future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08985" title="Abstract">arXiv:2312.08985</a> (replaced) [<a href="/pdf/2312.08985" title="Download PDF">pdf</a>, <a href="/format/2312.08985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OMG: Towards Open-vocabulary Motion Generation via Mixture of  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Han Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jiacheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sihan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuecheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1140">[1140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09002" title="Abstract">arXiv:2312.09002</a> (replaced) [<a href="/pdf/2312.09002" title="Download PDF">pdf</a>, <a href="/format/2312.09002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization with Reconfigurable Intelligent Surface: An Active Sensing  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Wireless Communications. This is an extended version of the previous arXiv paper <a href="/abs/2310.13160">arXiv:2310.13160</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1141">[1141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09038" title="Abstract">arXiv:2312.09038</a> (replaced) [<a href="/pdf/2312.09038" title="Download PDF">pdf</a>, <a href="/format/2312.09038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Recognition from Scientific Document based on Compartment  Refinement Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinghong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Wen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+K">Koichi Ota</a>, 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+S">Shinobu Hasegawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.17401">arXiv:2305.17401</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1142">[1142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09323" title="Abstract">arXiv:2312.09323</a> (replaced) [<a href="/pdf/2312.09323" title="Download PDF">pdf</a>, <a href="/format/2312.09323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspectives on the State and Future of Deep Learning -- 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Baraniuk%2C+R">Richard Baraniuk</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+M">Melanie Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Nakkiran%2C+P">Preetum Nakkiran</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1143">[1143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09404" title="Abstract">arXiv:2312.09404</a> (replaced) [<a href="/pdf/2312.09404" title="Download PDF">pdf</a>, <a href="/format/2312.09404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiasing Enhanced Sampling on a High-dimensional Free Energy Surface  with Deep Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yikai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+T+K">Tushar K. Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item1144">[1144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09494" title="Abstract">arXiv:2312.09494</a> (replaced) [<a href="/pdf/2312.09494" title="Download PDF">pdf</a>, <a href="/format/2312.09494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xudong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1145">[1145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09577" title="Abstract">arXiv:2312.09577</a> (replaced) [<a href="/pdf/2312.09577" title="Download PDF">pdf</a>, <a href="/format/2312.09577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphAr: An Efficient Storage Scheme for Graph Data in Data Lakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weibin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Diwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1146">[1146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09602" title="Abstract">arXiv:2312.09602</a> (replaced) [<a href="/pdf/2312.09602" title="Download PDF">pdf</a>, <a href="/format/2312.09602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modality is All You Need for Transferable Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Youhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hanwen Du</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yongxin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pengpeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fajie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaofang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDE'24 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1147">[1147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09669" title="Abstract">arXiv:2312.09669</a> (replaced) [<a href="/pdf/2312.09669" title="Download PDF">pdf</a>, <a href="/format/2312.09669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silent Guardian: Protecting Text from Malicious Exploitation by Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiawei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaojian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1148">[1148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09783" title="Abstract">arXiv:2312.09783</a> (replaced) [<a href="/pdf/2312.09783" title="Download PDF">pdf</a>, <a href="/format/2312.09783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep the Faith: Faithful Explanations in Convolutional Neural Networks  for Case-Based Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+T+N">Tom Nuno Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Bongratz%2C+F">Fabian Bongratz</a>, 
<a href="/search/cs?searchtype=author&query=Rickmann%2C+A">Anne-Marie Rickmann</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%B6lsterl%2C+S">Sebastian P&#xf6;lsterl</a>, 
<a href="/search/cs?searchtype=author&query=Wachinger%2C+C">Christian Wachinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in proceedings of AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1149">[1149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09857" title="Abstract">arXiv:2312.09857</a> (replaced) [<a href="/pdf/2312.09857" title="Download PDF">pdf</a>, <a href="/format/2312.09857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unsupervised Domain Adaptation for Time Series Classification: a  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+H+I">Hassan Ismail Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Del+Grosso%2C+G">Ganesh Del Grosso</a>, 
<a href="/search/cs?searchtype=author&query=Kerdoncuff%2C+T">Tanguy Kerdoncuff</a>, 
<a href="/search/cs?searchtype=author&query=Boisbunon%2C+A">Aurelie Boisbunon</a>, 
<a href="/search/cs?searchtype=author&query=Saffar%2C+I">Illyyne Saffar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1150">[1150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09888" title="Abstract">arXiv:2312.09888</a> (replaced) [<a href="/pdf/2312.09888" title="Download PDF">pdf</a>, <a href="/format/2312.09888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Computational Fluid Dynamics: In Situ Visualization of NekRS  using SENSEI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mateevitsi%2C+V+A">Victor A. Mateevitsi</a>, 
<a href="/search/cs?searchtype=author&query=Bode%2C+M">Mathis Bode</a>, 
<a href="/search/cs?searchtype=author&query=Ferrier%2C+N">Nicola Ferrier</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+P">Paul Fischer</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6bbert%2C+J+H">Jens Henrik G&#xf6;bbert</a>, 
<a href="/search/cs?searchtype=author&query=Insley%2C+J+A">Joseph A. Insley</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yu-Hsiang Lan</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+M">Misun Min</a>, 
<a href="/search/cs?searchtype=author&query=Papka%2C+M+E">Michael E. Papka</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Saumil Patel</a>, 
<a href="/search/cs?searchtype=author&query=Rizzi%2C+S">Silvio Rizzi</a>, 
<a href="/search/cs?searchtype=author&query=Windgassen%2C+J">Jonathan Windgassen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item1151">[1151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09909" title="Abstract">arXiv:2312.09909</a> (replaced) [<a href="/pdf/2312.09909" title="Download PDF">pdf</a>, <a href="/format/2312.09909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMP: Temporal Motion Propagation for Online Video Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruihuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1152">[1152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09979" title="Abstract">arXiv:2312.09979</a> (replaced) [<a href="/pdf/2312.09979" title="Download PDF">pdf</a>, <a href="/format/2312.09979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRAMoE: Revolutionizing Mixture of Experts for Maintaining World  Knowledge in Language Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+S">Shiliang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1153">[1153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09983" title="Abstract">arXiv:2312.09983</a> (replaced) [<a href="/pdf/2312.09983" title="Download PDF">pdf</a>, <a href="/format/2312.09983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Computationally Efficient Inverse Reinforcement Learning via  Reward Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooke%2C+L+H">Lauren H. Cooke</a>, 
<a href="/search/cs?searchtype=author&query=Klyne%2C+H">Harvey Klyne</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Edwin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Tambe%2C+M">Milind Tambe</a>, 
<a href="/search/cs?searchtype=author&query=Doshi-Velez%2C+F">Finale Doshi-Velez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1154">[1154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10029" title="Abstract">arXiv:2312.10029</a> (replaced) [<a href="/pdf/2312.10029" title="Download PDF">pdf</a>, <a href="/format/2312.10029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges with unsupervised LLM knowledge discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farquhar%2C+S">Sebastian Farquhar</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+V">Vikrant Varma</a>, 
<a href="/search/cs?searchtype=author&query=Kenton%2C+Z">Zachary Kenton</a>, 
<a href="/search/cs?searchtype=author&query=Gasteiger%2C+J">Johannes Gasteiger</a>, 
<a href="/search/cs?searchtype=author&query=Mikulik%2C+V">Vladimir Mikulik</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rohin Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages (38 including references and appendices). First three authors equal contribution, randomised order
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item672">Cross-lists</a></li>
<li><a href="#item742">Replacements</a></li>
</ul>
<small>[ total of 1154 entries:  <b>1-1154</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
